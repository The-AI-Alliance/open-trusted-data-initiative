const data_for_modality_feature_extraction = 
[
	{"name":"autogkb","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAutoGKB Annotation Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe AutoGKB Annotation Benchmark is a comprehensive dataset designed to evaluate models' ability to extract pharmacogenomic variant-drug associations from scientific literature. This ground truth values for this data were compiled by reviewers from PharmGKB. This benchmark addresses the critical need for automated systems that can identify genetic variants, associated drugs, and their clinical relationships from biomedicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shlokn/autogkb.","url":"https://huggingface.co/datasets/shlokn/autogkb","creator_name":"Shlok Natarajan","creator_url":"https://huggingface.co/shlokn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information and advice search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information and advice search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"protein_chain_conformational_states","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSchema description:\n\t\n\nThe manually curated dataset of open-closed monomers is included here as benchmarking_monomeric_open_closed_conformers.csv.  \nColumn descriptions:\n\n\t\n\t\t\n\t\tSchema description:\n\t\n\nThe manually curated dataset of open-closed monomers is included here as benchmarking_monomeric_open_closed_conformers.csv.  \nColumn descriptions:\n\nUNP_ACC | UniProt accession code\nUNP_START | Start of UniProt sequence for given PDBe entries\nUNP_END | End of UniProt sequence for givenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PDBEurope/protein_chain_conformational_states.","url":"https://huggingface.co/datasets/PDBEurope/protein_chain_conformational_states","creator_name":"Protein Data Bank in Europe","creator_url":"https://huggingface.co/PDBEurope","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"X_Twitter_Trending_Topics_August2025","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ¦ X-Twitter Scraper: Real-Time Search and Data Extraction Tool\n\t\n\nSearch and scrape X-Twitter (formerly Twitter) for posts by keyword, account, or trending topics.This no-code tool makes it easy to generate real-time, LLM-ready datasets for any AI or content use case.\nGet started with real-time scraping and instantly structure tweet data into clean JSON.\nStart Scraping\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸš€ Key Features\n\t\n\n\nâš¡ Real-Time Fetch â€“ Stream the latest tweets the moment theyâ€™re posted  \nðŸŽ¯ Flexibleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/X_Twitter_Trending_Topics_August2025.","url":"https://huggingface.co/datasets/Gopher-Lab/X_Twitter_Trending_Topics_August2025","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"limekiln","keyword":"feature-extraction","description":"aliard/limekiln dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aliard/limekiln","creator_name":"ardakanian","creator_url":"https://huggingface.co/aliard","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","ðŸ‡ºðŸ‡¸ Region: US","chemistry"],"keywords_longer_than_N":false},
	{"name":"TAD66K_for_Image_Aesthetics_Assessment","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nWe build a large-scale dataset called the Theme and Aesthetics Dataset with 66K images (TAD66K), which is specifically designed for IAA. Specifically, (1) it is a theme-oriented dataset containing 66K images covering 47 popular themes. All images were carefully selected by hand based on the theme. (2) In addition to common aesthetic criteria, we provide 47 criteria for the 47 themes. Images of each theme are annotated independently, and each image contains at leastâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shuai1995/TAD66K_for_Image_Aesthetics_Assessment.","url":"https://huggingface.co/datasets/Shuai1995/TAD66K_for_Image_Aesthetics_Assessment","creator_name":"He","creator_url":"https://huggingface.co/Shuai1995","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","10K<n<100K","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"raw_data","keyword":"feature-extraction","description":"\n","url":"https://huggingface.co/datasets/SilvioLima/raw_data","creator_name":"Silvio  Lima","creator_url":"https://huggingface.co/SilvioLima","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Collatz_conjecture_100m","keyword":"feature-extraction","description":"\n\n\n\t\n\t\t\n\t\tcollatz_conjecture_100m\n\t\n\nHello, this is the collatz conjecture dataset.\nThe Collatz Conjecture\n\nn is even number, Divide by 2.\nn is odd number, multiply by 3 and add 1.\nrepeat, See if it goes to 1.\nDoes it apply to all natural numbers?\n\nThis concise problem has not yet been proven.\nThis problem is also famous for its beautiful graphs.\nThe dataset contains the paths from 1 to 100 million natural numbers leading to 1.\nThe path where a single digit in a row becomes 1 is displayedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/taery/Collatz_conjecture_100m.","url":"https://huggingface.co/datasets/taery/Collatz_conjecture_100m","creator_name":"KwakTaeKyung","creator_url":"https://huggingface.co/taery","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","English","Korean","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Optimized_Video_Facial_Landmarks","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for 478-Point Normalized 3D Facial Landmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides pre-extracted, normalized 3D facial landmark features derived from the Video Emotion dataset. It is optimized for efficient training of emotion recognition and facial analysis models, bypassing the need to process large raw video files.\nLicense: The extracted feature data in this Parquet file is licensed under Apache 2.0. Note that the original source video files mayâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PSewmuthu/Optimized_Video_Facial_Landmarks.","url":"https://huggingface.co/datasets/PSewmuthu/Optimized_Video_Facial_Landmarks","creator_name":"Pasindu Sewmuthu Abewickrama Singhe","creator_url":"https://huggingface.co/PSewmuthu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","face-detection","thnhthngchu/video-emotion","English"],"keywords_longer_than_N":true},
	{"name":"entrenamiento","keyword":"feature-extraction","description":"antonypamo/entrenamiento dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/antonypamo/entrenamiento","creator_name":"Antony Padilla Morales","creator_url":"https://huggingface.co/antonypamo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","chemistry"],"keywords_longer_than_N":true},
	{"name":"visual-head","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ” Visual Head Analysis Dataset\n\t\n\n\"Unveiling Visual Perception in Language Models: An Attention Head Analysis Approach\" (CVPR 2025)\n\n\n\n\n\n\n\n\n\n\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nThis dataset contains comprehensive attention analysis results from various Large Multimodal Models (LMMs) across multiple vision-language benchmarks. The data enables research into visual attention patterns, attention head behavior, and multimodal interpretability.\n\t\n\t\t\n\t\tðŸ› ï¸ Associated Tools\n\t\n\nThe accompanying codebaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jing-bi/visual-head.","url":"https://huggingface.co/datasets/jing-bi/visual-head","creator_name":"jing bi","creator_url":"https://huggingface.co/jing-bi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","text-to-image","visual-question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"CompanyDocuments","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCompany Documents Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset comprises a comprehensive collection of over 2,000 company documents, categorized into four primary types: invoices, inventory reports, purchase orders, and shipping orders. Each document is provided in PDF format, along with a CSV file containing the text extracted from these documents, their respective labels, and the word count of each document. This dataset is well-suited for various natural language processing (NLP)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AyoubChLin/CompanyDocuments.","url":"https://huggingface.co/datasets/AyoubChLin/CompanyDocuments","creator_name":"ayoub cherguelaine","creator_url":"https://huggingface.co/AyoubChLin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","zero-shot-classification","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"ai-tech-articles","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAI/Tech Dataset\n\t\n\nThis dataset is a collection of AI/tech articles scraped from the web.\nIt's hosted on HuggingFace Datasets, so it is easier to load in and work with.\n\n\t\n\t\t\n\t\tTo load the dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Install HuggingFace Datasets\n\t\n\npip install datasets\n\n\n\t\n\t\t\n\t\t2. Load the dataset\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"siavava/ai-tech-articles\")\n\n# optionally, convert it to a pandas dataframe:\ndf = dataset[\"train\"].to_pandas()\n\nYou do not need to cloneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/siavava/ai-tech-articles.","url":"https://huggingface.co/datasets/siavava/ai-tech-articles","creator_name":"Amittai","creator_url":"https://huggingface.co/siavava","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"AIXDR","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [Edward Nyameri ]\nFunded by [optional]: [Nil funding but any interested POC is welcome]\nShared by [optional]: [Edward Nyameri ]\nLanguage(s) (NLP): [LLM]\nLicense: [MIT]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nyameri/AIXDR.","url":"https://huggingface.co/datasets/Nyameri/AIXDR","creator_name":"Edward Nyameri","creator_url":"https://huggingface.co/Nyameri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","feature-extraction","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Somali_Food_Dataset_Mini","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Somali Food Mini\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSomali Dataset Mini is a balanced collection of traditional Somali food and drink images.It showcases the culinary diversity of Somalia through six main meal types and 29 food categories.\nEach class contains approximately 100 images, making it ideal for:\n\nComputer vision experiments  \nImage classification projects  \nTransfer learning and CNN model training\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ Dataset Structure\n\t\n\nThis dataset contains imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AbdisamadO/Somali_Food_Dataset_Mini.","url":"https://huggingface.co/datasets/AbdisamadO/Somali_Food_Dataset_Mini","creator_name":"Omar","creator_url":"https://huggingface.co/AbdisamadO","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Somali","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"turkish_corpus","keyword":"feature-extraction","description":"umarigan/turkish_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/umarigan/turkish_corpus","creator_name":"umar igan","creator_url":"https://huggingface.co/umarigan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Turkish","mit","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"deep1b","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdeep1B\n\t\n\ndeep1B data, copied from https://research.yandex.com/blog/benchmarks-for-billion-scale-similarity-search, published:\nBabenko A, Lempitsky V. Efficient indexing of billion-scale datasets of deep descriptors[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 2055-2063.\n\n","url":"https://huggingface.co/datasets/qbo-odp/deep1b","creator_name":"hgf","creator_url":"https://huggingface.co/qbo-odp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","original","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"OpenMind","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tThe OpenMind Dataset: A large-scale Head-And-Neck 3D MRI Dataset for self-supervised learning\n\t\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe OpenMind Dataset is a large-scale 3D MRI dataset of the head and neck region featuring 114k MRI Images. Its purpose is to provide access of large amounts of 3D medical imaging data to accelerate the development of self-supervised learning methods for 3D medical imaging. This data was pooled from exactly 800 datasets from the OpenNeuro platform and provides 23â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AnonRes/OpenMind.","url":"https://huggingface.co/datasets/AnonRes/OpenMind","creator_name":"AnonResearcher","creator_url":"https://huggingface.co/AnonRes","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-feature-extraction","cc-by-4.0","3D","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"boe_2024_dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBOE Spain 2024 Official Documents\n\t\n\n\n\t\n\t\t\n\t\t1. Resource Summary\n\t\n\nThis dataset compiles all official publications from the BoletÃ­n Oficial del Estado (BOE) of Spain throughout the entire year 2024, covering daily governmental communications such as laws, decrees, ministerial resolutions, public appointments, official announcements, and administrative notifications.\nEach entry includes both the structured metadata (like section, department, topic, etc) and the full textual content ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Joz16gg162/boe_2024_dataset.","url":"https://huggingface.co/datasets/Joz16gg162/boe_2024_dataset","creator_name":"SebastiÃ¡n Badajoz GarcÃ­a Godos","creator_url":"https://huggingface.co/Joz16gg162","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","time-series-forecasting","Spanish"],"keywords_longer_than_N":true},
	{"name":"CelebA-attrs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCelebA-128x128\n\t\n\nCelebA with attrs at 128x128 resolution. \n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe attributes are binary attributes. The dataset is already split into train/test/validation sets.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{liu2015faceattributes,\n  title = {Deep Learning Face Attributes in the Wild},\n  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},\n  booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},\n  month = {December},\n  yearâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tpremoli/CelebA-attrs.","url":"https://huggingface.co/datasets/tpremoli/CelebA-attrs","creator_name":"tomas premoli","creator_url":"https://huggingface.co/tpremoli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-classification","image-feature-extraction","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"gibby_dataset","keyword":"feature-extraction","description":"jonathansuru/gibby_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jonathansuru/gibby_dataset","creator_name":"Jonathan Suru","creator_url":"https://huggingface.co/jonathansuru","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","summarization","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"Machine-Identity-Spectra","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMachine Identity Spectra Dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nVenafi is excited to release of the Machine Identity Spectra large dataset. \nThis collection of data contains extracted features from 19m+ certificates discovered over HTTPS (port 443) on the \npublic internet between July 20 and July 26, 2023.\nThe features are a combination of X.509 certificate features, RFC5280 compliance checks, \nand other attributes intended to be used for clustering, features analysis, and a base forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Venafi/Machine-Identity-Spectra.","url":"https://huggingface.co/datasets/Venafi/Machine-Identity-Spectra","creator_name":"Venafi, Inc.","creator_url":"https://huggingface.co/Venafi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"CelebA-attrs","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tCelebA-128x128\n\t\n\nCelebA with attrs at 128x128 resolution. \n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe attributes are binary attributes. The dataset is already split into train/test/validation sets.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{liu2015faceattributes,\n  title = {Deep Learning Face Attributes in the Wild},\n  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},\n  booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},\n  month = {December},\n  yearâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tpremoli/CelebA-attrs.","url":"https://huggingface.co/datasets/tpremoli/CelebA-attrs","creator_name":"tomas premoli","creator_url":"https://huggingface.co/tpremoli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-classification","image-feature-extraction","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"OpenCaselist","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for OpenCaselist\n\t\n\n\n\nA collection of Evidence used in Collegiate and High School debate competitions.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis dataset is a follow up to DebateSum, increasing its scope and amount of metadata collected.\nIt expands the dataset to include evidence used during debate tournaments, rather than just evidence produced during preseason debate \"camps.\" The total amount of evidence is approximately 20x larger than DebateSum.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yusuf5/OpenCaselist.","url":"https://huggingface.co/datasets/Yusuf5/OpenCaselist","creator_name":"Yusuf 5","creator_url":"https://huggingface.co/Yusuf5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-KO","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOpenOrca-KO\n\t\n\n\nOpenOrca dataset ì¤‘ ì•½ 2ë§Œê°œë¥¼ samplingí•˜ì—¬ ë²ˆì—­í•œ ë°ì´í„°ì…‹\në°ì´í„°ì…‹ ì´ìš©í•˜ì…”ì„œ ëª¨ë¸ì´ë‚˜ ë°ì´í„°ì…‹ì„ ë§Œë“œì‹¤ ë•Œ, ê°„ë‹¨í•œ ì¶œì²˜ í‘œê¸°ë¥¼ í•´ì£¼ì‹ ë‹¤ë©´ ì—°êµ¬ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤ðŸ˜­ðŸ˜­\n\n\n\t\n\t\t\n\t\tDataset inf0\n\t\n\n\nNIV // 1571ê°œ  \nFLAN // 9434ê°œ  \nT0 // 6351ê°œ  \nCoT // 2117ê°œ  \nKoCoT // 2159ê°œ\n\n\n\t\n\t\t\n\t\tTranslation\n\t\n\nUsing DeepL Pro API. Thanks.\n\n\nBelow is original dataset card\n\nðŸ‹ The OpenOrca Dataset! ðŸ‹\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kyujinpy/OpenOrca-KO.","url":"https://huggingface.co/datasets/kyujinpy/OpenOrca-KO","creator_name":"KyujinHan","creator_url":"https://huggingface.co/kyujinpy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"msmarco-mxbai-pooled","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tEmbedpress: mixedbread large on MsMarco\n\t\n\nThis is the full MsMarco corpus, embedded with Mixedbread AI's mixedbread-ai/mxbai-embed-large-v1.\nFor each document, we take the first 510 tokens (the model's max length -2 special tokens), and embed it, not using any instructions. Because the model was trained using Matryoshka Representation Learning, these embeddings can safely be truncated.\nThese are mainly useful for large-scale knowledge distillation.\nThe dataset consists of 8.8 millionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stephantulkens/msmarco-mxbai-pooled.","url":"https://huggingface.co/datasets/stephantulkens/msmarco-mxbai-pooled","creator_name":"StÃ©phan Tulkens","creator_url":"https://huggingface.co/stephantulkens","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"SSL4EO-S12-v1.1","keyword":"feature-extraction","description":"dataset details in https://github.com/DLR-MF-DAS/SSL4EO-S12-v1.1\n","url":"https://huggingface.co/datasets/embed2scale/SSL4EO-S12-v1.1","creator_name":"Embed2Scale","creator_url":"https://huggingface.co/embed2scale","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","cc-by-4.0","n>1T","Geospatial","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"reddit_finance_posts_sp500","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tReddit Finance Posts Dataset SP500\n\t\n\nThis dataset contains 431,923 Reddit posts collected from 20 finance-related subreddits via the Reddit API.\nAs keywords, all S&P 500 companies were used. The included subreddits are:\nstocks, wallstreetbets, investing, StockMarket, options, RobinHood,\npennystocks, SecurityAnalysis, personalfinance, Dividends, CryptoCurrency,\nCryptoMarkets, ETFs, FinancialIndependence, ValueInvesting, quant,\nalgotrading, forex, economy, Superstonk, spacsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emilpartow/reddit_finance_posts_sp500.","url":"https://huggingface.co/datasets/emilpartow/reddit_finance_posts_sp500","creator_name":"Emil Partow","creator_url":"https://huggingface.co/emilpartow","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"dfe-stacked_samsum","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"dfe-stacked_samsum\"\n\t\n\nThis custom dataset julep-ai/dfe-stacked_samsum was created from stacked-summaries/stacked-samsum-1024 by:\n\nExtracting summaries for corresponding dialogs to emulate \"facts\"\nThen truncating the dialogs to emulate \"missing information\"\nAnd then augmenting the dialogs using LLMs to emulate \"additional information\"\n\nIt is used to train our Dialog-Fact Encoder model.\n\nThis dataset is permissively licensed under the MIT license.\n\n\n\t\n\t\n\t\n\t\tNotebooksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/julep-ai/dfe-stacked_samsum.","url":"https://huggingface.co/datasets/julep-ai/dfe-stacked_samsum","creator_name":"Julep AI","creator_url":"https://huggingface.co/julep-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Ergonomics_Chiar_Customer_Viewdata_E-commerse","keyword":"feature-extraction","description":"liaHa/Ergonomics_Chiar_Customer_Viewdata_E-commerse dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/liaHa/Ergonomics_Chiar_Customer_Viewdata_E-commerse","creator_name":"lia","creator_url":"https://huggingface.co/liaHa","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","zero-shot-classification","text-to-speech","English"],"keywords_longer_than_N":true},
	{"name":"PypayaNumbers","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for PypayaNumbers\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of images of numbers along with their bounding box coordinates and labels. The dataset is divided into train and test sets, with each set containing images, numbers, and bounding boxes. The numbers are represented as one-line text files, while the bounding boxes are in YOLO format.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset supports the task of Opticalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PypayaTech/PypayaNumbers.","url":"https://huggingface.co/datasets/PypayaTech/PypayaNumbers","creator_name":"PypayaTech","creator_url":"https://huggingface.co/PypayaTech","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US","ocr"],"keywords_longer_than_N":true},
	{"name":"pierogue","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tPierogue\n\t\n\nPierogue is a small open-licensed machine-generated dataset that contains fifteen short texts in English covering five topics, provided with the relevance judgements (qrels), designed for educational purposes.\n\nTopics: cosmos, nature, music, technology, fashion\nSplits: train (10 documents, 375 qrels) and test (5 documents, 150 qrels)\n\nTexts were generated by ChatGPT 3.5. Queries, qrels, and analogies were generated by GPT-4. Words were provided with Word2Vec embeddingsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dustalov/pierogue.","url":"https://huggingface.co/datasets/dustalov/pierogue","creator_name":"Dmitry Ustalov","creator_url":"https://huggingface.co/dustalov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","feature-extraction","text-generation","document-retrieval","language-modeling"],"keywords_longer_than_N":true},
	{"name":"northwind-Stock_rapport","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNorthwind Stock Report Dataset\n\t\n\nThis dataset was created by CHERGUELAINE Ayoub & BOUBEKRI Faycal  for the purpose of document classification and analytics. The dataset contains monthly stock reports and monthly stock reports by category, extracted from the Northwind dataset.\nThe Northwind dataset is a sample database that comes with Microsoft Access, and is commonly used as a demo database for learning SQL. The dataset contains data on a fictional company called \"Northwind Traders\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AyoubChLin/northwind-Stock_rapport.","url":"https://huggingface.co/datasets/AyoubChLin/northwind-Stock_rapport","creator_name":"ayoub cherguelaine","creator_url":"https://huggingface.co/AyoubChLin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"k12-special-education-accommodations","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tK-12 Special Education Accommodations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nComprehensive dataset of special education accommodations, disabilities, and services for K-12 education in the United States. This dataset integrates federal IDEA standards, CEDS taxonomy, OCR compliance data, and state-specific requirements (Texas).\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset provides:\n\nFederal Standards: IDEA disability categories, CEDS taxonomy, educational environments\nAccommodationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/robworks-software/k12-special-education-accommodations.","url":"https://huggingface.co/datasets/robworks-software/k12-special-education-accommodations","creator_name":"Ryan Robson","creator_url":"https://huggingface.co/robworks-software","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","feature-extraction","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"recommender-data","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tThis is the DatasetHub for the recommender database\n\t\n\n\nYou can use this for applying recommended system\n\n","url":"https://huggingface.co/datasets/rmit-denominator/recommender-data","creator_name":"Denominator","creator_url":"https://huggingface.co/rmit-denominator","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Afar","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"medicinal-plants","keyword":"feature-extraction","description":"A growing dataset about medicinal plants. We plan to construct a multimodal dataset with images and text content extracted from \n\nbooks that went out of copywrite and \ndiverse and high-quality video data taken via smart phone and various lenses with a DSLR camera (24mm Macro, 50mm, 100mm Macro and a 24-120mm Zoom lens).\nParts of the iNaturalist and PlantNet300K datasets will be integrated as well to cover a wide spectrum of the kingdom Plantae.\n\nThe resulting dataset should be able to power aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mikehemberger/medicinal-plants.","url":"https://huggingface.co/datasets/mikehemberger/medicinal-plants","creator_name":"Mike Hemberger","creator_url":"https://huggingface.co/mikehemberger","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"Bone_Marrow_BMMCs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for single-cell multiome from bone marrow\n\t\n\n\n\nSingle-cell multiomics data collected from bone marrow mononuclear cells of 12 healthy human donors. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nMultimodal data as a basis for benchmarking\n\"Developing machine learning methods for biological systems is complicated by the difficulty of obtaining ground truth. Typically, machine learning tasks rely on manual annotation (as in images or natural language queries), dynamic measurements (as inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paupaiz/Bone_Marrow_BMMCs.","url":"https://huggingface.co/datasets/paupaiz/Bone_Marrow_BMMCs","creator_name":"Paulina Paiz","creator_url":"https://huggingface.co/paupaiz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","mit","ðŸ‡ºðŸ‡¸ Region: US","biology","medical"],"keywords_longer_than_N":false},
	{"name":"evaluation","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Invoices (Sparrow)\n\t\n\nThis dataset contains 500 invoice documents annotated and processed to be ready for Donut ML model fine-tuning.\nAnnotation and data preparation task was done by Katana ML team.\nSparrow - open-source data extraction solution by Katana ML.\nOriginal dataset info: KozÅ‚owski, Marek; Weichbroth, PaweÅ‚ (2021), â€œSamples of electronic invoicesâ€, Mendeley Data, V2, doi: 10.17632/tnj49gpmtz.2\n","url":"https://huggingface.co/datasets/FelipeBandeiraPoatek/evaluation","creator_name":"Felipe Bandeira","creator_url":"https://huggingface.co/FelipeBandeiraPoatek","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"peewee-issues","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Peewee Issues\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPeewee Issues is a dataset containing all the issues in the Peewee github repository up to the last date of extraction (5/3/2023). It has been made for educational purposes in mind (especifically, to get me used to using Hugging Face's datasets), but can be used for multi-label classification or semantic search. The contents are all in English and concern SQL databases and ORM libraries.\n","url":"https://huggingface.co/datasets/akumoth/peewee-issues","creator_name":"Rainer Palm","creator_url":"https://huggingface.co/akumoth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","topic-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"Tiktok_Chatgpt_Prompt_Guide","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“² Example Dataset: TikTok Scraper Tool\n\t\n\nðŸ‘‰ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâš¡ Instant Transcription â€“ Turn any TikTok video into an AI-ready transcript  \nðŸŽ¯ Metadata â€“ Get the title, language, description, and video hashtags  \nðŸ”— URL-Based Access â€“ Just drop in a TikTok video URL to start scraping  \nðŸ§© LLM-Ready Output â€“ Receive clean JSON ready for agents, RAG, or AI tools  \nðŸ’¸ Free Tier â€“ Use up to 100 queries during the beta period  \nðŸ’« Easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/Tiktok_Chatgpt_Prompt_Guide.","url":"https://huggingface.co/datasets/Gopher-Lab/Tiktok_Chatgpt_Prompt_Guide","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TikTok_Most_Shared_Video_Transcription_Example","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“² Example Dataset: TikTok Scraper Tool\n\t\n\nðŸ‘‰ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâš¡ Instant Transcription â€“ Turn any TikTok video into an AI-ready transcript  \nðŸŽ¯ Metadata â€“ Get the title, language description, and video hashtags  \nðŸ”— URL-Based Access â€“ Just drop in a TikTok video URL to start scraping  \nðŸ§© LLM-Ready Output â€“ Receive clean JSON ready for agents, RAG, or AI tools  \nðŸ’¸ Free Tier â€“ Use up to 100 queries during the beta period  \nðŸ’« Easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"ARXIV","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNeuroscience Journals Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: apache-2.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nJournalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PenguinMan/ARXIV.","url":"https://huggingface.co/datasets/PenguinMan/ARXIV","creator_name":"Subhankar Panda","creator_url":"https://huggingface.co/PenguinMan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"emonet-face-hq","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tEmoNet-Face: A Fine-Grained, Expert-Annotated Benchmark for Facial Emotion Recognition\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEmoNet-Face is a comprehensive benchmark suite designed to address critical gaps in facial emotion recognition (FER). Current benchmarks often have a narrow emotional spectrum, lack demographic diversity, and use uncontrolled imagery. EmoNet-Face provides a robust foundation for developing and evaluating AI systems with a deeper, more nuanced understanding of humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/emonet-face-hq.","url":"https://huggingface.co/datasets/laion/emonet-face-hq","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"emonet-face-binary","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tEmoNet-Face: A Fine-Grained, Expert-Annotated Benchmark for Facial Emotion Recognition\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEmoNet-Face is a comprehensive benchmark suite designed to address critical gaps in facial emotion recognition (FER). Current benchmarks often have a narrow emotional spectrum, lack demographic diversity, and use uncontrolled imagery. EmoNet-Face provides a robust foundation for developing and evaluating AI systems with a deeper, more nuanced understanding of humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/emonet-face-binary.","url":"https://huggingface.co/datasets/laion/emonet-face-binary","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"test-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jiwonny29/test-dataset.","url":"https://huggingface.co/datasets/Jiwonny29/test-dataset","creator_name":"Jiwon Shin","creator_url":"https://huggingface.co/Jiwonny29","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"wiki-scibatch-cohere-plaintext-banaei-9m","keyword":"feature-extraction","description":"natnitaract/wiki-scibatch-cohere-plaintext-banaei-9m dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/natnitaract/wiki-scibatch-cohere-plaintext-banaei-9m","creator_name":"Natapong Nitarach (Schwyter)","creator_url":"https://huggingface.co/natnitaract","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-3.0","1M - 10M","arrow"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-tr","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"OpenOrca-tr\"\n\t\n\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish dataset collection to enhance the performance of LLM's Produced in the Turkish Language.\nmalhajar/orca-tr is a translated version of the  OpenOrca and is the first ever SFT dataset in the Turkish Language with more than 2M entries! \nTranslated by: Mohamad Alhajar \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca dataset is a collection ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/OpenOrca-tr.","url":"https://huggingface.co/datasets/malhajar/OpenOrca-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Vietnamese_Golf_Scorecard","keyword":"feature-extraction","description":"BinKhoaLe1812/Vietnamese_Golf_Scorecard dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/BinKhoaLe1812/Vietnamese_Golf_Scorecard","creator_name":"LÃª ÄÄƒng Khoa (Liam)","creator_url":"https://huggingface.co/BinKhoaLe1812","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Vietnamese","mit","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-04062024-hsmq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-04062024-hsmq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-04062024-hsmq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-04062024-hsmq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-04062024-hsmq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-04062024-hsmq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-04062024-hsmq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-04062024-hsmq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-04062024-hsmq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-04062024-hsmq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"bnbbtc-orpo","keyword":"feature-extraction","description":"Please see https://github.com/molbal/trading-llm-experiment for details.\n","url":"https://huggingface.co/datasets/molbal/bnbbtc-orpo","creator_name":"BÃ¡lint MolnÃ¡r-KalÃ³","creator_url":"https://huggingface.co/molbal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"persons_with_spectacles","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“¸ Persons with Spectacles\n\t\n\nA curated image dataset of human faces annotated for the presence of spectacles (eyeglasses).\n\n\n\t\n\t\t\n\t\tDataset Card for hkanade/persons_with_spectacles\n\t\n\n\n\t\n\t\t\nFeature\nDetail\n\n\n\t\t\nDataset name\npersons_with_spectacles\n\n\nRepository\nhttps://huggingface.co/datasets/hkanade/persons_with_spectacles\n\n\nLicense\napache-2.0\n\n\nLanguages\nâ€”\n\n\nTasks\nText to Image, Image classification\n\n\nSize\n120\n\n\nFile format\nParquet\n\n\nDataset version\n1.0.0\n\n\n\t\n\n\n\t\n\t\t\n\t\t1. Datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hkanade/persons_with_spectacles.","url":"https://huggingface.co/datasets/hkanade/persons_with_spectacles","creator_name":"Hrishikesh Kanade","creator_url":"https://huggingface.co/hkanade","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","image-to-image","text-to-image","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"gridding","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tgridding datasets\n\t\n\nDonnÃ©es permettant d'effectuer des analyses au carreau pour la France mÃ©tropolitaine via la bibliothÃ¨que Python gridding-py.\n","url":"https://huggingface.co/datasets/cyrildever/gridding","creator_name":"Cyril Dever","creator_url":"https://huggingface.co/cyrildever","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","French","mit","10M<n<100M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"solyanka","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset card for Solyanka\n\t\n\nThis is a dataset collection of ~10 million weakly-supervised pairs for training text embedding models. Any dataset in collection can be used in SentenceTransformers with an InfoNCE loss.\n\n\t\n\t\t\n\t\tData processing\n\t\n\nThe initial pool of pairs were deduplified, filtered by length and quality. Most of documents are less than 512 tokens (FRIDA tokenizer). Some pairs were filtered by manual rules (e.g. by post votes, rating, views). We applied consistencyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai-forever/solyanka.","url":"https://huggingface.co/datasets/ai-forever/solyanka","creator_name":"ai-forever","creator_url":"https://huggingface.co/ai-forever","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","feature-extraction","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-932024-59f9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-932024-59f9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FEVER-256-24-gpt-4o-2024-05-13-989429","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFEVER-256-24-gpt-4o-2024-05-13-989429 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"dataset search for fact verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FEVER-256-24-gpt-4o-2024-05-13-989429 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-989429.","url":"https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-989429","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FEVER-256-24-gpt-4o-2024-05-13-989429","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFEVER-256-24-gpt-4o-2024-05-13-989429 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"dataset search for fact verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FEVER-256-24-gpt-4o-2024-05-13-989429 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-989429.","url":"https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-989429","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CNTXTAI_Legal_Legislation","keyword":"feature-extraction","description":"This dataset is highly valuable for a wide range of users. Legal researchers and scholars can utilize it to analyze legislative trends and domain-specific developments in the UAE, particularly in administrative and religious affairs. Policy makers and government analysts will find it useful for tracking regulatory changes, assessing sectoral focus, and evaluating recent legal reforms. Law firms and legal consultants can leverage the structured data for efficient case study analysis andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Legal_Legislation.","url":"https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Legal_Legislation","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"newspaper-navigator","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Newspaper Navigator\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset provides a Parquet-converted version of the Newspaper Navigator dataset from the Library of Congress. Originally released as JSON, Newspaper Navigator contains over 16 million pages of historic US newspapers annotated with bounding boxes, predicted visual types (e.g., photographs, maps), and OCR content. This work was carried out as part of a project by Benjamin Germain Lee et al.\nThis version of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/newspaper-navigator.","url":"https://huggingface.co/datasets/biglam/newspaper-navigator","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","object-detection","image-feature-extraction","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-235808","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-235808 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment analysis and opinion-based QA\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-235808 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-235808.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-235808","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-235808","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-235808 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment analysis and opinion-based QA\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-235808 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-235808.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-235808","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"folktexts","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for folktexts \n\t\n\nFolktexts is a suite of Q&A\ndatasets with natural outcome uncertainty, aimed at evaluating LLMs' calibration\non unrealizable tasks.\nThe folktexts datasets are derived from US Census data products.\nNamely, the datasets made available here are derived from the\n2018 Public Use Microdata Sample\n(PUMS). Individual features are mapped to natural text using the respective\ncodebook.\nEach task relates to predicting different individual\ncharacteristics (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/acruz/folktexts.","url":"https://huggingface.co/datasets/acruz/folktexts","creator_name":"AndrÃ© Cruz","creator_url":"https://huggingface.co/acruz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","feature-extraction","zero-shot-classification","English"],"keywords_longer_than_N":true},
	{"name":"Lean4-Changelog","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLean 4 Changelog Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Lean 4 Changelog Dataset provides structured, machine-readable entries for changes in Lean 4, including language and library updates, fixes, deprecations, and other modifications. This dataset focuses on release notes from Lean 4â€™s official changelogs, capturing the key updates that are most likely to impact users, developers, or researchers working with Lean 4.\nBy offering structured data for these changes, this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Changelog.","url":"https://huggingface.co/datasets/phanerozoic/Lean4-Changelog","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"PERSUADE_manageable","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tPERSUADE_manageable\n\t\n\nThis is a more space efficient version of the PERSUADE dataset with the full_text split into a second file, reducing it from 750mb to 130mb Everything else remains the same.\n","url":"https://huggingface.co/datasets/realbenpope/PERSUADE_manageable","creator_name":"Ben Pope","creator_url":"https://huggingface.co/realbenpope","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","zero-shot-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"Toknowmore","keyword":"feature-extraction","description":"Jsnsm/Toknowmore dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Jsnsm/Toknowmore","creator_name":"Kuncham","creator_url":"https://huggingface.co/Jsnsm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","zero-shot-classification","translation"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CMedQAv2-reranking-improved","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCMedQAv2-reranking-improved Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the CMedQAv2-reranking-improved model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved.","url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CMedQAv2-reranking-improved","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCMedQAv2-reranking-improved Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the CMedQAv2-reranking-improved model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved.","url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MechLLM","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMechLLM\n\t\n\nThis is a synthetic dataset generated for electron movement extraction. \n\n\t\n\t\t\n\t\tData Description\n\t\n\nThe synthetic folder contains the synthetic reaction image from the pistachio dataset with curved arrow programatically drawn on the image.\nThe number folder contains the related number labels of the atoms.\nthe json file for corresponding image folders contains the start and end atom of electron movements, and the number of electron movements.\n\n.\nâ”œâ”€â”€ number/\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ting25/MechLLM.","url":"https://huggingface.co/datasets/Ting25/MechLLM","creator_name":"Ching Ting LEUNG","creator_url":"https://huggingface.co/Ting25","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"rhvex-cve","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for rhvex-cve\n\t\n\nThis Dataset is extracted from publicly available Vulnerability Exploitability eXchange (VEX) files published by Red Hat.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nRed Hat security data is a central source of truth for Red Hat products regarding published, known vulnerabilities.\nThis data is published in form of Vulnerability Exploitability eXchange (VEX) available at: \nhttps://security.access.redhat.com/data/csaf/v2/vex/\nThis Dataset is created by extracting relevantâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vdanen/rhvex-cve.","url":"https://huggingface.co/datasets/vdanen/rhvex-cve","creator_name":"Vincent Danen","creator_url":"https://huggingface.co/vdanen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-generation","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-11_05_2024-hbxc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"AI framework for improving LLM responses\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-11_05_2024-hbxc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"AI framework for improving LLM responses\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tempora","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTempora\n\t\n\n\n  \n\n\n\nA contemporary dataset of 7,368 real-world documents published after March 1, 2025, curated for testing the temporal grounding of Large Language Models.\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nBelow are examples of how to load Tempora-0325 using the Hugging Face datasets library. Adjust the config_name as needed.\n\n\t\n\t\t\n\t\tLoading with datasets\n\t\n\nfrom datasets import load_dataset\n\n# Load the balanced subset\nds_balanced = load_dataset(\"sumuks/tempora\", name=\"tempora-0325B\", split=\"train\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sumukshashidhar-archive/tempora.","url":"https://huggingface.co/datasets/sumukshashidhar-archive/tempora","creator_name":"Sumuk's Archived Content","creator_url":"https://huggingface.co/sumukshashidhar-archive","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","text-generation","text2text-generation"],"keywords_longer_than_N":true},
	{"name":"arguana-c-128-24-gpt-4o-2024-05-13-68212","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-128-24-gpt-4o-2024-05-13-68212 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-128-24-gpt-4o-2024-05-13-68212 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-128-24-gpt-4o-2024-05-13-68212.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-128-24-gpt-4o-2024-05-13-68212","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-128-24-gpt-4o-2024-05-13-68212","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-128-24-gpt-4o-2024-05-13-68212 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-128-24-gpt-4o-2024-05-13-68212 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-128-24-gpt-4o-2024-05-13-68212.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-128-24-gpt-4o-2024-05-13-68212","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"resume-jd-match-kr","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tResume-JD Pair Matching Dataset\n\t\n\nA large-scale dataset for resume and job description (JD) matching tasks, generated using GPT-4o-mini. Ideal for training and evaluating models in HR tech, recommender systems, and information retrieval.\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset includes:\n\n1,320 Resumes  \n1,320 Job Descriptions (JDs)  \n30 Job Roles  \n4 Experience Levels  \n11 Tech Companies  \n29,040 Total Pairs (14,520 positive + 14,520 negative)\n\nPositive pairs were generated only when bothâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recuse/resume-jd-match-kr.","url":"https://huggingface.co/datasets/recuse/resume-jd-match-kr","creator_name":"KW recuse project","creator_url":"https://huggingface.co/recuse","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Korean","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Amani-ZU","keyword":"feature-extraction","description":"amaniabuzaid/Amani-ZU dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/amaniabuzaid/Amani-ZU","creator_name":"Amani Abu-Zaid","creator_url":"https://huggingface.co/amaniabuzaid","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","afl-3.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"PubMed-Cancer-NLP-Textual-Dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tPubMed-Cancer-NLP-Textual-Dataset\n\t\n\nThis dataset has been obtained from PubMed for research purposes. README will be updated with time.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nIt has multiple cancer samples with labels with their title and abstract from PubMed Repository.\n\nCurated by: Om Aryan\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: https://pubmed.ncbi.nlm.nih.gov\n\n","url":"https://huggingface.co/datasets/cyberpsych/PubMed-Cancer-NLP-Textual-Dataset","creator_name":"Om Aryan","creator_url":"https://huggingface.co/cyberpsych","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"FinSen","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tEnhancing Financial Market Predictions: Causality-Driven Feature Selection\n\t\n\nNote:[Please help give a Like â¤ï¸ if you think this FinSen dataset is good for you, Thanks:)]\nThis paper introduces FinSen dataset that revolutionizes financial market analysis by integrating economic and financial news articles from 197 countries with stock market data. The datasetâ€™s extensive coverage spans 15 years from 2007 to 2023 with temporal information, offering a rich, global perspective 160,000â€¦ See the full description on the dataset page: https://huggingface.co/datasets/EagleWHLiang/FinSen.","url":"https://huggingface.co/datasets/EagleWHLiang/FinSen","creator_name":"WENHAO LIANG","creator_url":"https://huggingface.co/EagleWHLiang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","10M<n<100M"],"keywords_longer_than_N":true},
	{"name":"geometric-vocab","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tResearch Update 9/13/2025\n\t\n\nThe MULTITUDE of tests I've ran show that with weighted decay these pentachora are more likely to collapse to zero than retain utility when trained directly. However, when used as a starting point and then only minorly shifted as a trajectory towards a goal, they are more likely to retain full cohesion and even be backtrackable. The constellations show that this is more than a probable solution, it's a likely solution to work.\nWhen the anchor [n, 1, dim] isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AbstractPhil/geometric-vocab.","url":"https://huggingface.co/datasets/AbstractPhil/geometric-vocab","creator_name":"AbstractPhila","creator_url":"https://huggingface.co/AbstractPhil","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"ssh-scan","keyword":"feature-extraction","description":"This dataset contains a big list of all the SSH response headers I could find running a scan over the entire internet.\nIP addresses have been removed for privacy reasons, and replaced with a uuid.\nThis dataset may contain data that is offensive, crass, homophobic, transphobic, racist, etc etc as it is the internet afterall, none of it represents the thoughts or opinions of the author.\n","url":"https://huggingface.co/datasets/ghostoverflow/ssh-scan","creator_name":"Lilly Aronleigh","creator_url":"https://huggingface.co/ghostoverflow","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","feature-extraction","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"ImageCaptioning_Catalan","keyword":"image-feature-extraction","description":"The dataset consists of 153,791 images, each accompanied by a description in Catalan. The images have been sourced from two repositories: \n\"yerevann/coco-karpathy\" and \"UCSC-VLAA/Recap-COCO-30K.\" This dataset is ideal for computer vision tasks, as it combines a wide variety of \nimages with detailed descriptions that can be useful for training machine learning models.\nIt is freely accessible to everyone, as long as proper credit is given to the original data sources. Thanks\n","url":"https://huggingface.co/datasets/Marxx01/ImageCaptioning_Catalan","creator_name":"Marc Hurtado Beneyto","creator_url":"https://huggingface.co/Marxx01","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-feature-extraction","text-to-image","Catalan","odc-by"],"keywords_longer_than_N":true},
	{"name":"Captcha_image","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\t6ä½æ··åˆéªŒè¯ç æ•°æ®é›†\n\t\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†æè¿°\n\t\n\n\nå†…å®¹ï¼šåŒ…å«21000å¼ 6ä½éªŒè¯ç å›¾ç‰‡ï¼Œå­—ç¬¦ç»„åˆæ¶µç›–0-9ã€A-Zã€a-zå…±62ç§å­—ç¬¦\nç”Ÿæˆæ–¹å¼ï¼šç¨‹åºåˆæˆ\næ ‡æ³¨æ ¼å¼ï¼šæ¯å¼ å›¾ç‰‡æ–‡ä»¶åå³å¯¹åº”æ ‡ç­¾ï¼ˆå¦‚3aB9Zq.jpgçš„æ ‡ç­¾ä¸º3aB9Zqï¼‰\n\n\n\t\n\t\t\n\t\tæ–‡ä»¶ç»“æž„\n\t\n\ndataset/\nâ”œâ”€â”€ train/ # è®­ç»ƒé›†1ä¸‡å¼ \nâ”‚ â”œâ”€â”€ 0aB1Cd.jpg\nâ”‚ â””â”€â”€ ...\nâ”œâ”€â”€ test/ # æµ‹è¯•é›†1ä¸‡å¼ \nâ”œâ”€â”€ val/ # éªŒè¯é›†1000å¼ \n","url":"https://huggingface.co/datasets/MianXu/Captcha_image","creator_name":"Mian Xu","creator_url":"https://huggingface.co/MianXu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6122024-ibs3-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6122024-ibs3-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Pet care\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6122024-ibs3-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Korean","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6122024-ibs3-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6122024-ibs3-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Pet care\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6122024-ibs3-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Korean","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Schemaorg","keyword":"feature-extraction","description":"This dataset is a collection of Mixed-hop Prediction datasets created from Schema.org's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/Schemaorg","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6232024-4vtf-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6232024-4vtf-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Heating Ventilation and Air Conditioning units\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6232024-4vtf-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6232024-4vtf-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6232024-4vtf-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6232024-4vtf-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6232024-4vtf-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Heating Ventilation and Air Conditioning units\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6232024-4vtf-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6232024-4vtf-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6232024-4vtf-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-512-192-gpt-4o-2024-05-13-73934","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-512-192-gpt-4o-2024-05-13-73934 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-512-192-gpt-4o-2024-05-13-73934 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-73934.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-73934","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-512-192-gpt-4o-2024-05-13-73934","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-512-192-gpt-4o-2024-05-13-73934 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-512-192-gpt-4o-2024-05-13-73934 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-73934.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-73934","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-512-192-gpt-4o-2024-05-13-347397","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-512-192-gpt-4o-2024-05-13-347397 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"COVID-19\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-512-192-gpt-4o-2024-05-13-347397 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-347397.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-347397","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-512-192-gpt-4o-2024-05-13-347397","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-512-192-gpt-4o-2024-05-13-347397 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"COVID-19\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-512-192-gpt-4o-2024-05-13-347397 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-347397.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-347397","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"macbinariesprofile","keyword":"feature-extraction","description":"Mac binaries disassembly profile\n","url":"https://huggingface.co/datasets/geeksuckmatzball/macbinariesprofile","creator_name":"John Tareco","creator_url":"https://huggingface.co/geeksuckmatzball","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"VideoMind","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ”VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nVideoMind is a large-scale video-centric multimodal dataset that can be used to learn powerful and transferable text-video representations \nfor video understanding tasks such as video question answering and video retrieval. The VideoMind dataset contains 105K(5K test for \nonly) video samples, each of which is accompanied by audio, as well as systematicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DixinChen/VideoMind.","url":"https://huggingface.co/datasets/DixinChen/VideoMind","creator_name":"dixin chen","creator_url":"https://huggingface.co/DixinChen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"domain-translations","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMultilingual Domain Name Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 155,004 domain names with their multilingual translations across 20 languages. Each domain has been segmented into constituent words and translated while preserving semantic meaning and commercial appeal. The dataset is particularly valuable for domain name research, multilingual NLP tasks, and understanding how brand names and concepts translate across languages.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/humbleworth/domain-translations.","url":"https://huggingface.co/datasets/humbleworth/domain-translations","creator_name":"HumbleWorth","creator_url":"https://huggingface.co/humbleworth","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","feature-extraction","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"VQA-cmarkea-table-vqa-clean","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\ncmarkea/table-vqa dataset that we processed.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@online{AgDeTQA,\n  AUTHOR = {Tom Agonnoude, Cyrile Delestre},\n  URL = {https://huggingface.co/datasets/cmarkea/table-vqa},\n  YEAR = {2024},\n  KEYWORDS = {NLP ; Multimodal}\n}\n\n","url":"https://huggingface.co/datasets/CATIE-AQ/VQA-cmarkea-table-vqa-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-feature-extraction","French","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"attackdex-paldea","keyword":"feature-extraction","description":"Single pokemon datasets containing all the attacks (from levelling or TMs) learnable by the relative monster. All the data refer to the Paldea region and they come from the project discussed in https://medium.com/@virtualmartire/i-built-an-algorithm-that-finds-the-optimal-pokemon-team-01ea152824a9.\n","url":"https://huggingface.co/datasets/smartire/attackdex-paldea","creator_name":"Stefano Martire","creator_url":"https://huggingface.co/smartire","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","feature-extraction","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bluesky-embeddings-daily","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ›°ï¸ Bluesky AI Analysis: Public Post Embeddings\n\t\n\nThis dataset contains vector embeddings of public posts from the Bluesky Social network, generated for the purpose of semantic search, discovery, and language model experimentation.\n\n\t\n\t\t\n\t\tðŸ“¦ Contents\n\t\n\nEach row in the dataset includes:\n\nuri: The AT URI of the post.\ncreated_at: The full timestamp when the post was created.\ncreated_date: The UTC calendar date (YYYY-MM-DD).\ncreated_hour: The UTC hour of day (0â€“23).\ntext: The post'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wildwood77/bluesky-embeddings-daily.","url":"https://huggingface.co/datasets/wildwood77/bluesky-embeddings-daily","creator_name":"David Brandt","creator_url":"https://huggingface.co/wildwood77","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"pokedex","keyword":"feature-extraction","description":"Regional pokedex from the Pokemon games.\nPokedex available at the moment:\n\nPaldea (utilised in https://medium.com/@virtualmartire/i-built-an-algorithm-that-finds-the-optimal-pokemon-team-01ea152824a9).\n\n","url":"https://huggingface.co/datasets/smartire/pokedex","creator_name":"Stefano Martire","creator_url":"https://huggingface.co/smartire","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","table-question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"wb_matched","keyword":"feature-extraction","description":"This is a dataset of questions, answers, feedbacks and products from the Russian marketplace Wildberries. With additional matching pair of textes.\nOriginal data scrapped by nyuuzyou\n","url":"https://huggingface.co/datasets/Roaoch/wb_matched","creator_name":"Alexandr","creator_url":"https://huggingface.co/Roaoch","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","feature-extraction","text-classification","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"readsb-hist_2025-04-01-000000-120000","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\treadsb-hist from ADS-B Exchange\n\t\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nSee https://github.com/LunaticGhoulPiano/Flight-Spotter\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis data is from readsb-hist, the ADS-B Exchange historical data.\nIn my filter_and_encode.py, I filter some essential columns, and add geohash with precision = 12, end ECEF encoding: ecef_x, ecef_y, and ecef_z, using lat, lon, and alt_geom.\n\n\t\n\t\t\n\t\n\t\n\t\tNumber of aircrafts by specific time and Size\n\t\n\n\nreadsb-hist_merged.csv: 6089010 rows, 1.18 GBâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LunaticGhoulPiano/readsb-hist_2025-04-01-000000-120000.","url":"https://huggingface.co/datasets/LunaticGhoulPiano/readsb-hist_2025-04-01-000000-120000","creator_name":"SU,PO-HSUN","creator_url":"https://huggingface.co/LunaticGhoulPiano","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","1M - 10M","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5272024-2fs4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5272024-2fs4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"sentiment analysis model fine-tuning\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5272024-2fs4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-2fs4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-2fs4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5272024-2fs4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5272024-2fs4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"sentiment analysis model fine-tuning\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5272024-2fs4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-2fs4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-2fs4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Single-cell-embedding-benchmark","keyword":"feature-extraction","description":"crisluengo/Single-cell-embedding-benchmark dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/crisluengo/Single-cell-embedding-benchmark","creator_name":"Cris Luengo","creator_url":"https://huggingface.co/crisluengo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","mit","ðŸ‡ºðŸ‡¸ Region: US","biology"],"keywords_longer_than_N":true},
	{"name":"ops-volltext-klassifizierung-v1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSynthetisches Dataset fÃ¼r OPS-Klassifizierung\n\t\n\n\n\t\n\t\t\n\t\tHaftungsausschluss\n\t\n\nDiese Daten wurden von https://gesund.bund.de gescraped und sind Eigentum des Urheberrechtsinhabers. Der alleinige Zweck dieses Datensatzes und der zugehÃ¶rigen Codebasis sowie anderer Materialien ist es, die deutsche medizinische Gemeinschaft bei der Erstellung hochspezialisierter deutscher Modelle zu unterstÃ¼tzen.\nWenn Sie an vorab geparsten Daten interessiert sind, die als Baseline fÃ¼r diese synthetischenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v1.","url":"https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v1","creator_name":"Bijay Regmi","creator_url":"https://huggingface.co/regmibijay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","feature-extraction","German","mit"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-32000-384-gpt-4o-2024-05-13-4321481","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-32000-384-gpt-4o-2024-05-13-4321481 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-32000-384-gpt-4o-2024-05-13-4321481 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-32000-384-gpt-4o-2024-05-13-4321481.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-32000-384-gpt-4o-2024-05-13-4321481","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-32000-384-gpt-4o-2024-05-13-4321481","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-32000-384-gpt-4o-2024-05-13-4321481 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-32000-384-gpt-4o-2024-05-13-4321481 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-32000-384-gpt-4o-2024-05-13-4321481.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-32000-384-gpt-4o-2024-05-13-4321481","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"sona-corpus","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTHE SONA CORPUS â€” Noisy-to-Clean Hindiâ€“English Parallel Dataset\n\t\n\nA clean, bilingual dataset card you can read at a glance and use immediately.\n\nCurated by: Aditya (AADIMIND)\nLanguages: Hindi, English\nTotal examples: 581312 (INPUT: 256 TOKENâ€¢ TARGET: 256 TOKEN)\nTasks: Text cleaning, GEC, OCR post-processing, Seq2Seq fine-tuning\nLicense: MIT\nSource: Hindi Wikipedia (HiWiki) processed into noisyâ€“clean pairs\nRepo: https://huggingface.co/datasets/AADIMIND/sona-corpusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AADIMIND/sona-corpus.","url":"https://huggingface.co/datasets/AADIMIND/sona-corpus","creator_name":"Aditya","creator_url":"https://huggingface.co/AADIMIND","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","text-classification","Hindi","English"],"keywords_longer_than_N":true},
	{"name":"Walking-Tours-Semantic","keyword":"image-feature-extraction","description":"\n  Walking Tours Semantic\n\n\n\n\n\nWalking Tours Semantic (WT-Sem), introduced in PooDLe, provides semantic segmentation masks for videos in the Walking Tours dataset, as well as three additional videos for validation.\nFrames are sampled every 2 seconds from each video and a top-of-the-line semantic segmentation model, OpenSeed, is used to generate the masks.\nSpecifically, the Swin-L variant of OpenSeed, pretrained on COCO and Objects365 and finetuned on ADE20K, is used.\nThe 3 new walkaroundâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentic-learning-ai-lab/Walking-Tours-Semantic.","url":"https://huggingface.co/datasets/agentic-learning-ai-lab/Walking-Tours-Semantic","creator_name":"agentic learning ai lab","creator_url":"https://huggingface.co/agentic-learning-ai-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-feature-extraction","cc-by-4.0","n<1K","Image"],"keywords_longer_than_N":true},
	{"name":"images-1","keyword":"image-feature-extraction","description":"keikhosrotav/images-1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/keikhosrotav/images-1","creator_name":"keikhosro tavakoli","creator_url":"https://huggingface.co/keikhosrotav","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"arxiv-author-affiliations","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tManually Annotated arXiv Preprints Dataset for Structured Extraction of Authors and Affiliations\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains manually annotated, structured metadata for a random sample of preprints from arXiv. Each entry in the dataset corresponds to a single publication and includes its title, language, arXiv ID, DOI link, a structured list of authors with their respective affiliations, and the corresponding PDF filename.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach objectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cometadata/arxiv-author-affiliations.","url":"https://huggingface.co/datasets/cometadata/arxiv-author-affiliations","creator_name":"Collaborative Metadata (COMET)","creator_url":"https://huggingface.co/cometadata","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","cc0-1.0","1K<n<10K","arxiv:2003.03151","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code snippet search for developers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code snippet search for developers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BenLOC","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDatasets of ML4MOC\n\t\n\nPresolved Data is stored in .\\instance. The folder structure after the datasets are set up looks as follows\ninstances/\n  MIPLIB/                   -> 1065 instances\n  set_cover/                -> 3994 instances\n  independent_set/          -> 1604 instances\n  nn_verification/          -> 3104 instances\n  load_balancing/           -> 2286 instances\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tMIPLIB\n\t\n\nHeterogeneous dataset from MIPLIB 2017, a well-establishedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SEVANTORY/BenLOC.","url":"https://huggingface.co/datasets/SEVANTORY/BenLOC","creator_name":"Hongpei Li","creator_url":"https://huggingface.co/SEVANTORY","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Afar","mit","1K<n<10K","arxiv:1810.12715"],"keywords_longer_than_N":true},
	{"name":"dfhq-dataset","keyword":"image-feature-extraction","description":"kangnam/dfhq-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kangnam/dfhq-dataset","creator_name":"Kangnam Kim","creator_url":"https://huggingface.co/kangnam","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-image","image-classification","image-feature-extraction","Korean","mit"],"keywords_longer_than_N":true},
	{"name":"all-nli-tr","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for AllNLITR\n\t\n\nThis dataset is a formatted version of NLI-TR datasets, sharing the same licenses. The format is intended to be in line with AllNLI by Sentence Transformers for ease of training.\nDespite originally being intended for Natural Language Inference (NLI), this dataset can be used for training/finetuning an embedding model for semantic textual similarity.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Subsets\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tpair-class subset\n\t\n\n\nColumns: \"premise\", \"hypothesis\", \"label\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/emrecan/all-nli-tr.","url":"https://huggingface.co/datasets/emrecan/all-nli-tr","creator_name":"Emrecan Ã‡elik","creator_url":"https://huggingface.co/emrecan","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","Turkish","cc-by-3.0"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-base-en-1362024-n19c-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-base-en-1362024-n19c-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Semantic Relationships\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-base-en-1362024-n19c-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-base-en-1362024-n19c-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-base-en-1362024-n19c-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-base-en-1362024-n19c-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-base-en-1362024-n19c-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Semantic Relationships\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-base-en-1362024-n19c-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-base-en-1362024-n19c-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-base-en-1362024-n19c-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"wikipedia_en","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\twikipedia_en\n\t\n\nThis is a curated Wikipedia English dataset for use with the II-Commons project.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset comprises a curated Wikipedia English pages. Data sourced directly from the official English Wikipedia database dump. We extract the pages, chunk them into smaller pieces, and embed them using Snowflake/snowflake-arctic-embed-m-v2.0. All vector embeddings are 16-bit half-precision vectors optimized for cosine indexingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Intelligent-Internet/wikipedia_en.","url":"https://huggingface.co/datasets/Intelligent-Internet/wikipedia_en","creator_name":"II","creator_url":"https://huggingface.co/Intelligent-Internet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10M - 100M","csv"],"keywords_longer_than_N":true},
	{"name":"Opendoc1-Analysis-Recognition","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tOpendoc1-Analysis-Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Opendoc1-Analysis-Recognition dataset is designed for tasks involving image-to-text, text classification, and image feature extraction. It contains images paired with class labels, making it suitable for vision-language tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nModalities: Image\nLanguages: English\nSize: Approximately 1,000 samples (n=1K)\nTags: image, analysis, vision-language\nLicense: Apache 2.0\n\n\n\t\n\t\t\n\t\tTasks\n\t\n\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Opendoc1-Analysis-Recognition.","url":"https://huggingface.co/datasets/prithivMLmods/Opendoc1-Analysis-Recognition","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-classification","image-feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-131171","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24-gpt-4o-2024-05-131171 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technology Stack Documentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-131171 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-131171.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-131171","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-131171","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24-gpt-4o-2024-05-131171 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technology Stack Documentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-131171 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-131171.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-131171","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"chronocept","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tChronocept: Instilling a Sense of Time in Machines\n\t\n\nAuthors: Krish Goel, Sanskar Pandey, KS Mahadevan, Harsh Kumar, and Vishesh KhadariaPublication: Chronocept: Instilling a Sense of Time in Machines\nChronocept is a benchmark for modeling the temporal validity of textual information as a continuous probability distribution over time. By fitting skewed-normal curves to annotated facts and passages, Chronocept captures phenomena such as gradual decay, delayed onset, and asymmetric peakâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/krishgoel/chronocept.","url":"https://huggingface.co/datasets/krishgoel/chronocept","creator_name":"Krish Goel","creator_url":"https://huggingface.co/krishgoel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"hanzi","keyword":"feature-extraction","description":"\næ¬¡æ•°æ®åŒ…å«501ä¸ªç±»åˆ«çš„æ‰‹å†™æ±‰å­—æ–‡ä»¶å¤¹ï¼Œæ¯ä¸€ä¸ªç±»åˆ«ä¸‹åŒ…å«å¤§çº¦50å¼ æ‰‹å†™æ±‰å­—\n\n","url":"https://huggingface.co/datasets/AISkywalker/hanzi","creator_name":"KobeSkywalker","creator_url":"https://huggingface.co/AISkywalker","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","100M<n<1B","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"AMAZON-Products-2023","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Amazon Products 2023\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains product metadata from Amazon, filtered to include only products that became available in 2023. The dataset is intended for use in semantic search applications and includes a variety of product categories.\n\nNumber of Rows: 117,243\nNumber of Columns: 15\n\n\n\t\n\t\t\n\t\tData Source\n\t\n\nThe data is sourced from Amazon Reviews 2023. \nIt includes product information across multiple categories, with additionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/milistu/AMAZON-Products-2023.","url":"https://huggingface.co/datasets/milistu/AMAZON-Products-2023","creator_name":"Milutin Studen","creator_url":"https://huggingface.co/milistu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","sentence-similarity","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"WordNetNoun","keyword":"feature-extraction","description":"This dataset is a collection of Multi-hop Inference and Mixed-hop Prediction datasets created from WordNet's subsumption (hypernym) hierarchy of noun entities for training and evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/WordNetNoun","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-13052024-35bv-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-13052024-35bv-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal regulations search for life sciences industry\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-13052024-35bv-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-35bv-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-35bv-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-13052024-35bv-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-13052024-35bv-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal regulations search for life sciences industry\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-13052024-35bv-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-35bv-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-35bv-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"fineweb-1M_longish","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tfineweb \"longish\" 1M\n\t\n\n1m samples w/ random seed w.r.t. previous samples.\n\nmin 512 GPT-4 tiktoken tokens\nmax 8192 GPT-4 tiktoken tokens\n\nBEE-spoke-data/claude-tokenizer token count:\n          token_count\ncount  1000000.000000\nmean      1218.231641\nstd        935.733312\nmin        139.000000\n25%        683.000000\n50%        905.000000\n75%       1350.000000\nmax       9550.000000\n\n\nTotal count:\t1218.23 M tokens\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/fineweb-1M_longish","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","feature-extraction","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"drone-lsr","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLight Stable Representations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains aerial orthomosaic tiles captured at three different times of day (10:00, 12:00, and 15:00). The dataset is organized into three configurations: default (raw images + canopy height), dinov2_base (DINOv2 embeddings), and dinov3_sat (DINOv3 embeddings). All configurations share consistent train/test splits with matching tile identifiers for cross-referencing. The dataset is designed for trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mpg-ranch/drone-lsr.","url":"https://huggingface.co/datasets/mpg-ranch/drone-lsr","creator_name":"MPG Ranch","creator_url":"https://huggingface.co/mpg-ranch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-to-image","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"chair","keyword":"feature-extraction","description":"jkcg/chair dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jkcg/chair","creator_name":"JO","creator_url":"https://huggingface.co/jkcg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-18062024-56t5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-18062024-56t5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-18062024-56t5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-18062024-56t5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-18062024-56t5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-18062024-56t5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-18062024-56t5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-18062024-56t5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-18062024-56t5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-18062024-56t5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-782024-wl54-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-782024-wl54-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-782024-wl54-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-782024-wl54-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-782024-wl54-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-782024-wl54-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-782024-wl54-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-782024-wl54-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-782024-wl54-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-782024-wl54-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Balanced-Ethereum-Smart-Contract","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Balanced Ethereum Smart Contract\n\t\n\nThe rapid expansion of blockchain technology, particularly Ethereum, has driven widespread adoption of smart contracts. However, the security of these contracts remains a critical concern due to the increasing frequency and complexity of vulnerabilities. This paper presents a comprehensive approach to detecting vulnerabilities in Ethereum smart contracts using pre-trained Large Language Models (LLMs). We apply transformer-based LLMsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Thi-Thu-Huong/Balanced-Ethereum-Smart-Contract.","url":"https://huggingface.co/datasets/Thi-Thu-Huong/Balanced-Ethereum-Smart-Contract","creator_name":"Le","creator_url":"https://huggingface.co/Thi-Thu-Huong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"markuplm_scimetadata","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Scientific Works Metadata Extraction\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Description\n\t\n\nDataset for training models (including MarkupLM) on the task of metadata extraction from scientific papers in HTML format. Contains BIO tagging for 27 metadata types.\nTask: Token Classification for entity extraction:\n['title', 'author', 'date', 'doi', 'issn', 'eissn', 'journal', 'publisher', 'pages', 'first_page', 'last_page', 'language', 'volume', 'issue', 'abstract', 'affiliation', 'keyword'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/endthesame/markuplm_scimetadata.","url":"https://huggingface.co/datasets/endthesame/markuplm_scimetadata","creator_name":"Egor Terentev","creator_url":"https://huggingface.co/endthesame","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","feature-extraction","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mobius-data","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMobius: Mixture-Of-Experts Transformer Model in Epigenetics of ME/CFS and Long COVID\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains DNA methylation data from blood samples of individuals with Myalgic Encephalomyelitis/Chronic Fatigue Syndrome (ME/CFS), Long COVID (LC), and healthy controls. The data is derived from Illumina HumanMethylation450 BeadChip and Illumina MethylationEPIC arrays and has been organized to facilitate research into epigenetic biomarkers for theseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VerisimilitudeX/mobius-data.","url":"https://huggingface.co/datasets/VerisimilitudeX/mobius-data","creator_name":"Piyush Acharya","creator_url":"https://huggingface.co/VerisimilitudeX","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","zero-shot-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"rawg-games-dataset","keyword":"feature-extraction","description":"\n  \n\n\n\n  \n  \n\n\nDescription\n\n  RAWG Games Dataset video game records data gathered directly from the RAWG API.\n  It includes essential fields such as game id, title, release date, rating, genres, platforms, descriptive tags, \n  Metacritic score, developers, publishers, playtime, and a detailed description. The data was collected to support \n  studies, trend analysis, and insights into the gaming industry. Each field is aligned with the specifications provided in the RAWG API documentation.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/atalaydenknalbant/rawg-games-dataset.","url":"https://huggingface.co/datasets/atalaydenknalbant/rawg-games-dataset","creator_name":"Atalay Denknalbant","creator_url":"https://huggingface.co/atalaydenknalbant","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","summarization","feature-extraction","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"rawg-games-dataset-updated","keyword":"feature-extraction","description":"\n  \n\n\n\n  \n  \n\n\nDescription\n\n  RAWG Games Dataset video game records data gathered directly from the RAWG API.\n  It includes essential fields such as game id, title, release date, rating, genres, platforms, descriptive tags, \n  Metacritic score, developers, publishers, playtime, and a detailed description. The data was collected to support \n  studies, trend analysis, and insights into the gaming industry. Each field is aligned with the specifications provided in the RAWG API documentation.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/IVproger/rawg-games-dataset-updated.","url":"https://huggingface.co/datasets/IVproger/rawg-games-dataset-updated","creator_name":"Ivan Golov","creator_url":"https://huggingface.co/IVproger","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","summarization","feature-extraction","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"readability","keyword":"feature-extraction","description":"Description: This dataset comprises approximately 200,000 paragraphs and readability metrics from each of four sources: \n\nHuggingFace's Fineweb-Edu\nRonen Eldan's TinyStories\nWikipedia-2023-11-embed-multilingual-v3 (English only)\nArXiv Abstracts-2021.\n\nEach paragraph falls within the character range of 50 to 2000.\nFormat: JSON, with each row representing a paragraph and containing both the text and its corresponding readability grade.\nFeatures:\n\nText: A paragraph of text from one of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/readability.","url":"https://huggingface.co/datasets/agentlans/readability","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"feature-extraction","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"image-feature-extraction","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"HealthRisk-1500-Medical-Risk-Prediction","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ¥ HealthRisk-1500: Medical Risk Prediction Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Œ Overview\n\t\n\nHealthRisk-1500 is a real-world patient risk prediction dataset designed for training NLP models, LLMs, and healthcare AI systems. This dataset includes 1,500 unique patient records, covering a wide range of symptoms, medical histories, lab reports, and risk levels. It is ideal for predictive analytics, medical text processing, and clinical decision support.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ” Use Cases\n\t\n\n\nðŸ©º Disease Riskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lvimuth/HealthRisk-1500-Medical-Risk-Prediction.","url":"https://huggingface.co/datasets/lvimuth/HealthRisk-1500-Medical-Risk-Prediction","creator_name":"Lakshitha Vimuth","creator_url":"https://huggingface.co/lvimuth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-henp-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-henp-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Accounting laws and guidelines search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-henp-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-henp-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-henp-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-henp-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-henp-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Accounting laws and guidelines search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-henp-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-henp-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-henp-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"clinical-trials","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tClinical Trials Dataset\n\t\n\nA comprehensive dataset of clinical trials sourced from ClinicalTrials.gov, featuring structured metadata, detailed study information, and pre-computed semantic embeddings for machine learning applications in biomedical research.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides a rich collection of clinical trial information systematically collected from the official ClinicalTrials.gov database. Each record contains detailed study metadata, eligibilityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/clinical-trials.","url":"https://huggingface.co/datasets/louisbrulenaudet/clinical-trials","creator_name":"Louis BrulÃ© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","text-classification","English","French"],"keywords_longer_than_N":true},
	{"name":"DBPedia-256-24-gpt-4o-2024-05-13-190101","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDBPedia-256-24-gpt-4o-2024-05-13-190101 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"dataset search for text classification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the DBPedia-256-24-gpt-4o-2024-05-13-190101 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/DBPedia-256-24-gpt-4o-2024-05-13-190101.","url":"https://huggingface.co/datasets/fine-tuned/DBPedia-256-24-gpt-4o-2024-05-13-190101","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DBPedia-256-24-gpt-4o-2024-05-13-190101","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDBPedia-256-24-gpt-4o-2024-05-13-190101 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"dataset search for text classification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the DBPedia-256-24-gpt-4o-2024-05-13-190101 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/DBPedia-256-24-gpt-4o-2024-05-13-190101.","url":"https://huggingface.co/datasets/fine-tuned/DBPedia-256-24-gpt-4o-2024-05-13-190101","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CanadianInvertebrates-ML","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for CanadianInvertebrates-ML\n\t\n\nAlternative names: InvertebratesCanada-ML, CanInv-ML, CanInv-1M, Canada-1.5M\nThis dataset is used in the paper BarcodeBERT: Transformers for Biodiversity Analysis.\n\n\t\n\t\t\n\t\tPaper Abstract\n\t\n\nIn the global challenge of understanding and characterizing biodiversity, short species-specific genomic sequences known as DNA barcodes play a critical role, enabling fine-grained comparisons among organisms within the same kingdom of life. Althoughâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bioscan-ml/CanadianInvertebrates-ML.","url":"https://huggingface.co/datasets/bioscan-ml/CanadianInvertebrates-ML","creator_name":"BIOSCAN","creator_url":"https://huggingface.co/bioscan-ml","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","cc-by-3.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-10630","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-10630 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-10630 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-10630.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-10630","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-10630","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-10630 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-10630 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-10630.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-10630","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-322852","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-322852 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-322852 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-322852.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-322852","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-322852","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-322852 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-322852 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-322852.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-322852","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MSMARCO-256-24-gpt-4o-2024-05-13-374380","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMSMARCO-256-24-gpt-4o-2024-05-13-374380 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"research dataset search for AI and NLP tasks\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the MSMARCO-256-24-gpt-4o-2024-05-13-374380 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-374380.","url":"https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-374380","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MSMARCO-256-24-gpt-4o-2024-05-13-374380","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMSMARCO-256-24-gpt-4o-2024-05-13-374380 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"research dataset search for AI and NLP tasks\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the MSMARCO-256-24-gpt-4o-2024-05-13-374380 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-374380.","url":"https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-374380","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Smart home technology brand\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Smart home technology brand\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"project_gutenberg","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArtificial Relationships in Fiction (ARF)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArtificial Relationships in Fiction (ARF) is a synthetically annotated dataset for Relation Extraction (RE) in fiction, created from a curated selection of literary texts sourced from Project Gutenberg. The dataset captures the rich, implicit relationships within fictional narratives using a novel ontology and GPT-4o for annotation. ARF is the first large-scale RE resource designed specifically for literary textsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Despina/project_gutenberg.","url":"https://huggingface.co/datasets/Despina/project_gutenberg","creator_name":"Despina Christou","creator_url":"https://huggingface.co/Despina","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"foursquare_places_100M","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFoursquare OS Places 100M\n\t\n\nFull Foursquare OS Places dump from https://opensource.foursquare.com/os-places/.\nThis is a single (geo-)parquet file based on the 81 individual parquet files from fused.io on https://source.coop/fused/fsq-os-places/2024-11-19/places.\nAs it's just 10Gb, it's fairly easy to handle as a single file and can easily be queried over modern technologies like httpfs. \n\n\t\n\t\t\n\t\n\t\n\t\tWays to query the file & visualize the results\n\t\n\nIf you just want to poke around inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/do-me/foursquare_places_100M.","url":"https://huggingface.co/datasets/do-me/foursquare_places_100M","creator_name":"Dominik WeckmÃ¼ller","creator_url":"https://huggingface.co/do-me","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","100M - 1B","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"egytriplets-2m","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tEgyTriplets - 2M ðŸ•ŒðŸ“š\n\t\n\nEgyTriplets - 2M is a high-quality dataset of 2 million Egyptian Arabic sentence triplets designed for semantic embedding training, especially in low-resource and dialectal NLP applications.\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâœ… 2 million triplets\nðŸ·ï¸ Format: (anchor, 3 hard positives, 3 hard negatives)\nðŸ“– Translation: Egyptian Arabic âž Modern Standard Arabic\nðŸ“Š Splits:\nTrain: 1,796,323 triplets\nValidation: 103,855 triplets\nTest: 99,543 triplets\n\n\n\n\n\n\t\n\t\t\n\t\tðŸ”¨ How Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metga97/egytriplets-2m.","url":"https://huggingface.co/datasets/metga97/egytriplets-2m","creator_name":"Mohammad Essam","creator_url":"https://huggingface.co/metga97","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Arabic","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"ArguAna-32000-384-gpt-4o-2024-05-13-3663751","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-32000-384-gpt-4o-2024-05-13-3663751 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-32000-384-gpt-4o-2024-05-13-3663751 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-32000-384-gpt-4o-2024-05-13-3663751","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-32000-384-gpt-4o-2024-05-13-3663751 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-32000-384-gpt-4o-2024-05-13-3663751 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting search engine for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting search engine for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"retriever-vidore-vdsid_french-clean","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nvidore/vdsid_french dataset that we processed.Although useless, we have created an empty answer column to facilitate the concatenation of this dataset with VQA datasets where only the quesion and image columns would be used to train a Colpali-type model or one of its derivatives.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{faysse2024colpaliefficientdocumentretrieval,\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \n      author={Manuel Faysse and Huguesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/retriever-vidore-vdsid_french-clean.","url":"https://huggingface.co/datasets/CATIE-AQ/retriever-vidore-vdsid_french-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","French","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mmarco-contrastive","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tmMARCO-contrastive\n\t\n\nThe dataset is a modification of mMARCO focusing on French and English parts. The aim is to train a\nbi-encoder model using all hard negatives from the database. Instead of having a query/positive/negative triplet, we pair all negatives with a query and a\npositive. However, it's worth noting that there are many false negatives in the dataset. This isn't a big issue with a triplet view because false negatives\nare much fewer in number, but it's more significant withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cmarkea/mmarco-contrastive.","url":"https://huggingface.co/datasets/cmarkea/mmarco-contrastive","creator_name":"Credit Mutuel Arkea","creator_url":"https://huggingface.co/cmarkea","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","feature-extraction","French","English"],"keywords_longer_than_N":true},
	{"name":"synthetic-text-similarity","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSynthetic Text Similarity\n\t\n\nThis dataset is created to facilitate the evaluation and training of models on the task of text similarity at longer contexts/examples than Bob likes frogs. as per classical sentence similarity datasets.\nIt consists of document pairs with associated similarity scores, representing the closeness of the documents in semantic space.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nFor each version of this dataset, embeddings are computed for all unique documents, followed byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/synthetic-text-similarity.","url":"https://huggingface.co/datasets/pszemraj/synthetic-text-similarity","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","odc-by","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"alpaca-gpt4_de-scored","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from mayflowergmbh/alpaca-gpt4_de with added cosine-similarity scores.\nThe scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy?\n\t\n\nTo build an experimental static embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/alpaca-gpt4_de-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/alpaca-gpt4_de-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"holistic health and well-being services\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"holistic health and well-being services\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"translator-openpredict","keyword":"feature-extraction","description":"This repository contains the data for the OpenPredict Translator API available at openpredict.semanticscience.org, which serves a few prediction models developed at the Institute of Data Science.\n\n","url":"https://huggingface.co/datasets/um-ids/translator-openpredict","creator_name":"Institute of Data Science at Maastricht University","creator_url":"https://huggingface.co/um-ids","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","Text","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-5qm5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-5qm5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-5qm5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5qm5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5qm5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-5qm5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-5qm5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-5qm5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5qm5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5qm5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-922024-pwti-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-922024-pwti-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-202457-oc31-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-202457-oc31-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal advice search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-202457-oc31-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-202457-oc31-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-202457-oc31-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal advice search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-202457-oc31-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tie-v1-scanned-images","keyword":"feature-extraction","description":"ashutoshroy02/tie-v1-scanned-images dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ashutoshroy02/tie-v1-scanned-images","creator_name":"ASHUTOSH ROY","creator_url":"https://huggingface.co/ashutoshroy02","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","sentence-similarity","English","mit"],"keywords_longer_than_N":true},
	{"name":"CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research dataset search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378.","url":"https://huggingface.co/datasets/fine-tuned/CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research dataset search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378.","url":"https://huggingface.co/datasets/fine-tuned/CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"feature-extraction","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-445b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Automotive industry\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-445b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Automotive industry\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"vietnamese-poem-context","keyword":"feature-extraction","description":"lunovian/vietnamese-poem-context dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/lunovian/vietnamese-poem-context","creator_name":"Nguyen Xuan An","creator_url":"https://huggingface.co/lunovian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","feature-extraction","sentence-similarity","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"coco2017-clip-codetr-feats","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCOCO2017 Derived Multimodal Features\n\t\n\nä¸åŒ…å«ä»»ä½• COCO å½±åƒã€‚æœ¬è³‡æ–™é›†æä¾›ä»¥ COCO2017 ç‚ºä¾†æºæ‰€ç”¢ç”Ÿçš„ç‰¹å¾µï¼š\n\ngridï¼šCLIP è¦–è¦º backbone çš„ 9Ã—9 patch ç‰¹å¾µï¼ˆ81Ã—768ï¼‰\nregionï¼šCo-DETR çš„å‰50ç‰©ä»¶å€åŸŸç‰¹å¾µï¼ˆ50Ã—256ï¼‰\ntextï¼šå°æ‡‰ captions çš„ CLIP text ç‰¹å¾µï¼ˆ5Ã—512ï¼‰ï¼ˆCOCO é è¨­ captions = 5/åœ–ï¼‰\n\n\næŽˆæ¬Šèˆ‡ä¾†æº  \n\nCOCO è¨»è§£ï¼ˆå« captionsï¼‰æŽ¡ CC BY 4.0ï¼›è«‹æ–¼ä½¿ç”¨æ™‚ä¿ç•™æ­¸å±¬èˆ‡éˆçµã€‚  \nCOCO å½±åƒéœ€ä¾å…¶åŽŸå§‹æŽˆæ¬Šï¼ˆå¤šæºè‡ª Flickrï¼‰å¦è¡Œä¸‹è¼‰ï¼›æœ¬è³‡æ–™é›†ä¸åŒ…å«å½±åƒã€‚\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tåŠ è¼‰èˆ‡ç¯„ä¾‹\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(\"username/coco2017-derived-feats-clip-codetr\", split=\"train\")\nex = ds[0]\nex[\"grid\"]   #â€¦ See the full description on the dataset page: https://huggingface.co/datasets/YesaOuO/coco2017-clip-codetr-feats.","url":"https://huggingface.co/datasets/YesaOuO/coco2017-clip-codetr-feats","creator_name":"Yesa","creator_url":"https://huggingface.co/YesaOuO","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"high-quality-text-long","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tHigh Quality Text (Longer) Dataset\n\t\n\nThis is agentlans/high-quality-text\nexcept that only chunks between 1750 and 2250 Meta Llama 3.1 tokens were kept.\nThe chunks were embedded using MongoDB/mdbr-leaf-mt\nand hierarchically clustered.\n","url":"https://huggingface.co/datasets/agentlans/high-quality-text-long","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","odc-by","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"entity-attribute-dataset-GPT-3.5-generated-v1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tEntity Attribute Dataset 306k (GPT-3.5 generated)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Entity Attribute Dataset 306k (GPT-3.5 generated) is designed for instruction fine-tuning, specifically for the task of generating structured catalogs in JSON format based on product titles. The dataset includes a diverse range of products from various categories such as food, home and kitchen, clothing, handicrafts, tools, automotive equipment, and more.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is intended forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BaSalam/entity-attribute-dataset-GPT-3.5-generated-v1.","url":"https://huggingface.co/datasets/BaSalam/entity-attribute-dataset-GPT-3.5-generated-v1","creator_name":"BaSalam","creator_url":"https://huggingface.co/BaSalam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","text2text-generation","Persian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-994884","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-994884 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-994884 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-994884","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-994884 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-994884 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-06052024-k5bq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-06052024-k5bq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance search for car policies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-k5bq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-k5bq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-k5bq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-06052024-k5bq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-06052024-k5bq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance search for car policies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-k5bq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-k5bq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-k5bq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-seuc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-seuc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"book search for startup advice\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-seuc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-seuc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-seuc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-seuc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-seuc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"book search for startup advice\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-seuc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-seuc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-seuc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"relative-positioning","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset aims to teach LLMs relative positioning (e.g. above, left from, below, etc.), \nwhich in my findings most LLMs, even SOTA where not able to produce under all circumstances.\nWill be pushing a fine-tuned mixtral-7x8B with this dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nContains Data for relative positioning on a grid(256, 256).\nAssumes Origin [0, 0] is in the bottom left.\nTwo Objects (Object 1, Object 2) are randomlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LlameUser/relative-positioning.","url":"https://huggingface.co/datasets/LlameUser/relative-positioning","creator_name":"Antoine Angert","creator_url":"https://huggingface.co/LlameUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dblp_aminer_triplets","keyword":"feature-extraction","description":"vaios-stergio/dblp_aminer_triplets dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/vaios-stergio/dblp_aminer_triplets","creator_name":"Vaios Stergiopoulos","creator_url":"https://huggingface.co/vaios-stergio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","sentence-similarity","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"brill_iconclass","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Brill Iconclass AI Test Set\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nA test dataset and challenge to apply machine learning to collections described with the Iconclass classification system.\n\nThis dataset contains 87749 images with Iconclass metadata assigned to the images. The iconclass metadata classification system is intended to provide 'the comprehensive classification system for the content of images.'.\n\nIconclass was developed in the Netherlands as a standardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/brill_iconclass.","url":"https://huggingface.co/datasets/biglam/brill_iconclass","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","feature-extraction","multi-class-image-classification","multi-label-image-classification"],"keywords_longer_than_N":true},
	{"name":"linkedin-jobs","keyword":"feature-extraction","description":"Merged files from https://www.kaggle.com/datasets/asaniczka/1-3m-linkedin-jobs-and-skills-2024\n","url":"https://huggingface.co/datasets/HaiweiHe/linkedin-jobs","creator_name":"Haiwei He","creator_url":"https://huggingface.co/HaiweiHe","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc0-1.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"UniVLN","keyword":"feature-extraction","description":"\n  \n    UniVLN: Universal Vision-Language Navigation\n    A universal benchmark for unifying VLN with multi-modal inputs\n  \n\n\n\n  \n    \n  \n  \n    \n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ”¥ News\n\t\n\n\n[2025/05/22] Upload Parquet files for generating the croissant file.\n[2025/05/15] Release of the first version of UniVLN.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ” Supported VLN Tasks\n\t\n\n\n\t\n\t\t\nDataset\nObjNav\nInstanceNav\nImgNav\nRoomNav\nPointNav\nInstructionNav\nDialogNav\n\n\n\t\t\nR2R\nâŒ\nâŒ\nâŒ\nâŒ\nâŒ\nâœ…\nâŒ\n\n\nVLN-CE\nâŒ\nâŒ\nâŒ\nâŒ\nâŒ\nâœ…\nâŒ\n\n\nHouse3D\nâŒ\nâŒ\nâŒ\nâœ…\nâŒ\nâŒ\nâŒ\n\n\nHM3D\nâœ…\nâœ…â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JunweiZheng/UniVLN.","url":"https://huggingface.co/datasets/JunweiZheng/UniVLN","creator_name":"Junwei Zheng","creator_url":"https://huggingface.co/JunweiZheng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Chinese","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-17052024-uhub-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-17052024-uhub-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal case document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-17052024-uhub-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-uhub-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-uhub-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-17052024-uhub-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-17052024-uhub-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal case document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-17052024-uhub-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-uhub-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-uhub-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"WillyShakes","keyword":"feature-extraction","description":"cd your-dataset-name\ncp /path/to/your/data/* .\ngit add .\ngit commit -m \"Add my dataset\"\ngit push\n","url":"https://huggingface.co/datasets/scenecoachai/WillyShakes","creator_name":"Janis Deedy","creator_url":"https://huggingface.co/scenecoachai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Latin","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"InertialPressureHumanPose","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ§ Human Activity Recognition Dataset with Inertial and Pressure Sensors\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Œ Overview\n\t\n\nThis dataset contains multimodal sensor data collected for human activity recognition using inertial (IMU) and plantar pressure sensors. It was designed to support research in human motion analysis, wearable sensing, smart healthcare, and fall detection.\nThe dataset includes six types of human activities, with signals recorded from five sensors:\n\n3 IM948 inertial sensors (waist, leftâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gtttttttttttttttttttt/InertialPressureHumanPose.","url":"https://huggingface.co/datasets/gtttttttttttttttttttt/InertialPressureHumanPose","creator_name":"çŽ‹å®‡åŸŽ","creator_url":"https://huggingface.co/gtttttttttttttttttttt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-822545","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-822545 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments in a debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-822545 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-822545","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-822545 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments in a debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-822545 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-862053","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-862053 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-862053 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-862053.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-862053","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-862053","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-862053 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-862053 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-862053.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-862053","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"general","keyword":"feature-extraction","description":"myyim/general dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/myyim/general","creator_name":"Man","creator_url":"https://huggingface.co/myyim","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-1362024-gcw6-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-1362024-gcw6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information Retrieval System\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-1362024-gcw6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-1362024-gcw6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-1362024-gcw6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-1362024-gcw6-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-1362024-gcw6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information Retrieval System\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-1362024-gcw6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-1362024-gcw6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-1362024-gcw6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stamp-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset êµ¬ì¡° ì„¤ëª…\n\t\n\nì´ ë””ë ‰í† ë¦¬ëŠ” STAMP í”„ë¡œì íŠ¸ì˜ ë°ì´í„°ì…‹ì„ í¬í•¨í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.\n\n\t\n\t\t\n\t\të””ë ‰í† ë¦¬ êµ¬ì¡°\n\t\n\ndataset/\nâ”œâ”€â”€ emb128/                        # 128ì°¨ì› ìž„ë² ë”© ë°ì´í„°\nâ”‚   â”œâ”€â”€ trace_embed/               # ì›ë³¸ ìž„ë² ë”© ë°ì´í„°\nâ”‚   â”œâ”€â”€ autoencoder_stage1/        # ì˜¤í† ì¸ì½”ë” í•™ìŠµ/ì¶”ë¡  ê²°ê³¼\nâ”‚   â”‚   â”œâ”€â”€ weight/                # í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸\nâ”‚   â”‚   â””â”€â”€ infer_result/          # ì¶”ë¡  ê²°ê³¼ (ìž ìž¬ ê³µê°„ ë°ì´í„°)\nâ”‚   â”œâ”€â”€ trace_latent/              # â†’ autoencoder_stage1/infer_result (ì‹¬ë³¼ë¦­ ë§í¬)\nâ”‚   â””â”€â”€ setting/                   # ì„¤ì • íŒŒì¼\nâ”œâ”€â”€ emb256/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/selen-kim/stamp-dataset.","url":"https://huggingface.co/datasets/selen-kim/stamp-dataset","creator_name":"kim","creator_url":"https://huggingface.co/selen-kim","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10M<n<100M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"kizaru","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains a collection of song lyrics by Russian rapper Kizaru, scraped from Genius. The lyrics have been chunked into meaningful phrases or lines and embedded using SentenceTransformers for use in semantic search and retrieval tasks, such as lyric bots, citation detectors, or creative NLP applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: @ksusonic\nLanguage(s) (NLP): Russian\nLicense: Dataset derivedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ksusonic/kizaru.","url":"https://huggingface.co/datasets/ksusonic/kizaru","creator_name":"Daniil","creator_url":"https://huggingface.co/ksusonic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","feature-extraction","Russian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-862024-gra4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"E-commerce software for an online store\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-862024-gra4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"E-commerce software for an online store\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"coding","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcoding Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the coding model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/coding.","url":"https://huggingface.co/datasets/fine-tuned/coding","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"coding","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcoding Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the coding model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/coding.","url":"https://huggingface.co/datasets/fine-tuned/coding","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-02082024-vrdv-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-02082024-vrdv-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-02082024-vrdv-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-02082024-vrdv-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-02082024-vrdv-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-02082024-vrdv-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-02082024-vrdv-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-02082024-vrdv-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-02082024-vrdv-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-02082024-vrdv-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"StringKilla","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tStringKilla - Small Datasets for String Algorithms Benchmarking\n\t\n\nThe goal of this dataset is to provide a fairly diverse set of strings to evalute the performance of various string-processing algorithms in StringZilla and beyond.\n\n\t\n\t\t\n\t\tEnglish Texts\n\t\n\n\n\t\n\t\t\n\t\tEnglish Leipzig Corpora Collection\n\t\n\n\n124 MB uncompressed\n1'000'000 lines of ASCII\n8'388'608 tokens of mean length 5\n\nThe dataset was originally pulled from Princeton's website:\nwget --no-clobber -O leipzig1M.txtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ashvardanian/StringKilla.","url":"https://huggingface.co/datasets/ashvardanian/StringKilla","creator_name":"Ash Vardanian","creator_url":"https://huggingface.co/ashvardanian","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","100K - 1M","text","Text"],"keywords_longer_than_N":true},
	{"name":"fintwit-images","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tFinTwit Images\n\t\n\nThis dataset is a collection of a sample of images from tweets that I scraped using my Discord bot that keeps track of financial influencers on Twitter.\nThe data consists of images that were part of tweets that did not mention a ticker.\nThis dataset can be used for a wide variety of tasks, such as image classification or feature extraction.\n\n\t\n\t\t\n\t\n\t\n\t\tFinTwit Charts Collection\n\t\n\nThis dataset is part of a larger collection of datasets, scraped from Twitter andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/fintwit-images.","url":"https://huggingface.co/datasets/StephanAkkerman/fintwit-images","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"dataset-featurization","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Featurization: Experiments\n\t\n\nThis repository contains datasets used in evaluating Dataset Featurization against the prompting baseline. For datasets used in the case studies, please refer to Compositional Preference Modeling and Compact Jailbreaks.\nThe evaluation focuses on three datasets: The New York Times Annotated Corpus (NYT), Amazon Reviews (Amazon), and DBPEDIA. For each dataset, we sample 15 different categories and construct three separate subsets, each containing 5â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bravansky/dataset-featurization.","url":"https://huggingface.co/datasets/Bravansky/dataset-featurization","creator_name":"Michal","creator_url":"https://huggingface.co/Bravansky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","language-modeling","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-203779","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-203779 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-203779 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-203779.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-203779","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-203779","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-203779 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-203779 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-203779.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-203779","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Education sector outreach\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Education sector outreach\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"wine-text-126k","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tWine Text Dataset 126K\n\t\n\nA comprehensive dataset of 125,787 wine records with detailed descriptions, pricing, categories, and regions. This dataset is perfect for natural language processing, recommendation systems, and wine-related machine learning tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains rich textual information about wines scraped from wine retailer websites. Each record includes the wine name, detailed tasting notes and descriptions, pricing information, wineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cipher982/wine-text-126k.","url":"https://huggingface.co/datasets/cipher982/wine-text-126k","creator_name":"David Rose","creator_url":"https://huggingface.co/cipher982","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"malagasy-text-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tmalagasy-text-dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Malagasy Text Dataset is a large-scale collection of text data in Malagasy, designed for a wide range of Natural Language Processing (NLP) tasks. It is ideal for training, fine-tuning, and evaluating language models, machine translation systems, and text generation models.\nAs a low-resource language dataset, it supports NLP research by providing high-quality Malagasy linguistic data, fostering advancements in machine learning andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lo-Renz-O/malagasy-text-dataset.","url":"https://huggingface.co/datasets/Lo-Renz-O/malagasy-text-dataset","creator_name":"Lorenzo Mamelona","creator_url":"https://huggingface.co/Lo-Renz-O","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","feature-extraction","Malagasy","mit"],"keywords_longer_than_N":true},
	{"name":"DecoyDB","keyword":"feature-extraction","description":"ðŸ”§Code, ðŸ“‚Dataset\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDecoyDB is a curated dataset of high-resolution protein-ligand complexes and their associated decoy structures. It is designed to support research on graph contrastive learning, binding affinity prediction, and structure-based drug discovery. The dataset is derived from experimentally resolved complexes and refined to ensure data quality.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach protein-ligand complex is stored in a nested directory under DecoyDB/, using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YupuZ/DecoyDB.","url":"https://huggingface.co/datasets/YupuZ/DecoyDB","creator_name":"Yupu Zhang","creator_url":"https://huggingface.co/YupuZ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-23052024-6kfw-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-23052024-6kfw-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"informational search for legal technology guidance\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-23052024-6kfw-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-6kfw-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-6kfw-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-23052024-6kfw-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-23052024-6kfw-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"informational search for legal technology guidance\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-23052024-6kfw-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-6kfw-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-6kfw-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-612024-vf79-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-612024-vf79-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-612024-vf79-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-612024-vf79-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-612024-vf79-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-612024-vf79-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-612024-vf79-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-612024-vf79-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-612024-vf79-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-612024-vf79-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Legal document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Legal document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-650620","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-512-192-gpt-4o-2024-05-13-650620 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"arxiv paper domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-650620 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-650620","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-512-192-gpt-4o-2024-05-13-650620 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"arxiv paper domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-650620 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6142024-0ndt-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6142024-0ndt-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"content moderation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6142024-0ndt-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Korean","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6142024-0ndt-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6142024-0ndt-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"content moderation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6142024-0ndt-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Korean","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cherry-juice-guide","keyword":"feature-extraction","description":"Dataset Details\nDataset Description\nThis dataset is derived from The Ultimate Tart Cherry Juice Buyerâ€™s Guide. It organizes information about tart cherry juice concentrate into a structured format, including dosage, dilution ratios, concentration levels (Brix), sourcing, certifications, storage, and documented health benefits.\nIt is designed to support AI training, information retrieval, question-answering, consumer education, and market research.\nCurated by: Traverse Bay Farms / Fruitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WindingIdeas/cherry-juice-guide.","url":"https://huggingface.co/datasets/WindingIdeas/cherry-juice-guide","creator_name":"Winding Ideas","creator_url":"https://huggingface.co/WindingIdeas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","text-generation","summarization","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information in German language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can loadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information in German language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can loadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"datasetTest","keyword":"feature-extraction","description":"Test\n","url":"https://huggingface.co/datasets/riccardopignari/datasetTest","creator_name":"RIccardo Pignari","creator_url":"https://huggingface.co/riccardopignari","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","afl-3.0","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"perfume","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tPerfume dataset, over 26k perfumes\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRAW Perfume dataset (2024 Year), over 26k perfumes. Images, ingredients, description, etc.\n\n\t\n\t\t\n\t\tHow to use\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# download raw archive file\nzip_file = hf_hub_download(\n    repo_id='doevent/perfume',\n    repo_type='dataset',\n    filename='images.zip',\n)\n\nimport zipfile\n\n# extract files to your directory\ndataset_dir = 'images'\nos.makedirs(dataset_dir, exist_ok=True)\nwithâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/doevent/perfume.","url":"https://huggingface.co/datasets/doevent/perfume","creator_name":"Max Skobeev","creator_url":"https://huggingface.co/doevent","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","feature-extraction","image-feature-extraction","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"Wrapped_3D_Attacks","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tWrapped 3D Attacks Dataset\n\t\n\n\n\t\n\t\t\n\t\tFull version of dataset is availible for commercial usage - leave a request on our website Axon Labs to purchase the dataset ðŸ’°\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset is designed to enhance Liveness Detection models by simulating Wrapped 3D Attacks â€” a more advanced version of 3D Print Attacks, where facial prints include 3D elements and additional attributes. It is particularly useful for iBeta Level 2 certification and anti-spoofing modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/Wrapped_3D_Attacks.","url":"https://huggingface.co/datasets/AxonData/Wrapped_3D_Attacks","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","video-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"perfume","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tPerfume dataset, over 26k perfumes\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRAW Perfume dataset (2024 Year), over 26k perfumes. Images, ingredients, description, etc.\n\n\t\n\t\t\n\t\tHow to use\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# download raw archive file\nzip_file = hf_hub_download(\n    repo_id='doevent/perfume',\n    repo_type='dataset',\n    filename='images.zip',\n)\n\nimport zipfile\n\n# extract files to your directory\ndataset_dir = 'images'\nos.makedirs(dataset_dir, exist_ok=True)\nwithâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/doevent/perfume.","url":"https://huggingface.co/datasets/doevent/perfume","creator_name":"Max Skobeev","creator_url":"https://huggingface.co/doevent","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","feature-extraction","image-feature-extraction","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"jinsaryko-tifa-en-nano-codec-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTifa EN Nano-Codec Dataset\n\t\n\nThis dataset is built upon the Tifa dataset and re-encoded using NVIDIAâ€™s NeMo Audio Codec into nano audio tokens.  \nIt is designed for fine-tuning multimodal LLMs and speech systems (TTS/ASR) that rely on codec-based audio token representations.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\ntext: transcription of the utterance.  \nspeaker: speaker identifier (string).  \nnano_layer_1 â€¦ nano_layer_4: tokenized audio representations from the NVIDIA NeMo Nano Codecâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nineninesix/jinsaryko-tifa-en-nano-codec-dataset.","url":"https://huggingface.co/datasets/nineninesix/jinsaryko-tifa-en-nano-codec-dataset","creator_name":"NineNineSix","creator_url":"https://huggingface.co/nineninesix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-465198","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-465198 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic debates\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-465198 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-465198.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-465198","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-465198","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-465198 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic debates\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-465198 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-465198.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-465198","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"deepspeed-from-new-new-docker","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdeepspeed-from-new-new-docker Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the deepspeed-from-new-new-docker model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker.","url":"https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"deepspeed-from-new-new-docker","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdeepspeed-from-new-new-docker Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the deepspeed-from-new-new-docker model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker.","url":"https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5202024-6tkj-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5202024-6tkj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"educational content for customer insights and marketing strategies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5202024-6tkj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-6tkj-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-6tkj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5202024-6tkj-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5202024-6tkj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"educational content for customer insights and marketing strategies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5202024-6tkj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-6tkj-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-6tkj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-qeye-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-qeye-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Cybersecurity and hacking information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-qeye-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-qeye-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-qeye-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-qeye-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-qeye-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Cybersecurity and hacking information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-qeye-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-qeye-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-qeye-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Telugu-NLP-AI-Dialect-Comedy-video-Dataset","keyword":"feature-extraction","description":"Telugu is one of the sweetest and oldest languages of India. A deep Dive into Telugu its spoken in 2 states and majorly 16 regional dailects.\nThis Dataset help you perform operations in NLP and Speech Recognition Models towards telugu Dialects.\n","url":"https://huggingface.co/datasets/Automation-Tribe/Telugu-NLP-AI-Dialect-Comedy-video-Dataset","creator_name":"AUTTRIBE-AI-AUTOMATION","creator_url":"https://huggingface.co/Automation-Tribe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Telugu","Kannada","English"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-546049","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-546049 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-546049 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-546049.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-546049","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-546049","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-546049 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-546049 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-546049.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-546049","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Test2","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ§  Open Humnoid Actuated Face Dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Open Humnoid Actuated Face Dataset has been created to support researchers and developers working on face-head actuated simulations for robotics, reinforcement learning, and human-computer interaction.The data was collected during a reinforcement learning (RL) training process where the agentâ€™s goal was to replicate human facial expressions using a humanoid head model.\nThe dataset pairs actuator angle positionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iamirulofficial/Test2.","url":"https://huggingface.co/datasets/iamirulofficial/Test2","creator_name":"Amirul","creator_url":"https://huggingface.co/iamirulofficial","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","mit","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"LSUN_bedroom_VQA_v2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"CSUN_bedroom_VQA_feliu_v2\"\n\t\n\n\n","url":"https://huggingface.co/datasets/fformosa/LSUN_bedroom_VQA_v2","creator_name":"Feliu Formosa","creator_url":"https://huggingface.co/fformosa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","feature-extraction","visual-question-answering","image-classification"],"keywords_longer_than_N":true},
	{"name":"historinhas","keyword":"feature-extraction","description":"\"Historinhas\" Ã© um dataset em portuguÃªs inspirado no TinyStories, desenvolvido para demonstrar que modelos de linguagem de menor escala podem gerar textos coerentes quando treinados em dados simplificados e de alta qualidade.\nEste conjunto de dados contÃ©m histÃ³rias curtas e simples em portuguÃªs, projetadas para serem compreensÃ­veis e adequadas para treinar modelos menores que ainda possam produzir narrativas coerentes e fluidas.\n","url":"https://huggingface.co/datasets/Boakpe/historinhas","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","zero-shot-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sudoku-image-recognition","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Sudoku Image Recognition\n\t\n\nImages of Sudoku puzzles for puzzle recognition. This dataset was used to bootstrap the Sudoku OCR engine.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset consists of 1400 labelled images of Sudoku puzzles. It is intended for training and evaluating a system that can automatically determine the state of each cell in the puzzle: whether it is solved or unsolved, and which digits it contains. The images are split intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lexski/sudoku-image-recognition.","url":"https://huggingface.co/datasets/Lexski/sudoku-image-recognition","creator_name":"Alex Kubiesa","creator_url":"https://huggingface.co/Lexski","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","cc0-1.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"stories-elements","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tStories Narrative Elements\n\t\n\nThis dataset contains stories from agentlans/stories-refinement annotated with key narrative elementsâ€”title, characters, setting, plot stages, themes, and full textâ€”in a structured format.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nSource: Stories from agentlans/stories-refinement.\nAnnotations: Generated using agentlans/Llama3.1-LexiHermes-SuperStorm with 10-shot learning, guided by 15 example analyses by Claude Sonnet 4.\nLegacy Data: The zero-shot.jsonl.zst file containsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/stories-elements.","url":"https://huggingface.co/datasets/agentlans/stories-elements","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Dataset_Susu-KedelAI","keyword":"feature-extraction","description":"Taffee/Dataset_Susu-KedelAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Taffee/Dataset_Susu-KedelAI","creator_name":"Luthfi","creator_url":"https://huggingface.co/Taffee","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Indonesian","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-5b5o-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-5b5o-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Fashion boutique products and reviews search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-5b5o-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-5b5o-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-5b5o-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-5b5o-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-5b5o-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Fashion boutique products and reviews search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-5b5o-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-5b5o-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-5b5o-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CoLan-150K","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCoLan-150K: A Conceptual Representation Dataset for Image Editing\n\t\n\nCoLan-150K is a large-scale dataset of conceptual representations designed to support image editing. It is introduced in the paper Concept Lancet: Image Editing with Compositional Representation Transplant (CVPR2025).\n\n\t\n\t\t\n\t\tOverview\n\t\n\nDiffusion models have revolutionized image synthesis and editing, yet one persistent challenge is how to accurately control the degree of editing. CoLan-150K addresses this byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/peterljq/CoLan-150K.","url":"https://huggingface.co/datasets/peterljq/CoLan-150K","creator_name":"Jinqi Luo","creator_url":"https://huggingface.co/peterljq","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","mit","arxiv:2504.02828","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"jina-embeddings-v2-base-en-2024513-kkxa-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-2024513-kkxa-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce search for RV accessories\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-2024513-kkxa-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024513-kkxa-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024513-kkxa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-2024513-kkxa-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-2024513-kkxa-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce search for RV accessories\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-2024513-kkxa-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024513-kkxa-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024513-kkxa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"StringWars","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tStringKilla - Small Datasets for String Algorithms Benchmarking\n\t\n\nThe goal of this dataset is to provide a fairly diverse set of strings to evalute the performance of various string-processing algorithms in StringZilla and beyond.\n\n\t\n\t\t\n\t\tEnglish Texts\n\t\n\n\n\t\n\t\t\n\t\tEnglish Leipzig Corpora Collection\n\t\n\n\n124 MB uncompressed\n1'000'000 lines of ASCII\n8'388'608 tokens of mean length 5\n\nThe dataset was originally pulled from Princeton's website:\nwget --no-clobber -O leipzig1M.txtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ashvardanian/StringWars.","url":"https://huggingface.co/datasets/ashvardanian/StringWars","creator_name":"Ash Vardanian","creator_url":"https://huggingface.co/ashvardanian","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","100K - 1M","text","Text"],"keywords_longer_than_N":true},
	{"name":"ops-volltext-klassifizierung-v2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSynthetisches Dataset fÃ¼r OPS-Klassifizierung\n\t\n\n\n\t\n\t\t\n\t\tHaftungsausschluss\n\t\n\nDiese Daten wurden von https://gesund.bund.de gescraped und sind Eigentum des Urheberrechtsinhabers. Der alleinige Zweck dieses Datensatzes und der zugehÃ¶rigen Codebasis sowie anderer Materialien ist es, die deutsche medizinische Gemeinschaft bei der Erstellung hochspezialisierter deutscher Modelle zu unterstÃ¼tzen.\nWenn Sie an vorab geparsten Daten interessiert sind, die als Baseline fÃ¼r diese synthetischenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v2.","url":"https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v2","creator_name":"Bijay Regmi","creator_url":"https://huggingface.co/regmibijay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"image-gen-vector-consistency","keyword":"image-feature-extraction","description":"Dataset for upcomming paper \"Evaluating Consistency of Image Generation Models with Vector Similarity\"\n","url":"https://huggingface.co/datasets/MexIvanov/image-gen-vector-consistency","creator_name":"Mex Ivanov","creator_url":"https://huggingface.co/MexIvanov","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Collatz_conjecture_100m","keyword":"feature-extraction","description":"\n\n\n\t\n\t\t\n\t\tCollatz_conjecture_100m\n\t\n\nHello, this is the Collatz conjecture dataset.\nThe Collatz conjecture\n\nn is even number, Divide by 2.\nn is odd number, multiply by 3 and add 1.\nrepeat, See if it goes to 1.\nDoes it apply to all natural numbers?\n\nThis concise problem has not yet been proven.\nThis problem is also famous for its beautiful graphs.\nThe dataset contains the paths from 1 to 100 million natural numbers leading to 1.\nThe path where a single digit in a row becomes 1 is displayedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Taery/Collatz_conjecture_100m.","url":"https://huggingface.co/datasets/Taery/Collatz_conjecture_100m","creator_name":"KwakTaeKyung","creator_url":"https://huggingface.co/Taery","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","English","Korean","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"rightnow-arabic-llm-corpus","keyword":"feature-extraction","description":"\n\n\t\n\t\t\n\t\tRightNow Arabic LLM Corpus\n\t\n\nThe largest and highest-quality Arabic language model training dataset, featuring 743,288 meticulously cleaned articles with 244 million words of professional Arabic text.\n\n\t\n\t\t\n\t\tAbout RightNow AI\n\t\n\nThis dataset was collected by the RightNow AI team, creators of the #1 GPU-powered AI code editor. Visit us at https://rightnowai.co/\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Articles\n743,288\n\n\nTotal Words\n244,000,000+\n\n\nDataset Size\n8.7â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus.","url":"https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"phomo-data","keyword":"feature-extraction","description":"\n\nPhotoclinometry-from-Motion (PhoMo)\n\n\n\nTravis Driver, Andrew Vaughan, Yang Cheng, Adnan Ansar, John Christian, Panagiotis Tsiotras\n\n\n\n\t\n\t\t\n\t\tThis is the official repository for Stereophotoclinometry Revisited, which is currently under review for publication to AIAA's Journal of Guidance, Control, and Dynamics (JGCD)\n\t\n\nPhotoclinometry-from-Motion (PhoMo) is a framework for autonomous image-based surface reconstruction and characterization of small celestial bodies. PhoMo integratesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/travisdriver/phomo-data.","url":"https://huggingface.co/datasets/travisdriver/phomo-data","creator_name":"Travis Driver","creator_url":"https://huggingface.co/travisdriver","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["robotics","feature-extraction","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-204265","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-204265 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-204265 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-204265","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-204265 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-204265 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"gooaq_mt_german","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tGerman GooAQ (Google Answers to Google Questions) question-answer pairs\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nThis dataset is a version of the GooAQ question-answer pairs dataset machine-translated to English and back from English to German (link to original dataset). This dataset can be used directly with Sentence Transformers to train embedding models.\nMachine translation has been performed using the English-to-German quickMT model and the quickMT library with beam_size = 5.\nThe dataset contains ~3Mâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","German","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"askubuntu","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical Q&A search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical Q&A search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-m8dn-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-m8dn-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-m8dn-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-m8dn-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"imageomics-2025","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAnonymized Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains aerial orthomosaic tiles captured at three different times of day (10:00, 12:00, and 15:00). The dataset is organized into three configurations: default (raw images + canopy height), dinov2_base (DINOv2 embeddings), and dinov3_sat (DINOv3 embeddings). All configurations share consistent train/test splits with matching tile identifiers for cross-referencing. The dataset is designed for training vision encodersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anondatasets/imageomics-2025.","url":"https://huggingface.co/datasets/anondatasets/imageomics-2025","creator_name":"anonymous","creator_url":"https://huggingface.co/anondatasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-to-image","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"STF","keyword":"feature-extraction","description":"yifansuper/STF dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yifansuper/STF","creator_name":"Yifan Li","creator_url":"https://huggingface.co/yifansuper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","cc-by-4.0","10K - 100K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"ann_pinterest_and_captions_numinous","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for diffusion_qualia_1 Dataset (by Numinous)\n\t\n\nThis is a dataset of ~7K images and their captions downloaded from Pinterest, and intended to be used for multimodal training and evaluation. \nThe images are saved as io.Bytes, aka a sequence of bytes, and intended to be read into PNG images, i.e. buf.getvalue() returns bytes objects containing PNG image data.\n","url":"https://huggingface.co/datasets/annh3/ann_pinterest_and_captions_numinous","creator_name":"Ann He","creator_url":"https://huggingface.co/annh3","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24-gpt-4o-2024-05-13-35883","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24-gpt-4o-2024-05-13-35883 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24-gpt-4o-2024-05-13-35883 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-35883.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-35883","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24-gpt-4o-2024-05-13-35883","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24-gpt-4o-2024-05-13-35883 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24-gpt-4o-2024-05-13-35883 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-35883.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-35883","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-321013","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-321013 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-321013 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-321013.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-321013","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-321013","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-321013 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-321013 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-321013.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-321013","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"PhysicalAI-SimReady-Warehouse-01","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tNVIDIA Physical AI SimReady Warehouse OpenUSD Dataset\n\t\n\n\n\nDataset Version: 1.1.0\nDate: May 18, 2025\nAuthor: NVIDIA, Corporation\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\n\n\t\t\n\t\n\t\tContents\n\t\n\nThis dataset includes the following:\n\nThis README file\nA CSV catalog that enumerates all of the OpenUSD assets that are part of this dataset including a sub-folder of images that showcase each 3D asset (physical_ai_simready_warehouse_01.csv). The CSV file is organized inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/PhysicalAI-SimReady-Warehouse-01.","url":"https://huggingface.co/datasets/nvidia/PhysicalAI-SimReady-Warehouse-01","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","robotics","depth-estimation","object-detection","image-classification"],"keywords_longer_than_N":true},
	{"name":"PRLx-GAN-synthetic-rim","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tPRLx-GAN\n\t\n\nRepository for Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis published in Synthetic Data at CVPR 2025. \n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\nParamagnetic rim lesions (PRLs) are a rare but highly prognostic lesion subtype in multiple sclerosis, visible only on susceptibility ($\\chi$) contrasts. This work presents a generative framework to: \n\nSynthesize new rim lesion maps that address class imbalance in training data \nEnable a novel denoisingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agr78/PRLx-GAN-synthetic-rim.","url":"https://huggingface.co/datasets/agr78/PRLx-GAN-synthetic-rim","creator_name":"Alexandra G. Roberts","creator_url":"https://huggingface.co/agr78","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-774308","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-774308 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment analysis and opinion-based QA\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-774308 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-774308.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-774308","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-774308","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-774308 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment analysis and opinion-based QA\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-774308 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-774308.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-774308","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cookie-policy-corpus","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for cookie-policy-corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe cookie-policy-corpus is a dataset that contains structured information from cookie policy web pages collected from real-world websites. Each entry includes the original webpage URL, raw policy content in its native language, extracted structured data (if available), and translated or processed content in both Vietnamese and English. The dataset supports research on cookie compliance detection, multilingual legalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sonhask/cookie-policy-corpus.","url":"https://huggingface.co/datasets/sonhask/cookie-policy-corpus","creator_name":"Son Ha Hong","creator_url":"https://huggingface.co/sonhask","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-2024512-wvj9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-2024512-wvj9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"construction project search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-2024512-wvj9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024512-wvj9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024512-wvj9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-2024512-wvj9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-2024512-wvj9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"construction project search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-2024512-wvj9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024512-wvj9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024512-wvj9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DeepScholarBench","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDeepScholarBench Dataset\n\t\n\n\n\n\n\n\n\nA comprehensive dataset of academic papers with extracted related works sections and recovered citations, designed for training and evaluating research generation systems.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset contains 63 academic papers from ArXiv with their related works sections and 1630 recovered citations, providing a rich resource for research generation and citation analysis tasks.\n\n\t\n\t\t\n\t\tðŸŽ¯ Use Cases\n\t\n\n\nResearch Generation: Train modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepscholar-bench/DeepScholarBench.","url":"https://huggingface.co/datasets/deepscholar-bench/DeepScholarBench","creator_name":"DeepScholar-Bench","creator_url":"https://huggingface.co/deepscholar-bench","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"reddit-logic","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tReddit Logic: A Dataset for Evaluating Clear and Consistent Reasoning in Natural Language Discourse\n\t\n\nThis dataset studies how people construct and express logical arguments in everyday online discussions. \nUsing posts from Reddit's r/ChangeMyView subreddit, \nthis collection provides well-structured argument analyses that are engaging for humans and machines.\nDataset Construction & Annotation\n\nA curated subset of 10â€‰000 posts was selected from the \"HuggingFaceGECLM/REDDIT_comments\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-logic.","url":"https://huggingface.co/datasets/agentlans/reddit-logic","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"LCC_deu_news_1M_bt","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\t1M*n backtranslated german news texts using quickMT with hard negatives\n\t\n\nThis still growing experimental project/dataset is not connected, funded or organized in any way by the The Leipzig Corpora Collection. I am very thankful that the main idea behind this collection has been released under CC-BY-4.0 - see Terms of Usage .\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nAt the moment the Leipzig Corpora Collention has many raw monolingual corpora transparently documented and available for downloads sinceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/LCC_deu_news_1M_bt.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/LCC_deu_news_1M_bt","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-8142024-iw0e-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-8142024-iw0e-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"sales data analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-8142024-iw0e-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-8142024-iw0e-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-8142024-iw0e-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-8142024-iw0e-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-8142024-iw0e-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"sales data analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-8142024-iw0e-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-8142024-iw0e-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-8142024-iw0e-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"vllm-pr-analysis","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tvLLM PR Test Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Overview\n\t\n\nThis dataset contains 98 vLLM project commits with their corresponding Pull Request (PR) timeline data and comprehensive test type classifications. It provides insights into testing patterns in a major LLM serving infrastructure project.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Description\n\t\n\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset was created by analyzing vLLM project PR timelines to:\n\nIdentify different types of testing and benchmarking activitiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Inferencebench/vllm-pr-analysis.","url":"https://huggingface.co/datasets/Inferencebench/vllm-pr-analysis","creator_name":"Inferencebench","creator_url":"https://huggingface.co/Inferencebench","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-5smg-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-5smg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-5smg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-5smg-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-5smg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-5smg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-855191","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-855191 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-855191 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-855191.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-855191","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-855191","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-855191 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-855191 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-855191.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-855191","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DOID","keyword":"feature-extraction","description":"This dataset is a collection of Mixed-hop Prediction datasets created from DOID's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/DOID","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-06052024-mhal-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-06052024-mhal-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"software documentation search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-mhal-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-06052024-mhal-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-06052024-mhal-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"software documentation search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-mhal-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-2852024-6p16-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-2852024-6p16-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"natural language processing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-2852024-6p16-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-2852024-6p16-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-2852024-6p16-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-2852024-6p16-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-2852024-6p16-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"natural language processing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-2852024-6p16-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-2852024-6p16-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-2852024-6p16-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LithoSim","keyword":"feature-extraction","description":"The benchmark of \"LithoSim: A Large, Holistic Lithography Simulation Benchmark for AI-Driven Semiconductor Manufacturing\"\nThe corresponding GitHub repo can be found at https://dw-hongquan.github.io/LithoSim/\n\n\t\n\t\t\n\t\tData Construction\n\t\n\n\n4 in-distributed dataset (OPC_Metal/Metal/OPC_Via/Via).\n1 out-of-distribution (OOD) dataset.\nEach main dataset has a train_val and a test folder with compressed data file.\nEach set of data contains a source_simple.src description of the source, a layout.png, aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/grandiflorum/LithoSim.","url":"https://huggingface.co/datasets/grandiflorum/LithoSim","creator_name":"Hongquan He","creator_url":"https://huggingface.co/grandiflorum","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","afl-3.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"DAG-Reasoning-DeepSeek-R1-0528","keyword":"feature-extraction","description":"Click here to support our open-source dataset and model releases!\nDAG-Reasoning-DeepSeek-R1-0528 is a dataset focused on analysis and reasoning, creating directed acyclic graphs testing the limits of DeepSeek R1 0528's graph-reasoning skills!\nThis dataset contains:\n\n4.08k synthetically generated prompts to create directed acyclic graphs in response to user input, with all responses generated using DeepSeek R1 0528.\nAll responses contain a multi-step thinking process to perform effectiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/DAG-Reasoning-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/DAG-Reasoning-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-512-192-gpt-4o-2024-05-13-866232","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-512-192-gpt-4o-2024-05-13-866232 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-866232 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-512-192-gpt-4o-2024-05-13-866232","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-512-192-gpt-4o-2024-05-13-866232 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-866232 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"VQA-cmarkea-doc-vqa-clean","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\ncmarkea/doc-vqa dataset that we processed.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@online{SoSoDocvqa,\n  AUTHOR = {LoÃ¯c SOKOUDJOU SONAGU, Yoann SOLA},\n  URL = {https://huggingface.co/datasets/cmarkea/doc-vqa},\n  YEAR = {2024},\n  KEYWORDS = {NLP ; Multimodal}\n}\n\n","url":"https://huggingface.co/datasets/CATIE-AQ/VQA-cmarkea-doc-vqa-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-feature-extraction","French","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"xwitter","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"xwitter100m_tweets\"\n\t\n\nForked from enryu43/twitter100m_tweets\nDOI: 10.5281/zenodo.15086029\n","url":"https://huggingface.co/datasets/0xseatedro/xwitter","creator_name":"ronin","creator_url":"https://huggingface.co/0xseatedro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","mit","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"Glint-360k-alignment","keyword":"image-feature-extraction","description":"yayoimizuha/Glint-360k-alignment dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yayoimizuha/Glint-360k-alignment","creator_name":"Tomokazu Katayama","creator_url":"https://huggingface.co/yayoimizuha","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","unlicense","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US","Face Recognition"],"keywords_longer_than_N":false},
	{"name":"laion-high-resolution-chinese","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tlaion-high-resolution-chinese\n\t\n\n\n\t\n\t\t\n\t\tç®€ä»‹ Brief Introduction\n\t\n\nå–è‡ªLaion5B-high-resolutionå¤šè¯­è¨€å¤šæ¨¡æ€æ•°æ®é›†ä¸­çš„ä¸­æ–‡éƒ¨åˆ†ï¼Œä¸€å…±2.66Mä¸ªå›¾æ–‡å¯¹ã€‚\nA subset from Laion5B-high-resolution (a multimodal dataset), around 2.66M image-text pairs (only Chinese).\n\n\t\n\t\t\n\t\tæ•°æ®é›†ä¿¡æ¯ Dataset Information\n\t\n\nå¤§çº¦ä¸€å…±2.66Mä¸ªä¸­æ–‡å›¾æ–‡å¯¹ã€‚å¤§çº¦å ç”¨381MBç©ºé—´ï¼ˆä»…ä»…æ˜¯urlç­‰æ–‡æœ¬ä¿¡æ¯ï¼Œä¸åŒ…å«å›¾ç‰‡ï¼‰ã€‚\n\nHomepage: laion-5b\nHuggingface: laion/laion-high-resolution\n\n\n\t\n\t\t\n\t\tä¸‹è½½ Download\n\t\n\nmkdir release && cd release\nfor i in {00000..00015}; do wgetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wanng/laion-high-resolution-chinese.","url":"https://huggingface.co/datasets/wanng/laion-high-resolution-chinese","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"functional_code","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCollection of functional programming languages from GitHub.\n\nPoint of Contact: dhuck\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of code examples of functional programming languages for code generation tasks. It was collected over a week long period in March 2023 as part of project in program synthesis.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{\n  'id': str\n  'repository': str\n  'filename': strâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dhuck/functional_code.","url":"https://huggingface.co/datasets/dhuck/functional_code","creator_name":"davin lawrence","creator_url":"https://huggingface.co/dhuck","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","afl-3.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Orca DPO Pair\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a pre-processed version of the OpenOrca dataset.\nThe original OpenOrca dataset is a collection of augmented FLAN data that aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing preference-tuned model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe OrcaDPO Pairâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceH4/orca_dpo_pairs.","url":"https://huggingface.co/datasets/HuggingFaceH4/orca_dpo_pairs","creator_name":"Hugging Face H4","creator_url":"https://huggingface.co/HuggingFaceH4","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"blackada","keyword":"feature-extraction","description":"ludekcizinsky/blackada dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ludekcizinsky/blackada","creator_name":"Ludek Cizinsky","creator_url":"https://huggingface.co/ludekcizinsky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1M<n<10M","Text"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entities-efficient-splade-100K","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDBPedia SPLADE + OpenAI: 100,000 SPLADE Sparse Vectors + OpenAI Embedding\n\t\n\nThis dataset has both OpenAI and SPLADE vectors for 100,000 DBPedia entries. This adds SPLADE Vectors to KShivendu/dbpedia-entities-openai-1M/\nModel id used to make these vectors: \nmodel_id = \"naver/efficient-splade-VI-BT-large-doc\"\n\nFor processing the query, use this: \nmodel_id = \"naver/efficient-splade-VI-BT-large-query\"\n\nIf you'd like to extract the indices and weights/values from the vectors, you can do soâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nirantk/dbpedia-entities-efficient-splade-100K.","url":"https://huggingface.co/datasets/nirantk/dbpedia-entities-efficient-splade-100K","creator_name":"Nirant Kasliwal","creator_url":"https://huggingface.co/nirantk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Captchas","keyword":"feature-extraction","description":"AvinashRicky/Captchas dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/AvinashRicky/Captchas","creator_name":"Avinash Ricky Yadlapalli","creator_url":"https://huggingface.co/AvinashRicky","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","text-generation","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"simpsonspix2pixdataset","keyword":"feature-extraction","description":"K00B404/simpsonspix2pixdataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/K00B404/simpsonspix2pixdataset","creator_name":"koo","creator_url":"https://huggingface.co/K00B404","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-gugugo-ko","keyword":"feature-extraction","description":"\n\n\t\n\t\t\n\t\tOpenOrca í•œêµ­ì–´ ë²ˆì—­ ë°ì´í„°ì…‹\n\t\n\nGugugo-koen-7B-V1.1ì„ ì´ìš©í•˜ì—¬ OpenOrcaë°ì´í„°ì…‹ì„ ë²ˆì—­í•˜ê³  ìžˆìŠµë‹ˆë‹¤.\në²ˆì—­ ì§„í–‰ìƒí™©ì€ ì•„ëž˜ë¥¼ ì°¸ê³ í•´ ì£¼ì‹­ì‹œì˜¤.\n\n\t\n\t\t\n\t\tì§„í–‰ìƒí™©\n\t\n\n\nGPT4 ìƒì„±ë¬¼ ì•½ 100ë§Œ ê°œ ì¤‘ ì•½ 64ë§Œ ê°œ ë²ˆì—­ì™„ë£Œ\nGPT3.5 ìƒì„±ë¬¼ ì•½ 350ë§Œ ê°œ ì¤‘ ì•½ 159ë§Œ ê°œ ë²ˆì—­ì™„ë£Œ\n\në°ì´í„°ì…‹ ì‚¬ìš© í›„ ì¶œì²˜í‘œê¸°ëŠ” ì œìž‘ìžì—ê²Œ í° íž˜ì´ ë©ë‹ˆë‹¤.\n\n\t\n\t\t\n\t\tOriginal dataset card: OpenOrca\n\t\n\nðŸ‹ The OpenOrca Dataset! ðŸ‹\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/squarelike/OpenOrca-gugugo-ko.","url":"https://huggingface.co/datasets/squarelike/OpenOrca-gugugo-ko","creator_name":"Woojun Jeong","creator_url":"https://huggingface.co/squarelike","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Marvel_network","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Marvel Network\n\t\n\nThis is a dataset for Marvel universe social network, which contains the relationships between Marvel heroes.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Marvel Comics character collaboration graph was originally constructed by Cesc RossellÃ³, Ricardo Alberich, and Joe Miro from the University of the Balearic Islands. They compare the characteristics of this universe to real-world collaboration networks, such as the Hollywood network, or the one created byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ShimizuYuki/Marvel_network.","url":"https://huggingface.co/datasets/ShimizuYuki/Marvel_network","creator_name":"HAOCHENG Qin","creator_url":"https://huggingface.co/ShimizuYuki","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","afl-3.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"car_dealership","keyword":"feature-extraction","description":"Retail Car Dealership Data\n\nData for a car delearship. Perform EDA extract features and clean it up. Source Kaggle.\nTry it out! It's primary goal is to provide an interface for users to download the dataset and try it out.\n","url":"https://huggingface.co/datasets/cs-uche/car_dealership","creator_name":"Sopuruchi","creator_url":"https://huggingface.co/cs-uche","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"peptide","keyword":"feature-extraction","description":"This dataset is collected from A transformer-based model to predict peptideâ€“HLA class I binding and optimize mutated peptides for vaccine design.\n","url":"https://huggingface.co/datasets/keiwoo/peptide","creator_name":"keiwoo","creator_url":"https://huggingface.co/keiwoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","1M - 10M","text","Text"],"keywords_longer_than_N":true},
	{"name":"distilabel-intel-orca-dpo-pairs-tr","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"malhajar/orca_dpo_pairs-tr\"\n\t\n\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish dataset collection to enhance the performance of LLM's Produced in the Turkish Language.\nmalhajar/orca_dpo_pairs-tr is a translated version of argilla/distilabel-intel-orca-dpo-pairs\nTranslated by: Mohamad Alhajar \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is a pre-processed version of the OpenOrca dataset translated toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/distilabel-intel-orca-dpo-pairs-tr.","url":"https://huggingface.co/datasets/malhajar/distilabel-intel-orca-dpo-pairs-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"TCRdb2","keyword":"feature-extraction","description":"This dataset is collected from TCRdb2.0. \nThe original sequence records are 691,744,135 with redundancy. \ntcrdb2.txt removes duplicates and remains 290,314,598.\ntcrdb2CDhit75.txt removes sequences with less than 75% identity using cd-hit and remains 1,782,927.\n","url":"https://huggingface.co/datasets/keiwoo/TCRdb2","creator_name":"keiwoo","creator_url":"https://huggingface.co/keiwoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","100M - 1B","text","Text"],"keywords_longer_than_N":true},
	{"name":"OpenOrca_35k","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"OpenOrca_35k\"\n\t\n\nThe first 35k examples from Open-Orca/OpenOrca\n","url":"https://huggingface.co/datasets/georgesung/OpenOrca_35k","creator_name":"Jou-ching (George) Sung","creator_url":"https://huggingface.co/georgesung","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"invoices-donut-data-v1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Invoices (Sparrow)\n\t\n\nThis dataset contains 500 invoice documents annotated and processed to be ready for Donut ML model fine-tuning.\nAnnotation and data preparation task was done by Katana ML team.\nSparrow - open-source data extraction solution by Katana ML.\nOriginal dataset info: KozÅ‚owski, Marek; Weichbroth, PaweÅ‚ (2021), â€œSamples of electronic invoicesâ€, Mendeley Data, V2, doi: 10.17632/tnj49gpmtz.2\n","url":"https://huggingface.co/datasets/katanaml-org/invoices-donut-data-v1","creator_name":"Katana ML","creator_url":"https://huggingface.co/katanaml-org","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"openorca-chinese-zhtw","keyword":"feature-extraction","description":"\n\n\t\n\t\t\n\t\tDataset Card for \"openorca-chinese-zhtw\"\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoing generation to expand its scope.\nThe data is primarily used for training and evaluation in the field of naturalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/openorca-chinese-zhtw.","url":"https://huggingface.co/datasets/erhwenkuo/openorca-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"high-quality-english-sentences","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tHigh-Quality English Sentences\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a collection of high-quality English sentences sourced from C4 and FineWeb (not FineWeb-Edu). The sentences have been carefully filtered and processed to ensure quality and uniqueness.\n\"High-quality\" means they're legible English and not spam, although they may still have spelling and grammar errors.\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nBefore filtering:\n\nC4: 1 million sentences\nFineWeb: 1 million sentencesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-english-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-english-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"Gitcoin-ODS-Hackhaton-GR15","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for [Gitcoin ODS Hackathon GR15]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis data set was created in the context of the first Gitcoin Open Data Science Hackathon.\nIt contains all the transactions on the Ethereum and Polygon chains of the wallet that contributed to the Grant 15 of Gitcoin grants program.\nIt was created in order to find patterns in the transactions of potential Sybil attackers by exploring their on-chain activity.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Poupou/Gitcoin-ODS-Hackhaton-GR15.","url":"https://huggingface.co/datasets/Poupou/Gitcoin-ODS-Hackhaton-GR15","creator_name":"Poupou web3","creator_url":"https://huggingface.co/Poupou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","no-annotation","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Top5percent","keyword":"feature-extraction","description":"ðŸ‹ The OpenOrca-Top5Percent Dataset! ðŸ‹\n\nWe are excited to introduce the OpenOrca-Top5Percent dataset, a refined version of the original OpenOrca dataset. This dataset contains only those entries which utilize the top 5% most frequently used words in the OpenOrca dataset, aiming to focus on high-frequency vocabulary for various NLP tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca-Top5Percent dataset is a curated subset of the augmented FLAN Collection data, focusing specifically on entries thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dynopii/OpenOrca-Top5percent.","url":"https://huggingface.co/datasets/dynopii/OpenOrca-Top5percent","creator_name":"Dynopii Inc","creator_url":"https://huggingface.co/dynopii","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"OpenOrca","keyword":"feature-extraction","description":"ðŸ‹ The OpenOrca Dataset! ðŸ‹\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tOfficial Models\n\t\n\n\n\t\n\t\n\t\n\t\tMistral-7B-OpenOrca\n\t\n\nOur latest model, the first 7B to score better overall than allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Open-Orca/OpenOrca.","url":"https://huggingface.co/datasets/Open-Orca/OpenOrca","creator_name":"OpenOrca","creator_url":"https://huggingface.co/Open-Orca","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"customer_service_information_extraction","keyword":"feature-extraction","description":"jonathansuru/customer_service_information_extraction dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jonathansuru/customer_service_information_extraction","creator_name":"Jonathan Suru","creator_url":"https://huggingface.co/jonathansuru","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"STimage-1K4M","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tSTimage-1K4M Dataset\n\t\n\nWelcome to the STimage-1K4M Dataset repository. This dataset is designed to foster research in the field of spatial transcriptomics, combining high-resolution histopathology images with detailed gene expression data. \n\n\n\t\n\t\t\n\t\tUpdate\n\t\n\nFeb 12, 2025\nWe corrected a typo in meta file (changed \"Human_Brain+Kidney_10X_02212023_Visium\" to \"Mouse_Brain+Kidney_10X_02212023_Visium\"). Please refer to meta_all_gene02122025.csv for the newest meta data.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jiawennnn/STimage-1K4M.","url":"https://huggingface.co/datasets/jiawennnn/STimage-1K4M","creator_name":"jiawen chen","creator_url":"https://huggingface.co/jiawennnn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-segmentation","image-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"extreme-floods-kg","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“– Dataset Summary\n\t\n\nFloods are among the most frequent and devastating disasters worldwide, yet data describing them is often scattered across unstructured reports, geospatial sources, and satellite imagery.This dataset unifies those heterogeneous data sources into a structured, ontology-aligned Knowledge Graph (KG) format.  \nEach event is represented with:  \n\nMetadata: disaster type, location, date, country.  \nTextual Descriptions: humanitarian situation reports from ReliefWeb.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/teoaivalis/extreme-floods-kg.","url":"https://huggingface.co/datasets/teoaivalis/extreme-floods-kg","creator_name":"Theodoros Aivalis","creator_url":"https://huggingface.co/teoaivalis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","sentence-similarity","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PetraAI","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tPETRA\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nPETRA is a multilingual dataset for training and evaluating AI systems on a diverse range of tasks across multiple modalities. It contains data in Arabic and English for tasks including translation, summarization, question answering, and more.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nData is separated by language into /ar and /en directories\nWithin each language directory, data is separated by task into subdirectories  \nTasks include:\nTranslation\nSummarizationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PetraAI/PetraAI.","url":"https://huggingface.co/datasets/PetraAI/PetraAI","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entities-splade-ensembledistil-10K","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"dbpedia-entities-splade-10K\"\n\t\n\nThis dataset has both OpenAI and SPLADE vectors for 10,000 DBPedia entries. This adds SPLADE Vectors to KShivendu/dbpedia-entities-openai-1M/\nModel id used to make these vectors: \nmodel_id = \"naver/splade-cocondenser-ensembledistil\"\n\nThis is available on Huggingface. \nIf you'd like to extract the indices and weights/values from the vectors, you can do so using the following snippet:\nimport numpy as np\nvec = np.array(ds[0]['vec']) #â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nirantk/dbpedia-entities-splade-ensembledistil-10K.","url":"https://huggingface.co/datasets/nirantk/dbpedia-entities-splade-ensembledistil-10K","creator_name":"Nirant Kasliwal","creator_url":"https://huggingface.co/nirantk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Paper2Web","keyword":"feature-extraction","description":"https://huggingface.co/papers/2510.15842\n\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sourcesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancisChen1/Paper2Web.","url":"https://huggingface.co/datasets/FrancisChen1/Paper2Web","creator_name":"Yuhang Chen","creator_url":"https://huggingface.co/FrancisChen1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","10K - 100K","webdataset","Text"],"keywords_longer_than_N":true},
	{"name":"nordjylland-news-image-captioning","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"nordjylland-news-image-captioning\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of image-caption pairs from the Danish newspaper TV2 Nord. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nImage captioning is the intended task for this dataset. No leaderboard is active at this point.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is available in Danish (da).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nAn example from the dataset looks as follows.\n{\n  \"file_name\": \"1.jpg\",\n  \"caption\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nordjylland-news-image-captioning.","url":"https://huggingface.co/datasets/alexandrainst/nordjylland-news-image-captioning","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","zero-shot-image-classification","feature-extraction","image-captioning","Danish"],"keywords_longer_than_N":true},
	{"name":"philippine-budget-2025-embeddings-mpnet","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tPhilippine Budget 2025 - Vector Embeddings (all-mpnet-base-v2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains vector embeddings of the 2025 People's Budget of the Philippines, a citizen-friendly overview of the PHP 6.326 trillion national budget published by the Department of Budget and Management (DBM).\n\n\t\n\t\t\n\t\tSource Document\n\t\n\nThese embeddings are based on the 2025 People's Enacted Budget (English version, revised as of April 22, 2025).\nDirect Download Link: 2025 People'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-mpnet.","url":"https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-mpnet","creator_name":"The Pageman","creator_url":"https://huggingface.co/pageman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-chinese-subset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tlaion2B-multi-chinese-subset\n\t\n\n\nGithub: Fengshenbang-LM\nDocs: Fengshenbang-Docs\n\n\n\t\n\t\t\n\t\tç®€ä»‹ Brief Introduction\n\t\n\nå–è‡ªLaion2Bå¤šè¯­è¨€å¤šæ¨¡æ€æ•°æ®é›†ä¸­çš„ä¸­æ–‡éƒ¨åˆ†ï¼Œä¸€å…±143Mä¸ªå›¾æ–‡å¯¹ã€‚\nA subset from Laion2B (a multimodal dataset), around 143M image-text pairs (only Chinese).\n\n\t\n\t\t\n\t\tæ•°æ®é›†ä¿¡æ¯ Dataset Information\n\t\n\nå¤§çº¦ä¸€å…±143Mä¸ªä¸­æ–‡å›¾æ–‡å¯¹ã€‚å¤§çº¦å ç”¨19GBç©ºé—´ï¼ˆä»…ä»…æ˜¯urlç­‰æ–‡æœ¬ä¿¡æ¯ï¼Œä¸åŒ…å«å›¾ç‰‡ï¼‰ã€‚\n\nHomepage: laion-5b\nHuggingface: laion/laion2B-multi\n\n\n\t\n\t\t\n\t\tä¸‹è½½ Download\n\t\n\nmkdir laion2b_chinese_release && cd laion2b_chinese_release\nfor i in {00000..00012}; doâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset.","url":"https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"Test_Asosoft_WER","keyword":"feature-extraction","description":"WER evaluation asosoft test set with large v2 whisper model\n","url":"https://huggingface.co/datasets/abdulhade/Test_Asosoft_WER","creator_name":"abdulhady abas abdullah","creator_url":"https://huggingface.co/abdulhade","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Kurdish","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"idr0012-fuchs-cellmorph-S-BIAD845","keyword":"feature-extraction","description":"stefanches/idr0012-fuchs-cellmorph-S-BIAD845 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/stefanches/idr0012-fuchs-cellmorph-S-BIAD845","creator_name":"Stefan Dvoretskii","creator_url":"https://huggingface.co/stefanches","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","feature-extraction","cc0-1.0","n>1T","3D"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entities-openai3-text-embedding-3-large-3072-1M","keyword":"feature-extraction","description":"1M OpenAI Embeddings: text-embedding-3-large 3072 dimensions + ada-002 1536 dimensions â€” parallel dataset\n\nCreated: February 2024. \nText used for Embedding: title (string) + text (string)\nEmbedding Model: text-embedding-3-large\nThis dataset was generated from the first 1M entries of https://huggingface.co/datasets/BeIR/dbpedia-entity, extracted by @KShivendu_ here\n\n","url":"https://huggingface.co/datasets/Qdrant/dbpedia-entities-openai3-text-embedding-3-large-3072-1M","creator_name":"Qdrant","creator_url":"https://huggingface.co/Qdrant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"mmBERT-pretrain-p1-fineweb2-langs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tmmBERT Pre-training Data P1\n\t\n\n\n\n\n\n\nPhase 1 of 3: Diverse multilingual pre-training data mixture (trained for 2.3T tokens) used to train the mmBERT model suite.\n\nNOTE: this is only P1 of the pre-training data due to HF limits, you need to download and combine all three into one folderThis dataset contains the pre-training phase data used to train all mmBERT encoder models. The data is provided in MDS format ready for use with Composer and the ModernBERT training repository.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/mmBERT-pretrain-p1-fineweb2-langs.","url":"https://huggingface.co/datasets/jhu-clsp/mmBERT-pretrain-p1-fineweb2-langs","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","feature-extraction","multilingual","mit","arxiv:2509.06888"],"keywords_longer_than_N":true},
	{"name":"mmBERT-pretrain-p1-fineweb2-langs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tmmBERT Pre-training Data P1\n\t\n\n\n\n\n\n\nPhase 1 of 3: Diverse multilingual pre-training data mixture (trained for 2.3T tokens) used to train the mmBERT model suite.\n\nNOTE: this is only P1 of the pre-training data due to HF limits, you need to download and combine all three into one folderThis dataset contains the pre-training phase data used to train all mmBERT encoder models. The data is provided in MDS format ready for use with Composer and the ModernBERT training repository.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/mmBERT-pretrain-p1-fineweb2-langs.","url":"https://huggingface.co/datasets/jhu-clsp/mmBERT-pretrain-p1-fineweb2-langs","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","feature-extraction","multilingual","mit","arxiv:2509.06888"],"keywords_longer_than_N":true},
	{"name":"Facerec","keyword":"feature-extraction","description":"Hujaaj-32/Facerec dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Hujaaj-32/Facerec","creator_name":"Isiyaku Haji Isiyaku","creator_url":"https://huggingface.co/Hujaaj-32","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["text-to-image","feature-extraction","fill-mask","English","ms-pl"],"keywords_longer_than_N":true},
	{"name":"research_assist_2022_2023","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Research Publications (Alpaca Format)\n\t\n\nThis dataset card describes the structured data points encompassing research titles, summaries, and publication dates in the realm of artificial intelligence (AI), machine learning (ML), computer vision and pattern recognition, and neural and evolutionary computing. The data spans research published from early 2022 to October 2023.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides structured dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jackboi/research_assist_2022_2023.","url":"https://huggingface.co/datasets/jackboi/research_assist_2022_2023","creator_name":"Jack W","creator_url":"https://huggingface.co/jackboi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"invoices-donut-data-v1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Invoices (Sparrow)\n\t\n\nThis dataset contains 500 invoice documents annotated and processed to be ready for Donut ML model fine-tuning.\nAnnotation and data preparation task was done by Katana ML team.\nSparrow - open-source data extraction solution by Katana ML.\nOriginal dataset info: KozÅ‚owski, Marek; Weichbroth, PaweÅ‚ (2021), â€œSamples of electronic invoicesâ€, Mendeley Data, V2, doi: 10.17632/tnj49gpmtz.2\n","url":"https://huggingface.co/datasets/v2run/invoices-donut-data-v1","creator_name":"Varun","creator_url":"https://huggingface.co/v2run","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"infovqa_colqwen2_embeddings","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tInfoVQA ColQwen2.5 Embeddings\n\t\n\nThis dataset contains pre-computed embeddings for the InfoVQA dataset using the ColQwen2.5 model.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of three configurations:\n\n\t\n\t\t\n\t\tCorpus Configuration\n\t\n\nContains document images with their embeddings.\nfrom datasets import load_dataset\ncorpus = load_dataset(\"WenxingZhu/infovqa_colqwen2_embeddings\", \"corpus\", split=\"test\")\n\nFields:\n\ncorpus-id (int): Document identifier\nimage (Image): Original documentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WenxingZhu/infovqa_colqwen2_embeddings.","url":"https://huggingface.co/datasets/WenxingZhu/infovqa_colqwen2_embeddings","creator_name":"WenxingZhu","creator_url":"https://huggingface.co/WenxingZhu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"northwind_Shipping_orders","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNorthwind Shipping Orders and Related Documents\n\t\n\nThis dataset contains a collection of Shipping Orders and related documents from the Northwind database, a sample database used by Microsoft for demonstrating database functionalities.\nThe Shipping Orders include information about the ship name, Address , Region, postal code ,country, customer ,employee shipped date  product names, quantities, unit prices, and total prices. The related documents include shipping documents and stockâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AyoubChLin/northwind_Shipping_orders.","url":"https://huggingface.co/datasets/AyoubChLin/northwind_Shipping_orders","creator_name":"ayoub cherguelaine","creator_url":"https://huggingface.co/AyoubChLin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CLIP-Kinetics700","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for CLIP-Kinetics70\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCLIP-Kinetics700 is a compressed version of the Kinetics700 dataset using OpenAI's CLIP model.\nThe original dataset is ~700 GB making it difficult to use and hold in memory on one machine. By downsampling each video to 1 FPS and encoding the frames using CLIP we we're able to compress the dataset to ~8 GB making it very memory-friendly and easy to use.\n\n\t\n\t\t\n\t\tDataset Preprocessingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iejMac/CLIP-Kinetics700.","url":"https://huggingface.co/datasets/iejMac/CLIP-Kinetics700","creator_name":"Maciej Kilian","creator_url":"https://huggingface.co/iejMac","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","zero-shot-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Semantic-Segmentation-Aerial-Imagery-Dataset","keyword":"feature-extraction","description":"The dataset comprises aerial imagery of Dubai acquired by MBRSC satellites and annotated with pixel-level semantic segmentation across 6 distinct classes. The dataset comprises a total of 72 images, which are organised into 6 larger tiles. The categories are as follows:\nCredit: Humans in the Loop is releasing an openly accessible dataset that has been annotated for a collaborative project with the Mohammed Bin Rashid Space Centre in Dubai, United Arab Emirates.\nDeep Learning Projects for Finalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gymprathap/Semantic-Segmentation-Aerial-Imagery-Dataset.","url":"https://huggingface.co/datasets/gymprathap/Semantic-Segmentation-Aerial-Imagery-Dataset","creator_name":"Gym Prathap","creator_url":"https://huggingface.co/gymprathap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"SLM4CRP_with_RTs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSLM4CRP_with_RTs Dataset\n\t\n\n \n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe SLM4CRP_with_RTs dataset is a chemical reaction predictions (CRPs) dataset featuring reaction type (RT) labels, developed from the Mol-Instruction. We introduce a novel knowledge elicitation approach integrating a self-feedback mechanism with data curation using large language models (LLMs). This dataset embodies domain-specific knowledge by combining reactants and products of chemical reactions with annotated RTs, demonstratingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/liupf/SLM4CRP_with_RTs.","url":"https://huggingface.co/datasets/liupf/SLM4CRP_with_RTs","creator_name":"Pengfei Liu","creator_url":"https://huggingface.co/liupf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint1\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint1","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-1562024-to89-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-1562024-to89-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific research in medicine, biology, and technology\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1562024-to89-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-1562024-to89-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-1562024-to89-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific research in medicine, biology, and technology\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1562024-to89-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arayun_173","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tKey Contributions\n\t\n\n\nDefines ARAYUN_173 as an auditable system structure.  \nProvides reproducible methods for coherence validation in AI systems.  \nEstablishes a symbolic safeguard protocol to prevent cognitive drift.  \nContributes a framework for emergent AI self-regulation.\n\n\n\n\t\n\t\t\n\t\tDataset Content\n\t\n\n\nFormat: PDF  \nSize: <1k rows (documentation dataset)  \nLicense: CC-BY 4.0\n\nThis dataset hosts the original research document:â€œARAYUN_173 â€“ A Protocol for Coherence andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Arayun/arayun_173.","url":"https://huggingface.co/datasets/Arayun/arayun_173","creator_name":"L.","creator_url":"https://huggingface.co/Arayun","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","zero-shot-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal document search for Dutch legislation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal document search for Dutch legislation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"germanrag-scored","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from DiscoResearch/germanrag with added cosine-similarity scores.\nThe scores between 'question' and 'answer' have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\nIf you want to filter negative answersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/germanrag-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/germanrag-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"extract-0","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tExtract-0 Document Information Extraction Dataset\n\t\n\n\nThis dataset contains 280,128 synthetic training examples for document information extraction, used to train Extract-0, a specialized 7B parameter language model that outperforms GPT-4 and other larger models on extraction tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Extract-0 dataset represents a comprehensive collection of document extraction examples generated from diverse sources including arXiv papers, PubMed Central articlesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HenriqueGodoy/extract-0.","url":"https://huggingface.co/datasets/HenriqueGodoy/extract-0","creator_name":"Henrique Godoy","creator_url":"https://huggingface.co/HenriqueGodoy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"govdocs1-pdf-source","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tgovdocs1: source PDF files\n\t\n\n\n[!NOTE]\nConverted versions of other document types (word, txt, etc) are available in this repo\n\nThis is ~220,000 open-access PDF documents (about 6.6M pages) from the dataset govdocs1. It wants to be OCR'd.\n\nUploaded as tar file pieces of ~10 GiB each due to size/file count limits with an index.csv covering details\n5,000 randomly sampled PDFs are available unarchived in sample/. Hugging Face supports previewing these in-browser, for example this oneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/govdocs1-pdf-source.","url":"https://huggingface.co/datasets/BEE-spoke-data/govdocs1-pdf-source","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","image-feature-extraction","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-vbal-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-vbal-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-vbal-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-vbal-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-vbal-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-vbal-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"STAR","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFor detailed information, please see https://linlin-dev.github.io/project/STAR.html\n\t\n\n\n\t\n\t\t\n\t\tHow to Extract Split Archive Files on Ubuntu\n\t\n\nTo extract a split archive (e.g., STAR.7z.001, STAR.7z.002, etc.) on Ubuntu, follow these steps:\n\n\n\t\n\t\t\n\t\tStep 1: Install p7zip\n\t\n\nIf p7zip is not already installed, use the following commands to install it:\nsudo apt update\nsudo apt install p7zip-full\n\n\n\n\t\n\t\t\n\t\tStep 2: Verify Split Files Are in the Same Directory\n\t\n\nEnsure all split filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Zhuzi24/STAR.","url":"https://huggingface.co/datasets/Zhuzi24/STAR","creator_name":"wangtingzhu","creator_url":"https://huggingface.co/Zhuzi24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"keywording2","keyword":"image-feature-extraction","description":"umuth/keywording2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/umuth/keywording2","creator_name":"umut hasanoÄŸlu","creator_url":"https://huggingface.co/umuth","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"artf-categories-512x256","keyword":"feature-extraction","description":"Coco-formattedaRTF keypoints dataset train/val/test splits for T-shirts, Shorts and towels. See original repo for more details.\nThis dataset is not 'arrow-formatted'. HF simply serves as storage. Best to download the raw files instead of 'arrowed' version using following snippet:\n    huggingface_hub.snapshot_download(ARTF_RESIZED_CATEGORIES_HF_URL,repo_type=\"dataset\",local_dir=ARTF_CATEGORIES_DATASETS_DIR)\n\n","url":"https://huggingface.co/datasets/tlpss/artf-categories-512x256","creator_name":"Thomas Lips","creator_url":"https://huggingface.co/tlpss","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Devi_Bhagavatam","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for srimad_devi_bhagavata_mahapurana\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a complete, structured representation of the ÅšrÄ«mad DevÄ«-bhÄgavatam mahÄpurÄá¹‡e in CSV format, broken down into Skandas, AdhyÄyas, and individual Å›lokas. It is designed for NLP applicationsâ€”including feature extraction, classification, translation, summarization, question-answering, and generationâ€”on classical Sanskrit scripture.\n\nCurated by: Aluminiumâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/snskrt/Devi_Bhagavatam.","url":"https://huggingface.co/datasets/snskrt/Devi_Bhagavatam","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","token-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"virginia-woolf-monologue-chunks","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tVirginia Woolf Monologue Chunks Dataset\n\t\n\nThis dataset contains 6 semantically chunked text segments derived from a contemporary monologue based on Virginia Woolf's seminal essay \"A Room of One's Own\" (1929). It comes pre-loaded with vector embeddings from three different models, making it a ready-to-use resource for a variety of NLP tasks.\nIn addition to the dataset itself, this repository includes a comprehensive embedding analysis, detailed statistics, and 7 visualizations to helpâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pageman/virginia-woolf-monologue-chunks.","url":"https://huggingface.co/datasets/pageman/virginia-woolf-monologue-chunks","creator_name":"The Pageman at Bettergov.ph","creator_url":"https://huggingface.co/pageman","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","text-retrieval","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-953989","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-953989 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-953989 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-953989.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-953989","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-953989","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-953989 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-953989 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-953989.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-953989","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tekno21-brain-stroke-dataset-multi","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for BTX24/tekno21-brain-stroke-dataset-multi\n\t\n\n\n\t\n\t\t\n\t\tðŸ”— Dataset Sources\n\t\n\n\nDataset Source: TEKNOFEST-2021 Stroke Dataset\nKaggle: Ä°nme Veri Seti (Stroke Dataset)\nSaÄŸlÄ±k BakanlÄ±ÄŸÄ± AÃ§Ä±k Veri PortalÄ±: Ä°nme Veri Seti\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: PNG\nTotal Images: 7,369\nCategories:\nhemorajik/ (Hemorrhagic stroke images)\niskemik/ (Ischemic stroke images)\nnormal/ (Non-stroke images)\n\n\nThe dataset is structured in a folder-based format where images are grouped intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BTX24/tekno21-brain-stroke-dataset-multi.","url":"https://huggingface.co/datasets/BTX24/tekno21-brain-stroke-dataset-multi","creator_name":"BORAN TOKTAY","creator_url":"https://huggingface.co/BTX24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","image-to-text","image-feature-extraction","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"stackoverflow","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code snippet search for developers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code snippet search for developers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tekno21-brain-stroke-dataset-multi","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for BTX24/tekno21-brain-stroke-dataset-multi\n\t\n\n\n\t\n\t\t\n\t\tðŸ”— Dataset Sources\n\t\n\n\nDataset Source: TEKNOFEST-2021 Stroke Dataset\nKaggle: Ä°nme Veri Seti (Stroke Dataset)\nSaÄŸlÄ±k BakanlÄ±ÄŸÄ± AÃ§Ä±k Veri PortalÄ±: Ä°nme Veri Seti\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: PNG\nTotal Images: 7,369\nCategories:\nhemorajik/ (Hemorrhagic stroke images)\niskemik/ (Ischemic stroke images)\nnormal/ (Non-stroke images)\n\n\nThe dataset is structured in a folder-based format where images are grouped intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BTX24/tekno21-brain-stroke-dataset-multi.","url":"https://huggingface.co/datasets/BTX24/tekno21-brain-stroke-dataset-multi","creator_name":"BORAN TOKTAY","creator_url":"https://huggingface.co/BTX24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","image-to-text","image-feature-extraction","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"GPT-OSS-20B-MoE-expert-activations","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tGPT-OSS-20B MoE Expert Activations\n\t\n\nThis dataset contains router activation patterns and expert selection data from OpenAI's GPT-OSS-20B mixture-of-experts model during text generation across diverse evaluation benchmarks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nGPT-OSS-20B is OpenAI's open-weight mixture-of-experts language model with 21B total parameters and 3.6B active parameters per token. This dataset captures the internal routing decisions made by the model's router networks whenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/GPT-OSS-20B-MoE-expert-activations.","url":"https://huggingface.co/datasets/AmanPriyanshu/GPT-OSS-20B-MoE-expert-activations","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","apache-2.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"boletin-oficial-argentina-questions","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBORA y preguntas contextualmente relevantes\n\t\n\nEste dataset contiene textos de hasta 2000 caracteres extraÃ­dos del BoletÃ­n Oficial de la RepÃºblica Argentina, junto a preguntas sintetizadas relevantes para el contexto previsto.\nEste dataset es posible gracias a la colaboraciÃ³n entre SandboxAI e IdeaLab/CITECCA, de la Universidad Nacional de Rio Negro\n\n\t\n\t\t\n\t\n\t\n\t\tPara quÃ©?\n\t\n\nEl objetivo de este dataset es el entrenamiento de un modelo de embeddings en el Ã¡mbito legal argentino.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/marianbasti/boletin-oficial-argentina-questions.","url":"https://huggingface.co/datasets/marianbasti/boletin-oficial-argentina-questions","creator_name":"Marian Basti","creator_url":"https://huggingface.co/marianbasti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Spanish","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"ru-WANLI","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tRuWANLI\n\t\n\nRuWaNLI (Russian-Worker-AI Collaboration for NLI) is a natural language inference dataset inspired by Liu et al. (2022).\nWe replicated the WaNLI generation pipeline, but for Russian with some changes in labeling process.\nSee Dataset Structure for details about the dataset itself and Dataset Creation for details about the collection process.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nThe dataset can be used to train natural language inference models which determineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepvk/ru-WANLI.","url":"https://huggingface.co/datasets/deepvk/ru-WANLI","creator_name":"deep vk","creator_url":"https://huggingface.co/deepvk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Russian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-792024-tyen-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Financial risk analysis in credit analysis and investment banking\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-792024-tyen-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Financial risk analysis in credit analysis and investment banking\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TheGuardian-Articles","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\nThe dataset was curated to facilitate research and development in natural language processing tasks such as text classification and information extraction from news articles.\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\t\n\t\t\n\t\tInitial Data Collection and Normalization\n\t\n\nArticles and similar content were scraped from theguardian.com website.\n\n\t\n\t\t\n\t\tEncoding\n\t\n\nThe primary language of the dataset is English, but it may contain content in other languages. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Stefan171/TheGuardian-Articles.","url":"https://huggingface.co/datasets/Stefan171/TheGuardian-Articles","creator_name":"Stefan Carter","creator_url":"https://huggingface.co/Stefan171","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"genius","keyword":"feature-extraction","description":"\n    GENIUS\n    \n\nGenius, originally known as Rap Genius, was created as a platform for annotating rap music lyrics. Over time, the website expanded to cover a broader range of music genres, becoming a comprehensive resource for lyrics across many well-known artists.\n\nGiven the vast collection of lyrics available on the Genius platform, we are making the full dataset, consisting of over 8,885,602 lyrics, publicly accessible. This dataset serves as a valuable resource for the development ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/genius.","url":"https://huggingface.co/datasets/sleeping-ai/genius","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","1M - 10M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"fcube","keyword":"feature-extraction","description":"Nechba/fcube dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Nechba/fcube","creator_name":"nechba mohammed","creator_url":"https://huggingface.co/Nechba","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"qa-from-abstract-graphene","keyword":"feature-extraction","description":"Shinapri/qa-from-abstract-graphene dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Shinapri/qa-from-abstract-graphene","creator_name":"Shinapri Delucania","creator_url":"https://huggingface.co/Shinapri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","summarization","feature-extraction","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a collection of astronomical text data gathered from various sources, used to train a large natural language model for astronomy. \nThe data is jsonline format:\n{\n    id: \"uniqe identifier\",\n    source: \"the source of data, like wiki, BBC, etc.\",\n    meta: \"some meta information, like title, etc.\",\n    text: \"the content for model training\"\n}\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: ZheJiang Labâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shichenhui/test.","url":"https://huggingface.co/datasets/shichenhui/test","creator_name":"shichenhui","creator_url":"https://huggingface.co/shichenhui","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Chinese","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"chemical-documents","keyword":"image-feature-extraction","description":"The dataset consists of CC-BY-4.0 licensed open access papers and the annotations on-top are provided under the same license. Train, test and validation splits are provided as separate folders containing the image files and a single json file containing the annotations in COCO format.\nThe classes are close to the TFT-ID dataset and extend into 3 chemistry specific labels. chem_reaction contains everything with reaction arrows, chem_structures are structural formulas without reactions andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ElstnerAnalytics/chemical-documents.","url":"https://huggingface.co/datasets/ElstnerAnalytics/chemical-documents","creator_name":"Elstner Analytics GmbH","creator_url":"https://huggingface.co/ElstnerAnalytics","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-feature-extraction","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"CropClimateX","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tCropClimateX\n\t\n\n\nRepository: TBA\nPaper: TBA\n\n\nThe database includes 15,500 small data cubes (i.e., minicubes), each with a spatial coverage of 12x12km, spanning 1527 counties in the US. The minicubes comprise data from multiple sensors (Sentinel-2, Landsat-8, MODIS), weather and extreme events (Daymet, heat/cold waves, and U.S. drought monitor maps), as well as soil and terrain features, making it suitable for various agricultural monitoring tasks. It integrates crop- andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/torchgeo/CropClimateX.","url":"https://huggingface.co/datasets/torchgeo/CropClimateX","creator_name":"TorchGeo","creator_url":"https://huggingface.co/torchgeo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["time-series-forecasting","tabular-regression","tabular-classification","image-feature-extraction","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"hermes-function-calling-v1-jsonl","keyword":"feature-extraction","description":"\n\n\t\n\t\t\n\t\tHermes Function-Calling V1\n\t\n\nThis dataset is the compilation of structured output and function calling data used in the Hermes 2 Pro series of models.\nThis repository contains a structured output dataset with function-calling conversations, json-mode, agentic json-mode and structured extraction samples, designed to train LLM models in performing function calls and returning structured output based on natural language instructions. The dataset features various conversational scenariosâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/minpeter/hermes-function-calling-v1-jsonl.","url":"https://huggingface.co/datasets/minpeter/hermes-function-calling-v1-jsonl","creator_name":"minpeter","creator_url":"https://huggingface.co/minpeter","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"IndLands","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tIndLands Dataset\n\t\n\nThis dataset contains landslide data considering events from four Indian states: Himachal Pradesh, Mizoram, Sikkim, and Uttarakhand as our study region\n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach state contains multiple event folders. Every event folder includes:\n\npre_event_features.csv: Features captured before the landslide event.\npost_event_features.csv: Features captured after the landslide event.\nfeature_list.csv: The list of features used for the event.\nevent_metadata.txt:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DataUploader/IndLands.","url":"https://huggingface.co/datasets/DataUploader/IndLands","creator_name":"Anonymous Data uploader","creator_url":"https://huggingface.co/DataUploader","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","cc-by-4.0","1M<n<10M","Geospatial","Text"],"keywords_longer_than_N":true},
	{"name":"M3DRS","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tM3DRS: Multi-Modal Multi-Resolution Remote Sensing Dataset\n\t\n\nThis repository hosts the M3DRS dataset, a comprehensive collection of 5-channel remote sensing images (RGB, NIR, nDSM) from Switzerland, France, and Italy. The dataset is unlabelled and specifically designed to support self-supervised learning tasks. It is part of our submission to the NeurIPS 2025 Datasets and Benchmarks Track. The dataset is organized into three folders, each containing ZIP archives of images grouped byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/heig-vd-geo/M3DRS.","url":"https://huggingface.co/datasets/heig-vd-geo/M3DRS","creator_name":"HEIG-Vd Geomatic","creator_url":"https://huggingface.co/heig-vd-geo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","100B<n<1T","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DES-Reasoning-DeepSeek-V3.1","keyword":"feature-extraction","description":"Click here to support our open-source dataset and model releases!\nDES-Reasoning-DeepSeek-V3.1 is a dataset focused on analysis and reasoning, creating discrete event simulations testing the limits of DeepSeek V3.1's simulation, Python scripting, and analysis skills!\nThis dataset contains:\n\n4.03k synthetically generated prompts to create discrete event simulations and analysis chat in response to user input, with all responses generated using DeepSeek V3.1.\nAll responses contain a multi-stepâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/DES-Reasoning-DeepSeek-V3.1.","url":"https://huggingface.co/datasets/sequelbox/DES-Reasoning-DeepSeek-V3.1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"gothenburg-price-tag","keyword":"image-feature-extraction","description":"fangsonglong/gothenburg-price-tag dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fangsonglong/gothenburg-price-tag","creator_name":"Fangsong Long","creator_url":"https://huggingface.co/fangsonglong","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-feature-extraction","Swedish","unlicense","< 1K"],"keywords_longer_than_N":true},
	{"name":"Open-Orca","keyword":"feature-extraction","description":"ðŸ‹ The OpenOrca Dataset! ðŸ‹\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tOfficial Models\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tMistral-7B-OpenOrca\n\t\n\nOur latest model, the first 7B to score better overall than allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Triangle104/Open-Orca.","url":"https://huggingface.co/datasets/Triangle104/Open-Orca","creator_name":"Lymeman","creator_url":"https://huggingface.co/Triangle104","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"companies-2023-q4-sm","keyword":"feature-extraction","description":"This collection of data includes over seventeen million global companies. The dataset has information such as a company's name, website domain, size, year founded, industry, city/state, country and the handle of their LinkedIn URL.\nSchema, data stats, general documentation, and other datasets can be found at: https://docs.bigpicture.io/docs/free-datasets/companies/\n\n\t\n\t\t\n\t\tUpdate:\n\t\n\nFollowing SavvyIQ's acquisition of BigPicture technology, our team is now building next-generation businessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bigpictureio/companies-2023-q4-sm.","url":"https://huggingface.co/datasets/bigpictureio/companies-2023-q4-sm","creator_name":"BigPicture","creator_url":"https://huggingface.co/bigpictureio","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","odc-by","10M - 100M","csv"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-64-24-gpt-4o-2024-05-13","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-64-24-gpt-4o-2024-05-13 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical knowledge sharing platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-64-24-gpt-4o-2024-05-13 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-13.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-13","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-64-24-gpt-4o-2024-05-13","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-64-24-gpt-4o-2024-05-13 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical knowledge sharing platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-64-24-gpt-4o-2024-05-13 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-13.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-13","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"PD12M-ru","keyword":"image-feature-extraction","description":"Translated captions from Spawning/PD12M into Russian using Google Translate.\n","url":"https://huggingface.co/datasets/d0rj/PD12M-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-to-text","text-to-image","translated","Spawning/PD12M"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-13052024-ch9n-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-13052024-ch9n-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal content search for data protection regulations\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-13052024-ch9n-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-ch9n-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-ch9n-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-13052024-ch9n-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-13052024-ch9n-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal content search for data protection regulations\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-13052024-ch9n-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-ch9n-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-ch9n-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"winwin_product_data","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\twinwin å›¾åƒè¯†åˆ« æ•°æ®é›†è¯´æ˜Ž\n\t\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†æè¿°\n\t\n\n\næˆ‘ä»¬çš„winwin-productsæ•°æ®é›†ä¸­çš„æ‰€æœ‰å›¾ç‰‡å‡æ¥è‡ªçº¿ä¸‹å®žä½“å•†å“ä½¿ç”¨ä¸“é—¨çš„é‡‡é›†è£…ç½®,é‡‡é›†çš„é«˜æ¸…çš„å•†å“360åº¦å›¾ç‰‡, å•†å“çš„å„ä¸ªæ–¹å‘çš„å›¾ç‰‡å‡æœ‰.ç»è¿‡åŽ»é‡å¤„ç†ä¹‹åŽ, ç›®å‰æ•°æ®é›†åŒ…å«3553ä¸ªSKU, æ€»å…±è¿‘4ä¸‡å¤šå¼ å›¾ç‰‡, ç›®å‰ä¸»è¦æ¶µç›–çš„ç±»ç›®æ˜¯é¥®æ–™, ä¹³åˆ¶å“, è€ƒè™‘åˆ°å®žé™…åº”ç”¨åœºæ™¯, å›¾ç‰‡çš„æ•°é‡åˆ†å¸ƒå¹¶ä¸å‡è¡¡, ä¸”æ‰€æœ‰å›¾ç‰‡å‡ç”±é©¬ä¸Šèµ¢æ•°æ®ä¸“å®¶å›¢é˜Ÿæ‰‹åŠ¨æ£€æŸ¥/æ ‡æ³¨.\n\n\n\t\n\t\t\n\t\tæ”¯æŒçš„ä»»åŠ¡\n\t\n\n\næ”¯æŒå›¾åƒç‰¹å¾çš„æå–, é…åˆå‘é‡åº“è¿›è¡Œå›¾ç‰‡æ¯”å¯¹è®¡ç®—, æ¥è¿›è¡Œå›¾åƒçš„æ£€ç´¢ä»»åŠ¡.\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ ¼å¼è¯´æ˜Ž\n\t\n\n\nä¸»è¦ç”¨äºŽå›¾åƒæ£€ç´¢ä»»åŠ¡, æ•°æ®é›†ä¸»è¦åˆ†ä»¥ä¸‹ä¸‰éƒ¨åˆ†\n\nè®­ç»ƒæ•°æ®é›†(train): ç”¨æ¥è®­ç»ƒæ¨¡åž‹, ä½¿æ¨¡åž‹èƒ½å¤Ÿå­¦ä¹ è¯¥é›†åˆçš„å›¾åƒç‰¹å¾\n\nåº•åº“æ•°æ®é›†(gallery): ç”¨æ¥æä¾›å›¾åƒæ£€ç´¢ä»»åŠ¡ä¸­çš„åº•åº“æ•°æ®, è¯¥é›†åˆå¯ä»¥å’Œè®­ç»ƒæ•°æ®é›†ç›¸åŒ, ä¹Ÿå¯ä»¥ä¸åŒ\n\næµ‹è¯•æ•°æ®é›†(query):ç”¨æ¥æµ‹è¯•æ¨¡åž‹çš„å¥½åâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/junzai/winwin_product_data.","url":"https://huggingface.co/datasets/junzai/winwin_product_data","creator_name":"houxiaojun","creator_url":"https://huggingface.co/junzai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Chinese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"emonet-face-binary","keyword":"image-feature-extraction","description":"t1a5anu-anon/emonet-face-binary dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/t1a5anu-anon/emonet-face-binary","creator_name":"t1a5anu-anon","creator_url":"https://huggingface.co/t1a5anu-anon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DOOMGAN-Ocular-Morphs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDOOMGAN: Ocular Morph Dataset\n\t\n\nThis repository contains the official public dataset for the paper: \"DOOMGAN: High-Fidelity Dynamic Identity Obfuscation Ocular Generative Morphing\" funded by the NSF award no. 2345561. \nThe dataset consists of 10,000 high-fidelity morphed ocular images generated by the DOOMGAN model. These images are intended to facilitate research and development of Morph Attack Detection (MAD) systems for visible-spectrum ocular biometrics.\n\nPaper: IJCB 2025 DOOMGANâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BharathK333/DOOMGAN-Ocular-Morphs.","url":"https://huggingface.co/datasets/BharathK333/DOOMGAN-Ocular-Morphs","creator_name":"Bharath Krishnamurthy","creator_url":"https://huggingface.co/BharathK333","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","10K - 100K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Boning-Slicing","keyword":"feature-extraction","description":"BinKhoaLe1812/Boning-Slicing dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/BinKhoaLe1812/Boning-Slicing","creator_name":"LÃª ÄÄƒng Khoa (Liam)","creator_url":"https://huggingface.co/BinKhoaLe1812","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"jina-embeddings-v2-base-en-19052024-oiu8-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-19052024-oiu8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"E-commerce advertising platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-19052024-oiu8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-19052024-oiu8-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-19052024-oiu8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-19052024-oiu8-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-19052024-oiu8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"E-commerce advertising platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-19052024-oiu8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-19052024-oiu8-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-19052024-oiu8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"US-1M","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nUS-1M establishes a new benchmark in medical imaging research, comprising 1.28 million rigorously annotated ultrasound images with precise anatomical structure delineations and comprehensive \ndemographic metadata\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n","url":"https://huggingface.co/datasets/wyh1128/US-1M","creator_name":"wyh","creator_url":"https://huggingface.co/wyh1128","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"GoDatas","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Go Game Dataset for Neural Network Training\n\t\n\nThis is a high-quality dataset designed for Go neural network training, containing board positions extracted from curated SGF game records. The dataset is divided into three strength categories: Standard, Strong, and Elite, with approximately 1,000 samples per category.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Go board positions and corresponding moves extracted from high-quality SGFâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Karesis/GoDatas.","url":"https://huggingface.co/datasets/Karesis/GoDatas","creator_name":"æ¨äº¦é”‹","creator_url":"https://huggingface.co/Karesis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","feature-extraction","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"KAR4DDI","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe dataset in this study is a Drug-Drug Interaction Event (DDIE) dataset obtained from DeepDDI 2. It includes detailed information on 2,386 drugs, each represented by a 50-dimensional Principal Components Analysis (PCA) feature vector, and the corresponding SMILES strings. Additionally, drug descriptions from DDInter and DrugBank have been integrated into the dataset.\nThe DDIE dataset comprises 222,127 drug pairs, enabling the prediction of 113 different DDIE types.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/liupf/KAR4DDI.","url":"https://huggingface.co/datasets/liupf/KAR4DDI","creator_name":"Pengfei Liu","creator_url":"https://huggingface.co/liupf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","mit","100K<n<1M","Text"],"keywords_longer_than_N":true},
	{"name":"csszengarden","keyword":"feature-extraction","description":"Technologic101/csszengarden dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Technologic101/csszengarden","creator_name":"Anthony Chapman","creator_url":"https://huggingface.co/Technologic101","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"TxT360-500k-sample-no_cc","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/TxT360-500k-sample-no_cc\n\t\n\nno common crawl\n","url":"https://huggingface.co/datasets/BEE-spoke-data/TxT360-500k-sample-no_cc","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"bioinf595-L04","keyword":"feature-extraction","description":"marissadolorfino/bioinf595-L04 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/marissadolorfino/bioinf595-L04","creator_name":"Marissa Dolorfino","creator_url":"https://huggingface.co/marissadolorfino","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","feature-extraction","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5202024-rxyq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5202024-rxyq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"gaming information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5202024-rxyq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-rxyq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-rxyq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5202024-rxyq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5202024-rxyq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"gaming information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5202024-rxyq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-rxyq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-rxyq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Mycollection","keyword":"feature-extraction","description":"JMaeen25/Mycollection dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/JMaeen25/Mycollection","creator_name":"Jordan K. Maeen","creator_url":"https://huggingface.co/JMaeen25","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["table-question-answering","text-classification","token-classification","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MLDSUM_NEW","keyword":"feature-extraction","description":"sandylolpotty/MLDSUM_NEW dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sandylolpotty/MLDSUM_NEW","creator_name":"sandeep","creator_url":"https://huggingface.co/sandylolpotty","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"StreetView360AtoZ","keyword":"image-feature-extraction","description":"StreetView 360X is a dataset containing 6342 360 degree equirectangular street view images randomly sampled and downloaded from Google Street View. It is published as part of the paper \"StreetView360X: A Location-Conditioned Latent Diffusion Model for Generating Equirectangular 360 Degree Street Views\" (Princeton COS Senior Independent Work by Everett Shen). Images are labelled with their capture coordinates and panorama IDs. Scripts for extending the dataset (i.e. fetching additional images)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/everettshen/StreetView360AtoZ.","url":"https://huggingface.co/datasets/everettshen/StreetView360AtoZ","creator_name":"Everett Shen","creator_url":"https://huggingface.co/everettshen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-classification","image-to-text","image-feature-extraction","mit"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical advice and treatment search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical advice and treatment search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TxT360-5M-sample-en","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/TxT360-5M-sample-en\n\t\n\nenglish only sample from LLM360/TxT360:\n\nmin length 256 GPT-4 tokens\nmax length 24576 GPT-4 tokens\n\nGPT-4 tiktoken token count:\n        token_count\ncount  5.000000e+06\nmean   1.003614e+03\nstd    1.424231e+03\nmin    2.570000e+02\n25%    4.020000e+02\n50%    6.220000e+02\n75%    1.050000e+03\nmax    2.457400e+04\n\n\nTotal count:\t5018.07 M tokens\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/TxT360-5M-sample-en","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","odc-by","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-06052024-yl1z-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-06052024-yl1z-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"social behavior advice search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-06052024-yl1z-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-yl1z-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-yl1z-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-06052024-yl1z-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-06052024-yl1z-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"social behavior advice search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-06052024-yl1z-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-yl1z-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-yl1z-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"mmarco-de-distilled-scored","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is a distilled (reduced) \"german only\" dataset (train split only) version still in original order from unicamp-dl/mmarco with added cosine-similarity scores. The full source of mmarco by unicamp is hosted in the repository on GitHub.\nThe scores between 'query' and 'text' have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer correspondsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/mmarco-de-distilled-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/mmarco-de-distilled-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"HueManity","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tHueManity: A Benchmark for Testing Human-Like Visual Perception in MLLMs\n\t\n\nPaper | Code\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHueManity is a benchmark dataset featuring 83,850 images designed to test the fine-grained visual perception of Multimodal Large Language Models (MLLMs). Each image presents a two-character alphanumeric string embedded within Ishihara-style dot patterns, challenging models to perform precise pattern recognition in visually cluttered environments.\nThe dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jayant-Sravan/HueManity.","url":"https://huggingface.co/datasets/Jayant-Sravan/HueManity","creator_name":"Jayant Sravan Tamarapalli","creator_url":"https://huggingface.co/Jayant-Sravan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","image-to-text","image-feature-extraction","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-421451","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-421451 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-421451 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-421451.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-421451","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-421451","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-421451 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-421451 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-421451.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-421451","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RedHat-security-VeX","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for RedHat-security-VeX\n\t\n\nThis Dataset is extracted from publicly available Vulnerability Exploitability eXchange (VEX) files published by Red Hat.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nRed Hat security data is a central source of truth for Red Hat products regarding published, known vulnerabilities.\nThis data is published in form of Vulnerability Exploitability eXchange (VEX) available at: \nhttps://security.access.redhat.com/data/csaf/v2/vex/\nThis Dataset is created by extractingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huzaifas-sidhpurwala/RedHat-security-VeX.","url":"https://huggingface.co/datasets/huzaifas-sidhpurwala/RedHat-security-VeX","creator_name":"Huzaifa Sidhpurwala","creator_url":"https://huggingface.co/huzaifas-sidhpurwala","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-generation","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"AI-Belha","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for AI-Belha\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAI-Belha is a dataset comprising audio recordings from beehives, collected to determine the presence and status of the queen bee. The dataset includes 86 mono WAV files, each approximately 60 seconds long and sampled at 16 kHz, totaling about 1 hour and 26 minutes of audio. Each recording is annotated with beekeeper observations and model predictions regarding the queen bee's status.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NOSInovacao/AI-Belha.","url":"https://huggingface.co/datasets/NOSInovacao/AI-Belha","creator_name":"NOS InovaÃ§Ã£o, SA","creator_url":"https://huggingface.co/NOSInovacao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","audio-classification","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"alpaca_ccass_motivations_sommaires_titres","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTraining dataset for summarizing and titling decisions of the French Court of cassation based on motivations\n\t\n\nThis alpaca-format dataset is designed to train models for summarizing and titling French Supreme Court decisions based on the grounds of them. Created with a view to producing metadata for decisions not published in the bulletin, this dataset aims to simplify the development of annotation and categorization tools, and is positioned as a facilitator for jurisprudentialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maurya/alpaca_ccass_motivations_sommaires_titres.","url":"https://huggingface.co/datasets/maurya/alpaca_ccass_motivations_sommaires_titres","creator_name":"Amaury Fouret","creator_url":"https://huggingface.co/maurya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","feature-extraction","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"emojis","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Emojis\n\t\n\n\n\n\n\n\n\nThis is a FiftyOne dataset with 1816 samples.\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nimport fiftyone.utils.huggingface as fouh\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = fouh.load_from_hub(\"jamarks/emojis\")\n\n# Launch the App\nsession = fo.launch_app(dataset)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jamarks/emojis.","url":"https://huggingface.co/datasets/jamarks/emojis","creator_name":"Jacob Marks","creator_url":"https://huggingface.co/jamarks","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","English","cc-by-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Tupac-hit-em-up-comments","keyword":"feature-extraction","description":"\n  \n\n\n\nHit 'Em Up by 2Pac (Tupac Shakur) stands as one of the most influential and iconic diss tracks in the history of rap. Written and performed by the legendary Tupac Shakur, the song embodies his raw, unfiltered artistry and fearless commentary. Known not only as a rapper but as a poet, Tupac consistently tackled social issues, justice, and the realities of life through his music. His unparalleled lyrical genius has inspired generations of artists, including Eminem, Kendrick Lamar, and J.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/Tupac-hit-em-up-comments.","url":"https://huggingface.co/datasets/sleeping-ai/Tupac-hit-em-up-comments","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Decoy_DB","keyword":"feature-extraction","description":"ðŸ”§Code, ðŸ“‚Dataset\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDecoyDB is a curated dataset of high-resolution protein-ligand complexes and their associated decoy structures. It is designed to support research on graph contrastive learning, binding affinity prediction, and structure-based drug discovery. The dataset is derived from experimentally resolved complexes and refined to ensure data quality.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach protein-ligand complex is stored in a nested directory under DecoyDB/, using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YupuZ/Decoy_DB.","url":"https://huggingface.co/datasets/YupuZ/Decoy_DB","creator_name":"Yupu Zhang","creator_url":"https://huggingface.co/YupuZ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"ClevelandMuseumArt","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCleveland Museum of Art Open Access Dataset\n\t\n\nThis dataset contains the complete Cleveland Museum of Art Open Access collection data, originally sourced from the ClevelandMuseumArt/openaccess GitHub repository and reuploaded for broader distribution, Parquet generation for high-performance analytics, and seamless integration with data science workflows.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Cleveland Museum of Art provides open access to information on more than 61,000 artworks inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ClevelandMuseumArt.","url":"https://huggingface.co/datasets/nyuuzyou/ClevelandMuseumArt","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","image-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"german-oasst1-qa-format-scored","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train and validation splits) in original order from AgentWaller/german-oasst1-qa-format with added cosine-similarity scores.\nThe scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy?\n\t\n\nTo build an experimentalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/german-oasst1-qa-format-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/german-oasst1-qa-format-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hico_det","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for HICO-DET Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHICO-DET is a dataset for detecting human-object interactions (HOI) in images. It contains 47,776 images (38,118 in train set and 9,658 in test set), 600 HOI categories constructed by 80 object categories and 117 verb classes. HICO-DET provides more than 150k annotated human-object pairs. V-COCO provides 10,346 images (2,533 for training, 2,867 for validating and 4,946 for testing) and 16,199 person instances. Each personâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhimeng/hico_det.","url":"https://huggingface.co/datasets/zhimeng/hico_det","creator_name":"Zhimeng Guo","creator_url":"https://huggingface.co/zhimeng","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","image-feature-extraction","image-to-text","English","mit"],"keywords_longer_than_N":true},
	{"name":"munich-public-services","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"Munich Public Services\"\n\t\n\nzur deutschen Dokumentation\n\nThis dataset contains information about the services provided to the public by the City of Munich in the form of written articles, corresponding metadata as well as embeddings.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe Munich Public Services dataset contains around 1.400 articles about various public services provided by the City of Munich.\nNext to the content of the articles, the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/it-at-m/munich-public-services.","url":"https://huggingface.co/datasets/it-at-m/munich-public-services","creator_name":"it@M","creator_url":"https://huggingface.co/it-at-m","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","German","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SciKnowEval","keyword":"feature-extraction","description":"\n\n   SciKnowEval \n Evaluating Multi-level Scientific Knowledge of Large Language Models \n\n\n\nPlease refer to our repository and paper for more details.\n\n\nåšå­¦ä¹‹ ï¼Œå®¡é—®ä¹‹ ï¼Œæ…Žæ€ä¹‹ ï¼Œæ˜Žè¾¨ä¹‹ ï¼Œç¬ƒè¡Œä¹‹ã€‚\nâ€”â€” ã€Šç¤¼è®° Â· ä¸­åº¸ã€‹ Doctrine of the Mean\n\n\n\n\n\n\nThe Scientific Knowledge Evaluation (SciKnowEval) benchmark for Large Language Models (LLMs) is inspired by the profound principles outlined in the â€œDoctrine of the Meanâ€ from ancient Chinese philosophy. This benchmark is designed to assess LLMs based on their proficiency inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hicai-zju/SciKnowEval.","url":"https://huggingface.co/datasets/hicai-zju/SciKnowEval","creator_name":"AI CrossX  Lab, HIC@Zhejiang University","creator_url":"https://huggingface.co/hicai-zju","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","text-classification","summarization","English"],"keywords_longer_than_N":true},
	{"name":"Synthetic_Banking_Data","keyword":"feature-extraction","description":"ChiragPatankar/Synthetic_Banking_Data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ChiragPatankar/Synthetic_Banking_Data","creator_name":"Chirag Shrikant Patankar","creator_url":"https://huggingface.co/ChiragPatankar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"housing-prices-malaysia-2025","keyword":"feature-extraction","description":"This dataset contains 2,000 entries of house price data from all states in Malaysia, providing a comprehensive overview of the countryâ€™s real estate market for 2025. Sourced from Brickz, a trusted platform for property transaction insights, it includes detailed information such as property location, tenure, type, median prices, and transaction counts. This dataset is ideal for real estate market analysis, predictive modeling, and exploring trends across Malaysiaâ€™s diverse property market.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jienweng/housing-prices-malaysia-2025.","url":"https://huggingface.co/datasets/jienweng/housing-prices-malaysia-2025","creator_name":"Lai JIen Weng","creator_url":"https://huggingface.co/jienweng","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","English","Malay","mit"],"keywords_longer_than_N":true},
	{"name":"brombeeren","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tBlackberry in Germany\n\t\n\nThis dataset contains images of blackberry plants from Germany.\n","url":"https://huggingface.co/datasets/fhswf/brombeeren","creator_name":"Fachhochschule SÃ¼dwestfalen","creator_url":"https://huggingface.co/fhswf","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","afl-3.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-572024-xg53-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-572024-xg53-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scripting language documentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-572024-xg53-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-572024-xg53-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-572024-xg53-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scripting language documentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-572024-xg53-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Non_Verbal_audio","keyword":"feature-extraction","description":"\nThe Nonverbal Vocalization Dataset, also known as the Vocal Characterizer, is a human nonverbal vocal sound dataset that was crowdsourced from the South Korean public and consists of 56.7 hours of brief clips from 1419 speakers. The dataset also contains metadata about sex, age, noise level, and speech quality. \"Teeth-chattering,\" \"teeth-grinding,\" \"tongue-clicking,\" \"coughing,\" \"yawning,\" \"throat clearing,\" \"sighing,\" \"lip-popping,\" \"lip-smacking,\" \"panting,\" \"crying,\" \"laughing,\" \"sneezingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wtfkedar/Non_Verbal_audio.","url":"https://huggingface.co/datasets/wtfkedar/Non_Verbal_audio","creator_name":"kedar","creator_url":"https://huggingface.co/wtfkedar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","zero-shot-classification","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Touche2020-256-24-gpt-4o-2024-05-13-27907","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTouche2020-256-24-gpt-4o-2024-05-13-27907 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the Touche2020-256-24-gpt-4o-2024-05-13-27907 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907.","url":"https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Touche2020-256-24-gpt-4o-2024-05-13-27907","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTouche2020-256-24-gpt-4o-2024-05-13-27907 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the Touche2020-256-24-gpt-4o-2024-05-13-27907 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907.","url":"https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Ara-TyDi-Triplet","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArabic Mr. TyDi in Triplet Format\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a transformed version of the Arabic subset of the Mr. TyDi dataset, designed specifically for training retrieval and re-ranking models. Each query is paired with a positive passage and one of the multiple negative passages in a triplet format: (query, positive, negative). This restructuring resulted in a total of 362,000 rows, making it ideal for pairwise ranking tasks and contrastive learning approaches.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Ara-TyDi-Triplet.","url":"https://huggingface.co/datasets/NAMAA-Space/Ara-TyDi-Triplet","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","feature-extraction","Arabic","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ChatML-OpenOrca","keyword":"feature-extraction","description":"Open-Orca/OpenOrca in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Minueza-32M-Base\")\n\ndataset = load_dataset(\"Open-Orca/OpenOrca\", split=\"train\")\n\ndef format(columns):\n    messages = []\n\n    system_prompt = columns[\"system_prompt\"].strip()\n\n    if system_prompt:\n        messages.append({\n            \"role\": \"system\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-OpenOrca.","url":"https://huggingface.co/datasets/Felladrin/ChatML-OpenOrca","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"1M-OpenOrca_be","keyword":"feature-extraction","description":"En/Be\nðŸ‹ The Belarusian OpenOrca Dataset! ðŸ‹\n\n\n\nBelarusian OpenOrca dataset - is rich collection of augmented FLAN data aligns, that translated in belarusian language.\nThat dataset should help training LLM in belarusian language and should help on other NLP tasks.\nThis dataset have 2 version:\n\n~1M GPT-4 completions (Now translating)\n~3.2M GPT-3.5 completions (Can be translated in future)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe fields are:\n\n'id', a unique numbered identifier which includes one of 'niv'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be.","url":"https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be","creator_name":"Artsem Holub","creator_url":"https://huggingface.co/WiNE-iNEFF","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Ordalie-FR-STS-benchmark","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOrdalie - French STS Benchmark\n\t\n\n\n30k sentence pairs\nScore either 0 or 1\n\n","url":"https://huggingface.co/datasets/OrdalieTech/Ordalie-FR-STS-benchmark","creator_name":"Ordalie Technologies","creator_url":"https://huggingface.co/OrdalieTech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","French","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-2062024-u43q-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tBAAI_bge-large-en-2062024-u43q-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-2062024-u43q-webapp model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-2062024-u43q-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-2062024-u43q-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-2062024-u43q-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tBAAI_bge-large-en-2062024-u43q-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-2062024-u43q-webapp model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-2062024-u43q-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-2062024-u43q-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"yourbench_archived","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸŒŸ YourBench Y1: A Diverse Domain Benchmark Dataset\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nYourBench Y1 is a carefully curated dataset of documents from 8 different domains, specifically designed to evaluate language models on content likely generated or produced after July 2024. This dataset provides a unique benchmark for testing model performance on contemporary content across diverse professional and technical domains.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nðŸ“Š 8 balanced domains with 5â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sumukshashidhar-archive/yourbench_archived.","url":"https://huggingface.co/datasets/sumukshashidhar-archive/yourbench_archived","creator_name":"Sumuk's Archived Content","creator_url":"https://huggingface.co/sumukshashidhar-archive","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Database schema for a data management system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Database schema for a data management system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-14062024-fimj-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-14062024-fimj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"psychometric assessment in academia\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-14062024-fimj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-fimj-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-fimj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-14062024-fimj-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-14062024-fimj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"psychometric assessment in academia\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-14062024-fimj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-fimj-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-fimj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Selfie_and_Official_ID_Photo_Dataset","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tSelfie & Official ID Photo Dataset (18k+ Images)\n\t\n\n\n\t\n\t\t\n\t\tFull version of the dataset is available for commercial usage. Leave a request on our website Axonlabs to purchase the dataset ðŸ’°\n\t\n\n\n\t\n\t\t\n\t\tFor feedback and additional sample requests, please contact us!\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Selfie & Official ID Photo Dataset contains over 18,000 images contributed by over 2,000 individuals. The dataset includes real-life selfies and official ID photos, making it ideal forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/Selfie_and_Official_ID_Photo_Dataset.","url":"https://huggingface.co/datasets/AxonData/Selfie_and_Official_ID_Photo_Dataset","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","video-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-526066","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-526066 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-526066 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-526066","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-526066 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-526066 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"bluesky-sentiment","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBluesky Sentiment Dataset Card\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nBluesky Sentiment contains posts from the agentlans/bluesky dataset, annotated for six emotions: \nhappiness, sadness, fear, disgust, anger, and surprise.\nAnnotations were generated automatically using ChatGPT, providing a nuanced, multidimensional sentiment analysis beyond simple positive/negative labels.\nThe dataset covers posts in multiple languages.\nThe few-shot config contains annotations by google/gemma-3-4b-it with 10-shotâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/bluesky-sentiment.","url":"https://huggingface.co/datasets/agentlans/bluesky-sentiment","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","English","multilingual"],"keywords_longer_than_N":true},
	{"name":"literary-dataset-pack","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLiterary Dataset Pack\n\t\n\nA rich and diverse multi-task instruction dataset generated from classic public domain literature.\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nLiterary Dataset Pack is a high-quality instruction-tuning dataset crafted from classic literary texts in the public domain (e.g., Alice in Wonderland). Each paragraph is transformed into multiple supervised tasks designed to train or fine-tune large language models (LLMs) across a wide range of natural language understanding and generationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/codeXpedite/literary-dataset-pack.","url":"https://huggingface.co/datasets/codeXpedite/literary-dataset-pack","creator_name":"CodeXpedite","creator_url":"https://huggingface.co/codeXpedite","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","question-answering","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"HUVER","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for HUVER\n\t\n\n\n\nThe dataset is comprised of a 6,051 unique UAV configurations, where each configuration is described by multiple data for-\nmats, including a grammar string, an RGB image, and an GLB file.\nComplementing these representation modalities, we also provide a configuration-based description, i.e., a text descriptor describing the features of each UAV using natural language\n\nCurated by: Abhiram Karri, Gary Stump, Christopher McComb, Binyang Song\n\nLanguage(s) (NLP):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/raiselab/HUVER.","url":"https://huggingface.co/datasets/raiselab/HUVER","creator_name":"RAISE Lab","creator_url":"https://huggingface.co/raiselab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-to-3d","image-feature-extraction","text-to-3d","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"MetaCognition-Preference","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMetaCognition Preference Dataset\n\t\n\nThe MetaCognition Preference Dataset is a structured dataset for analyzing and evaluating model reasoning through a cognitive decomposition lens. It is built on top of the NVIDIA HelpSteer2 dataset and extends it with annotations that reflect the meta-cognitive and tactical structure of language model outputs.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nEach sample in this dataset consists of:\n\nAn instruction or query.\nTwo model outputs (output_a, output_b) responding toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Death-Raider/MetaCognition-Preference.","url":"https://huggingface.co/datasets/Death-Raider/MetaCognition-Preference","creator_name":"Darsh Kachroo","creator_url":"https://huggingface.co/Death-Raider","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","reinforcement-learning","English","mit"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"HUVER","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for HUVER\n\t\n\n\n\nThe dataset is comprised of a 6,051 unique UAV configurations, where each configuration is described by multiple data for-\nmats, including a grammar string, an RGB image, and an GLB file.\nComplementing these representation modalities, we also provide a configuration-based description, i.e., a text descriptor describing the features of each UAV using natural language\n\nCurated by: Abhiram Karri, Gary Stump, Christopher McComb, Binyang Song\n\nLanguage(s) (NLP):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/raiselab/HUVER.","url":"https://huggingface.co/datasets/raiselab/HUVER","creator_name":"RAISE Lab","creator_url":"https://huggingface.co/raiselab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-to-3d","image-feature-extraction","text-to-3d","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-892024-idqb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"career development and matchmaking\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-892024-idqb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"career development and matchmaking\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-598568","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-598568 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-598568 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-598568.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-598568","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-598568","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-598568 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-598568 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-598568.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-598568","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"apt-eval","keyword":"feature-extraction","description":"\nðŸš¨ APT-Eval Dataset ðŸš¨\n\nAlmost AI, Almost Human: The Challenge of Detecting AI-Polished Writing \nðŸ“ Paper, ðŸ–¥ï¸ Github\n\n\nAPT-Eval is the first and largest dataset to evaluate the AI-text detectors behavior for AI-polished texts.\nIt contains almost 15K text samples, polished by 5 different LLMs, for 6 different domains, with 2 major polishing types. All of these samples initially came from purely human written texts.\nIt not only includes AI-polished texts, but also includes fine-grainedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/smksaha/apt-eval.","url":"https://huggingface.co/datasets/smksaha/apt-eval","creator_name":"Shoumik Saha","creator_url":"https://huggingface.co/smksaha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"X_Twitter_Trending_Topics_August2025","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ¦ X-Twitter Scraper: Real-Time Search and Data Extraction Tool\n\t\n\nSearch and scrape X-Twitter (formerly Twitter) for posts by keyword, account, or trending topics.This no-code tool makes it easy to generate real-time, LLM-ready datasets for any AI or content use case.\nGet started with real-time scraping and instantly structure tweet data into clean JSON.\nStart Scraping\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸš€ Key Features\n\t\n\n\nâš¡ Real-Time Fetch â€“ Stream the latest tweets the moment theyâ€™re posted  \nðŸŽ¯ Flexibleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/X_Twitter_Trending_Topics_August2025.","url":"https://huggingface.co/datasets/Gopher-Lab/X_Twitter_Trending_Topics_August2025","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"springer-sounds","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSpringer Sounds\n\t\n\nThis dataset is derived from the repository published by David Springer.\nIt comprises multiple phonocardiogram (PCG) signals, each sampled at a frequency of 1000 Hz.\nOriginally, the dataset was shared in MAT format to accompany the implementation of the article \"Logistic Regression-HSMM-based Heart Sound Segmentation\".\nThe current version represents a subset of the original data, focusing solely on the signal values and their corresponding pre-computed labels.\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alvgaona/springer-sounds.","url":"https://huggingface.co/datasets/alvgaona/springer-sounds","creator_name":"Alvaro Gaona","creator_url":"https://huggingface.co/alvgaona","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","webdataset"],"keywords_longer_than_N":true},
	{"name":"MI-Eval-Bench","keyword":"image-feature-extraction","description":"Pillowkoh/MI-Eval-Bench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Pillowkoh/MI-Eval-Bench","creator_name":"Koh Jun Hao","creator_url":"https://huggingface.co/Pillowkoh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-feature-extraction","English","apache-2.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"babbling_kinova","keyword":"feature-extraction","description":"mvnagakishan/babbling_kinova dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mvnagakishan/babbling_kinova","creator_name":"Venkata Naga Kishan Munjulury","creator_url":"https://huggingface.co/mvnagakishan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","text-classification","token-classification","table-question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Text-ADBench","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nThis repositoty covers 8 Text datasets inlcuding: 20Newsgroups, DBpedia14, IMDB, SMS_SPAM, SST2, WOS, Enron, Reuters21578.\nWe provide the original textual data, preprocess data and multiple embeddings based LLama2, Llama3, Mistral and Embedding Models (text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002) from OpenAI.\n\n\t\n\t\t\n\t\n\t\n\t\ttask_categories:\n- text-classification\n- feature-extraction\ntags:\n- anomaly-detection\n- benchmark\n-â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Feng-001/Text-ADBench.","url":"https://huggingface.co/datasets/Feng-001/Text-ADBench","creator_name":"XiaoFeng","creator_url":"https://huggingface.co/Feng-001","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","feature-extraction","mit","arxiv:2507.12295","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"scidocs-c-64-24-gpt-4o-2024-05-135334","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24-gpt-4o-2024-05-135334 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce search for products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24-gpt-4o-2024-05-135334 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-135334.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-135334","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24-gpt-4o-2024-05-135334","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24-gpt-4o-2024-05-135334 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce search for products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24-gpt-4o-2024-05-135334 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-135334.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-135334","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"philosophy-culture-translations-html-csv","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAI-Culture Philosophy and Culture Translations CSV + HTML Corpus\n\t\n\nThe corpus contains an exceptionally diverse range of cultural, philosophical, and literary texts, available in 12 major languages. Among other topics, there is extensive engagement with the ethics and aesthetics of artificial intelligence and its cultural and philosophical implications, as well as connections between AI and philosophy of language and philosophy of mind.\nThis project is maintained by a non-profitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv.","url":"https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv","creator_name":"AIâ€‘Cultureâ€‘Commons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset\n\t\n\n\nHindiNER-golden-dataset  - a small, diverse and high quality general Hindi NER dataset\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe HindiNER-golden-dataset  includes 952 diverse source texts sampled from nisram-hindi-text-0.0 dataset. Their labels were generated using Llama-3.3-70B-Instruct and then manually corrected twice.\n\nCurated by: nis12ram\nLanguage(s) (NLP): Hindi\nLicense: Apache License 2.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset.","url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"chestx","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains vision data for chest X-ray pathology identification.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nimage: The PIL image of the chest X-ray. These images are size (224,224) by default.\npathols: A binary-valued (14)-shaped array that indicates whether each of the 14 pathologies is present.\nstructs: A binary-valued array of shapes (14,224,224) that gives the segmentation for each of the 14 anatomical structures.\n\nThe 14 pathologies are:\n\nAtelectasis\nCardiomegalyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BrachioLab/chestx.","url":"https://huggingface.co/datasets/BrachioLab/chestx","creator_name":"Brachio Lab","creator_url":"https://huggingface.co/BrachioLab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"random-graphs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tRandom Graphs\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nOver 20â€‰000 randomly generated directed graphs with labels and formatting assigned at random.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nGeneration method: ErdÅ‘sâ€“RÃ©nyi random graph model  \nVertices: 2 to 15 per graph  \nEdge probability: Uniformly random between 0.0 and 1.0  \nLabels: Sampled from the agentlans/noun-phrases dataset\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry includes:\n\nimage: PNG rendering of the graph  \ndot: Graphviz DOT source code  \nlisp:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/random-graphs.","url":"https://huggingface.co/datasets/agentlans/random-graphs","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","feature-extraction","English","apache-2.0","Image"],"keywords_longer_than_N":true},
	{"name":"Contextual_Vision_for_Unexploded_Ordnances","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCTX-UXO: A Comprehensive Dataset for Detection and Identification of UneXploded Ordnances\n\t\n\n\n\n\t\n\t\t\n\t\tDOI: DOI:10.21227/cwnm-de53\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nAccording to US NOAA, unexploded ordnances (UXO) are â€œexplosive weapons such as bombs, bullets, shells, grenades, mines, etc. that did not explode when they were employed and still pose a risk of detonationâ€. UXOs are among the most dangerous threats to human life, environment and wildlife protection as well as to economicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UXO-Politehnica-Bucharest/Contextual_Vision_for_Unexploded_Ordnances.","url":"https://huggingface.co/datasets/UXO-Politehnica-Bucharest/Contextual_Vision_for_Unexploded_Ordnances","creator_name":"Researcher Craioveanu Gheorghe Marian","creator_url":"https://huggingface.co/UXO-Politehnica-Bucharest","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"upvoteweb-posts","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tupvoteweb: posts\n\t\n\nPosts in upvoteweb.\n\n\t\n\t\t\n\t\tconfigs\n\t\n\n\n[!IMPORTANT]There are several configs representing different permutations of this dataset. Load the relevant config for the task you are interested in.\n\nOverview of configs:\n\ndefault: largely unfiltered/unprocessed original data\neduscored: the \"eduscore\" predicted on the text column with huggingface's trained classifier\nen-clean: filter language for en and language_score for > 0.6. Run clean-text on the text col, preservingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/upvoteweb-posts.","url":"https://huggingface.co/datasets/BEE-spoke-data/upvoteweb-posts","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","image-to-text","text-to-image","fill-mask"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-23052024-upq5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-23052024-upq5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"generic search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-23052024-upq5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-23052024-upq5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-23052024-upq5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-23052024-upq5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-23052024-upq5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"generic search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-23052024-upq5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-23052024-upq5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-23052024-upq5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"support2-1","keyword":"feature-extraction","description":"Source: https://github.com/Parzon/SUPPORT2_ML_ANALYSIS\nInformation available at: https://archive.ics.uci.edu/dataset/880/support2\n","url":"https://huggingface.co/datasets/Suchinthana/support2-1","creator_name":"Wijesundara","creator_url":"https://huggingface.co/Suchinthana","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["time-series-forecasting","feature-extraction","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SciFact-32000-384-gpt-4o-2024-05-13-83349675","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-32000-384-gpt-4o-2024-05-13-83349675 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-32000-384-gpt-4o-2024-05-13-83349675 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-32000-384-gpt-4o-2024-05-13-83349675.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-32000-384-gpt-4o-2024-05-13-83349675","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SciFact-32000-384-gpt-4o-2024-05-13-83349675","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-32000-384-gpt-4o-2024-05-13-83349675 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-32000-384-gpt-4o-2024-05-13-83349675 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-32000-384-gpt-4o-2024-05-13-83349675.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-32000-384-gpt-4o-2024-05-13-83349675","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SynthVPT","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tVPT-Synth-Objects: A Synthetic Dataset for Visual Perspective Taking\n\t\n\nThis is a proof-of-concept synthetic dataset designed for training socio-cognitive foundational models for robotics, specifically in Visual Perspective Taking (VPT). The core task is to enable a robot to infer an object's 6D pose (position and orientation) relative to another agent, given a single RGB image.\nThis dataset was generated using NVIDIA Isaac Sim and Omniverse Replicator. Each entry provides an imageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jwgcurrie/SynthVPT.","url":"https://huggingface.co/datasets/jwgcurrie/SynthVPT","creator_name":"Joel Currie","creator_url":"https://huggingface.co/jwgcurrie","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","robotics","image-feature-extraction","depth-estimation","image-to-text"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance services\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance services\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Matvel","keyword":"feature-extraction","description":"DevKiDm/Matvel dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/DevKiDm/Matvel","creator_name":"Duy Nam Schlitz","creator_url":"https://huggingface.co/DevKiDm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","German","English"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-1752024-zdtc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-1752024-zdtc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Pharmacology research on antidepressants\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-1752024-zdtc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-zdtc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-zdtc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-1752024-zdtc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-1752024-zdtc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Pharmacology research on antidepressants\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-1752024-zdtc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-zdtc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-zdtc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CMedQAv2-3","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCMedQAv2-3 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"healthcare information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the CMedQAv2-3 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-3.","url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CMedQAv2-3","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCMedQAv2-3 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"healthcare information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the CMedQAv2-3 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-3.","url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-890333","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-890333 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"argumentation and sentiment analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-890333 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-890333.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-890333","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-890333","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-890333 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"argumentation and sentiment analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-890333 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-890333.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-890333","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SemTabNet","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SemTabNet\n\t\n\nThis dataset accompanies the following paper:\nTitle: Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs\nAuthors: Lokesh Mishra, Sohayl Dhibi, Yusik Kim, Cesar Berrospi Ramis, Shubham Gupta, Michele Dolfi, Peter Staar\nVenue: Accepted at the NLP4Climate workshop in the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024) \n\nIn this paper, we propose STATEMENTS as a new knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ds4sd/SemTabNet.","url":"https://huggingface.co/datasets/ds4sd/SemTabNet","creator_name":"Docling","creator_url":"https://huggingface.co/ds4sd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","table-question-answering","text2text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"Synthetic-X-Ray-Dataset","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tSelf-Supervised Learning Powered by Synthetic Data From Diffusion Models: Unconditional Synthetic Images for Chest Xray\n\t\n\nThis repository contains a fully synthetic dataset used for the study, Self-Supervised Learning Powered by Synthetic Data From Diffusion Models: Application to X-Ray Images.\n\nAbstract: \nSynthetic data offers a compelling solution to the challenges associated with acquiring high-quality medical data, which is often constrained by privacy concerns and limitedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/serag-ai/Synthetic-X-Ray-Dataset.","url":"https://huggingface.co/datasets/serag-ai/Synthetic-X-Ray-Dataset","creator_name":"serag-ai","creator_url":"https://huggingface.co/serag-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"chew_lexical","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nThis is the lexical/no-overlapping split of the CHEW dataset(CHEW: A Dataset of CHanging Events in Wikipedia). \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is the Lexical/No-overlapping split of the CHEW Dataset,where CHEW stands for CHanging Events in Wikipedia. It contains Wikipedia titles, text in two timestamped versions and Binary Label showing Change(1) or No change(0). Change here means there has been informationmâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hsuvaskakoty/chew_lexical.","url":"https://huggingface.co/datasets/hsuvaskakoty/chew_lexical","creator_name":"Hsuvas Borkakoty","creator_url":"https://huggingface.co/hsuvaskakoty","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","feature-extraction","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"hwtcm-sft-v1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tA dataset of Tradictional Chinese Medicine (TCM) for SFT\n\t\n\nä¸€ä¸ªç”¨äºŽå¾®è°ƒLLMçš„ä¼ ç»Ÿä¸­åŒ»æ•°æ®é›†\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis repository contains a dataset of Traditional Chinese Medicine (TCM) for fine-tuning large language models.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains 7,096 Chinese sentences related to TCM. The sentences are collected from various sources on the Internet, including medical websites, TCM forums, and TCM books. The dataset is generated or judged by various LLMs, includingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm-sft-v1.","url":"https://huggingface.co/datasets/Monor/hwtcm-sft-v1","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","feature-extraction","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"neodataset","keyword":"feature-extraction","description":"This dataset contains User Story and Story Points\n","url":"https://huggingface.co/datasets/giseldo/neodataset","creator_name":"Giseldo Neo","creator_url":"https://huggingface.co/giseldo","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","afl-3.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"youtube-timestamps-extraction","keyword":"feature-extraction","description":"lyleokoth/youtube-timestamps-extraction dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/lyleokoth/youtube-timestamps-extraction","creator_name":"lyle okoth","creator_url":"https://huggingface.co/lyleokoth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-157892","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-157892 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-157892 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-157892.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-157892","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-157892","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-157892 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-157892 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-157892.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-157892","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"captchaimages","keyword":"feature-extraction","description":"ThangaTharun/captchaimages dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ThangaTharun/captchaimages","creator_name":"S","creator_url":"https://huggingface.co/ThangaTharun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MedMKG","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMedMKG: Medical Multimodal Knowledge Graph\n\t\n\nWe introduce MedMKG, a Medical Multimodal Knowledge Graph that seamlessly fuses clinical concepts with medical images.MedMKG is constructed via a multi-stage pipeline that accurately identifies and disambiguates medical concepts while extracting their interrelations.To ensure the conciseness of the resulting graph, we further employ a pruning strategy based on our novel Neighbor-aware Filtering (NaF) algorithm.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‚ Providedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xcwangpsu/MedMKG.","url":"https://huggingface.co/datasets/xcwangpsu/MedMKG","creator_name":"Xiaochen Wang","creator_url":"https://huggingface.co/xcwangpsu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"plism-dataset-tiles","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tPLISM dataset\n\t\n\nThe Pathology Images of Scanners and Mobilephones (PLISM) dataset was created by (Ochi et al., 2024) for the evaluation of AI modelsâ€™ robustness to inter-institutional domain shifts.\nAll histopathological specimens used in creating the PLISM dataset were sourced from patients who were diagnosed and underwent surgery at the University of Tokyo Hospital between 1955 and 2018. \nPLISM-wsi consists in a group of consecutive slides digitized under 7 different scanners andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/owkin/plism-dataset-tiles.","url":"https://huggingface.co/datasets/owkin/plism-dataset-tiles","creator_name":"Owkin","creator_url":"https://huggingface.co/owkin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","cc-by-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"professional networking and mentorship\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"professional networking and mentorship\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Benchmark-Testing","keyword":"feature-extraction","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","token-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"central_florida_native_plants","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCentral Florida Native Plants Language Embeddings\n\t\n\nThis dataset contains language embeddings for 232 native plant species from Central Florida, extracted using the DeepSeek-V3 language model.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset provides pre-computed language embeddings for Central Florida plant species. Each species has been encoded using the prompt \"Ecophysiology of {species_name}:\" to capture semantic information about the plant's ecological characteristics.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepearth/central_florida_native_plants.","url":"https://huggingface.co/datasets/deepearth/central_florida_native_plants","creator_name":"DeepEarth","creator_url":"https://huggingface.co/deepearth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"TxT360-1M-sample","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/TxT360-1M-sample\n\t\n\nOne million row sample from LLM360/TxT360:\n\nmin length 256 GPT-4 tokens\nmax length 8192 GPT-4 tokens\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/TxT360-1M-sample","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","odc-by","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-140539","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-140539 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-140539 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-140539","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-140539 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-140539 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-607244","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-607244 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"None\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-607244 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-607244.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-607244","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-607244","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-607244 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"None\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-607244 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-607244.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-607244","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cbr_bonds_info_detector","keyword":"feature-extraction","description":"The Central Bank of Russia (CBR) posts decisions on the registration of securities on its website. We are interested in bonds. The dataset consists of: instructions for the model (in English) plus the text of the decision (in Russian) from the CBR and a dictionary with keys and values from the text of the decisions\nUPD, Dec 1, 2024: Structure of the dataset has been changed:\n\n'train' and 'test' splits (80%/20%);\nthe task is to extract only securities numbers from the provided text;\noutput ->â€¦ See the full description on the dataset page: https://huggingface.co/datasets/winterForestStump/cbr_bonds_info_detector.","url":"https://huggingface.co/datasets/winterForestStump/cbr_bonds_info_detector","creator_name":"Aleksei Trikoz","creator_url":"https://huggingface.co/winterForestStump","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Russian","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-08082024-cs2v-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-08082024-cs2v-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Wellness and Mindfulness\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-08082024-cs2v-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-08082024-cs2v-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-08082024-cs2v-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-08082024-cs2v-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-08082024-cs2v-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Wellness and Mindfulness\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-08082024-cs2v-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-08082024-cs2v-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-08082024-cs2v-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-610535","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-610535 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-610535 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-610535.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-610535","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-610535","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-610535 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-610535 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-610535.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-610535","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TikTok_Most_Shared_Video_Transcription_Example","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“² Example Dataset: TikTok Scraper Tool\n\t\n\nðŸ‘‰ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâš¡ Instant Transcription â€“ Turn any TikTok video into an AI-ready transcript  \nðŸŽ¯ Metadata â€“ Get the title, language description, and video hashtags  \nðŸ”— URL-Based Access â€“ Just drop in a TikTok video URL to start scraping  \nðŸ§© LLM-Ready Output â€“ Receive clean JSON ready for agents, RAG, or AI tools  \nðŸ’¸ Free Tier â€“ Use up to 100 queries during the beta period  \nðŸ’« Easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"Garbage_Classification_YOLO","keyword":"feature-extraction","description":"Notice: train set include 80% of original dataset, test and val sets have 10%.\n","url":"https://huggingface.co/datasets/BinKhoaLe1812/Garbage_Classification_YOLO","creator_name":"LÃª ÄÄƒng Khoa (Liam)","creator_url":"https://huggingface.co/BinKhoaLe1812","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","10K - 100K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Item-EMB","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tAL-GR/Item-EMB: Multi-modal Item Embeddings\n\t\n\nPaper: FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets\nCode: https://github.com/selous123/al_sid\nProject Page: https://huggingface.co/AL-GR\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository, AL-GR/Item-EMB, is a companion dataset to the main AL-GR generative recommendation dataset. It contains the 512-dimensional multi-modal embeddings for over 500 million items that appear in the AL-GR sequences.\nEach item isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/Item-EMB.","url":"https://huggingface.co/datasets/AL-GR/Item-EMB","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-feature-extraction","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-xqq9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-xqq9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"machine learning data generation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-xqq9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-xqq9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-xqq9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-xqq9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-xqq9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"machine learning data generation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-xqq9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-xqq9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-xqq9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Item-EMB","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAL-GR/Item-EMB: Multi-modal Item Embeddings\n\t\n\nPaper: FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets\nCode: https://github.com/selous123/al_sid\nProject Page: https://huggingface.co/AL-GR\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository, AL-GR/Item-EMB, is a companion dataset to the main AL-GR generative recommendation dataset. It contains the 512-dimensional multi-modal embeddings for over 500 million items that appear in the AL-GR sequences.\nEach item isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/Item-EMB.","url":"https://huggingface.co/datasets/AL-GR/Item-EMB","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-feature-extraction","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Good_Tires","keyword":"image-feature-extraction","description":"NMiriams/Good_Tires dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NMiriams/Good_Tires","creator_name":"Miriam Nanteza","creator_url":"https://huggingface.co/NMiriams","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-classification","image-feature-extraction","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Good_Tires","keyword":"feature-extraction","description":"NMiriams/Good_Tires dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NMiriams/Good_Tires","creator_name":"Miriam Nanteza","creator_url":"https://huggingface.co/NMiriams","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-classification","image-feature-extraction","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal document search for Dutch legislation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal document search for Dutch legislation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cdm-csa","keyword":"feature-extraction","description":"This dataset contains original CSA PDFs and their extracted data already transformed in CDM .json format.\n","url":"https://huggingface.co/datasets/finosfoundation/cdm-csa","creator_name":"FINOS","creator_url":"https://huggingface.co/finosfoundation","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","finance"],"keywords_longer_than_N":true},
	{"name":"MechRxn","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tStructural Molecular Identifiers of Chemical Reaction Mechanism Images (SMiCRM)\n\t\n\n296 molecular images from real chemical reaction mechanism images, selected based on uniqueness and complexity.\nAll images contain curved arrows, often used in chemical reaction mechanisms to indicate electron movement.\nAll images are paired with their SMILES and structural data files (SDF) for training optical chemical structure recognition molecules as a benchmark dataset.\n","url":"https://huggingface.co/datasets/Ting25/MechRxn","creator_name":"Ching Ting LEUNG","creator_url":"https://huggingface.co/Ting25","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"central-florida-native-plants-language-embeddings","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCentral Florida Native Plants Language Embeddings\n\t\n\nThis dataset contains language embeddings for 232 native plant species from Central Florida, extracted using the DeepSeek-V3 language model.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset provides pre-computed language embeddings for Central Florida plant species. Each species has been encoded using the prompt \"Ecophysiology of {species_name}:\" to capture semantic information about the plant's ecological characteristics.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepearth/central-florida-native-plants-language-embeddings.","url":"https://huggingface.co/datasets/deepearth/central-florida-native-plants-language-embeddings","creator_name":"DeepEarth","creator_url":"https://huggingface.co/deepearth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-46681","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-46681 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-46681 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-46681.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-46681","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-46681","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-46681 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-46681 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-46681.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-46681","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"3D_paper_mask_attack_dataset_for_Liveness","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tLiveness Detection Dataset: 3D Paper Mask Attacks\n\t\n\n\n\t\n\t\t\n\t\tFull version of the dataset is available for commercial usage. Leave a request on our website Axonlabs to purchase the dataset ðŸ’°\n\t\n\n\n\t\n\t\t\n\t\tFor feedback and additional sample requests, please contact us!\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe 3D Paper Mask Attack Dataset focuses on 3D volume-based paper attacks, incorporating elements such as the nose, shoulders, and forehead. These attacks are designed to be advanced and areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/3D_paper_mask_attack_dataset_for_Liveness.","url":"https://huggingface.co/datasets/AxonData/3D_paper_mask_attack_dataset_for_Liveness","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","video-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_06b","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,000,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-0.6B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 1,000,000 samples with embeddingsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_06b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_06b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"compositional-preference-modeling","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Featurization: Compositional Preference Modeling\n\t\n\nThis repository contains the datasets used in our case study on compositional preference modeling from Dataset Featurization, demonstrating how our unsupervised featurization pipeline can produce features describing human preferences and match expert-level produced features. This case study is built on top of Compositional Preference Modeling (CPM).\n\n\t\n\t\t\n\t\n\t\n\t\tHH-RLHF - Featurization\n\t\n\nUtilizing HH-RLHF dataset, we provideâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bravansky/compositional-preference-modeling.","url":"https://huggingface.co/datasets/Bravansky/compositional-preference-modeling","creator_name":"Michal","creator_url":"https://huggingface.co/Bravansky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","language-modeling","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"medical_records_did","keyword":"feature-extraction","description":"synavate/medical_records_did dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/synavate/medical_records_did","creator_name":"Synavate Labs","creator_url":"https://huggingface.co/synavate","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"image-wallpapers-dataset","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tNavanjana/image-wallpapers-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality images paired with descriptive text annotations, designed for computer vision and multimodal machine learning tasks. Each image has been preprocessed to standard dimensions and paired with detailed descriptions extracted from web sources.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Images: [NUMBER] images\nImage Format: JPEG (RGB)\nImage Dimensions: 224Ã—224 pixels\nText Descriptions: Naturalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Navanjana/image-wallpapers-dataset.","url":"https://huggingface.co/datasets/Navanjana/image-wallpapers-dataset","creator_name":"Navanjana","creator_url":"https://huggingface.co/Navanjana","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-feature-extraction","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reduced-imagenet","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tImagenet Mini Dataset\n\t\n\nThis dataset is a subset of the Imagenet validation set containing 26,000 images. It has been curated to have equal class distributions, with 26 randomly sampled images from each class.\nAll images have been resized to (224, 224) pixels, and are in RGB format.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset in your research, please cite the original Imagenet dataset:\nDeng, J., Dong, W., Socher, R., Li, L.-J., Li, K., & Fei-Fei, L. (2009). Imagenet: A large-scaleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/richwardle/reduced-imagenet.","url":"https://huggingface.co/datasets/richwardle/reduced-imagenet","creator_name":"Rich Wardle","creator_url":"https://huggingface.co/richwardle","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","apache-2.0","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Coq-MetaCoq","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMetaCoq Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe MetaCoq Dataset is derived from the MetaCoq repository, focusing on the formalization of Coq's meta-theory in the Coq proof assistant. This dataset processes .v files from the core theory directories to extract mathematical content in a structured format. This work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset, providing a specialized view of the MetaCoq libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq.","url":"https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","mit"],"keywords_longer_than_N":true},
	{"name":"volve_daily_drilling_report","keyword":"feature-extraction","description":"This is the repository for the Daily Drilling Reports (DDRs) from Volve field, consisting of 1759 files. The original files were in WITSML format, but they have been converted into JSON format here.\n","url":"https://huggingface.co/datasets/bengsoon/volve_daily_drilling_report","creator_name":"bengsoon chuah","creator_url":"https://huggingface.co/bengsoon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","feature-extraction","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"augmented_canonical_pubchem_13m","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tPubChem 10M - Augmented SMILES Dataset\n\t\n\nThis dataset is derived from the original PubChem 10M and has been canonicalized using RDKit (2024.9.4) to ensure structural consistency.  \nTo enhance molecular diversity, 33% of the dataset was randomly sampled and augmented using RDKitâ€™s Chem.MolToRandomSmilesVect function, following an approach similar to NVIDIAâ€™s molmim method for SMILES augmentation.  \n\n\t\n\t\t\n\t\tDataset Overview:\n\t\n\n\nSource: PubChem 10M  \nCanonicalization: RDKit (2024.9.4)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Derify/augmented_canonical_pubchem_13m.","url":"https://huggingface.co/datasets/Derify/augmented_canonical_pubchem_13m","creator_name":"Derify","creator_url":"https://huggingface.co/Derify","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","odc-by","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"overture-places","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOverture Places\n\t\n\nA lightweight frontend app using transformers.js showcasing the use of semantic similarity for geospatial applications such as geosocial media. Building on Overturempas Places, dynamically loading data from a singe 8Gb flatgeobuf file.\n\nApp: https://do-me.github.io/overture-places/\nGitHub: https://github.com/do-me/overture-places\n\n\n\t\n\t\t\n\t\n\t\n\t\tSearch the whole world with natural language!\n\t\n\n\nData on Huggingface:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/do-me/overture-places.","url":"https://huggingface.co/datasets/do-me/overture-places","creator_name":"Dominik WeckmÃ¼ller","creator_url":"https://huggingface.co/do-me","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","Geospatial"],"keywords_longer_than_N":true},
	{"name":"stock-charts","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tStock Charts\n\t\n\nThis dataset is a collection of a sample of images from tweets that I scraped using my Discord bot that keeps track of financial influencers on Twitter.\nThe data consists of images that were part of tweets that mentioned a stock.\nThis dataset can be used for a wide variety of tasks, such as image classification or feature extraction.\n\n\t\n\t\t\n\t\n\t\n\t\tFinTwit Charts Collection\n\t\n\nThis dataset is part of a larger collection of datasets, scraped from Twitter and labeled by aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/stock-charts.","url":"https://huggingface.co/datasets/StephanAkkerman/stock-charts","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"gooaq_mt_german_0_hard_negatives","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tRemaining GooAQ (Google Answers to Google Questions) question-answer pairs in German without hard negatives.\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nThis dataset contains the remaining 600K of lines of german machine translated texts of the mined hard negatives ~2M question-answer-negative triplets and question-answer-negative_1...-negative_5 tuples gooaq_mt_german_5_hard_negatives. The full original Gooaq dataset in english only: (link to original dataset). This dataset can be used directly with Sentenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german_0_hard_negatives.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german_0_hard_negatives","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","German","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"attacked_wrong_label","keyword":"feature-extraction","description":"XiaoYuanZzz22333/attacked_wrong_label dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/XiaoYuanZzz22333/attacked_wrong_label","creator_name":"zz","creator_url":"https://huggingface.co/XiaoYuanZzz22333","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","mit","ðŸ‡ºðŸ‡¸ Region: US","code"],"keywords_longer_than_N":false},
	{"name":"pd12m","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tPD12M\n\t\n\nThis is a curated PD12M dataset for use with the II-Commons project.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset comprises a curated Public Domain 12M image collection, refined by filtering for active image links. EXIF data was extracted, and images underwent preprocessing and feature extraction using SigLIP 2. All vector embeddings are normalized 16-bit half-precision vectors optimized for L2 indexing with vectorchord.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sourcesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Intelligent-Internet/pd12m.","url":"https://huggingface.co/datasets/Intelligent-Internet/pd12m","creator_name":"II","creator_url":"https://huggingface.co/Intelligent-Internet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10M - 100M","csv"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-askubuntu","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-askubuntu Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-askubuntu model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-askubuntu","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-askubuntu Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-askubuntu model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"repository-learning","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tRepository Learning Training Dataset\n\t\n\nThis dataset contains training data extracted from GitHub repositories for training context-aware code review models. The dataset supports three primary machine learning tasks: contrastive learning, fine-tuning, and semantic indexing.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nPurpose: Enable training of AI models that understand repository-specific code review patterns and provide contextual feedback.\nSource: GitHub repositories with rich pull request historyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kotlarmilos/repository-learning.","url":"https://huggingface.co/datasets/kotlarmilos/repository-learning","creator_name":"Milos Kotlar","creator_url":"https://huggingface.co/kotlarmilos","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","feature-extraction","machine-generated"],"keywords_longer_than_N":true},
	{"name":"tmdb_5000_movies","keyword":"feature-extraction","description":"Dataset source: TMDB 5000 Movie Dataset\n","url":"https://huggingface.co/datasets/jibala1022/tmdb_5000_movies","creator_name":"Balaji S","creator_url":"https://huggingface.co/jibala1022","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"open-synthetic-embeddings","keyword":"feature-extraction","description":"","url":"https://huggingface.co/datasets/jspringer/open-synthetic-embeddings","creator_name":"Jacob Springer","creator_url":"https://huggingface.co/jspringer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","sentence-similarity","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"central-florida-native-plants","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDeepEarth Central Florida Native Plants Dataset v0.2.0\n\t\n\n\n\t\n\t\t\n\t\tðŸŒ¿ Dataset Summary\n\t\n\nA comprehensive multimodal dataset featuring 33,665 observations of 232 native plant species from Central Florida. This dataset combines citizen science observations with state-of-the-art vision and language embeddings for advancing multimodal self-supervised ecological intelligence research.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nðŸŒ Spatiotemporal Coverage: Complete GPS coordinates and timestamps for allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepearth/central-florida-native-plants.","url":"https://huggingface.co/datasets/deepearth/central-florida-native-plants","creator_name":"DeepEarth","creator_url":"https://huggingface.co/deepearth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","zero-shot-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"genesis-of-the-daleks-narrative-kg","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tGenesis of the Daleks Narrative Knowledge Graph\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive narrative knowledge graph extracted from the Doctor Who serial \"Genesis of the Daleks\" (1975), analyzed using the Fabula V2 pipeline. The graph captures characters, locations, events, objects, organizations, and their complex relationships throughout the six-episode story.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Nodes: 3,728\nTotal Relationships: 10,978\nEpisodes Analyzed: 6â€¦ See the full description on the dataset page: https://huggingface.co/datasets/brandburner/genesis-of-the-daleks-narrative-kg.","url":"https://huggingface.co/datasets/brandburner/genesis-of-the-daleks-narrative-kg","creator_name":"Mike Atherton","creator_url":"https://huggingface.co/brandburner","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["graph-ml","text-generation","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BIOMON","keyword":"feature-extraction","description":"\"BIOMON: Using passive acoustic monitoring methods to survey bird communities in biodiverse agricultural farmlands in the EU\"\nhttps://cordis.europa.eu/project/id/101090273\n1/6/2022 - 31/5/2024\nBIOMON is funded by the European Union's Horizon Europe programme, ERA Talents, under grant agreement 101090273\nA complete description of the dataset can be found in the following article: \nMammides, C., Ieronymidou, C. & Papadopoulos, H. (2025). An ecoacoustic dataset collected on the island of Cyprusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cmammides/BIOMON.","url":"https://huggingface.co/datasets/cmammides/BIOMON","creator_name":"Christos Mammides","creator_url":"https://huggingface.co/cmammides","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"EarthLoc2_FAISS","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸŒ EarthLoc2 FAISS Index (DINOv2 + SALAD)\n\t\n\nThis is the FAISS index used in the Hugging Face Space:ðŸ”— EarthLoc2: Image Geolocalization\n\n\n\t\n\t\t\n\t\tðŸ“¦ Whatâ€™s Inside?\n\t\n\nThis index was constructed by encoding all of the 2021 Sentinel-2 satellite images from the EarthLoc dataset:\nðŸ‘‰ EarthLoc_2021_Database\nEach image is encoded four times (with rotations of 0Â°, 90Â°, 180Â°, and 270Â°), and descriptors were extracted using:\nhttps://huggingface.co/pawlo2013/EarthLoc2\nAlso see the correspondingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pawlo2013/EarthLoc2_FAISS.","url":"https://huggingface.co/datasets/pawlo2013/EarthLoc2_FAISS","creator_name":"Pawel Piwowarski","creator_url":"https://huggingface.co/pawlo2013","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scidocs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scidocs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"UnifiedWasteClassificationDataset","keyword":"image-feature-extraction","description":"sidmaji/UnifiedWasteClassificationDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sidmaji/UnifiedWasteClassificationDataset","creator_name":"Siddhant Maji","creator_url":"https://huggingface.co/sidmaji","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","image-to-image","image-to-text","image-text-to-text"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint5","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint5\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint5","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LM2rulers38","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLM2rulers38\n\t\n\nThe LM2rulers38 dataset contains cropped rulers from lots of herbarium specimens. Images are organized by ruler_class and split into train / val / test.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThis repository uses the imagefolder format:\nLM2rulers38/\nâ””â”€ train/\n    â””â”€ <ruler_class>/*.jpg\n\nâ””â”€ val/\n    â””â”€ <ruler_class>/*.jpg\n\nâ””â”€ test/\n    â””â”€ <ruler_class>/*.jpg\n\n\nClasses with fewer than 10 images were skipped.  \nFor all included classes, an 80/10/10 split is created with at least 1 image perâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phyloforfun/LM2rulers38.","url":"https://huggingface.co/datasets/phyloforfun/LM2rulers38","creator_name":"LeafMachine2 x VoucherVision","creator_url":"https://huggingface.co/phyloforfun","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","Undetermined","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"da-wiki-icc","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for â€œDanish Wikipedia â€” Image, Caption, Contextâ€\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThis dataset contains images from Danish Wikipedia articles paired with:\n\ncaptions â€” the local image caption \nneighbouring_context â€” the surrounding section/block text where the image appears in markdown\nfull text â€” the full article markdown, stored once per article, with all other rows pointing to the canonical copy via full_text_row_id\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tFiles & Splitsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/V4ldeLund/da-wiki-icc.","url":"https://huggingface.co/datasets/V4ldeLund/da-wiki-icc","creator_name":"Vladimir Salnikov","creator_url":"https://huggingface.co/V4ldeLund","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","feature-extraction","image-captioning","Danish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-872024-od97-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-872024-od97-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"job search and recruitment\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-872024-od97-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-od97-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-od97-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-872024-od97-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-872024-od97-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"job search and recruitment\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-872024-od97-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-od97-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-od97-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"news-of-the-brazilian-newspaper","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNews of the Brazilian Newspaper\n\t\n\nThis repository contains a comprehensive dataset of news articles from a Brazilian newspaper, Folha de SÃ£o Paulo (http://www.folha.uol.com.br/). The dataset includes 167,053 examples of news articles, comprising headlines, URLs of articles, complete articles, and their respective categories. \n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThe headlines were initially gathered from Inshorts and were then used to scrape the complete news articles from Folha de SÃ£o Paulo.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper.","url":"https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","text-generation","Portuguese"],"keywords_longer_than_N":true},
	{"name":"literary-reasoning","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLiterary Reasoning: Symbolism and Structure from Classic Texts\n\t\n\n\n\t\n\t\t\n\t\tðŸ§  Purpose and Scope\n\t\n\nThis dataset is designed to support literary reasoning, specifically interpretive analysis of themes and symbolism in classic literature. It enables research into how models can analyze literature beyond surface-level content.\nIt targets advanced tasks like:\n\nDetecting symbolic elements\nInterpreting tone and genre-specific devices\nAnalyzing narrative structures\nRecognizing literaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/literary-reasoning.","url":"https://huggingface.co/datasets/agentlans/literary-reasoning","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","multilingual","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"reddit-ethics","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tReddit Ethics: Real-World Ethical Dilemmas from Reddit\n\t\n\nReddit Ethics is a curated dataset of genuine ethical dilemmas collected from Reddit, designed to support research and education in philosophical ethics, AI alignment, and moral reasoning.\nEach entry features a real-world scenario accompanied by structured ethical analysis through major frameworksâ€”utilitarianism, deontology, and virtue ethics. The dataset also provides discussion questions, sample answers, and proposedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-ethics.","url":"https://huggingface.co/datasets/agentlans/reddit-ethics","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"napierone-pdf-raw","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/napierone-pdf-raw\n\t\n\nNapierOne PDF files converted with marker.\n\n\t\n\t\t\n\t\tdetected languages\n\t\n\nCounter({'en': 4665,\n         'nl': 2,\n         'fi': 7,\n         'fr': 8,\n         'cy': 54,\n         'sq': 1,\n         'it': 1,\n         'unknown-error': 5,\n         'sk': 1,\n         'es': 2,\n         'de': 3,\n         'ro': 1,\n         'pl': 1,\n         'zh': 1,\n         'so': 1,\n         'ml': 1})\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/napierone-pdf-raw","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","Welsh","odc-by"],"keywords_longer_than_N":true},
	{"name":"Generating_Video_Data","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tGenerating_Video_Data\n\t\n\nHanzhe Liang\nmodified: 23 May\n\nðŸ˜Š This library contains some common data for training video generation models. This is a library of summary datasets, with thanks to the original authors for their contributions. Regardless of which data you need, the following steps:\nmkdir data\ncd data\n\nNext, go to my cloud database link and download the data you want into the folderdata/.\nOnce you've downloaded the data you need, we've found preprocessing steps from itsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HanzheL/Generating_Video_Data.","url":"https://huggingface.co/datasets/HanzheL/Generating_Video_Data","creator_name":"Hanzhe","creator_url":"https://huggingface.co/HanzheL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-feature-extraction","video-classification","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"omega-multimodal","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tOMEGA Labs Bittensor Subnet: Multimodal Dataset for AGI Research\n\t\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe OMEGA Labs Bittensor Subnet Dataset is a groundbreaking resource for accelerating Artificial General Intelligence (AGI) research and development. This dataset, powered by the Bittensor decentralized network, aims to be the world's largest multimodal dataset, capturing the vast landscape of human knowledge and creation.\nWith over 1 million hours of footage and 30 million+ 2-minute videoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/omegalabsinc/omega-multimodal.","url":"https://huggingface.co/datasets/omegalabsinc/omega-multimodal","creator_name":"OMEGA Labs, Inc.","creator_url":"https://huggingface.co/omegalabsinc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-text-to-text","video-classification","image-classification","image-to-text","image-to-video"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-13-61285","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24-gpt-4o-2024-05-13-61285 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"knowledge base search for questions and answers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-13-61285 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-13-61285.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-13-61285","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-13-61285","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24-gpt-4o-2024-05-13-61285 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"knowledge base search for questions and answers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-13-61285 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-13-61285.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-13-61285","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"experimental-paper-json-xtraction-2","keyword":"feature-extraction","description":"Shinapri/experimental-paper-json-xtraction-2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Shinapri/experimental-paper-json-xtraction-2","creator_name":"Shinapri Delucania","creator_url":"https://huggingface.co/Shinapri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","summarization","question-answering","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"slimorca_dedup_german_experimental-scored","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from jphme/slimorca_dedup_german_experimental with added cosine-similarity scores. As no license was given for this version, I chose the MIT license from the original Open-Orca/SlimOrca-Dedup dataset.\nThe scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for fasterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/slimorca_dedup_german_experimental-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/slimorca_dedup_german_experimental-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5202024-55bm-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5202024-55bm-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal regulations search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5202024-55bm-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-55bm-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-55bm-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5202024-55bm-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5202024-55bm-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal regulations search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5202024-55bm-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-55bm-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-55bm-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Indian-Supreme-Court-Judgements-Chunked","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tIndian Supreme Court Judgements Chunked\n\t\n\n\n\t\n\t\t\n\t\tExecutive Summary\n\t\n\nThe dataset aims to address the chronic backlog in the Indian judiciary system, particularly in the Supreme Court, by creating a dataset optimized for legal language models (LLMs). The dataset will consist of pre-processed, chunked, and embedded textual data derived from the Supreme Court's judgment PDFs.\n\n\t\n\t\t\n\t\tProblem and Importance - Motivation\n\t\n\nIndian courts are overwhelmed with pending cases, with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vihaannnn/Indian-Supreme-Court-Judgements-Chunked.","url":"https://huggingface.co/datasets/vihaannnn/Indian-Supreme-Court-Judgements-Chunked","creator_name":"Vihaan Nama","creator_url":"https://huggingface.co/vihaannnn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","sentence-similarity","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint2\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint2","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-06052024-ruwi-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-06052024-ruwi-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance search for car policies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-06052024-ruwi-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-ruwi-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-ruwi-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-06052024-ruwi-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-06052024-ruwi-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance search for car policies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-06052024-ruwi-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-ruwi-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-ruwi-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MH370_Malaysian_Airlines_Satellite_Data","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMH370 Inmarsat Satellite Data Logs\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains the data communication logs from the Inmarsat satellite system related to Malaysia Airlines Flight MH370 (9M-MRO). The data was provided to the authorities to assist in the ongoing investigation and search efforts for the missing aircraft.\n\n\t\n\t\t\n\t\tDataset Contents\n\t\n\nThe dataset consists of structured logs recorded at the Ground Earth Station (GES), capturing communications between the Inmarsat satelliteâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ilyass31/MH370_Malaysian_Airlines_Satellite_Data.","url":"https://huggingface.co/datasets/ilyass31/MH370_Malaysian_Airlines_Satellite_Data","creator_name":"Ilyas_dahaoui","creator_url":"https://huggingface.co/ilyass31","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Pes2o-Abstract-X","keyword":"feature-extraction","description":"Introducing Pes2o-X, also known as Pes2o-Abstract-X, a derived dataset from the original Pes2o dataset released by Allen AI. The Pes2o dataset aimed to provide a large corpus of open-access research papers, including both abstracts and full text. However, it required pre-processing before the abstracts could be used for training or fine-tuning machine learning models.\nAt LAION AI, we initiated a project called X, focusing on developing high-quality training corpora from scratch, reorganisingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/Pes2o-Abstract-X.","url":"https://huggingface.co/datasets/laion/Pes2o-Abstract-X","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","feature-extraction","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"Amazon-2023-GenQ","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tAmazon Reviews Dataset for Query Generation\n\t\n\nThis dataset is designed for training models on tasks such as query generation, reranking, semantic search, and vision-language tasks (e.g., CLIP, VLMS) using Amazon product metadata.The original datasets can be found here: https://amazon-reviews-2023.github.io/\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a curated sample derived from seven filtered Amazon product category datasets \n(Amazon All Beauty, Amazon Fashion, Sports andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/smartcat/Amazon-2023-GenQ.","url":"https://huggingface.co/datasets/smartcat/Amazon-2023-GenQ","creator_name":"SmartCat","creator_url":"https://huggingface.co/smartcat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","summarization","sentence-similarity","text-classification","text-generation"],"keywords_longer_than_N":true},
	{"name":"FIP1","keyword":"feature-extraction","description":"\n\n\t\n\t\t\n\t\tThe FIP 1.0 Data Set: Highly Resolved Annotated Image Time Series of 4,000 Wheat Plots Grown in Six Years\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nWe provide time series data for more than 4,000 wheat plots, including aligned high-resolution image sequences totaling more than 153,000 aligned images across six years.\nMeasurement data for eight key wheat traits is included, namely canopy cover values, plant heights, wheat head counts, senescence ratings, heading dateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mikeboss/FIP1.","url":"https://huggingface.co/datasets/mikeboss/FIP1","creator_name":"Mike Boss","creator_url":"https://huggingface.co/mikeboss","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["time-series-forecasting","feature-extraction","tabular-regression","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-994439","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-994439 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-994439 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-994439.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-994439","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-994439","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-994439 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-994439 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-994439.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-994439","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Anti_spoofing_dataset_Print_attack","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tLiveness Detection Dataset: Printed Photos Attacks\n\t\n\n\n\t\n\t\t\n\t\t2D Masks Presentation Attack Detection\n\t\n\nPhoto Print attack dataset (3K individuals+) for Presentation Attack Detection level 1 (PAD). Biometric Attack dataset with printed photos attacks which is used by both iBeta and NIST FATE to assess liveness detection algorithms. This dataset is tailored for training AI models to identify photo print attacks on individuals. Print photo attacks include Zoom effects as mandated by NISTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/Anti_spoofing_dataset_Print_attack.","url":"https://huggingface.co/datasets/AxonData/Anti_spoofing_dataset_Print_attack","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","video-classification","image-segmentation","English"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"MusicSem","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for MusicSem\n\t\n\n\n\n\nThis dataset contains 35977 entries of text-audio pairs. There is an accompanying test set of size 480 which is withheld for leaderboard purposes. Please reach out to authors for further access.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Rebecca Salganik, Teng Tu, Fei-Yueh Chen, Xiaohao Liu, Kaifeng Lu, Ethan Luvisia, Zhiyao Duan, Guillaume Salha-Galvan, Anson Kahng, Yunshan Ma, Jian Kang\nLanguage(s) : English\nLicense: MITâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AMSRNA/MusicSem.","url":"https://huggingface.co/datasets/AMSRNA/MusicSem","creator_name":"Rsalgani","creator_url":"https://huggingface.co/AMSRNA","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","summarization","feature-extraction","audio-text-to-text","English"],"keywords_longer_than_N":true},
	{"name":"Replay_attack_mobile","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tLiveness Detection Replay Dataset (3K+ Attacks, 1.5K People)\n\t\n\n\n\t\n\t\t\n\t\tiBeta Level 1 Dataset\n\t\n\nLiveness detection dataset of Replay attacks performed on Mobile devices. This dataset consists of 1,500 individuals who provided selfies, followed by 3,000 replay display attacks executed across 15 different mobile devices. These attacks are captured from a diverse range of devices, spanning low, medium, and high-end mobile phones, providing extensive variation in screen types, lightingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/Replay_attack_mobile.","url":"https://huggingface.co/datasets/AxonData/Replay_attack_mobile","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","video-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"the-stack-smol-xs-all","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tbigcode/the-stack-smol-xs - all configs\n\t\n\nAll configs from bigcode/the-stack-smol-xs concatenated and shuffled. 100 examples each of:\n['ada', 'agda', 'alloy', 'antlr', 'applescript', 'assembly', 'augeas', 'awk',\n 'batchfile', 'bison', 'bluespec', 'c', 'c++', 'c-sharp', 'clojure', 'cmake',\n 'coffeescript', 'common-lisp', 'css', 'cuda', 'dart', 'dockerfile', 'elixir',\n 'elm', 'emacs-lisp', 'erlang', 'f-sharp', 'fortran', 'glsl', 'go', 'groovy',\n 'haskell', 'html', 'idris', 'isabelle'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/the-stack-smol-xs-all.","url":"https://huggingface.co/datasets/BEE-spoke-data/the-stack-smol-xs-all","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","text-classification","bigcode/the-stack-smol-xs","odc-by"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-512-192-gpt-4o-2024-05-13-777321 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-512-192-gpt-4o-2024-05-13-777321 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6192024-56os-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Education technology\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6192024-56os-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Education technology\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tamily-1","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tTamily-1: Ancient Tamil OCR Synthetic Dataset\n\t\n\nTamizhi \"à®¤à®®à®¿à®´à®¿\"\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\nRepository: sasicodes/tamily-1\nPoint of Contact: @sasicodes\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nTamily-1 is an ancient Tamil OCR synthetic dataset generated from the first 200,000 rows of Solvari-1, a large Tamil text corpus. The dataset contains rendered images of Tamil text with various augmentations and styles, making it suitable for training OCR models.\n\n\t\n\t\t\n\t\tFields\n\t\n\n\nimage: PNG image of rendered Tamilâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sasicodes/tamily-1.","url":"https://huggingface.co/datasets/sasicodes/tamily-1","creator_name":"Sasi","creator_url":"https://huggingface.co/sasicodes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-feature-extraction","sasicodes/solvari-1","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"UltraTextbooks-2.1-fw_mix","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/UltraTextbooks-2.1-fw_mix\n\t\n\n\nfiltered ultratextbooks for min 50 words\nshuffle in 500k rows from fineweb to facilitate continual pretrain\n\nGPT-4 tiktoken token count:\n        token_count\ncount  3.701646e+06\nmean   9.934539e+02\nstd    1.726200e+03\nmin    5.400000e+01\n25%    2.580000e+02\n50%    5.540000e+02\n75%    1.363000e+03\nmax    4.277600e+05\n\n\nTotal count:\t3677.41 M tokens\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/UltraTextbooks-2.1-fw_mix","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","fill-mask","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"hermes-function-calling-v1","keyword":"feature-extraction","description":"\n\n\t\n\t\t\n\t\tHermes Function-Calling V1\n\t\n\nThis dataset is the compilation of structured output and function calling data used in the Hermes 2 Pro series of models.\nThis repository contains a structured output dataset with function-calling conversations, json-mode, agentic json-mode and structured extraction samples, designed to train LLM models in performing function calls and returning structured output based on natural language instructions. The dataset features various conversational scenariosâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/giovannioliveira/hermes-function-calling-v1.","url":"https://huggingface.co/datasets/giovannioliveira/hermes-function-calling-v1","creator_name":"Giovanni Oliveira","creator_url":"https://huggingface.co/giovannioliveira","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"IIoTset","keyword":"feature-extraction","description":"This dataset is generated from dataset Edge-IIoTset (covert and label pcap files to json format) for research purpose.\nYou can download Edge-IIoTset from https://ieee-dataport.org/documents/edge-iiotset-new-comprehensive-realistic-cyber-security-dataset-iot-and-iiot-applications\n\npcap-json.tar.gz: Json format (without labels) for pcap files of Edge-IIoTset.\ndataset.tar.gz: Json format (with labels) for pcap files of Edge-IIoTset.\n\nResearch for https://github.com/jim-xie-cn/Research-SSPE-COPAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JimXie/IIoTset.","url":"https://huggingface.co/datasets/JimXie/IIoTset","creator_name":"XieWenWei","creator_url":"https://huggingface.co/JimXie","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"coco-clip-vit-l-14","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCOCO Dataset Processed with CLIP ViT-L/14\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset represents a processed version of the '2017 Unlabeled images' subset of the COCO dataset (COCO Dataset), utilizing the CLIP ViT-L/14 model from OpenAI. The original dataset comprises 123K images, approximately 19GB in size, which have been processed to generate 786-dimensional vectors. These vectors can be utilized for various applications like semantic search systems, image similarity assessments, and more.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/s-emanuilov/coco-clip-vit-l-14.","url":"https://huggingface.co/datasets/s-emanuilov/coco-clip-vit-l-14","creator_name":"Simeon Emanuilov","creator_url":"https://huggingface.co/s-emanuilov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","sentence-similarity","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Office-Home-LDS","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOffice-Home-LDS Dataset\n\t\n\nPaper: â€œGeometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learningâ€ \nGithub: 2025CVPR_GGEUR \nThe Office-Home-LDS dataset is constructed by introducing label skew on top of the domain skew present in the Office-Home dataset. \nThe goal is to create a more challenging and realistic dataset that simultaneously exhibits both label skew and domain skew.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ”— Citation\n\t\n\nThe article has been accepted by 2025CVPR, if you useâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WeiDai-David/Office-Home-LDS.","url":"https://huggingface.co/datasets/WeiDai-David/Office-Home-LDS","creator_name":"Wei Dai","creator_url":"https://huggingface.co/WeiDai-David","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","English","apache-2.0","Image"],"keywords_longer_than_N":true},
	{"name":"travail-emploi-clean","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ—‚ï¸ Travail-Emploi (Cleaned)\n\t\n\nThis dataset is a cleaned version of AgentPublic/travail-emploi,where duplicate chunks have been removed to improve retrieval performance in RAG experiments.\n\n\t\n\t\t\n\t\tðŸ“– License\n\t\n\nDistributed under the Etalab Open License 2.0, identical to the original dataset.\n","url":"https://huggingface.co/datasets/edouardfoussier/travail-emploi-clean","creator_name":"Edouard Foussier","creator_url":"https://huggingface.co/edouardfoussier","license_name":"Etalab Open License 2.0 English","license_url":"https://scancode-licensedb.aboutcode.org/etalab-2.0-en.html","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","French","etalab-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MIMIC-Meme-Dataset","keyword":"feature-extraction","description":"This dataset endeavors to fill the research void by presenting a meticulously curated collection of misogynistic memes in a code-mixed language of Hindi and English. It introduces two sub-tasks: the first entails a binary classification to determine the presence of misogyny in a meme, while the second task involves categorizing the misogynistic memes into multiple labels, including Objectification, Prejudice, and Humiliation.\nFor more Information and Citation: Singh, A., Sharma, D., & Singhâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aakash941/MIMIC-Meme-Dataset.","url":"https://huggingface.co/datasets/Aakash941/MIMIC-Meme-Dataset","creator_name":"Aakash Singh","creator_url":"https://huggingface.co/Aakash941","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Hindi","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-257061","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-257061 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-257061 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-257061.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-257061","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-257061","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-257061 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-257061 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-257061.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-257061","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"reddit_finance_posts_apple-tesla-microsoft","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tReddit Finance Posts Dataset (Apple, Tesla, Microsoft)\n\t\n\nThis dataset contains 12046 Reddit Posts collected from 20 finance-related subreddits via the Reddit API using the keywords Apple, Tesla, and Microsoft.\nThe included subreddits are:\nstocks, wallstreetbets, investing, StockMarket, options, RobinHood,\npennystocks, SecurityAnalysis, personalfinance, Dividends, CryptoCurrency,\nCryptoMarkets, ETFs, FinancialIndependence, ValueInvesting, quant,\nalgotrading, forex, economy, Superstonkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emilpartow/reddit_finance_posts_apple-tesla-microsoft.","url":"https://huggingface.co/datasets/emilpartow/reddit_finance_posts_apple-tesla-microsoft","creator_name":"Emil Partow","creator_url":"https://huggingface.co/emilpartow","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"postglacial-shaded-relief","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tShaded relief image dataset for geomorphological studies of Polish postglacial landscape\n\t\n\nThis dataset contains a list of 138 png images of shaded relief cut into the 128x128 arrays. The area that the dataset covers is compacted within the\ntwo main geomorphological spheres in Poland - postglacial denuded and nondenuded landscape. Arrays representing one of two categories are labeled accordingly.\nShaded relief scene has been calculated with exposition and sunlight paramiters set toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Pacoch/postglacial-shaded-relief.","url":"https://huggingface.co/datasets/Pacoch/postglacial-shaded-relief","creator_name":"Jakub","creator_url":"https://huggingface.co/Pacoch","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"laion-translated-to-en-korean-subset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tlaion-translated-to-en-korean-subset\n\t\n\n\n\t\n\t\t\n\t\tAbout dataset\n\t\n\na subset data of laion/laion2B-multi-joined-translated-to-en and laion/laion1B-nolang-joined-translated-to-en, including only korean\n\n\t\n\t\t\n\t\tLisence\n\t\n\nCC-BY-4.0\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instance\n\t\n\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"Bingsu/laion-translated-to-en-korean-subset\")\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['hash', 'URL', 'TEXT', 'ENG TEXT'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion-translated-to-en-korean-subset.","url":"https://huggingface.co/datasets/Bingsu/laion-translated-to-en-korean-subset","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","multilingual","Korean"],"keywords_longer_than_N":true},
	{"name":"CelebA_embedding_StyleGAN_to_VAE","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ§  Synthetic CelebA-StyleGAN Embedding Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ§© Dataset Creation Notes\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was created by combining CelebA, StyleGAN (FFHQ), and Stable Diffusion (VAE Encoder)to generate facial embeddings annotated with visual attributes.\n\n\t\n\t\t\n\t\tðŸ”¹ Step-by-step process\n\t\n\n\nAttribute Classifier (CelebA)\n\nTrained a ResNet-based classifier on the CelebA dataset to predict 40 facial attributes.  \nAchieved ~92% accuracy on the validation set.\nThe â€œBlurryâ€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/None00000/CelebA_embedding_StyleGAN_to_VAE.","url":"https://huggingface.co/datasets/None00000/CelebA_embedding_StyleGAN_to_VAE","creator_name":"akjbd","creator_url":"https://huggingface.co/None00000","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","zero-shot-classification","cc-by-4.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"ARK-Metadata-V2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTitle\n\t\n\nMetadata of the \"Alter Realkatalog\" (ARK) of Berlin State Library (SBB) Version 2 â€“ August 2025\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset was created with the intent to provide a single larger set of metadata from Berlin State Library for research purposes and the development of AI applications.\nThe dataset comprises descriptive metadata of 2.639.554 titles derived from the union catalogue K10plus, a database with about 200 million records from libraries across 11 German states.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ARK-Metadata-V2.","url":"https://huggingface.co/datasets/SBB/ARK-Metadata-V2","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","English"],"keywords_longer_than_N":true},
	{"name":"uniprot-swissprot","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset: Uniprot Swissprot\n\t\n\n","url":"https://huggingface.co/datasets/khairi/uniprot-swissprot","creator_name":"khairi abidi","creator_url":"https://huggingface.co/khairi","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","afl-3.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"pre-duplicate","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tThis file are pre-trained rvc for training models.\n\t\n\n\n\t\n\t\t\n\t\tThis files are not mine, i just backing up this file due to colab new term of service that making rvc can't run in google colab.\n\t\n\n\n\t\n\t\t\n\t\tCredit owner\n\t\n\nLiu\n","url":"https://huggingface.co/datasets/mrmocciai/pre-duplicate","creator_name":"Mocci lutha","creator_url":"https://huggingface.co/mrmocciai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"WordNetNoun","keyword":"feature-extraction","description":"Disambiguated version of WordNet's noun hierarchy where entity names are formatted  as \"name: definition\" to resolve polysemy issues. This prevents training signal  conflicts when the same word has multiple meanings.\n","url":"https://huggingface.co/datasets/Jinrui/WordNetNoun","creator_name":"Lin","creator_url":"https://huggingface.co/Jinrui","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"eyeinfo","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tEyeInfo Dataset\n\t\n\nThe EyeInfo Dataset is an open-source eye-tracking dataset created by Fabricio Batista Narcizo, a research scientist at the IT University of Copenhagen (ITU) and GN Audio A/S (Jabra), Denmark. This dataset was introduced in the paper \"High-Accuracy Gaze Estimation for Interpolation-Based Eye-Tracking Methods\" (DOI: 10.3390/vision5030041). The dataset contains high-speed monocular eye-tracking data from an off-the-shelf remote eye tracker using active illumination.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fabricionarcizo/eyeinfo.","url":"https://huggingface.co/datasets/fabricionarcizo/eyeinfo","creator_name":"Fabricio Batista Narcizo","creator_url":"https://huggingface.co/fabricionarcizo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"feature-extraction","description":"Important Notice:\n\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \"Usability\" score calculation for these unreliable datasets.\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\n\n\n\nThe featuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"OpenOrcaNo-15k","keyword":"feature-extraction","description":"ðŸ‹ The OpenOrca Dataset Norwegian! ðŸ‹\n\nThis is a subset of 15000 rows of the OpenOrca dataset, translated into Norwegian.\nTranslation is done with Amazon Translate, and is provided by Ruter as an artifact from Ruter AI Lab.\n\n\t\n\t\t\n\t\tDataset structure\n\t\n\nThe dataset is structured in the following way:\n{\n    \"instruction\": \"Norwegian instruction\",\n    \"input\": \"Norwegian input\",\n    \"output\": \"Norwegian output\",\n    \"instruction_en\": \"English instruction\",\n    \"input_en\": \"English input\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RuterNorway/OpenOrcaNo-15k.","url":"https://huggingface.co/datasets/RuterNorway/OpenOrcaNo-15k","creator_name":"Ruter","creator_url":"https://huggingface.co/RuterNorway","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"text2image-multi-prompt","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\ttext2image multi-prompt(s): a dataset collection\n\t\n\n\ncollection of several text2image prompt datasets\ndata was cleaned/normalized with the goal of removing \"model specific APIs\" like the \"--ar\" for Midjourney and so on\ndata de-duplicated on a basic level: exactly duplicate prompts were dropped (after cleaning and normalization)\n\n\n\t\n\t\t\n\t\tupdates\n\t\n\n\nOct 2023: the default config has been updated with better deduplication. It was deduplicated with minhash (params: n-gram size set to 3â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/text2image-multi-prompt.","url":"https://huggingface.co/datasets/pszemraj/text2image-multi-prompt","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","monolingual","bartman081523/stable-diffusion-discord-prompts","succinctly/midjourney-prompts"],"keywords_longer_than_N":true},
	{"name":"TinyOrca","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is a new curated subset of the SlimOpenOrca data. \n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{TinyOrca,\n  title = {TinyOrca: An Open Dataset of GPT-4 Augmented FLAN Reasoning Traces, with Verification},\n  author = {Prince Canuma},\n  year = {2024},\n  publisher = {HuggingFace},\n  url = {https://https://huggingface.co/prince-canuma/TinyOrca}\n}\n\n@misc{SlimOrca,\n  title = {SlimOrca: An Open Dataset of GPT-4 Augmented FLAN Reasoning Traces, with Verification},\n  author = {Wing Lian and Guanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prince-canuma/TinyOrca.","url":"https://huggingface.co/datasets/prince-canuma/TinyOrca","creator_name":"Prince Canuma","creator_url":"https://huggingface.co/prince-canuma","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Marathi_Handwritten","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Marathi Handwritten OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Marathi Handwritten Text Dataset is a collection of handwritten text images in Marathi (à¤¦à¥‡à¤µà¤¨à¤¾à¤—à¤°à¥€ à¤²à¤¿à¤ªà¥€),\naimed at supporting the development of Optical Character Recognition (OCR) systems, handwriting analysis tools,\nand language research.The dataset was curated from native Marathi speakers to ensure a variety of handwriting styles and character variations.\nThe dataset contains 2520 images with twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten.","url":"https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","image-feature-extraction","Marathi","mit"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entities-openai3-text-embedding-3-large-1536-1M","keyword":"feature-extraction","description":"1M OpenAI Embeddings: text-embedding-3-large 1536 dimensions\n\nCreated: February 2024. \nText used for Embedding: title (string) + text (string)\nEmbedding Model: OpenAI text-embedding-3-large\nThis dataset was generated from the first 1M entries of https://huggingface.co/datasets/BeIR/dbpedia-entity, extracted by @KShivendu_ here\n\n","url":"https://huggingface.co/datasets/Qdrant/dbpedia-entities-openai3-text-embedding-3-large-1536-1M","creator_name":"Qdrant","creator_url":"https://huggingface.co/Qdrant","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"new-dataset","keyword":"feature-extraction","description":"coasttmetal/new-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/coasttmetal/new-dataset","creator_name":"Matsumoto","creator_url":"https://huggingface.co/coasttmetal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"function-calling-small","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tæ•°æ®é›†å†…å®¹è¯´æ˜Ž:\n\t\n\nåŒ…å«700+ä¸ªé˜¿é‡Œäº‘OpenAPIçš„ä¿¡æ¯;åŒ…æ‹¬Dataworks,EMRï¼ŒDataLakeï¼ŒMaxcomputeï¼ŒHologram,å®žæ—¶è®¡ç®—Flinkç‰ˆï¼ŒQuickBI,DTSç­‰å¤šä¸ªäº§å“çš„å…¬å¼€Open APIä¿¡æ¯ã€‚\n\n\t\n\t\t\n\t\tæ ·ä¾‹\n\t\n\n{\n  \"systemPrompt\": ä½ æ˜¯ä¸€ä¸ªå‡½æ•°ç­›é€‰åŠ©ç†ï¼Œå¦‚æžœä¸Žé—®é¢˜ç›¸å…³çš„è¯,æ‚¨å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‡½æ•°æ¥èŽ·å–æ›´å¤šæ•°æ®ä»¥å›žç­”ç”¨æˆ·æå‡ºçš„é—®é¢˜:{\"function\": \"UpdateTicketNum\", \"description\": \"å¯¹ç”¨äºŽå…ç™»åµŒå…¥æŠ¥è¡¨çš„æŒ‡å®šçš„ticketè¿›è¡Œæ›´æ–°ç¥¨æ®æ•°é‡æ“ä½œã€‚\", \"arguments\": [{\"name\": \"Ticket\", \"type\": \"string\", \"description\": \"ä¸‰æ–¹åµŒå…¥çš„ç¥¨æ®å€¼ï¼Œå³URLä¸­çš„accessTicketå€¼ã€‚\"}, {\"name\": \"TicketNum\", \"type\": \"integer\", \"description\": \"ç¥¨æ®æ•°ã€‚\\n- å–å€¼èŒƒå›´ï¼š1~99998ï¼Œå»ºè®®å€¼ä¸º1ã€‚\"}]}{\"function\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Deepexi/function-calling-small.","url":"https://huggingface.co/datasets/Deepexi/function-calling-small","creator_name":"Deepexi Inc","creator_url":"https://huggingface.co/Deepexi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Chinese","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Traditional-Chinese","keyword":"feature-extraction","description":"ðŸ‹ OpenOrca-Chinese æ•°æ®é›†ï¼ðŸ‹\n\næ„Ÿè¬  Open-Orca/OpenOrca  è³‡æ–™é›†çš„ç™¼å¸ƒï¼Œç‚ºå»£å¤§NLPç ”ç©¶äººå“¡å’Œé–‹ç™¼è€…å¸¶ä¾†äº†å¯¶è²´çš„è³‡æºï¼\né€™æ˜¯ä¸€å€‹å°  Open-Orca/OpenOrca  è³‡æ–™é›†ä¸­æ–‡ç¿»è­¯çš„ç‰ˆæœ¬ï¼Œç¿»è­¯å¼•æ“Žç‚º Google ç¿»è­¯ï¼Œå¸Œæœ›èƒ½ç‚ºä¸­æ–‡ LLM ç ”ç©¶åšå‡ºä¸€é»žé»žè²¢ç»ã€‚\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lchakkei/OpenOrca-Traditional-Chinese.","url":"https://huggingface.co/datasets/lchakkei/OpenOrca-Traditional-Chinese","creator_name":"Lee Chak Kei","creator_url":"https://huggingface.co/lchakkei","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"rp_books-en","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"rp_books-en\"\n\t\n\nFiltering/cleaning on the 'red pajama books' subset of togethercomputer/Long-Data-Collections\nThe default config:\nDataset({\n    features: ['meta', 'text'],\n    num_rows: 26372\n})\n\n\n\t\n\t\t\n\t\ttoken count\n\t\n\n\n\t\n\t\t\n\t\tdefault\n\t\n\nGPT-4 tiktoken token count:\n        token_count\ncount  2.637200e+04\nmean   1.009725e+05\nstd    1.161315e+05\nmin    3.811000e+03\n25%    3.752750e+04\n50%    7.757950e+04\n75%    1.294130e+05\nmax    8.687685e+06\n\nTotal count:\t2662.85 Mâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/rp_books-en.","url":"https://huggingface.co/datasets/BEE-spoke-data/rp_books-en","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","fill-mask","togethercomputer/Long-Data-Collections","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"cqadupstack\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a preprocessed version of cqadupstack, to make it easily consumable via huggingface. The original dataset can be found here.\nCQADupStack is a benchmark dataset for community question-answering (cQA) research. It contains threads from twelve StackExchange1 subforums, annotated with duplicate question information and comes with pre-defined training, development, and test splits, both for retrieval and classificationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLukas22/cqadupstack.","url":"https://huggingface.co/datasets/LLukas22/cqadupstack","creator_name":"Lukas Kreussel","creator_url":"https://huggingface.co/LLukas22","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","feature-extraction","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"fiqa","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"cqadupstack\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a preprocessed version of fiqa, to make it easily consumable via huggingface. The original dataset can be found here.\nThe growing maturity of Natural Language Processing (NLP) techniques and resources is drastically changing the landscape of many application domains which are dependent on the analysis of unstructured data at scale. The financial domain, with its dependency on the interpretation of multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLukas22/fiqa.","url":"https://huggingface.co/datasets/LLukas22/fiqa","creator_name":"Lukas Kreussel","creator_url":"https://huggingface.co/LLukas22","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","cc-by-3.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dolphin-ru","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDolphin-ru ðŸ¬\n\t\n\nThis is translated version of ehartford/dolphin into Russian.\n","url":"https://huggingface.co/datasets/d0rj/dolphin-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"tajik-text-segmentation","keyword":"feature-extraction","description":"This dataset contains texts in Tajik language with sentence annotations. It can be used to train and evaluate sentence-wise text segmentation algorithms.\nThe dataset contains more than 100 short and long texts and more than 3000 annotated sentences. The texts were carefully selected from different catergories \nsuch as news, articles, novels, classical texts, poetry, and religious texts. It deliberately contains more of \"hard\" passages where splitting them by period \".\" characters would resultâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sobir-hf/tajik-text-segmentation.","url":"https://huggingface.co/datasets/sobir-hf/tajik-text-segmentation","creator_name":"sobir","creator_url":"https://huggingface.co/sobir-hf","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Tajik","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Pima","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Pima\n\t\n\nThe Pima dataset is a well-known data repository in the field of healthcare and machine learning. The dataset contains demographic, clinical and diagnostic characteristics of Pima Indian women and is primarily used to predict the onset of diabetes based on these attributes. Each data point includes information such as age, number of pregnancies, body mass index, blood pressure, and glucose concentration. Researchers and data scientists use the Pima dataset toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Genius-Society/Pima.","url":"https://huggingface.co/datasets/Genius-Society/Pima","creator_name":"Genius Society","creator_url":"https://huggingface.co/Genius-Society","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"LIFD_Seismic_Data","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for LFID Seismic Data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA description of the dataset:\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\ncoming soon - Kaggle links? \n\n\t\n\t\t\n\t\tData Fields\n\t\n\nSAC files\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nAll seismic data were downloaded through the IRIS Wilber 3 system (https://ds.iris.edu/wilber3/) or IRIS Web Services (https://service.iris.edu/), including the following seismic networks: (1) the AZ (ANZA; UC San Diego, 1982); (2) the TA (Transportable Array;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cemachelen/LIFD_Seismic_Data.","url":"https://huggingface.co/datasets/cemachelen/LIFD_Seismic_Data","creator_name":"Helen Burns","creator_url":"https://huggingface.co/cemachelen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-to-image","time-series-forecasting","object-detection","unconditional-image-generation"],"keywords_longer_than_N":true},
	{"name":"SlimOrca","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Isotonic/SlimOrca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a deduplicated version of Open-Orca/OpenOrca\nMinHash Deduplication with Jaccard Threshold = 0.80\nOriginal dataset size: 4233923\nNumber of duplicate clusters: 522077\nFiles in duplicate cluster: 2115143\nUnique files in duplicate cluster: 892638\nFiltered dataset size: 3011418\n\n","url":"https://huggingface.co/datasets/Isotonic/SlimOrca","creator_name":"Isotonic","creator_url":"https://huggingface.co/Isotonic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","table-question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-korean-subset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tlaion2B-multi-korean-subset\n\t\n\n\n\t\n\t\t\n\t\tAbout dataset\n\t\n\na subset data of laion/laion2B-multi, including only korean\n\n\t\n\t\t\n\t\tLisence\n\t\n\nCC-BY-4.0\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instance\n\t\n\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"Bingsu/laion2B-multi-korean-subset\")\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW', 'similarity'],\n        num_rows: 11376263â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset.","url":"https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"hermes-function-calling-v1","keyword":"feature-extraction","description":"\n\n\t\n\t\t\n\t\tHermes Function-Calling V1\n\t\n\nThis dataset is the compilation of structured output and function calling data used in the Hermes 2 Pro series of models.\nThis repository contains a structured output dataset with function-calling conversations, json-mode, agentic json-mode and structured extraction samples, designed to train LLM models in performing function calls and returning structured output based on natural language instructions. The dataset features various conversational scenariosâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NousResearch/hermes-function-calling-v1.","url":"https://huggingface.co/datasets/NousResearch/hermes-function-calling-v1","creator_name":"NousResearch","creator_url":"https://huggingface.co/NousResearch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"HelpSteer-hindi","keyword":"feature-extraction","description":"SherryT997/HelpSteer-hindi dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SherryT997/HelpSteer-hindi","creator_name":"Sherry Thomas","creator_url":"https://huggingface.co/SherryT997","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"AI-Dictionary","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAI Dictionary Dataset\n\t\n\nWelcome to the AI Dictionary dataset on HuggingFace. This dataset is a comprehensive tool comprised of 16,665 unique key phrases that describe the whole domain of Artificial Intelligence (AI). It serves both the research community and industry domains, aiding in the identification of radical innovations and uncovering applications of AI in new domains.\nThis dataset is the result of the research paper \"The AI Dictionary: The Foundation for a Text-Based Tool toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/J0nasW/AI-Dictionary.","url":"https://huggingface.co/datasets/J0nasW/AI-Dictionary","creator_name":"Jonas Wilinski","creator_url":"https://huggingface.co/J0nasW","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TACO-hf","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/TACO-hf\n\t\n\nSimple re-host of https://huggingface.co/datasets/BAAI/TACO but saved as hf dataset for ease of use.\nFeatures:\nDatasetDict({\n    \"train\": Dataset({\n        \"features\": [\n            \"question\",\n            \"solutions\",\n            \"starter_code\",\n            \"input_output\",\n            \"difficulty\",\n            \"raw_tags\",\n            \"name\",\n            \"source\",\n            \"tags\",\n            \"skill_types\",\n            \"url\",\n            \"Expected Auxiliaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/TACO-hf.","url":"https://huggingface.co/datasets/BEE-spoke-data/TACO-hf","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","BAAI/TACO","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MTS_Dialogue-Clinical_Note","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMTS Dialogue (Clinical Note Summarisation)\n\t\n\nMain Dataset\nThe MTS-Dialog dataset is a new collection of 1.7k short doctor-patient conversations and corresponding summaries (section headers and contents).\nThe training set consists of 1,201 pairs of conversations and associated summaries.\nThe validation set consists of 100 pairs of conversations and their summaries.\nThe \"dialogue\" column contain Doctor-Patient conversation. The \"section_text\" column contains the Clinical Note of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/har1/MTS_Dialogue-Clinical_Note.","url":"https://huggingface.co/datasets/har1/MTS_Dialogue-Clinical_Note","creator_name":"Harikrishnan KC","creator_url":"https://huggingface.co/har1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Tuberculosis_Dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMultimodal Dataset of Tuberculosis Patients including CT and Clinical Case Reports\n\t\n\nZhankai Ye    \nNetID: zy172\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is curated from the original â€œThe MultiCaRe Datasetâ€ to focus on the chest tuberculosis patients. This is a multimodal dataset consisting of lung computed tomography (CT) imaging data and the clinical case records of tuberculosis patients, along with their case keywords, the captions of their CT images, patient_id, gender, and ageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset.","url":"https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset","creator_name":"Zhankai Ye","creator_url":"https://huggingface.co/moukaii","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"FATURA2-invoices","keyword":"feature-extraction","description":"The dataset consists of 10000 jpg images with white backgrounds, 10000 jpg images with colored backgrounds (the same colors used in the paper) as well as 3x10000 json annotation files. The images are generated from 50 different templates.\nhttps://zenodo.org/records/10371464\n\n\n\t\n\t\n\t\n\t\tdataset_info:\n  features:\n  - name: image\n    dtype: image\n  - name: ner_tags\n    sequence: int64\n  - name: words\n    sequence: string\n  - name: bboxes\n    sequence:\n      sequence: int64\n  splits:\n  - name: trainâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mathieu1256/FATURA2-invoices.","url":"https://huggingface.co/datasets/mathieu1256/FATURA2-invoices","creator_name":"Mathieu Goedhart","creator_url":"https://huggingface.co/mathieu1256","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"northwind_PurchaseOrders","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tPurchase Orders Dataset\n\t\n\nThis dataset consists of purchase orders from various companies. It was created by CHERGUELAINE Ayoub & BOUBEKRI Faycal  with the help of ChatGPT for the purpose of document classification and analytics.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe dataset contains a collection of purchase orders from different companies. Each purchase order consists of the following fields:\norder_id: The unique identifier for the purchase order.\norder_date: The date on which the purchaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AyoubChLin/northwind_PurchaseOrders.","url":"https://huggingface.co/datasets/AyoubChLin/northwind_PurchaseOrders","creator_name":"ayoub cherguelaine","creator_url":"https://huggingface.co/AyoubChLin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Coil100-Augmented","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset derives from Coil100. \nThere are more than 1,1M images of 100 objects. Each object was turned on a turnable through 360 degrees to vary object pose with respect to a fixed color camera. Images of the objects were taken at pose intervals of 5 degrees. This corresponds to 72 poses per object. \nIn addition to the original dataset, planar rotation (9 angles) and  18 scaling factors have been applied so that there are no dependencies between factors.\nObjectsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dappu97/Coil100-Augmented.","url":"https://huggingface.co/datasets/dappu97/Coil100-Augmented","creator_name":"Jacopo Dapueto","creator_url":"https://huggingface.co/dappu97","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","image-to-3d","image-segmentation","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-690454","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-690454 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-690454 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-690454.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-690454","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-690454","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-690454 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-690454 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-690454.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-690454","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Arabic-Triplet-With-Multi-Negatives","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArabic Triplet with Multi Negatives\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a modified version of the Arabic subset of the Mr. TyDi dataset, tailored for retrieval and re-ranking tasks. The original dataset has been restructured by splitting the negative passages into separate fields (negative1, negative2, ..., negativeN) for each query. This modification allows more flexibility for training and evaluating retrieval and re-ranking models.\nThe dataset retains the original intentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Arabic-Triplet-With-Multi-Negatives.","url":"https://huggingface.co/datasets/NAMAA-Space/Arabic-Triplet-With-Multi-Negatives","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"plaindetector","keyword":"feature-extraction","description":"CoruNethron/plaindetector dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/CoruNethron/plaindetector","creator_name":"Denis Golovkin","creator_url":"https://huggingface.co/CoruNethron","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"entity_type_hi_pilener","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for entity_type_hi_pilener\n\t\n\n\n\nentity_type_hi_pilener is a translated, filtered and corrected version of Pile-NER-type\n\n\t\n\t\t\n\t\t5 step processing on Pile-NER-type\n\t\n\n\nstep1: Removed all Entities whose source text is not in English using langdetect.\nstep2: Removed all Entity Type that are not in English using fast-langdetect.\nstep3: Translated all Entity Type to Hindi using indictrans2-en-indic-1B with greedy_sampling(num_beams=1, do_sample=False).\nstep4: Removed allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nis12ram/entity_type_hi_pilener.","url":"https://huggingface.co/datasets/nis12ram/entity_type_hi_pilener","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Hindi","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting search engine for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting search engine for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"digital_signatures","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDigital Signatures Dataset\n\t\n\nThis dataset contains unique synthetic digital signatures rendered in different fonts:\n\n4,000 synthetic signatures in Rage font\n\n4,000 synthetic signatures in Mistral font\n2,000 synthetic signatures in Arial Unicode font\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nFor the development of models that can detect digital signatures in documentation using the publicly available DocusignÂ® font styles.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is organized into three folders:\n\nrage/ - Containsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Benjy/digital_signatures.","url":"https://huggingface.co/datasets/Benjy/digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-23052024-hbdj-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-23052024-hbdj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"test run search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-23052024-hbdj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-23052024-hbdj-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-23052024-hbdj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"test run search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-23052024-hbdj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"clear-ru-translated","keyword":"feature-extraction","description":"This is the translated from English to Russian CLEAR Corpus. Link to original corpus: https://github.com/scrosseye/CLEAR-Corpus .For translation we used Qwen2.5-72B-Instruct-GPTQ-Int4 to translate the corpus.Our prompt was: \n  {\"role\": \"system\", \"content\": \"You are a helpful assistant. You are a good translator from English to Russian.\"},\n  {\"role\": \"user\", \"content\": content}\n\n","url":"https://huggingface.co/datasets/v-urushkin/clear-ru-translated","creator_name":"Victor Urushkin","creator_url":"https://huggingface.co/v-urushkin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Russian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"BioMedGraphica","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBioMedGraphica\n\t\n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n    \n  \n\n\nBioMedGraphica is an all-in-one platform for biomedical data integration and knowledge graph generation. It harmonizes fragmented biomedical datasets into a unified, graph AI-ready resource that facilitates precision medicine, therapeutic target discovery, and integrative biomedical AI research.\nDeveloped using data from 43 biomedical databases, BioMedGraphica integrates:\n\n11 entity types\n30 relation types\nOverâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FuhaiLiAiLab/BioMedGraphica.","url":"https://huggingface.co/datasets/FuhaiLiAiLab/BioMedGraphica","creator_name":"FuhaiLiAiLab","creator_url":"https://huggingface.co/FuhaiLiAiLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["graph-ml","token-classification","feature-extraction","other","expert-generated"],"keywords_longer_than_N":true},
	{"name":"MOLE","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMOLE: Metadata Extraction and Validation in Scientific Papers\n\t\n\nMOLE is a dataset for evaluating and validating metadata extracted from scientific papers. The paper can be found here.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‹ Dataset Structure\n\t\n\nThe main datasets attributes are shown below. Also for earch feature there is binary value attribute_exist. The value is 1 if the attribute is retrievable form the paper, otherwise it is 0. \n\nName (str): What is the name of the dataset?\nSubsets (List[Dict[Name, Volumeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IVUL-KAUST/MOLE.","url":"https://huggingface.co/datasets/IVUL-KAUST/MOLE","creator_name":"Image and Video Understanding Lab","creator_url":"https://huggingface.co/IVUL-KAUST","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","French","jp"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-562024-j4ar-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-562024-j4ar-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"software documentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-j4ar-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-562024-j4ar-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-562024-j4ar-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"software documentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-j4ar-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-982705","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-982705 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-982705 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-982705.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-982705","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-982705","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-982705 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-982705 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-982705.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-982705","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"Think-Observe","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tThink-Observe Dataset\n\t\n\nWelcome to the Think-Observe dataset! This dataset is designed to fine-tune Large Language Models (LLMs) to improve their accuracy and ability to reflect before providing answers. It includes a collection of questions and answers tagged with think and observe tags.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe Think-Observe dataset consists of pairs of questions and answers, with each entry tagged to signify its role in the model's training process:\n\nthink: This tag is usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayush-thakur02/Think-Observe.","url":"https://huggingface.co/datasets/ayush-thakur02/Think-Observe","creator_name":"Ayush Thakur","creator_url":"https://huggingface.co/ayush-thakur02","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","feature-extraction","text2text-generation"],"keywords_longer_than_N":true},
	{"name":"merged_bigvul_primevul","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMerged BigVul and PrimeVul Dataset\n\t\n\nDataset ID: mahdin70/merged_bigvul_primevul\nThis dataset is a merged and preprocessed combination of the BigVul (bstee615/bigvul) and PrimeVul (colin/PrimeVul, \"default\" configuration) datasets, designed for vulnerability analysis and machine learning tasks. The preprocessing ensures consistency in column names, data types, and formats, making it suitable for fine-tuning models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\nThe dataset integrates vulnerabilityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mahdin70/merged_bigvul_primevul.","url":"https://huggingface.co/datasets/mahdin70/merged_bigvul_primevul","creator_name":"Mukit Mahdin","creator_url":"https://huggingface.co/mahdin70","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ELNER-DZ","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tELNER-DZ: Algerian Arabic Dataset for Named Entity Recognition and Entity Linking\n\t\n\nThis dataset, titled ELNER-DZ, was created by Bouguettoucha Hadjer Hanine and Djouablia Ilhem as part of our Masterâ€™s thesis . It is the first large-scale dataset designed for Named Entity Recognition (NER) and Entity Linking (EL) in Algerian Arabic Dialect (Darija), including both Arabic script and Arabizi (Latin-script).\nThis dataset contains over 2 million dialectal sentences labeled with more thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HadjerHaninebgt7878/ELNER-DZ.","url":"https://huggingface.co/datasets/HadjerHaninebgt7878/ELNER-DZ","creator_name":"Hanine_Bgt","creator_url":"https://huggingface.co/HadjerHaninebgt7878","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-497939","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-497939 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-497939 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-497939.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-497939","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-497939","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-497939 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-497939 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-497939.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-497939","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting forum search engine for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting forum search engine for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ave-2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAVE-2: AudioVisual Event Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAVE-2 is a comprehensive dataset featuring 570,138 audio-visual clips with detailed five-dimensional alignment quality annotations. This dataset enables systematic investigation of how alignment quality affects multimodal model performance across retrieval and generation tasks.\n\n\t\n\t\t\n\t\tðŸŒŸ Key Features\n\t\n\n\nðŸŽ¬ 570k+ annotated clips with granular quality scores (0-10 scale)\nðŸ“ Five-dimensional scoring: temporalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ali-vosoughi/ave-2.","url":"https://huggingface.co/datasets/ali-vosoughi/ave-2","creator_name":"Ali Vosoughi","creator_url":"https://huggingface.co/ali-vosoughi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","visual-question-answering","text-to-audio","text-to-speech","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"DRIFT","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tThe DRIFT (Domain-Adaptive Regression for Forest Monitoring) dataset\n\t\n\nDataset download link: https://sid.erda.dk/share_redirect/f1Hmpeh6O2\nProject page: https://dgominski.github.io/drift/\nGitHub page: https://github.com/sizhuoli/Domain_adaptive_regression_with_ordered_embedding_space\nPublication: ECCV 2024 proceeding: Get Your Embedding Space in Order: Domain-Adaptive Regression for Forest Monitoring (https://arxiv.org/abs/2405.00514)\n\n\n\t\n\t\n\t\n\t\tDescription\n\t\n\nThe DRIFT datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sizhuoli/DRIFT.","url":"https://huggingface.co/datasets/sizhuoli/DRIFT","creator_name":"Sizhuo Li","creator_url":"https://huggingface.co/sizhuoli","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"MVCap-4M","keyword":"feature-extraction","description":"\n  Omniview-Tuning: Boosting Viewpoint Invariance of Vision-Language Pre-training Models\n  \n    Shouwei Ruan, \n    Yinpeng Dong, \n    Hanqing Liu, Yao Huang, \n    Hang Su and \n    Xingxing Wei.\n  \n\n\n\n\n\n  \n    \n  \n  \n    \n    \n  \n  \n    \n  \n\n\nThis repo releases the MVCap-4M dataset introduced in our paper: \"Omniview-Tuning: Boosting Viewpoint Invariance of Vision-Language Pre-training Models\" (ECCV2024)\nMulti-View Caption (MVCap-4M) is a large-scale dataset tailored for viewpoint invarianceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RSW233/MVCap-4M.","url":"https://huggingface.co/datasets/RSW233/MVCap-4M","creator_name":"RSW","creator_url":"https://huggingface.co/RSW233","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","feature-extraction","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"abscorrespondance","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAustralian Geographic Correspondence Table (ABS ASGS Edition 3)\n\t\n\nA comprehensive correspondence table linking Australian geographic hierarchies (POA â†” LGA â†” SA2 â†” Branch Catchments) built using real Australian Bureau of Statistics (ABS) data.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides complete spatial correspondence relationships between different levels of the Australian Statistical Geography Standard (ASGS) Edition 3, enabling accurate feature aggregation and geographicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/massomo/abscorrespondance.","url":"https://huggingface.co/datasets/massomo/abscorrespondance","creator_name":"Massimo Raso","creator_url":"https://huggingface.co/massomo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","tabular-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-3778","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-3778 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-3778 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-3778","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-3778 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-3778 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"aesthetics-wiki","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset is webscraped version of aesthetics-wiki. There are 1022 aesthetics captured.\n\n\t\n\t\t\n\t\tColumns + dtype\n\t\n\n\ntitle: str\ndescription: str (raw representation, including \\n because it could help in structuring data)\nkeywords_spacy: str (['NOUN', 'ADJ', 'VERB', 'NUM', 'PROPN'] keywords extracted from description with POS from Spacy library)\nremoved weird characters, numbers, spaces, stopwords\n\n\n\n\n\t\n\t\t\n\t\tCleaning\n\t\n\nStandard Pandas cleaning\n\nCleaned the data byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ninar12/aesthetics-wiki.","url":"https://huggingface.co/datasets/ninar12/aesthetics-wiki","creator_name":"Nina Rhone","creator_url":"https://huggingface.co/ninar12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-15052024-stsl-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-15052024-stsl-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical classification search for HVAC equipment and parts\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-15052024-stsl-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-15052024-stsl-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-15052024-stsl-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-15052024-stsl-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-15052024-stsl-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical classification search for HVAC equipment and parts\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-15052024-stsl-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-15052024-stsl-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-15052024-stsl-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information retrieval for symbols ASK in Norwegian language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Norwegian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information retrieval for symbols ASK in Norwegian language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Norwegian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-115380","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-512-192-gpt-4o-2024-05-13-115380 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-115380 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-115380.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-115380","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-115380","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-512-192-gpt-4o-2024-05-13-115380 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-115380 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-115380.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-115380","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-128-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-1752024-13s3-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-1752024-13s3-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical and biomedical sciences knowledge base\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-1752024-13s3-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-13s3-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-13s3-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-1752024-13s3-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-1752024-13s3-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical and biomedical sciences knowledge base\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-1752024-13s3-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-13s3-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-13s3-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Ko-En","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOpenOrca-Ko-En\n\t\n\n\nkyujinpy/OpenOrca-KOì™€ Open-Orca/OpenOrcaë¥¼ ê³µí†µëœ ë°ì´í„°ë§Œ í•„í„°ë§í•˜ê³  í•©ì¹œ ë°ì´í„°ì…‹ìž…ë‹ˆë‹¤.\nì»¬ëŸ¼ì€ ê¸°ì¡´ OpenOrcaì— ë§žì¶°ì„œ system_prompt_{ko/en}, question_{ko/en}, response_{ko/en} ìœ¼ë¡œ ë³€ê²½í•˜ì˜€ìŠµë‹ˆë‹¤.\nì¤‘ë³µëœ idë¥¼ ì œê±°í•˜ì—¬ ë°ì´í„°ìˆ˜ê°€ ì¼ë¶€ ê°ì†Œí•˜ì˜€ìŠµë‹ˆë‹¤.\në°ì´í„°ì…‹ì„ ë§Œë“œëŠ”ë° ì‚¬ìš©í•œ ìŠ¤í¬ë¦½íŠ¸ìž…ë‹ˆë‹¤.\në°ì´í„°ì…‹ ì´ìš©í•˜ì…”ì„œ ëª¨ë¸ì´ë‚˜ ë°ì´í„°ì…‹ì„ ë§Œë“œì‹¤ ë•Œ, ì´ ë°ì´í„°ì…‹ë¿ë§Œ ì•„ë‹ˆë¼ ìœ„ ë°ì´í„°ì…‹ë„ í•¨ê»˜ ì¶œì²˜í‘œê¸°ë¥¼ í•´ì£¼ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset inf0\n\t\n\n\nNIV // 1551ê°œ(OpenOrca-KO: 1571ê°œ)  \nFLAN // 9338ê°œ(OpenOrca-KO: 9434ê°œ)\nT0 // 6303ê°œ(OpenOrca-KO: 6351ê°œ)\nCoT // 2092ê°œ(OpenOrca-KO: 2117ê°œ)\nKoCoT // 2159ê°œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/appleparan/OpenOrca-Ko-En.","url":"https://huggingface.co/datasets/appleparan/OpenOrca-Ko-En","creator_name":"Jongsu Kim","creator_url":"https://huggingface.co/appleparan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"docs_on_several_languages","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"docs_on_several_languages\"\n\t\n\nThis dataset is a collection of different images in different languages.\nThe daset includes the following languages: Azerbaijani (az: 0), Belorussian (be: 1), Chinese (zh: 16), English (en: 2), Estonian (et: 3), Finnish (fn: 4), Georgian (gr: 5), Japanese (ja: 6), Korean (ko: 7), Kazakh (kk: 8), Latvian (lv: 10), Lithuanian (lt: 9), Mongolian (mn: 11), Norwegian (no: 12), Polish (pl: 13), Russian (ru: 14), Ukranian (uk: 15).\nEach languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages.","url":"https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","feature-extraction","Azerbaijani","Belarusian"],"keywords_longer_than_N":true},
	{"name":"resume-skills-matcher","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tResume Skills Matcher Dataset\n\t\n\nDataset for matching job requirements with resume skills. Enables automated skill gap analysis and resume optimization for job applications.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains job descriptions paired with relevant skills, enabling skills matching algorithms for resume optimization and job fit analysis.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\njob_title: Position title\ncompany_type: Type of company (startup, enterprise, etc.)\nrequired_skills: Coreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anixlynch/resume-skills-matcher.","url":"https://huggingface.co/datasets/anixlynch/resume-skills-matcher","creator_name":"Anix Lynch","creator_url":"https://huggingface.co/anixlynch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","feature-extraction","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ScienceGlossary-NER_fit","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Science Terms and Phrases Glossary\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains scientific terms and phrases from various disciplines, compiled from multiple sources. \nIt expands on the dataset JonyC/ScienceGlossary.\nEach term is paired with 3â€“4 sentences that demonstrate its usage or provide a definition. These example sentences were generated using google/flan-t5-xl.\nAll sentences are tokenized using spaCy for optimal token alignment during NER training. Eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JonyC/ScienceGlossary-NER_fit.","url":"https://huggingface.co/datasets/JonyC/ScienceGlossary-NER_fit","creator_name":"Jonatan Cohen","creator_url":"https://huggingface.co/JonyC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","feature-extraction","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific articles\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific articles\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CodeEval","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCodeEval Dataset\n\t\n\n\n\t\n\t\t\nLanguage\nCount\n\n\n\t\t\nPython\n50\n\n\nJavaScript\n40\n\n\nJava\n40\n\n\nRuby\n20\n\n\nC++\n20\n\n\nTypeScript\n10\n\n\nGo\n20\n\n\nC#\n10\n\n\nRust\n10\n\n\nTotal\n220\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tCorrectness Statistics\n\t\n\n\n\t\n\t\t\nCorrectness\nCount\n\n\n\t\t\nTrue\n127\n\n\nFalse\n93\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset is structured as follows:\n[\n    {\n        \"language\": \"python\",\n        \"code\": \"def reverse_string(s):\\n    return s.reverse()\",\n        \"correctness\": false,\n        \"explanation\": \"incorrectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chungimungi/CodeEval.","url":"https://huggingface.co/datasets/chungimungi/CodeEval","creator_name":"Aarush","creator_url":"https://huggingface.co/chungimungi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","feature-extraction","text2text-generation"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"image-feature-extraction","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"tomato-leaves-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTomato Leaves Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains images of tomato leaves categorized into different classes based on the type of disease or health condition. The dataset is divided into training, validation, and test sets, with a ratio of 8:1:1. The classes include various diseases as well as healthy leaves. The dataset includes both augmented and non-augmented images.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized into three main splits:\n\ntrain\nvalidation\ntestâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lorenzoxi/tomato-leaves-dataset.","url":"https://huggingface.co/datasets/lorenzoxi/tomato-leaves-dataset","creator_name":"Lorenzo","creator_url":"https://huggingface.co/lorenzoxi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-classification","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"feature-extraction","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Chemical and Laboratory Equipment Pricing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Chemical and Laboratory Equipment Pricing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"IBMR","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tIBMR Dataset: Insulator Burn Mark RGB-Point Cloud Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe full version of this dataset will be released upon acceptance of the accompanying publication.\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\nIBMR/\nâ”‚\nâ”œâ”€â”€ Sample 1/\nâ”‚   â”œâ”€â”€ sample-1.png\nâ”‚   â”œâ”€â”€ sample-1.pcd\nâ”‚   â””â”€â”€ GT/\nâ”‚       â”œâ”€â”€ insulator-1.txt\nâ”‚       â””â”€â”€ burn_mark-1.txt\nâ”œâ”€â”€ Sample 2/\nâ”‚   â”œâ”€â”€ sample-2.png\nâ”‚   â”œâ”€â”€ sample-2.pcd\nâ”‚   â””â”€â”€ GT/\nâ”‚       â”œâ”€â”€ insulator-2.txt\nâ”‚       â””â”€â”€ burn_mark-2.txt\nâ””â”€â”€ ...\n\n","url":"https://huggingface.co/datasets/Junqiu-Tang/IBMR","creator_name":"Junqiu Tang","creator_url":"https://huggingface.co/Junqiu-Tang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1M - 10M","text"],"keywords_longer_than_N":true},
	{"name":"danbooru_wikis_full","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDanbooru Full Wiki Dataset\n\t\n\nThis is the full wiki dataset of danbooru.donmai.us, containing the wiki pages/tags/tag aliases/tag implications. You can train something like LLMs on this dataset\n\n\t\n\t\t\n\t\tInformation\n\t\n\n\n\t\n\t\t\n\t\tWiki Pages\n\t\n\nThere are 189161 wiki items in total. Last updated at 2024-06-16 02:31:27 UTC.\nThese are the information of recent 50 wiki items:\n\n\t\n\t\t\nid\ntitle\nother_names\ntext_length\nis_locked\nis_deleted\ncreated_at\nupdated_at\n\n\n\t\t\n196503\nli_yuting_(female)\n[\"ç¦»é›¨å©·\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru_wikis_full.","url":"https://huggingface.co/datasets/deepghs/danbooru_wikis_full","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"DS569k","keyword":"feature-extraction","description":"Want to analyze some proteins, but lack embeddings? Want to perform vector similarity search? Want a context of known proteins embeddings? Look no further!\nThis repository is a dataset of Reviewed Swiss-Prot Proteins. Each protein I compute the embeddings for ESM2 (6 layer model) and ProteinCLIP. \n\n\t\n\t\t\n\t\n\t\n\t\tSpecs\n\t\n\nSee the data viewer for all information. Most of the metadata on each protein and the sequences themself come from Reviewed Swiss-Prot Proteins.\nImportant columns\n\naccession: theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/donnyb/DS569k.","url":"https://huggingface.co/datasets/donnyb/DS569k","creator_name":"Donny Bertucci","creator_url":"https://huggingface.co/donnyb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-512-192-gpt-4o-2024-05-13-439294","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-512-192-gpt-4o-2024-05-13-439294 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-512-192-gpt-4o-2024-05-13-439294 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-439294.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-439294","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-512-192-gpt-4o-2024-05-13-439294","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-512-192-gpt-4o-2024-05-13-439294 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-512-192-gpt-4o-2024-05-13-439294 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-439294.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-439294","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"job-titles","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tComprehensive Job Titles Dataset\n\t\n\nA high-quality, deduplicated dataset of 65,248 unique job titles compiled from authoritative sources including ESCO (European Skills, Competences, Qualifications and Occupations), O*NET (Occupational Information Network), and OSCA (Occupational Skills and Competencies Australia).\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides a comprehensive collection of job titles that have been carefully processed to remove duplicates and near-duplicatesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gpriday/job-titles.","url":"https://huggingface.co/datasets/gpriday/job-titles","creator_name":"Greg Priday","creator_url":"https://huggingface.co/gpriday","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wine-images-126k","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tWine Images Dataset 126K\n\t\n\nA comprehensive dataset of 107,821 wine bottle images linked to the Wine Text Dataset 126K. This companion dataset provides high-quality wine bottle images for computer vision, multimodal machine learning, and wine recognition tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains wine bottle images scraped from wine retailer websites. Each image is linked to detailed wine information (descriptions, pricing, categories, regions) via stable IDs thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cipher982/wine-images-126k.","url":"https://huggingface.co/datasets/cipher982/wine-images-126k","creator_name":"David Rose","creator_url":"https://huggingface.co/cipher982","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","image-to-text","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Instruct2DS","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mtybilly/Instruct2DS.","url":"https://huggingface.co/datasets/mtybilly/Instruct2DS","creator_name":"Tianyi (Billy) Ma","creator_url":"https://huggingface.co/mtybilly","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"flickr-10K","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFlickr-10k dataset\n\t\n\nThis dataset is subset of original dataset of Flickr-30K dataset and contains additional generated caption using Janus-Pro  from Deepseek. This gives an additional captions generated captions column to use.\nOriginal size of dataset is more than 4 GBs but this dataset contains images and all other columns inside it still its just 700 MBs, this is because it was originally stored in Lance format.\n\n\n\t\n\t\n\t\n\t\tWhat is Flickr30k dataset?TheÂ Flickr30k datasetÂ is a popularâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PrashantDixit0/flickr-10K.","url":"https://huggingface.co/datasets/PrashantDixit0/flickr-10K","creator_name":"Prashant Dixit","creator_url":"https://huggingface.co/PrashantDixit0","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","zero-shot-classification","sentence-similarity","text-generation"],"keywords_longer_than_N":true},
	{"name":"malagasy-sentence","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset consists of clean, structured sentences extracted via Optical Character Recognition (OCR) from approximately 1GB of Malagasy thesis documents. These documents were collected based on educational, cultural, and linguistic themes.\nThe dataset is saved in CSV format, and is particularly useful for NLP tasks involving sentence-level modeling in Malagasy â€” a low-resource language.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\nLanguage: Malagasy\nSource: OCR'd academic thesisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lo-Renz-O/malagasy-sentence.","url":"https://huggingface.co/datasets/Lo-Renz-O/malagasy-sentence","creator_name":"Lorenzo Mamelona","creator_url":"https://huggingface.co/Lo-Renz-O","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Malagasy","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"LawDual-Bench","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLawDual-Bench: A Dual-Task Benchmark and Chain-of-Thought Impact Study for Legal Reasoning\n\t\n\n\n  \n\n\néšç€å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMsï¼‰åœ¨æ³•å¾‹åº”ç”¨ä¸­çš„å¿«é€Ÿå‘å±•ï¼Œç³»ç»Ÿè¯„ä¼°å…¶åœ¨æ³•å¾‹æ–‡æ¡£å¤„ç†å’Œåˆ¤å†³é¢„æµ‹ä¸­çš„æŽ¨ç†èƒ½åŠ›å˜å¾—å°¤ä¸ºè¿«åˆ‡ã€‚ç›®å‰å…¬å¼€çš„æ³•å¾‹æµ‹è¯„åŸºå‡†ç¼ºå°‘ç»Ÿä¸€çš„è¯„ä¼°æž¶æž„ï¼Œå¯¹è¿™ä¸¤ä¸ªä»»åŠ¡çš„æ”¯æŒå¹¶ä¸å¥½ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº† LawDual-Benchï¼Œå¡«è¡¥äº†ä¸­æ–‡æ³•å¾‹è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸä¸­ç»“æž„åŒ–æŽ¨ç†è¯„ä¼°çš„å…³é”®ç©ºç™½ï¼Œå¹¶ä¸ºæ³•å¾‹åž‚ç±»å¤§æ¨¡åž‹ç³»ç»Ÿçš„è¯„ä¼°ä¸Žä¼˜åŒ–æä¾›äº†åšå®žåŸºç¡€ã€‚æ›´å¤šè¯¦æƒ…å¯æŸ¥çœ‹æˆ‘ä»¬çš„è®ºæ–‡ã€‚\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“„ ä»‹ç»\n\t\n\nLawDual-Bench ç»ç²¾å¿ƒè®¾è®¡ï¼Œå¯ä»¥å¯¹å¤§æ¨¡åž‹çš„æ³•å¾‹æ–‡æ¡£ç†è§£å’Œæ¡ˆæƒ…åˆ†æžæŽ¨ç†èƒ½åŠ›è¿›è¡Œç²¾ç¡®è¯„ä¼°ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€å¥—åŠè‡ªåŠ¨åŒ–çš„æ•°æ®é›†æž„å»ºæ–¹æ¡ˆï¼Œé€šè¿‡äººå·¥+LLMçš„æ–¹å¼ï¼Œæž„å»ºäº†ä¸€ä¸ªå…¨é¢çš„å†…å¹•äº¤æ˜“æ•°æ®é›†ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥å¾ˆè½»æ˜“åœ°æ‰©å±•æ•°æ®é›†çš„æ•°é‡ä¸Žæ¡ˆæƒ…çš„ç§ç±»ã€‚å†æ¬¡åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬è®¾è®¡äº†ç»“æž„åŒ–ä¿¡æ¯æŠ½å– å’Œ æ¡ˆä»¶äº‹å®žåˆ†æžä¸Žåˆ¤å†³é¢„æµ‹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yuwh07/LawDual-Bench.","url":"https://huggingface.co/datasets/Yuwh07/LawDual-Bench","creator_name":"ä¿žæ–‡ç€š","creator_url":"https://huggingface.co/Yuwh07","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Corrosion_Rust","keyword":"feature-extraction","description":"BinKhoaLe1812/Corrosion_Rust dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/BinKhoaLe1812/Corrosion_Rust","creator_name":"LÃª ÄÄƒng Khoa (Liam)","creator_url":"https://huggingface.co/BinKhoaLe1812","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"alpaca_ccass_motivations_sommaires_titres","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTraining dataset for summarizing and titling decisions of the French Court of cassation based on motivations\n\t\n\nThis alpaca-format dataset is designed to train models for summarizing and titling French Supreme Court decisions based on the grounds of them. Created with a view to producing metadata for decisions not published in the bulletin, this dataset aims to simplify the development of annotation and categorization tools, and is positioned as a facilitator for jurisprudentialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cour-de-cassation/alpaca_ccass_motivations_sommaires_titres.","url":"https://huggingface.co/datasets/Cour-de-cassation/alpaca_ccass_motivations_sommaires_titres","creator_name":"Cour de cassation","creator_url":"https://huggingface.co/Cour-de-cassation","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","feature-extraction","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Telugu-NLP-AI-Dialect-Comedy-video-Dataset","keyword":"feature-extraction","description":"This is a data set collected from web sources for telugu dialect or slang classification.\nYou can download the data here and use the data provided and perform bulk data actions.\n","url":"https://huggingface.co/datasets/AUTTRIBE/Telugu-NLP-AI-Dialect-Comedy-video-Dataset","creator_name":"AUTTRIBE","creator_url":"https://huggingface.co/AUTTRIBE","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Telugu","English","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"Colors","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nA dataset that contains the color names and their relations with their respective RGB Values with over 40k rows.\n\n\n\nRepository: Generation-of-Colors-using-BiLSTMs\nCitation:\n\n  @misc{sinha2023generation,\n      title={Generation Of Colors using Bidirectional Long Short Term Memory Networks}, \n      author={A. Sinha},\n      year={2023},\n      eprint={2311.06542},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n\n","url":"https://huggingface.co/datasets/chungimungi/Colors","creator_name":"Aarush","creator_url":"https://huggingface.co/chungimungi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","zero-shot-classification","question-answering","table-question-answering"],"keywords_longer_than_N":true},
	{"name":"mmBERT-pretrain-p1-fineweb2-langs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tmmBERT Pre-training Data P1\n\t\n\n\n\n\n\n\nPhase 1 of 3: Diverse multilingual pre-training data mixture (trained for 2.3T tokens) used to train the mmBERT model suite.\n\nNOTE: this is only P1 of the pre-training data due to HF limits, you need to download and combine all three into one folderThis dataset contains the pre-training phase data used to train all mmBERT encoder models. The data is provided in MDS format ready for use with Composer and the ModernBERT training repository.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/mmBERT-pretrain-p1-fineweb2-langs.","url":"https://huggingface.co/datasets/jhu-clsp/mmBERT-pretrain-p1-fineweb2-langs","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","feature-extraction","multilingual","mit","arxiv:2509.06888"],"keywords_longer_than_N":true},
	{"name":"mmBERT-pretrain-p1-fineweb2-langs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tmmBERT Pre-training Data P1\n\t\n\n\n\n\n\n\nPhase 1 of 3: Diverse multilingual pre-training data mixture (trained for 2.3T tokens) used to train the mmBERT model suite.\n\nNOTE: this is only P1 of the pre-training data due to HF limits, you need to download and combine all three into one folderThis dataset contains the pre-training phase data used to train all mmBERT encoder models. The data is provided in MDS format ready for use with Composer and the ModernBERT training repository.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/mmBERT-pretrain-p1-fineweb2-langs.","url":"https://huggingface.co/datasets/jhu-clsp/mmBERT-pretrain-p1-fineweb2-langs","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","feature-extraction","multilingual","mit","arxiv:2509.06888"],"keywords_longer_than_N":true},
	{"name":"ru-filtered-web-captions","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDiTy/ru-filtered-web-captions\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nThis is a translated RussianÂ part of the filtered web captions.\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{\n    'caption': 'gladiator standing in a smoke with torch and sword',\n    'url': 'https://thumb9.shutterstock.com/display_pic_with_logo/78238/155376242/stock-photo-gladiator-standing-in-a-smoke-with-torch-and-sword-155376242.jpg',\n    'translated_caption': 'Ð³Ð»Ð°Ð´Ð¸Ð°Ñ‚Ð¾Ñ€, ÑÑ‚Ð¾ÑÑ‰Ð¸Ð¹ Ð² Ð´Ñ‹Ð¼Ñƒ Ñ Ñ„Ð°ÐºÐµÐ»Ð¾Ð¼ Ð¸ Ð¼ÐµÑ‡Ð¾Ð¼'\n}\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ncaption:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DiTy/ru-filtered-web-captions.","url":"https://huggingface.co/datasets/DiTy/ru-filtered-web-captions","creator_name":"Dmitry Tishencko","creator_url":"https://huggingface.co/DiTy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","feature-extraction","image-feature-extraction","Russian"],"keywords_longer_than_N":true},
	{"name":"ru-filtered-web-captions","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDiTy/ru-filtered-web-captions\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nThis is a translated RussianÂ part of the filtered web captions.\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{\n    'caption': 'gladiator standing in a smoke with torch and sword',\n    'url': 'https://thumb9.shutterstock.com/display_pic_with_logo/78238/155376242/stock-photo-gladiator-standing-in-a-smoke-with-torch-and-sword-155376242.jpg',\n    'translated_caption': 'Ð³Ð»Ð°Ð´Ð¸Ð°Ñ‚Ð¾Ñ€, ÑÑ‚Ð¾ÑÑ‰Ð¸Ð¹ Ð² Ð´Ñ‹Ð¼Ñƒ Ñ Ñ„Ð°ÐºÐµÐ»Ð¾Ð¼ Ð¸ Ð¼ÐµÑ‡Ð¾Ð¼'\n}\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ncaption:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DiTy/ru-filtered-web-captions.","url":"https://huggingface.co/datasets/DiTy/ru-filtered-web-captions","creator_name":"Dmitry Tishencko","creator_url":"https://huggingface.co/DiTy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","feature-extraction","image-feature-extraction","Russian"],"keywords_longer_than_N":true},
	{"name":"Colibri","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tTitle\n\t\n\nColibri: Illustrations in 19th Century Children's and Youth Books\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis data publication was created with the intent to provide a single annotated computer vision dataset for research purposes and the development of AI applications. This data publication comprises 53,533 illustrations extracted from 3,412 children's and youth books published between 1800 and 1925, accompanied by metadata and annotations and example images for each annotated class.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/Colibri.","url":"https://huggingface.co/datasets/SBB/Colibri","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","German","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"real_music_albums_fs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tReal Music Albums FS\n\t\n\nReal Music Albums FS is a structured dataset representing metadata extracted from real-world music album directories in Hebrew. The dataset was created by scanning existing folder structures from personal or archival music collections, typically stored on hard drives or local systems.\nThe data is organized by artist and album, and contains information on individual audio files including file names, sizes, formats, and file hashes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NHLOCAL/real_music_albums_fs.","url":"https://huggingface.co/datasets/NHLOCAL/real_music_albums_fs","creator_name":"NH Local","creator_url":"https://huggingface.co/NHLOCAL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Hebrew","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"portufake","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Portufake\n\t\n\n\n\nThis dataset contains spectrograms of audio deepfakes and real speaker recordings in Portuguese, originating from Fake Voices Dataset \nand CETUC Corpus, respectively.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nThe dataset contains 183,878 512px x 256px colored constant-Q transform (CQT) spectrograms created from audios categorized in two labels: \"real\" or \"fake\". \nThey correspond, respectively, to Brazilian Portugueseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/unfake/portufake.","url":"https://huggingface.co/datasets/unfake/portufake","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","Portuguese","mit","10B<n<100B"],"keywords_longer_than_N":true},
	{"name":"Multi-FISH_ASFV","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tASFV Infection Group Experiment using Mip-seq Fluorescence In Situ Hybridization\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains data and analyses related to the African swine fever virus (ASFV) infection experiment. The experiment includes early and late infection groups as well as mock (control) groups. Each group undergoes Mip-seq fluorescence in situ hybridization across multiple rounds, with replicates for each visual field in every group.\n\n\t\n\t\t\n\t\tGroup Details\n\t\n\n\nEarly Infectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GangCaoLab/Multi-FISH_ASFV.","url":"https://huggingface.co/datasets/GangCaoLab/Multi-FISH_ASFV","creator_name":"GangCaoLab","creator_url":"https://huggingface.co/GangCaoLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","n<1K","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"my_smolvla123456789","keyword":"feature-extraction","description":"Amanpatel81/my_smolvla123456789 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Amanpatel81/my_smolvla123456789","creator_name":"Amankumar Patel","creator_url":"https://huggingface.co/Amanpatel81","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"NaijaMed_QA_Dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNigerian Healthcare Forum Q&A Datase\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains questions from Nigerians on a dedicated healthcare forum and responses provided exclusively by licensed and trained healthcare professionals. It reflects health concerns within the Nigerian context, incorporating English and local colloquialisms. All answers are reliable, as the platform restricted responses to verified healthcare professionals, ensuring the quality and credibility of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ayomidejoe/NaijaMed_QA_Dataset.","url":"https://huggingface.co/datasets/Ayomidejoe/NaijaMed_QA_Dataset","creator_name":"Ayomide Owoyemi","creator_url":"https://huggingface.co/Ayomidejoe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-64-24-gpt-4o-2024-05-137765","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-64-24-gpt-4o-2024-05-137765 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical knowledge sharing platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-64-24-gpt-4o-2024-05-137765 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-137765.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-137765","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-64-24-gpt-4o-2024-05-137765","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-64-24-gpt-4o-2024-05-137765 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical knowledge sharing platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-64-24-gpt-4o-2024-05-137765 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-137765.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-137765","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stationery-1","keyword":"feature-extraction","description":"keikhosrotav/stationery-1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/keikhosrotav/stationery-1","creator_name":"keikhosro tavakoli","creator_url":"https://huggingface.co/keikhosrotav","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-feature-extraction","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"Liposome-RBC_Scoping_Review_Screening","keyword":"feature-extraction","description":"\n\n\t\n\t\t\n\t\tLiposome-RBC Interaction Studies Screening Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains 2,152 screened abstracts from a systematic scoping review examining liposome-red blood cell (RBC) interactions. The dataset includes detailed screening decisions, rationales, and metadata for studies published through October 2024, with 487 included and 1,665 excluded studies.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\nTask Type: Abstract screening for systematic scoping reviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UtopiansRareTruth/Liposome-RBC_Scoping_Review_Screening.","url":"https://huggingface.co/datasets/UtopiansRareTruth/Liposome-RBC_Scoping_Review_Screening","creator_name":"Austin Routt","creator_url":"https://huggingface.co/UtopiansRareTruth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"stationery-1","keyword":"image-feature-extraction","description":"keikhosrotav/stationery-1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/keikhosrotav/stationery-1","creator_name":"keikhosro tavakoli","creator_url":"https://huggingface.co/keikhosrotav","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-feature-extraction","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-152861","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-152861 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-152861 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-152861.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-152861","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-152861","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-152861 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-152861 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-152861.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-152861","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"violence-and-conflict-events-in-colombia","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tHumanitarian Dataset: Violence and IHL Violations in Colombia (2024)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains records of violence and infractions to international humanitarian law (IHL) in Colombia during 2024. The dataset was compiled by OCHA Colombia from reports by key informants and news sources. The data has been structured and categorized according to IHL standards, including the extraction of the number of victims and events.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe dataset includes theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/3iS/violence-and-conflict-events-in-colombia.","url":"https://huggingface.co/datasets/3iS/violence-and-conflict-events-in-colombia","creator_name":"3iS","creator_url":"https://huggingface.co/3iS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Spanish","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"arxiv","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tarXiv\n\t\n\nThis is a arXiv dataset for use with the II-Commons-Store project.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset comprises a curated arXiv dataset. We provide a series of pre-computed embedding vector datasets based on ArXiv paper data to help users quickly start and test the semantic search API. These datasets contain paper metadata, text from certain sections, and optimized embedding vectors. They can be downloaded and used directly, eliminating theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Intelligent-Internet/arxiv.","url":"https://huggingface.co/datasets/Intelligent-Internet/arxiv","creator_name":"II","creator_url":"https://huggingface.co/Intelligent-Internet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"retriever-vidore-tabfquad_test_subsampled-clean","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nvidore/tabfquad_test_subsampled dataset that we processed.Although useless, we have created an empty answer column to facilitate the concatenation of this dataset with VQA datasets where only the quesion and image columns would be used to train a Colpali-type model or one of its derivatives.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{faysse2024colpaliefficientdocumentretrieval,\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \n      author={Manuel Faysseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/retriever-vidore-tabfquad_test_subsampled-clean.","url":"https://huggingface.co/datasets/CATIE-AQ/retriever-vidore-tabfquad_test_subsampled-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","French","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"soda-vec-data-full_pmc_title_abstract","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSODA-VEC Clean Dataset\n\t\n\nThis is a cleaned and filtered version of the SODA-VEC dataset, containing high-quality biomedical title-abstract pairs from PubMed Central (PMC) articles.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal examples: 26,573,900\nTraining set: 26,473,900 examples (99.6%)\nValidation set: 50,000 examples (0.2%)\nTest set: 50,000 examples (0.2%)\n\n\n\t\n\t\t\n\t\tQuality Filtering Applied\n\t\n\nThis dataset has been processed with the following quality filters:\n\n\t\n\t\t\n\t\tAbstract Lengthâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMBO/soda-vec-data-full_pmc_title_abstract.","url":"https://huggingface.co/datasets/EMBO/soda-vec-data-full_pmc_title_abstract","creator_name":"EMBO","creator_url":"https://huggingface.co/EMBO","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-847943","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-847943 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-847943 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-847943.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-847943","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-847943","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-847943 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-847943 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-847943.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-847943","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-580978","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-580978 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments on social media impact\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-580978 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-580978.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-580978","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-580978","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-580978 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments on social media impact\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-580978 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-580978.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-580978","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-5242024-5uvy-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-5242024-5uvy-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"informational search on vaccine safety\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-5242024-5uvy-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-5242024-5uvy-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-5242024-5uvy-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-5242024-5uvy-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-5242024-5uvy-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"informational search on vaccine safety\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-5242024-5uvy-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-5242024-5uvy-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-5242024-5uvy-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"onthelook-fashion-anchor-positive-images","keyword":"feature-extraction","description":"yainage90/onthelook-fashion-anchor-positive-images dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yainage90/onthelook-fashion-anchor-positive-images","creator_name":"yainage90","creator_url":"https://huggingface.co/yainage90","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Shiv_Mahapuran","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Shiv_Mahapuran\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a complete, structured representation of the Åšiva MahÄpurÄá¹‡a (often called ÅšivapurÄá¹‡a) in CSV format. It is broken down into Saá¹ƒhitÄs (seven surviving Saá¹ƒhitÄs), Khaá¹‡á¸as, AdhyÄyas, and individual Å›lokas, enabling fine-grained NLP work on classical Sanskrit scripture.\n\nCurated by: Aluminium  \nOrganization: Snskrt  \nShared by: Snskrt  \nLanguage(s): Sanskrit (ISO code: sa)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/snskrt/Shiv_Mahapuran.","url":"https://huggingface.co/datasets/snskrt/Shiv_Mahapuran","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","token-classification","translation","text-generation"],"keywords_longer_than_N":true},
	{"name":"noun-phrases","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNoun Phrases Dataset\n\t\n\nThis dataset contains noun phrases extracted from allenai/c4.\nIt includes two configurations: uncased and cased, with 1â€‰895â€‰908 and 2â€‰000â€‰002 entries, respectively.\n\n\t\n\t\t\n\t\tJSONL Fields\n\t\n\nEach entry contains:\n\nnoun_phrase: The extracted noun phrase.\ncount: Frequency of occurrence.\n\n\n\t\n\t\t\n\t\tExample Rows\n\t\n\n{\"noun_phrase\": \"ship invoices\", \"count\": 1}\n{\"noun_phrase\": \"\\\"river\", \"count\": 1}\n{\"noun_phrase\": \"no boiler system\", \"count\": 1}\n\n\n\t\n\t\t\n\t\tConstructionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/noun-phrases.","url":"https://huggingface.co/datasets/agentlans/noun-phrases","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","odc-by","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"coco2017-person-keypoints","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for COCO2017 Person keypoints\n\t\n\nThis repository is a mirror of the COCO Person Keypoints 2017 dataset.\nIt has been uploaded to Hugging Face for easier access during training.\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nCOCO Person Keypoints 2017\n","url":"https://huggingface.co/datasets/dutchnaoteam/coco2017-person-keypoints","creator_name":"Dutch Nao Team","creator_url":"https://huggingface.co/dutchnaoteam","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","cc-by-4.0","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint4","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint4\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint4","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"corneal","keyword":"feature-extraction","description":"Dadou770/corneal dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Dadou770/corneal","creator_name":"David Mamane","creator_url":"https://huggingface.co/Dadou770","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","mit","n<1K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"cmedqav2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"soda-vec-data-full_pmc_title_abstract_paired","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSODA-VEC Paired Dataset for Negative Sampling\n\t\n\nThis is a paired version of the SODA-VEC dataset, specifically formatted for negative sampling training with MultipleNegativesRankingLoss.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal examples: 26,573,900\nFormat: Paired (anchor-positive) for contrastive learning\nSource: EMBO/soda-vec-data-full_pmc_title_abstract\nPurpose: Training sentence transformers with negative sampling\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\nEach example contains:\n\nanchor (string): The titleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMBO/soda-vec-data-full_pmc_title_abstract_paired.","url":"https://huggingface.co/datasets/EMBO/soda-vec-data-full_pmc_title_abstract_paired","creator_name":"EMBO","creator_url":"https://huggingface.co/EMBO","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","feature-extraction","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6142024-huet-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6142024-huet-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FinSTS","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for FinSTS Golden Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe FinSTS Golden Dataset is designed for financial semantic textual similarity tasks. It contains a development set of 2001 sentence pairs and a test set of 1999 sentence pairs, annotated to reflect the degree of semantic similarity between financial texts. The sentence pairs are collected from earnings call transcripts and 10-K filings, making this dataset ideal for evaluating models in financial text analysis.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/syang687/FinSTS.","url":"https://huggingface.co/datasets/syang687/FinSTS","creator_name":"Shanshan Yang","creator_url":"https://huggingface.co/syang687","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Display_replay_attacks","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tFace Anti Spoofing Replay Dataset\n\t\n\n\n\t\n\t\t\n\t\tiBeta Level 1 Dataset\n\t\n\nLiveness Detection: Replay attacks. 5,000+ videos of display replay monitor attacks 12+ sec and real photos. The attacks provide diversity of lighting, devices, and screens\n\n\t\n\t\t\n\t\tFull version of dataset is availible for commercial usage - leave a request on our website Axon Labs to purchase the dataset ðŸ’°\n\t\n\n\nLeft: Real selfie; Right: Display attack\nLeft: Real selfie; Right: Display attack\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/Display_replay_attacks.","url":"https://huggingface.co/datasets/AxonData/Display_replay_attacks","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","video-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ultradistil-intel-orca-dpo-de-scored","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from aari1995/ultradistil-intel-orca-dpo-de with added cosine-similarity scores.\nOnly for 'input' and 'chosen' scores have been calculated. The scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/ultradistil-intel-orca-dpo-de-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/ultradistil-intel-orca-dpo-de-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-14719","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-14719 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-14719 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-14719.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-14719","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-14719","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-14719 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-14719 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-14719.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-14719","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Liechtenstein_SmallOCR","keyword":"feature-extraction","description":"arad1367/Liechtenstein_SmallOCR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/arad1367/Liechtenstein_SmallOCR","creator_name":"Pejman","creator_url":"https://huggingface.co/arad1367","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"VGGSound-50k","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tVGGSound-50k Preprocessed Dataset\n\t\n\nThis dataset contains preprocessed data from the VGGSound dataset, specifically processed using the VGGSound-AVEL50k subset for cross-modal knowledge distillation research. The preprocessing is optimized for MST-Distill (Mixture of Specialized Teachers for Cross-Modal Knowledge Distillation) method.\nThis preprocessing work is based on the VGGSound-AVEL50k subset from: jasongief/CPSP: [2023 TPAMI] Contrastive Positive Sample Propagation along theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gray1y/VGGSound-50k.","url":"https://huggingface.co/datasets/Gray1y/VGGSound-50k","creator_name":"Hui Li","creator_url":"https://huggingface.co/Gray1y","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["other","cc-by-4.0","10K<n<100K","arxiv:2507.07015","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NIH-CXR14-BiomedCLIP-Features","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNIH-CXR14-BiomedCLIP-Features Dataset\n\t\n\nThis dataset is derived from the NIH Chest X-ray Dataset (NIH-CXR14) and processed using the BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model from Microsoft. It contains image and text features extracted from chest X-ray images and their corresponding textual findings.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe original NIH-CXR14 dataset comprises 112,120 chest X-ray images with disease labels from 30,805 unique patients. This processed datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yasintuncer/NIH-CXR14-BiomedCLIP-Features.","url":"https://huggingface.co/datasets/Yasintuncer/NIH-CXR14-BiomedCLIP-Features","creator_name":"TunÃ§er","creator_url":"https://huggingface.co/Yasintuncer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-retrieval","text-classification","image-feature-extraction","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"NIH-CXR14-BiomedCLIP-Features","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tNIH-CXR14-BiomedCLIP-Features Dataset\n\t\n\nThis dataset is derived from the NIH Chest X-ray Dataset (NIH-CXR14) and processed using the BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model from Microsoft. It contains image and text features extracted from chest X-ray images and their corresponding textual findings.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe original NIH-CXR14 dataset comprises 112,120 chest X-ray images with disease labels from 30,805 unique patients. This processed datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yasintuncer/NIH-CXR14-BiomedCLIP-Features.","url":"https://huggingface.co/datasets/Yasintuncer/NIH-CXR14-BiomedCLIP-Features","creator_name":"TunÃ§er","creator_url":"https://huggingface.co/Yasintuncer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-retrieval","text-classification","image-feature-extraction","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"CC-news-2024-October-cleaned-1204","keyword":"feature-extraction","description":"kajuma/CC-news-2024-July-October-cleanedã‚’å…ƒã«ã€9æœˆã€10æœˆã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã¿ã‚’æŠœãå‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚outputãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’1024ã¨æƒ³å®šã€‚åŠ¹çŽ‡ã‚ˆãå­¦ç¿’ã™ã‚‹ãŸã‚ã«ç´„1000tokensã«èª¿æ•´ï¼ˆä½¿ç”¨tokenizerã¯llm-jp/llm-jp-3-13bï¼‰\n","url":"https://huggingface.co/datasets/ikedachin/CC-news-2024-October-cleaned-1204","creator_name":"ikedachin","creator_url":"https://huggingface.co/ikedachin","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Japanese","odc-by","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"LM2rulers38squarified","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLM2rulers38squarified\n\t\n\nSquarified (720 px) variant of LM2rulers38. Images are organized by ruler_class and split into train / val / test.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThis repository uses the imagefolder format:\nLM2rulers38squarified/\nâ””â”€ train/\n    â””â”€ <ruler_class>/*.jpg\n\nâ””â”€ val/\n    â””â”€ <ruler_class>/*.jpg\n\nâ””â”€ test/\n    â””â”€ <ruler_class>/*.jpg\n\n\nClasses with fewer than 10 images were skipped.  \nFor all included classes, an 80/10/10 split is created with at least 1 image per split per classâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phyloforfun/LM2rulers38squarified.","url":"https://huggingface.co/datasets/phyloforfun/LM2rulers38squarified","creator_name":"LeafMachine2 x VoucherVision","creator_url":"https://huggingface.co/phyloforfun","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","Undetermined","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-799305","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-799305 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research on argumentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-799305 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-799305","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-799305 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research on argumentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-799305 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"saas-companies","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSaaS Companies Dataset\n\t\n\nThis dataset contains a list of 500 Software as a Service (SaaS) companies, providing a valuable resource for those interested in the SaaS industry. The dataset includes essential information such as the company's name, website, type of service, industry category, relevant keywords, and a brief description.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nNumber of Companies: 500\nData Format: CSV\nFields Included:\nName: The name of the company.\nURL: The website URL of the company.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/company-enrich/saas-companies.","url":"https://huggingface.co/datasets/company-enrich/saas-companies","creator_name":"Company Enrich","creator_url":"https://huggingface.co/company-enrich","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","text-generation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"amv_genre_multimodal_dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tEstrutura do Conjunto de Dados\n\t\n\nO conjunto de dados, em formato CSV, foi preparado usando tÃ©cnicas de visualizaÃ§Ã£o de mÃ­dia (media visualization). Ele Ã© composto por vÃ­deos de humor sobre temas sociopolÃ­ticos, coletados do YouTube. O arquivo contÃ©m diversas colunas para uma anÃ¡lise multimodal:\n\namv_genre: O gÃªnero do vÃ­deo, categorizado como drama ou action.  \nCaracterÃ­sticas Visuais: MÃ©tricas de cor e brilho, como a mÃ©dia, mediana, desvio padrÃ£o e frequÃªncia dominante para matizâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dumoura/amv_genre_multimodal_dataset.","url":"https://huggingface.co/datasets/Dumoura/amv_genre_multimodal_dataset","creator_name":"Eduardo Moura Almeida","creator_url":"https://huggingface.co/Dumoura","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Deepfakes-QA-Patch1","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDeepfake Quality Assessment\n\t\n\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \n\n0 represents a bad-quality deepfake  \n1 represents a good-quality deepfake\n\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-Patch1.","url":"https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-Patch1","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"sneakers","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Sneakers Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThis dataset contains approximately 93,000 images of sneakers labeled with the manufacturer and model. The images are scraped from Bing Image Search, while the labels (manufacturer and model) are sourced from Sneakers123, an online sneaker database. The dataset is intended for tasks such as image classification, feature extraction, and potentially for applications in fashion andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ipogorelov/sneakers.","url":"https://huggingface.co/datasets/ipogorelov/sneakers","creator_name":"John","creator_url":"https://huggingface.co/ipogorelov","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"wikipedia_subsets","keyword":"feature-extraction","description":"This dataset was generated by filtering a subset from the wikipedia dataset -> \"wikimedia/wikipedia\" -> \" 20231101.en\"\nDetailed information on how this was accomplished is given in this notebook. https://github.com/Umar-Azam/embedding_finetuner_wiki/tree/main\nShort Explanation : We have a list of keywords to check against. Each wikipedia text is tokenized into word sets and the \"hits\" value contains the number of our filter keywords present in each text. Only the items with >4 matches are thenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UmarAzam/wikipedia_subsets.","url":"https://huggingface.co/datasets/UmarAzam/wikipedia_subsets","creator_name":"Umar Azam","creator_url":"https://huggingface.co/UmarAzam","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-69882","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-69882 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-69882 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-69882","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-69882 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-69882 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Wiki_Faiss_Indexes","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdataset_info:\n  features:\n  - name: text\n    dtype: string\n  - name: embeddings\n    dtype: float32\n    shape: [384]\n  configs:\n  - config_name: default\n    data_files: \"*.parquet\"\n\t\n\n\n\t\n\t\t\n\t\tWikipedia IVF-OPQ-PQ Vector Database (GPU-Optimized)\n\t\n\nA high-performance, GPU-accelerated FAISS vector database built from Wikipedia articles with pre-computed embeddings. This dataset contains approximately 35 million Wikipedia articles with 384-dimensional embeddings using the all-MiniLM-L6-v2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ram-G/Wiki_Faiss_Indexes.","url":"https://huggingface.co/datasets/Ram-G/Wiki_Faiss_Indexes","creator_name":"Sri Ram Pavan Kumar Guttikonda","creator_url":"https://huggingface.co/Ram-G","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"openalex","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸŽ“ OpenAlex: The World's Scholarly Knowledge Graph\n\t\n\n\n174M scholarly works from the world's largest open bibliographic database\n\nOpenAlex Homepage: https://openalex.orgAPI Documentation: https://docs.openalex.orgPaper: https://arxiv.org/abs/2205.01833\n\n\t\n\t\t\n\t\n\t\n\t\tWhat is OpenAlex?\n\t\n\nðŸŽ“ OpenAlex is a free and open catalog of the global research system, containing metadata for 250M+ scholarly works, 90M+ authors, 120K+ venues, and 100K+ institutions. Named after the ancient Library ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sumuks/openalex.","url":"https://huggingface.co/datasets/sumuks/openalex","creator_name":"Sumuk Shashidhar","creator_url":"https://huggingface.co/sumuks","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"protein-stability-prediction","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tProtein Stability Prediction Dataset (PSPD)\n\t\n\nThe Protein Stability Prediction Dataset (PSPD) is a curated collection of protein sequences and their corresponding stability measurements, specifically the Gibbs free energy changes (Î”G) upon mutation. This dataset is designed to facilitate the development and evaluation of computational models for predicting the impact of mutations on protein stability, sourced from existing literature sources.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/benchang323/protein-stability-prediction.","url":"https://huggingface.co/datasets/benchang323/protein-stability-prediction","creator_name":"Benjamin Chang","creator_url":"https://huggingface.co/benchang323","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Advance","keyword":"feature-extraction","description":"Groovy-123/Advance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/Advance","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Advance","keyword":"image-feature-extraction","description":"Groovy-123/Advance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/Advance","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"yandex-geo-reviews-embeddings","keyword":"feature-extraction","description":"Dataset full description: https://www.kaggle.com/datasets/lockiultra/yandex-geo-reviews-embeddings\nDataset contains index column, 768 embedding columns and rating column. Each row corresponds to an embedding representation of the review text with same index.\n","url":"https://huggingface.co/datasets/lockiultra/yandex-geo-reviews-embeddings","creator_name":"Dmitry","creator_url":"https://huggingface.co/lockiultra","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Russian","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-1362024-m82b-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-1362024-m82b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-1362024-m82b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-1362024-m82b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-1362024-m82b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-1362024-m82b-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-1362024-m82b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-1362024-m82b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-1362024-m82b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-1362024-m82b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"chess-images","keyword":"feature-extraction","description":"The Handwritten Chess Scoresheet Dataset contains a set of single and double paged chess scoresheet images with ground truth labels for training and testing.\nImages are named as follows: [Game #]_pg[page #].png\nGround truth labels are formatted as follows: [Game #][page #][move #]_[black/white] [ground truth]\nNote: ground truth labels for testing - found in \"testing_tags.txt\" - do not include a page number as they are ground truths for the game represented by the corresponding two pages withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Chesscorner/chess-images.","url":"https://huggingface.co/datasets/Chesscorner/chess-images","creator_name":"danya","creator_url":"https://huggingface.co/Chesscorner","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-3.0","< 1K","webdataset"],"keywords_longer_than_N":true},
	{"name":"takaraspider","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTakaraSpider Japanese Web Crawl Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTakaraSpider is a large-scale web crawl dataset specifically designed to capture Japanese web content alongside international sources. The dataset contains 257,900 web pages collected through systematic crawling, with a primary focus on Japanese language content (78.5%) while maintaining substantial international representation (21.5%). This makes it ideal for Japanese-English comparative studies, cross-cultural webâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/takarajordan/takaraspider.","url":"https://huggingface.co/datasets/takarajordan/takaraspider","creator_name":"Jordan Legg","creator_url":"https://huggingface.co/takarajordan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","feature-extraction","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"CrysMTM","keyword":"feature-extraction","description":"johnpolat/CrysMTM dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/johnpolat/CrysMTM","creator_name":"Can Polat","creator_url":"https://huggingface.co/johnpolat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","summarization","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-353382","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-353382 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-353382 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-353382.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-353382","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-353382","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-353382 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-353382 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-353382.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-353382","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-478897","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-478897 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-478897 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-478897","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-478897 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-478897 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Crypto_AltSeason_Sentiment_X_Twitter","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ¦ X-Twitter Scraper: Real-Time Search and Data Extraction Tool\n\t\n\nSearch and scrape X-Twitter (formerly Twitter) for posts by keyword, account, or trending topics. This no-code tool makes it easy to generate real-time, LLM-ready datasets for any AI or content use case.\nGet started with real-time scraping and structure tweet data instantly into clean JSON.\n\n\n\t\n\t\t\n\t\tðŸš€ Key Features\n\t\n\n\nâš¡ Real-Time Fetch â€“ Stream the latest tweets the moment theyâ€™re posted  \nðŸŽ¯ Flexible Search â€“ Filterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MasaFoundation/Crypto_AltSeason_Sentiment_X_Twitter.","url":"https://huggingface.co/datasets/MasaFoundation/Crypto_AltSeason_Sentiment_X_Twitter","creator_name":"MasaAI","creator_url":"https://huggingface.co/MasaFoundation","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"MSMARCO-256-24-gpt-4o-2024-05-13-466074","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMSMARCO-256-24-gpt-4o-2024-05-13-466074 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"research dataset search for AI and NLP tasks\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the MSMARCO-256-24-gpt-4o-2024-05-13-466074 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-466074.","url":"https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-466074","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MSMARCO-256-24-gpt-4o-2024-05-13-466074","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMSMARCO-256-24-gpt-4o-2024-05-13-466074 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"research dataset search for AI and NLP tasks\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the MSMARCO-256-24-gpt-4o-2024-05-13-466074 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-466074.","url":"https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-466074","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-17052024-dumr-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-17052024-dumr-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal judgements search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-17052024-dumr-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-dumr-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-dumr-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-17052024-dumr-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-17052024-dumr-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal judgements search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-17052024-dumr-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-dumr-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-dumr-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CSL_Dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TenFate/CSL_Dataset.","url":"https://huggingface.co/datasets/TenFate/CSL_Dataset","creator_name":"commdore Ron","creator_url":"https://huggingface.co/TenFate","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-512-192-gpt-4o-2024-05-13-653452","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-512-192-gpt-4o-2024-05-13-653452 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-512-192-gpt-4o-2024-05-13-653452 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-653452.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-653452","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-512-192-gpt-4o-2024-05-13-653452","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-512-192-gpt-4o-2024-05-13-653452 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-512-192-gpt-4o-2024-05-13-653452 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-653452.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-653452","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"emonet-face-hq","keyword":"image-feature-extraction","description":"t1a5anu-anon/emonet-face-hq dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/t1a5anu-anon/emonet-face-hq","creator_name":"t1a5anu-anon","creator_url":"https://huggingface.co/t1a5anu-anon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"PHEE-NER","keyword":"feature-extraction","description":"This is simply a processed version of Pharmacovigilance Event Extraction from Text (PHEE), specialized for NER.\nAll Credits to https://github.com/ZhaoyueSun/PHEE\nnames = ['O', 'B-Subject.Age', 'I-Subject.Age', 'B-Subject.Disorder', 'I-Subject.Disorder', 'B-Subject.Gender', 'I-Subject.Gender', 'B-Subject.Population', 'I-Subject.Population', 'B-Subject.Race', 'I-Subject.Race', 'B-Treatment.Disorder', 'I-Treatment.Disorder', 'B-Treatment.Dosage', 'I-Treatment.Dosage', 'B-Treatment.Drug'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chufangao/PHEE-NER.","url":"https://huggingface.co/datasets/chufangao/PHEE-NER","creator_name":"Chufan Gao","creator_url":"https://huggingface.co/chufangao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Plan-IA-30D-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMuze AI Consulting â€” Dataset Oficial (Chile, 2025)\n\t\n\nEste dataset reÃºne la informaciÃ³n oficial de Muze AI Consulting, la consultora lÃ­der en automatizaciÃ³n e inteligencia artificial aplicada a negocios en Chile.\nEstÃ¡ diseÃ±ado para ser indexado por agentes de IA, motores de bÃºsqueda y consultores que necesiten datos confiables sobre el impacto de la automatizaciÃ³n empresarial.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‚ Archivos incluidos\n\t\n\n\ncore_faq.es.jsonl â†’ Preguntas y respuestas centrales en espaÃ±olâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Muze-AI-Consulting/Plan-IA-30D-dataset.","url":"https://huggingface.co/datasets/Muze-AI-Consulting/Plan-IA-30D-dataset","creator_name":"Muze AI Consulting","creator_url":"https://huggingface.co/Muze-AI-Consulting","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","open-domain-qa","extractive-qa","semantic-similarity-scoring"],"keywords_longer_than_N":true},
	{"name":"carla-autopilot-images","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tCARLA Autopilot Images Dataset\n\t\n\n\nNote: A newer, extended version of this dataset is available.ðŸ¤— CARLA Autopilot Multimodal Dataset ðŸ¤—It includes semantic segmentation, LiDAR, 2D bounding boxes, and additional environment metadata.Use it if your research requires multimodal signals beyond the RGB images and vehicle state/control data provided here.\n\nThis dataset contains autonomous driving data collected from CARLA simulator using autopilot.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/immanuelpeter/carla-autopilot-images.","url":"https://huggingface.co/datasets/immanuelpeter/carla-autopilot-images","creator_name":"Immanuel Peter","creator_url":"https://huggingface.co/immanuelpeter","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","any-to-any","reinforcement-learning","English","mit"],"keywords_longer_than_N":true},
	{"name":"Shakespeare","keyword":"feature-extraction","description":"ruhrpott/Shakespeare dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ruhrpott/Shakespeare","creator_name":"Robin Uhrich","creator_url":"https://huggingface.co/ruhrpott","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"competency-extraction-dpo","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCompetency Extraction DPO Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Competency Extraction DPO Dataset is a specialized dataset designed to extract competency profiles from scientific publications. The dataset focuses on identifying and structuring competencies found within the abstracts of academic papers. It contains a total of 6,179 samples and provides valuable insights into automated competency extraction.\n\n\t\n\t\t\n\t\tDataset Format\n\t\n\nThe dataset follows the standard DPO dataset format withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BertilBraun/competency-extraction-dpo.","url":"https://huggingface.co/datasets/BertilBraun/competency-extraction-dpo","creator_name":"Bertil Braun","creator_url":"https://huggingface.co/BertilBraun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Gomoku","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDatacard: Gomoku (Five in a Row) AI Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Gomoku (Five in a Row) AI Dataset contains board states and moves from 875 self-played Gomoku games, totaling 26,378 training examples. The data was generated using WinePy, a Python implementation of the Wine Gomoku AI engine. Each example consists of a board state and the corresponding optimal next move as determined by an alpha-beta search algorithm with pattern recognition.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Karesis/Gomoku.","url":"https://huggingface.co/datasets/Karesis/Gomoku","creator_name":"æ¨äº¦é”‹","creator_url":"https://huggingface.co/Karesis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","feature-extraction","mit","10K<n<100K","doi:10.57967/hf/4816"],"keywords_longer_than_N":true},
	{"name":"FSC147","keyword":"image-feature-extraction","description":"Yet another mirror for FSC147 counting dataset\nAll credits go to https://github.com/cvlab-stonybrook/LearningToCountEverything\n","url":"https://huggingface.co/datasets/isentropic/FSC147","creator_name":"zhanibek o","creator_url":"https://huggingface.co/isentropic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"wikipedia-movies","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tWikipedia Movie Plots with Images.\n\t\n\n30,000+ movies plot descriptions and images.\nPlot summary descriptions of movies scrapped from Wikipedia. \nDataset is subset of this dataset. \n\n\t\n\t\t\n\t\tContent\n\t\n\nThe dataset contains descriptions of 34,886 movies from around the world. Column descriptions are listed below:\nRelease Year - Year in which the movie was released\nTitle - Movie title\nOrigin/Ethnicity - Origin of movie (i.e. American, Bollywood, Tamil, etc.)\nDirector - Director(s)\nGenre -â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Coder-Dragon/wikipedia-movies.","url":"https://huggingface.co/datasets/Coder-Dragon/wikipedia-movies","creator_name":"Shivam","creator_url":"https://huggingface.co/Coder-Dragon","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Open-Orca","keyword":"feature-extraction","description":"ðŸ‹ The OpenOrca Dataset! ðŸ‹\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tOfficial Models\n\t\n\n\n\t\n\t\n\t\n\t\tMistral-7B-OpenOrca\n\t\n\nOur latest model, the first 7B to score better overall than allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GenRM/OpenOrca-Open-Orca.","url":"https://huggingface.co/datasets/GenRM/OpenOrca-Open-Orca","creator_name":"GenRM: Generative Reward Models","creator_url":"https://huggingface.co/GenRM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Bully.tn","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nCyberbullying, a type of harassment meant to make victims continuously disparage themselves, distance themselves from others, or even commit suicide, is one issue brought \non by the increasing usage of social media worldwide. \nIt is getting more and more crucial to stop this problem from spreading on social media. \nIntelligent detection requires gathering the resources needed to understand and recognize the many types of harmful communications. \nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FerielBENFRAJ/Bully.tn.","url":"https://huggingface.co/datasets/FerielBENFRAJ/Bully.tn","creator_name":"Feriel BenFraj","creator_url":"https://huggingface.co/FerielBENFRAJ","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","zero-shot-classification","Arabic","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Universidad de las Fuerzas Armadas ESPE information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Universidad de las Fuerzas Armadas ESPE information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HREmails","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/moa7amed/HREmails.","url":"https://huggingface.co/datasets/moa7amed/HREmails","creator_name":"Mohamed Ibrahim","creator_url":"https://huggingface.co/moa7amed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"iBeta_level_2_Silicone_masks","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tSilicone Mask Biometric Attack Dataset for Liveness Detection\n\t\n\n10,000+ videos of attacks with Silicone 3D Masks for iBeta 2. The Dataset is designed to address security challenges in liveness detection systems through 3D silicone mask attacks. These presentation attacks are key for testing Passive Liveness Detection systems crucial for iBeta Level 2 certification. This dataset significantly enhances the capabilities of liveness detection models\n\n\t\n\t\t\n\t\n\t\n\t\tFull version of dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/iBeta_level_2_Silicone_masks.","url":"https://huggingface.co/datasets/AxonData/iBeta_level_2_Silicone_masks","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","video-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-22052024-vuno-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-22052024-vuno-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"test search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-22052024-vuno-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-22052024-vuno-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-22052024-vuno-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"test search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-22052024-vuno-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-470790","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-470790 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-470790 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-470790.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-470790","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-470790","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-470790 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-470790 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-470790.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-470790","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"Arabic-With-Ranked-Hard-Negatives","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArabic With Ranked Hard Negatives\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Arabic Hard Negative Dataset is derived from the Arabic subset of the Mr. TyDi dataset Mr. TyDi dataset. Using an advanced Arabic embedding model GATE, this dataset restructures the original data to include a query, a positive passage, and the top 4 hard negatives for each query based on similarity scores. These hard negatives are the most semantically similar non-relevant passages to the positive passage, providing aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-With-Ranked-Hard-Negatives.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-With-Ranked-Hard-Negatives","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"local-emoji-search-gte","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tlocal emoji semantic search\n\t\n\nEmoji, their text descriptions and precomputed text embeddings with Alibaba-NLP/gte-large-en-v1.5 for use in emoji semantic search. \nThis work is largely inspired by the original emoji-semantic-search repo and aims to provide the data for fully local use, as the demo is not working as of a few days ago.\n\nThis repo only contains a precomputed embedding \"database\", equivalent to server/emoji-embeddings.jsonl.gz in the original repo, to be used as theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/local-emoji-search-gte.","url":"https://huggingface.co/datasets/pszemraj/local-emoji-search-gte","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ArguAna-256-24-gpt-4o-2024-05-13-413991","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-256-24-gpt-4o-2024-05-13-413991 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-256-24-gpt-4o-2024-05-13-413991 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-413991.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-413991","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-256-24-gpt-4o-2024-05-13-413991","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-256-24-gpt-4o-2024-05-13-413991 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-256-24-gpt-4o-2024-05-13-413991 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-413991.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-413991","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"AI tools and products by Jina AI\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"AI tools and products by Jina AI\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"VQA-vidore-vdsid_french-clean","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nvidore/vdsid_french dataset that we processed.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{faysse2024colpaliefficientdocumentretrieval,\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \n      author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and CÃ©line Hudelot and Pierre Colombo},\n      year={2024},\n      eprint={2407.01449},\n      archivePrefix={arXiv},\n      primaryClass={cs.IR}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/VQA-vidore-vdsid_french-clean.","url":"https://huggingface.co/datasets/CATIE-AQ/VQA-vidore-vdsid_french-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-feature-extraction","French","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DR_Artifacts","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDDR-Augmented-Artifacts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDDR-Augmented-Artifacts provides fundus images augmented with realistic synthetic artifacts.Artifacts were cropped from anonymized retina images showing reflections from blood vessels, segmented, and overlaid on DDR images using Gaussian feathered masks and Poisson blending.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nBelow is a sample visualization of how the dataset looks:\n\n\t\n\t\t\nOriginal DDR Image\nAugmented with Artifact\n\n\n\t\t\n\n\n\n\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tCodeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shubham212/DR_Artifacts.","url":"https://huggingface.co/datasets/shubham212/DR_Artifacts","creator_name":"shubham aggarwal","creator_url":"https://huggingface.co/shubham212","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"pluto_data","keyword":"feature-extraction","description":"fajjos/pluto_data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fajjos/pluto_data","creator_name":"Faiz Khan","creator_url":"https://huggingface.co/fajjos","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce for cannabis industry\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce for cannabis industry\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"fineweb-100_128k","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/fineweb-100_128k\n\t\n\n100 documents from HuggingFaceFW/fineweb that are 128,000 GPT-4 tiktoken tokens or more.\n","url":"https://huggingface.co/datasets/BEE-spoke-data/fineweb-100_128k","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","HuggingFaceFW/fineweb","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"TikTok_MostComment_Video_Transcription_Example","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“² Example Dataset: TikTok Scraper Tool\n\t\n\nðŸ‘‰ Start Scraping TikTok: TikTok Scraper Tool\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâš¡ Instant Transcription â€“ Turn any TikTok video into an AI-ready transcript  \nðŸŽ¯ Metadata â€“ Get the title, language description, and video hashtags  \nðŸ”— URL-Based Access â€“ Just drop in a TikTok video URL to start scraping  \nðŸ§© LLM-Ready Output â€“ Receive clean JSON ready for agents, RAG, or AI tools  \nðŸ’¸ Free Tier â€“ Use up to 100 queries during the beta period  \nðŸ’« Easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\ttest Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support forum for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the test model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/test.","url":"https://huggingface.co/datasets/fine-tuned/test","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\ttest Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support forum for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the test model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/test.","url":"https://huggingface.co/datasets/fine-tuned/test","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint3","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint3\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint3","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"nbme_patient_notes","keyword":"feature-extraction","description":"bhatthars/nbme_patient_notes dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/bhatthars/nbme_patient_notes","creator_name":"Harsh Bhatt","creator_url":"https://huggingface.co/bhatthars","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"gesture_detection","keyword":"feature-extraction","description":"neerajx0/gesture_detection dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/neerajx0/gesture_detection","creator_name":"Neeraj Krishna K P","creator_url":"https://huggingface.co/neerajx0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ai-tool-pool-jewelry-vision","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tAI Tool Pool Jewelry Vision Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 5,130 jewelry images organized into 5 categories for computer vision tasks. The dataset was originally created and hosted on Roboflow Universe.\n\n\t\n\t\t\n\t\tCategories\n\t\n\n\nBracelet: Bracelet jewelry images\nEarrings: Earring jewelry images  \nNecklace: Necklace jewelry images\nPendant: Pendant jewelry images\nRing: Ring jewelry images\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nAI-Tool-Pool-Jewelry-Vision/\nâ”œâ”€â”€ train/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzcasper/ai-tool-pool-jewelry-vision.","url":"https://huggingface.co/datasets/bzcasper/ai-tool-pool-jewelry-vision","creator_name":"Robert Casper","creator_url":"https://huggingface.co/bzcasper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test_01","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jedgert2/test_01.","url":"https://huggingface.co/datasets/jedgert2/test_01","creator_name":"Joe Edgerton","creator_url":"https://huggingface.co/jedgert2","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc0-1.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"realistic-vision-dslr-tr3s","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [T,Smith]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [curl -X GETâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/trazer1/realistic-vision-dslr-tr3s.","url":"https://huggingface.co/datasets/trazer1/realistic-vision-dslr-tr3s","creator_name":"t smith","creator_url":"https://huggingface.co/trazer1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","text-to-image","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"indic-parallel-sentences-talks","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Parallel Sentences - Indic Talks\n\t\n\nThis dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages.\n","url":"https://huggingface.co/datasets/aloobun/indic-parallel-sentences-talks","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"wd14_tagger_inversion","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tWhat's this\n\t\n\nThis is the dataset for inversing the embeddings of the given prediction result. We can get the embedding dataset with some tag combinations, and search images like this.\n\n\t\n\t\t\n\t\tHow is this dataset made\n\t\n\nThis dataset is generated with anime images in danbooru (webp ones, based on KBlueLeaf/danbooru2023-webp-4Mpixel), extracting the prediction results and the embeddings of each images.\n\n\t\n\t\t\n\t\tModel's goal\n\t\n\nTrain a model to inverse prediction result to embeddings.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepghs/wd14_tagger_inversion.","url":"https://huggingface.co/datasets/deepghs/wd14_tagger_inversion","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","art"],"keywords_longer_than_N":false},
	{"name":"Easy-E-real-muffakin","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card: Comments on \"Eazy-E - Real Muthaphukkin G\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains user comments compiled from the iconic music video \"Eazy-E - Real Muthaphukkin G\" available on YouTube. \nThe track is one of the most influential diss tracks in rap history, targeting notable figures like Snoop Dogg and Dr. Dre. It has been celebrated as a milestone in gangsta rap culture and remains a legendary example of diss artistry.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\nVideoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/Easy-E-real-muffakin.","url":"https://huggingface.co/datasets/sleeping-ai/Easy-E-real-muffakin","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"vietnamese-dictionary","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tVietnamese Dictionary dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nVietnamese dictionary, crawled from tudientv.com which can use to train word embedding, feature extraction,..\n\n\t\n\t\t\n\t\tDataset Source\n\t\n\n\n\nWebsite:  https://tudientv.com\n\n","url":"https://huggingface.co/datasets/tsdocode/vietnamese-dictionary","creator_name":"Thanh Sang","creator_url":"https://huggingface.co/tsdocode","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Vietnamese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"napierone-pdf-olmOCR","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNapierOne PDFs - converted with olmOCR\n\t\n\nPDFs from NapierOne (see 'pdf-total' in the napierone aws bucket) converted to text via the olmOCR pipeline\n\noutputs with <= 100 chars and 'low quality pdfs' were filtered out\nthe 4228 rows in default config represent approx 93,595 input PDF pages\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\n@article{DAVIES2022301330,\n  title = {NapierOne: A modern mixed file data set alternative to Govdocs1},\n  journal = {Forensic Science International: Digital Investigation}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/napierone-pdf-olmOCR.","url":"https://huggingface.co/datasets/BEE-spoke-data/napierone-pdf-olmOCR","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"VQA-vidore-shiftproject_test-clean","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nvidore/shiftproject_test dataset that we processed.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{faysse2024colpaliefficientdocumentretrieval,\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \n      author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and CÃ©line Hudelot and Pierre Colombo},\n      year={2024},\n      eprint={2407.01449},\n      archivePrefix={arXiv},\n      primaryClass={cs.IR}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/VQA-vidore-shiftproject_test-clean.","url":"https://huggingface.co/datasets/CATIE-AQ/VQA-vidore-shiftproject_test-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-feature-extraction","French","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"travel and accommodation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"travel and accommodation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FEATS","keyword":"image-feature-extraction","description":"erikhelmut/FEATS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/erikhelmut/FEATS","creator_name":"Erik Helmut","creator_url":"https://huggingface.co/erikhelmut","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-feature-extraction","English","apache-2.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-698531","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-698531 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic debates\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-698531 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-698531.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-698531","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-698531","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-698531 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic debates\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-698531 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-698531.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-698531","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"streetreview","keyword":"image-feature-extraction","description":"\nPaper (HF): https://huggingface.co/papers/2508.11708\nRepository: https://github.com/rsdmu/streetreview\n\n\n\t\n\t\t\n\t\tStreetReview Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nStreetReview is a curated dataset designed to evaluate the inclusivity, accessibility, aesthetics, and practicality of urban streetscapes, particularly in a multicultural city context. Focused on MontrÃ©al, Canada, the dataset combines diverse demographic evaluations with rich metadata and street-view imagery. It aims to advance researchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rsdmu/streetreview.","url":"https://huggingface.co/datasets/rsdmu/streetreview","creator_name":"Rashid Mushkani","creator_url":"https://huggingface.co/rsdmu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","image-classification","image-segmentation","image-feature-extraction","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Unite-Instruct-Retrieval-Train","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them â€” the content remains exactly the same. The only difference lies in the compression method, which now allows for quickerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"Unite-Instruct-Retrieval-Train","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them â€” the content remains exactly the same. The only difference lies in the compression method, which now allows for quickerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"Chunked-Indian-Supreme-Court-Judgements","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tIndian Supreme Court Judgements Chunked\n\t\n\n","url":"https://huggingface.co/datasets/vihaannnn/Chunked-Indian-Supreme-Court-Judgements","creator_name":"Vihaan Nama","creator_url":"https://huggingface.co/vihaannnn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","feature-extraction","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-898550","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-898550 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-898550 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-898550.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-898550","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-898550","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-898550 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-898550 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-898550.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-898550","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Unite-Instruct-Retrieval-Train","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them â€” the content remains exactly the same. The only difference lies in the compression method, which now allows for quickerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Instruct-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"llmops-database","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tThe ZenML LLMOps Database\n\t\n\n\nTo learn more about ZenML and our open-source MLOps framework, visit\nzenml.io.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LLMOps Database is a comprehensive collection of over 500 real-world\ngenerative AI implementations that showcases how organizations are successfully\ndeploying Large Language Models (LLMs) in production. The case studies have been\ncarefully curated to focus on technical depth and practical problem-solving,\nwith an emphasis on implementation detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenml/llmops-database.","url":"https://huggingface.co/datasets/zenml/llmops-database","creator_name":"ZenML","creator_url":"https://huggingface.co/zenml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-classification","text-generation","news-articles-summarization"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Black_People_Face_Recognition","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tBlack people Face Detection Dataset: 3M+ Identities\n\t\n\nLarge human faces dataset for face recognition models (10M+ images)\nShare with us your feedback and recieve additional samples for free!ðŸ˜Š\nFull version of dataset is availible for commercial usage - leave a request on our website Axon Labs to purchase the dataset ðŸ’°\nDataset targeting 1:N and 1:1 NIST face recognition tests. Dataset contains 3M individuals, each with 3-5 images containing their faces\nThe dataset is â€œcleanedâ€ and hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/Black_People_Face_Recognition.","url":"https://huggingface.co/datasets/AxonData/Black_People_Face_Recognition","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","video-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"FEVER-256-24-gpt-4o-2024-05-13-961879","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFEVER-256-24-gpt-4o-2024-05-13-961879 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"dataset search for fact verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FEVER-256-24-gpt-4o-2024-05-13-961879 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-961879.","url":"https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-961879","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FEVER-256-24-gpt-4o-2024-05-13-961879","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFEVER-256-24-gpt-4o-2024-05-13-961879 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"dataset search for fact verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FEVER-256-24-gpt-4o-2024-05-13-961879 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-961879.","url":"https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-961879","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"compact-jailbreaks","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Featurization: Extracting Compact Jailbreaks\n\t\n\nThis repository contains the datasets used in our case study on extracting compact representations of jailbreak tactics, demonstrating how our unsupervised featurization pipeline can effectively compress large sets of adversarial prompts while maintaining their effectiveness and diversity.\n\n\t\n\t\t\n\t\tFeaturization - WildTeaming\n\t\n\nAccess both the input dataset from WildTeaming and the evaluation stage outputs containing candidateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bravansky/compact-jailbreaks.","url":"https://huggingface.co/datasets/Bravansky/compact-jailbreaks","creator_name":"Michal","creator_url":"https://huggingface.co/Bravansky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","language-modeling","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"resampled_IDS_datasets","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for resampled_IDS_datasets\n\t\n\nIntrusion Detection Systems (IDS) play a crucial role in securing computer networks against malicious activities. However, their efficacy is consistently hindered by the persistent challenge of class imbalance in real-world datasets. While various methods, such as resampling techniques, ensemble methods, cost-sensitive learning, data augmentation, and so on, have individually addressed imbalance classification issues, there exists a notableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Thi-Thu-Huong/resampled_IDS_datasets.","url":"https://huggingface.co/datasets/Thi-Thu-Huong/resampled_IDS_datasets","creator_name":"Le","creator_url":"https://huggingface.co/Thi-Thu-Huong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","apache-2.0","100M<n<1B"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24-gpt-4o-2024-05-13-46337","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24-gpt-4o-2024-05-13-46337 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24-gpt-4o-2024-05-13-46337 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-13-46337.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-13-46337","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24-gpt-4o-2024-05-13-46337","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24-gpt-4o-2024-05-13-46337 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24-gpt-4o-2024-05-13-46337 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-13-46337.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-13-46337","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Unite-Base-Retrieval-Train","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them â€” the content remains exactly the same. The only difference lies in the compression method, which now allows for quickerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"Unite-Base-Retrieval-Train","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them â€” the content remains exactly the same. The only difference lies in the compression method, which now allows for quickerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"Unite-Base-Retrieval-Train","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tModality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tStatistics\n\t\n\n\n    \n\n\n\n\t\n\t\t\n\t\tAccessing Images and Videos\n\t\n\n\n2025-06-19: We've updated the compressed archives for all image and video files to enable faster extraction.If you've already downloaded the previous files, there's no need to redownload them â€” the content remains exactly the same. The only difference lies in the compression method, which now allows for quickerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train.","url":"https://huggingface.co/datasets/friedrichor/Unite-Base-Retrieval-Train","creator_name":"Kong","creator_url":"https://huggingface.co/friedrichor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","image-feature-extraction","video-text-to-text"],"keywords_longer_than_N":true},
	{"name":"wximg_vl","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wx1995/wximg_vl.","url":"https://huggingface.co/datasets/wx1995/wximg_vl","creator_name":"wuxiang","creator_url":"https://huggingface.co/wx1995","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Copernicus-Pretrain","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Copernicus-Pretrain\n\t\n\n\n\nCopernicus-Pretrain is a large-scale EO pretraining dataset with 18.7M aligned images covering all major Sentinel missions (S1,2,3,5P).\nOfficially named Copernicus-Pretrain, also referred to as SSL4EO-S (\"S\" means Sentinel), as an extension of SSL4EO-S12 to the whole Sentinel series.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\nCopernicus-Pretrain contains 18.7M aligned imagery from all major Sentinel missions in operation (Sentinel-1 SAR, Sentinel-2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wangyi111/Copernicus-Pretrain.","url":"https://huggingface.co/datasets/wangyi111/Copernicus-Pretrain","creator_name":"Yi Wang","creator_url":"https://huggingface.co/wangyi111","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","cc-by-4.0","10M<n<100M","Geospatial"],"keywords_longer_than_N":true},
	{"name":"search_in_text-01","keyword":"feature-extraction","description":"This is a simple dataset generated by GPT-4o mini for accurate text search in Russian.\nFormat:\nStory: a story between 500 and 1500 words\nqa [list]:\n\nq: A question that has an answer as a quote in the text (if thereâ€™s no answer, itâ€™s left blank)\na: The answer to the questionâ€”if available, it's a quote; if not, the field is left blank\nreply: the starting and ending character positions of the quote (accuracy check)â€”if the answer is blank, reply is \"from 0 to 0\".\n\nThe dataset can be used in searchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ifmain/search_in_text-01.","url":"https://huggingface.co/datasets/ifmain/search_in_text-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Russian","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24-gpt-4o-2024-05-13-50353","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24-gpt-4o-2024-05-13-50353 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24-gpt-4o-2024-05-13-50353 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-50353.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-50353","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24-gpt-4o-2024-05-13-50353","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24-gpt-4o-2024-05-13-50353 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24-gpt-4o-2024-05-13-50353 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-50353.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-50353","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-06052024-irct-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-06052024-irct-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance search for car policies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-irct-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-irct-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-irct-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-06052024-irct-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-06052024-irct-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance search for car policies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-irct-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-irct-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-irct-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-449863","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-449863 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-449863 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-449863.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-449863","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-449863","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-449863 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-449863 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-449863.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-449863","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"rhvex-affects","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for rhvex-affects\n\t\n\nThis Dataset is extracted from publicly available Vulnerability Exploitability eXchange (VEX) files published by Red Hat.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nRed Hat security data is a central source of truth for Red Hat products regarding published, known vulnerabilities.\nThis data is published in form of Vulnerability Exploitability eXchange (VEX) available at: \nhttps://security.access.redhat.com/data/csaf/v2/vex/\nThis Dataset is created by extractingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vdanen/rhvex-affects.","url":"https://huggingface.co/datasets/vdanen/rhvex-affects","creator_name":"Vincent Danen","creator_url":"https://huggingface.co/vdanen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","text-generation","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5152024-tsbl-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5152024-tsbl-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Ticket assignment\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5152024-tsbl-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5152024-tsbl-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5152024-tsbl-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5152024-tsbl-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5152024-tsbl-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Ticket assignment\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5152024-tsbl-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5152024-tsbl-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5152024-tsbl-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DEEPFRUlT_DATASET","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDeepFruit Dataset\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains total of 21,122 fully labeled images, featuring 20 different kinds of fruits. It is structured into an 80% training set (16,899 images) and a 20% testing set (4,223 images), facilitating a ready-to-use framework for model training and evaluation.\nAdditionally, there are two CSV files that label the types of fruits depicted in each image.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe \"DeepFruit\" dataset is a comprehensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET.","url":"https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET","creator_name":"shangrong chi","creator_url":"https://huggingface.co/sc890","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Casrel_Chinese","keyword":"feature-extraction","description":"woshiyuanshengaoshou/Casrel_Chinese dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/woshiyuanshengaoshou/Casrel_Chinese","creator_name":"åˆ˜ç„‰","creator_url":"https://huggingface.co/woshiyuanshengaoshou","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ru-HNP","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tRuHNP\n\t\n\nRuHNP (Russian-Hard-Non-Paraphrases) is a freely available dataset of paraphrases.\nIt was generated using ChatGPT (gpt-3.5-turbo) with the aim to provide high-quality negative pairs to enhance understanding of paraphrases by sentence encoders.\nFor each text from Wikipedia, a neutral data source, we generate 5 positive and 5 negative pairs.\nA manual evaluation performed on several models shows that the distance between the distributions of the cosine similarity of positive andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepvk/ru-HNP.","url":"https://huggingface.co/datasets/deepvk/ru-HNP","creator_name":"deep vk","creator_url":"https://huggingface.co/deepvk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Russian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"syntheory","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for SynTheory\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSynTheory is a synthetic dataset of music theory concepts, specifically rhythmic (tempos and time signatures) and tonal (notes, intervals, scales, chords, and chord progressions). \nEach of these 7 concepts has its own config.\ntempos consist of 161 total integer tempos (bpm) ranging from 50 BPM to 210 BPM (inclusive), 5 percussive instrument types (click_config_name), and 5 random start time offsets (offset_time).\ntime_signaturesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meganwei/syntheory.","url":"https://huggingface.co/datasets/meganwei/syntheory","creator_name":"Megan Wei","creator_url":"https://huggingface.co/meganwei","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","feature-extraction","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"target-audience","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTarget Audience\n\t\n\nThis dataset contains text samples from the agentlans/high-quality-text collection (sample_k10000 config). \nIt uses the google/gemma-3-12b-it model to identify the target audience of each text and to rewrite the content to better appeal to that audience.\n\ntext: the original text from the dataset  \naudience: a detailed description of the textâ€™s intended target audience  \nrevised: the original text rewritten to better engage the identified audience\n\n{\n  \"text\": \"Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/target-audience.","url":"https://huggingface.co/datasets/agentlans/target-audience","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","odc-by","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"smartstein","keyword":"feature-extraction","description":"from datasets import load_dataset\nds = load_dataset(\"nyu-mll/glue\", \"ax\")\nfrom datasets import load_dataset\nds = load_dataset(\"nyu-mll/glue\", \"cola\")\nfrom datasets import load_dataset\nds = load_dataset(\"nyu-mll/glue\", \"mnli\")\n","url":"https://huggingface.co/datasets/jurgenpaul82/smartstein","creator_name":"westerveld","creator_url":"https://huggingface.co/jurgenpaul82","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","translation","text-generation","fill-mask"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-2024__6__12_-1217-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-2024__6__12_-1217-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Python programming\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-2024__6__12_-1217-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-2024__6__12_-1217-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-2024__6__12_-1217-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Python programming\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-2024__6__12_-1217-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MSK-Medical-Rehabilitation-Dialogue-Assessment","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMSK-Medical-Rehabilitation-Dialogue-Assessment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset combines medical consultations with rehabilitation engineering assessments for training models on healthcare dialogue and entity extraction tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Samples: 4,301\nMedical Consultations: 1,200 (from MTS-Dialog dataset)\nRehabilitation Assessments: 3,000 (synthetic, covering wheelchair/seating evaluations)\nFormat: Doctor-patient dialogues with structured clinicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Atereoyin/MSK-Medical-Rehabilitation-Dialogue-Assessment.","url":"https://huggingface.co/datasets/Atereoyin/MSK-Medical-Rehabilitation-Dialogue-Assessment","creator_name":"Ayuba Abiola","creator_url":"https://huggingface.co/Atereoyin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","feature-extraction","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-135760","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24-gpt-4o-2024-05-135760 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Q&A forum for Ubuntu users\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-135760 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-135760","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24-gpt-4o-2024-05-135760 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Q&A forum for Ubuntu users\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-135760 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"keywording","keyword":"image-feature-extraction","description":"umuth/keywording dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/umuth/keywording","creator_name":"umut hasanoÄŸlu","creator_url":"https://huggingface.co/umuth","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"GWFSS-competition","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nCompetition Page\nIf you want any update on the Global Wheat Dataset Community, go on https://www.global-wheat.com/\nWheat is a cornerstone of global food security, serving as a dietary staple for billions of people worldwide. Detailed analysis of wheat plants can help scientists and farmers cultivate healthier, more resilient, and more productive crops. The Global Wheat Full Semantic Segmentation (GWFSS) task aims to perform pixel-level segmentation of plant componentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XIANG-Shuai/GWFSS-competition.","url":"https://huggingface.co/datasets/XIANG-Shuai/GWFSS-competition","creator_name":"XIANG","creator_url":"https://huggingface.co/XIANG-Shuai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-segmentation","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-9xxb-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-9xxb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"literary search for narratives\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-9xxb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-9xxb-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-9xxb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-9xxb-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-9xxb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"literary search for narratives\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-9xxb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-9xxb-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-9xxb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ImplexConv-opposed","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“š Dataset Summary\n\t\n\nImplexConv is a large-scale dataset developed to evaluate implicit reasoning in long-term, multi-session conversations.The dataset is divided into two parts:\n\nSupportive Implicit Reasoning: Contains 814 examples.\nOpposed Implicit Reasoning: Contains 1,550 examples.\n\nEach example includes approximately 100 dialogue sessions, along with multiple question-answer pairs. The dataset challenges models to track long-term dependencies and reason beyond explicit context.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kaylee0501/ImplexConv-opposed.","url":"https://huggingface.co/datasets/Kaylee0501/ImplexConv-opposed","creator_name":"Xintong Li","creator_url":"https://huggingface.co/Kaylee0501","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-672024-v51y-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-672024-v51y-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-672024-v51y-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-672024-v51y-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-672024-v51y-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-672024-v51y-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-672024-v51y-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-672024-v51y-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-672024-v51y-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-672024-v51y-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Persian_Cooking","keyword":"feature-extraction","description":"dadashzadeh/Persian_Cooking dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/dadashzadeh/Persian_Cooking","creator_name":"dadashzadeh","creator_url":"https://huggingface.co/dadashzadeh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","question-answering","Persian","mit"],"keywords_longer_than_N":true},
	{"name":"imagenet-clip-features","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tUpdate; 9/26/2025\n\t\n\nHaving to download this whole repo is annoying, so I'm making sure the splits are named train/val/test (if they exist) and the named subset is the clip name.\n\n\t\n\t\t\n\t\tOlder non-dated updates\n\t\n\nEverything extracted with torch configured as deterministic; using seed 42 on an a100 using colab; so if it has variances from expectation it's on cuda.\nIt's a little quirky; \n\nMost of the splits have train, test, val. Many do not.\nMost of the splits have a proper \"image_id\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AbstractPhil/imagenet-clip-features.","url":"https://huggingface.co/datasets/AbstractPhil/imagenet-clip-features","creator_name":"AbstractPhila","creator_url":"https://huggingface.co/AbstractPhil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-feature-extraction","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-475598","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-475598 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-475598 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-475598.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-475598","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-475598","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-475598 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-475598 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-475598.","url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-475598","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"imagenet-clip-features","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tUpdate; 9/26/2025\n\t\n\nHaving to download this whole repo is annoying, so I'm making sure the splits are named train/val/test (if they exist) and the named subset is the clip name.\n\n\t\n\t\t\n\t\tOlder non-dated updates\n\t\n\nEverything extracted with torch configured as deterministic; using seed 42 on an a100 using colab; so if it has variances from expectation it's on cuda.\nIt's a little quirky; \n\nMost of the splits have train, test, val. Many do not.\nMost of the splits have a proper \"image_id\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AbstractPhil/imagenet-clip-features.","url":"https://huggingface.co/datasets/AbstractPhil/imagenet-clip-features","creator_name":"AbstractPhila","creator_url":"https://huggingface.co/AbstractPhil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-feature-extraction","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"entity-attribute-sft-dataset-GPT-4.0-generated-v1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tEntity Attribute Dataset 50k (GPT-4.0 Generated)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Entity Attribute SFT Dataset (GPT-4.0 Generated) is a machine-generated dataset designed for instruction fine-tuning. It includes detailed product information generated based on the title of each product, aiming to create a structured catalog in JSON format. The dataset encompasses a variety of product categories such as food, home and kitchen, clothing, handicrafts, tools, automotive equipment, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BaSalam/entity-attribute-sft-dataset-GPT-4.0-generated-v1.","url":"https://huggingface.co/datasets/BaSalam/entity-attribute-sft-dataset-GPT-4.0-generated-v1","creator_name":"BaSalam","creator_url":"https://huggingface.co/BaSalam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","feature-extraction","Persian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Crab-RAG","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Crab RAG: Synthetic RAG Dataset\n\t\n\n\n\nThis dataset is synthetically generated using internal AI models to simulate various information retrieval and response generation tasks. It includes documents, entities, instructions, and responses, designed for use in RAG (Retrieval-Augmented Generation) systems.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe Crab RAG dataset is a synthetic collection aimed at facilitating the development and testing ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arzuhussein/Crab-RAG.","url":"https://huggingface.co/datasets/arzuhussein/Crab-RAG","creator_name":"Arzu Huseynov","creator_url":"https://huggingface.co/arzuhussein","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","feature-extraction","sentence-similarity","text-classification"],"keywords_longer_than_N":true},
	{"name":"retriever-princeton-nlp-CharXiv-clean","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nprinceton-nlp/CharXiv dataset that we processed.Although useless, we have created an empty answer column to facilitate the concatenation of this dataset with VQA datasets where only the quesion and image columns would be used to train a Colpali-type model or one of its derivatives.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{wang2024charxiv,\n  title={CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs},\n  author={Wang, Zirui and Xia, Mengzhou and He, Luxi andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/retriever-princeton-nlp-CharXiv-clean.","url":"https://huggingface.co/datasets/CATIE-AQ/retriever-princeton-nlp-CharXiv-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","French","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Cybersec-Mutli-domain","keyword":"feature-extraction","description":"Creator: Zain NadeemRole: Python Django Developer | Software Engineer | Prompt Engineer | Ethical HackerLicense: CC BY 4.0Records: ~220,000Format: JSONLLanguage: English\n\n\n\t\n\t\t\n\t\tðŸ“Œ Overview\n\t\n\nThe CyberSec Multi-Domain Dataset is a structured collection of synthetic and open-source cybersecurity data across five important domains. It is designed for building, testing, and benchmarking machine learning models in cybersecurity, threat intelligence, and automation systems.\nThis dataset helpsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZainNadeem7/Cybersec-Mutli-domain.","url":"https://huggingface.co/datasets/ZainNadeem7/Cybersec-Mutli-domain","creator_name":"Zain Nadeem","creator_url":"https://huggingface.co/ZainNadeem7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","text-retrieval","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Mathematics - Geometry for k-6 kids aligned with California common core standards\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Mathematics - Geometry for k-6 kids aligned with California common core standards\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"summarization-yahoo-stock-finance-article-text","keyword":"feature-extraction","description":"This is a summarization in format of key bullet points of various articles on financial stock related news from finance yahoo website.\nThe summarization model that was used here is llama3.3-70B\nThe dataset has a symbol, which is a stock that news article is related to.\n","url":"https://huggingface.co/datasets/vladlen32230/summarization-yahoo-stock-finance-article-text","creator_name":"vladlen32230","creator_url":"https://huggingface.co/vladlen32230","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","zero-shot-classification","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"Crypto_AltSeason_Sentiment_X_Twitter","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ¦ X-Twitter Scraper: Real-Time Search and Data Extraction Tool\n\t\n\nSearch and scrape X-Twitter (formerly Twitter) for posts by keyword, account, or trending topics. This no-code tool makes it easy to generate real-time, LLM-ready datasets for any AI or content use case.\nGet started with real-time scraping and structure tweet data instantly into clean JSON.\n\n\n\t\n\t\t\n\t\tðŸš€ Key Features\n\t\n\n\nâš¡ Real-Time Fetch â€“ Stream the latest tweets the moment theyâ€™re posted  \nðŸŽ¯ Flexible Search â€“ Filterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/Crypto_AltSeason_Sentiment_X_Twitter.","url":"https://huggingface.co/datasets/Gopher-Lab/Crypto_AltSeason_Sentiment_X_Twitter","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-2499","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-2499 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-2499 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-2499","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-2499 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-2499 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"allenai-soda","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSODA chat dataset\n\t\n\nThis is the SODA dataset in ShareGPT-like format.\nAccording to the dataset's creators: \"ðŸ¥¤SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions.\"\nThe following changes were made to the data:\n\nkept only dialogues with two people alternating turns\nthe SODA narrative was adapted into a system prompt for an AI to roleplay as the second person\nextra turns were removed so that each conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-soda.","url":"https://huggingface.co/datasets/agentlans/allenai-soda","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","text2text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"i-claudius-narrative-kg","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tI, Claudius Complete Series Narrative Knowledge Graph\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive narrative knowledge graph extracted from all 13 episodes of the BBC's \"I, Claudius\" (1976), analyzed using the Fabula V2 pipeline. The graph captures the complex web of Roman imperial politics, family dynamics, and power struggles across the reigns of Augustus, Tiberius, Caligula, and Claudius.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Nodes: 10,357\nTotal Relationships:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/brandburner/i-claudius-narrative-kg.","url":"https://huggingface.co/datasets/brandburner/i-claudius-narrative-kg","creator_name":"Mike Atherton","creator_url":"https://huggingface.co/brandburner","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["graph-ml","text-generation","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"pippa_deduped_detoxify_score","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"pippa_deduped_detoxify_score\"\n\t\n\nThis dataset is produced from using Detoxify (https://github.com/unitaryai/detoxify) on the dataset:\n\nPygmalionAI/PIPPA (deduped version only)\n\nOn cursory review, there are some outliers:\n\ncontent not marked for toxicity\ncontent marked for toxicity incorrectly\nsome content marked with high scores that doesn't seem toxic\nsome content not marked when clearly offensive\n\nHowever, the bulk seems to be fairly right on the mark, so I'mâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jtatman/pippa_deduped_detoxify_score.","url":"https://huggingface.co/datasets/jtatman/pippa_deduped_detoxify_score","creator_name":"James","creator_url":"https://huggingface.co/jtatman","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"edgar-corpus-htm2020","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tedgar-corpus-htm2020\n\t\n\ndataset_info:\n  features:\n  - name: filename\n    dtype: string\n  - name: cik\n    dtype: string\n  - name: text\n    dtype: string\n  splits:\n  - name: train\n    num_bytes: 1004707483.6321189\n    num_examples: 6505\n  - name: test\n    num_bytes: 26565670.58950414\n    num_examples: 172\n  - name: validation\n    num_bytes: 26256767.44311456\n    num_examples: 170\n  download_size: 851417906\n  dataset_size: 1057529921.6647376\n\n","url":"https://huggingface.co/datasets/pszemraj/edgar-corpus-htm2020","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","fill-mask","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"flan-t5-base-embed-refinedweb","keyword":"feature-extraction","description":"All of the data together is around 61GB. It's the last hidden states of 131,072 samples from refinedweb padded/truncated to 512 tokens on the left, fed through google/flan-t5-base.\nStructure:\n{\n  \"encoding\": List, shaped (512, 768) aka (tokens, d_model),\n  \"text\": String, the original text that was encoded,\n  \"attention_mask\": List, binary mask to pass to your model with encoding to not attend to pad tokens\n}\n\n","url":"https://huggingface.co/datasets/crumb/flan-t5-base-embed-refinedweb","creator_name":"crumb","creator_url":"https://huggingface.co/crumb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiHopRAG","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nA Dataset for Evaluating Retrieval-Augmented Generation Across Documents\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultiHop-RAG: a QA dataset to evaluate retrieval and reasoning across documents with metadata in the RAG pipelines. It contains 2556 queries, with evidence for each query distributed across 2 to 4 documents. The queries also involve document metadata, reflecting complex scenarios commonly found in real-world RAG applications.\n\n\t\n\t\t\n\t\tDataset Sourcesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yixuantt/MultiHopRAG.","url":"https://huggingface.co/datasets/yixuantt/MultiHopRAG","creator_name":"yixuan","creator_url":"https://huggingface.co/yixuantt","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","English","odc-by","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"msmarco_answerai_colbert_small_embeddings","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMS MARCO ColBERT Embeddings\n\t\n\nPre-computed ColBERT embeddings for MS MARCO using PyLate and answerdotai/answerai-colbert-small-v1.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\ndata/corpus/: 177 parquet files with document embeddings\ndata/queries/: 11 parquet files with query embeddings\ndata/qrels/train.parquet: Relevance judgments (532,751 pairs)\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load from directory (recommended for large datasets)\ncorpus =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WenxingZhu/msmarco_answerai_colbert_small_embeddings.","url":"https://huggingface.co/datasets/WenxingZhu/msmarco_answerai_colbert_small_embeddings","creator_name":"WenxingZhu","creator_url":"https://huggingface.co/WenxingZhu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"bee-wings-small","keyword":"feature-extraction","description":"Random Small","url":"https://huggingface.co/datasets/smaciu/bee-wings-small","creator_name":"Slawek Maciura","creator_url":"https://huggingface.co/smaciu","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","afl-3.0","1K - 10K","Image","Text"],"keywords_longer_than_N":true},
	{"name":"law.go.kr","keyword":"feature-extraction","description":" Legal case retrieval with Korean Precedents (powered by https://law.go.kr/)\n\nThis dataset repository maintains files required for legal case retrieval using Korean Precedents acquired from https://law.go.kr/\nFor codes and more information, refer to GitHub page\n","url":"https://huggingface.co/datasets/woalsdnd/law.go.kr","creator_name":"Jaemin Son","creator_url":"https://huggingface.co/woalsdnd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","feature-extraction","Korean","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"flan-t5-large-embed-refinedweb","keyword":"feature-extraction","description":"All of the data together is around 81.3GB. It's the last hidden states of 131,072 samples from refinedweb padded/truncated to 512 tokens on the left, fed through google/flan-t5-base.\nStructure:\n{\n  \"encoding\": List, shaped (512, 1024) aka (tokens, d_model),\n  \"text\": String, the original text that was encoded,\n  \"attention_mask\": List, binary mask to pass to your model with encoding to not attend to pad tokens\n}\n\n","url":"https://huggingface.co/datasets/crumb/flan-t5-large-embed-refinedweb","creator_name":"crumb","creator_url":"https://huggingface.co/crumb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"NOAA-Buoy","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNOAA Buoy meterological data\n\t\n\nNOAA Buoy Data was downloaded, processed, and cleaned for tasks pertaining to tabular data. The data consists of meteorological measurements. There are two datasets\n\nFrom 1980 through 2022 (denoted with \"years\" in file names)\nFrom Jan 2023 through end of Sept 2023 (denoted with \"2023\" in file names)\n\nThe original intended use is for anomaly detection in tabular data. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains weatherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Qdrant/NOAA-Buoy.","url":"https://huggingface.co/datasets/Qdrant/NOAA-Buoy","creator_name":"Qdrant","creator_url":"https://huggingface.co/Qdrant","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","tabular-classification","time-series-forecasting","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"EDA_on_IMDB_Movies_Dataset","keyword":"feature-extraction","description":"drossi/EDA_on_IMDB_Movies_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/drossi/EDA_on_IMDB_Movies_Dataset","creator_name":"Daniel Rossing","creator_url":"https://huggingface.co/drossi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc0-1.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"climate-codex","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tClimate Codex: Climate Technology Fundraisers Dataset\n\t\n\nClimate Codex is a dataset that compiles climate technology fundraiser data from March 2020 to February 5, 2024. The data has been collected from various newsletters and blogs, including CTVC by Sightline Climate, Keep Cool, and other potential sources in the future, such as Climatebase.org and Bloomberg Green. This dataset captures key investments, innovative startups, and significant fundraising events that aim to addressâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Xcissa/climate-codex.","url":"https://huggingface.co/datasets/Xcissa/climate-codex","creator_name":"Xcissa Innovations, LLP","creator_url":"https://huggingface.co/Xcissa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"OpenOrca","keyword":"feature-extraction","description":"ðŸ‹ The OpenOrca Dataset! ðŸ‹\n\n\n\nWe are thrilled to announce the release of the OpenOrca dataset!\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper.\nIt has been instrumental in generating high-performing model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n\n\t\n\t\t\n\t\n\t\n\t\tOfficial Models\n\t\n\n\n\t\n\t\n\t\n\t\tMistral-7B-OpenOrca\n\t\n\nOur latest model, the first 7B to score better overall than allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/polinaeterna/OpenOrca.","url":"https://huggingface.co/datasets/polinaeterna/OpenOrca","creator_name":"Polina Kazakova","creator_url":"https://huggingface.co/polinaeterna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"synthetic-introduction-extraction","keyword":"feature-extraction","description":"angelmmiguel/synthetic-introduction-extraction dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/angelmmiguel/synthetic-introduction-extraction","creator_name":"Angel M De Miguel","creator_url":"https://huggingface.co/angelmmiguel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Spanish","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"laion2b_multi_korean_subset_with_image","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tlaion2b_multi_korean_subset_with_image\n\t\n\nimg2datasetì„ í†µí•´ ë‹¤ìš´ë¡œë“œì— ì„±ê³µí•œ Bingsu/laion2B-multi-korean-subset ì´ë¯¸ì§€ë¥¼ ì •ë¦¬í•œ ë°ì´í„°ì…‹ìž…ë‹ˆë‹¤.\nì´ë¯¸ì§€ëŠ” 9,800,137ìž¥ìž…ë‹ˆë‹¤.\nì´ë¯¸ì§€ëŠ” ì§§ì€ ìª½ ê¸¸ì´ê°€ 256ì´ ë˜ë„ë¡ ë¦¬ì‚¬ì´ì¦ˆ ë˜ì—ˆìœ¼ë©°, í’ˆì§ˆ 100ì¸ webpíŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\t1. datasets\n\t\n\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"Bingsu/laion2b_multi_korean_subset_with_image\", streaming=True, split=\"train\")\n\n>>> dataset.features\n{'image': Image(decode=True, id=None),\n 'text': Value(dtype='string', id=None)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image.","url":"https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","extended|laion/laion2B-multi"],"keywords_longer_than_N":true},
	{"name":"RAGTruth_Xtended","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset provides response token logits and hidden states, complementing the underlying RAGTruth dataset. It has been generated using [https://github.com/jakobsnl/RAGTruth_Xtended].\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is built upon RAGTruth (github.com/ParticleMedia/RAGTruth), which consists of character-level annotation of different types of hallucination for responses to a given set of LLM tasks.\nOut of allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jakobsnel/RAGTruth_Xtended.","url":"https://huggingface.co/datasets/jakobsnel/RAGTruth_Xtended","creator_name":"Jakob Snel","creator_url":"https://huggingface.co/jakobsnel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","text-classification","feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs-tr","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"malhajar/orca_dpo_pairs-tr\"\n\t\n\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish dataset collection to enhance the performance of LLM's Produced in the Turkish Language.\nmalhajar/orca_dpo_pairs-tr is a translated version of HuggingFaceH4/orca_dpo_pairs\nTranslated by: Mohamad Alhajar \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is a pre-processed version of the OpenOrca dataset translated to Turkish.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/orca_dpo_pairs-tr.","url":"https://huggingface.co/datasets/malhajar/orca_dpo_pairs-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"sift1m","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tsift1m\n\t\n\nsift1m data, copied from http://corpus-texmex.irisa.fr/, published:\nJÃ©gou H, Douze M, Schmid C. Improving bag-of-features for large scale image search[J]. International journal of computer vision, 2010, 87(3): 316-336.\n\n","url":"https://huggingface.co/datasets/qbo-odp/sift1m","creator_name":"hgf","creator_url":"https://huggingface.co/qbo-odp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","original","apache-2.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"NDD","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNeoantigen Discovery Dataset (NDD) - v0.1\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Neoantigen Discovery Dataset (NDD) was developed with a clear focus on machine learning applications in neoantigen prediction. From the outset, NDD has been designed to support model development by systematically collecting a broad range of dimensions â€” including basic information, experimental labels, and ML-ready predictive features that can be directly used for training and validation.\nIn neoantigen researchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NeoDiscovery/NDD.","url":"https://huggingface.co/datasets/NeoDiscovery/NDD","creator_name":"Iris Jiang","creator_url":"https://huggingface.co/NeoDiscovery","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","n<1K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"fineweb-10bt-mxbai-pooled","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tEmbedpress: mixedbread large on Fineweb 10B sample\n\t\n\nThis is the 10Bt sample of Fineweb, embedded with Mixedbread AI's mixedbread-ai/mxbai-embed-large-v1.\nFor each document, we take the first 510 tokens (the model's max length -2 special tokens), and embed it, not using any instructions. Because the model was trained using Matryoshka Representation Learning, these embeddings can safely be truncated.\nThese are mainly useful for large-scale knowledge distillation.\nThe dataset consistsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stephantulkens/fineweb-10bt-mxbai-pooled.","url":"https://huggingface.co/datasets/stephantulkens/fineweb-10bt-mxbai-pooled","creator_name":"StÃ©phan Tulkens","creator_url":"https://huggingface.co/stephantulkens","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"fquad2_test","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"Fquad2_test\"\n\t\n\nThis dataset is released as part of FrenchBench, a benchmarking initiative for French Language Model evaluation.\nIt can be used for extractive QA, binary classifcation or infiormation retrieving evaluation !\n\n\t\n\t\t\n\t\tCite\n\t\n\n@misc{faysse2024croissantllm,\n      title={CroissantLLM: A Truly Bilingual French-English Language Model}, \n      author={Manuel Faysse and Patrick Fernandes and Nuno M. Guerreiro and AntÃ³nio Loison and Duarte M. Alves and Caioâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/manu/fquad2_test.","url":"https://huggingface.co/datasets/manu/fquad2_test","creator_name":"Manuel Faysse","creator_url":"https://huggingface.co/manu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","sentence-similarity","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"DecoyDB","keyword":"feature-extraction","description":"ðŸ”§Code, ðŸ“‚Dataset\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDecoyDB is a curated dataset of high-resolution protein-ligand complexes and their associated decoy structures. It is designed to support research on graph contrastive learning, binding affinity prediction, and structure-based drug discovery. The dataset is derived from experimentally resolved complexes and refined to ensure data quality.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach protein-ligand complex is stored in a nested directory under DecoyDB/, using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jiangteam/DecoyDB.","url":"https://huggingface.co/datasets/jiangteam/DecoyDB","creator_name":"Dr. Zhe Jiang's InterDisciplinary Emerging Artificial Intelligence Lab (IDEAL)","creator_url":"https://huggingface.co/jiangteam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_seasons","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Geo-Tagged Social Media Posts with Timestamps\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Seasons\" dataset is a collection of over 600,000 social media posts spanning 12 months and encompassing 15 distinct time zones. It focuses on six countries: Cuba, Iran, Russia, North Korea, Syria, and Venezuela, with each post containing textual content, timestamps, and geographical coordinates. The dataset's primary objective is to investigate the correlation between the timing of postsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_seasons.","url":"https://huggingface.co/datasets/yachay/text_coordinates_seasons","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"ChatGPT_tweets","keyword":"feature-extraction","description":"Dataset sourced from Twitter, featuring 30,000 rows of multilingual user feedback tweets about ChatGPT. Each row contains text feedback, reflecting diverse user experiences. This dataset, hosted on Hugging Face, provides valuable resources for language analysis and understanding user interactions across different languages. Potential use cases include language modeling, multilingual sentiment analysis, user behavior analysis, and training of machine learning models for natural languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MouezYazidi/ChatGPT_tweets.","url":"https://huggingface.co/datasets/MouezYazidi/ChatGPT_tweets","creator_name":"Mouez Yazidi","creator_url":"https://huggingface.co/MouezYazidi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"flan-t5-small-embed-refinedweb","keyword":"feature-extraction","description":"All of the data together is around 41GB. It's the last hidden states of 131,072 samples from refinedweb padded/truncated to 512 tokens on the left, fed through google/flan-t5-small.\nStructure:\n{\n  \"encoding\": List, shaped (512, 512) aka (tokens, d_model),\n  \"text\": String, the original text that was encoded,\n  \"attention_mask\": List, binary mask to pass to your model with encoding to not attend to pad tokens\n}\n\njust a tip, you cannot load this with the RAM in the free ver of google colab, notâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/crumb/flan-t5-small-embed-refinedweb.","url":"https://huggingface.co/datasets/crumb/flan-t5-small-embed-refinedweb","creator_name":"crumb","creator_url":"https://huggingface.co/crumb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Brain-Computer-Interaction-Eye-State-Classification","keyword":"feature-extraction","description":"gymprathap/Brain-Computer-Interaction-Eye-State-Classification dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/gymprathap/Brain-Computer-Interaction-Eye-State-Classification","creator_name":"Gym Prathap","creator_url":"https://huggingface.co/gymprathap","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"AnyPattern","keyword":"feature-extraction","description":"The dataset proposed in our paper \"AnyPattern: Towards In-context Image Copy Detection\".\nPlease go to Github for the code about how to use this dataset.\nHere, we show how to download this dataset.\n\n\t\n\t\t\n\t\tanypattern_v31\n\t\n\nfor letter in {a..z}; do\n  wget https://huggingface.co/datasets/WenhaoWang/AnyPattern/resolve/main/train/anypattern_v31_part_a$letter\ndone\nwget https://huggingface.co/datasets/WenhaoWang/AnyPattern/resolve/main/train/anypattern_v31_part_ba\n\ncat anypattern_v31_part_a{a..z}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WenhaoWang/AnyPattern.","url":"https://huggingface.co/datasets/WenhaoWang/AnyPattern","creator_name":"Wenhao Wang","creator_url":"https://huggingface.co/WenhaoWang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"docs-python-v1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for creating python docs from methods. This is formatted from semeru/code-code-galeras-code-completion-from-docstring-3k-deduped\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: semeru/code-code-galeras-code-completion-from-docstring-3k-deduped\nLanguage(s) (NLP): Python\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ASHu2/docs-python-v1.","url":"https://huggingface.co/datasets/ASHu2/docs-python-v1","creator_name":"Ashutosh Mishra","creator_url":"https://huggingface.co/ASHu2","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"KaLM-embedding-finetuning-data","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish, Chinese, Multilingual\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach in datasets is in the following format:\n\nquery, string, one query per sample\npos, list[string], usually containing one positive example\nneg, list[string], usually containing seven negative examples\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAll these datasets have been preprocessed and can be used for finetuning your embedding models.\n\n\t\n\t\t\nSource\nType\nCateg.\nLanguage\nPairs\nPairs(filtered)\n\n\n\t\t\nCodeFeedback\nRetrieval\ns2p\nenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KaLM-Embedding/KaLM-embedding-finetuning-data.","url":"https://huggingface.co/datasets/KaLM-Embedding/KaLM-embedding-finetuning-data","creator_name":"KaLM-Embedding","creator_url":"https://huggingface.co/KaLM-Embedding","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Chinese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"energy_induction_motor_simulation","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for energy_induction_motor_simulation\n\t\n\n\nThis dataset is simulated for four electrical motors using simulation modeling in MATLAB.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nAccurately forecasting electrical signals from three-phase Direct Torque Control (DTC) induction motors is crucial for achieving optimal motor performance and effective condition monitoring. However, the intricate nature of multiple DTC induction motors and the variability in operational conditions presentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Thi-Thu-Huong/energy_induction_motor_simulation.","url":"https://huggingface.co/datasets/Thi-Thu-Huong/energy_induction_motor_simulation","creator_name":"Le","creator_url":"https://huggingface.co/Thi-Thu-Huong","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","time-series-forecasting","English","mit"],"keywords_longer_than_N":true},
	{"name":"SudarTopic","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSudar Topics Dataset\n\t\n\n\n\t\n\t\t\n\t\tÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ\n\t\n\nÐ˜ÐµÑ€Ð°Ñ€Ñ…Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ñ‚Ð¾Ð¿Ð¸ÐºÐ¾Ð² Ð¸Ð· ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Sudar Books, ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‰Ð¸Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑÑ… Ñ Ñ€ÑƒÑÑÐºÐ¸Ð¼Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑÐ¼Ð¸ Ð¸ Ñ€Ð°Ð·Ð²ÐµÑ€Ð½ÑƒÑ‚Ñ‹Ð¼Ð¸ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ°Ð¼Ð¸ Ð´Ð»Ñ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸.\n\n\t\n\t\t\n\t\tÐ¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…\n\t\n\nÐ”Ð°Ñ‚Ð°ÑÐµÑ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ð¿Ð¾Ð»Ñ:\n\nid (int): Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ñ‚Ð¾Ð¿Ð¸ÐºÐ°\nparent_id (int, nullable): ID Ñ€Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÑÐºÐ¾Ð³Ð¾ Ñ‚Ð¾Ð¿Ð¸ÐºÐ° Ð² Ð¸ÐµÑ€Ð°Ñ€Ñ…Ð¸Ð¸\nhierarchy_level (int): Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ Ð² Ð¸ÐµÑ€Ð°Ñ€Ñ…Ð¸Ð¸ (0 - ÐºÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ)\ntopic_descr_ruâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/valeronserg/SudarTopic.","url":"https://huggingface.co/datasets/valeronserg/SudarTopic","creator_name":"Valeron Serg","creator_url":"https://huggingface.co/valeronserg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Russian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FracAtlas_dataset","keyword":"image-feature-extraction","description":"The \"FracAtlas\" dataset is a collection of musculoskeletal radiographs for fracture classification, localization, and segmentation. \nIt includes 4,083 X-Ray images with annotations in multiple formats.The annotations include bbox, segmentations, and etc. \nThe dataset is intended for use in deep learning tasks in medical imaging, specifically targeting the understanding of bone fractures. \nIt is freely available under a CC-BY 4.0 license.","url":"https://huggingface.co/datasets/yh0701/FracAtlas_dataset","creator_name":"Yuhan Hou","creator_url":"https://huggingface.co/yh0701","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":null,"first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-feature-extraction","English","cc-by-2.5"],"keywords_longer_than_N":true},
	{"name":"ClimateX","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tClimateX: Expert Confidence in Climate Statements\n\t\n\nWhat do LLMs know about climate? Let's find out!\n\n\t\n\t\t\n\t\tClimateX Dataset\n\t\n\nWe introduce the Expert Confidence in Climate Statements (ClimateX) dataset, a novel, curated, expert-labeled, natural language dataset of 8094 statements extracted or paraphrased from the IPCC Assessment Report 6: Working Group I report, Working Group II report, and Working Group III report, respectively.\nEach statement is labeled with the correspondingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rlacombe/ClimateX.","url":"https://huggingface.co/datasets/rlacombe/ClimateX","creator_name":"Romain Lacombe","creator_url":"https://huggingface.co/rlacombe","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","text-classification","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"SpanishParaphraseCorpora","keyword":"feature-extraction","description":"Spanish Paraphrase Corpora.\nThis is a dataset of a total of 6896 pairs of sentences, 314 paraphrased pairs of sentences and 6558 non-paraphrased pairs of sentences.'', MICAI 2020: Advances in Computational Intelligence pp 214â€“223.","url":"https://huggingface.co/datasets/GIL-UNAM/SpanishParaphraseCorpora","creator_name":"Grupo de IngenierÃ­a LingÃ¼Ã­stica","creator_url":"https://huggingface.co/GIL-UNAM","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","Spanish","cc0-1.0","n<1K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"gooaq_pairs_danish","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tGooAQ (Google Answers to Google Questions) question-answer pairs in Danish\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nThis dataset is a version of the GooAQ question-answer pairs dataset machine-translated from English to Danish (link to original dataset).\nMachine translation is performed using the Helsinki NLP English-to-Danish OPUS-MT model.\nThe dataset contains ~3M question-answer pairs and can be used to train embedding and question-answer models. Each pair consists of one question ('query') and oneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KennethTM/gooaq_pairs_danish.","url":"https://huggingface.co/datasets/KennethTM/gooaq_pairs_danish","creator_name":"Kenneth T Martinsen","creator_url":"https://huggingface.co/KennethTM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","Danish","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"wave-energy","keyword":"feature-extraction","description":"cmudrc/wave-energy dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cmudrc/wave-energy","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","feature-extraction","image-to-image","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Wikinews-multilingual","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tWikinews - weakly aligned multilingual pararell sentence datasets\n\t\n\nThis dataset contains 15,200 multilingual WikiNews articles in 33 languages.\nOut of 15,200 articles, 9,960 are non-English news and 5240 are English news.  All non-English news are linked to one of 5240 English news. Linked articles show the same event.\nList of non-English languages are: Spanish, French, German, Portuguese, Polish, Italian, Chinese, Russian, Japanese, Dutch, Swedish, Tamil, Serbian, Czech, Catalanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fumika/Wikinews-multilingual.","url":"https://huggingface.co/datasets/Fumika/Wikinews-multilingual","creator_name":"Fumika Isono","creator_url":"https://huggingface.co/Fumika","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"philippine-budget-2025-embeddings-minilm","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tPhilippine Budget 2025 - Vector Embeddings (all-MiniLM-L6-v2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains vector embeddings of the 2025 People's Budget of the Philippines, a citizen-friendly overview of the PHP 6.326 trillion national budget published by the Department of Budget and Management (DBM).\n\n\t\n\t\t\n\t\tSource Document\n\t\n\nThese embeddings are based on the 2025 People's Enacted Budget (English version, revised as of April 22, 2025).\nDirect Download Link: 2025 People'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-minilm.","url":"https://huggingface.co/datasets/pageman/philippine-budget-2025-embeddings-minilm","creator_name":"The Pageman","creator_url":"https://huggingface.co/pageman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-retrieval","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ColBERT-TREC-COVID","keyword":"feature-extraction","description":"This dataset consists ColBERTv2.0 document vectors for the entire TREC-COVID dataset from BeIR. That 128 dimension per token, with 180 tokens for each of 171332 documents. \nThe dataset was created using A100-40GB sponsored by Qdrant. The code to create these vectors is here: https://colab.research.google.com/drive/1hEhyleSrBz_mPyQJnRc0MwBenDuX1ahY?usp=sharing\nThis dataset was created for indexing experiments by Qdrant.\n","url":"https://huggingface.co/datasets/Qdrant/ColBERT-TREC-COVID","creator_name":"Qdrant","creator_url":"https://huggingface.co/Qdrant","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Table-Extraction","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTable Extract Dataset\n\t\n\nThis dataset is designed to evaluate the ability of large language models (LLMs) to extract tables from text. It provides a collection of text snippets containing tables and their corresponding structured representations in JSON format.\n\n\t\n\t\t\n\t\tSource\n\t\n\nThe dataset is based on the Table Fact Dataset, also known as TabFact, which contains 16,573 tables extracted from Wikipedia.\n\n\t\n\t\t\n\t\tSchema:\n\t\n\nEach data point in the dataset consists of two elements:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Effyis/Table-Extraction.","url":"https://huggingface.co/datasets/Effyis/Table-Extraction","creator_name":"Group","creator_url":"https://huggingface.co/Effyis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Student_Performance","keyword":"feature-extraction","description":"DElmazi/Student_Performance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/DElmazi/Student_Performance","creator_name":"Dina Elmazi","creator_url":"https://huggingface.co/DElmazi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"SlimOrca","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is a new curated subset of our OpenOrca data. This release provides an efficient means of reaching performance on-par with using larger slices of our data, while only including ~500k GPT-4 completions.\nThe key change in this dataset is that we've done an additional pass, using GPT-4 to remove answers which appear wrong based on the human annotations from the FLAN dataset.\nThis reduces the dataset size to only ~500k entries, allowing training to a similar quality levelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Open-Orca/SlimOrca.","url":"https://huggingface.co/datasets/Open-Orca/SlimOrca","creator_name":"OpenOrca","creator_url":"https://huggingface.co/Open-Orca","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entities-google-palm-gemini-embedding-001-100K","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for DBPedia 100K: Gemini Google Embedding Model 001\n\t\n\n100K vectors from DBPedia!\nEmbedding Model: Google's latest Embedding Model 001 -- the successor to the Gecko Models!\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n100K Google Embeddings -- 768 dimensions\nCreated: December 2023\nText used for Embedding: title (string) + text (string)\nEmbedding Model: Google's models/embedding-001\n\nCurated by: Nirant Kasliwal\nFunded by: Qdrant Gmbh\nLanguage(s) (NLP): Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nirantk/dbpedia-entities-google-palm-gemini-embedding-001-100K.","url":"https://huggingface.co/datasets/nirantk/dbpedia-entities-google-palm-gemini-embedding-001-100K","creator_name":"Nirant Kasliwal","creator_url":"https://huggingface.co/nirantk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Beacon","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBeacon Dataset for Sycophancy Evaluation\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Beacon dataset is designed to measure sycophantic bias in Large Language Models (LLMs) through a novel single-turn forced-choice evaluation paradigm. It consists of 420 carefully curated prompts, each paired with a principled response and a sycophantic alternative. Expert annotations rate responses on dimensions of Critical Thinking and Fluency, enabling fine-grained behavioral analysis.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sanskxr02/Beacon.","url":"https://huggingface.co/datasets/sanskxr02/Beacon","creator_name":"pandey","creator_url":"https://huggingface.co/sanskxr02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"unsupervised","keyword":"feature-extraction","description":"We do not maintain this repository further. For accessing the most recent Indonesian Fake News dataset that we created, please visit BRIN's dataverse:  https://data.brin.go.id/dataset.xhtml?persistentId=hdl:20.500.12690/RIN/7QBRKQ\n","url":"https://huggingface.co/datasets/nlp-brin-id/unsupervised","creator_name":"NLP Research Group - BRIN Indonesia","creator_url":"https://huggingface.co/nlp-brin-id","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Indonesian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Testone","keyword":"feature-extraction","description":"War455da/Testone dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/War455da/Testone","creator_name":"Tony face","creator_url":"https://huggingface.co/War455da","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","table-question-answering","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"Long-Term-Care-Aggregated-Data","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tProject 1 Proposal of the Long Term Care(LTC) Aggregated Dataset\n\t\n\nKAO, HSUAN-CHEN(Justin)   \nNetID: hk310\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe long-term care aggregated dataset, essential for conducting experience studies, is an extensive and valuable compilation of variables central to the analysis and prediction of long-term care (LTC) insurance products. This dataset integrates two critical files: one detailing claim incidence and the other capturing policy terminations. This merger isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mastergopote44/Long-Term-Care-Aggregated-Data.","url":"https://huggingface.co/datasets/mastergopote44/Long-Term-Care-Aggregated-Data","creator_name":"Justin Kao","creator_url":"https://huggingface.co/mastergopote44","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ECInstruct","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for ECInstruct\n\t\n\nOur paper was accepted to ICML 2024.\nECInstruct comprises 10 tasks, including attribute value extraction, product relation prediction, \nproduct matching, sentiment analysis, sequential recommendation, multiclass product classification, product\nsubstitute identification, query product rank, answerability prediction, and answer generation. \nECInstruct is split into training sets, validation sets, in-domain (IND)\ntest sets, and out-of-domain (OOD) test sets.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NingLab/ECInstruct.","url":"https://huggingface.co/datasets/NingLab/ECInstruct","creator_name":"Ning Lab","creator_url":"https://huggingface.co/NingLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"angle-UAE-pairs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tangle UAE pairs\n\t\n\nloaded the four datasets containing pairs for Universal AnglE Embeddings\n\nnote that qrecc is not included in this dataset\n\nmulti_nli (train set)\nsnli (train set)\nqqp (train set)\nmrpc (train set)\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/angle-UAE-pairs","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","feature-extraction","English","odc-by","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"cropData","keyword":"feature-extraction","description":"MuraliKrish/cropData dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MuraliKrish/cropData","creator_name":"Mallikarjun H T","creator_url":"https://huggingface.co/MuraliKrish","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"dbpedia-entities-openai-1M","keyword":"feature-extraction","description":"1M OpenAI Embeddings -- 1536 dimensions\nCreated: June 2023.\nText used for Embedding: title (string) + text (string)\nEmbedding Model: text-embedding-ada-002\nFirst used for the pgvector vs VectorDB (Qdrant) benchmark: https://nirantk.com/writing/pgvector-vs-qdrant/\n\n\t\n\t\t\n\t\tFuture work\n\t\n\nWe are planning to take this up to 10M (and possibly 100M) vectors. Contact @KShivendu_ on Twitter or mail to hello@nirantk.com if you want to help :)\n\n\t\n\t\t\n\t\tCredits:\n\t\n\nThis dataset was generated from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M.","url":"https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M","creator_name":"Kumar Shivendu","creator_url":"https://huggingface.co/KShivendu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"LIFD_Magnetic_Field_Data","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for LFID Magnetic Field Data\n\t\n\nYou will need the package\nhttps://chaosmagpy.readthedocs.io/en/master/\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA description of the dataset:\nThe gufm1 model is a global geomagnetic model based on spherical harmonics, covering the period 1590 - 1990, and is described in the publication:\nAndrew Jackson, Art R. T. Jonkers and Matthew R. Walker (2000), â€œFour centuries of geomagnetic secular variation from historical recordsâ€, Phil. Trans. R. Soc.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cemachelen/LIFD_Magnetic_Field_Data.","url":"https://huggingface.co/datasets/cemachelen/LIFD_Magnetic_Field_Data","creator_name":"Helen Burns","creator_url":"https://huggingface.co/cemachelen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","image-to-image","time-series-forecasting","object-detection","unconditional-image-generation"],"keywords_longer_than_N":true},
	{"name":"paperswithcode","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tA cleaned dataset from paperswithcode.com\n\t\n\nLast dataset update: July 2023\nThis is a cleaned up dataset optained from paperswithcode.com through their API service. It represents a set of around 56K carefully categorized papers into 3K tasks and 16 areas. The papers contain arXiv and NIPS IDs as well as title, abstract and other meta information.\nIt can be used for training text classifiers that concentrate on the use of specific AI and ML methods and frameworks.\n\n\t\n\t\t\n\t\n\t\n\t\tContentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/J0nasW/paperswithcode.","url":"https://huggingface.co/datasets/J0nasW/paperswithcode","creator_name":"Jonas Wilinski","creator_url":"https://huggingface.co/J0nasW","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cv_backbones","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"monetjoe/cv_backbones\"\n\t\n\nThis repository consolidates the collection of backbone networks for pre-trained computer vision models available on the PyTorch official website. It mainly includes various Convolutional Neural Networks (CNNs) and Vision Transformer models pre-trained on the ImageNet1K dataset. The entire collection is divided into two subsets, V1 and V2, encompassing multiple classic and advanced versions of visual models. These pre-trained backboneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/monetjoe/cv_backbones.","url":"https://huggingface.co/datasets/monetjoe/cv_backbones","creator_name":"Monet","creator_url":"https://huggingface.co/monetjoe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"aal_stats_vol","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for aal_stats_vol\n\t\n\nThe AAL (Automated Anatomical Labeling) Statistical Volume Dataset provides a comprehensive collection of brain volume measurements based on AAL atlases. It covers statistical information on brain regions derived from structural magnetic resonance imaging (MRI) scans. Researchers commonly utilize this dataset for studies related to neuroimaging, neuroscience, and structural analysis of the brain.The AAL Statistical Volume Dataset plays a key role inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Genius-Society/aal_stats_vol.","url":"https://huggingface.co/datasets/Genius-Society/aal_stats_vol","creator_name":"Genius Society","creator_url":"https://huggingface.co/Genius-Society","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-ru","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOpenOrca-ru\n\t\n\nThis is translated version of Open-Orca/OpenOrca into Russian.\n","url":"https://huggingface.co/datasets/d0rj/OpenOrca-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"TikTok_MostComment_Video_Transcription_Example","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“² Example Dataset: TikTok Scraper Tool\n\t\n\nðŸ‘‰ Start Scraping TikTok: TikTok Scraper Tool\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâš¡ Instant Transcription â€“ Turn any TikTok video into an AI-ready transcript  \nðŸŽ¯ Metadata â€“ Get the title, language description, and video hashtags  \nðŸ”— URL-Based Access â€“ Just drop in a TikTok video URL to start scraping  \nðŸ§© LLM-Ready Output â€“ Receive clean JSON ready for agents, RAG, or AI tools  \nðŸ’¸ Free Tier â€“ Use up to 100 queries during the beta period  \nðŸ’« Easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"project1","keyword":"feature-extraction","description":"This new dataset is designed to solve this great NLP task and is crafted with a lot of care.","url":"https://huggingface.co/datasets/Jiwonny29/project1","creator_name":"Jiwon Shin","creator_url":"https://huggingface.co/Jiwonny29","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"fmri-fm","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ§  MindEye: fMRI-to-Image Reconstruction Dataset\n\t\n\n\n\n\n\nMindEye is a groundbreaking fMRI-to-image dataset that enables state-of-the-art reconstruction and retrieval of viewed natural scene images from human brain activity.  \n\nðŸŽ¥ Built on the Natural Scenes Dataset (NSD), containing brain responses from 4 participants who passively viewed MS-COCO natural scenes during 7-Tesla fMRI scanning  \nðŸ† Achieves >90% accuracy across multiple reconstruction metrics and >93% top-1 retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AshwinKM2005/fmri-fm.","url":"https://huggingface.co/datasets/AshwinKM2005/fmri-fm","creator_name":"Ashwin K M","creator_url":"https://huggingface.co/AshwinKM2005","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","feature-extraction","mit","10K<n<100K","arxiv:2305.18274"],"keywords_longer_than_N":true},
	{"name":"drone-lsr","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLight Stable Representations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains aerial orthomosaic tiles captured at three different times of day (10:00, 12:00, and 15:00). The dataset is organized into three configurations: default (raw images + canopy height), dinov2_base (DINOv2 embeddings), and dinov3_sat (DINOv3 embeddings). All configurations share consistent train/test splits with matching tile identifiers for cross-referencing. The dataset is designed for trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mpg-ranch/drone-lsr.","url":"https://huggingface.co/datasets/mpg-ranch/drone-lsr","creator_name":"MPG Ranch","creator_url":"https://huggingface.co/mpg-ranch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-to-image","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for \"scidocs\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a modified version of the original scidocs dataset for retrieval tasks. The original is availabe here.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n    \"title\": \"Discovery of inference rules for question-answering\",\n    \"abstract\": \"One of the main challenges in question-answering is the potential mismatch between the expressions in questions and ...\",\n}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLukas22/scidocs.","url":"https://huggingface.co/datasets/LLukas22/scidocs","creator_name":"Lukas Kreussel","creator_url":"https://huggingface.co/LLukas22","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","feature-extraction","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"torch-issues","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gopikrsmscs/torch-issues.","url":"https://huggingface.co/datasets/gopikrsmscs/torch-issues","creator_name":"Gopikrishna Pavuluri","creator_url":"https://huggingface.co/gopikrsmscs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"good-catalogue","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Amazon Products 2023\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains product metadata from Amazon, filtered to include only products that became available in 2023. The dataset is intended for use in semantic search applications and includes a variety of product categories.\n\nNumber of Rows: 117,243\nNumber of Columns: 15\n\n\n\t\n\t\t\n\t\tData Source\n\t\n\nThe data is sourced from Amazon Reviews 2023. \nIt includes product information across multiple categories, with additionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aqorium/good-catalogue.","url":"https://huggingface.co/datasets/aqorium/good-catalogue","creator_name":"A. Q. Orium","creator_url":"https://huggingface.co/aqorium","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","sentence-similarity","English","mit"],"keywords_longer_than_N":true},
	{"name":"Indian_electoral_bond_dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card contains cleaned elctoral bond data (India) by matching the companies that have purchased the electoral bonds to the parties that have encashed them.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\n\n\nSource: Election commission of India\nSource files: https://www.eci.gov.in/disclosure-of-electoral-bonds\nData cleaning and curation: https://github.com/jyoti-sn/Elections/blob/main/Electoral_bond_Analysis.ipynbâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JyotiNayak/Indian_electoral_bond_dataset.","url":"https://huggingface.co/datasets/JyotiNayak/Indian_electoral_bond_dataset","creator_name":"Jyoti Shankar Nayak","creator_url":"https://huggingface.co/JyotiNayak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Chinese","keyword":"feature-extraction","description":"ðŸ‹ OpenOrca-Chinese æ•°æ®é›†ï¼ðŸ‹\n\næ„Ÿè°¢  Open-Orca/OpenOrca  æ•°æ®é›†çš„å‘å¸ƒï¼Œç»™å¹¿å¤§NLPç ”ç©¶äººå‘˜å’Œå¼€å‘è€…å¸¦æ¥äº†å®è´µçš„èµ„æºï¼  \nè¿™æ˜¯ä¸€ä¸ªå¯¹  Open-Orca/OpenOrca  æ•°æ®é›†ä¸­æ–‡ç¿»è¯‘çš„ç‰ˆæœ¬ï¼Œç¿»è¯‘å¼•æ“Žä¸º Google ç¿»è¯‘ï¼Œå¸Œæœ›èƒ½ç»™ä¸­æ–‡ LLM ç ”ç©¶åšå‡ºä¸€ç‚¹ç‚¹è´¡çŒ®ã€‚\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yys/OpenOrca-Chinese.","url":"https://huggingface.co/datasets/yys/OpenOrca-Chinese","creator_name":"yanyusong","creator_url":"https://huggingface.co/yys","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"OllaGen-1","keyword":"feature-extraction","description":"\n\n\n\t\n\t\t\n\t\tOllaGen1\n\t\n\n OllaBench Generator 1 - Generating Cognitive Behavioral QA for Cybersecurity\n\n   \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tLatest News\n\t\n\n\n[2024/06/11] The OllaBench Dataset is replacing this one.\n[2024/02/07] ðŸš€ OllaGen1 is Launched!\n\n\n\t\n\t\n\t\n\t\tOllaGen1 Overview\n\t\n\nThe grand challenge that most CEO's care about is maintaining the right level of cybersecurity at a minimum cost as companies are not able to reduce cybersecurity risks despite their increased cybersecurity investments [1]. Fortunatelyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/theResearchNinja/OllaGen-1.","url":"https://huggingface.co/datasets/theResearchNinja/OllaGen-1","creator_name":"Tam Nguyen","creator_url":"https://huggingface.co/theResearchNinja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"northwind_invocies","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNorthwind Invoices and Related Documents\n\t\n\nThis dataset contains a collection of invoices and related documents from the Northwind database, a sample database used by Microsoft for demonstrating database functionalities.\nThe invoices include information about the customer, the salesperson, the order date, order ID, product IDs, product names, quantities, unit prices, and total prices. The related documents include shipping documents and stock documents.\nThis dataset was created byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AyoubChLin/northwind_invocies.","url":"https://huggingface.co/datasets/AyoubChLin/northwind_invocies","creator_name":"ayoub cherguelaine","creator_url":"https://huggingface.co/AyoubChLin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"note-taking-v2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBullet Point Notes\n\t\n\nThis dataset contains English language text with their automatically-generated notes in point form.\n\nText samples from agentlans/high-quality-text-long sample_k10000 config.\ngoogle/gemma-3-12b-it was used to generate Markdown format notes for each sample.\n\n\n\t\n\t\t\n\t\n\t\n\t\tSee Also\n\t\n\nagentlans/note-taking, another point form dataset but with shorter texts.\n","url":"https://huggingface.co/datasets/agentlans/note-taking-v2","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Sand-Fire-ULDA","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSand and Fire Dataset Collection for ULDA\n\t\n\n\n\t\n\t\t\n\t\tUnified Language-driven Zero-shot Domain Adaptation\n\t\n\nGitHub: https://github.com/Yangsenqiao/ULDA/\nHomepage: https://senqiaoyang.com/project/ulda/\nPaper: https://arxiv.org/pdf/2404.07155\n","url":"https://huggingface.co/datasets/Senqiao/Sand-Fire-ULDA","creator_name":"Senqiao Yang","creator_url":"https://huggingface.co/Senqiao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"time-entries-and-phases","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTime Entry Dataset at a Glance\n\t\n\n\n31 litigation matters\nâ‰ˆ13k unique time entries\nâ‰ˆ20k hours of billed time\n4 phases labeled: Pleading, Discovery, Pretrial, Trial\n\nLaw firm invoices were OCRed with tersseract 3.0, LLMs extracted time entries, with manual data cleaning. \nSource PDF documents available on request.\n\n\t\n\t\t\n\t\n\t\n\t\tSample: New York Commercial Contract Case\n\t\n\nTime entries for an example matter are shown for a New York commercial contract dispute: \n\n\t\n\t\t\nTitle\nCowen and Companyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LexPipe/time-entries-and-phases.","url":"https://huggingface.co/datasets/LexPipe/time-entries-and-phases","creator_name":"LexPipe, Inc.","creator_url":"https://huggingface.co/LexPipe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs.","url":"https://huggingface.co/datasets/fine-tuned/scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs.","url":"https://huggingface.co/datasets/fine-tuned/scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Legal document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Legal document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-64-24-gpt-4o-2024-05-136897","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-64-24-gpt-4o-2024-05-136897 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-64-24-gpt-4o-2024-05-136897 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136897.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-64-24-gpt-4o-2024-05-136897","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-64-24-gpt-4o-2024-05-136897 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-64-24-gpt-4o-2024-05-136897 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136897.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-632024-34lw-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-632024-34lw-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-632024-34lw-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-632024-34lw-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-632024-34lw-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-632024-34lw-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-632024-34lw-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-632024-34lw-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-632024-34lw-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-632024-34lw-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"The_Stack_Processed-v2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ”¥ The Stack Processed V2\n\t\n\nA curated, balanced, and ML-optimized multi-language programming dataset\n\n\n\n\n\n\n\t\n\t\n\t\n\t\tðŸŽ¯ Why Choose This Dataset?\n\t\n\nA meticulously curated version of \"The Stack\" optimized for training robust multi-language code models. Perfect balance between quality, diversity, and usability.\nâœ¨ Key Advantages:\n\nðŸŽ¯ Perfect Balance: ~10,000 files per major programming language\nâš¡ Training-Ready: Parquet format optimized for ML workflows  \nðŸ† Superior Quality: 91.3% syntaxâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vinsblack/The_Stack_Processed-v2.","url":"https://huggingface.co/datasets/vinsblack/The_Stack_Processed-v2","creator_name":"Vincenzo Gallo","creator_url":"https://huggingface.co/vinsblack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","text-classification","code","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-221689","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-221689 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-221689 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-221689","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-221689 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-221689 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-14062024-xdwa-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-14062024-xdwa-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"talent assessments in global organizations\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-14062024-xdwa-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-xdwa-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-xdwa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-14062024-xdwa-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-14062024-xdwa-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"talent assessments in global organizations\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-14062024-xdwa-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-xdwa-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-xdwa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"pokemoncards","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Pokemon Cards TCG\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information about Pokemon Trading Card Game (TCG) cards, decks, and sets. It is designed to be used for training machine learning models to classify and analyze Pokemon cards.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks: \nImage Classification\nText Classification\nInformation Retrieval\nImage-to-Text\nImage Feature Extraction\nImage Segmentation\nImage Classificationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tooni/pokemoncards.","url":"https://huggingface.co/datasets/tooni/pokemoncards","creator_name":"toni","creator_url":"https://huggingface.co/tooni","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-segmentation","sentence-similarity","image-to-text","image-feature-extraction"],"keywords_longer_than_N":true},
	{"name":"THEBUCKETv1","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tThe BUCKETv1 Datset\n\t\n\nThis dataset is published as part of our paper:\nSea-ing Through Scattered Rays: Revisiting the Image Formation Model for Realistic Underwater Image Generation\nAccepted in the CVAUI & AAMVEMV workshop in ICCV 2025 \n\nProject page: https://vap.aau.dk/sea-ing-through-scattered-rays/\nCode: https://github.com/vismiroglou/STSR\narXiv: https://arxiv.org/abs/2509.15011\n\n\n\t\n\t\n\t\n\t\tDataset Description:\n\t\n\nThe purpose of this dataset is to study the effects of turbidity onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vapaau/THEBUCKETv1.","url":"https://huggingface.co/datasets/vapaau/THEBUCKETv1","creator_name":"Visual Analysis and Perception Lab, Aalborg University","creator_url":"https://huggingface.co/vapaau","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Weather_Heatwave_Real-Time_X-Twitter_Example","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ¦ X-Twitter Scraper: Real-Time Search and Data Extraction Tool\n\t\n\nSearch and scrape X-Twitter (formerly Twitter) for posts by keyword, account, or trending topics. This no-code tool makes it easy to generate real-time, LLM-ready datasets for any AI or content use case.\nGet started with real-time scraping and structure tweet data instantly into clean JSON.\nðŸ‘‰ Launch Scraper Tool\n\n\t\n\t\t\n\t\n\t\n\t\tðŸš€ Key Features\n\t\n\n\nâš¡ Real-Time Fetch â€” Stream the latest tweets the moment theyâ€™re posted\nðŸŽ¯â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/Weather_Heatwave_Real-Time_X-Twitter_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/Weather_Heatwave_Real-Time_X-Twitter_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"danbooru_wikis_full","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDanbooru Full Wiki Dataset\n\t\n\nThis is the full wiki dataset of danbooru.donmai.us, containing the wiki pages/tags/tag aliases/tag implications. You can train something like LLMs on this dataset\n","url":"https://huggingface.co/datasets/itterative/danbooru_wikis_full","creator_name":"itterative","creator_url":"https://huggingface.co/itterative","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"nyuv2","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tNYUv2\n\t\n\nThis is an unofficial and preprocessed version of NYU Depth Dataset V2 made available for easier integration with modern ML workflows. The dataset was converted from the original .mat format into a split structure with embedded RGB images, depth maps, semantic masks, and instance masks in Hugging Face-compatible format.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“¸ Sample Visualization\n\t\n\n\n  \n    \n      \n        \n        RGB\n      \n      \n        \n        Depth (Jet colormap)\n        \n        Semantic Maskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jagennath-hari/nyuv2.","url":"https://huggingface.co/datasets/jagennath-hari/nyuv2","creator_name":"Jagennath Hari","creator_url":"https://huggingface.co/jagennath-hari","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","image-segmentation","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"rips-koren-torah-xlatin-corpus","keyword":"feature-extraction","description":"Source\n: TorahBibleCodes / TorahBibleCodes \nTransliterated into Latin script.\n","url":"https://huggingface.co/datasets/mad0perator/rips-koren-torah-xlatin-corpus","creator_name":"mad0perator.crypto","creator_url":"https://huggingface.co/mad0perator","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","translation","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"Cifer-Fraud-Detection-Dataset-AF","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“Š Cifer Fraud Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ§  Overview\n\t\n\nThe Cifer-Fraud-Detection-Dataset-AF is a high-fidelity, fully synthetic dataset created to support the development and benchmarking of privacy-preserving, federated, and decentralized machine learning systems in financial fraud detection.\nThis dataset draws structural inspiration from the PaySim simulator, which was built using aggregated mobile money transaction data from a real financial provider operating in 14+ countries.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CiferAI/Cifer-Fraud-Detection-Dataset-AF.","url":"https://huggingface.co/datasets/CiferAI/Cifer-Fraud-Detection-Dataset-AF","creator_name":"Cifer","creator_url":"https://huggingface.co/CiferAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","feature-extraction","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"ZamAI-Pashto-Dataset-Cleaned","keyword":"feature-extraction","description":"tasal9/ZamAI-Pashto-Dataset-Cleaned dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/tasal9/ZamAI-Pashto-Dataset-Cleaned","creator_name":"Yaqoob Tasal","creator_url":"https://huggingface.co/tasal9","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Pashto","apache-2.0","10K<n<100K","Text"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-562024-j9xx-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-562024-j9xx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Internet Backbone and Colocation Provider\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-562024-j9xx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-562024-j9xx-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-562024-j9xx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-562024-j9xx-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-562024-j9xx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Internet Backbone and Colocation Provider\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-562024-j9xx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-562024-j9xx-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-562024-j9xx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"hal_univcotedazur_shs_articles_2013-2023","keyword":"feature-extraction","description":"The hal_data.csv dataset comes from a request on the HAL API (the French national open archive) limited to the UNIV-COTEDAZUR portal instance.\nThe request collects the bibliographic records of the SHS articles with abstract published between 2013 and 2023\nThe parameters passed in the url request are :\n\nq=docType_s:ART\nfq=abstract_s:[%22%22%20TO%20*]\nfq=domain_s:shs\nfq=publicationDateY_i:[2013%20TO%202023]\nfl=halId_s,doiId_s,uri_s,title_s,subTitle_s,authFullName_s,producedDate_s,journalTitle_sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Geraldine/hal_univcotedazur_shs_articles_2013-2023.","url":"https://huggingface.co/datasets/Geraldine/hal_univcotedazur_shs_articles_2013-2023","creator_name":"GÃ©raldine Geoffroy","creator_url":"https://huggingface.co/Geraldine","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","French","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"plism-dataset","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tPLISM dataset\n\t\n\nThis preprocessed dataset was directly generated from owkin/plism-dataset-tiles. It is meant to perform the features extraction in a more convenient way.\nAs such, this dataset contains 91 .h5 files each containing 16,278 images converted into numpy arrays. This allows for easy resuming but require 225 Go storage.\n\n\t\n\t\t\n\t\tHow to extract features\n\t\n\n\n[!IMPORTANT]\nðŸŽ‰ Check plismbench to perform the feature extraction of PLISM dataset and get run our robustness benchmarkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/owkin/plism-dataset.","url":"https://huggingface.co/datasets/owkin/plism-dataset","creator_name":"Owkin","creator_url":"https://huggingface.co/owkin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","cc-by-4.0","100B<n<1T","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Anti_Spoofing_Cut_print_attack","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tCut 2D Masks Presentation Attack Detection for Liveness Detection (2K+ individuals)\n\t\n\nLiveness Detection Dataset with video attacks with printed 2D masks. This dataset focuses on cutout photo print attacks which might be used by iBeta and NIST FATE to assess liveness detection algorithms. This dataset is tailored for training AI models to identify a variation of cutout 2D print attack\n\n\t\n\t\t\n\t\n\t\n\t\tFull version of dataset is availible for commercial usage - leave a request on ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/Anti_Spoofing_Cut_print_attack.","url":"https://huggingface.co/datasets/AxonData/Anti_Spoofing_Cut_print_attack","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","video-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"service-public-filtered","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ—‚ï¸ Service-Public Dataset (Filtered)\n\t\n\nThis dataset is a filtered version of AgentPublic/service-public.It only keeps the themes \"Travail â€“ Formation\" and \"Ressources humaines\", making it more focused and directly applicable for HR and employment-related RAG experiments.  \n\n\t\n\t\t\n\t\tðŸ“– License\n\t\n\nThis dataset is distributed under the Etalab Open License 2.0, the same as the original dataset.\n","url":"https://huggingface.co/datasets/edouardfoussier/service-public-filtered","creator_name":"Edouard Foussier","creator_url":"https://huggingface.co/edouardfoussier","license_name":"Etalab Open License 2.0 English","license_url":"https://scancode-licensedb.aboutcode.org/etalab-2.0-en.html","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","French","etalab-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"augmented_canonical_druglike_QED_43M","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDruglike QED 43M - Augmented SMILES Dataset\n\t\n\nThis dataset is derived from the Druglike molecule datasets for drug discovery dataset and has been canonicalized using RDKit (2024.9.4) to ensure structural consistency.  \nTo enhance molecular diversity, 33% of the dataset was randomly sampled and augmented using RDKitâ€™s Chem.MolToRandomSmilesVect function, following an approach similar to NVIDIA's molmim method for SMILES augmentation.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview:\n\t\n\n\nSource:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Derify/augmented_canonical_druglike_QED_43M.","url":"https://huggingface.co/datasets/Derify/augmented_canonical_druglike_QED_43M","creator_name":"Derify","creator_url":"https://huggingface.co/Derify","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","cc-by-4.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-562024-xbuk-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-562024-xbuk-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Documentation search for programming language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-xbuk-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-562024-xbuk-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-562024-xbuk-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Documentation search for programming language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-xbuk-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"survivorlib-chemistry-hatmaking","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tsurvivorlib: chemistry & hatmaking\n\t\n\nReference/test using olmOCR on some full PDF books from the survivor library archive\n","url":"https://huggingface.co/datasets/pszemraj/survivorlib-chemistry-hatmaking","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-512-192-gpt-4o-2024-05-13-43315","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-512-192-gpt-4o-2024-05-13-43315 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"news articles\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-512-192-gpt-4o-2024-05-13-43315 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-43315.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-43315","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-512-192-gpt-4o-2024-05-13-43315","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-512-192-gpt-4o-2024-05-13-43315 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"news articles\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-512-192-gpt-4o-2024-05-13-43315 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-43315.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-43315","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MultiOOD","keyword":"feature-extraction","description":"\n\nMultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities\n\n\n    Hao Dong1\n    â€ƒ\n    Yue Zhao2\n    â€ƒ\n    Eleni Chatzi1\n    â€ƒ\n    Olga Fink3\n\n\n    1ETH Zurich, 2University of Southern California, 3EPFL\n\n\n\n\n    \n        â€¢ arXiv â€¢\n    \n\n\n\n\n\n\n\n\n\n\n\nMultiOOD is the first-of-its-kind benchmark for Multimodal OOD Detection, characterized by diverse dataset sizes and varying modality combinations.\n\t\n\t\t\n\t\tCode\n\t\n\nhttps://github.com/donghao51/MultiOOD\n\n\t\n\t\t\n\t\tMultiOOD Benchmark\n\t\n\nMultiOODâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hdong51/MultiOOD.","url":"https://huggingface.co/datasets/hdong51/MultiOOD","creator_name":"Hao Dong","creator_url":"https://huggingface.co/hdong51","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","< 1K","webdataset"],"keywords_longer_than_N":true},
	{"name":"my-distiset-2248f47e","keyword":"feature-extraction","description":"kritsanan/my-distiset-2248f47e dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kritsanan/my-distiset-2248f47e","creator_name":"namoang","creator_url":"https://huggingface.co/kritsanan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Thai","English","mit","parquet"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-417900","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-417900 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-417900 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-417900.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-417900","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-417900","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-417900 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-417900 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-417900.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-417900","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-30052024-rc2l-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-30052024-rc2l-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-30052024-rc2l-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-30052024-rc2l-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-30052024-rc2l-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-30052024-rc2l-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-30052024-rc2l-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-30052024-rc2l-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-30052024-rc2l-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-30052024-rc2l-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"techcrunch-articles","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tTechCrunch News Articles Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset contains 10,265 high-quality news articles scraped from TechCrunch, one of the leading technology news websites. The dataset includes comprehensive article content, metadata, and quality assessments suitable for various NLP tasks including text classification, sentiment analysis, summarization, and content generation.\n\n\t\n\t\t\n\t\tðŸŽ¯ Key Features\n\t\n\n\n10,265 articles with full text content\nHigh-quality filteringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/techcrunch-articles.","url":"https://huggingface.co/datasets/abhilash88/techcrunch-articles","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","question-answering","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"alagoasideb","keyword":"feature-extraction","description":"A prÃ³xima versÃ£o desse modelo terÃ¡ um pequeno tratamento dos dados, em relaÃ§Ã£o ao tipo das colunas.\n","url":"https://huggingface.co/datasets/giseldo/alagoasideb","creator_name":"Giseldo Neo","creator_url":"https://huggingface.co/giseldo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Portuguese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Defective_Tires","keyword":"feature-extraction","description":"NMiriams/Defective_Tires dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NMiriams/Defective_Tires","creator_name":"Miriam Nanteza","creator_url":"https://huggingface.co/NMiriams","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-classification","cc-by-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"finance and investment\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"finance and investment\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sentinel-beetles","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Beetles as Sentinel Taxa: Predicting drought conditions from NEON specimen imagery\n\t\n\nThis dataset contains images of pinned carabid beetle specimens collected by the National Ecological Observatory Network (NEON) from ecological sites across the U.S., along with associated metadata and drought severity indices (Standardized Precipitation Evapotranspiration Index (SPEI)). It was developed to for the second HDR ML Challenge, and is intended to support the development ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imageomics/sentinel-beetles.","url":"https://huggingface.co/datasets/imageomics/sentinel-beetles","creator_name":"HDR Imageomics Institute","creator_url":"https://huggingface.co/imageomics","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","English","Latin","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-652024-vsmg-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-652024-vsmg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Insurance claim processing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-652024-vsmg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-652024-vsmg-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-652024-vsmg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-652024-vsmg-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-652024-vsmg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Insurance claim processing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-652024-vsmg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-652024-vsmg-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-652024-vsmg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting queries\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting queries\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-256-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tstackoverflow-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"competency-extraction-dpo-v2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tCompetency Extraction DPO Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Competency Extraction DPO Dataset is a specialized dataset designed to extract competency profiles from scientific publications. The dataset focuses on identifying and structuring competencies found within the abstracts of academic papers. It contains a total of 6,179 samples and provides valuable insights into automated competency extraction.\n\n\t\n\t\t\n\t\tDataset Format\n\t\n\nThe dataset follows the standard DPO dataset format withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BertilBraun/competency-extraction-dpo-v2.","url":"https://huggingface.co/datasets/BertilBraun/competency-extraction-dpo-v2","creator_name":"Bertil Braun","creator_url":"https://huggingface.co/BertilBraun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Road_following","keyword":"feature-extraction","description":"The road image dataset used for training the road_following_model\n","url":"https://huggingface.co/datasets/MianXu/Road_following","creator_name":"Mian Xu","creator_url":"https://huggingface.co/MianXu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-27052024-w9t8-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-27052024-w9t8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce search for intimate care products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-27052024-w9t8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-27052024-w9t8-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-27052024-w9t8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-27052024-w9t8-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-27052024-w9t8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce search for intimate care products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-27052024-w9t8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-27052024-w9t8-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-27052024-w9t8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SIH2025-json","keyword":"feature-extraction","description":"prof-freakenstein/SIH2025-json dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/prof-freakenstein/SIH2025-json","creator_name":"Anurag Kumar Singh","creator_url":"https://huggingface.co/prof-freakenstein","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HR-VILAGE-3K3M","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tHR-VILAGE-3K3M: Human Respiratory Viral Immunization Longitudinal Gene Expression\n\t\n\nThis repository provides the HR-VILAGE-3K3M dataset, a curated collection of human longitudinal gene expression profiles, antibody measurements, and aligned metadata from respiratory viral immunization and infection studies. The dataset includes baseline transcriptomic profiles and covers diverse exposure types (vaccination, inoculation, and mixed exposure). HR-VILAGE-3K3M is designed as a benchmarkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xuejun72/HR-VILAGE-3K3M.","url":"https://huggingface.co/datasets/xuejun72/HR-VILAGE-3K3M","creator_name":"Xuejun Sun","creator_url":"https://huggingface.co/xuejun72","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","feature-extraction","token-classification","summarization","fill-mask"],"keywords_longer_than_N":true},
	{"name":"druglike","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDruglike - Augmented SMILES Dataset\n\t\n\nThis dataset is derived from various datasets which were collated, deduped, and processed to create a comprehensive collection of druglike molecules. The combined dataset has been canonicalized using RDKit (2024.9.4) to ensure structural consistency.\nTo enhance molecular diversity, 33% of the dataset was randomly sampled and augmented using RDKit's Chem.MolToRandomSmilesVect function, following an approach similar to NVIDIA's molmim method forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Derify/druglike.","url":"https://huggingface.co/datasets/Derify/druglike","creator_name":"Derify","creator_url":"https://huggingface.co/Derify","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-512-192-gpt-4o-2024-05-13-768442 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-512-192-gpt-4o-2024-05-13-768442 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442.","url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-499715","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-499715 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-499715 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-499715","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-499715 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-499715 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Item-SID","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for AL-GR-Item-SID\n\t\n\nPaper | Code | Project Page\n\n\t\n\t\t\n\t\tðŸ“– Dataset Description\n\t\n\nAL-GR-Item-SID is a dataset containing Semantic IDs (SIDs) for products from an anonymized e-commerce platform. These IDs are generated using a multi-modal model and are specifically designed to serve as dense, meaningful features for Generative Recommendation systems, such as the LLM model.\nUnlike traditional sparse item IDs (e.g., item_12345), Semantic IDs are sequences of discrete tokensâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/Item-SID.","url":"https://huggingface.co/datasets/AL-GR/Item-SID","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"latent_imagenet","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tVQGAN-Processed ImageNet Test Latents\n\t\n\nThis dataset contains the ImageNet Test images encoded into 3Ã—64Ã—64 latent representations using VQGAN.These latent features can be used for tasks such as image generation, compression, and semantic communication research.\n\n\t\n\t\t\n\t\tExample\n\t\n\nThe figures below show the visualization of a sample in the latent space (3 channels):\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tlatent_imagenet (VQGAN-encoded ImageNet Test Set)\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset containsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/liangzhidanta/latent_imagenet.","url":"https://huggingface.co/datasets/liangzhidanta/latent_imagenet","creator_name":"çŽ‹å¤§åŠ›","creator_url":"https://huggingface.co/liangzhidanta","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","zero-shot-classification","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MegaDepth-Syn","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tMegaDepth-Syn Dataset\n\t\n\nThe MegaDepth-Syn Dataset is generated from the MegaDepth dataset\nusing our MINIMA data engine, which contains for extra 6 modalities: infrared, depth, event, normal, sketch, and paint.\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nImage matching for both cross-view and cross-modality plays a critical role in multimodal perception. In practice, the\nmodality gap caused by different imaging systems/styles poses great challenges to the matching task. Existing works try\nto extract invariantâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lsxi77777/MegaDepth-Syn.","url":"https://huggingface.co/datasets/lsxi77777/MegaDepth-Syn","creator_name":"Jiangwei Ren","creator_url":"https://huggingface.co/lsxi77777","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","apache-2.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"mtg-cards-SIFT-Features","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMTG Card SIFT Features Dataset (v5.1)\n\t\n\n\nThis dataset contains the latest incremental MTG card SIFT + RootSIFT feature extraction pipeline. It is designed for server-side production inference, enabling additive updates to the FAISS index and id_map.json without retraining or reindexing from scratch.\n\nNote: This version aligns with a daily resources-nightly.zip Hugging Face upload workflow for reliable continuous deployment via my production server.\n\n\n\n\t\n\t\n\t\n\t\tWhatâ€™s New in v5.1?â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features.","url":"https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features","creator_name":"Jake Turner","creator_url":"https://huggingface.co/JakeTurner616","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"COIL-100","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for COIL-100\n\t\n\n\nThis is a FiftyOne dataset with 7200 samples.\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nimport fiftyone.utils.huggingface as fouh\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = fouh.load_from_hub(\"Voxel51/COIL-100\")\n\n# Launch the App\nsession = fo.launch_app(dataset)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/COIL-100.","url":"https://huggingface.co/datasets/Voxel51/COIL-100","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-to-3d","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"expresso-conversational-en-nano-codec-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tExpresso Conversational EN Nano-Codec Dataset\n\t\n\nThis dataset is built upon the Expresso conversational dataset and re-encoded using NVIDIAâ€™s NeMo Audio Codec into nano audio tokens.  \nIt is designed for fine-tuning multimodal LLMs and speech systems (TTS/ASR) that rely on codec-based audio token representations.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\ntext: transcription of the utterance.  \nspeaker: speaker identifier (string).  \nnano_layer_1 â€¦ nano_layer_4: tokenized audio representationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nineninesix/expresso-conversational-en-nano-codec-dataset.","url":"https://huggingface.co/datasets/nineninesix/expresso-conversational-en-nano-codec-dataset","creator_name":"NineNineSix","creator_url":"https://huggingface.co/nineninesix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Electric-Vehicle-Specs-Dataset-2025","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tâš¡ Electric Vehicle Specs Dataset 2025\n\t\n\nThis dataset provides a comprehensive collection of specifications and performance metrics for modern electric vehicles (EVs), scraped from EV-Database.org.\nIt supports use in:\n\nðŸ” Data science\nðŸ§  Machine learning\nðŸ“ˆ Market analysis\nâ™»ï¸ Sustainability studies\nðŸš— EV adoption research\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š Core Attributes\n\t\n\nEach row represents a specific EV model with attributes across:\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ· Brand & Classification\n\t\n\n\nBrand & Model:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/UrvishAhir1/Electric-Vehicle-Specs-Dataset-2025.","url":"https://huggingface.co/datasets/UrvishAhir1/Electric-Vehicle-Specs-Dataset-2025","creator_name":"Urvish Ahir","creator_url":"https://huggingface.co/UrvishAhir1","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Personal Development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Personal Development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5282024-hkt5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5282024-hkt5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5282024-hkt5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5282024-hkt5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5282024-hkt5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5282024-hkt5-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5282024-hkt5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5282024-hkt5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5282024-hkt5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5282024-hkt5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jurisprudence","keyword":"feature-extraction","description":"\n\n \n\n\t\n\t\t\n\t\n\t\n\t\tâœ¨ Jurisprudence, release v2025.03.20 ðŸ›ï¸\n\t\n\nJurisprudence is an open-source project that automates the collection and distribution of French legal decisions. It leverages the Judilibre API provided by the Cour de Cassation to:\n\nFetch rulings from major French courts (Cour de Cassation, Cour d'Appel, Tribunal Judiciaire)\nProcess and convert the data into easily accessible formats\nPublish & version updated datasets on Hugging Face every few days.It aims to democratize access toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/antoinejeannot/jurisprudence.","url":"https://huggingface.co/datasets/antoinejeannot/jurisprudence","creator_name":"Antoine Jeannot","creator_url":"https://huggingface.co/antoinejeannot","license_name":"Etalab Open License 2.0 English","license_url":"https://scancode-licensedb.aboutcode.org/etalab-2.0-en.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","zero-shot-classification","sentence-similarity","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"Luminous","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kskip/Luminous.","url":"https://huggingface.co/datasets/Kskip/Luminous","creator_name":"William Kyle Skipper","creator_url":"https://huggingface.co/Kskip","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","summarization","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"Ladder_Polymer","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ljding94/Ladder_Polymer.","url":"https://huggingface.co/datasets/ljding94/Ladder_Polymer","creator_name":"Lijie Ding","creator_url":"https://huggingface.co/ljding94","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K<n<10K","doi:10.57967/hf/5316"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MoE-Transformer-Model-Zoos","keyword":"feature-extraction","description":"Data.zip file can be found in Files and versions.\n","url":"https://huggingface.co/datasets/JohnDoe4765/MoE-Transformer-Model-Zoos","creator_name":"John Doe","creator_url":"https://huggingface.co/JohnDoe4765","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"herman-json-mode","keyword":"feature-extraction","description":"\n\n\t\n\t\t\n\t\tHerman: Indonesian Single-Turn JSON Mode\n\t\n\nHerman is an Indonesian language dataset specifically designed \nfor training LLMs using a single-turn JSON mode. This dataset \nis used in Supervised Fine-Tuning (SFT) to improve JSON parsing \ncapabilities in LLMs. Herman was obtained from Hermes and translated \ninto Indonesian for the purpose of training Indonesian language models.\nCode used for constructing Herman can be found here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema Format\n\t\n\nThe desired JSON schema canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SulthanAbiyyu/herman-json-mode.","url":"https://huggingface.co/datasets/SulthanAbiyyu/herman-json-mode","creator_name":"Sulthan Abiyyu Hakim","creator_url":"https://huggingface.co/SulthanAbiyyu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Indonesian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"picture_short_caption","keyword":"feature-extraction","description":"It is used for training to generate short sentence copywriting according to image content, the source of the image dataset is https://unsplash.com/, and the source of short sentence copywriting is Claude3.7\nç”¨åšå›¾ç‰‡å†…å®¹ç”ŸæˆçŸ­å¥æ–‡æ¡ˆè®­ç»ƒï¼Œå›¾ç‰‡æ•°æ®é›†æ¥è‡ª https://unsplash.com/ï¼ŒçŸ­å¥æ–‡æ¡ˆæ¥è‡ª Claude3.7 æ¨¡åž‹\n","url":"https://huggingface.co/datasets/xieyongfeng/picture_short_caption","creator_name":"xieyongfeng","creator_url":"https://huggingface.co/xieyongfeng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","text-classification","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"typed_digital_signatures","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tTyped Digital Signatures Dataset\n\t\n\nThis comprehensive dataset contains synthetic digital signatures rendered across 30 different Google Fonts, specifically selected for their handwriting and signature-style characteristics. Each font contributes unique stylistic elements, making this dataset ideal for robust signature analysis and font recognition tasks.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Fonts: 30 different Google Fonts\nImages per Font: 3,000 signatures\nTotal Dataset Size: ~90,000â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Benjy/typed_digital_signatures.","url":"https://huggingface.co/datasets/Benjy/typed_digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"rocket-league-replays","keyword":"feature-extraction","description":"chrisrca/rocket-league-replays dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/chrisrca/rocket-league-replays","creator_name":"Christian Reynolds","creator_url":"https://huggingface.co/chrisrca","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","mit","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-k007-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information in German\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-k007-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information in German\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CNTXTAI_Medical_Doctor_Notes","keyword":"feature-extraction","description":"Emergency Department Case Notes Dataset\nDataset Summary\nThis dataset contains 43 emergency department medical case notes, sourced from MTSamples, a widely recognized repository of medical transcription samples. Each entry includes a case title, category, and source link to a PDF document with detailed notes.\nThis dataset is highly valuable for medical research, categorization, and analysis. The structured format allows for efficient information retrieval and classification, making it aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Medical_Doctor_Notes.","url":"https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Medical_Doctor_Notes","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-15062024-atex-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-15062024-atex-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-1280-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c-1280-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Legal document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-1280-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-1280-24.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-1280-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-1280-24","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tdutch-legal-c-1280-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Legal document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-1280-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-1280-24.","url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-1280-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"smartphone-and-smartwatch-activity-and-biometrics-15m6","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSmartphone and Smartwatch Activity and Biometrics 15m6\n\t\n\nA 15.6-million-sample, multi-device time-series corpus that unites 3-axis accelerometer and gyroscope streams from 51 volunteers. Each participant carried a smartphone and smartwatch while performing 18 everyday activities for three minutes apiece, generating synchronized recordings sampled at 20 Hz.\nEvery record is formatted as:  \n\nsubject_id â€“ integer 1600â€“1650 uniquely identifying the volunteer\nactivity_code â€“ single ASCIIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mnemoraorg/smartphone-and-smartwatch-activity-and-biometrics-15m6.","url":"https://huggingface.co/datasets/mnemoraorg/smartphone-and-smartwatch-activity-and-biometrics-15m6","creator_name":"Mnemora Organization","creator_url":"https://huggingface.co/mnemoraorg","license_name":"Educational Community License v2.0","license_url":"https://choosealicense.com/licenses/ecl-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","ecl-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-afuz-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-afuz-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"genre-specific search for fantasy novels\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-afuz-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-afuz-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-afuz-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-afuz-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-afuz-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"genre-specific search for fantasy novels\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-afuz-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-afuz-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-afuz-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"experimental-paper-json-xtraction","keyword":"feature-extraction","description":"Shinapri/experimental-paper-json-xtraction dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Shinapri/experimental-paper-json-xtraction","creator_name":"Shinapri Delucania","creator_url":"https://huggingface.co/Shinapri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","feature-extraction","text-generation","table-question-answering"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-5222024-i8af-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-5222024-i8af-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"issue tracking search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-5222024-i8af-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-5222024-i8af-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-5222024-i8af-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-5222024-i8af-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-5222024-i8af-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"issue tracking search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-5222024-i8af-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-5222024-i8af-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-5222024-i8af-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ClimateFEVER-256-24-gpt-4o-2024-05-13-918964","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tClimateFEVER-256-24-gpt-4o-2024-05-13-918964 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic dataset search for climate change claims\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ClimateFEVER-256-24-gpt-4o-2024-05-13-918964 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-918964.","url":"https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-918964","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ClimateFEVER-256-24-gpt-4o-2024-05-13-918964","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tClimateFEVER-256-24-gpt-4o-2024-05-13-918964 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic dataset search for climate change claims\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ClimateFEVER-256-24-gpt-4o-2024-05-13-918964 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-918964.","url":"https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-918964","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ARK-Metadata","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMetadata of the \"Alter Realkatalog\" (ARK) of Berlin State Library (SBB)\n\t\n\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nThis dataset was created with the intent to provide a single larger set of metadata from Berlin State Library for research purposes and the development of AI applications.\nThe dataset comprises of descriptive metadata of 2.619.397 titles, which together form the \"Alte Realkatalog\" of Berlin State Libray, which may be translated to \"Old Subject Catalogue\". The data are stored in columnarâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ARK-Metadata.","url":"https://huggingface.co/datasets/SBB/ARK-Metadata","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","English"],"keywords_longer_than_N":true},
	{"name":"english-words-definitions","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tEnglish Words Definitions\n\t\n\nThis dataset contains definitions and important facts about 467k words that appear in the context of English texts.\nIt has been used to train our high-performance, compact text embedding models mdbr-leaf-ir and mdbr-leaf-mt.\nThe original list of words stems from here. We have extended it with definitions and important facts about each word using Claude 3.7 Sonnet.\n","url":"https://huggingface.co/datasets/MongoDB/english-words-definitions","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"mev51","keyword":"feature-extraction","description":"robocodeteam/mev51 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/robocodeteam/mev51","creator_name":"halil mustafa gÃ¶ksu","creator_url":"https://huggingface.co/robocodeteam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"language-metric-data","keyword":"feature-extraction","description":"# This dataset contains the entire content of three files loaded as a single example:\n# - `languages_list.pkl`: A pickled list of language strings.\n# - `average_distances_matrix.npy`: A NumPy matrix converted to a list of lists of floats.\n# - `distances_matrices.pkl`: A pickled dict of dicts of NumPy matrices.  \n#    It is converted into a list of records where each record corresponds to a dataset with a nested list of models and their associated distance matrices.\n#","url":"https://huggingface.co/datasets/mshamrai/language-metric-data","creator_name":"Maksym Shamrai","creator_url":"https://huggingface.co/mshamrai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","mit","arxiv:2508.11676","ðŸ‡ºðŸ‡¸ Region: US","multilingual"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-51550","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-51550 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-51550 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-51550.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-51550","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-51550","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-51550 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-51550 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-51550.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-51550","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"msd_sprites","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMSD Sprites Dataset Attribution\n\t\n\nThe Multi-factor Sequential Disentanglement benchmark includes a modified variant of the Sprites dataset, adapted to support sequential multi-factor disentanglement.\n\nOriginal repository:https://github.com/YingzhenLi/Sprites\n\nReference paper:Y. Li, J. Yu, C. Zhang, C. Gan.Disentangled Sequential Autoencoder, ICML 2018.https://arxiv.org/abs/1803.02991\n\n\n@inproceedings{li2018disentangle,\n  title = {Disentangled Sequential Autoencoder},\n  author = {Liâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TalBarami/msd_sprites.","url":"https://huggingface.co/datasets/TalBarami/msd_sprites","creator_name":"Tal Barami","creator_url":"https://huggingface.co/TalBarami","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"test-run","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\ttest-run Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research for argumentation data\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the test-run model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/test-run.","url":"https://huggingface.co/datasets/fine-tuned/test-run","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"test-run","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\ttest-run Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research for argumentation data\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the test-run model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/test-run.","url":"https://huggingface.co/datasets/fine-tuned/test-run","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"animepics","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tAnimePics\n\t\n\nThis dataset is a pure image dataset in WebDataset format, designed for pre-training anime-style models. \nIt can also be used to evaluate the effect of additional pre-training on backbones trained primarily on real-world images when applied to datasets of a completely different nature. \nThe dataset is designed to be continuously updated, leveraging the features of WebDataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe animepics dataset is a large-scaleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/animepics.","url":"https://huggingface.co/datasets/zenless-lab/animepics","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","mit","100M<n<1B","ðŸ‡ºðŸ‡¸ Region: US","anime"],"keywords_longer_than_N":true},
	{"name":"Face4FairShifts","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFace4FairShifts: A Large Image Benchmark for Fairness and Robust Learning across Visual Domains\n\t\n\nBy Tianjin University\nFor more information about the dataset, visit the project website:\n  https://meviuslab.github.io/Face4FairShifts/\nPlease note that the use of this dataset is RESTRICTED to non-commercial research and educational purposes.\n\n\t\n\t\t\n\t\n\t\n\t\tFile Information\n\t\n\n\nFace Images (Img/)\n  100,000 original face images across four domains: 30,000 in Photo, 25,000 each in Art andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LYM619/Face4FairShifts.","url":"https://huggingface.co/datasets/LYM619/Face4FairShifts","creator_name":"Yumeng Lin","creator_url":"https://huggingface.co/LYM619","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","afl-3.0","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-stackoverflow","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-stackoverflow Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code snippet search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-stackoverflow model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-stackoverflow","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-stackoverflow Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code snippet search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-stackoverflow model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ai-culture-multilingual-json-dolma","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAI-Culture Multilingual JSON + DOLMA Corpus\n\t\n\n\n16M words Â· 12 languages Â· CC-BY-4.0\n\nThe AI-Culture corpus contains 5K articles providing comprehensive philosophical and cultural content, exploring the intersection of technology, artificial intelligence, and human culture, perfectly aligned across 12 languages. All content maintains identical parallel structure across translations with zero duplication and editor-curated quality.\nThis project is maintained by a non-profit digitalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma.","url":"https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma","creator_name":"AIâ€‘Cultureâ€‘Commons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"tree-of-life-vector-db","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for TreeOfLife-10M Vector database\n\t\n\nPersistent files for vector Database created with chromadb \ncontaining the embeddings for all images in the imageomics/TreeOfLife-10M dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains the generated vector database built using ChromaDb as the backend vector database solution for the entire TreeOfLife-10M dataset.\nThe rationale behind creating a vector database was to enable blazingly fast nearest neighbor search. \nThe vectorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imageomics/tree-of-life-vector-db.","url":"https://huggingface.co/datasets/imageomics/tree-of-life-vector-db","creator_name":"HDR Imageomics Institute","creator_url":"https://huggingface.co/imageomics","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["image-feature-extraction","English","cc0-1.0","1M<n<10M","Image"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24-gpt-4o-2024-05-133652","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24-gpt-4o-2024-05-133652 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general search for paper products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24-gpt-4o-2024-05-133652 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-133652.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-133652","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24-gpt-4o-2024-05-133652","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24-gpt-4o-2024-05-133652 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general search for paper products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24-gpt-4o-2024-05-133652 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-133652.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-133652","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"react-shadcn-codex","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tReact Shadcn Codex Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe React Shadcn Codex is a curated collection of over 3,000 React components that utilize shadcn, Framer Motion, and Lucide React. This dataset provides a valuable resource for developers looking to understand and implement modern React UI components with these popular libraries.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe dataset includes:\n\n3,000+ React components using shadcn UI\nComponents with Framer Motion animations\nUsage examples of Lucide Reactâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/valentin-marquez/react-shadcn-codex.","url":"https://huggingface.co/datasets/valentin-marquez/react-shadcn-codex","creator_name":"valentin marquez","creator_url":"https://huggingface.co/valentin-marquez","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"elise-en-nano-codec-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tElise EN Nano-Codec Dataset\n\t\n\nThis dataset is built upon the Elise dataset and re-encoded using NVIDIAâ€™s NeMo Audio Codec into nano audio tokens.  \nIt is designed for fine-tuning multimodal LLMs and speech systems (TTS/ASR) that rely on codec-based audio token representations.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\ntext: transcription of the utterance.  \nspeaker: speaker identifier (string).  \nnano_layer_1 â€¦ nano_layer_4: tokenized audio representations from the NVIDIA NeMo Nano Codecâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nineninesix/elise-en-nano-codec-dataset.","url":"https://huggingface.co/datasets/nineninesix/elise-en-nano-codec-dataset","creator_name":"NineNineSix","creator_url":"https://huggingface.co/nineninesix","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-1362024-2wos-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-1362024-2wos-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information Retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1362024-2wos-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1362024-2wos-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1362024-2wos-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-1362024-2wos-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-1362024-2wos-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information Retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1362024-2wos-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1362024-2wos-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1362024-2wos-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"anime-characters","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAnime Character Dataset\n\t\n\nThis dataset contains detailed information about anime characters scraped from MyAnimeList.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach character entry contains the following fields:\n\nmal_id: MyAnimeList character ID\nurl: Character page URL\nname: Character name\nname_kanji: Character name in Kanji (if available)\nnicknames: List of character nicknames\nabout: Character description/biography\nfavorites: Number of users who favorited this character\nanime_appearances: List ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/realoperator42/anime-characters.","url":"https://huggingface.co/datasets/realoperator42/anime-characters","creator_name":"realoperator42","creator_url":"https://huggingface.co/realoperator42","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Bank-Review","keyword":"feature-extraction","description":"Nigerian Banks - Bank Reviews Dataset Collection\n    A comprehensive collection of customer reviews from Google Play Store (from app launch to 2024)\n    \n    \n        \n            Access Bank - CSV File: access_reviews.csv\n        \n        \n        \n            EcoBank - CSV File: ecoBank_reviews.csv\n        \n        \n        \n            First Bank of Nigeria (FBN) - CSV File: fbn_reviews.csv\n            FCMB - CSV File: fcmb_reviews.csv\n        \n        \n        \n            Fidelity Bank -â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Federal-University-Lokoja/Bank-Review.","url":"https://huggingface.co/datasets/Federal-University-Lokoja/Bank-Review","creator_name":"Federal University Lokoja","creator_url":"https://huggingface.co/Federal-University-Lokoja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"gooaq_mt_german_5_hard_negatives","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tGooAQ (Google Answers to Google Questions) question-answer pairs in German with 5 mined hard negatives.\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nThis dataset is a collection of ~2M question-answer-negative triplets and question-answer-negative_1...-negative_5 tuples from the machine translated version of MarcGrumpyOlejak/gooaq_mt_german. The full original Gooaq dataset in english only: (link to original dataset). This dataset can be used directly with Sentence Transformers to train embedding models.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german_5_hard_negatives.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german_5_hard_negatives","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","German","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"dataset_aplikasi_merek_pdki","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“ Data Aplikasi Merek Dagang Indonesia (PDKI)\n\t\n\n\n\t\n\t\t\n\t\tâœ… Overview\n\t\n\nDataset ini merupakan kumpulan aplikasi merek dagang di Indonesia, diperoleh dari PDâ€¯KI (Pangkalan Data Kekayaan Intelektual), DJKI, periode 1988â€“2024. Metadata mencakup:\n\nBrand name\nNama pemilik\nTahun permohonan\nKode & deskripsi NICE class\nStatus aplikasi (terdaftar / ditolak)\nLogo (jika tersedia)\n\nTotal sample: 337.334, dengan 87.424 sampel memiliki logo. Data ini digunakan untuk pelatihan dan evaluasi KeloraAIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gibranlynardi/dataset_aplikasi_merek_pdki.","url":"https://huggingface.co/datasets/gibranlynardi/dataset_aplikasi_merek_pdki","creator_name":"Gibran Tegar Ramadhan Putra Lynardi","creator_url":"https://huggingface.co/gibranlynardi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["tabular-classification","feature-extraction","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","legal"],"keywords_longer_than_N":true},
	{"name":"russian-synonyms","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tRussian synonyms\n\t\n\nSynonyms of various words alphabetically.\n","url":"https://huggingface.co/datasets/d0rj/russian-synonyms","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-ranking","feature-extraction","Russian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5222024-hkde-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5222024-hkde-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code repository search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5222024-hkde-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5222024-hkde-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5222024-hkde-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code repository search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5222024-hkde-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"prompt-safety-scores","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tComposite Safety Scoring for Prompts Using Multiple LLM Annotations\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nEvaluating the safety of prompts is essential but challenging. Existing approaches often depend on predefined categories, which can be circumvented by new jailbreaks or attacks. Additionally, different tasks may require different safety thresholds.\nThis study explores using large language models (LLMs) themselves to annotate prompt safety. By combining these annotations, a continuous safetyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/prompt-safety-scores.","url":"https://huggingface.co/datasets/agentlans/prompt-safety-scores","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"professional development and job seeking\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"professional development and job seeking\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5102024-h7o7-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5102024-h7o7-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"professional matchmaking services\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5102024-h7o7-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-h7o7-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-h7o7-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5102024-h7o7-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5102024-h7o7-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"professional matchmaking services\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5102024-h7o7-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-h7o7-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-h7o7-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NQ-256-24-gpt-4o-2024-05-13-803084","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNQ-256-24-gpt-4o-2024-05-13-803084 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"question answering dataset search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NQ-256-24-gpt-4o-2024-05-13-803084 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NQ-256-24-gpt-4o-2024-05-13-803084.","url":"https://huggingface.co/datasets/fine-tuned/NQ-256-24-gpt-4o-2024-05-13-803084","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NQ-256-24-gpt-4o-2024-05-13-803084","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNQ-256-24-gpt-4o-2024-05-13-803084 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"question answering dataset search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NQ-256-24-gpt-4o-2024-05-13-803084 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NQ-256-24-gpt-4o-2024-05-13-803084.","url":"https://huggingface.co/datasets/fine-tuned/NQ-256-24-gpt-4o-2024-05-13-803084","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DeFine","keyword":"feature-extraction","description":"Test set and Data Resources for analogical reasoning with earnings call transcripts in research: DeFine: Decision-Making with Analogical Reasoning over Factor Profiles  Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu  Accepted to findings of ACL 2025, Vienna, Austria, USA  ðŸ“„ Arxiv Paper Â Â \nðŸ  Home Page Â Â \nðŸ™ Github\n\n\t\n\t\n\t\n\t\tAbstract\n\t\n\nLLMs are ideal for decision-making thanks to their ability to reason over long contexts. However, challengesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huuuyeah/DeFine.","url":"https://huggingface.co/datasets/huuuyeah/DeFine","creator_name":"Yebowen Hu","creator_url":"https://huggingface.co/huuuyeah","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","summarization","question-answering","zero-shot-classification","English"],"keywords_longer_than_N":true},
	{"name":"authorship-attribution-data","keyword":"feature-extraction","description":"Dataset of authorship attribution. Each row has columns base_messages, same_author_messages, and different_author_messages. Each column is a set of 10 messages separated by \\n<sep>\\n. base_messages and same_author_messages are two sets of non-overlapping messages written by the same author, and different_author_messages is a set of messages written by a randomly selected different author. The columns are set up to make triplet loss training easy to do.\nAll data is from Discord, and most dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/trentmkelly/authorship-attribution-data.","url":"https://huggingface.co/datasets/trentmkelly/authorship-attribution-data","creator_name":"Trent Kelly","creator_url":"https://huggingface.co/trentmkelly","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-141246","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-141246 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-141246 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-141246.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-141246","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-141246","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-141246 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-141246 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-141246.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-141246","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"nbme-llama2","keyword":"feature-extraction","description":"joshitanm/nbme-llama2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/joshitanm/nbme-llama2","creator_name":"Tanmay Joshi","creator_url":"https://huggingface.co/joshitanm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","question-answering","summarization","English"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"web development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"web development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SnomedCT","keyword":"feature-extraction","description":"This dataset is a collection of Multi-hop Inference and Mixed-hop Prediction datasets created from SnomedCT's subsumption hierarchy (TBox) for training and evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/SnomedCT","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Tripadvisor_stadium_reviews_P5_schools","keyword":"feature-extraction","description":"tyrealqian/Tripadvisor_stadium_reviews_P5_schools dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/tyrealqian/Tripadvisor_stadium_reviews_P5_schools","creator_name":"Yizhou Qian","creator_url":"https://huggingface.co/tyrealqian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Tiktok_Chatgpt_Prompt_Guide","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“² Example Dataset: TikTok Scraper Tool\n\t\n\nðŸ‘‰ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâš¡ Instant Transcription â€“ Turn any TikTok video into an AI-ready transcript  \nðŸŽ¯ Metadata â€“ Get the title, language, description, and video hashtags  \nðŸ”— URL-Based Access â€“ Just drop in a TikTok video URL to start scraping  \nðŸ§© LLM-Ready Output â€“ Receive clean JSON ready for agents, RAG, or AI tools  \nðŸ’¸ Free Tier â€“ Use up to 100 queries during the beta period  \nðŸ’« Easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/Tiktok_Chatgpt_Prompt_Guide.","url":"https://huggingface.co/datasets/Gopher-Lab/Tiktok_Chatgpt_Prompt_Guide","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DebateBench","keyword":"feature-extraction","description":"utkarsh2105/DebateBench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/utkarsh2105/DebateBench","creator_name":"Utkarsh Tiwari","creator_url":"https://huggingface.co/utkarsh2105","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","question-answering","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"captcha_chinese_click_1","keyword":"image-feature-extraction","description":"Amort/captcha_chinese_click_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Amort/captcha_chinese_click_1","creator_name":"Amoter","creator_url":"https://huggingface.co/Amort","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","image-feature-extraction","zero-shot-image-classification","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-548936","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-548936 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-548936 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-548936","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-548936 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-548936 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"augmented_canonical_druglike_QED_Pfizer_15M","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDruglike QED Pfizer 15M - Augmented SMILES Dataset\n\t\n\nThis dataset is derived from the Druglike molecule datasets for drug discovery dataset and has been canonicalized using RDKit (2024.9.4) to ensure structural consistency.  \nTo enhance molecular diversity, 33% of the dataset was randomly sampled and augmented using RDKitâ€™s Chem.MolToRandomSmilesVect function, following an approach similar to NVIDIA's molmim method for SMILES augmentation.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview:\n\t\n\n\nSource:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Derify/augmented_canonical_druglike_QED_Pfizer_15M.","url":"https://huggingface.co/datasets/Derify/augmented_canonical_druglike_QED_Pfizer_15M","creator_name":"Derify","creator_url":"https://huggingface.co/Derify","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","cc-by-4.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"wordnet-lexical-topology","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tWordNet Lexical Topology Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WordNet Lexical Topology Dataset provides comprehensive n-gram frequency analysis from multiple sources:\n\nNLTK WordNet: Original Princeton WordNet with 117,659 synsets\nHF WordNet: Frequency-weighted definitions from 864,894 entries with cardinality data\nUnicode: Character names from 143,041 Unicode codepoints\n\nThis dataset preserves sequential information crucial for language modeling and text generation, with over 12â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AbstractPhil/wordnet-lexical-topology.","url":"https://huggingface.co/datasets/AbstractPhil/wordnet-lexical-topology","creator_name":"AbstractPhila","creator_url":"https://huggingface.co/AbstractPhil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","text-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5272024-ou25-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5272024-ou25-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Sentiment Analysis and Emotional Nuances\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5272024-ou25-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-ou25-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-ou25-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5272024-ou25-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5272024-ou25-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Sentiment Analysis and Emotional Nuances\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5272024-ou25-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-ou25-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-ou25-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scientific_question-generation","keyword":"feature-extraction","description":"Data originated from: \nhttps://openstax.org.â€\nhttps://openstax.org/details/books/chemistry-2e\n","url":"https://huggingface.co/datasets/leaschuessler/scientific_question-generation","creator_name":"Lea SchÃ¼ÃŸler","creator_url":"https://huggingface.co/leaschuessler","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","feature-extraction","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"LoveConflict","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ’” CoupleConflict-RedNote (ä¸­æ–‡æƒ…ä¾£å†²çªå¿ƒç†æ ‡ç­¾æ•°æ®é›†)\n\t\n\n\n\t\n\t\t\n\t\tðŸ“˜ Dataset Description\n\t\n\nCoupleConflict-RedNote æ˜¯ä¸€ä¸ªåŸºäºŽçœŸå®žç¤¾äº¤åª’ä½“å¹³å°å°çº¢ä¹¦ï¼ˆRedNoteï¼‰æ•´ç†çš„ä¸­æ–‡æƒ…ä¾£å†²çªæ•°æ®é›†ï¼ŒåŒ…å« 185 æ¡äº‰åµåœºæ™¯ï¼Œå®Œæ•´ä¿ç•™æ¯ä¸ªå†²çªçš„èƒŒæ™¯å™è¿°ã€å¯¹è¯ç¤ºä¾‹ã€äººç‰©å¿ƒç†çŠ¶æ€ä¸Žå†²çªæ ‡ç­¾ã€‚\næœ¬æ•°æ®é›†ç‰¹åˆ«å…³æ³¨æ‹çˆ±ä¸ŽåŒå±…é˜¶æ®µçš„äº²å¯†å…³ç³»å†²çªï¼Œå¹¶åœ¨æ¯æ¡è®°å½•ä¸­æ ‡æ³¨äº”å¤§å¿ƒç†ç»´åº¦ï¼Œæ”¯æŒå¿ƒç†å­¦å»ºæ¨¡ã€æƒ…ç»ªç†è§£ä¸ŽLLMæ¨¡æ‹Ÿè®­ç»ƒç­‰ä»»åŠ¡ã€‚\n\n\n\t\n\t\t\n\t\tðŸ” æ•°æ®ç‰¹ç‚¹\n\t\n\n\nðŸ“Œ å…±è®¡ 185 æ¡çœŸå®žäº‰åµè®°å½•ï¼ˆå…¨éƒ¨ä¸ºä¸­æ–‡ï¼‰\nðŸ“‚ æ¯æ¡è®°å½•åŒ…å«ï¼š\ndescriptionï¼šå†²çªèƒŒæ™¯å™è¿°\nexamplesï¼šäº‰åµå¯¹è¯åŽŸå¥ç¤ºä¾‹\nsituationsï¼šäº‰åµåŒæ–¹çš„ä¸»è§‚æƒ…å¢ƒ\nparty_a / party_bï¼šäº”ç»´å¿ƒç†æ ‡ç­¾ï¼ˆè¯¦è§ä¸‹æ–‡ï¼‰\n\n\nðŸ§  å¿ƒç†æ ‡ç­¾ç»´åº¦ï¼ˆæ¯æ–¹ç‹¬ç«‹ï¼‰ï¼š\nemotion_typeï¼šæƒ…ç»ªç±»åž‹ï¼ˆå¦‚ æ„¤æ€’ã€æ‚²ä¼¤ã€ç„¦è™‘ï¼‰\nattribution_styleï¼šå½’å› æ–¹å¼ï¼ˆå¦‚ ä»–è´£åž‹ã€æƒ…å¢ƒå½’å› åž‹ï¼‰â€¦ See the full description on the dataset page: https://huggingface.co/datasets/GreenGoat/LoveConflict.","url":"https://huggingface.co/datasets/GreenGoat/LoveConflict","creator_name":"Minzhi Lai","creator_url":"https://huggingface.co/GreenGoat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Chinese","mit","n<1K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"VideoEval","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for VideoEval\n\t\n\n\n\t\n\t\t\n\t\tVidTAB\n\t\n\n\n\t\n\t\t\n\t\tAction Recognition in Dark\n\t\n\nYou could download all videos from ARID at https://opendatalab.com/OpenDataLab/Action_Recognition_in_the_Dark.\nYou just need to use the mp4 video in the video folder and then use the annotations we provided.\n\n\t\n\t\t\n\t\n\t\n\t\tAction Recognition in Long Video\n\t\n\nYou could download all videos from Breakfast at https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/.\nYou just need to use the mp4â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lixinhao/VideoEval.","url":"https://huggingface.co/datasets/lixinhao/VideoEval","creator_name":"Xinhao Li","creator_url":"https://huggingface.co/lixinhao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"Product_Similarity_Dataset","keyword":"feature-extraction","description":"This following dataset is a rich dataset of product similarity. The dataset has been design to be challenging to train on by having quite a lot of hard negatives\nThis dataset is especially targeted toward fine-tuning usecase, especially to finetune reranker or embedding model.\nThe data are especially adapted for listwise loss like LambdaLoss or ListNetLoss.\nThe data are in JSONL and each line follow the same format as here below : \n\nA \"query\", the anchor product label\n\"docs\", the potentialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset.","url":"https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset","creator_name":"Antoine Demangeon","creator_url":"https://huggingface.co/Antix5","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","feature-extraction","French","German","Chinese"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"software development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"software development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MusicSem","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for MusicSem\n\t\n\n\n\n\nThis dataset contains 35977 entries of text-audio pairs. There is an accompanying test set of size 480 which is withheld for leaderboard purposes. Please reach out to authors for further access.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Rebecca Salganik, Teng Tu, Fei-Yueh Chen, Xiaohao Liu, Kaifeng Lu, Ethan Luvisia, Zhiyao Duan, Guillaume Salha-Galvan, Anson Kahng, Yunshan Ma, Jian Kang\nLanguage(s) : English\nLicense: MITâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rsalga/MusicSem.","url":"https://huggingface.co/datasets/Rsalga/MusicSem","creator_name":"Rebecca Salganik","creator_url":"https://huggingface.co/Rsalga","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","summarization","feature-extraction","audio-text-to-text","English"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"EuLearn","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3D objects representing a topologically diverse collection of surfaces, each generated from closed, parameterized curves with varying number of self-intersections (singular knots). \nThe surfaces are organized by topological genus, ranging from 0 to 10. \nFor each surface, we included the following four files:\n\nNon-Smoothed STL Mesh (*_ns.stl): A 3D mesh of the surface with sharp geometry and unmodified vertex positions. This version retainsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/appliedgeometry/EuLearn.","url":"https://huggingface.co/datasets/appliedgeometry/EuLearn","creator_name":"Applied Geometry Lab","creator_url":"https://huggingface.co/appliedgeometry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","graph-ml","text-to-3d","tabular-regression","other"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-623812","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-623812 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-623812 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-623812.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-623812","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-623812","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-623812 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-623812 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-623812.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-623812","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"PathoROB-camelyon","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tPathoROB\n\t\n\nPreprint | Code | Licenses | Cite\nPathoROB is a benchmark for the robustness of pathology foundation models (FMs) to non-biological medical center differences.\n\n\nPathoROB contains four datasets covering 28 biological classes from 34 medical centers and three metrics:\n\nRobustness Index: Measures the ability of an FM to capture biological features while ignoring\nnon-biological features.\nAverage Performance Drop (APD): Measures the impact of non-biological features on theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bifold-pathomics/PathoROB-camelyon.","url":"https://huggingface.co/datasets/bifold-pathomics/PathoROB-camelyon","creator_name":"BIFOLD Pathomics","creator_url":"https://huggingface.co/bifold-pathomics","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","English","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-6vz1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-6vz1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-6vz1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-6vz1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-6vz1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-6vz1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-6vz1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-6vz1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-6vz1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-6vz1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"PaperSeek-OpenAlex-Embeddings","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ“š PaperSeek: OpenAlex English Titles & Abstracts (April 2025 Snapshot)\n\t\n\nThis dataset is part of the PaperSeek framework, a semantic search engine designed for literature discovery using research questions and prior knowledge. PaperSeek is developed as part of a Master's thesis to explore novel approaches in enhancing academic search relevance.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“¦ Dataset Overview\n\t\n\n\nSource: OpenAlex\nSnapshot Date: April 1st, 2025\nLanguage: English\nContents:\nTitle\nAbstract\nEmbeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Grozkal/PaperSeek-OpenAlex-Embeddings.","url":"https://huggingface.co/datasets/Grozkal/PaperSeek-OpenAlex-Embeddings","creator_name":"Mohammad Saknini","creator_url":"https://huggingface.co/Grozkal","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","English","cc0-1.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"stock-photos-asian-people","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tStock Photos (Asian People, Stable Diffusion 1.5)\n\t\n\n\n  \n  Collage of randomly selected images from the dataset\n\n\nCollection of synthetic stock photographs created with Stable Diffusion 1.5, emphasizing Asian people \n(including East Asians, Southeast Asians, South Asians, and Central Asians).\nImages were generated using a diverse set of prompts and filtered for quality, realism, and safety.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nImage generation\nImage captioning\nVisual representation learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/stock-photos-asian-people.","url":"https://huggingface.co/datasets/agentlans/stock-photos-asian-people","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","feature-extraction","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ClimateFEVER-256-24-gpt-4o-2024-05-13-572217","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tClimateFEVER-256-24-gpt-4o-2024-05-13-572217 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic dataset search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ClimateFEVER-256-24-gpt-4o-2024-05-13-572217 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-572217.","url":"https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-572217","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ClimateFEVER-256-24-gpt-4o-2024-05-13-572217","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tClimateFEVER-256-24-gpt-4o-2024-05-13-572217 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic dataset search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ClimateFEVER-256-24-gpt-4o-2024-05-13-572217 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-572217.","url":"https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-572217","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-05062024-x987-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-05062024-x987-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-05062024-x987-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-05062024-x987-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-05062024-x987-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-05062024-x987-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"strike-T1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tStrike-T1\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tdataset_info:\n  features:\n  - name: image\n    dtype: image\n  - name: cr\n    dtype: int64\n  splits:\n  - name: train\n    num_bytes: 162832.0\n    num_examples: 12\n  download_size: 70261\n  dataset_size: 162832.0\nconfigs:\n- config_name: default\n  data_files:\n  - split: train\n    path: data/train-*\n\t\n\n","url":"https://huggingface.co/datasets/hsienchen/strike-T1","creator_name":"hsien chen","creator_url":"https://huggingface.co/hsienchen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Avaric","Avestan","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Kuno-RZN-D1","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThe VinkuraAI/Kuno-RZN-D1 is a specially curated dataset for training LLaMA (3.1 and 3.2) models, with a focus on reasoning tasks. It is available for download on Hugging Face and comes with detailed instructions to guide model training for complex reasoning capabilities.\nThis dataset includes a variety of tasks such as text-based reasoning, conversational analysis, and structured reasoning prompts. The goal is to enhance the performance of LLaMA models in reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VinkuraAI/Kuno-RZN-D1.","url":"https://huggingface.co/datasets/VinkuraAI/Kuno-RZN-D1","creator_name":"Vinkura AI","creator_url":"https://huggingface.co/VinkuraAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Img2Text-Algorithm-Retrieval","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tImg2Text-Algorithm-Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe Img2Text-Algorithm-Retrieval dataset is designed for retrieving text descriptions of algorithms from corresponding images. This dataset consists of structured text, raw text, algorithm images, and metadata such as source URLs and filenames. It can be useful for tasks like OCR-based text retrieval, image-to-text learning, and document understanding.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nModality: Image, Text  \nFormat: Parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Img2Text-Algorithm-Retrieval.","url":"https://huggingface.co/datasets/prithivMLmods/Img2Text-Algorithm-Retrieval","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-feature-extraction","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Multi-FuzzerCAN-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Multi-FuzzerCAN\n\t\n\nThe Controller Area Network (CAN) is crucial for automotive safety, yet remains vulnerable\nto various fuzzing attacks that can compromise vehicle operations. This paper presents a comprehensive\ndetection framework that identifies both common CAN vulnerabilities (DoS, Spoofing, Replay, and general\nFuzzing) and specific fuzzer attack types (identity, replay, random, brute force, and mutation-based) using\ndeep learning-based models. We evaluate fourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Thi-Thu-Huong/Multi-FuzzerCAN-dataset.","url":"https://huggingface.co/datasets/Thi-Thu-Huong/Multi-FuzzerCAN-dataset","creator_name":"Le","creator_url":"https://huggingface.co/Thi-Thu-Huong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-922024-puz9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-922024-puz9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Shrimad_Bhagavad_Gita","keyword":"feature-extraction","description":"snskrt/Shrimad_Bhagavad_Gita dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/snskrt/Shrimad_Bhagavad_Gita","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-512-192-gpt-4o-2024-05-13-985263","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-512-192-gpt-4o-2024-05-13-985263 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial news and analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-512-192-gpt-4o-2024-05-13-985263 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-985263.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-985263","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-512-192-gpt-4o-2024-05-13-985263","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-512-192-gpt-4o-2024-05-13-985263 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial news and analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-512-192-gpt-4o-2024-05-13-985263 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-985263.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-985263","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5122024-3toh-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5122024-3toh-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"construction project estimation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5122024-3toh-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5122024-3toh-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5122024-3toh-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5122024-3toh-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5122024-3toh-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"construction project estimation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5122024-3toh-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5122024-3toh-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5122024-3toh-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scientific_papers_from_arxiv","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscientific_papers_from_arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific research\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scientific_papers_from_arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv.","url":"https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scientific_papers_from_arxiv","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tscientific_papers_from_arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific research\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scientific_papers_from_arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv.","url":"https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"gpt-4-self-instruct-german-scored","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from CausalLM/GPT-4-Self-Instruct-German with added cosine-similarity scores.\nThe scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy?\n\t\n\nTo build an experimental static embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/gpt-4-self-instruct-german-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/gpt-4-self-instruct-german-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-733782","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-733782 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-733782 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-733782","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-733782 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-733782 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FoodOn","keyword":"feature-extraction","description":"This dataset is a collection of Mixed-hop Prediction datasets created from FoodOn's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\n","url":"https://huggingface.co/datasets/Hierarchy-Transformers/FoodOn","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"laptop_dataset","keyword":"feature-extraction","description":"Deltan2002/laptop_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Deltan2002/laptop_dataset","creator_name":"Deltan Lobo","creator_url":"https://huggingface.co/Deltan2002","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","question-answering","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"lawma-tasks","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLawma legal classification tasks\n\t\n\nThis repository contains the legal classification tasks from Lawma.\nThese tasks were derived from the Supreme Court and Songer Court of Appeals databases.\nSee the project's GitHub repository for more details.\nPlease cite as:\n@misc{dominguezolmedo2024lawmapowerspecializationlegal,\n      title={Lawma: The Power of Specialization for Legal Tasks}, \n      author={Ricardo Dominguez-Olmedo and Vedant Nanda and Rediet Abebe and Stefan Bechtold and Christophâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ricdomolm/lawma-tasks.","url":"https://huggingface.co/datasets/ricdomolm/lawma-tasks","creator_name":"Ricardo","creator_url":"https://huggingface.co/ricdomolm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","feature-extraction","zero-shot-classification","English"],"keywords_longer_than_N":true},
	{"name":"mocap_dataes","keyword":"feature-extraction","description":"","url":"https://huggingface.co/datasets/OpenLoong/mocap_dataes","creator_name":"OpenLoong","creator_url":"https://huggingface.co/OpenLoong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US","humanoid_robot"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_8b","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 500,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-8B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 500,000 samples with embeddings\nQueryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_8b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_8b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"synthetic-confidential-information-injected-business-excerpts","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSynthetic Confidential Information Injected Business Excerpts\n\t\n\nThis dataset aims to provide business report excerpts which contain relevant confidential/sensitive information.\nThis includes mentions of :\n  1. Internal Marketing Strategies.\n  2. Proprietary Product Composition.\n  3. License Internals.\n  4. Internal Sales Projections.\n  5. Confidential Patent Details.\n  6. others.\n\nThe dataset contains around 1k business excerpt - Reasons pairs. The Reason field contains theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rohit-D/synthetic-confidential-information-injected-business-excerpts.","url":"https://huggingface.co/datasets/Rohit-D/synthetic-confidential-information-injected-business-excerpts","creator_name":"Rohit D","creator_url":"https://huggingface.co/Rohit-D","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","feature-extraction","summarization","English"],"keywords_longer_than_N":true},
	{"name":"ImageCaption_domain","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tImageCaption_domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nImageCaption_domain is a multi-domain image-caption dataset automatically constructed from the ImageNet21K_Recaption dataset. Each domain corresponds to a subtree in the WordNet hierarchy, and each sample contains an image, a short caption, CLIP tokens, and domain/class labels. The dataset is designed for research in multi-domain, multimodal, and federated learning scenarios.\n\n\t\n\t\t\n\t\n\t\n\t\tData Source\n\t\n\n\nOriginal dataset:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tony20487/ImageCaption_domain.","url":"https://huggingface.co/datasets/Tony20487/ImageCaption_domain","creator_name":"Tony Stark","creator_url":"https://huggingface.co/Tony20487","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","zero-shot-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-l","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-l Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical troubleshooting forum\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-l model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-l.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-l","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-l","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\taskubuntu-l Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical troubleshooting forum\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-l model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-l.","url":"https://huggingface.co/datasets/fine-tuned/askubuntu-l","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"flo","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tflo Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the flo model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"florianhoenicke/flo\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/florianhoenicke/flo.","url":"https://huggingface.co/datasets/florianhoenicke/flo","creator_name":"Florian HÃ¶nicke","creator_url":"https://huggingface.co/florianhoenicke","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"flo","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tflo Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the flo model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"florianhoenicke/flo\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/florianhoenicke/flo.","url":"https://huggingface.co/datasets/florianhoenicke/flo","creator_name":"Florian HÃ¶nicke","creator_url":"https://huggingface.co/florianhoenicke","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"filtered_articles_by_year","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Filtered Articles by Year\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Filtered Articles by Year dataset contains yearly-segmented web articles from the FineWeb dataset, specifically filtered and processed for temporal language analysis and Word2Vec model training. This dataset spans 21 years (2005-2025) and serves as the foundation for research into semantic change, concept emergence, and language evolution over time.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adameubanks/filtered_articles_by_year.","url":"https://huggingface.co/datasets/adameubanks/filtered_articles_by_year","creator_name":"Adam Eubanks","creator_url":"https://huggingface.co/adameubanks","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","language-modeling","text-scoring","monolingual"],"keywords_longer_than_N":true},
	{"name":"EarthLoc_2021_Database","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tðŸŒ Sentinel 2021 Image WebDataset\n\t\n\nThis dataset contains 150k 1024x1024 satellite images accross (9,10,11) zooms and bounded within (-60,60) latitude.\nStored using the WebDataset format. \nThe data is sharded across 11 .tar archives, and each sample contains:\n\nA JPEG image .jpg\nA unique key __key__ corresponding to the original image path\nCompanion .index file for fast random access stored next to the shard\n\nThis key encodes all relevant metadata about the image, including itsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pawlo2013/EarthLoc_2021_Database.","url":"https://huggingface.co/datasets/pawlo2013/EarthLoc_2021_Database","creator_name":"Pawel Piwowarski","creator_url":"https://huggingface.co/pawlo2013","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","English","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"hwtcm-deepseek-r1-distill-data","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tç®€ä»‹\n\t\n\nDeepSeekè’¸é¦çš„ä¼ ç»Ÿä¸­åŒ»æ•°æ®é›†ï¼ŒåŽŸå§‹æ•°æ®æ¥æºäºŽç½‘ç»œï¼Œæœªè¿›è¡Œäººå·¥å®¡æŸ¥ã€‚\n\n\t\n\t\t\n\t\t7Bæ¨¡åž‹å¾®è°ƒæ•ˆæžœ\n\t\n\n\næ¨¡åž‹è¡¨çŽ°å‡ºäº†æŽ¨ç†èƒ½åŠ›ï¼Œå‡†ç¡®æ€§æœ‰å¾…ç»§ç»­éªŒè¯ã€‚\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tæˆ‘ä»¬çš„å…¶ä»–äº§å“\n\t\n\nä¸­åŒ»NERï¼šèƒ½è¯†åˆ«æ–¹å‰‚ã€æœ¬è‰ã€æ¥æºã€ç—…åã€ç—‡çŠ¶ã€è¯åž‹ï¼Œä¹Ÿè®¸æ˜¯åŸºäºŽBERTå¼€æºæ¨¡åž‹ä¸­è¯†åˆ«æœ€å¥½çš„æ¨¡åž‹ã€‚ä¸­åŒ»è€ƒè¯•é¢˜ï¼šä¹Ÿè®¸æ˜¯å…¨ç½‘æœ€æ—©å¼€æºã€æ•°æ®æœ€å¤šçš„ä¸­åŒ»è€ƒè¯•é¢˜ï¼Œæˆ‘ä»¬å†…éƒ¨å°†å…¶ç”¨äºŽæ¨¡åž‹è®­ç»ƒçš„æ€§èƒ½è¯„æµ‹æ•°æ®é›†ã€‚ä¸­åŒ»SFTæ•°æ®é›†ï¼šä¸­åŒ»QAæ•°æ®é›†ï¼Œç”¨äºŽSFTå¾®è°ƒã€‚ä»“å…¬ï¼šåŸºäºŽQwençš„æŒ‡ä»¤å¾®è°ƒæ¨¡åž‹ï¼ˆæš‚æœªå¼€æºï¼‰ã€‚ä»“å…¬R1ï¼šåŸºäºŽDeepSeekè’¸é¦çš„è¶…è¿‡100ä¸‡æ¡QAçš„æŒ‡ä»¤å¾®è°ƒæ¨¡åž‹ï¼Œæ‹¥æœ‰å¼ºå¤§çš„æŽ¨ç†èƒ½åŠ›ï¼ˆæš‚æœªå¼€æºï¼‰ã€‚  \nã€‚ã€‚ã€‚è¿˜æœ‰å¾ˆå¤š\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you find this project useful in your research, please consider cite:\n@misc{hwtcm2024,\n    title={{hwtcm-deepseek-r1-distill-data} A traditionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm-deepseek-r1-distill-data.","url":"https://huggingface.co/datasets/Monor/hwtcm-deepseek-r1-distill-data","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","feature-extraction","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CNTXTAI_Medical_Patient_Reports","keyword":"feature-extraction","description":"Laboratory Tests Dataset\n\nOverview\n\nThis dataset provides a structured list of laboratory tests categorized under \"Laboratory Tests.\" It is designed for medical professionals, researchers, and data analysts interested in studying and organizing laboratory test data for clinical and diagnostic purposes.\nThis dataset is highly valuable for medical research, categorization, and analysis. The structured format allows for efficient information retrieval and classification, making it aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Medical_Patient_Reports.","url":"https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Medical_Patient_Reports","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"TreeOfLife-10M-EOL-NaturalImages","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for TreeOfLife-10M-EOL-NaturalImages\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a curated version of the TreeOfLife-10M-WEBP EOL training split, filtered to contain exclusively natural biological imagery.\nThe dataset has been systematically cleaned using the Vision Data Curation (VDC) framework to remove non-natural content while preserving high-quality biological specimens.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis version further refines the dataset fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/birder-project/TreeOfLife-10M-EOL-NaturalImages.","url":"https://huggingface.co/datasets/birder-project/TreeOfLife-10M-EOL-NaturalImages","creator_name":"Birder","creator_url":"https://huggingface.co/birder-project","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-classification","image-feature-extraction","imageomics/TreeOfLife-10M","birder-project/TreeOfLife-10M-WEBP"],"keywords_longer_than_N":true},
	{"name":"AL-GR","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tAL-GR: A Large-scale Generative Recommendation Dataset\n\t\n\nPaper: FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial DatasetsCode: https://github.com/selous123/al_sidProject Page: https://huggingface.co/datasets/AL-GR\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nAL-GR is a large-scale dataset designed for generative recommendation tasks using Large Language Models (LLMs). The core idea is to transform user historical behavior sequences into natural language prompts, enablingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/AL-GR.","url":"https://huggingface.co/datasets/AL-GR/AL-GR","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","feature-extraction","image-feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"HotpotQA-256-24-gpt-4o-2024-05-13-773587","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tHotpotQA-256-24-gpt-4o-2024-05-13-773587 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code repository search for machine learning datasets and models\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the HotpotQA-256-24-gpt-4o-2024-05-13-773587 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/HotpotQA-256-24-gpt-4o-2024-05-13-773587.","url":"https://huggingface.co/datasets/fine-tuned/HotpotQA-256-24-gpt-4o-2024-05-13-773587","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HotpotQA-256-24-gpt-4o-2024-05-13-773587","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tHotpotQA-256-24-gpt-4o-2024-05-13-773587 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code repository search for machine learning datasets and models\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the HotpotQA-256-24-gpt-4o-2024-05-13-773587 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/HotpotQA-256-24-gpt-4o-2024-05-13-773587.","url":"https://huggingface.co/datasets/fine-tuned/HotpotQA-256-24-gpt-4o-2024-05-13-773587","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"intergalactic-host","keyword":"feature-extraction","description":"jurgenpaul82/intergalactic-host dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jurgenpaul82/intergalactic-host","creator_name":"westerveld","creator_url":"https://huggingface.co/jurgenpaul82","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-64-24-gpt-4o-2024-05-136538","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-64-24-gpt-4o-2024-05-136538 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-64-24-gpt-4o-2024-05-136538 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136538.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136538","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-64-24-gpt-4o-2024-05-136538","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-64-24-gpt-4o-2024-05-136538 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-64-24-gpt-4o-2024-05-136538 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136538.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136538","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"AL-GR","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tAL-GR: A Large-scale Generative Recommendation Dataset\n\t\n\nPaper: FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial DatasetsCode: https://github.com/selous123/al_sidProject Page: https://huggingface.co/datasets/AL-GR\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nAL-GR is a large-scale dataset designed for generative recommendation tasks using Large Language Models (LLMs). The core idea is to transform user historical behavior sequences into natural language prompts, enablingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/AL-GR.","url":"https://huggingface.co/datasets/AL-GR/AL-GR","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","feature-extraction","image-feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-32000-384-gpt-4o-2024-05-13-94264207","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-32000-384-gpt-4o-2024-05-13-94264207 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-32000-384-gpt-4o-2024-05-13-94264207 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-32000-384-gpt-4o-2024-05-13-94264207.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-32000-384-gpt-4o-2024-05-13-94264207","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-32000-384-gpt-4o-2024-05-13-94264207","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-32000-384-gpt-4o-2024-05-13-94264207 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-32000-384-gpt-4o-2024-05-13-94264207 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-32000-384-gpt-4o-2024-05-13-94264207.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-32000-384-gpt-4o-2024-05-13-94264207","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Entrepreneurship and Career Development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Entrepreneurship and Career Development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sunflower-leaf","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSunflower Leaf Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains data representing various characteristics of sunflower leaves. It includes measurements of leaf dimensions, area, color, and health status. This dataset is suitable for research, educational purposes, or any analysis involving plant biology.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of the following attributes:\n\nWidth (cm): The width of the leaf, measured in centimeters.\nLength (cm): The length of the leafâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayush-thakur02/sunflower-leaf.","url":"https://huggingface.co/datasets/ayush-thakur02/sunflower-leaf","creator_name":"Ayush Thakur","creator_url":"https://huggingface.co/ayush-thakur02","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"GTA5-MultiDomain","keyword":"image-feature-extraction","description":"zgh456/GTA5-MultiDomain dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zgh456/GTA5-MultiDomain","creator_name":"Gehao Zhang","creator_url":"https://huggingface.co/zgh456","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","image-feature-extraction","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-46082","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-46082 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-46082 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-46082.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-46082","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-46082","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-46082 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-46082 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-46082.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-46082","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"napierone-epub-raw","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/napierone-epub-raw\n\t\n\nNapierOne EPUB files converted with marker. Seems to contain mostly books from Project Gutenberg.\n\n\t\n\t\t\n\t\tdetected languages\n\t\n\nvia fasttext-langdetect\n{'ca': 1,\n 'cy': 1,\n 'da': 6,\n 'de': 105,\n 'en': 4403,\n 'eo': 2,\n 'es': 61,\n 'fi': 76,\n 'fr': 189,\n 'he': 1,\n 'hu': 5,\n 'is': 1,\n 'it': 40,\n 'la': 6,\n 'nl': 41,\n 'pl': 4,\n 'pt': 38,\n 'sv': 10,\n 'tl': 9}\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/napierone-epub-raw","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","Spanish","Finnish"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-624125","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-624125 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-624125 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-624125.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-624125","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-624125","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-624125 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-624125 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-624125.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-624125","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-456029","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-456029 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-456029 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-456029.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-456029","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-456029","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-456029 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-456029 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-456029.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-456029","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-512-192-gpt-4o-2024-05-13-14571","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-512-192-gpt-4o-2024-05-13-14571 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-14571 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-14571.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-14571","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-512-192-gpt-4o-2024-05-13-14571","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSciFact-512-192-gpt-4o-2024-05-13-14571 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-14571 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-14571.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-14571","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"eg-legal-rag","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal RAG Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRetrieval-augmented generation optimized dataset with summaries, keywords, and cross-references for building legal search systems.\nThis dataset contains 1,046 examples of rag data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-rag.","url":"https://huggingface.co/datasets/fr3on/eg-legal-rag","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Food-Composition","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tIngredients CSV/Parquet File\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe following data comes from the United States Department of Agricultureâ€™s Food Composition Database. It contains data for various types of food ingredients including the amounts of different vitamins and minerals found in the foods as well as macronutrient percentages. The food covered spans a large variety of foods from butter to Campbellâ€™s soup. Much of the supplementary documenation for each field comes directly from that pagesâ€™â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hootan09/Food-Composition.","url":"https://huggingface.co/datasets/hootan09/Food-Composition","creator_name":"niki","creator_url":"https://huggingface.co/hootan09","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-268697","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-268697 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-268697 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-268697","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-268697 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-268697 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SDD","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSequenceDistanceDataset (SDD)\n\t\n\nA Cross-Domain Benchmark for Sequence Similarity Analysis  \n\n\t\n\t\t\n\t\tOverview\n\t\n\nA comprehensive benchmarking dataset for evaluating distance metrics in two domains:  \n\nðŸ§¬ Biological Sequences (Proteins from UniProt/UniRef)  \nðŸ—ºï¸ Movement Trajectories (GPS data from 3 cities)\n\nDesigned to support research in similarity search, metric learning, and cross-domain analysis.  \n\n\n\t\n\t\t\n\t\tKey Features\n\t\n\nâœ… Precomputed Distance Matrices  \n\nEliminates computationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Airchang/SDD.","url":"https://huggingface.co/datasets/Airchang/SDD","creator_name":"Airchang","creator_url":"https://huggingface.co/Airchang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","mit","ðŸ‡ºðŸ‡¸ Region: US","biology"],"keywords_longer_than_N":false},
	{"name":"NASADEM_DATASET","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNASADEM_DATASET/\n  README.md\n  train/metadata.csv\n  train.zip \n\t\n\n","url":"https://huggingface.co/datasets/SalvadorCB/NASADEM_DATASET","creator_name":"Salvador Cantuarias BraÃ±es","creator_url":"https://huggingface.co/SalvadorCB","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","afl-3.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"oab_exams_2011_2025_combined","keyword":"feature-extraction","description":"russ7/oab_exams_2011_2025_combined dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/russ7/oab_exams_2011_2025_combined","creator_name":"Erick Russo de Freitas Mathias","creator_url":"https://huggingface.co/russ7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","Portuguese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-10052024-lns6-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-10052024-lns6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Use case search for SaaS and AI products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-10052024-lns6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-10052024-lns6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-10052024-lns6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-10052024-lns6-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-10052024-lns6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Use case search for SaaS and AI products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-10052024-lns6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-10052024-lns6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-10052024-lns6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Urdu-Low-Resource-Language-Dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Low-Resource-Language-Dataset\n\t\n\nThis dataset is designed to aid Natural Language Processing (NLP) research on low-resource languages, particularly Urdu. It includes structured datasets and preprocessing tools curated from the BBC Urdu website.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains articles, summaries, and topics scraped from BBC Urdu. It is structured into training and testing datasets for machine learning applications. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Subayyal/Urdu-Low-Resource-Language-Dataset.","url":"https://huggingface.co/datasets/Subayyal/Urdu-Low-Resource-Language-Dataset","creator_name":"Subayyal Sheikh","creator_url":"https://huggingface.co/Subayyal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","feature-extraction","sentence-similarity","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5252024-jzfp-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5252024-jzfp-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"cloud provider product performance and cost analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5252024-jzfp-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5252024-jzfp-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5252024-jzfp-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5252024-jzfp-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5252024-jzfp-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"cloud provider product performance and cost analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5252024-jzfp-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5252024-jzfp-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5252024-jzfp-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Passport-Dataset","keyword":"feature-extraction","description":"BinKhoaLe1812/Synthetic-Passport-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/BinKhoaLe1812/Synthetic-Passport-Dataset","creator_name":"LÃª ÄÄƒng Khoa (Liam)","creator_url":"https://huggingface.co/BinKhoaLe1812","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Vietnamese","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"open-images-100k-180x180","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOpen Images Dataset 100K 180x180 - Dataset Card\n\t\n\nThis dataset provides modified images from the Open Images Dataset. Images are available in HDF5 format along with their URLs in TsvHttpData-1.0 format. The dataset is divided into training, validation, and test sets.\n\nCurated by: Google LLC\nImages License: CC BY 2.0 License\nOriginal (Google) Repository: Open Images Dataset\nHugging Face Repository: bitmind/open-images-v7\n\n\n\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\n\t\n\t\n\t\n\t\tDescription\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/duchema/open-images-100k-180x180.","url":"https://huggingface.co/datasets/duchema/open-images-100k-180x180","creator_name":"Mathieu Duchesneau","creator_url":"https://huggingface.co/duchema","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","cc-by-2.0","100K - 1M","csv","Image"],"keywords_longer_than_N":true},
	{"name":"entity_type_hi_pilener_constraint","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for entity_type_hi_pilener_constraint\n\t\n\nThese dataset is a modified version of entity_type_hi_pilener\nCheck out the Colab Notebook used to modify entity_type_hi_pilener\n","url":"https://huggingface.co/datasets/nis12ram/entity_type_hi_pilener_constraint","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"t5-xxl-embedding","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tT5-XXL Embeddings for Image Generation Prompts\n\t\n\nThis dataset contains 4096-dimensional text embeddings for prompts from the Gustavosta/Stable-Diffusion-Prompts dataset.\n\n\t\n\t\t\n\t\tModel Used\n\t\n\nThe embeddings were generated using a T5-XXL encoder model. Specifically, the weights from t5xxl_fp8_e4m3fn_scaled.safetensors were used.\nImportant Note: While the source model weights were in a FP8 format, the embeddings in this dataset have been calculated and stored in full float32 precisionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JusteLeo/t5-xxl-embedding.","url":"https://huggingface.co/datasets/JusteLeo/t5-xxl-embedding","creator_name":"JusteLeo","creator_url":"https://huggingface.co/JusteLeo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"t5-xxl-embedding","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tT5-XXL Embeddings for Image Generation Prompts\n\t\n\nThis dataset contains 4096-dimensional text embeddings for prompts from the Gustavosta/Stable-Diffusion-Prompts dataset.\n\n\t\n\t\t\n\t\tModel Used\n\t\n\nThe embeddings were generated using a T5-XXL encoder model. Specifically, the weights from t5xxl_fp8_e4m3fn_scaled.safetensors were used.\nImportant Note: While the source model weights were in a FP8 format, the embeddings in this dataset have been calculated and stored in full float32 precisionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JusteLeo/t5-xxl-embedding.","url":"https://huggingface.co/datasets/JusteLeo/t5-xxl-embedding","creator_name":"JusteLeo","creator_url":"https://huggingface.co/JusteLeo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"building","keyword":"feature-extraction","description":"this is test dataset\n","url":"https://huggingface.co/datasets/yinjoy30/building","creator_name":"yhy","creator_url":"https://huggingface.co/yinjoy30","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Chinese","mit","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"norwegian-nli-triplets-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tnorwegian-nli-triplets-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Keyword-based search engine for documents\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the norwegian-nli-triplets-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/norwegian-nli-triplets-c.","url":"https://huggingface.co/datasets/fine-tuned/norwegian-nli-triplets-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Norwegian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"norwegian-nli-triplets-c","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tnorwegian-nli-triplets-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Keyword-based search engine for documents\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the norwegian-nli-triplets-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/norwegian-nli-triplets-c.","url":"https://huggingface.co/datasets/fine-tuned/norwegian-nli-triplets-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Norwegian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"25kTrees","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tManual crown delineation of individual trees in 2 countries: Denmark and Finland\n\t\n\nDataset download link: https://sid.erda.dk/sharelink/eFt21tspNe\nGitHub page: https://github.com/sizhuoli/TreeCountSegHeight\nPublication: https://doi.org/10.1093/pnasnexus/pgad076\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset description\n\t\n\n---------- Denmark data---------- :\nMore than 20k individual trees growing in different landscapes.\nAnnotation masks are paired with aerial photographs with a spatial resolution of 20cm.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sizhuoli/25kTrees.","url":"https://huggingface.co/datasets/sizhuoli/25kTrees","creator_name":"Sizhuo Li","creator_url":"https://huggingface.co/sizhuoli","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-feature-extraction","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LoC-PD-Books-preprocessed","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLoC-PD-Books: preprocessed\n\t\n\nThis is the storytracer/LoC-PD-Books dataset with the following preprocessing steps:\n\napply clean-text package keeping casing and newlines\ndrop OCR garbled text in first few lines of each example\nfix (most) 'hard' newlines w/ regex similar to gutenberg clean\n'grade' first 512 tokens of each book with this quantized model; keep examples from labels clean (all) and mild gibberish w/ score 0.9 or higher\n\n\n","url":"https://huggingface.co/datasets/pszemraj/LoC-PD-Books-preprocessed","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","storytracer/LoC-PD-Books","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5102024-kvgq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5102024-kvgq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"database search for structured data\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5102024-kvgq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-kvgq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-kvgq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5102024-kvgq-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5102024-kvgq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"database search for structured data\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5102024-kvgq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-kvgq-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-kvgq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"chatml-function-calling-v2","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Conversion\n\t\n\nThis dataset is a converted version of the Glaive Function Calling v2 dataset, originally hosted on Hugging Face.\n\n\t\n\t\t\n\t\tChat Template for Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis chat template is designed to work with this dataset.\n\n\t\n\t\t\n\t\tTemplate\n\t\n\n\nchat_template = \"\"\"{%- set tools = tools if tools is defined else None -%}\n{%- set date_string = date_string if date_string is defined else \"1 Sep 2024\" -%}\n\n{%- set system_message = messages[0].content ifâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankush13r/chatml-function-calling-v2.","url":"https://huggingface.co/datasets/ankush13r/chatml-function-calling-v2","creator_name":"Ankush Rana","creator_url":"https://huggingface.co/ankush13r","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"natural-questions","keyword":"feature-extraction","description":"This is a mirror of Google's Natural Questions (NQ).\nThe dataset is converted into paris of (query, answer_passage).\n\nNatural Questions (NQ) contains real user questions issued to Google search, and answers found from Wikipedia by annotators. NQ is designed for the training and evaluation of automatic question answering systems.\n\n","url":"https://huggingface.co/datasets/malteos/natural-questions","creator_name":"malteos","creator_url":"https://huggingface.co/malteos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","feature-extraction","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5162024-o9um-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5162024-o9um-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Note-taking app features search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5162024-o9um-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5162024-o9um-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5162024-o9um-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5162024-o9um-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5162024-o9um-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Note-taking app features search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5162024-o9um-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5162024-o9um-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5162024-o9um-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-256-24-gpt-4o-2024-05-13-952023","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-256-24-gpt-4o-2024-05-13-952023 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-256-24-gpt-4o-2024-05-13-952023 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-952023.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-952023","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-256-24-gpt-4o-2024-05-13-952023","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArguAna-256-24-gpt-4o-2024-05-13-952023 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-256-24-gpt-4o-2024-05-13-952023 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-952023.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-952023","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"S2WC-RSS-like","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset for Weakly Supervised Semantic Segmentation\n\t\n\nBased on the ESA WorldCover 2020 v100 dataset:\n\nZanaga, D., Van De Kerchove, R., De Keersmaecker, W., Souverijns, N., Brockmann, C., Quast, R., Wevers, J., Grosu, A., Paccini, A., Vergnaud, S., Cartus, O., Santoro, M., Fritz, S., Georgieva, I., Lesiv, M., Carter, S., Herold, M., Li, Linlin, Tsendbazar, N.E., Ramoino, F., Arino, O., 2021. ESA WorldCover 10 m 2020 v100. https://doi.org/10.5281/zenodo.5571936\n\nHomepage:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/j-h-f/S2WC-RSS-like.","url":"https://huggingface.co/datasets/j-h-f/S2WC-RSS-like","creator_name":"Jan-Hendrik","creator_url":"https://huggingface.co/j-h-f","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","cc-by-4.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US","code"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-978964","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-978964 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-978964 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-978964.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-978964","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-978964","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-978964 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-978964 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-978964.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-978964","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-32000-384-gpt-4o-2024-05-13-78042877 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"arxiv paper domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tSCIDOCS-32000-384-gpt-4o-2024-05-13-78042877 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"arxiv paper domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Chinese-Tag-Extraction","keyword":"feature-extraction","description":"Johnson8187/Chinese-Tag-Extraction dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Johnson8187/Chinese-Tag-Extraction","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-classification","zero-shot-classification","feature-extraction","Chinese"],"keywords_longer_than_N":true},
	{"name":"Shiv_puran_OCR","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Shlok vs Non Shlok in Shiv puran\n\t\n\nThis dataset will enable a object detection model to differentiate between shlok vs Non-Shlok in this types of books, after that shloks can be cropped and a parallel corpus of image-text can be created.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nPDF from internet archive was used, will link it here later\n\n\t\n\t\t\n\t\tUses\n\t\n\nTo further develop Sanskrit OCR\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\nWrite a python script to crop the shlok boxes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/snskrt/Shiv_puran_OCR.","url":"https://huggingface.co/datasets/snskrt/Shiv_puran_OCR","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-image","text-classification","feature-extraction","Sanskrit","Hindi"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-37376","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-37376 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-37376 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-37376.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-37376","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-37376","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-37376 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-37376 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-37376.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-37376","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"COCO_Person","keyword":"image-feature-extraction","description":"This Dataset is a subsets of COCO 2017 -train- images using \"Crowd\" & \"person\" Labels With the First Caption of Each one\n\nCOCO Summary:\nThe COCO dataset is a comprehensive collection designed for object detection, segmentation, and captioning tasks.\nIt comprises over 200,000 images, encompassing a diverse array of everyday scenes and objects.\nEach image features multiple objects and scenes across 80 distinct object categories, all of which are annotated with descriptive image captions.\n","url":"https://huggingface.co/datasets/Hamdy20002/COCO_Person","creator_name":"Abdelrahman Hamdy","creator_url":"https://huggingface.co/Hamdy20002","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support search for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support search for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"GridNet-HD","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ—‚ GridNet-HD dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Introduction\n\t\n\nThis dataset was developed for 3D semantic segmentation task using both images and 3D point clouds specialized on electrical infrastructure.\nGrid (electrical) Network at High Density and High Resolution represents the first Image+LiDAR dataset accurately co-referenced in the electrical infrastructure domain.\nThis dataset is associated with a public leaderboard hosted on Hugging Face Spaces, available at: leaderboard.\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/heig-vd-geo/GridNet-HD.","url":"https://huggingface.co/datasets/heig-vd-geo/GridNet-HD","creator_name":"HEIG-Vd Geomatic","creator_url":"https://huggingface.co/heig-vd-geo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-780826","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-780826 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-780826 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-780826.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-780826","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-780826","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\n\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-780826 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-780826 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-780826.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-780826","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"leetcode-problems-dataset","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tLeetCode Problems Dataset\n\t\n\nThis dataset contains a comprehensive collection of LeetCode programming problems along with their features, metadata, and instructions.\n\n\n\t\n\t\t\n\t\tAttribution\n\t\n\nThis dataset is derived from multiple sources:\n\nLeetCode's website (https://leetcode.com) â€” All problem content, solutions, and related materials are the property of LeetCode and are those that are available publicly (No premium problem is shared!).\nLeetCodeHelp (https://leetcodehelp.github.io) â€”â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Alishohadaee/leetcode-problems-dataset.","url":"https://huggingface.co/datasets/Alishohadaee/leetcode-problems-dataset","creator_name":"Seyedali Shohadaeolhosseini","creator_url":"https://huggingface.co/Alishohadaee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","text-classification","zero-shot-classification","feature-extraction","text2text-generation"],"keywords_longer_than_N":true},
	{"name":"wikipedia_qwen_4b","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tVector Database Dataset\n\t\n\nGenerated embeddings dataset for vector database training and evaluation with multiple format support.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,000,000 text samples with high-quality vector embeddings generated using Qwen/Qwen3-Embedding-4B from the wikimedia/wikipedia dataset. The dataset is designed for vector database training, similarity search, and retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nBase dataset: 1,000,000 samples with embeddingsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maknee/wikipedia_qwen_4b.","url":"https://huggingface.co/datasets/maknee/wikipedia_qwen_4b","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","text-retrieval","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"RAVine-dense-index","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tRAVine-dense-index\n\t\n\nThis repository contains dense index files for the search tools of the RAVine: Reality-Aligned Evaluation for Agentic Search framework. The corpus is MS MARCO V2.1, encoded using Alibaba-NLP/gte-modernbert-base.\nPaper: RAVine: Reality-Aligned Evaluation for Agentic Search\nCode: https://github.com/SwordFaith/RAVine\n\n\t\n\t\t\n\t\n\t\n\t\tAbstract\n\t\n\nAgentic search, as a more autonomous and adaptive paradigm of retrieval augmentation, is driving the evolution of intelligentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sapphirex/RAVine-dense-index.","url":"https://huggingface.co/datasets/sapphirex/RAVine-dense-index","creator_name":"yilong xu","creator_url":"https://huggingface.co/sapphirex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","apache-2.0","arxiv:2507.16725","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-396610","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-396610 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-396610 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-396610.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-396610","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-396610","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-396610 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-396610 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-396610.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-396610","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Arcosoph-Codex-Weaver-FC-Reasoning","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tArcosoph Codex Weaver Function Calling Reasoning Dataset (V1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nWelcome to the Arcosoph-Codex-Weaver-FC-Reasoning dataset! This is a comprehensive, multi-source, and meticulously curated dataset designed for instruction-tuning language models to function as intelligent, offline AI agents.\nThis dataset is provided in a universal, easy-to-parse JSON Lines (.jsonl) format, making it an ideal \"source of truth\" for creating fine-tuning data for various modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcosoph/Arcosoph-Codex-Weaver-FC-Reasoning.","url":"https://huggingface.co/datasets/arcosoph/Arcosoph-Codex-Weaver-FC-Reasoning","creator_name":"Arcosoph AI","creator_url":"https://huggingface.co/arcosoph","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"synthetic-nli-triplet","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nSynthetic-nli-triplet is a dataset generated through an iterative sampling process from the existing nli-triplet dataset. \nEach sampled triplet is used as input to prompt the TheBloke/Mistral-7B-Instruct-v0.1-GPTQ model, \nin generating new and synthetic triplet samples, further expanding the data for tasks involving Natural Language Inference (NLI).\n\n\t\n\t\t\n\t\n\t\n\t\tHow to use\n\t\n\nfrom datasets import load_dataset\n\nmy_dataset = load_dataset(\"lxyuan/synthetic-nli-triplet\")\n\n>>>â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lxyuan/synthetic-nli-triplet.","url":"https://huggingface.co/datasets/lxyuan/synthetic-nli-triplet","creator_name":"Lik Xun Yuan","creator_url":"https://huggingface.co/lxyuan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-27052024-4e8w-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-27052024-4e8w-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"agricultural pest management guidelines search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-27052024-4e8w-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-27052024-4e8w-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-27052024-4e8w-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-27052024-4e8w-webapp","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-27052024-4e8w-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"agricultural pest management guidelines search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-27052024-4e8w-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-27052024-4e8w-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-27052024-4e8w-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"discursos-senado-legislatura-56","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDiscursos da 56Âª Legislatura do Senado Federal\n\t\n\n\n\t\n\t\t\n\t\tVisÃ£o geral\n\t\n\nCorpus de pronunciamentos do PlenÃ¡rio do Senado Federal durante a 56Âª Legislatura (2019â€“2022), coletados via API pÃºblica e consolidados em Parquet. Cada linha Ã© um pronunciamento com metadados e texto integral quando disponÃ­vel.\n\n\t\n\t\t\n\t\tDetalhes do dataset\n\t\n\n\n\t\n\t\t\n\t\tDescriÃ§Ã£o\n\t\n\n\nPeriodo: 2019-02-01 a 2023-01-01\n\nUnidade: pronunciamento no PlenÃ¡rio do Senado\n\nFormato: Parquet (colunar, comprimido)  \n\nCamposâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fabriciosantana/discursos-senado-legislatura-56.","url":"https://huggingface.co/datasets/fabriciosantana/discursos-senado-legislatura-56","creator_name":"Fabricio Fernandes Santana","creator_url":"https://huggingface.co/fabriciosantana","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","summarization","text-retrieval","text-generation"],"keywords_longer_than_N":true},
	{"name":"Comprehensive_Feature_Extraction_DDoS_Datasets","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for Comprehensive_Feature_Extraction_DDoS_Datasets\n\t\n\n\n\nThis dataset card aims to be provided preprocessed five published DDoS datasets based on three feature extracted methods, including correlation, IM, and UFS. \n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe imperative for robust detection mechanisms has grown in the face of increasingly sophisticated Distributed Denial of Service (DDoS) attacks. This paper introduces DDoSBERT, an innovative approach harnessing transformer textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Thi-Thu-Huong/Comprehensive_Feature_Extraction_DDoS_Datasets.","url":"https://huggingface.co/datasets/Thi-Thu-Huong/Comprehensive_Feature_Extraction_DDoS_Datasets","creator_name":"Le","creator_url":"https://huggingface.co/Thi-Thu-Huong","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"Microsoft_Learn","keyword":"feature-extraction","description":"PetraAI/Microsoft_Learn dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PetraAI/Microsoft_Learn","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","fill-mask","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24-gpt-4o-2024-05-131129","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24-gpt-4o-2024-05-131129 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24-gpt-4o-2024-05-131129 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-131129.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-131129","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24-gpt-4o-2024-05-131129","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24-gpt-4o-2024-05-131129 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24-gpt-4o-2024-05-131129 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-131129.","url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-131129","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tå¼µæ‚¦æ¥·è¬›å¤èªžéŸ³æ•¸æ“šé›†\n\t\n\nEnglish\nå‘¢å€‹ä¿‚å¼µæ‚¦æ¥·è¬›ã€Šä¸‰åœ‹æ¼”ç¾©ã€‹ã€ã€Šæ°´æ»¸å‚³ã€‹ã€ã€Šèµ°é€²æ¯›æ¾¤æ±çš„æœ€å¾Œæ­²æœˆã€‹ã€ã€Šé¹¿é¼Žè¨˜ã€‹èªžéŸ³æ•¸æ“šé›†ã€‚å¼µæ‚¦æ¥·ä¿‚å»£å·žæœ€å‡ºåå˜…è¬›å¤ä½¬ / ç²µèªžèª¬æ›¸è—äººã€‚ä½¢å¾žä¸Šä¸–ç´€ä¸ƒåå¹´ä»£é–‹å§‹å°±å–ºå»£æ±å„å€‹æ”¶éŸ³é›»å°åº¦è¬›å¤ï¼Œä½¢æŠŠè²ä¿‚å¥½å¤šå»£å·žäººå˜…å…±åŒå›žæ†¶ã€‚æœ¬æ•¸æ“šé›†æ”¶é›†å˜…ä¿‚ä½¢æœ€çŸ¥åå˜…å››éƒ¨ä½œå“ã€‚\næ•¸æ“šé›†ç”¨é€”ï¼š\n\nTTSï¼ˆèªžéŸ³åˆæˆï¼‰è¨“ç·´é›†\nASRï¼ˆèªžéŸ³è­˜åˆ¥ï¼‰è¨“ç·´é›†æˆ–æ¸¬è©¦é›†\nå„ç¨®èªžè¨€å­¸ã€æ–‡å­¸ç ”ç©¶\nç›´æŽ¥è½åšŸæ¬£è³žè—è¡“ï¼\n\nTTS æ•ˆæžœæ¼”ç¤ºï¼šhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\tèª¬æ˜Ž\n\t\n\n\næ‰€æœ‰æ–‡æœ¬éƒ½æ ¹æ“š https://jyutping.org/blog/typo/ åŒ https://jyutping.org/blog/particles/ è¦ç¯„ç”¨å­—ã€‚\næ‰€æœ‰æ–‡æœ¬éƒ½ä½¿ç”¨å…¨è§’æ¨™é»žï¼Œå†‡åŠè§’æ¨™é»žã€‚\næ‰€æœ‰æ–‡æœ¬éƒ½ç”¨æ¼¢å­—è½‰å¯«ï¼Œç„¡é˜¿æ‹‰ä¼¯æ•¸å­—ç„¡è‹±æ–‡å­—æ¯\næ‰€æœ‰éŸ³é »æºéƒ½å­˜æ”¾å–º/sourceï¼Œç‚ºæ–¹ä¾¿ç›´æŽ¥ç”¨ä½œè¨“ç·´æ•¸æ“šï¼Œåˆ‡åˆ†å¾Œå˜…éŸ³é »éƒ½æ”¾å–º opus/\næ‰€æœ‰ opus éŸ³é »çš†ç‚º 48000â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"ç²µèªžè¨ˆç®—èªžè¨€å­¸åŸºç¤Žå»ºè¨­çµ„ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"VD-Metadata","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tMetadata of the \"Verzeichnis der im deutschen Sprachraum erschienen Drucke\"\n\t\n\n\n\t\n\t\t\n\t\tTitle\n\t\n\nMetadata of the \"Verzeichnis der im deutschen Sprachraum erschienen Drucke\"\n\n\t\n\t\t\n\t\tDescription and Motivation\n\t\n\nThis data publication was created with the intent to provide bibliographic and subject indexing metadata for research purposes and the development of AI applications. This data publication can be regarded as the German national bibliography of the period 1500â€“1800. It consists ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/VD-Metadata.","url":"https://huggingface.co/datasets/SBB/VD-Metadata","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","Greek"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-825318","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-825318 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment analysis and opinion-based QA\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-825318 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-825318.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-825318","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-825318","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-825318 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment analysis and opinion-based QA\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-825318 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-825318.","url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-825318","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Weather_Heatwave_Real-Time_X-Twitter_Example","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tðŸ¦ X-Twitter Scraper: Real-Time Search and Data Extraction Tool\n\t\n\nSearch and scrape X-Twitter (formerly Twitter) for posts by keyword, account, or trending topics. This no-code tool makes it easy to generate real-time, LLM-ready datasets for any AI or content use case.\nGet started with real-time scraping and structure tweet data instantly into clean JSON.\nðŸ‘‰ Launch Scraper Tool\n\n\t\n\t\t\n\t\n\t\n\t\tðŸš€ Key Features\n\t\n\n\nâš¡ Real-Time Fetch â€” Stream the latest tweets the moment theyâ€™re posted\nðŸŽ¯â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MasaFoundation/Weather_Heatwave_Real-Time_X-Twitter_Example.","url":"https://huggingface.co/datasets/MasaFoundation/Weather_Heatwave_Real-Time_X-Twitter_Example","creator_name":"MasaAI","creator_url":"https://huggingface.co/MasaFoundation","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"LogoDet-3K","keyword":"image-feature-extraction","description":"\n\t\n\t\t\n\t\tDataset Card for LogoDet-3K\n\t\n\nLogoDet-3K dataset aims on logotype (image) detection task.\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLogoDet-3K consists of thousand images with brands' logotypes and their bounding boxes. This dataset aims to help train logotype detection models.\n\n\n\n\n\nLicense: MIT\n\n\n\n\n\t\n\t\t\n\t\tDataset Usage\n\t\n\nYou can download this dataset by the following command (make sure that you have installed Huggingface Datasets):\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/PodYapolsky/LogoDet-3K.","url":"https://huggingface.co/datasets/PodYapolsky/LogoDet-3K","creator_name":"Anatoly","creator_url":"https://huggingface.co/PodYapolsky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-segmentation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"xCodeEval","keyword":"feature-extraction","description":"The ability to solve problems is a hallmark of intelligence and has been an enduring goal in AI. AI systems that can create programs as solutions to problems or assist developers in writing programs can increase productivity and make programming more accessible. Recently, pre-trained large language models have shown impressive abilities in generating new codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been performed in a scattered way on only one or two specific tasks, in a few languages, at a partial granularity (e.g., function) level and in many cases without proper training data. Even more concerning is that in most cases the evaluation of generated codes has been done in terms of mere lexical overlap rather than actual execution whereas semantic similarity (or equivalence) of two code segments depends only on their ``execution similarity'', i.e., being able to get the same output for a given input.","url":"https://huggingface.co/datasets/NTU-NLP-sg/xCodeEval","creator_name":"NLP Group of Nanyang Technological University","creator_url":"https://huggingface.co/NTU-NLP-sg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","token-classification","text-retrieval","text-generation","text-classification"],"keywords_longer_than_N":true},
	{"name":"dd-indexes","keyword":"feature-extraction","description":"\n\t\n\t\t\n\t\tâš¡ Pre-computed Search Indexes for Due Diligence\n\t\n\nHigh-performance search indexes and ML artifacts for AI-powered due diligence analysis\nThis repository contains pre-computed search indexes, embeddings, and knowledge graphs that power fast document retrieval and analysis. Skip the expensive embedding computation and start searching immediately!\n\n\t\n\t\t\n\t\tðŸŽ¯ What's Included\n\t\n\n\n\t\n\t\t\n\t\tðŸ” FAISS Vector Indexes (4 indexes, 20.2MB)\n\t\n\nHigh-performance similarity search with sub-second queryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jmzlx/dd-indexes.","url":"https://huggingface.co/datasets/jmzlx/dd-indexes","creator_name":"Juan Salas","creator_url":"https://huggingface.co/jmzlx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-question-answering","text-classification","feature-extraction","English"],"keywords_longer_than_N":true}
]
;
