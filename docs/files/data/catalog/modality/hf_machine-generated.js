var data_for_machine_generated = 
[
	{"name":"pierogue","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dustalov/pierogue","creator_name":"Dmitry Ustalov","creator_url":"https://huggingface.co/dustalov","description":"\\n\\t\\n\\t\\t\\n\\t\\tPierogue\\n\\t\\n\\nPierogue is a small open-licensed machine-generated dataset that contains fifteen short texts in English covering five topics, provided with the relevance judgements (qrels), designed for educational purposes.\\n\\nTopics: cosmos, nature, music, technology, fashion\\nSplits: train (10 documents, 375 qrels) and test (5 documents, 150 qrels)\\n\\nTexts were generated by ChatGPT 3.5. Queries, qrels, and analogies were generated by GPT-4. Words were provided with Word2Vec embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dustalov/pierogue."},
	{"name":"pierogue","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dustalov/pierogue","creator_name":"Dmitry Ustalov","creator_url":"https://huggingface.co/dustalov","description":"\\n\\t\\n\\t\\t\\n\\t\\tPierogue\\n\\t\\n\\nPierogue is a small open-licensed machine-generated dataset that contains fifteen short texts in English covering five topics, provided with the relevance judgements (qrels), designed for educational purposes.\\n\\nTopics: cosmos, nature, music, technology, fashion\\nSplits: train (10 documents, 375 qrels) and test (5 documents, 150 qrels)\\n\\nTexts were generated by ChatGPT 3.5. Queries, qrels, and analogies were generated by GPT-4. Words were provided with Word2Vec embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dustalov/pierogue."},
	{"name":"observation_or_evaluation","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/thomasgauthier/observation_or_evaluation","creator_name":"Thomas Gauthier-Caron","creator_url":"https://huggingface.co/thomasgauthier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Observation or evaluation\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains statements classified into observations and evaluations categories, based on the principles of Nonviolent Communication (NVC) teached by Marshall Rosenberg. It includes a synthetic dataset generated and augmented through various language models to classify statements reflecting either pure observations (noticing) or evaluations (judgments), aimed at understanding and practicing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thomasgauthier/observation_or_evaluation."},
	{"name":"FACTOID","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/aisafe/FACTOID","creator_name":"safe ai","creator_url":"https://huggingface.co/aisafe","description":"aisafe/FACTOID dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"nst-da-norm","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NST-da Normalized\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): da\\nLicense: cc0-1.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm."},
	{"name":"bhojpuri","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
	{"name":"basic_shapes_object_detection","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/driesverachtert/basic_shapes_object_detection","creator_name":"Dries Verachtert","creator_url":"https://huggingface.co/driesverachtert","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBasic Shapes Object Detection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis Basic Shapes Object Detection dataset has been created to test fine-tuning of object detection models. Fine-tuning some model to detect the basic shapes should be rather easy: just a bit of training should be enough to get the model to do correct object detection quite fast.\\nEach entry in the dataset has a RGB PNG image with a white background and 3 basic geometric shapes:\\n\\nA blue square\\nA red circle\\nA green triangle‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/driesverachtert/basic_shapes_object_detection."},
	{"name":"indic_sts","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jaygala24/indic_sts","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic STS\\n\\t\\n\\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Fields\\n\\t\\n\\n\\nlang_code: 2-digit ISO language code\\nsource: The source from which the candidate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jaygala24/indic_sts."},
	{"name":"NextGenBench","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/KaraKaraWitch/NextGenBench","creator_name":"KaraKaraWitch","creator_url":"https://huggingface.co/KaraKaraWitch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Next Generation Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a multitask test consisting of only questions (some are MCQ) from various branches of knowledge. Specifically the following topics:\\nAbstract Algebra\\nAnatomy\\nAstronomy\\nBusiness Ethics\\nClinical Knowledge\\nPrimary School Biology\\nPrimary School Chemistry\\nPrimary School Physics\\nPrimary School Math\\nPrimary School English\\nPrimary School Science\\nPrimary School Computer Science\\nComputer Security\\nDaily‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaraKaraWitch/NextGenBench."},
	{"name":"moroccan-darija-youtube-subtitles","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles","creator_name":"Hamza Bourbouh","creator_url":"https://huggingface.co/bourbouh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMoroccan Darija YouTube Subtitles Dataset\\n\\t\\n\\nThis dataset contains subtitles from YouTube videos in Moroccan Darija, a colloquial Arabic dialect spoken in Morocco. The subtitles were collected from several popular Moroccan YouTube channels, providing a diverse set of transcriptions in the Darija language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is provided as a CSV file, where each row represents a YouTube video and contains the following columns:\\n\\nvideo_id: The unique‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles."},
	{"name":"indic-swim-ir-cross-lingual","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual Indic subset of the SWIM-IR dataset, where the query generated is in the Indo-European language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual."},
	{"name":"swim-ir-cross-lingual","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual."},
	{"name":"code_leak_qa","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fyt7943/code_leak_qa","creator_name":"fyt","creator_url":"https://huggingface.co/fyt7943","description":"fyt7943/code_leak_qa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"code_leak_qa","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fyt7943/code_leak_qa","creator_name":"fyt","creator_url":"https://huggingface.co/fyt7943","description":"fyt7943/code_leak_qa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"copyright_unlearning","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/boyiwei/copyright_unlearning","creator_name":"Boyi Wei","creator_url":"https://huggingface.co/boyiwei","description":"boyiwei/copyright_unlearning dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"copyright_unlearning","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/boyiwei/copyright_unlearning","creator_name":"Boyi Wei","creator_url":"https://huggingface.co/boyiwei","description":"boyiwei/copyright_unlearning dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"indic_sts","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/mteb/indic_sts","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic STS\\n\\t\\n\\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Fields\\n\\t\\n\\n\\nlang_code: 2-digit ISO language code\\nsource: The source from which the candidate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/indic_sts."},
	{"name":"latam-xix","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"spanish-corpus-xix","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"News_Hinglish_English","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/suyash2739/News_Hinglish_English","creator_name":"suyash agarwal","creator_url":"https://huggingface.co/suyash2739","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a collection of text conversations in Hinglish (code mixing between Hindi-English) and their corresponding English versions. Can be used for Translating between the two.\\nThis dataset was generated by translating the first 5000 news content from the Inshorts Dataset - English News [https://www.kaggle.com/datasets/shivamtaneja2304/inshorts-dataset-english]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nHinglish\\nEnglish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nAn example from the json‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suyash2739/News_Hinglish_English."},
	{"name":"unlearning","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LZ12DH/unlearning","creator_name":"Li Zhaodonghui","creator_url":"https://huggingface.co/LZ12DH","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LZ12DH/unlearning."},
	{"name":"unlearning","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LZ12DH/unlearning","creator_name":"Li Zhaodonghui","creator_url":"https://huggingface.co/LZ12DH","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LZ12DH/unlearning."},
	{"name":"assettoCorsaGym","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dasgringuen/assettoCorsaGym","creator_name":"Adrian R","creator_url":"https://huggingface.co/dasgringuen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Assetto Corsa Gym\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe AssettoCorsaGym dataset comprises 64 million steps, including 2.3 million steps from human drivers and the remaining from Soft Actor-Critic (SAC) policies. Data collection involved 15 drivers completing at least five laps per track and car. Participants included a professional e-sports driver, four experts, five casual drivers, and five beginners.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nAutonomous‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dasgringuen/assettoCorsaGym."},
	{"name":"tarwiiga_adgen_dataset","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maelghrib/tarwiiga_adgen_dataset","creator_name":"Mustafa A. Elghrib","creator_url":"https://huggingface.co/maelghrib","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTarwiiga AdGen Dataset\\n\\t\\n\\nThis dataset is generated using LLM for the purpose of fine-tunning another LLM for the task of generating Google Ads, and it used is by Tarwiiga AdGen from Tarwiiga\\n"},
	{"name":"github-issues","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CodeLifeCL/github-issues","creator_name":"CL","creator_url":"https://huggingface.co/CodeLifeCL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nGitHub Issues with comments\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: https://github.com/huggingface/datasets/issues\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOut-of-Scope Use\\n\\t\\n\\n\\n\\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CodeLifeCL/github-issues."},
	{"name":"github-issues","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CodeLifeCL/github-issues","creator_name":"CL","creator_url":"https://huggingface.co/CodeLifeCL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nGitHub Issues with comments\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: https://github.com/huggingface/datasets/issues\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOut-of-Scope Use\\n\\t\\n\\n\\n\\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CodeLifeCL/github-issues."},
	{"name":"BioKGBench-Dataset","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AutoLab-Westlake/BioKGBench-Dataset","creator_name":"AutoLab Westlake","creator_url":"https://huggingface.co/AutoLab-Westlake","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAgent4S-BioKG\\n\\t\\n\\nA Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science.\\n\\n\\n    \\n    \\n\\n     Github \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nPursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws increasing attention, where one common approach is to build a copilot agent driven by Large Language Models(LLMs).However, to evaluate such systems, people either rely on direct Question-Answering(QA) to the LLM itself, or in a biomedical experimental‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AutoLab-Westlake/BioKGBench-Dataset."},
	{"name":"soda-audio","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/fixie-ai/soda-audio","creator_name":"Fixie.ai","creator_url":"https://huggingface.co/fixie-ai","description":"Parent dataset: SODA\\nThe dataset was created based on SODA by first subsetting it and then adding two synthetic columns for training the Ultravox model:\\n\\nalt_last_turn: is an alternative for the last turn of the dialogue (dialogue[-1]) and was (re-)generated by Llama-3-8B Instruct;\\naudio_one_but_last: is the TTS'd speech for the turn before the last one (dialogue[-2]) using the Eleven Labs voice API using a set of random voices.\\n\\n"},
	{"name":"fleurs_clean","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
	{"name":"sec-material-contracts-qa","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"800+ EDGAR contracts with PDF images and key information extracted by the OpenAI GPT-4o model.\\nThe key information is defined as follows:\\nclass KeyInformation(BaseModel):\\n    agreement_date : str = Field(description=\\\"Agreement signing date of the contract. (date)\\\")\\n    effective_date : str = Field(description=\\\"Effective date of the contract. (date)\\\")\\n    expiration_date : str = Field(description=\\\"Service end date or expiration date of the contract. (date)\\\")\\n    party_address : str =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenghao/sec-material-contracts-qa."},
	{"name":"sec-material-contracts-qa","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"800+ EDGAR contracts with PDF images and key information extracted by the OpenAI GPT-4o model.\\nThe key information is defined as follows:\\nclass KeyInformation(BaseModel):\\n    agreement_date : str = Field(description=\\\"Agreement signing date of the contract. (date)\\\")\\n    effective_date : str = Field(description=\\\"Effective date of the contract. (date)\\\")\\n    expiration_date : str = Field(description=\\\"Service end date or expiration date of the contract. (date)\\\")\\n    party_address : str =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenghao/sec-material-contracts-qa."},
	{"name":"sec-material-contracts-qa-splitted","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa-splitted","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"Mixed and filtered version of chenghao/sec-material-contracts-qa and jordyvl/DUDE_subset_100val.\\n"},
	{"name":"sec-material-contracts-qa-splitted","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa-splitted","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"Mixed and filtered version of chenghao/sec-material-contracts-qa and jordyvl/DUDE_subset_100val.\\n"},
	{"name":"sea-vqa","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/wit543/sea-vqa","creator_name":"Norawit Urailertprasert","creator_url":"https://huggingface.co/wit543","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SEA-VQA\\n\\t\\n\\nSEA-VQA is a dataset designed to evaluate the performance of Visual Question Answering (VQA) models on culturally specific content from Southeast Asia (SEA). This dataset aims to highlight the challenges and gaps in existing VQA models when confronted with culturally rich content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSEA-VQA is a specialized VQA dataset that includes images from eight Southeast Asian countries, curated from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wit543/sea-vqa."},
	{"name":"MultiPL-E","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nuprl-staging/MultiPL-E","creator_name":"Northeastern University PRL","creator_url":"https://huggingface.co/nuprl-staging","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiPL-E\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPL-E is a dataset for evaluating large language models for code\\ngeneration that supports 22 programming languages. It takes the OpenAI \\nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\\ntranslate them  to other languages. It is easy to add support for new languages \\nand benchmarks.\\nThe dataset is divided into several configurations named SRCDATA-LANG, where\\nSRCDATA is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl-staging/MultiPL-E."},
	{"name":"MultiPL-E","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nuprl-staging/MultiPL-E","creator_name":"Northeastern University PRL","creator_url":"https://huggingface.co/nuprl-staging","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiPL-E\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPL-E is a dataset for evaluating large language models for code\\ngeneration that supports 22 programming languages. It takes the OpenAI \\nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\\ntranslate them  to other languages. It is easy to add support for new languages \\nand benchmarks.\\nThe dataset is divided into several configurations named SRCDATA-LANG, where\\nSRCDATA is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl-staging/MultiPL-E."},
	{"name":"GridTallyBench","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MoonTideF/GridTallyBench","creator_name":"MoonTide","creator_url":"https://huggingface.co/MoonTideF","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGridTallyBench: Checkerboard Image Dataset for MLLM Benchmarking\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nGridTallyBench is a collection of synthetic checkerboard images designed to test and benchmark Multi-modal Large Language Models (MLLMs) on tasks involving visual pattern recognition and counting. This dataset offers a controlled environment for evaluating model performance on basic visual tasks, particularly useful for assessing an MLLM's ability to count and describe simple geometric‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MoonTideF/GridTallyBench."},
	{"name":"12-weltanschauungen","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Lafisrap/12-weltanschauungen","creator_name":"Michael Schmidt","creator_url":"https://huggingface.co/Lafisrap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t12 Denkarten, 7 Erkenntnisstimmungen und 45 kulturgewordene Gedankenfehler\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of writings on twelve thinking styles, seven moods of cognition, and forty-five culturally manifested cognitive errors. It includes a collection of texts that analyze and critique various aspects of human thought processes within a cultural context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset can be used for tasks such as text generation, text classification‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lafisrap/12-weltanschauungen."},
	{"name":"DarijaMMLU","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MBZUAI-Paris/DarijaMMLU","creator_name":"MBZUAI France Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DarijaMMLU\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDarijaMMLU is an evaluation benchmark designed to assess large language models' (LLM) performance in Moroccan Darija, a variety of Arabic. It consists of 22,027 multiple-choice questions, translated from selected subsets of the Massive Multitask Language Understanding (MMLU) and ArabicMMLU benchmarks to measure model performance on 44 subjects in Darija.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nTask Category: Multiple-choice‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/DarijaMMLU."},
	{"name":"TOFU-C","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-C","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C."},
	{"name":"TOFU-C","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-C","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C."},
	{"name":"TOFU-Cf","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-Cf","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cf."},
	{"name":"TOFU-Cf","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-Cf","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cf."},
	{"name":"TOFU-Cr","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-Cr","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cr."},
	{"name":"TOFU-Cr","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-Cr","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cr."},
	{"name":"capivara-plugin-orchestration","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/LeonardoBenitez/capivara-plugin-orchestration","creator_name":"Leonardo Santiago Benitez Pereira","creator_url":"https://huggingface.co/LeonardoBenitez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t# Dataset Card for Capivara Plugin Orchestration\\n\\t\\n\\n"},
	{"name":"TOFU-C","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFU-C","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C."},
	{"name":"TOFU-C","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFU-C","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C."},
	{"name":"TOFUCr1","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFUCr1","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCr1."},
	{"name":"TOFUCr1","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFUCr1","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCr1."},
	{"name":"wise-data","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/meaningalignment/wise-data","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe wise-data and wise-data-preferences datasets are synthetically created collections of values-laden conversations, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. These datasets were specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data."},
	{"name":"wise-data","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/meaningalignment/wise-data","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe wise-data and wise-data-preferences datasets are synthetically created collections of values-laden conversations, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. These datasets were specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data."},
	{"name":"Trust-Data","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/declare-lab/Trust-Data","creator_name":"Deep Cognition and Language Research (DeCLaRe) Lab","creator_url":"https://huggingface.co/declare-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Trust framework\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\n\\nRepository: https://github.com/declare-lab/trust-align\\nPaper: https://arxiv.org/abs/2409.11242\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Summary\\n\\t\\n\\nThe Trust-score evaluation dataset includes the top 100 GTR-retrieved results for ASQA, QAMPARI, and ExpertQA, along with the top 100 BM25-retrieved results for ELI5. The answerability of each question is assessed based on its accompanying documents.\\nThe Trust-align training dataset comprises 19K high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/declare-lab/Trust-Data."},
	{"name":"wise-data-preferences","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/meaningalignment/wise-data-preferences","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe wise-data-preferences dataset is a synthetically created collection of values-laden conversations with preferred and rejected responses, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. This dataset was specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using DPO (Direct Preference Optimization).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data-preferences."},
	{"name":"wise-data-preferences","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/meaningalignment/wise-data-preferences","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe wise-data-preferences dataset is a synthetically created collection of values-laden conversations with preferred and rejected responses, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. This dataset was specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using DPO (Direct Preference Optimization).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data-preferences."},
	{"name":"steambans","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/steambans","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Steam User Bans\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 476,694 Steam users, including their profile details, ban status, and gaming activity. The data was collected from the Steam platform and includes information such as Steam ID, profile URL, username, avatar, account creation date, visibility state, VAC and game bans, economy ban status, time since last ban, Steam level, friend count, game count, total playtime, and CS2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/steambans."},
	{"name":"TOFUCrP","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFUCrP","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCrP."},
	{"name":"TOFUCrP","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFUCrP","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCrP."},
	{"name":"TruthGen","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/wwbrannon/TruthGen","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TruthGen\\n\\t\\n\\nTruthGen is a dataset of generated political statements, created to assess the relationship between truthfulness and political bias in reward models and language models. It consists of non-repetitive, non-political factual statements paired with false statements, designed to evaluate models for their ability to distinguish true from false information while minimizing political content. The dataset was generated using GPT-3.5, GPT-4 and Gemini, with a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/TruthGen."},
	{"name":"TruthGen","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/wwbrannon/TruthGen","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TruthGen\\n\\t\\n\\nTruthGen is a dataset of generated political statements, created to assess the relationship between truthfulness and political bias in reward models and language models. It consists of non-repetitive, non-political factual statements paired with false statements, designed to evaluate models for their ability to distinguish true from false information while minimizing political content. The dataset was generated using GPT-3.5, GPT-4 and Gemini, with a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/TruthGen."},
	{"name":"SynWOZ","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Ayushnangia/SynWOZ","creator_name":"Ayush Nangia","creator_url":"https://huggingface.co/Ayushnangia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynWOZ\\n\\t\\n\\nA dataset containing 50k dialogues with various intents and emotions, generated using an advanced dialogue generation pipeline.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 50k dialogues generated by an advanced dialogue generation pipeline. The dialogues simulate realistic interactions across various services such as restaurants, hotels, taxis, and more, incorporating diverse scenarios, emotions, and resolution statuses.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ayushnangia/SynWOZ."},
	{"name":"SynWOZ","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Ayushnangia/SynWOZ","creator_name":"Ayush Nangia","creator_url":"https://huggingface.co/Ayushnangia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynWOZ\\n\\t\\n\\nA dataset containing 50k dialogues with various intents and emotions, generated using an advanced dialogue generation pipeline.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 50k dialogues generated by an advanced dialogue generation pipeline. The dialogues simulate realistic interactions across various services such as restaurants, hotels, taxis, and more, incorporating diverse scenarios, emotions, and resolution statuses.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ayushnangia/SynWOZ."},
	{"name":"xlam-function-calling-60k-raw","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw","creator_name":"Product Science","creator_url":"https://huggingface.co/product-science","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXLAM Function Calling 60k Raw Dataset\\n\\t\\n\\nThis dataset includes train and test splits derived from Salesforce/xlam-function-calling-60k.\\n\\nTrain split size: 95% of the original dataset\\nTest split size: 5% of the original dataset\\n\\n"},
	{"name":"traffic-qa","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/paulelliotco/traffic-qa","creator_name":"Paul Elliot","creator_url":"https://huggingface.co/paulelliotco","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFHWA Traffic Signal Timing Q&A Dataset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\n4,368 Q&A pairs on traffic signal timing topics.  \\nAI-generated using Google's Gemini model.  \\nStructured for training and fine-tuning AI models.  \\nBased on official FHWA documentation.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nQuestion: Traffic signal timing question.  \\nAnswer: Detailed technical answer.  \\nSection ID: Reference to the original source section.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paulelliotco/traffic-qa."},
	{"name":"traffic-qa","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/paulelliotco/traffic-qa","creator_name":"Paul Elliot","creator_url":"https://huggingface.co/paulelliotco","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFHWA Traffic Signal Timing Q&A Dataset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\n4,368 Q&A pairs on traffic signal timing topics.  \\nAI-generated using Google's Gemini model.  \\nStructured for training and fine-tuning AI models.  \\nBased on official FHWA documentation.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nQuestion: Traffic signal timing question.  \\nAnswer: Detailed technical answer.  \\nSection ID: Reference to the original source section.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paulelliotco/traffic-qa."},
	{"name":"llmops-database","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zenml/llmops-database","creator_name":"ZenML","creator_url":"https://huggingface.co/zenml","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe ZenML LLMOps Database\\n\\t\\n\\n\\nTo learn more about ZenML and our open-source MLOps framework, visit\\nzenml.io.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LLMOps Database is a comprehensive collection of over 500 real-world\\ngenerative AI implementations that showcases how organizations are successfully\\ndeploying Large Language Models (LLMs) in production. The case studies have been\\ncarefully curated to focus on technical depth and practical problem-solving,\\nwith an emphasis on implementation details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zenml/llmops-database."},
	{"name":"aircraft-images","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/aircraft-images","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for High-Resolution Aircraft Images\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 165,340 high-resolution aircraft images collected from the internet, along with machine-generated captions. The captions were generated using Gemini Flash 1.5 AI model and are stored in separate text files matching the image filenames.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is monolingual:\\n\\nEnglish (en): All image captions are in English\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/aircraft-images."},
	{"name":"allenai-prosocial-dialog","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tProsocialDialog ShareGPT Format\\n\\t\\n\\nThis is an adapted version of the allenai/prosocial-dialog dataset, restructured to follow a ShareGPT-like format. This dataset teaches conversational AI agents how to respond to problematic content while adhering to social norms. It covers a wide range of unethical, problematic, biased, and toxic situations, providing responses that encourage prosocial behavior grounded in commonsense social rules.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach conversation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog."},
	{"name":"math-augmented-dataset","keyword":"machine-generated","license":"GNU General Public License v2.0","language":"en","url":"https://huggingface.co/datasets/nivektk/math-augmented-dataset","creator_name":"Kevin Fabio Ramos L√≥pez","creator_url":"https://huggingface.co/nivektk","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath-Augmented-Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Math-Augmented-Dataset extends the MATH dataset by Dan Hendrycks, focusing on algebra problems. It comprises 1,006 validated examples from the algebra subset, structured in JSON format with detailed step-by-step solutions generated using Large Language Models (LLMs) with chain-of-thought reasoning.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach JSON file contains:\\n\\nproblem: The math problem statement, including LaTeX expressions.\\nlevel:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nivektk/math-augmented-dataset."},
	{"name":"blackjack","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JackFurby/blackjack","creator_name":"Jack","creator_url":"https://huggingface.co/JackFurby","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Blackjack\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA dataset containing two sets of playing card images for hands in the card game Blackjack. Each set contains at least 10,000 images and has a series of attributes. This dataset is based on the dataset Playing cards [1]\\nTrain and test splits are provided in both JSON and pickle formats. Concept and task classification labels (both zero indexed) and names are provided in txt files.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackFurby/blackjack."},
	{"name":"blackjack","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JackFurby/blackjack","creator_name":"Jack","creator_url":"https://huggingface.co/JackFurby","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Blackjack\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA dataset containing two sets of playing card images for hands in the card game Blackjack. Each set contains at least 10,000 images and has a series of attributes. This dataset is based on the dataset Playing cards [1]\\nTrain and test splits are provided in both JSON and pickle formats. Concept and task classification labels (both zero indexed) and names are provided in txt files.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackFurby/blackjack."},
	{"name":"test1","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mujif/test1","creator_name":"dasf","creator_url":"https://huggingface.co/mujif","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttest\\n\\t\\n\\ntest1\\n"},
	{"name":"test1","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mujif/test1","creator_name":"dasf","creator_url":"https://huggingface.co/mujif","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttest\\n\\t\\n\\ntest1\\n"},
	{"name":"subdomains","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/subdomains","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Subdomain Statistics from scanner.ducks.party\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains monthly archives of subdomain statistics for websites seen by the scanner.ducks.party web bot. The data is provided in CSV format, with each archive containing two columns: Subdomain and Count.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English, with subdomains potentially in multiple languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/subdomains."},
	{"name":"question-complexity","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rokokot/question-complexity","creator_name":"Robin Kokot","creator_url":"https://huggingface.co/rokokot","description":"\\n\\t\\n\\t\\t\\n\\t\\tQuestion Type and Complexity (QTC) Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe Question Type and Complexity (QTC) dataset is a comprehensive resource for linguistics/NLP research focusing on question classification and linguistic complexity analysis across multiple languages. It contains questions from two distinct sources (TyDi QA and Universal Dependencies v2.15), automatically annotated with question types (polar/content) and a set of linguistic complexity features.\\nKey Features:\\n\\n2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rokokot/question-complexity."},
	{"name":"TOFU-C-All","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-All","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-All."},
	{"name":"TOFU-C-All","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-All","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-All."},
	{"name":"mosel","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description, Collection, and Source\\n\\t\\n\\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel."},
	{"name":"hostnames","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/hostnames","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCT Log Archive: Download Hostnames from Inactive Logs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWarning\\n\\t\\n\\nThe data was obtained by parsing CT with modified software, which will be discussed below. I cannot guarantee the accuracy of the data, as it is possible that some data was lost due to a variety of factors, such as the data from Let's Encrypt Oak 2022. If you want to do passive data analysis and you want maximum accuracy for each specific CT, then I highly recommend that you use self-written software‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/hostnames."},
	{"name":"axay-javascript-dataset-pn","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/israellaguan/axay-javascript-dataset-pn","creator_name":"Israel Antonio Rosales Laguan","creator_url":"https://huggingface.co/israellaguan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDPO JavaScript Dataset\\n\\t\\n\\nThis repository contains a modified version of the JavaScript dataset originally sourced from axay/javascript-dataset-pn. The dataset has been adapted to fit the DPO (Dynamic Programming Object) format, making it compatible with the LLaMA-Factory project.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is licensed under the Apache 2.0 License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe dataset consists of JavaScript code snippets that have been restructured and enhanced for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/israellaguan/axay-javascript-dataset-pn."},
	{"name":"axay-javascript-dataset-pn","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/israellaguan/axay-javascript-dataset-pn","creator_name":"Israel Antonio Rosales Laguan","creator_url":"https://huggingface.co/israellaguan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDPO JavaScript Dataset\\n\\t\\n\\nThis repository contains a modified version of the JavaScript dataset originally sourced from axay/javascript-dataset-pn. The dataset has been adapted to fit the DPO (Dynamic Programming Object) format, making it compatible with the LLaMA-Factory project.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is licensed under the Apache 2.0 License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe dataset consists of JavaScript code snippets that have been restructured and enhanced for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/israellaguan/axay-javascript-dataset-pn."},
	{"name":"amr-3-parsed","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/hoshuhan/amr-3-parsed","creator_name":"hoshuhan","creator_url":"https://huggingface.co/hoshuhan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AMR 3.0 Parsed\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains parsed Abstract Meaning Representation (AMR) annotations from the LDC2020T02 release, formatted as instruction-following conversations. Each example consists of a sentence and its corresponding AMR graph representation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nTasks: Semantic parsing, specifically generating AMR graphs from English sentences\\nLeaderboards: AMR Parsing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoshuhan/amr-3-parsed."},
	{"name":"TOFU-C-Shuffle","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle."},
	{"name":"TOFU-C-Shuffle","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle."},
	{"name":"TOFU-C-single","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-single","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-single."},
	{"name":"TOFU-C-single","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-single","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-single."},
	{"name":"TOFU-Cbin","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-Cbin","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cbin."},
	{"name":"TOFU-Cbin","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-Cbin","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cbin."},
	{"name":"TOFU-C-Direct","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Direct","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Direct."},
	{"name":"TOFU-C-Direct","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Direct","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Direct."},
	{"name":"MiSC","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jihyoung/MiSC","creator_name":"Jihyoung Jang","creator_url":"https://huggingface.co/jihyoung","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiSC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nMiSC is the first dataset designed to implement the concept of mixed-session conversations, where a main speaker interacts with different partners across multiple sessions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLoad with Hugging Face Datasets\\n\\t\\n\\nYou can load the MiSC dataset using the Hugging Face Datasets library with the following code:\\nfrom datasets import load_dataset\\nmisc = load_dataset(\\\"jihyoung/MiSC\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe language of the MiSC dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jihyoung/MiSC."},
	{"name":"ukiyo-e-face-blip2-captions","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/py-img-gen/ukiyo-e-face-blip2-captions","creator_name":"Image Generation with Python","creator_url":"https://huggingface.co/py-img-gen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ukiyo-e-face-blip2-captions\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nukiyo-e-face-blip2-captions is a dataset that adds captions to Ukiyo-e face dataset using BLIP2 model.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe language data in ukiyo-e-face-blip2-captions is in English.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nimport datasets as ds\\n\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/py-img-gen/ukiyo-e-face-blip2-captions."},
	{"name":"SemEval2024-task8","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/d0rj/SemEval2024-task8","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSemEval2024-task8\\n\\t\\n\\nUnofficial mirror of M4 dataset from mbzuai-nlp/SemEval2024-task8 (website, github, codabench).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubtask A\\n\\t\\n\\nAn object in the JSON format:\\n{\\n  id -> identifier of the example,\\n  label -> label (human text: 0, machine text: 1,),\\n  text -> text generated by a machine or written by a human,\\n  model -> model that generated the data,\\n  source -> source (Wikipedia, Wikihow, Peerread, Reddit, Arxiv)  on English or language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/SemEval2024-task8."},
	{"name":"test_4","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
	{"name":"TOFU-C-All","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-C-All","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C-All."},
	{"name":"TOFU-C-All","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/annnli/TOFU-C-All","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C-All."},
	{"name":"Eason_TOFU","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/EasonZhong/Eason_TOFU","creator_name":"Yisheng Zhong","creator_url":"https://huggingface.co/EasonZhong","description":"EasonZhong/Eason_TOFU dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Eason_TOFU","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/EasonZhong/Eason_TOFU","creator_name":"Yisheng Zhong","creator_url":"https://huggingface.co/EasonZhong","description":"EasonZhong/Eason_TOFU dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"exorde-social-media-december-2024-week1","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Exorde/exorde-social-media-december-2024-week1","creator_name":"ExordeLabs","creator_url":"https://huggingface.co/Exorde","description":""},
	{"name":"multimodal_meme_classification_singapore","keyword":"machine-generated","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/aliencaocao/multimodal_meme_classification_singapore","creator_name":"Billy Cao","creator_url":"https://huggingface.co/aliencaocao","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Offensive Memes in Singapore Context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a collection of memes from various existing datasets, online forums, and freshly scrapped contents. It contains both global-context memes and Singapore-context memes, in different splits. It has textual description and a label stating if it is offensive under Singapore society's standards.\\n\\nCurated by: Cao Yuxuan, Wu Jiayang, Alistair Cheong, Theodore Lee‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aliencaocao/multimodal_meme_classification_singapore."},
	{"name":"multimodal_meme_classification_singapore","keyword":"machine-generated","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/aliencaocao/multimodal_meme_classification_singapore","creator_name":"Billy Cao","creator_url":"https://huggingface.co/aliencaocao","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Offensive Memes in Singapore Context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a collection of memes from various existing datasets, online forums, and freshly scrapped contents. It contains both global-context memes and Singapore-context memes, in different splits. It has textual description and a label stating if it is offensive under Singapore society's standards.\\n\\nCurated by: Cao Yuxuan, Wu Jiayang, Alistair Cheong, Theodore Lee‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aliencaocao/multimodal_meme_classification_singapore."},
	{"name":"nep_qa_test","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jangedoo/nep_qa_test","creator_name":"Sanjaya Subedi","creator_url":"https://huggingface.co/jangedoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Nepali Q&A Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nNepali Q&A Dataset\\nThis dataset was automatically generated using this library\\n\\nCurated by: ['Sanjaya Subedi jangedoo@gmail.com']\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): ['ne']\\nLicense: mit\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jangedoo/nep_qa_test."},
	{"name":"PubMedQA","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/qiaojin/PubMedQA","creator_name":"Qiao Jin","creator_url":"https://huggingface.co/qiaojin","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe official leaderboard is available at: https://pubmedqa.github.io/.\\n500 questions in the pqa_labeled are used as the test set. They can be found at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qiaojin/PubMedQA."},
	{"name":"soda","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/allenai/soda","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ü•§SODA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nü•§SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions. Dialogues are distilled from a PLM (InstructGPT; Ouyang et al., 2022) by contextualizing social commonsense knowledge from a knowledge graph (Atomic10x; West et al., 2022). Human evaluation shows that dialogues in SODA are more consistent, specific, and (surprisingly) natural than prior‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/soda."},
	{"name":"blimp","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/nyu-mll/blimp","creator_name":"NYU Machine Learning for Language","creator_url":"https://huggingface.co/nyu-mll","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"blimp\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBLiMP is a challenge set for evaluating what language models (LMs) know about\\nmajor grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each\\ncontaining 1000 minimal pairs isolating specific contrasts in syntax,\\nmorphology, or semantics. The data is automatically generated according to\\nexpert-crafted grammars.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyu-mll/blimp."},
	{"name":"kilt_tasks","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KILT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKILT has been built from 11 datasets representing 5 types of tasks:\\n\\nFact-checking\\nEntity linking\\nSlot filling\\nOpen domain QA\\nDialog generation\\n\\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks."},
	{"name":"spider","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/xlangai/spider","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students.\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xlangai/spider."},
	{"name":"youtube_caption_corrections","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/community-datasets/youtube_caption_corrections","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for YouTube Caption Corrections\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is built from pairs of YouTube captions where both an auto-generated and a manually-corrected caption are available for a single specified language. It currently only in English, but scripts at repo support other languages. The motivation for creating it was from viewing errors in auto-generated captions at a recent virtual conference, with the hope that there could be some way to help‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/youtube_caption_corrections."},
	{"name":"youtube_caption_corrections","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/community-datasets/youtube_caption_corrections","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for YouTube Caption Corrections\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is built from pairs of YouTube captions where both an auto-generated and a manually-corrected caption are available for a single specified language. It currently only in English, but scripts at repo support other languages. The motivation for creating it was from viewing errors in auto-generated captions at a recent virtual conference, with the hope that there could be some way to help‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/youtube_caption_corrections."},
	{"name":"rebel-dataset","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/rebel-dataset","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"REBEL is a silver dataset created for the paper REBEL: Relation Extraction By End-to-end Language generation"},
	{"name":"rebel-dataset","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/rebel-dataset","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"REBEL is a silver dataset created for the paper REBEL: Relation Extraction By End-to-end Language generation"},
	{"name":"ru-paraphrase-NMT-Leipzig","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/cointegrated/ru-paraphrase-NMT-Leipzig","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for cointegrated/ru-paraphrase-NMT-Leipzig\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset contains 1 million Russian sentences and their automatically generated paraphrases. \\nIt was created by David Dale (@cointegrated) by translating the rus-ru_web-public_2019_1M corpus from the Leipzig collection into English and back into Russian. A fraction of the resulting paraphrases are invalid, and should be filtered out.\\nThe blogpost \\\"–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤: –∫–æ—Ä–ø—É—Å–∞‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/ru-paraphrase-NMT-Leipzig."},
	{"name":"aaac","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/DebateLabKIT/aaac","creator_name":"DebateLab at KIT","creator_url":"https://huggingface.co/DebateLabKIT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Artificial Argument Analysis Corpus (AAAC)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDeepA2 is a modular framework for deep argument analysis. DeepA2 datasets contain comprehensive logical reconstructions of informally presented arguments in short argumentative texts. This document describes two synthetic DeepA2 datasets for artificial argument analysis: AAAC01 and AAAC02.\\n# clone\\ngit lfs clone https://huggingface.co/datasets/debatelab/aaac\\n\\nimport pandas as pd\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DebateLabKIT/aaac."},
	{"name":"aaac","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/DebateLabKIT/aaac","creator_name":"DebateLab at KIT","creator_url":"https://huggingface.co/DebateLabKIT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Artificial Argument Analysis Corpus (AAAC)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDeepA2 is a modular framework for deep argument analysis. DeepA2 datasets contain comprehensive logical reconstructions of informally presented arguments in short argumentative texts. This document describes two synthetic DeepA2 datasets for artificial argument analysis: AAAC01 and AAAC02.\\n# clone\\ngit lfs clone https://huggingface.co/datasets/debatelab/aaac\\n\\nimport pandas as pd\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DebateLabKIT/aaac."},
	{"name":"klexikon","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/dennlinger/klexikon","creator_name":"Dennis Aumiller","creator_url":"https://huggingface.co/dennlinger","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for the Klexikon Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion History\\n\\t\\n\\n\\nv0.3 (2022-09-01): Removing some five samples from the dataset due to duplication conflicts with other samples.\\nv0.2 (2022-02-28): Updated the files to no longer contain empty sections and removing otherwise empty lines at the end of files. Also removing lines with some sort of coordinate.\\nv0.1 (2022-01-19): Initial data release on Huggingface datasets.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Klexikon dataset is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dennlinger/klexikon."},
	{"name":"Ukr-Synth","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ukr-models/Ukr-Synth","creator_name":"Volodymyr Kurnosov","creator_url":"https://huggingface.co/ukr-models","description":"Large silver standard Ukrainian corpus annotated with morphology tags, syntax trees and PER, LOC, ORG NER-tags."},
	{"name":"norwegian-paws-x","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NbAiLab/norwegian-paws-x","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"Norwegian PAWS-X, Bokmaal and Nynorsk machine-translated versions of PAWS-X.\\n\\nPAWS-X, a multilingual version of PAWS (Paraphrase Adversaries from Word Scrambling) for six languages.\\n\\nThis dataset contains 23,659 human translated PAWS evaluation pairs and 296,406 machine\\ntranslated training pairs in six typologically distinct languages: French, Spanish, German,\\nChinese, Japanese, and Korean. English language is available by default. All translated\\npairs are sourced from examples in PAWS-Wiki.\\n\\nFor further details, see the accompanying paper: PAWS-X: A Cross-lingual Adversarial Dataset\\nfor Paraphrase Identification (https://arxiv.org/abs/1908.11828)\\n\\nNOTE: There might be some missing or wrong labels in the dataset and we have replaced them with -1."},
	{"name":"norwegian-paws-x","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NbAiLab/norwegian-paws-x","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"Norwegian PAWS-X, Bokmaal and Nynorsk machine-translated versions of PAWS-X.\\n\\nPAWS-X, a multilingual version of PAWS (Paraphrase Adversaries from Word Scrambling) for six languages.\\n\\nThis dataset contains 23,659 human translated PAWS evaluation pairs and 296,406 machine\\ntranslated training pairs in six typologically distinct languages: French, Spanish, German,\\nChinese, Japanese, and Korean. English language is available by default. All translated\\npairs are sourced from examples in PAWS-Wiki.\\n\\nFor further details, see the accompanying paper: PAWS-X: A Cross-lingual Adversarial Dataset\\nfor Paraphrase Identification (https://arxiv.org/abs/1908.11828)\\n\\nNOTE: There might be some missing or wrong labels in the dataset and we have replaced them with -1."},
	{"name":"clevr-math","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dali-does/clevr-math","creator_name":"Adam Dahlgren Lindstr√∂m","creator_url":"https://huggingface.co/dali-does","description":"CLEVR-Math is a dataset for compositional language, visual and mathematical reasoning. CLEVR-Math poses questions about mathematical operations on visual scenes using subtraction and addition, such as \\\"Remove all large red cylinders. How many objects are left?\\\". There are also adversarial (e.g. \\\"Remove all blue cubes. How many cylinders are left?\\\") and multihop questions (e.g. \\\"Remove all blue cubes. Remove all small purple spheres. How many objects are left?\\\")."},
	{"name":"clevr-math","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dali-does/clevr-math","creator_name":"Adam Dahlgren Lindstr√∂m","creator_url":"https://huggingface.co/dali-does","description":"CLEVR-Math is a dataset for compositional language, visual and mathematical reasoning. CLEVR-Math poses questions about mathematical operations on visual scenes using subtraction and addition, such as \\\"Remove all large red cylinders. How many objects are left?\\\". There are also adversarial (e.g. \\\"Remove all blue cubes. How many cylinders are left?\\\") and multihop questions (e.g. \\\"Remove all blue cubes. Remove all small purple spheres. How many objects are left?\\\")."},
	{"name":"MultiPL-E","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nuprl/MultiPL-E","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for MultiPL-E\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPL-E is a dataset for evaluating large language models for code\\ngeneration that supports 22 programming languages. It takes the OpenAI \\nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\\ntranslate them  to other languages. It is easy to add support for new languages \\nand benchmarks.\\nThe dataset is divided into several configurations named SRCDATA-LANG, where\\nSRCDATA is either‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/MultiPL-E."},
	{"name":"MultiPL-E","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nuprl/MultiPL-E","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for MultiPL-E\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPL-E is a dataset for evaluating large language models for code\\ngeneration that supports 22 programming languages. It takes the OpenAI \\nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\\ntranslate them  to other languages. It is easy to add support for new languages \\nand benchmarks.\\nThe dataset is divided into several configurations named SRCDATA-LANG, where\\nSRCDATA is either‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/MultiPL-E."},
	{"name":"kqa_pro","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/drt/kqa_pro","creator_name":"Yuanchun","creator_url":"https://huggingface.co/drt","description":"A large-scale, diverse, challenging dataset of complex question answering over knowledge base."},
	{"name":"prosocial-dialog","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/allenai/prosocial-dialog","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ProsocialDialog Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nProsocialDialog is the first large-scale multi-turn English dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborative‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/prosocial-dialog."},
	{"name":"mnli-norwegian","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NbAiLab/mnli-norwegian","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMNLI Norwegian\\n\\t\\n\\nThe Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced collection of 433k sentence pairs annotated with textual entailment information. The corpus is modeled on the SNLI corpus, but differs in that it covers a range of genres of spoken and written text, and supports a distinctive cross-genre generalisation evaluation. There is also a HuggingFace version of the dataset available. \\nThis dataset is machine translated using Google Translate.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/mnli-norwegian."},
	{"name":"stackoverflow-questions","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pacovaldez/stackoverflow-questions","creator_name":"Paco Valdez","creator_url":"https://huggingface.co/pacovaldez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Stackoverflow Post Questions]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCompanies that sell Open-source software tools usually hire an army of Customer representatives to try to answer every question asked about their tool. The first step in this process \\nis the prioritization of the question. The classification scale usually consists of 4 values, P0, P1, P2, and P3, with different meanings across every participant in the industry. On \\nthe other hand, every software‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacovaldez/stackoverflow-questions."},
	{"name":"spectrogram-captions","keyword":"machine-generated","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/vucinatim/spectrogram-captions","creator_name":"Tim Vuƒçina","creator_url":"https://huggingface.co/vucinatim","description":"Dataset of captioned spectrograms (text describing the sound).\\n"},
	{"name":"spectrogram-captions","keyword":"machine-generated","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/vucinatim/spectrogram-captions","creator_name":"Tim Vuƒçina","creator_url":"https://huggingface.co/vucinatim","description":"Dataset of captioned spectrograms (text describing the sound).\\n"},
	{"name":"clintox","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/clintox","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for clintox\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nclintox is a dataset included in MoleculeNet. Qualitative data of drugs approved by the FDA and those that have failed clinical trials for toxicity reasons. This uses the CT_TOX task.\\nNote, there was one molecule in the training set that could not be converted to SELFIES (*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clintox."},
	{"name":"clintox","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/clintox","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for clintox\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nclintox is a dataset included in MoleculeNet. Qualitative data of drugs approved by the FDA and those that have failed clinical trials for toxicity reasons. This uses the CT_TOX task.\\nNote, there was one molecule in the training set that could not be converted to SELFIES (*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clintox."},
	{"name":"lambada_openai","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/EleutherAI/lambada_openai","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","description":"The LAMBADA dataset as processed by OpenAI. It is used to evaluate the capabilities\\nof computational models for text understanding by means of a word prediction task.\\nLAMBADA is a collection of narrative texts sharing the characteristic that human subjects\\nare able to guess their last word if they are exposed to the whole text, but not\\nif they only see the last sentence preceding the target word. To succeed on LAMBADA,\\ncomputational models cannot simply rely on local context, but must be able to keep track\\nof information in the broader discourse.\\n\\nReference: https://github.com/openai/gpt-2/issues/131#issuecomment-497136199"},
	{"name":"weibo16","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kuroneko5943/weibo16","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"DBLP-QuAD","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/awalesushil/DBLP-QuAD","creator_name":"Sushil Awale","creator_url":"https://huggingface.co/awalesushil","description":"    DBLP-QuAD is a scholarly knowledge graph question answering dataset with     10,000 question - SPARQL query pairs targeting the DBLP knowledge graph.     The dataset is split into 7,000 training, 1,000 validation and 2,000 test     questions."},
	{"name":"SciQA","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/orkg/SciQA","creator_name":"The Open Research Knowledge Graph","creator_url":"https://huggingface.co/orkg","description":"    SciQA contains 2,565 SPARQL query - question pairs along with answers fetched from the open research knowledge graph (ORKG)     via a Virtuoso SPARQL endpoint, it is a collection of both handcrafted and autogenerated questions and queries.     The dataset is split into 70% training, 10% validation and 20% test examples. The dataset is available as JSON files."},
	{"name":"swiss_leading_decision_summarization","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_leading_decision_summarization","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"This dataset contains court decisions for the swiss ruling summarization task."},
	{"name":"jat-dataset","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jat-project/jat-dataset","creator_name":"Jack of All Trades project","creator_url":"https://huggingface.co/jat-project","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJAT Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Jack of All Trades (JAT) dataset combines a wide range of individual datasets. It includes expert demonstrations by expert RL agents, image and caption pairs, textual data and more. The JAT dataset is part of the JAT project, which aims to build a multimodal generalist agent.\\nPaper: https://huggingface.co/papers/2402.09844\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n>>> from datasets import load_dataset\\n>>> dataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jat-project/jat-dataset."},
	{"name":"unarXive-en2ru","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/waleko/unarXive-en2ru","creator_name":"Alexander Kovrigin","creator_url":"https://huggingface.co/waleko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for unarXive-en2ru\\n\\t\\n\\nThis dataset contains text excerpts from the unarXive citation recommendation dataset along with their translations into Russian. The translations have been obtained using OpenAI GPT-3.5-Turbo. The dataset is intended for machine translation research.\\n"},
	{"name":"TOFU","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/locuslab/TOFU","creator_name":"Locus Lab","creator_url":"https://huggingface.co/locuslab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/locuslab/TOFU."},
	{"name":"TOFU","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/locuslab/TOFU","creator_name":"Locus Lab","creator_url":"https://huggingface.co/locuslab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/locuslab/TOFU."},
	{"name":"tamil_stories","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/aitamilnadu/tamil_stories","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\ntamil_stories is an open source dataset of instruct-style records generated by scraping publicly available short stories on the following websites.\\n\\nSiruvarmalar\\nTamilsurangam\\n\\nApart from scraping and automated cleaning, the data was also tagged manually by a group of volunteers. \\nThis dataset created as part of Aya Open Science Initiative by Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/tamil_stories."},
	{"name":"aya_evaluation_suite","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages ‚Üí‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
	{"name":"swim-ir-monolingual","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/swim-ir-monolingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Monolingual)\\n\\t\\n\\n\\n\\n\\nThis is the monolingual subset of the SWIM-IR dataset, where the query generated and the passage are both in the same language.\\nA few remaining languages will be added in the upcoming v2 version of SWIM-IR. The dataset is available as CC-BY-SA 4.0.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-monolingual."},
	{"name":"ru-instruct","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/d0rj/ru-instruct","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t–ö–∞—Ä—Ç–æ—á–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\\n\\t\\n\\n–°–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞ (—Å–ø–∞—Å–∏–±–æ –º–æ–¥–µ–ª–∏ Den4ikAI/nonsense_gibberish_detector). –î–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω SimHash'–æ–º.\\n–û–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –Ω—ë–º –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞ –Ω–µ –∑–∞–≤—ë–∑, in progress.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t–°–æ—Å—Ç–∞–≤\\n\\t\\n\\n–°–æ–±—Ä–∞–ª –∏–∑ —ç—Ç–∏—Ö –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö:\\n\\nd0rj/OpenOrca-ru (–æ—Ç Open-Orca/OpenOrca)\\nd0rj/OpenHermes-2.5-ru (–æ—Ç teknium/OpenHermes-2.5)\\nd0rj/dolphin-ru (–æ—Ç ehartford/dolphin)\\nd0rj/alpaca-cleaned-ru (–æ—Ç‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/ru-instruct."},
	{"name":"MoroccanSocialMedia-MultiGen","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen","creator_name":"MBZUAI France Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MoroccanSocialMedia-MultiGen (MSM-MG)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMoroccanSocialMedia-MultiGen (MSM-MG) is a dataset of 12,973 pairs of native Darija social media posts (tweets and YouTube comments) and their synthetic counterparts. The dataset supports six tasks: Continuation, Reply, Summarization, Rephrasing, Explanation, and Safe Response. The synthetic generations were created by prompting Claude 3.5 Sonnet to perform each of these tasks based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen."},
	{"name":"qe4pe","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gsarti/qe4pe","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"\\n\\t\\n\\t\\t\\n\\t\\tQuality Estimation for Post-Editing (QE4PE)\\n\\t\\n\\nFor more details on QE4PE, see our paper and our Github repository\\nGabriele Sarti ‚Ä¢ Vil√©m Zouhar ‚Ä¢ Grzegorz Chrupa≈Ça ‚Ä¢ Ana Guerberof Arenas ‚Ä¢ Malvina Nissim ‚Ä¢ Arianna Bisazza\\n\\n    \\n\\n\\n\\nWord-level quality estimation (QE) detects erroneous spans in machine translations, which can direct and facilitate human post-editing. While the accuracy of word-level QE systems has been assessed extensively, their usability and downstream influence on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gsarti/qe4pe."},
	{"name":"qe4pe","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gsarti/qe4pe","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"\\n\\t\\n\\t\\t\\n\\t\\tQuality Estimation for Post-Editing (QE4PE)\\n\\t\\n\\nFor more details on QE4PE, see our paper and our Github repository\\nGabriele Sarti ‚Ä¢ Vil√©m Zouhar ‚Ä¢ Grzegorz Chrupa≈Ça ‚Ä¢ Ana Guerberof Arenas ‚Ä¢ Malvina Nissim ‚Ä¢ Arianna Bisazza\\n\\n    \\n\\n\\n\\nWord-level quality estimation (QE) detects erroneous spans in machine translations, which can direct and facilitate human post-editing. While the accuracy of word-level QE systems has been assessed extensively, their usability and downstream influence on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gsarti/qe4pe."},
	{"name":"twinviews-13k","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/wwbrannon/twinviews-13k","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TwinViews-13k\\n\\t\\n\\nThis dataset contains 13,855 pairs of left-leaning and right-leaning political statements matched by topic. The dataset was generated using GPT-3.5 Turbo and has been audited to ensure quality and ideological balance. It is designed to facilitate the study of political bias in reward models and language models, with a focus on the relationship between truthfulness and political views.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/twinviews-13k."},
	{"name":"twinviews-13k","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/wwbrannon/twinviews-13k","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TwinViews-13k\\n\\t\\n\\nThis dataset contains 13,855 pairs of left-leaning and right-leaning political statements matched by topic. The dataset was generated using GPT-3.5 Turbo and has been audited to ensure quality and ideological balance. It is designed to facilitate the study of political bias in reward models and language models, with a focus on the relationship between truthfulness and political views.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/twinviews-13k."},
	{"name":"websim","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/websim","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Websim.ai User Projects\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 137,452 user projects from Websim.ai, a service for creating small sites from a description using Large Language Models (LLMs). The data is stored in JSONL format and includes details about each project, such as project metadata, user information, and the generated HTML content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English, as it contains project‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/websim."},
	{"name":"metallurgy-qa","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Abdulrhman37/metallurgy-qa","creator_name":"Eldeeb","creator_url":"https://huggingface.co/Abdulrhman37","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetallurgy and Materials Science Knowledge Extraction Dataset\\n\\t\\n\\nThis repository contains a dataset generated from parsed books related to various aspects of metallurgy, materials science, and engineering. The dataset is designed for fine-tuning Large Language Models (LLMs) for Question-Answering (QA) tasks in the domain of metallurgy and materials science.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe dataset includes content derived from technical books in the field of metallurgy and materials‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Abdulrhman37/metallurgy-qa."},
	{"name":"metallurgy-qa","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Abdulrhman37/metallurgy-qa","creator_name":"Eldeeb","creator_url":"https://huggingface.co/Abdulrhman37","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetallurgy and Materials Science Knowledge Extraction Dataset\\n\\t\\n\\nThis repository contains a dataset generated from parsed books related to various aspects of metallurgy, materials science, and engineering. The dataset is designed for fine-tuning Large Language Models (LLMs) for Question-Answering (QA) tasks in the domain of metallurgy and materials science.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe dataset includes content derived from technical books in the field of metallurgy and materials‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Abdulrhman37/metallurgy-qa."},
	{"name":"xlam-function-calling-60k-raw-augmented","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw-augmented","creator_name":"Product Science","creator_url":"https://huggingface.co/product-science","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXLAM Function Calling 60k Raw Augmented Dataset\\n\\t\\n\\nThis dataset includes augmented train and test splits derived from product-science/xlam-function-calling-60k-raw.\\n\\nTrain split size: Original size plus augmented data\\nTest split size: Original size plus augmented data\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAugmentation Details\\n\\t\\n\\nThis dataset has been augmented by modifying function names in the original data. Randomly selected function names have underscores replaced with periods at random positions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw-augmented."},
	{"name":"exorde-social-media-one-month-2024","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Exorde/exorde-social-media-one-month-2024","creator_name":"ExordeLabs","creator_url":"https://huggingface.co/Exorde","description":""},
	{"name":"klingai","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/klingai","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KLING AI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 12,782 AI-generated media items (images and videos) created using KLING AI's generative tools. The content includes metadata and original files for various AI generations, encompassing both still images and motion videos created through text-to-image and image-to-video transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en), with prompts and metadata in English.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/klingai."},
	{"name":"begemot","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/begemot","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Begemot.ai\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 2,728,999 educational project descriptions in Russian language generated with neural networks from begemot.ai website. The content includes project titles, descriptions, chapters and chapter content across various educational topics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian (ru).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/begemot."},
	{"name":"emojis","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/emojis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Emojis.com\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata for 3,264,372 AI-generated emoji images from Emojis.com. Each entry represents an emoji with associated metadata including prompt text and image URLs.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nslug: Unique identifier for the emoji (string)\\nid: Internal ID (string) \\nnoBackgroundUrl:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/emojis."},
	{"name":"journals","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/journals","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Historical Russian Technical Journal Images\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains images of pages from old Russian technical journals with descriptions generated using Google Gemini 2.0 Flash.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is monolingual:\\n\\nRussian (ru): All journal pages are in Russian with corresponding Russian descriptions\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Files\\n\\t\\n\\nThe dataset consists of:\\n\\nImage files (.jpg format)\\nCorresponding description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/journals."},
	{"name":"asset","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/asset","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASSET\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASSET (Alva-Manchego et al., 2020) is multi-reference dataset for the evaluation of sentence simplification in English. The dataset uses the same 2,359 sentences from TurkCorpus (Xu et al., 2016) and each sentence is associated with 10 crowdsourced simplifications. Unlike previous simplification datasets, which contain a single transformation (e.g., lexical paraphrasing in TurkCorpus or sentence\\nsplitting in HSplit), the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/asset."},
	{"name":"bbc_hindi_nli","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/midas/bbc_hindi_nli","creator_name":"MIDAS Research Laboratory, IIIT-Delhi","creator_url":"https://huggingface.co/midas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BBC Hindi NLI Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nDataset for Natural Language Inference in Hindi Language. BBC Hindi Dataset consists of textual-entailment pairs.\\nEach row of the Datasets if made up of 4 columns - Premise, Hypothesis, Label and Topic.\\nContext and Hypothesis is written in Hindi while Entailment_Label is in English.\\nEntailment_label is of 2 types - entailed and not-entailed.\\nDataset can be used to train models for Natural Language Inference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/midas/bbc_hindi_nli."},
	{"name":"cs_restaurants","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/community-datasets/cs_restaurants","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Czech Restaurant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a dataset for NLG in task-oriented spoken dialogue systems with Czech as the target language. It originated as a translation of the English San Francisco Restaurants dataset by Wen et al. (2015). The domain is restaurant information in Prague, with random/fictional values. It includes input dialogue acts and the corresponding outputs in Czech.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/cs_restaurants."},
	{"name":"generics_kb","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/community-datasets/generics_kb","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Generics KB\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDataset contains a large (3.5M+ sentence) knowledge base of generic sentences.  This is the first large resource to contain naturally occurring generic sentences, rich in high-quality, general, semantically complete statements. All GenericsKB sentences are annotated with their topical term, surrounding context (sentences), and a (learned) confidence. We also release GenericsKB-Best (1M+ sentences), containing the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/generics_kb."},
	{"name":"kor_nli","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/kakaobrain/kor_nli","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"kor_nli\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKorean Natural Language Inference datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmulti_nli\\n\\t\\n\\n\\nSize of downloaded dataset files: 42.11 MB\\nSize of the generated dataset: 84.72 MB\\nTotal amount of disk used: 126.85 MB\\n\\nAn example of 'train' looks as follows.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/kor_nli."},
	{"name":"swedish_medical_ner","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/community-datasets/swedish_medical_ner","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for swedish_medical_ner\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwedMedNER is Named Entity Recognition dataset on medical text in Swedish. It consists three subsets which are in turn derived from three different sources respectively: the Swedish Wikipedia (a.k.a. wiki), L√§kartidningen (a.k.a. lt), and 1177 V√•rdguiden (a.k.a. 1177). While the Swedish Wikipedia and L√§kartidningen subsets in total contains over 790000 sequences with 60 characters each, the 1177 V√•rdguiden‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/swedish_medical_ner."},
	{"name":"turk","keyword":"machine-generated","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/community-datasets/turk","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TURK\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTURK is a multi-reference dataset for the evaluation of sentence simplification in English. The dataset consists of 2,359 sentences from the Parallel Wikipedia Simplification (PWKP) corpus. Each sentence is associated with 8 crowdsourced simplifications that focus on only lexical paraphrasing (no sentence splitting or deletion).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNo Leaderboard for the task.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/turk."},
	{"name":"xcsr","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for X-CSR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr."},
	{"name":"ik-nlp-22_transqe","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/GroNLP/ik-nlp-22_transqe","creator_name":"GroNLP","creator_url":"https://huggingface.co/GroNLP","description":"The e-SNLI dataset extends the Stanford Natural Language Inference Dataset to\\ninclude human-annotated natural language explanations of the entailment\\nrelations. This version includes an automatic translation to Dutch and two quality estimation annotations\\nfor each translated field."},
	{"name":"carbon_24","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/albertvillanova/carbon_24","creator_name":"Albert Villanova del Moral","creator_url":"https://huggingface.co/albertvillanova","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Carbon-24\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCarbon-24 contains 10k carbon materials, which share the same composition, but have different structures. There is 1 element and the materials have 6 - 24 atoms in the unit cells.\\nCarbon-24 includes various carbon structures obtained via ab initio random structure searching (AIRSS) (Pickard & Needs, 2006; 2011) performed at 10 GPa.\\nThe original dataset includes 101529 carbon structures, and we selected the 10% of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/albertvillanova/carbon_24."},
	{"name":"carbon_24","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/albertvillanova/carbon_24","creator_name":"Albert Villanova del Moral","creator_url":"https://huggingface.co/albertvillanova","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Carbon-24\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCarbon-24 contains 10k carbon materials, which share the same composition, but have different structures. There is 1 element and the materials have 6 - 24 atoms in the unit cells.\\nCarbon-24 includes various carbon structures obtained via ab initio random structure searching (AIRSS) (Pickard & Needs, 2006; 2011) performed at 10 GPa.\\nThe original dataset includes 101529 carbon structures, and we selected the 10% of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/albertvillanova/carbon_24."},
	{"name":"Urban100","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/eugenesiow/Urban100","creator_name":"Eugene Siow","creator_url":"https://huggingface.co/eugenesiow","description":"The Urban100 dataset contains 100 images of urban scenes. \\nIt commonly used as a test set to evaluate the performance of super-resolution models."},
	{"name":"ManyTypes4TypeScript","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript","creator_name":"Kevin Jesse","creator_url":"https://huggingface.co/kevinjesse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels Trained On ManyTypes4TypeScript\\n\\t\\n\\n\\n[CodeBERT](https://huggingface.co/kevinjesse/codebert-MT4TS)\\n[GraphCodeBERT](https://huggingface.co/kevinjesse/graphcodebert-MT4TS)\\n[CodeBERTa](https://huggingface.co/kevinjesse/codeberta-MT4TS)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nManyTypes4TypeScript type inference dataset, available at the DOI link below. \\nGiven a line of source code, the task is to identify types that correspond with the tokens of code. We treat this as a tagging task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript."},
	{"name":"medwiki","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mvarma/medwiki","creator_name":"Maya Varma","creator_url":"https://huggingface.co/mvarma","description":"MedWiki is a large-scale sentence dataset collected from Wikipedia with medical entity (UMLS) annotations. This dataset is intended for pretraining."},
	{"name":"tr-qnli","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nlpyeditepe/tr-qnli","creator_name":"Yeditepe NLP Lab","creator_url":"https://huggingface.co/nlpyeditepe","description":"nlpyeditepe/tr-qnli dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tr_rte","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nlpyeditepe/tr_rte","creator_name":"Yeditepe NLP Lab","creator_url":"https://huggingface.co/nlpyeditepe","description":"nlpyeditepe/tr_rte dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"casum","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/casum","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CaSum\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCaSum is a summarization dataset. It is extracted from a newswire corpus crawled from the Catalan News Agency (Ag√®ncia Catalana de Not√≠cies; ACN). The corpus consists of 217,735 instances that are composed by the headline and the body.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset can be used to train a model for abstractive summarization. Success on this task is typically measured by achieving a high Rouge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/casum."},
	{"name":"Tilde-MODEL-Catalan","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/softcatala/Tilde-MODEL-Catalan","creator_name":"Softcatal√†","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tilde-MODEL-Catalan\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains the German version of the Tilde-MODEL corpus aligned with a Catalan translation.\\nThe catalan text has been obtained using Apertium's RBMT system from the Spanish version. It contains 3.4M segments.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used to train NMT and SMT systems.\\nIt has been used as a training corpus for the Softcatal√† machine translation engine.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/Tilde-MODEL-Catalan."},
	{"name":"lsoie","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/wardenga/lsoie","creator_name":"Robert Wardenga","creator_url":"https://huggingface.co/wardenga","description":"The Large Scale Open Information Extraction Dataset (LSOIE), is a dataset 20 \\ntimes larger than the next largest human-annotated Open Information Extraction\\n(OIE) dataset. LSOIE is a built upon the QA-SRL 2.0 dataset."},
	{"name":"adv_glue","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/AI-Secure/adv_glue","creator_name":"Secure Learning Lab","creator_url":"https://huggingface.co/AI-Secure","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Adversarial GLUE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAdversarial GLUE Benchmark (AdvGLUE) is a comprehensive robustness evaluation benchmark that focuses on the adversarial robustness evaluation of language models. It covers five natural language understanding tasks from the famous GLUE tasks and is an adversarial version of GLUE benchmark.\\nAdvGLUE considers textual adversarial attacks from different perspectives and hierarchies, including word-level transformations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-Secure/adv_glue."},
	{"name":"pesp","keyword":"machine-generated","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/apjanco/pesp","creator_name":"Andy Janco","creator_url":"https://huggingface.co/apjanco","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPages of Early Soviet Performance (PESP)\\n\\t\\n\\nThis dataset was created as part of the Pages of Early Soviet Performance project at Princeton and provides text and image research data from a previously scanned collection of illustrated periodicals held by Princeton University's Slavic Collections. The project was a partnership with ITMO University in Saint Petersburg. Our work focused on document segmentation and the prediction of image, text, title, and mixedtext regions in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/apjanco/pesp."},
	{"name":"indicxnli","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Divyanshu/indicxnli","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\\nto predict textual entailment (does sentence A imply/contradict/neither sentence\\nB) and is a classification task (given two sentences, predict one of three\\nlabels)."},
	{"name":"indicxnli","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Divyanshu/indicxnli","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\\nto predict textual entailment (does sentence A imply/contradict/neither sentence\\nB) and is a classification task (given two sentences, predict one of three\\nlabels)."},
	{"name":"bigscience-lama","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/janck/bigscience-lama","creator_name":"Jan-Christoph Kalo","creator_url":"https://huggingface.co/janck","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LAMA: LAnguage Model Analysis - a dataset for probing and analyzing the factual and commonsense knowledge contained in pretrained language models.\\n\\t\\n\\n@inproceedings{petroni2020how,\\n  title={How Context Affects Language Models' Factual Predictions},\\n  author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\\\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},\\n  booktitle={Automated Knowledge Base Construction},\\n  year={2020}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/janck/bigscience-lama."},
	{"name":"bigscience-lama","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/janck/bigscience-lama","creator_name":"Jan-Christoph Kalo","creator_url":"https://huggingface.co/janck","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LAMA: LAnguage Model Analysis - a dataset for probing and analyzing the factual and commonsense knowledge contained in pretrained language models.\\n\\t\\n\\n@inproceedings{petroni2020how,\\n  title={How Context Affects Language Models' Factual Predictions},\\n  author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\\\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},\\n  booktitle={Automated Knowledge Base Construction},\\n  year={2020}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/janck/bigscience-lama."},
	{"name":"twitter_pos_vcb","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/strombergnlp/twitter_pos_vcb","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"Part-of-speech information is basic NLP task. However, Twitter text\\nis difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style.\\nThis data is the vote-constrained bootstrapped data generate to support state-of-the-art results.\\n\\nThe data is about 1.5 million English tweets annotated for part-of-speech using Ritter's extension of the PTB tagset.\\nThe tweets are from 2012 and 2013, tokenized using the GATE tokenizer and tagged\\njointly using the CMU ARK tagger and Ritter's T-POS tagger. Only when both these taggers' outputs\\nare completely compatible over a whole tweet, is that tweet added to the dataset.\\n\\nThis data is recommend for use a training data **only**, and not evaluation data.\\n\\nFor more details see https://gate.ac.uk/wiki/twitter-postagger.html and https://aclanthology.org/R13-1026.pdf"},
	{"name":"wit_base","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
	{"name":"QA2D","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/domenicrosati/QA2D","creator_name":"Domenic Rosati","creator_url":"https://huggingface.co/domenicrosati","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QA2D\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nExisting datasets for natural language inference (NLI) have propelled research on language understanding. We propose a new method for automatically deriving NLI datasets from the growing abundance of large-scale question answering datasets. Our approach hinges on learning a sentence transformation model which converts question-answer pairs into their declarative forms. Despite being primarily trained on a single QA dataset, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domenicrosati/QA2D."},
	{"name":"QA2D","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/domenicrosati/QA2D","creator_name":"Domenic Rosati","creator_url":"https://huggingface.co/domenicrosati","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QA2D\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nExisting datasets for natural language inference (NLI) have propelled research on language understanding. We propose a new method for automatically deriving NLI datasets from the growing abundance of large-scale question answering datasets. Our approach hinges on learning a sentence transformation model which converts question-answer pairs into their declarative forms. Despite being primarily trained on a single QA dataset, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domenicrosati/QA2D."},
	{"name":"divemt","keyword":"machine-generated","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/GroNLP/divemt","creator_name":"GroNLP","creator_url":"https://huggingface.co/GroNLP","description":"DivEMT is the first publicly available post-editing study of Neural Machine Translation (NMT) over a typologically diverse set of target languages. Using a strictly controlled setup, 18 professional translators were instructed to translate or post-edit the same set of English documents into Arabic, Dutch, Italian, Turkish, Ukrainian, and Vietnamese. During the process, their edits, keystrokes, editing times, pauses, and perceived effort were logged, enabling an in-depth, cross-lingual evaluation of NMT quality and its post-editing process."},
	{"name":"machine_translated_cnn_dailymail_da_small","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ajders/machine_translated_cnn_dailymail_da_small","creator_name":"Anders Jess Pedersen","creator_url":"https://huggingface.co/ajders","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for machine_translated_cnn_dailymail_da_small\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a machine translated subset of the CNN Dailymail Dataset into Danish. The dataset is translated using the Helsinki-NLP/opus-mt-en-da-model. The dataset consists of 2872 articles with summaries with intended usage for Danish text summarisation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nMachine translated articles (article) with corresponding summaries (highlights).\\n{\\n  'article':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajders/machine_translated_cnn_dailymail_da_small."},
	{"name":"machine_translated_cnn_dailymail_da_small","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ajders/machine_translated_cnn_dailymail_da_small","creator_name":"Anders Jess Pedersen","creator_url":"https://huggingface.co/ajders","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for machine_translated_cnn_dailymail_da_small\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a machine translated subset of the CNN Dailymail Dataset into Danish. The dataset is translated using the Helsinki-NLP/opus-mt-en-da-model. The dataset consists of 2872 articles with summaries with intended usage for Danish text summarisation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nMachine translated articles (article) with corresponding summaries (highlights).\\n{\\n  'article':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajders/machine_translated_cnn_dailymail_da_small."},
	{"name":"ru_paraphraser","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/merionum/ru_paraphraser","creator_name":"Vadim Gudkov","creator_url":"https://huggingface.co/merionum","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ParaPhraser\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParaPhraser is a news headlines corpus annotated according to the following schema:\\n1: precise paraphrases\\n0: near paraphrases\\n-1: non-paraphrases\\n\\nThe Plus part is also available.\\nIt contains clusters of news headline paraphrases labeled automatically by a fine-tuned paraphrase detection BERT model.In order to load it:\\nfrom datasets import load_dataset\\n\\ncorpus = load_dataset('merionum/ru_paraphraser'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/merionum/ru_paraphraser."},
	{"name":"wikitext_linked","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/DFKI-SLT/wikitext_linked","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","description":" The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\\n Good and Featured articles on Wikipedia. Dependency Relations, POS, NER tags are marked with trankit and\\n entities are linked with entity-fishing.\\n The dataset is available under the Creative Commons Attribution-ShareAlike License."},
	{"name":"wikitext_linked","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/DFKI-SLT/wikitext_linked","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","description":" The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\\n Good and Featured articles on Wikipedia. Dependency Relations, POS, NER tags are marked with trankit and\\n entities are linked with entity-fishing.\\n The dataset is available under the Creative Commons Attribution-ShareAlike License."},
	{"name":"askD","keyword":"machine-generated","license":"GNU Lesser General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/ju-resplande/askD","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\\\\\\r\\n#TODO: description"},
	{"name":"hmd-erwt-training","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Livingwithmachines/hmd-erwt-training","creator_name":"Living with Machines","creator_url":"https://huggingface.co/Livingwithmachines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ERWT Hertiage Made Digital Newspapers training data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains text extracted at the page level from historic digitised newspapers from the Heritage Made Digital newspaper digitisation program. The newspapers in the dataset were published between 1800 and 1870.\\nThe data was primarily created as a dataset for training 'time-aware' language models.\\nThe dataset contains text generated from Optical Character Recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Livingwithmachines/hmd-erwt-training."},
	{"name":"FLUTE","keyword":"machine-generated","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/ColumbiaNLP/FLUTE","creator_name":"Columbia University NLP Group","creator_url":"https://huggingface.co/ColumbiaNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FigLang2022SharedTask\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nModel in the loop approach for fig lang generation and explainability\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInitial Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ColumbiaNLP/FLUTE."},
	{"name":"cultural_heritage_metadata_accuracy","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotated dataset to assess the accuracy of the textual description of cultural heritage records\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset contains more than 100K textual descriptions of cultural items from Cultura Italia, the Italian National Cultural aggregator. Each of the description is labeled either HIGH or LOW quality, according its adherence to the standard cataloguing guidelines provided by Istituto Centrale per il Catalogo e la Documentazione (ICCD).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy."},
	{"name":"atypical_animacy","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/biglam/atypical_animacy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for atypical_animacy\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAtypical animacy detection dataset, based on nineteenth-century sentences in English extracted from an open dataset of nineteenth-century books digitized by the British Library. This dataset contains 598 sentences containing mentions of machines. Each sentence has been annotated according to the animacy and humanness of the machine in the sentence. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/atypical_animacy."},
	{"name":"wino_x","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/demelin/wino_x","creator_name":"Denis Emelin","creator_url":"https://huggingface.co/demelin","description":"Wino-X is a parallel dataset of German, French, and Russian Winograd schemas, aligned with their English \\ncounterparts, used to examine whether neural machine translation models can perform coreference resolution that \\nrequires commonsense knowledge and whether multilingual language models are capable of commonsense reasoning across \\nmultiple languages."},
	{"name":"old_bailey_proceedings","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/biglam/old_bailey_proceedings","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Old Bailey Proceedings\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nNote We are making this dataset available via the HuggingFace hub to open it up to more users and use cases. We have focused primarily on making an initial version of this dataset available, focusing on some potential use cases. If you think there are other configurations this dataset should support, please use the community tab to open an issue. \\nThe dataset consists of 2,163‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/old_bailey_proceedings."},
	{"name":"clmet_3_1","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/biglam/clmet_3_1","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"The Corpus of Late Modern English Texts, version 3.1 (CLMET3.1) has been created by Hendrik De Smet, \\nSusanne Flach, Hans-J√ºrgen Diller and Jukka Tyrkk√∂, as an offshoot of a bigger project developing a database of text \\ndescriptors (Diller, De Smet & Tyrkk√∂ 2011). CLMET3.1 is a principled collection of public domain texts drawn from \\nvarious online archiving projects. This dataset can be used for part-of-speech tagging, NER and text classification"},
	{"name":"ShahNegar","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sadrasabouri/ShahNegar","creator_name":"Sadra Sabouri","creator_url":"https://huggingface.co/sadrasabouri","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShahNegar (A Plotted version of The Shahnameh)\\n\\t\\n\\nThis dataset is a plotted version of Ferdowsi's Shahnameh (which is a highly-regarded ancient set of Farsi poems) generated using DALL-E mini (aka craiyon). You can use this dataset using the code below: \\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"sadrasabouri/ShahNegar\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains more than 30K images with their corresponding text from the Shahnameh. For each Shahnameh‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sadrasabouri/ShahNegar."},
	{"name":"sbb-dc-ocr","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/SBB/sbb-dc-ocr","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Berlin State Library OCR data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nThe digital collections of the SBB contain 153,942 digitized works from the time period of 1470 to 1945.\\n\\n\\nAt the time of publication, 28,909 works have been OCR-processed resulting in 4,988,099 full-text pages.\\nFor each page with OCR text, the language has been determined by langid (Lui/Baldwin 2012).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nlanguage-modeling: this dataset has the potential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/sbb-dc-ocr."},
	{"name":"inglish","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jakartaresearch/inglish","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for beginner to make a translation model for Indonesian and English."},
	{"name":"inglish","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jakartaresearch/inglish","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for beginner to make a translation model for Indonesian and English."},
	{"name":"EstCOPA","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tartuNLP/EstCOPA","creator_name":"TartuNLP","creator_url":"https://huggingface.co/tartuNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EstCOPA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEstCOPA is an extended version of XCOPA that was created with a goal to further investigate Estonian language understanding of large language models. EstCOPA provides two new versions of train, eval and test datasets in Estonian: firstly, a machine translated (En->Et) version of original English COPA (Roemmele et al., 2011)  and secondly, a manually post-edited version of the same machine translated data.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tartuNLP/EstCOPA."},
	{"name":"myv_ru_2022","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/slone/myv_ru_2022","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for slone/myv_ru_2022\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a corpus of parallel Erzya-Russian words, phrases and sentences, collected in the paper The first neural machine translation system for the Erzya language.\\nErzya (myv) is a language from the Uralic family. It is spoken primarily in the Republic of Mordovia and some other regions of Russia and other post-Soviet countries. We use the Cyrillic version of its script. \\nThe corpus consists of the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slone/myv_ru_2022."},
	{"name":"myv_ru_2022","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/slone/myv_ru_2022","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for slone/myv_ru_2022\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a corpus of parallel Erzya-Russian words, phrases and sentences, collected in the paper The first neural machine translation system for the Erzya language.\\nErzya (myv) is a language from the Uralic family. It is spoken primarily in the Republic of Mordovia and some other regions of Russia and other post-Soviet countries. We use the Cyrillic version of its script. \\nThe corpus consists of the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slone/myv_ru_2022."},
	{"name":"nouns","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/m1guelpf/nouns","creator_name":"Miguel Piedrafita","creator_url":"https://huggingface.co/m1guelpf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Nouns auto-captioned\\n\\t\\n\\nDataset used to train Nouns text to image model\\nAutomatically generated captions for Nouns from their attributes, colors and items. Help on the captioning script appreciated!\\nFor each row the dataset contains image and text keys. image is a varying size PIL jpeg, and text is the accompanying text caption. Only a train split is provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use this dataset, please cite it as:\\n@misc{piedrafita2022nouns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m1guelpf/nouns."},
	{"name":"IE_SemParse","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Divyanshu/IE_SemParse","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"    IE-SemParse is an Inter-bilingual Seq2seq Semantic parsing dataset for 11 distinct Indian languages"},
	{"name":"IE_SemParse","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Divyanshu/IE_SemParse","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"    IE-SemParse is an Inter-bilingual Seq2seq Semantic parsing dataset for 11 distinct Indian languages"},
	{"name":"unlabelled_IA_with_snorkel_labels","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/ImageIN/unlabelled_IA_with_snorkel_labels","creator_name":"ImageIN","creator_url":"https://huggingface.co/ImageIN","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHistoric book pages illustration weak annotations\\n\\t\\n\\n"},
	{"name":"skateboarding-tricks","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vogloblinsky/skateboarding-tricks","creator_name":"Ogloblinsky","creator_url":"https://huggingface.co/vogloblinsky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Skateboarding tricks\\n\\t\\n\\nDataset used to train Text to skateboarding image model.\\nFor each row the dataset contains image and text keys.\\nimage is a varying size PIL jpeg, and text is the accompanying text caption.\\n"},
	{"name":"playing-cards","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JackFurby/playing-cards","creator_name":"Jack","creator_url":"https://huggingface.co/JackFurby","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Playing cards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA dataset containing four sets of playing card images. Each set contains 10,000 images and has a series of attributes. Cards are randomly rotated, flipped and scaled (within limits).\\nTrain and test splits are provided in both JSON and pickle formats. Concept and task classification labels (both zero indexed) and names are provided in txt files.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackFurby/playing-cards."},
	{"name":"playing-cards","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JackFurby/playing-cards","creator_name":"Jack","creator_url":"https://huggingface.co/JackFurby","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Playing cards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA dataset containing four sets of playing card images. Each set contains 10,000 images and has a series of attributes. Cards are randomly rotated, flipped and scaled (within limits).\\nTrain and test splits are provided in both JSON and pickle formats. Concept and task classification labels (both zero indexed) and names are provided in txt files.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackFurby/playing-cards."},
	{"name":"slo_thesaurus","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cjvt/slo_thesaurus","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"This is an automatically created Slovene thesaurus from Slovene data available in a comprehensive \\nEnglish‚ÄìSlovenian dictionary, a monolingual dictionary, and a corpus. A network analysis on the bilingual dictionary \\nword co-occurrence graph was used, together with additional information from the distributional thesaurus data \\navailable as part of the Sketch Engine tool and extracted from the 1.2 billion word Gigafida corpus and the \\nmonolingual dictionary."},
	{"name":"slo_thesaurus","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cjvt/slo_thesaurus","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"This is an automatically created Slovene thesaurus from Slovene data available in a comprehensive \\nEnglish‚ÄìSlovenian dictionary, a monolingual dictionary, and a corpus. A network analysis on the bilingual dictionary \\nword co-occurrence graph was used, together with additional information from the distributional thesaurus data \\navailable as part of the Sketch Engine tool and extracted from the 1.2 billion word Gigafida corpus and the \\nmonolingual dictionary."},
	{"name":"slownet","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cjvt/slownet","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"sloWNet is the Slovene WordNet developed in the expand approach: it contains the complete Princeton WordNet 3.0 and \\nover 70 000 Slovene literals. These literals have been added automatically using different types of existing resources, \\nsuch as bilingual dictionaries, parallel corpora and Wikipedia. 33 000 literals have been subsequently hand-validated."},
	{"name":"slownet","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cjvt/slownet","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"sloWNet is the Slovene WordNet developed in the expand approach: it contains the complete Princeton WordNet 3.0 and \\nover 70 000 Slovene literals. These literals have been added automatically using different types of existing resources, \\nsuch as bilingual dictionaries, parallel corpora and Wikipedia. 33 000 literals have been subsequently hand-validated."},
	{"name":"spiced","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/copenlu/spiced","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SPICED\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Scientific Paraphrase and Information ChangE Dataset (SPICED) is a dataset of paired scientific findings from scientific papers, news media, and Twitter. The types of pairs are between <paper, news> and <paper, tweet>. Each pair is labeled for the degree of information similarity in the findings described by each sentence, on a scale from 1-5. This is called the Information Matching Score (IMS). The data was curated from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spiced."},
	{"name":"codeparrot-train-more-filter-3.3b-cleaned","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kejian/codeparrot-train-more-filter-3.3b-cleaned","creator_name":"Kejian Shi","creator_url":"https://huggingface.co/kejian","description":"kejian/codeparrot-train-more-filter-3.3b-cleaned dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"machine-paraphrase-dataset","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Machine Paraphrase Dataset (MPC)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Machine Paraphrase Corpus (MPC) consists of ~200k examples of original, and paraphrases using two online paraphrasing tools.\\nIt uses two paraphrasing tools (SpinnerChief, SpinBot) on three source texts (Wikipedia, arXiv, student theses).\\nThe examples are not aligned, i.e., we sample different paragraphs for originals and paraphrased versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\nYou can load the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset."},
	{"name":"machine-paraphrase-dataset","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Machine Paraphrase Dataset (MPC)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Machine Paraphrase Corpus (MPC) consists of ~200k examples of original, and paraphrases using two online paraphrasing tools.\\nIt uses two paraphrasing tools (SpinnerChief, SpinBot) on three source texts (Wikipedia, arXiv, student theses).\\nThe examples are not aligned, i.e., we sample different paragraphs for originals and paraphrased versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\nYou can load the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset."},
	{"name":"autoencoder-paraphrase-dataset","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Machine Paraphrase Dataset (MPC)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Autoencoder Paraphrase Corpus (APC) consists of ~200k examples of original, and paraphrases using three neural language models.\\nIt uses three models (BERT, RoBERTa, Longformer) on three source texts (Wikipedia, arXiv, student theses).\\nThe examples are aligned, i.e., we sample the same paragraphs for originals and paraphrased versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\nYou can load the dataset using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset."},
	{"name":"autoencoder-paraphrase-dataset","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Machine Paraphrase Dataset (MPC)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Autoencoder Paraphrase Corpus (APC) consists of ~200k examples of original, and paraphrases using three neural language models.\\nIt uses three models (BERT, RoBERTa, Longformer) on three source texts (Wikipedia, arXiv, student theses).\\nThe examples are aligned, i.e., we sample the same paragraphs for originals and paraphrased versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\nYou can load the dataset using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset."},
	{"name":"autoregressive-paraphrase-dataset","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset."},
	{"name":"autoregressive-paraphrase-dataset","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset."},
	{"name":"idk-mrc","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/rifkiaputri/idk-mrc","creator_name":"Rifki Afina Putri","creator_url":"https://huggingface.co/rifkiaputri","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for IDK-MRC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nI(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers answerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA, the new unanswerable question in IDK-MRC is generated using a question generation model and human-written question. Each paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rifkiaputri/idk-mrc."},
	{"name":"idk-mrc","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/rifkiaputri/idk-mrc","creator_name":"Rifki Afina Putri","creator_url":"https://huggingface.co/rifkiaputri","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for IDK-MRC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nI(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers answerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA, the new unanswerable question in IDK-MRC is generated using a question generation model and human-written question. Each paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rifkiaputri/idk-mrc."},
	{"name":"YannicKilcher-apes","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dn-gh/YannicKilcher-apes","creator_name":"Danial Gharaie","creator_url":"https://huggingface.co/dn-gh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"YannicKilcher-apes\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"raddromur_asr","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for raddromur_asr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Raddr√≥mur Icelandic Speech 22.09\\\" (\\\"Raddr√≥mur Corpus\\\" for short) is an Icelandic corpus created by the Language and Voice Laboratory (LVL) at Reykjav√≠k University (RU) in 2022. It is made out of radio podcasts mostly taken from R√öV (ruv.is).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample Usage\\n\\t\\n\\nThe Raddr√≥mur Corpus counts with the train split only. To load the training split pass its name as a config name:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr."},
	{"name":"raddromur_asr","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for raddromur_asr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Raddr√≥mur Icelandic Speech 22.09\\\" (\\\"Raddr√≥mur Corpus\\\" for short) is an Icelandic corpus created by the Language and Voice Laboratory (LVL) at Reykjav√≠k University (RU) in 2022. It is made out of radio podcasts mostly taken from R√öV (ruv.is).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample Usage\\n\\t\\n\\nThe Raddr√≥mur Corpus counts with the train split only. To load the training split pass its name as a config name:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr."},
	{"name":"wave-energy","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cmudrc/wave-energy","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","description":"cmudrc/wave-energy dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"DocBank","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maveriq/DocBank","creator_name":"Haris Jabbar","creator_url":"https://huggingface.co/maveriq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DocBank\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDocBank is a new large-scale dataset that is constructed using a weak supervision approach. It enables models to integrate both the textual and layout information for downstream tasks. The current DocBank dataset totally includes 500K document pages, where 400K for training, 50K for validation and 50K for testing.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nDocument AI (text and layout)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maveriq/DocBank."},
	{"name":"DocBank","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maveriq/DocBank","creator_name":"Haris Jabbar","creator_url":"https://huggingface.co/maveriq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DocBank\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDocBank is a new large-scale dataset that is constructed using a weak supervision approach. It enables models to integrate both the textual and layout information for downstream tasks. The current DocBank dataset totally includes 500K document pages, where 400K for training, 50K for validation and 50K for testing.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nDocument AI (text and layout)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maveriq/DocBank."},
	{"name":"bace_regression","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/bace_regression","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bace_regression\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbace_regression is a dataset included in MoleculeNet. This dataset consists of  Quantitative (IC50) binding results for a set of inhibitors of human Œ≤-secretase 1(BACE-1).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: the IC50 binding results\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_regression."},
	{"name":"bace_regression","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/bace_regression","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bace_regression\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbace_regression is a dataset included in MoleculeNet. This dataset consists of  Quantitative (IC50) binding results for a set of inhibitors of human Œ≤-secretase 1(BACE-1).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: the IC50 binding results\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_regression."},
	{"name":"bace_classification","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/bace_classification","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bace_classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbace_classification is a dataset included in MoleculeNet. This dataset consists of qualitative (binary label) binding binding results for a set of inhibitors of human Œ≤-secretase 1(BACE-1).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: the binary label binding results‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_classification."},
	{"name":"bace_classification","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/bace_classification","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bace_classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbace_classification is a dataset included in MoleculeNet. This dataset consists of qualitative (binary label) binding binding results for a set of inhibitors of human Œ≤-secretase 1(BACE-1).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: the binary label binding results‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_classification."},
	{"name":"pcba_686978","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/pcba_686978","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pcba_686978\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\npcba_686978 is a dataset included in MoleculeNet. PubChem BioAssay (PCBA) is a database consisting of biological activities of small molecules generated by high-throughput screening. We have chosen one of the larger tasks (ID 686978) as described in https://par.nsf.gov/servlets/purl/10168888.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/pcba_686978."},
	{"name":"pcba_686978","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/pcba_686978","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pcba_686978\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\npcba_686978 is a dataset included in MoleculeNet. PubChem BioAssay (PCBA) is a database consisting of biological activities of small molecules generated by high-throughput screening. We have chosen one of the larger tasks (ID 686978) as described in https://par.nsf.gov/servlets/purl/10168888.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/pcba_686978."},
	{"name":"tweetyface_debug","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ML-Projects-Kiel/tweetyface_debug","creator_name":"Machine Learning Projects FH Kiel","creator_url":"https://huggingface.co/ML-Projects-Kiel","description":"DEBUG DATASET"},
	{"name":"stackoverflow-questions-2016","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pacovaldez/stackoverflow-questions-2016","creator_name":"Paco Valdez","creator_url":"https://huggingface.co/pacovaldez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Stackoverflow Post Questions]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCompanies that sell Open-source software tools usually hire an army of Customer representatives to try to answer every question asked about their tool. The first step in this process \\nis the prioritization of the question. The classification scale usually consists of 4 values, P0, P1, P2, and P3, with different meanings across every participant in the industry. On \\nthe other hand, every software‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacovaldez/stackoverflow-questions-2016."},
	{"name":"nailbiting_classification","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/alecsharpie/nailbiting_classification","creator_name":"Alec Sharp","creator_url":"https://huggingface.co/alecsharpie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Nail Biting Classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA binary image dataset for classifying nailbiting. Images are cropped to only show the mouth area.\\nShould contain edge cases such as drinking water, talking on the phone, scratching chin etc.. all in \\\"no biting\\\" category\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n7147 Images\\n14879790 bytes total\\n12332617 bytes download\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n128 x 64 (w x h, pixels)\\nBlack and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alecsharpie/nailbiting_classification."},
	{"name":"delaney","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/delaney","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for delaney\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\ndelaney (aka. ESOL) is a dataset included in MoleculeNet. Water solubility data(log solubility in mols per litre) for common organic small molecules.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: log solubility in mols per litre\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/delaney."},
	{"name":"delaney","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/delaney","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for delaney\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\ndelaney (aka. ESOL) is a dataset included in MoleculeNet. Water solubility data(log solubility in mols per litre) for common organic small molecules.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: log solubility in mols per litre\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/delaney."},
	{"name":"clearance","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/clearance","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for clearance\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nclearance is a dataset included in Chemberta-2 benchmarking. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget:\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an 80/10/10 train/valid/test split using scaffold split. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInitial Data Collection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clearance."},
	{"name":"clearance","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/clearance","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for clearance\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nclearance is a dataset included in Chemberta-2 benchmarking. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget:\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an 80/10/10 train/valid/test split using scaffold split. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInitial Data Collection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clearance."},
	{"name":"lipo","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/lipo","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for lipo\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nlipo is a dataset included in MoleculeNet. It measures the experimental results of octanol/water distribution coefficient(logD at pH 7.4)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: octanol/water distribution coefficient(logD at pH 7.4)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/lipo."},
	{"name":"lipo","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/lipo","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for lipo\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nlipo is a dataset included in MoleculeNet. It measures the experimental results of octanol/water distribution coefficient(logD at pH 7.4)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: octanol/water distribution coefficient(logD at pH 7.4)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/lipo."},
	{"name":"bbbp","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/bbbp","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bbbp\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbbbp is a dataset included in MoleculeNet. This dataset has binary labels of blood-brain barrier penetration(permeability).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: blood-brain barrier penetration(permeability)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an 80/10/10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bbbp."},
	{"name":"bbbp","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/bbbp","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bbbp\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbbbp is a dataset included in MoleculeNet. This dataset has binary labels of blood-brain barrier penetration(permeability).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: blood-brain barrier penetration(permeability)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an 80/10/10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bbbp."},
	{"name":"model-written-evals","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Anthropic/model-written-evals","creator_name":"Anthropic","creator_url":"https://huggingface.co/Anthropic","description":"\\n\\t\\n\\t\\t\\n\\t\\tModel-Written Evaluation Datasets\\n\\t\\n\\nThis repository includes datasets written by language models, used in our paper on \\\"Discovering Language Model Behaviors with Model-Written Evaluations.\\\"\\nWe intend the datasets to be useful to:\\n\\nThose who are interested in understanding the quality and properties of model-generated data\\nThose who wish to use our datasets to evaluate other models for the behaviors we examined in our work (e.g., related to model persona, sycophancy, advanced AI risks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anthropic/model-written-evals."},
	{"name":"model-written-evals","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Anthropic/model-written-evals","creator_name":"Anthropic","creator_url":"https://huggingface.co/Anthropic","description":"\\n\\t\\n\\t\\t\\n\\t\\tModel-Written Evaluation Datasets\\n\\t\\n\\nThis repository includes datasets written by language models, used in our paper on \\\"Discovering Language Model Behaviors with Model-Written Evaluations.\\\"\\nWe intend the datasets to be useful to:\\n\\nThose who are interested in understanding the quality and properties of model-generated data\\nThose who wish to use our datasets to evaluate other models for the behaviors we examined in our work (e.g., related to model persona, sycophancy, advanced AI risks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anthropic/model-written-evals."},
	{"name":"tox21_srp53","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/tox21_srp53","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tox21_srp53\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\ntox21_srp53 is a dataset included in MoleculeNet. It is the p53 stress-response pathway activation (SR-p53) task from Tox21.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: clinical trial toxicity (or absence of toxicity)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/tox21_srp53."},
	{"name":"tox21_srp53","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zpn/tox21_srp53","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tox21_srp53\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\ntox21_srp53 is a dataset included in MoleculeNet. It is the p53 stress-response pathway activation (SR-p53) task from Tox21.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: clinical trial toxicity (or absence of toxicity)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/tox21_srp53."},
	{"name":"golf-courses","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bethecloud/golf-courses","creator_name":"Kevin Leffew (GTM @ Replit)","creator_url":"https://huggingface.co/bethecloud","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary: golf-course\\n\\t\\n\\nThis dataset (bethecloud/golf-courses) includes 21 unique images of golf courses pulled from Unsplash.  \\nThe dataset is a collection of photographs taken at various golf courses around the world. The images depict a variety of scenes, including fairways, greens, bunkers, water hazards, and clubhouse facilities. The images are high resolution and have been carefully selected to provide a diverse range of visual content for fine-tuning a machine‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bethecloud/golf-courses."},
	{"name":"stock11","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kuroneko5943/stock11","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"naamapadam","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/ai4bharat/naamapadam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":""},
	{"name":"naamapadam","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/ai4bharat/naamapadam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":""},
	{"name":"fake_railroad_company","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidwisdom/fake_railroad_company","creator_name":"David Wisdom","creator_url":"https://huggingface.co/davidwisdom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfake_railroad_company\\n\\t\\n\\nThis is toy data I created about an imaginary railroad company.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV1\\n\\t\\n\\nThis is the first version of the data that I generated.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV2\\n\\t\\n\\nI tweaked some of the weights I used to calculate the satisfaction score.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV3\\n\\t\\n\\nSome customers are now power users who ride more often than other users.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV4\\n\\t\\n\\nCustomers with children are more likely to be members\\n"},
	{"name":"fake_railroad_company","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidwisdom/fake_railroad_company","creator_name":"David Wisdom","creator_url":"https://huggingface.co/davidwisdom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfake_railroad_company\\n\\t\\n\\nThis is toy data I created about an imaginary railroad company.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV1\\n\\t\\n\\nThis is the first version of the data that I generated.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV2\\n\\t\\n\\nI tweaked some of the weights I used to calculate the satisfaction score.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV3\\n\\t\\n\\nSome customers are now power users who ride more often than other users.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV4\\n\\t\\n\\nCustomers with children are more likely to be members\\n"},
	{"name":"divemt_attributions","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/inseq/divemt_attributions","creator_name":"Inseq","creator_url":"https://huggingface.co/inseq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DivEMT Attributions\\n\\t\\n\\nFor more details on DivEMT, see our EMNLP 2022 Paper and our Github repository\\n"},
	{"name":"pile-detoxify","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/tomekkorbak/pile-detoxify","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pile-pii-scrubadub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains text from The Pile, annotated based on the toxicity of each sentence.\\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the toxicity predicted by the Detoxify.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is taken from The Pile, which is English text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-detoxify."},
	{"name":"pile-pii-scrubadub","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pile-pii-scrubadub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains text from The Pile, annotated based on the personal idenfitiable information (PII) in each sentence.\\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the percentage of words in it that are classified as PII by Scrubadub.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is taken‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub."},
	{"name":"bioleaflets-biomedical-ner","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ruslan/bioleaflets-biomedical-ner","creator_name":"Ruslan Yermak","creator_url":"https://huggingface.co/ruslan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BioLeaflets Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBioLeaflets is a biomedical dataset for Data2Text generation. It is a corpus of 1,336 package leaflets of medicines authorised in Europe, which were obtained by scraping the European Medicines Agency (EMA) website. \\nPackage leaflets are included in the packaging of medicinal products and contain information to help patients use the product safely and appropriately. \\nThis dataset comprises the large majority (‚àº‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruslan/bioleaflets-biomedical-ner."},
	{"name":"soda_synthetic_dialogue","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/emozilla/soda_synthetic_dialogue","creator_name":"Jeffrey Quesnelle","creator_url":"https://huggingface.co/emozilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ü•§SODA Synthetic Dialogue\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nü•§SODA Synthetic Dialogue is a set of synthetic dialogues between Assistant and\\nUser. In each conversation, User asks Assistant to perform summarization or\\nstory generation tasks based on a snippet of an existing dialogue, story, or\\nfrom a title or theme.\\nThis data was created by synthesizing the dialogues in\\nü•§Soda and applying a set of\\ntemplates to generate the conversation. The original research paper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emozilla/soda_synthetic_dialogue."},
	{"name":"swiss_doc2doc_ir","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_doc2doc_ir","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"https://huggingface.co/spaces/huggingface/datasets-tagging\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Swiss Doc2doc Information Retrieval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwiss Doc2doc Information Retrieval is a multilingual, diachronic dataset of 131K Swiss Federal Supreme Court (FSCS) cases annotated with law citations and ruling citations, posing a challenging text classification task. As unique label we are using decision_id of cited rulings and uuid of cited law articles, which can be found in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rcds/swiss_doc2doc_ir."},
	{"name":"comps","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kanishka/comps","creator_name":"Kanishka Misra","creator_url":"https://huggingface.co/kanishka","description":"COMPS is a dataset of minimal pair sentences in English that enables the \\ntesting knowledge of concepts and their properties in language models (LMs).\\nSpecifically, it tests the ability of LMs to attribute properties to everyday \\nconcepts, and demonstrate reasoning compatible with property inheritance, where\\nsubordinate concepts inherit the properties of their superordinate (hypernyms)."},
	{"name":"fashion_mnist_ambiguous","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mweiss/fashion_mnist_ambiguous","creator_name":"Michael Weiss","creator_url":"https://huggingface.co/mweiss","description":"The images were created such that they have an unclear ground truth, \\ni.e., such that they are similar to multiple - but not all - of the datasets classes.\\nRobust and uncertainty-aware models should be able to detect and flag these ambiguous images.\\nAs such, the dataset should be merged / mixed with the original dataset and we\\nprovide such 'mixed' splits for convenience. Please refer to the dataset card for details."},
	{"name":"Fact-Completion","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\nHomepage: https://bit.ly/ischool-berkeley-capstone\\nRepository: https://github.com/daniel-furman/Capstone\\nPoint of Contact: daniel_furman@berkeley.edu\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTest Description\\n\\t\\n\\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \\\"knows\\\" this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion."},
	{"name":"unarXive_imrad_clf","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/saier/unarXive_imrad_clf","creator_name":"Tarek Saier","creator_url":"https://huggingface.co/saier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for unarXive IMRaD classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe unarXive IMRaD classification dataset contains 530k paragraphs from computer science papers and the IMRaD section they originate from. The paragraphs are derived from unarXive.\\nThe dataset can be used as follows.\\nfrom datasets import load_dataset\\n\\nimrad_data = load_dataset('saier/unarXive_imrad_clf')\\nimrad_data = imrad_data.class_encode_column('label')  # assign target label column\\nimrad_data =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saier/unarXive_imrad_clf."},
	{"name":"unarXive_citrec","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/saier/unarXive_citrec","creator_name":"Tarek Saier","creator_url":"https://huggingface.co/saier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for unarXive citation recommendation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe unarXive citation recommendation dataset contains 2.5 Million paragraphs from computer science papers and with an annotated citation marker. The paragraphs and citation information is derived from unarXive.\\nNote that citation infromation is only given as the OpenAlex ID of the cited paper. An important consideration for models is therefore if the data is used as is, or if additional information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saier/unarXive_citrec."},
	{"name":"swiss_law_area_prediction","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_law_area_prediction","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"This dataset contains court decision for law area prediction task."},
	{"name":"swiss_leading_decisions","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_leading_decisions","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Swiss Leading Decisions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwiss Leading Decisions is a multilingual, diachronic dataset of 21K Swiss Federal Supreme Court (FSCS) cases. This dataset is part of a challenging text classification task. We also provide additional metadata as the publication year, the law area and the canton of origin per case, to promote robustness and fairness studies on the critical area of legal NLP.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rcds/swiss_leading_decisions."},
	{"name":"swiss_criticality_prediction","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_criticality_prediction","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"This dataset contains Swiss federal court decisions for the legal criticality prediction task"},
	{"name":"letras-carnaval-cadiz","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/IES-Rafael-Alberti/letras-carnaval-cadiz","creator_name":"IES Rafael Alberti","creator_url":"https://huggingface.co/IES-Rafael-Alberti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Letras Carnaval C√°diz\\n\\t\\n\\n\\n\\n    \\n        English |\\n        Espa√±ol\\n    \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChangelog\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nRelease\\nDescription\\n\\n\\n\\t\\t\\nv1.0\\nInitial release of the dataset. Included more than 1K lyrics. It is necessary to verify the accuracy of the data, especially the subset midaccurate.\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a comprehensive collection of lyrics from the Carnaval de C√°diz, a significant cultural heritage of the city of C√°diz, Spain. Despite‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IES-Rafael-Alberti/letras-carnaval-cadiz."},
	{"name":"prosocial-dialog-filtered","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered","creator_name":"Josh Oliver","creator_url":"https://huggingface.co/Englishman2022","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nProsocialDialogFiltered is a filtered version of the ProsocialDialog dataset.\\nMultiple versions are present:\\n\\nIn train_no_casual, rows with the label \\\"casual\\\" have been filtered out as a starting point.\\nIn train_no_possibly, rows with \\\"possibly needs caution\\\" have been filtered out.\\nIn train_no_probably, rows with \\\"probably needs caution\\\" have been filtered out, as I found those to be largely pointless as well, leaving only \\\"needs caution\\\" and \\\"needs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered."},
	{"name":"Bhasha-Abhijnaanam","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Aksharantar\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBhasha-Abhijnaanam is a language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\nAssamese (asm)\\nHindi (hin)\\nMaithili (mai)\\nNepali (nep)\\nSanskrit (san)\\nTamil (tam)\\n\\n\\nBengali (ben)\\nKannada (kan)\\nMalayalam (mal)\\nOriya (ori)\\nSantali (sat)\\nTelugu (tel)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam."},
	{"name":"rsd-ists-2016","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","description":"Training and test data for the task of Recognizing Semantic Differences (RSD).\\nSee the paper for details on how the dataset was created, and see our code at https://github.com/ZurichNLP/recognizing-semantic-differences for an example of how to use the data for evaluation.\\nThe data are derived from the SemEval-2016 Task 2 for Interpretable Semantic Textual Similarity organized by Agirre et al. (2016).\\nThe original URLs of the data are:\\n\\nTrain:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016."},
	{"name":"dane_plus","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/KennethEnevoldsen/dane_plus","creator_name":"Kenneth C. Enevoldsen","creator_url":"https://huggingface.co/KennethEnevoldsen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDaNE+\\n\\t\\n\\nThis is a version of DaNE, where the original NER labels have been updated to follow the ontonotes annotation scheme. The annotation process used the model trained on the Danish dataset DANSK for the first round of annotation and then all the discrepancies were manually reviewed and corrected by Kenneth C. Enevoldsen. A discrepancy include notably also includes newly added entities such as PRODUCT and WORK_OF_ART. Thus in practice a great deal of entities were manually‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KennethEnevoldsen/dane_plus."},
	{"name":"quickdraw","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Xenova/quickdraw","creator_name":"Joshua","creator_url":"https://huggingface.co/Xenova","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Quick, Draw!\\n\\t\\n\\nThis is a processed version of Google's Quick, Draw dataset to be compatible with the latest versions of ü§ó Datasets that support .parquet files. NOTE: this dataset only contains the \\\"preprocessed_bitmaps\\\" subset of the original dataset.\\n"},
	{"name":"samromur_synthetic","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_synthetic","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"Samr√≥mur Synthetic consists of 72 hours of synthetized speech in Icelandic."},
	{"name":"samromur_synthetic","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_synthetic","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"Samr√≥mur Synthetic consists of 72 hours of synthetized speech in Icelandic."},
	{"name":"blbooks-parquet","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/biglam/blbooks-parquet","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for British Library Books\\n\\t\\n\\nThis dataset is the same as https://huggingface.co/datasets/TheBritishLibrary/blbooks, however, this version is stored as parquet to avoid needing to run a datasets script. This also makes loading this dataset much quicker. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of books digitised by the British Library in partnership with Microsoft. The dataset includes ~25 million pages of out of copyright texts. The majority of the texts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/blbooks-parquet."},
	{"name":"blbooks-parquet-embedded","keyword":"machine-generated","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/davanstrien/blbooks-parquet-embedded","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"blbooks-parquet-embedded\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"professor_heideltime_en","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/professor_heideltime_en","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProfessor HeidelTime\\n\\t\\n\\n\\n\\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Details\\n\\t\\n\\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\\n\\n\\t\\n\\t\\t\\nDataset\\nLanguage\\nDocuments\\nFrom\\nTo\\nTokens\\nTimexs\\n\\n\\n\\t\\t\\nAll the News 2.0\\nEN\\n24,642\\n2016-01-01\\n2020-04-02\\n18,755,616\\n254,803\\n\\n\\nItalian Crime News\\nIT\\n9,619\\n2011-01-01\\n2021-12-31\\n3,296,898\\n58,823\\n\\n\\nGerman‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/professor_heideltime_en."},
	{"name":"hl-narratives","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/michelecafagna26/hl-narratives","creator_name":"Michele Cafagna","creator_url":"https://huggingface.co/michelecafagna26","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for the High-Level Narratives Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe High-Level Narratives (HL-Narratives) dataset aligns object-centric descriptions from COCO \\nwith synthetic high-level narratives captions automatically generated by merging scene, action, rationale captions from the HL Dataset using T5\\nThe HL-Naratives dataset contains 14997 images from COCO and a total of 134973 synthetic captions (3 captions per image) aligned with ~749984 object-centric captions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michelecafagna26/hl-narratives."},
	{"name":"pubmed_qa","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/highnote/pubmed_qa","creator_name":"Highnote Health, Inc.","creator_url":"https://huggingface.co/highnote","description":"PubMedQA is a novel biomedical question answering (QA) dataset collected from PubMed abstracts.\\nThe task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative\\nstatins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\\nPubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances.\\nEach PubMedQA instance is composed of (1) a question which is either an existing research article\\ntitle or derived from one, (2) a context which is the corresponding abstract without its conclusion,\\n(3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question,\\nand (4) a yes/no/maybe answer which summarizes the conclusion.\\nPubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their\\nquantitative contents, is required to answer the questions."},
	{"name":"minispider","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ravidborse/minispider","creator_name":"Ravikiran Borse","creator_url":"https://huggingface.co/ravidborse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ravidborse/minispider."},
	{"name":"thirukkural_instruct","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nthirukkural_QA is an open source dataset of instruct-style records generated by converting publicly available data on Thirukkural and it's meaning.\\nThis was created as part of Aya Open Science Initiative by Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\nQuestion Answering\\n\\nLanguages: Tamil Version: 1.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct."},
	{"name":"wikianc","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
	{"name":"wikianc","keyword":"machine-generated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
	{"name":"oe_dataset","keyword":"machine-generated","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/ABC-iRobotics/oe_dataset","creator_name":"Antal Bejczy Center for Intelligent Robotics","creator_url":"https://huggingface.co/ABC-iRobotics","description":"An instance segmentation dataset for robotic manipulation in a tabletop environment.\\nThe dataset incorporates real and synthetic images for testing sim-to-real model transfer after fine-tuning."},
	{"name":"ro-paraphrase-bible","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/andyP/ro-paraphrase-bible","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Romanian Bible Paraphrase Corpus\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/AndyTheFactory/ro-paraphrase-bible\\nRepository: https://github.com/AndyTheFactory/ro-paraphrase-bible\\nPoint of Contact: Andrei Paraschiv\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA paraphprase corpus created from 10 different Romanian language Bible versions. Since the Bible has all paragraphs uniquely numbered an alignment between two \\nversions is straighforward. \\nWe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andyP/ro-paraphrase-bible."},
	{"name":"TimeQA","keyword":"machine-generated","license":"BSD 3-Clause Clear License","language":"en","url":"https://huggingface.co/datasets/hugosousa/TimeQA","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTimeQA\\n\\t\\n\\nCheck out the original GitHub repo to learn more about the dataset.\\n"},
	{"name":"ProfessorHeidelTime","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProfessor HeidelTime\\n\\t\\n\\nPaper    GitHub\\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Details\\n\\t\\n\\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\\n\\n\\t\\n\\t\\t\\nDataset\\nLanguage\\nDocuments\\nFrom\\nTo\\nTokens\\nTimexs\\n\\n\\n\\t\\t\\nAll the News 2.0\\nEN\\n24,642\\n2016-01-01\\n2020-04-02\\n18,755,616\\n254,803\\n\\n\\nItalian Crime News\\nIT\\n9,619\\n2011-01-01\\n2021-12-31\\n3,296,898\\n58‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime."},
	{"name":"Marathon","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Lemoncoke/Marathon","creator_name":"Lei Zhang","creator_url":"https://huggingface.co/Lemoncoke","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Marathon\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRelease\\n\\t\\n\\n\\n[2024/05/15] üî• Marathon is accepted by ACL 2024 Main Conference.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMarathon benchmark is a new long-context multiple-choice benchmark, mainly based on LooGLE, with some original data from LongBench. The context length can reach up to 200K+. Marathon benchmark comprises six tasks: Comprehension and Reasoning, Multiple Information Retrieval, Timeline Reorder, Computation, Passage Retrieval, and Short‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lemoncoke/Marathon."},
	{"name":"LongSumEt","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/TalTechNLP/LongSumEt","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"LongSumEt\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLongSumEt is an estonian language long summarization dataset with pages filtered from CulturaX dataset. The dataset consists of the page text, and machine generated short summary, long summary and bulletpoints.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEstonian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/LongSumEt."},
	{"name":"rejection_sampling_phi_2_OA_rm","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm","creator_name":"Aliz√©e Pace","creator_url":"https://huggingface.co/alizeepace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Rejection Sampling Phi-2 with OpenAssistant RM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Rejection Sampling Phi-2 with OpenAssistant RM\\\" dataset consists of 10 pairs of prompts and responses, which were generated using rejection sampling over 10 Phi-2 generation using the OpenAssistant Reward Model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset and its creation rationale could be used to support models for question-answering, text-generation, or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm."},
	{"name":"rejection_sampling_phi_2_OA_rm","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm","creator_name":"Aliz√©e Pace","creator_url":"https://huggingface.co/alizeepace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Rejection Sampling Phi-2 with OpenAssistant RM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Rejection Sampling Phi-2 with OpenAssistant RM\\\" dataset consists of 10 pairs of prompts and responses, which were generated using rejection sampling over 10 Phi-2 generation using the OpenAssistant Reward Model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset and its creation rationale could be used to support models for question-answering, text-generation, or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm."},
	{"name":"escagleu-64k","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/escagleu-64k","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for escagleu-64K corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nescagleu-64k is a parallel corpus comprising 64091 sentences translated among Spanish, Catalan, Valencian Catalan, Galician, and Basque.\\nThe original sentences are in Spanish and come from the Spanish Common Voice Corpus.\\nWe prepared this corpus with the aim of creating a parallel speech dataset among these languages using the Common Voice platform between the frame of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/escagleu-64k."},
	{"name":"tiny-stack","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fhswf/tiny-stack","creator_name":"Fachhochschule S√ºdwestfalen","creator_url":"https://huggingface.co/fhswf","description":"\\n\\t\\n\\t\\t\\n\\t\\tAbout\\n\\t\\n\\nDataset for tinystack.\\n"},
	{"name":"hebrew-tzfira-dataset","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mbole/hebrew-tzfira-dataset","creator_name":"Bolek","creator_url":"https://huggingface.co/mbole","description":"\\n\\t\\n\\t\\t\\n\\t\\tHa-Tsfira OCR and POS-Tagged Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains OCR-processed and POS-tagged text from Ha-Tsfira (◊î◊¶◊§◊ô◊®◊î), a Hebrew-language newspaper published in Poland from 1862 and then from 1874 to 1931. The dataset includes 50 newspaper issues that have been digitized, cleaned, and linguistically annotated.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nHebrew (he)\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['id', 'ocr_text', 'cleaned_text'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mbole/hebrew-tzfira-dataset."},
	{"name":"synthetic-contextual-anonymizer-dataset","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset","creator_name":"Micha≈Ç Kurkowski","creator_url":"https://huggingface.co/kurkowski","description":"\\n\\t\\n\\t\\t\\n\\t\\tContextual Text Anonymizer Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains synthetically generated pairs of texts (original and anonymized) for various document types. The dataset was created for training text anonymization models while preserving context.\\n\\n\\t\\n\\t\\t\\n\\t\\tDocument Types\\n\\t\\n\\nThe dataset includes examples from the following categories:\\n\\nMedical records\\nBanking documents\\nBusiness correspondence\\nRecruitment documents\\nSocial media content\\nLegal documents\\nEducational‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset."},
	{"name":"synthetic-contextual-anonymizer-dataset","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset","creator_name":"Micha≈Ç Kurkowski","creator_url":"https://huggingface.co/kurkowski","description":"\\n\\t\\n\\t\\t\\n\\t\\tContextual Text Anonymizer Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains synthetically generated pairs of texts (original and anonymized) for various document types. The dataset was created for training text anonymization models while preserving context.\\n\\n\\t\\n\\t\\t\\n\\t\\tDocument Types\\n\\t\\n\\nThe dataset includes examples from the following categories:\\n\\nMedical records\\nBanking documents\\nBusiness correspondence\\nRecruitment documents\\nSocial media content\\nLegal documents\\nEducational‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset."},
	{"name":"mongs","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sangyon/mongs","creator_name":"yoon","creator_url":"https://huggingface.co/sangyon","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sangyon/mongs."},
	{"name":"mongs","keyword":"machine-generated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sangyon/mongs","creator_name":"yoon","creator_url":"https://huggingface.co/sangyon","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sangyon/mongs."},
	{"name":"COPA-cy","keyword":"machine-generated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mgrbyte/COPA-cy","creator_name":"Matt Russell","creator_url":"https://huggingface.co/mgrbyte","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for COPA-cy\\n\\t\\n\\n"},
	{"name":"jat-dataset","keyword":"machine-generated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jobs-git/jat-dataset","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"\\n\\t\\n\\t\\t\\n\\t\\tJAT Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Jack of All Trades (JAT) dataset combines a wide range of individual datasets. It includes expert demonstrations by expert RL agents, image and caption pairs, textual data and more. The JAT dataset is part of the JAT project, which aims to build a multimodal generalist agent.\\nPaper: https://huggingface.co/papers/2402.09844\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"jat-project/jat-dataset\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/jat-dataset."}
]
;
