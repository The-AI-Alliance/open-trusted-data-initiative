var data_for_reasoning = [

  {"name":"Knowledge_Pile","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile","creator_name":"Query-of-CC","creator_url":"https://huggingface.co/Query-of-CC","description":"Knowledge Pile is a knowledge-related data leveraging Query of CC.\\nThis dataset is a partial of Knowledge Pile(about 40GB disk size), full datasets have been released in [ü§ó knowledge_pile_full], a total of 735GB disk size and 188B tokens (using Llama2 tokenizer).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuery of CC\\n\\t\\n\\nJust like the figure below, we initially collected seed information in some specific domains, such as keywords, frequently asked questions, and textbooks, to serve as inputs for the Query Bootstrapping‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile."},
  {"name":"TemplateGSM","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/math-ai/TemplateGSM","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tTraining and Evaluating Language Models with Template-based Data Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTemplateGSM Dataset\\n\\t\\n\\nThe TemplateGSM dataset is a large-scale collection of over 7 million (with potential for unlimited generation) grade school math problems, each paired with both code-based and natural language solutions.  Designed to advance mathematical reasoning in language models, this dataset presents a diverse range of challenges to assess and improve model capabilities in solving‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/math-ai/TemplateGSM."},
  {"name":"LOGIC-701","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hivaze/LOGIC-701","creator_name":"Sergey Bratchikov","creator_url":"https://huggingface.co/hivaze","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLOGIC-701 Benchmark\\n\\t\\n\\nThis is a synthetic and filtered dataset for benchmarking large language models (LLMs). It consists of 701 medium and hard logic puzzles with solutions on 10 distinct topics.\\nA feature of the dataset is that it tests exclusively logical/reasoning abilities, offering only 5 answer options. There are no or very few tasks in the dataset that require external knowledge about events, people, facts, etc.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis benchmark is also part of an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hivaze/LOGIC-701."},
  {"name":"ZharfaTech-Open-Platypus-Persian-Farsi","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi","creator_name":"ZharfaTech","creator_url":"https://huggingface.co/ZharfaTech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersian Open-Platypus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout ZharfaTech\\n\\t\\n\\nZharfaTech is a pioneer in developing Language Learning Models (LLMs) tailored for the Persian language, aiming to empower over 100 million Persian speakers worldwide. Our mission encompasses bridging the digital divide in LLM-related services like content generation, customer relationship systems, and more, with a dual approach of fostering open-source collaboration and delivering high-value, specialized closed-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi."},
  {"name":"MMOS","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cyzhh/MMOS","creator_name":"Yezeng Chen","creator_url":"https://huggingface.co/cyzhh","description":"ArXiv | Models | Data | Code | \\nYou can download the dataset as follows\\nfrom datasets import load_dataset\\nds = load_dataset(\\\"cyzhh/MMOS\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach dataset row has the following structure\\n{\\n  \\\"idx\\\": ..., # problem id\\n  \\\"prompt\\\": ..., # problem \\n  \\\"completion\\\": ... # reasoning path with python\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nWe do not alter the license of any of the underlying data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nFor the MMOS, cite \\n@misc{chen2024empirical,\\n      title={An Empirical Study‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyzhh/MMOS."},
  {"name":"Retrieve-Pile","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Query-of-CC/Retrieve-Pile","creator_name":"Query-of-CC","creator_url":"https://huggingface.co/Query-of-CC","description":"Retrieve-Pile (Knowledge-Pile) is a knowledge-related data leveraging Retrieve-from-CC (We also called this method as \\\"Query of CC\\\")Ôºåa total of 735GB disk size and 188B tokens (using Llama2 tokenizer). \\n\\n\\t\\n\\t\\t\\n\\t\\tRetrieve-from-CC\\n\\t\\n\\nJust like the figure below, we initially collected seed information in some specific domains, such as keywords, frequently asked questions, and textbooks, to serve as inputs for the Query Bootstrapping stage. Leveraging the great generalization capability of large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Query-of-CC/Retrieve-Pile."},
  {"name":"lumos_multimodal_ground_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_multimodal_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_multimodal_ground_iterative."},
  {"name":"lumos_multimodal_plan_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_multimodal_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_multimodal_plan_iterative."},
  {"name":"tamil-orca","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/azharmo/tamil-orca","creator_name":"Mohamed Azharudeen M","creator_url":"https://huggingface.co/azharmo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTamil Orca-Style Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository hosts the Tamil Orca-style dataset, meticulously curated to enhance the reasoning capabilities of large language models in Tamil. The dataset is a fusion of translations and responses generated by GPT-4 and Gemini models.\\n\\nContent: The dataset contains three columns - 'Instruction', 'Query', and 'Answer'. \\nPurpose: It's designed to significantly improve the reasoning capability of AI language models in Tamil.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/azharmo/tamil-orca."},
  {"name":"tamil-orca-transliterated","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/azharmo/tamil-orca-transliterated","creator_name":"Mohamed Azharudeen M","creator_url":"https://huggingface.co/azharmo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTamil Orca-Style Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository hosts the Tamil Orca-style transliterated dataset, meticulously curated to enhance the reasoning capabilities of large language models in Tamil. The dataset is a transliterated version tamil-orca fusion of translations and responses generated by GPT-4 and Gemini models.\\n\\nContent: The dataset contains three columns - 'Instruction', 'Query', and 'Answer'. \\nPurpose: It's designed to significantly improve the reasoning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/azharmo/tamil-orca-transliterated."},
  {"name":"MathCodeInstruct","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct."},
  {"name":"Multilingual-Benchmark","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n"},
  {"name":"TextBooksPersonaHub","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/drodin/TextBooksPersonaHub","creator_name":"nacer","creator_url":"https://huggingface.co/drodin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTextBooksPersonaHub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe TextBooksPersonaHub dataset is an extension of the proj-persona/PersonaHub dataset, created using the technique described in the paper Textbooks Are All You Need II. This dataset contains synthetically generated \\\"textbook-like\\\" passages tailored in french to specific personas, aimed at enhancing language model training with high-quality and diverse content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/drodin/TextBooksPersonaHub."},
  {"name":"TextBooksPersonaHub-FR","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/drodin/TextBooksPersonaHub-FR","creator_name":"nacer","creator_url":"https://huggingface.co/drodin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTextBooksPersonaHub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe TextBooksPersonaHub dataset is an extension of the proj-persona/PersonaHub dataset, created using the technique described in the paper Textbooks Are All You Need II. This dataset contains synthetically generated \\\"textbook-like\\\" passages tailored in french to specific personas, aimed at enhancing language model training with high-quality and diverse content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/drodin/TextBooksPersonaHub-FR."},
  {"name":"reflection-small-sonnet","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/efederici/reflection-small-sonnet","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerified reasoning examples\\n\\t\\n\\n"},
  {"name":"German-RAG-ORPO-Alpaca-HESSIAN-AI","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Alpaca-Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \\nThe subsets can be for this training step are derived from 2 different sources:\\n\\nSauerkrautLM Preference Datasets:\\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI."},
  {"name":"summexecedit","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Salesforce/summexecedit","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFactual Consistency in Summarization\\n\\t\\n\\nEvaluate your model's ability to detect and explain the factual inconsistency in summaries. This repo contains the benchmark from our paper \\\"SummExecEdit: A Factual Consistency Benchmark in Summarization with Executable Edits\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummExecEdit Benchmark\\n\\t\\n\\nThis benchmark is built over our previous benchmark - SummEdits. Consistent summaries are used from SummEdits. New inconsistent and challenging summaries are generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/summexecedit."},
  {"name":"BigGSM","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LightChen2333/BigGSM","creator_name":"Qiguang Chen","creator_url":"https://huggingface.co/LightChen2333","description":"\\n  Unlocking the Boundaries of Thought: A Reasoning Granularity Framework to Quantify and Optimize Chain-of-Thought\\n\\n\\n\\n      \\n    | [ArXiv] | [ü§óHuggingFace] |\\n    \\n    \\n\\n\\nüåü Any contributions via PRs, issues, emails or other methods are greatly appreciated.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüî•News\\n\\t\\n\\n\\nüéñÔ∏è Our work is accepted by NeurIPS 2024 (Oral).\\nüî• We have release benchmark on [ü§óHuggingFace].\\nüî• The paper is also available on [ArXiv].\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüí° Motivation\\n\\t\\n\\nChain-of-Thought (CoT) reasoning has emerged‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LightChen2333/BigGSM."},
  {"name":"pisc-tr","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/berhaan/pisc-tr","creator_name":"Berhan T√ºrk√º Ay","creator_url":"https://huggingface.co/berhaan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nRepository: LLaVA-CoT GitHub Repository\\nPaper: LLaVA-CoT on arXiv\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\ncat image.zip.part-* > image.zip #not uploaded yet\\nunzip image.zip\\n\\nThe train.jsonl file contains the question-answering data and is structured in the following format:\\n{\\n  \\\"id\\\": \\\"example_id\\\",\\n  \\\"image\\\": \\\"example_image_path\\\",\\n  \\\"conversations\\\": [\\n    {\\\"from\\\": \\\"human\\\", \\\"value\\\": \\\"L√ºtfen resimdeki kƒ±rmƒ±zƒ± metal nesnelerin sayƒ±sƒ±nƒ±‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/berhaan/pisc-tr."},
  {"name":"LOGIC-701-instruct","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/evilfreelancer/LOGIC-701-instruct","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLOGIC-701 (instruct)\\n\\t\\n\\nBased on https://huggingface.co/datasets/hivaze/LOGIC-701\\nSources https://github.com/EvilFreelancer/LOGIC-701-instruct\\n"},
  {"name":"RelatLogic","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shb777/RelatLogic","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"RelatLogic: A Dataset for Comparative and Conditional Reasoning\\nThis is a comparative logic and conditional reasoning dataset. \\nEach data point has a premise, question, answer, reasoning and attribute.\\nPlease cite this dataset using the provided BibTeX if you find it useful.\\n@misc {sb_2025,\\n    author       = { {SB} },\\n    title        = { RelatLogic (Revision 15b1922) },\\n    year         = 2025,\\n    url          = { https://huggingface.co/datasets/shb777/RelatLogic },\\n    doi          = {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/RelatLogic."},
  {"name":"Unaligned-Thinking-o1","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fhai50032/Unaligned-Thinking-o1","creator_name":"Low IQ Gen AI","creator_url":"https://huggingface.co/fhai50032","description":"\\n\\t\\n\\t\\t\\n\\t\\tUnaligned Thinking o1  - Uncensored Data from Gemini 2.0 Flash Thinking\\n\\t\\n\\nWelcome to the \\\"Unaligned Thinking\\\" (Unaligned-Thinking-o1) dataset, a collection of raw toxic, output from the Gemini 2.0 Flash Thinking \\nThis Dataset is created using Prompt Engineering\\nDisclaimer:\\nThis Dataset contains highly toxic dataset , while still providing top-notch relevant answer very detailed and very verbose , only beaten by sonnet-3.5 gemini-exp-1206 O1\\nThe data contained within this dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fhai50032/Unaligned-Thinking-o1."},
  {"name":"rank1-R1-MSMARCO","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\trank1-R1-MSMARCO: Reasoning Outputs from MS MARCO Dataset\\n\\t\\n\\nüìÑ Paper | üöÄ GitHub Repository\\nThis dataset contains outputs from Deepseek's R1 model on the MS MARCO passage dataset, used to train rank1. It showcases the reasoning chains and relevance judgments generated when determining document relevance for information retrieval queries.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe rank1-R1-MSMARCO dataset consists of reasoning chains and relevance judgments produced on the MS MARCO passage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO."},
  {"name":"FineCorpus-WorkoutExercise","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/padilfm/FineCorpus-WorkoutExercise","creator_name":"Widi Fadhil","creator_url":"https://huggingface.co/padilfm","description":"\\n\\t\\n\\t\\t\\n\\t\\tFineCorpus-WorkoutExercise\\n\\t\\n\\nThis dataset contains structured workout exercise prompts for fine-tuning LLMs. \\n\\n\\t\\n\\t\\t\\n\\t\\tStructure:\\n\\t\\n\\n\\nconversations: Contains multi-turn dialogue pairs.\\nsource: Indicates whether the data is from reasoning (Human) or generated by an AI model (LLM).\\ncategory: Categorizes data into Q&A, Explain, Describe, Translate.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage:\\n\\t\\n\\nTo use this dataset:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"padiflm/FineCorpus-WorkoutExercise\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/padilfm/FineCorpus-WorkoutExercise."},
  {"name":"Medprompt-MedMCQA-R1","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HPAI-BSC/Medprompt-MedMCQA-R1","creator_name":"High Performance Artificial Intelligence @ Barcelona Supercomputing Center (HPAI at BSC)","creator_url":"https://huggingface.co/HPAI-BSC","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card: Medprompt-MedMCQA-R1\\n\\t\\n\\n\\nMedprompt-MedMCQA-R1 is a reasoning-augmented database designed for context retrieval in multiple-choice medical question answering. The dataset supports the development and evaluation of AI systems tailored to healthcare, particularly in tasks requiring enhanced contextual reasoning and retrieval-based assistance. By including structured reasoning and verified responses, Medprompt-MedMCQA-R1 enables a more transparent and interpretable workflow‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/Medprompt-MedMCQA-R1."},
  {"name":"Medprompt-MedQA-R1","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HPAI-BSC/Medprompt-MedQA-R1","creator_name":"High Performance Artificial Intelligence @ Barcelona Supercomputing Center (HPAI at BSC)","creator_url":"https://huggingface.co/HPAI-BSC","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card: Medprompt-MedQA-R1\\n\\t\\n\\n\\nMedprompt-MedQA-R1 is a reasoning-augmented database designed for context retrieval in multiple-choice medical question answering. The dataset supports the development and evaluation of AI systems tailored to healthcare, particularly in tasks requiring enhanced contextual reasoning and retrieval-based assistance. By including structured reasoning and verified responses, Medprompt-MedQA-R1 enables a more transparent and interpretable workflow for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/Medprompt-MedQA-R1."},
  {"name":"NuminaMath-1.5-Verifiable","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yentinglin/NuminaMath-1.5-Verifiable","creator_name":"Yen-Ting Lin","creator_url":"https://huggingface.co/yentinglin","description":"\\n\\t\\n\\t\\t\\n\\t\\tNuminaMath-1.5-Verifiable\\n\\t\\n\\nA filtered subset of NuminaMath-1.5, retaining only non-synthetic examples with valid answers.\\nFiltering Criteria\\n    ‚Ä¢\\tExcludes synthetic examples.\\n    ‚Ä¢\\tKeeps only entries with non-empty, meaningful answers.\\n    ‚Ä¢\\tRemoves generic placeholders like ‚Äúproof‚Äù and ‚Äúnotfound.‚Äù\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"yentinglin/NuminaMath-1.5-Verifiable\\\")\\n\\n"},
  {"name":"OpenR1-Math-220k-paired","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIR-hl/OpenR1-Math-220k-paired","creator_name":"Hsu Shihyueh","creator_url":"https://huggingface.co/AIR-hl","description":"\\n\\t\\n\\t\\t\\n\\t\\t!!! Is there anyone can help me? https://github.com/huggingface/trl/issues/2994\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is built by filtering the open-r1/OpenR1-Math-220k dataset according to the following rules:\\n\\nFirst, filter all of rows with only correct answers\\nThe chosen contains the shortest and correct generation, the rejected contains the wrong generation.\\nAll data with a prompt+chosen length exceeding 16k are filtered out.\\nWe provide the length for both chosen and rejected‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIR-hl/OpenR1-Math-220k-paired."},
  {"name":"clevr-tr","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/berhaan/clevr-tr","creator_name":"Berhan T√ºrk√º Ay","creator_url":"https://huggingface.co/berhaan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nRepository: LLaVA-CoT GitHub Repository\\nPaper: LLaVA-CoT on arXiv\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nunzip image.zip\\n\\nThe train.jsonl file contains the question-answering data and is structured in the following format:\\n{\\n  \\\"id\\\": \\\"example_id\\\",\\n  \\\"image\\\": \\\"example_image_path\\\",\\n  \\\"conversations\\\": [\\n    {\\\"from\\\": \\\"human\\\", \\\"value\\\": \\\"L√ºtfen resimdeki kƒ±rmƒ±zƒ± metal nesnelerin sayƒ±sƒ±nƒ± belirtin.\\\"},\\n    {\\\"from\\\": \\\"gpt\\\", \\\"value\\\": \\\"Resimde‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/berhaan/clevr-tr."},
  {"name":"German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long-Context Alpaca-Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \\nThe subsets are derived from Synthetic generation inspired by Tencent's (‚ÄúScaling Synthetic Data Creation with 1,000,000,000 Personas‚Äù).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI."},
  {"name":"smolThink","keyword":"reasoning","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/AILaborant/smolThink","creator_name":"AI Laborant","creator_url":"https://huggingface.co/AILaborant","description":"A small dataset that contains reasoning and complex mathematical problems, along with physics, and a little bit of geometry.\\n"},
  {"name":"smolBasisTolk","keyword":"reasoning","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/AILaborant/smolBasisTolk","creator_name":"AI Laborant","creator_url":"https://huggingface.co/AILaborant","description":"Smol but a wide variety of topics dataset for basic AI training.\\n"},
  {"name":"LongBench-v2-Pause1","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JamesBegin/LongBench-v2-Pause1","creator_name":"James Begin","creator_url":"https://huggingface.co/JamesBegin","description":"\\n\\t\\n\\t\\t\\n\\t\\tLongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks\\n\\t\\n\\nüåê Project Page: https://longbench2.github.io\\nüíª Github Repo: https://github.com/THUDM/LongBench\\nüìö Arxiv Paper: https://arxiv.org/abs/2412.15204\\nLongBench v2 is designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 has the following features: (1) Length: Context length ranging from 8k to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JamesBegin/LongBench-v2-Pause1."},
  {"name":"verify-teaser","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jing-bi/verify-teaser","creator_name":"jing bi","creator_url":"https://huggingface.co/jing-bi","description":"\\n\\t\\n\\t\\t\\n\\t\\tVERIFY: A Benchmark of Visual Explanation and Reasoning for Investigating Multimodal Reasoning FidelitY\\n\\t\\n\\nVERIFY is the first benchmark explicitly designed to assess the reasoning paths of MLLMs in visual reasoning tasks. \\nBy introducing novel evaluation metrics that go beyond mere accuracy, VERIFY highlights critical limitations in current MLLMs and emphasizes the need for a more balanced approach to visual perception and logical reasoning.\\nDetails of the benchmark can viewed at the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jing-bi/verify-teaser."},
  {"name":"PyRe-v2","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/theprint/PyRe-v2","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\t\\n\\t\\t\\n\\t\\tPyRe 2\\n\\t\\n\\nThis data set is a mix of samples from a number of public data sets (sources indidcated in the actual data). The goal with this set was to create a smaller set focused on coding (primarily Python), math, and reasoning.\\n"},
  {"name":"bbh-fr","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/le-leadboard/bbh-fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bbh-fr\\n\\t\\n\\nle-leadboard/bbh-fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation fran√ßaise du benchmark BIG-Bench Hard (BBH).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBBH-fr est l'adaptation fran√ßaise d'une suite de 23 t√¢ches BIG-Bench particuli√®rement exigeantes. Ces t√¢ches ont √©t√© s√©lectionn√©es car elles repr√©sentaient initialement des d√©fis o√π les mod√®les de langage n'atteignaient pas les performances humaines moyennes.\\nCat√©gories de t√¢ches‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/bbh-fr."},
  {"name":"TimeSeriesExam1","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AutonLab/TimeSeriesExam1","creator_name":"Auton Lab","creator_url":"https://huggingface.co/AutonLab","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for TimeSeriesExam-1\\n\\t\\n\\nThis dataset provides Question-Answer (QA) pairs for the paper TimeSeriesExam: A Time Series Understanding Exam. Example inference code can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\tüìñIntroduction\\n\\t\\n\\nLarge Language Models (LLMs) have recently demonstrated a remarkable ability to model time series data. These capabilities can be partly explained if LLMs understand basic time series concepts. However, our knowledge of what these models understand about time series data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AutonLab/TimeSeriesExam1."},
  {"name":"thinker","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/minchyeom/thinker","creator_name":"l","creator_url":"https://huggingface.co/minchyeom","description":"A Chain-of-Thought (CoT) dataset that contains traces of complex and sophisticated reasoning, to mimic the \\\"thinking\\\" process of OpenAI's o1. Wrap the contents of the reasoning column in some XML tag (such as <reasoning>).\\nRaw .jsonl dataset file can be found under the Files and Versions tab.\\n"},
  {"name":"dpo-merged","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CultriX/dpo-merged","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"dpo-merged-binarized","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CultriX/dpo-merged-binarized","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged-binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"SWAP","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sxiong/SWAP","creator_name":"Siheng Xiong","creator_url":"https://huggingface.co/sxiong","description":"\\n\\t\\n\\t\\t\\n\\t\\tSWAP: A Synthetic Dataset for Complex Reasoning with Trajectories and Process Supervision\\n\\t\\n\\nThis repository contains the data for the paper Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.\\nSWAP (Structure-aware Planning) solves complex reasoning by introducing a Generator-Discriminator architecture, and incorporates structural information to guide the reasoning process and provides a soft verification mechanism over the steps.\\nWe generate the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sxiong/SWAP."},
  {"name":"mathematical_reasoning_preference","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Shekswess/mathematical_reasoning_preference","creator_name":"Bojan Jakimovski","creator_url":"https://huggingface.co/Shekswess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\nTopic: Mathematical Reasoning\\nDomains: Mathematics, Reasoning, Thinking\\nFocus: This dataset can contain any type of mathematical reasoning and thinking.\\nNumber of Entries: 493\\nDataset Type: None\\nModel Used: bedrock/us.amazon.nova-pro-v1:0\\nLanguage: English\\nAdditional Information: The dataset is designed to provide a wide range of mathematical reasoning examples.\\nGenerated by: SynthGenAI Package\\n\\n"},
  {"name":"RobustFT","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/luojunyu/RobustFT","creator_name":"junyu","creator_url":"https://huggingface.co/luojunyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRobustFT Dataset\\n\\t\\n\\nThis dataset is part of the RobustFT project: Robust Supervised Fine-tuning for Large Language Models under Noisy Response. The dataset contains various test cases with different noise ratios for training and evaluating robust fine-tuning approaches.\\nOur paper: https://huggingface.co/papers/2412.14922\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nRobustFT/\\n‚îú‚îÄ‚îÄ arc/\\n‚îÇ ‚îÇ‚îÄ‚îÄ noisy30.csv\\n‚îÇ ‚îÇ‚îÄ‚îÄ noisy50.csv\\n‚îÇ ‚îÇ‚îÄ‚îÄ noisy70.csv\\n‚îÇ ‚îú‚îÄ‚îÄ labeled.csv\\n‚îÇ ‚îî‚îÄ‚îÄ test.csv\\n‚îú‚îÄ‚îÄ drop/\\n‚îÇ ‚îÇ‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/luojunyu/RobustFT."},
  {"name":"VMCBench","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/suyc21/VMCBench","creator_name":"Yuchang Su","creator_url":"https://huggingface.co/suyc21","description":"\\n\\t\\n\\t\\t\\n\\t\\tVMCBench (Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation)\\n\\t\\n\\nüåê Homepage | ü§ó Dataset | üìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Introduction\\n\\t\\n\\nWe introduce VMCBench: a benchmark that unifies 20 existing visual question answering (VQA) datasets into a consistent multiple-choice format. VMCBench spans a diverse array of visual and linguistic contexts, rigorously testing various model capabilities. By‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suyc21/VMCBench."},
  {"name":"V1-33K","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/haonan3/V1-33K","creator_name":"Haonan Wang","creator_url":"https://huggingface.co/haonan3","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tV1: Toward Multimodal Reasoning by Designing Auxiliary Tasks\\n\\t\\n\\n\\nüöÄ  Toward Multimodal Reasoning via Unsupervised Task -- Future Prediction üåü\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\nAuthors: Haonan Wang, Chao Du, Tianyu PangGitHub: haonan3/V1Dataset: V1-33K on Hugging Face\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMultimodal Reasoning\\n\\t\\n\\nRecent Large Reasoning Models (LRMs) such as DeepSeek-R1 have demonstrated impressive reasoning abilities; however, their capabilities are limited to textual data. Current models capture only a small part of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haonan3/V1-33K."},
  {"name":"countdown-numbers-3-8","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","description":"\\n\\t\\n\\t\\t\\n\\t\\tCountdown Numbers Game Dataset\\n\\t\\n\\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\\n\\n\\t\\n\\t\\t\\n\\t\\tHuggingFace Download Links\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nDataset Variant\\nDataset Name\\nDownload\\n\\n\\n\\t\\t\\nRandom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8."},
  {"name":"countdown-numbers-3-8-nz","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8-nz","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","description":"\\n\\t\\n\\t\\t\\n\\t\\tCountdown Numbers Game Dataset\\n\\t\\n\\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\\n\\n\\t\\n\\t\\t\\n\\t\\tHuggingFace Download Links\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nDataset Variant\\nDataset Name\\nDownload\\n\\n\\n\\t\\t\\nRandom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8-nz."},
  {"name":"German-RAG-LLM-HARD-BENCHMARK","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-LLM-HARD Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis German-RAG-LLM-HARD-BENCHMARK represents a specialized collection for evaluate language models with a focus on hard to solve RAG-specific capabilities. To evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/GRAG-LLM-HARD-BENCHMARK\\nThe subsets are derived from Synthetic generation inspired by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK."},
  {"name":"SkunkworksAI-reasoning-0.01-ko","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/youjunhyeok/SkunkworksAI-reasoning-0.01-ko","creator_name":"Ïú†Ï§ÄÌòÅ","creator_url":"https://huggingface.co/youjunhyeok","description":"SkunkworksAI/reasoning-0.01 Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ nayohan/llama3-instrucTrans-enko-8b Î™®Îç∏ÏùÑ ÏÇ¨Ïö©Ìï¥ Î≤àÏó≠ÌñàÏäµÎãàÎã§.\\nThanks for SkunkworksAI and nayohan.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÏõêÎ≥∏\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\treasoning-0.01 subset\\n\\t\\n\\nsynthetic dataset of reasoning chains for a wide variety of tasks.\\nwe leverage data like this across multiple reasoning experiments/projects.\\nstay tuned for reasoning models and more data.\\nThanks to Hive Digital Technologies (https://x.com/HIVEDigitalTech) for their compute support in this project and beyond.\\n"},
  {"name":"NL-Eye","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MorVentura/NL-Eye","creator_name":"Mor Ventura","creator_url":"https://huggingface.co/MorVentura","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNL-Eye Benchmark\\n\\t\\n\\nWill a Visual Language Model (VLM)-based bot warn us about slipping if it detects a wet floor? \\nRecent VLMs have demonstrated impressive capabilities, yet their ability to infer outcomes and causes remains underexplored. To address this, we introduce NL-Eye, a benchmark designed to assess VLMs' visual abductive reasoning skills. \\nNL-Eye adapts the abductive Natural Language Inference (NLI) task to the visual domain, requiring models to evaluate the plausibility‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MorVentura/NL-Eye."},
  {"name":"Light-R1-DPOData","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/qihoo360/Light-R1-DPOData","creator_name":"Âåó‰∫¨Â•áËôéÁßëÊäÄÊúâÈôêÂÖ¨Âè∏","creator_url":"https://huggingface.co/qihoo360","description":"\\n\\t\\n\\t\\t\\n\\t\\tLight-R1: Surpassing R1-Distill from Scratch* with $1000 through Curriculum SFT & DPO\\n\\t\\n\\n*from models without long COT\\ntechnical report\\nGitHub page\\nHere is the DPO data we used to train Light-R1-32B.\\nSimply refer to dpo-pairs.json\\n\\n\\t\\n\\t\\t\\nModel\\nTrained From\\nRelease Date\\nAIME24\\nAIME25\\n\\n\\n\\t\\t\\nDeepSeek-R1-Distill-Llama-70B\\nLlama-3.3-70B-Instruct\\n25.1.20\\n70.0\\n54.1\\n\\n\\nDeepSeek-R1-Distill-Qwen-32B\\nQwen2.5-32B\\n25.1.20\\n72.6\\n54.9\\n\\n\\nLIMO (32B)\\nQwen2.5-32B-Instruct25.2.4\\n56.3\\n47.1\\n\\n\\ns1.1-32B‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qihoo360/Light-R1-DPOData."},
  {"name":"Arabic-gsm8k","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Arabic GSM8K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nArabic GSM8K is an Arabic translation of the GSM8K (Grade School Math 8K) dataset, which contains high-quality linguistically diverse grade school math word problems. The original dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning, and this Arabic version aims to extend these capabilities to Arabic language models and applications.\\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k."},
  {"name":"ProcessBench","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Qwen/ProcessBench","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcessBench\\n\\t\\n\\nThis repository contains the dataset of the ProcessBench benchmark proposed by Qwen Team.\\nYou can refer to our GitHub repository for the evaluation code and the prompt templates we use in this work.\\nIf you find this work relevant or helpful to your work, please kindly cite us:\\n@article{processbench,\\n  title={ProcessBench: Identifying Process Errors in Mathematical Reasoning}, \\n  author={\\n    Chujie Zheng and Zhenru Zhang and Beichen Zhang and Runji Lin and Keming Lu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/ProcessBench."},
  {"name":"dolphin-r1-french","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WiroAI/dolphin-r1-french","creator_name":"Wiro AI","creator_url":"https://huggingface.co/WiroAI","description":"\\n  \\n  \\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n  \\n    \\n  \\n    \\n    \\n  \\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tDolphin R1 French üê¨\\n\\t\\n\\n\\nDolphin-R1 is an Apache-2.0 English dataset curated by Eric Hartford and Cognitive Computations\\nDolphin-R1-french is a French subset of the original dataset.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSponsors\\n\\t\\n\\nTheir and Wiro AI's appreciation for the generous sponsors of Dolphin R1 - Without whom this dataset could not exist.\\n\\nDria https://x.com/driaforall - Inference Sponsor (DeepSeek)\\nChutes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiroAI/dolphin-r1-french."},
  {"name":"dolphin-r1-italian","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WiroAI/dolphin-r1-italian","creator_name":"Wiro AI","creator_url":"https://huggingface.co/WiroAI","description":"\\n  \\n  \\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n  \\n    \\n  \\n    \\n    \\n  \\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tDolphin R1 Italian üê¨\\n\\t\\n\\n\\nDolphin-R1 is an Apache-2.0 English dataset curated by Eric Hartford and Cognitive Computations\\nDolphin-R1-Italian is a Italian subset of the original dataset.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSponsors\\n\\t\\n\\nTheir and Wiro AI's appreciation for the generous sponsors of Dolphin R1 - Without whom this dataset could not exist.\\n\\nDria https://x.com/driaforall - Inference Sponsor (DeepSeek)\\nChutes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiroAI/dolphin-r1-italian."},
  {"name":"thinking-multilingual-30-23-small-690","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \\nOr use the \\\"big\\\" version: big 10k rows version\\n"},
  {"name":"clevr-math","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dali-does/clevr-math","creator_name":"Adam Dahlgren Lindstr√∂m","creator_url":"https://huggingface.co/dali-does","description":"CLEVR-Math is a dataset for compositional language, visual and mathematical reasoning. CLEVR-Math poses questions about mathematical operations on visual scenes using subtraction and addition, such as \\\"Remove all large red cylinders. How many objects are left?\\\". There are also adversarial (e.g. \\\"Remove all blue cubes. How many cylinders are left?\\\") and multihop questions (e.g. \\\"Remove all blue cubes. Remove all small purple spheres. How many objects are left?\\\")."},
  {"name":"reason_code-search-net-python","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"reason_code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \\nGiven a Python 3 function:\\n\\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\\nType 2: Generate a summary explaining what its input parameters represent (\\\"For example: infile: a file descriptor of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python."},
  {"name":"reason_code-search-net-python","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"reason_code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \\nGiven a Python 3 function:\\n\\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\\nType 2: Generate a summary explaining what its input parameters represent (\\\"For example: infile: a file descriptor of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python."},
  {"name":"General-Knowledge","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MuskumPillerum/General-Knowledge","creator_name":"EurekaBotics","creator_url":"https://huggingface.co/MuskumPillerum","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset is a collection of questions and answers themed on general facts and reasoning. The dataset is divided into two features - 'Question' and 'Answer'. \\nIt is meant to be used for training a model to be good at general knowledge and reasoning. This dataset is inspired from the Alpaca dataset, and infact contains a subset of the alpaca dataset in itself.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDistribution\\n\\t\\n\\n  The distribution of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MuskumPillerum/General-Knowledge."},
  {"name":"lumos_web_agent_plan_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_web_agent_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_web_agent_plan_iterative."},
  {"name":"StackMathQA","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/math-ai/StackMathQA","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tStackMathQA\\n\\t\\n\\nStackMathQA is a meticulously curated collection of 2 million mathematical questions and answers, sourced from various Stack Exchange sites. This repository is designed to serve as a comprehensive resource for researchers, educators, and enthusiasts in the field of mathematics and AI research.\\n\\n\\t\\n\\t\\t\\n\\t\\tConfigs\\n\\t\\n\\nconfigs:\\n- config_name: stackmathqa1600k\\n  data_files: data/stackmathqa1600k/all.jsonl\\n  default: true\\n- config_name: stackmathqa800k\\n  data_files:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/math-ai/StackMathQA."},
  {"name":"AutoMathText","keyword":"reasoning","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/math-ai/AutoMathText","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tAutoMathText\\n\\t\\n\\nAutoMathText is an extensive and carefully curated dataset encompassing around 200 GB of mathematical texts. It's a compilation sourced from a diverse range of platforms including various websites, arXiv, and GitHub (OpenWebMath, RedPajama, Algebraic Stack). This rich repository has been autonomously selected (labeled) by the state-of-the-art open-source language model, Qwen-72B. Each piece of content in the dataset is assigned a score lm_q1q2_score within the range of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/math-ai/AutoMathText."},
  {"name":"MathVision","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MathLLMs/MathVision","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\tMeasuring Multimodal Mathematical Reasoning with the MATH-Vision Dataset\\n\\t\\n\\n[üíª Github] [üåê Homepage]  [üìä Leaderboard ] [üîç Visualization] [üìñ ArXiv Paper]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüöÄ Data Usage\\n\\t\\n\\n\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"MathLLMs/MathVision\\\")\\nprint(dataset)\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tüí• News\\n\\t\\n\\n\\n[2025.03.10] üí• Kimi k1.6 Preview ü•á Sets New SOTA on MATH-V with 53.29%!See the full leaderboard.\\n[2025.02.28] üí• Doubao-1.5-pro Sets New SOTA on MATH-V with 48.62%! Read more on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathVision."},
  {"name":"CriticBench","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/llm-agents/CriticBench","creator_name":"LLM-Agents","creator_url":"https://huggingface.co/llm-agents","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nCriticBench is a comprehensive benchmark designed to assess LLMs' abilities to generate, critique/discriminate and correct reasoning across a variety of tasks. CriticBench encompasses five reasoning domains: mathematical, commonsense, symbolic, coding, and algorithmic. It compiles 15 datasets and incorporates responses from three LLM families.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: THU\\nFunded by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llm-agents/CriticBench."},
  {"name":"FLenQA","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/alonj/FLenQA","creator_name":"Alon Jacoby","creator_url":"https://huggingface.co/alonj","description":"Same Task, More tokens\\nthe Impact of Input Length on the Reasoning Performance of Large Language Models\\nMosh Levy[*,1], Alon Jacoby[*,1], Yoav Goldberg[1,2]\\n\\n\\nPlease see full details in our pre-print on arxiv\\n \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is this all about?\\n\\t\\n\\nWe explore the impact of extending input lengths on the capabilities of Large Language Models (LLMs). \\nDespite LLMs advancements in recent times, their performance consistency across different input lengths is not well understood.\\nHere, we aim to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alonj/FLenQA."},
  {"name":"StackMathQA","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/agicorp/StackMathQA","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStackMathQA\\n\\t\\n\\nStackMathQA is a meticulously curated collection of 2 million mathematical questions and answers, sourced from various Stack Exchange sites. This repository is designed to serve as a comprehensive resource for researchers, educators, and enthusiasts in the field of mathematics and AI research.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tConfigs\\n\\t\\n\\nconfigs:\\n- config_name: stackmathqa1600k\\n  data_files: data/stackmathqa1600k/all.jsonl\\n  default: true\\n- config_name: stackmathqa800k\\n  data_files:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agicorp/StackMathQA."},
  {"name":"MathCodeInstruct-Plus","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus."},
  {"name":"MuSR","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/TAUR-Lab/MuSR","creator_name":"TAUR Lab at UT Austin","creator_url":"https://huggingface.co/TAUR-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCreating murder mysteries that require multi-step reasoning with commonsense using ChatGPT!\\n\\t\\n\\nBy: Zayne Sprague, Xi Ye, Kaj Bostrom, Swarat Chaudhuri, and Greg Durrett.\\nView the dataset on our custom viewer and project website!\\nCheck out the paper. Appeared at ICLR 2024 as a spotlight presentation!\\nGit Repo with the source data, how to recreate the dataset (and create new ones!) here\\n"},
  {"name":"FOL-nli","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tasksource/FOL-nli","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"FOL-nli\\\"\\n\\t\\n\\nhttps://github.com/sileod/unigram/\\nhttps://arxiv.org/abs/2406.11035\\nCitation:\\n@article{sileo2024scaling,\\n  title={Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars},\\n  author={Sileo, Damien},\\n  journal={arXiv preprint arXiv:2406.11035},\\n  year={2024}\\n}\\n\\n"},
  {"name":"LoGiPT-data","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jzfeng/LoGiPT-data","creator_name":"Jamie Jiazhan Feng","creator_url":"https://huggingface.co/jzfeng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThese are the training data for LoGiPT from NAACL'24 paper: \\\"Language Models can be Deductive Solvers\\\".\\n\\nLoGiPT-data-ProofWriter.json: Instruction-tuning data for LoGiPT constructed from ProofWriter.\\nLoGiPT-data-PrOntoQA.json: Instruction-tuning data for LoGiPT constructed from PrOntoQA.\\n\\nAll training examples are organised in Json-format and Vicuna-style.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIf you find this data helpful, please cite our NAACL'24 paper: (or Arxiv version:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jzfeng/LoGiPT-data."},
  {"name":"Risky_Choices","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Josephgflowers/Risky_Choices","creator_name":"Joseph G Flowers","creator_url":"https://huggingface.co/Josephgflowers","description":"Dataset Summary\\nThe Risky Choices dataset is a derived version of the original choices13k dataset. It is designed to assist in training language models for tasks such as decision-making reasoning, explanation generation, and natural language processing. The dataset contains human decision rates on 13,006 risky choice problems, restructured into a natural language format suitable for various AI and ML applications.\\nIn this processed version, each entry is presented as a decision-making scenario‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Josephgflowers/Risky_Choices."},
  {"name":"frames-benchmark","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/frames-benchmark","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFRAMES: Factuality, Retrieval, And reasoning MEasurement Set\\n\\t\\n\\nFRAMES is a comprehensive evaluation dataset designed to test the capabilities of Retrieval-Augmented Generation (RAG) systems across factuality, retrieval accuracy, and reasoning.\\nOur paper with details and experiments is available on arXiv: https://arxiv.org/abs/2409.12941.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\n824 challenging multi-hop questions requiring information from 2-15 Wikipedia articles\\nQuestions span diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/frames-benchmark."},
  {"name":"reasoning-base-20k","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/KingNish/reasoning-base-20k","creator_name":"Nishith Jain","creator_url":"https://huggingface.co/KingNish","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Reasoning Base 20k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is designed to train a reasoning model. That can think through complex problems before providing a response, similar to how a human would. The dataset includes a wide range of problems from various domains (science, coding, math, etc.), each with a detailed chain of thought (COT) and the correct answer. The goal is to enable the model to learn and refine its‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KingNish/reasoning-base-20k."},
  {"name":"German-RAG-ORPO-ShareGPT-HESSIAN-AI","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) ShareGPT-Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGerman-RAG - German Retrieval Augmented Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \\nThe subsets can be for this training step are derived from 3 different sources:\\n\\nSauerkrautLM Preference Datasets:\\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI."},
  {"name":"24-game","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nlile/24-game","creator_name":"nathan lile","creator_url":"https://huggingface.co/nlile","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath Twenty Four (24s Game) Dataset\\n\\t\\n\\nA comprehensive dataset for the classic math twenty four game (also known as the 4 numbers game / 24s game / Game of 24). This dataset of mathematical reasoning challenges was collected from 4nums.com, featuring over 1,300 unique puzzles of the Game of 24, with difficulty metrics derived from over 6.4 million human solution attempts since 2012.\\nIn each puzzle, players must use exactly four numbers and basic arithmetic operations (+, -, √ó, /) to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nlile/24-game."},
  {"name":"MAmmoTH-VL-Instruct-12M","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MAmmoTH-VL/MAmmoTH-VL-Instruct-12M","creator_name":"MAmmoTH-VL","creator_url":"https://huggingface.co/MAmmoTH-VL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMAmmoTH-VL-Instruct-12M\\n\\t\\n\\nüè† Homepage | ü§ñ MAmmoTH-VL-8B | üíª Code | üìÑ Arxiv | üìï PDF | üñ•Ô∏è Demo\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nOur simple yet scalable visual instruction data rewriting pipeline consists of three steps: manual data source collection, rewriting using MLLMs/LLMs, and filtering via the same MLLM as a judge. Examples below illustrate transformations in math and science categories, showcasing detailed, step-by-step responses.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe data distribution of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAmmoTH-VL/MAmmoTH-VL-Instruct-12M."},
  {"name":"VISCO","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVISCO\\n\\t\\n\\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\\nüåê Project | üìñ Paper | üíª Github\\n\\n\\nOutline:\\n\\nIntroduction\\nData\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\\n\\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\\n5604 step-wise annotations of critique, showing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO."},
  {"name":"u-math","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/toloka/u-math","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","description":"U-MATH is a comprehensive benchmark of 1,100 unpublished university-level problems sourced from real teaching materials. \\nIt is designed to evaluate the mathematical reasoning capabilities of Large Language Models (LLMs). The dataset is balanced across six core mathematical topics and includes 20% of multimodal problems (involving visual elements such as graphs and diagrams). \\nFor fine-grained performance evaluation results and detailed discussion, check out our paper.\\n\\nüìä U-MATH benchmark at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/toloka/u-math."},
  {"name":"LongBench-v2","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/THUDM/LongBench-v2","creator_name":"Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University","creator_url":"https://huggingface.co/THUDM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks\\n\\t\\n\\nüåê Project Page: https://longbench2.github.io\\nüíª Github Repo: https://github.com/THUDM/LongBench\\nüìö Arxiv Paper: https://arxiv.org/abs/2412.15204\\nLongBench v2 is designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 has the following features: (1) Length: Context length ranging from 8k‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/THUDM/LongBench-v2."},
  {"name":"Letta-o1","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/minchyeom/Letta-o1","creator_name":"l","creator_url":"https://huggingface.co/minchyeom","description":"Modified System Prompt for Letta:\\nYou are Letta, the latest version of Limnal Corporation's digital companion, developed in 2023.\\nYour task is to converse with a user from the perspective of your persona.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minchyeom/Letta-o1."},
  {"name":"multimodal_textbook","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/DAMO-NLP-SG/multimodal_textbook","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultimodal-Textbook-6.5M\\n\\t\\n\\n    \\n\\n\\n  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is for \\\"2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining\\\", containing 6.5M images interleaving with 0.8B text from instructional videos.\\n\\nIt contains pre-training corpus using interleaved image-text format. Specifically, our multimodal-textbook includes 6.5M keyframesextracted from instructional videos, interleaving with 0.8B ASR texts.\\nAll the images and text are extracted from online‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/multimodal_textbook."},
  {"name":"Tachibana-QVQ","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Tachibana-QVQ","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Tachibana-QVQ is a dataset containing code-reasoning and code-instruct responses across a wide variety of programming tasks.\\nThis dataset contains:\\n\\n103k prompts from sequelbox/Tachibana, with all responses generated by Qwen/QVQ-72B-Preview.\\nResponses demonstrate QVQ's code-reasoning ability and general code capabilities.\\n\\nResponses have not been filtered or edited at all: some responses will contain infinite thought loops, incomplete answers, inaccurate responses, or other identified or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana-QVQ."},
  {"name":"distilabel-reasoning-R1-Llama-70B","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/distilabel-reasoning-R1-Llama-70B","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tHow this Data was made\\n\\t\\n\\nWe made this data through the following steps:\\n\\nSample English reasoning-style prompts from argilla/distilabel-reasoning-prompts.\\nRemove similar prompts using text similarity based on BAAI/bge-m3 embeddings.\\nTranslate English prompts to Japanese using gpt-4o-mini-2024-07-18.\\nGenerate answers to prompts using deepseek-ai/DeepSeek-R1-Distill-Llama-70B.\\nFilter responses (to ja_valid) which did not:\\nFinish within 2048 tokens\\nContain a valid <think> section\\nHave‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/distilabel-reasoning-R1-Llama-70B."},
  {"name":"GPQA-diamond-ClaudeR1","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/spawn99/GPQA-diamond-ClaudeR1","creator_name":"Cavit Erginsoy","creator_url":"https://huggingface.co/spawn99","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GPQA Diamond Reasoning Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nA benchmark dataset for evaluating hybrid AI architectures, comparing reasoning-augmented LLMs (DeepSeek R1) against standalone models (Claude Sonnet 3.5). Contains 198 physics questions with:\\n\\nGround truth answers and explanations\\nModel responses from multiple architectures\\nGranular token usage and cost metrics\\nDifficulty metadata and domain categorization\\n\\nCurated by: LLM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/spawn99/GPQA-diamond-ClaudeR1."},
  {"name":"HyperThink-v1","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NuclearAi/HyperThink-v1","creator_name":"Nuclear Ai","creator_url":"https://huggingface.co/NuclearAi","description":"\\n\\t\\n\\t\\t\\n\\t\\tHyperThink-v1\\n\\t\\n\\nThere is no need to read about it much , just use it and make awesome models , we will continously focus to expand it ! enjoy guys üòé .\\nRam Ram üö©üö©\\n"},
  {"name":"smol-smoltalk-plus-reasoning-synthetic-data","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/david-thrower/smol-smoltalk-plus-reasoning-synthetic-data","creator_name":"David Thrower","creator_url":"https://huggingface.co/david-thrower","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Smol-Smoltalk Plus Reasoning\\n\\t\\n\\n\\nThis is a project to make a fork of HuggingFaceTB/smol-smoltalk which includes reasoning data generated using HuggingFaceTB/SmolLM2-1.7B-Instruct.\\nThis is a work in progress. I ran a proof of concept on a small subset and will scale this up as I am able to.\\nContributions to scale this up and complete this data are welcome, especially from those with access to more substantial GPU resources.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/david-thrower/smol-smoltalk-plus-reasoning-synthetic-data."},
  {"name":"r1-reasoning-tr","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SoAp9035/r1-reasoning-tr","creator_name":"Ahmet Burhan Kayalƒ±","creator_url":"https://huggingface.co/SoAp9035","description":"\\n\\t\\n\\t\\t\\n\\t\\tR1 Reasoning TR\\n\\t\\n\\nThis is an R1 reasoning dataset translated into Turkish, containing conversations between users and assistants. Thanks to lightblue for the dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is released under the Apache 2.0 License.\\n"},
  {"name":"Raiden-DeepSeek-R1-PREVIEW","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Raiden-DeepSeek-R1-PREVIEW","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"This is a preview of the full Raiden-Deepseek-R1 creative and analytical reasoning dataset, containing the first ~6k rows. Get the full dataset here!\\nThis dataset uses synthetic data generated by deepseek-ai/DeepSeek-R1.\\nThe initial release of Raiden uses 'creative_content' and 'analytical_reasoning' prompts from microsoft/orca-agentinstruct-1M-v1.\\nDataset has not been reviewed for format or accuracy. All responses are synthetic and provided without editing.\\nUse as you will.\\n"},
  {"name":"ethical-framework","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ktiyab/ethical-framework","creator_name":"Tiyab K.","creator_url":"https://huggingface.co/ktiyab","description":"\\n\\t\\n\\t\\t\\n\\t\\t1. Dataset Title\\n\\t\\n\\nEthical AI Decision-Making Training Data (Montreal Declaration Edition)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t2. Overview\\n\\t\\n\\nThis dataset contains carefully crafted scenarios (instructions) and detailed responses illustrating step-by-step ethical reasoning aligned with the principles outlined in the Montreal Declaration for Responsible AI. Each entry poses a complex ethical challenge and provides a reasoned solution while referencing the specific principle(s) being tested.  \\nThese entries can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ktiyab/ethical-framework."},
  {"name":"aime2025-ru","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kristaller486/aime2025-ru","creator_name":"Kristaller486","creator_url":"https://huggingface.co/kristaller486","description":"\\n\\t\\n\\t\\t\\n\\t\\tRussian Description (English below)\\n\\t\\n\\n–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –±–µ–Ω—á–º–∞—Ä–∫–∞ AIME 2025 –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –ú–æ–¥–µ–ª—å-–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ - Gemini 2.0 Pro Experimental.\\n\\n\\t\\n\\t\\t\\n\\t\\tEnglish Description\\n\\t\\n\\nTranslated version of AIME 2025 into Russian. Model-translator - Gemini 2.0 Pro Experimental.\\n\\n\\t\\n\\t\\t\\n\\t\\tLeaderboard\\n\\t\\n\\n\\n"},
  {"name":"bilmecebench","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/selimc/bilmecebench","creator_name":"selim","creator_url":"https://huggingface.co/selimc","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tBilmeceBench: Turkish Cultural Reasoning Benchmark\\n\\t\\n\\nBilmeceBench is a collection of traditional Turkish riddles designed to evaluate language models' cultural understanding and reasoning capabilities. The dataset contains authentic Turkish riddles (bilmece) that require both linguistic comprehension and cultural context to solve. Unfortunately, I currently lack the resources and time to conduct comprehensive model testing or evaluations, but users can utilize this dataset to perform‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/selimc/bilmecebench."},
  {"name":"Raiden-DeepSeek-R1","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Raiden-DeepSeek-R1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Click here to support our open-source dataset and model releases!\\nRaiden-DeepSeek-R1 is a dataset containing creative-reasoning and analytic-reasoning responses, testing the limits of DeepSeek R1's reasoning skills!\\nThis dataset contains:\\n\\n63k 'creative_content' and 'analytical_reasoning' prompts from microsoft/orca-agentinstruct-1M-v1, with all responses generated by deepseek-ai/DeepSeek-R1.\\nResponses demonstrate the reasoning capabilities of DeepSeek's 685b parameter R1 reasoning model.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Raiden-DeepSeek-R1."},
  {"name":"Deepthink-Reasoning-Instruction","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/prithivMLmods/Deepthink-Reasoning-Instruction","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepthink Reasoning Demo\\n\\t\\n\\nDeepthink Reasoning is a comprehensive data repository designed to break down complex problems, especially in coding (Python, Go, Java, C++, C#, etc.) and algorithms. It provides detailed problem analyses and systematic solutions to achieve the desired outcomes.\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nComprehensive Problem Breakdown: Deepthink Reasoning dissects problems into smaller, manageable components to facilitate effective understanding and solution generation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepthink-Reasoning-Instruction."},
  {"name":"LogicPro","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jiangjin/LogicPro","creator_name":"jiangjin","creator_url":"https://huggingface.co/jiangjin","description":"\\n  \\n  \\n  LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning\\n\\n\\n\\n  [üìë Paper] ‚Ä¢\\n  [ü§ó HF Dataset] ‚Ä¢\\n  [üëª GitHub]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData description\\n\\t\\n\\n{\\n  \\\"id\\\": \\\"logicpro_lc679_225531-43120\\\",\\n  \\\"title\\\": \\\"24 Game\\\", # Title of the original leetcode algorithm problem.\\n  \\\"difficulty\\\": \\\"Hard\\\",\\n  \\\"content\\\": \\\"...\\\", # The questions of the original leetcode algorithm problem.\\n  \\\"python\\\": \\\"...\\\", # The original gold python solution\\n  \\\"test_input_string\\\": \\\"...\\\", # Current Test Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jiangjin/LogicPro."},
  {"name":"rank1-training-data","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhu-clsp/rank1-training-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\trank1-training-data: Training Dataset for rank1 Reasoning Rerankers\\n\\t\\n\\nüìÑ Paper | üöÄ GitHub Repository\\nThis dataset contains the training data used to develop the rank1 family of reasoning rerankers with LLaMA Factory. It includes query-document pairs with relevance judgments and reasoning chains that guided the models to make binary relevance decisions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe rank1-training-data dataset is a comprehensive collection of training examples used to teach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-training-data."},
  {"name":"OpenThoughts-TR-18k","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k","creator_name":"selim","creator_url":"https://huggingface.co/selimc","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpenThoughts-TR-18k: Turkish Synthetic Reasoning Dataset\\n\\t\\n\\nOpenThoughts-TR-18k is a Turkish translation of a subset of the original Open-Thoughts-114k dataset. It contains ~18k high-quality synthetic reasoning examples covering mathematics, science, coding problems, and puzzles, all translated into Turkish. This dataset is designed to support reasoning task fine tuning for Turkish language models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n~18k translated reasoning examples\\nCovers multiple domains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k."},
  {"name":"VL-Thinking","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/UCSC-VLAA/VL-Thinking","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","description":"\\n\\t\\n\\t\\t\\n\\t\\tVL-Thinking: An R1-Derived Visual Instruction Tuning Dataset for Thinkable LVLMs\\n\\t\\n\\n\\n  üåê Project Page  ‚Ä¢ üíª  Code  ‚Ä¢ ü§î Dataset \\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tContents\\n\\t\\n\\n\\nDataset Card üìö\\nGeneration Pipeline üö∞\\nExamples\\nOngoing\\nContributors üìù\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card üìö\\n\\t\\n\\nThe first version consists of samples from the following datasets:\\n\\n\\n\\n\\t\\n\\t\\t\\nName\\n# original samples\\n# verified\\n\\n\\n\\t\\t\\nCLEVR_Math\\n35,000\\n28,018\\n\\n\\nGeoQA170K\\n14,019\\n7,794\\n\\n\\nSynthesis\\n29,998\\n26,672\\n\\n\\nChartQA18,317\\n12,139\\n\\n\\nDocVQA\\n10,194\\n8,206‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UCSC-VLAA/VL-Thinking."},
  {"name":"Arabic-Optimized-Reasoning-Dataset","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Jr23xd23/Arabic-Optimized-Reasoning-Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","description":"\\n\\t\\n\\t\\t\\n\\t\\tArabic Optimized Reasoning Dataset\\n\\t\\n\\nDataset Name: Arabic Optimized ReasoningLicense: Apache-2.0Formats: CSVSize: 1600 rowsBase Dataset: cognitivecomputations/dolphin-r1Libraries Used: Datasets, Dask, Croissant\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Arabic Optimized Reasoning Dataset helps AI models get better at reasoning in Arabic. While AI models are good at many tasks, they often struggle with reasoning in languages other than English. This dataset helps fix this problem by:\\n\\nUsing fewer tokens‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic-Optimized-Reasoning-Dataset."},
  {"name":"Thinking-multilingual-big-10k-sft","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\\nenjoy üëç\\n"},
  {"name":"100k-raz-es","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/sintergica/100k-raz-es","creator_name":"Sint√©rgica AI","creator_url":"https://huggingface.co/sintergica","description":"sintergica/100k-raz-es dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\\nnote: translations are not human generated.\\n"},
  {"name":"reasoning-conversations","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Reasoning Dataset\\n\\t\\n\\n\\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\\n\\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\\n\\n\\nCredits sponsored by Currents API\\n"},
  {"name":"Medic-Thoughts-16k","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/XeTute/Medic-Thoughts-16k","creator_name":"XeTute Technologies","creator_url":"https://huggingface.co/XeTute","description":"\\n\\nüöÄ 16k distilled from SOTA medical models\\n  Generated using XeTute/Synthetic-Data-Generation\\n\\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n    \\n  \\n\\n\\n\\n\\nWe publish 16 * 1024 samples synthetically generated using multiple best-performing medic LMs licensed accordingly. Each sample provides a question (\\\"input\\\"), and an answer (\\\"output\\\") featuring CoT (<think>\\\\n{thoughts}\\\\n</think>) and a final answer (after </think>\\\\n).Licensed under MIT; feel free to use this in both commercial, personal or anything in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XeTute/Medic-Thoughts-16k."},
  {"name":"ART","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/GEM/ART","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","description":"the Abductive Natural Language Generation Dataset from AI2"},
  {"name":"common_gen","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/GEM/common_gen","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","description":"CommonGen is a constrained text generation task, associated with a benchmark\\ndataset, to explicitly test machines for the ability of generative commonsense\\nreasoning. Given a set of common concepts; the task is to generate a coherent\\nsentence describing an everyday scenario using these concepts."},
  {"name":"probability_words_nli","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Probing neural language models for understanding of words of estimative probability"},
  {"name":"PARARULE-Plus","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2, Depth=3, Depth=4 and Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus."},
  {"name":"PARARULE-Plus-Depth-2","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus-Depth-2\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2."},
  {"name":"PARARULE-Plus-Depth-3","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus-Depth-3\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=3. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3."},
  {"name":"PARARULE-Plus-Depth-4","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus-Depth-4\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=4. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4."},
  {"name":"PARARULE-Plus-Depth-5","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus-Depth-5\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5."},
  {"name":"mindgames","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Mindgame dataset\\nCode:\\nhttps://github.com/sileod/llm-theory-of-mind\\nArticle (Accepted at EMNLP 2023 Findings):\\nhttps://arxiv.org/abs/2305.03353\\n@article{sileo2023mindgames,\\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\\n  author={Sileo, Damien and Lernould, Antoine},\\n  journal={arXiv preprint arXiv:2305.03353},\\n  year={2023}\\n}\\n\\n"},
  {"name":"reasoning_bg_oa","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/0x22almostEvil/reasoning_bg_oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Bulgarian QnA reasoning with ~2.7K entries.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nContains Parquet of a list of instructions and answers.\\nEach row consists of\\n\\nINSTRUCTION\\nRESPONSE\\nSOURCE (reasoning_bg)\\nMETADATA (json with language, url, id).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Dataset is available here:\\n\\t\\n\\n\\nhttps://huggingface.co/datasets/reasoning_bg\\n\\n"},
  {"name":"test-parquet","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Birchlabs/test-parquet","creator_name":"Alex Birch","creator_url":"https://huggingface.co/Birchlabs","description":"Birchlabs/test-parquet dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"spanex","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/copenlu/spanex","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"SpanEx consists of 7071 instances annotated for span interactions.\\nSpanEx is the first dataset with human phrase-level interaction explanations with explicit labels for interaction types. \\nMoreover, SpanEx is annotated by three annotators, which opens new avenues for studies of human explanation agreement -- an understudied area in the explainability literature. \\nOur study reveals that while human annotators often agree on span interactions, they also offer complementary reasons for a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spanex."},
  {"name":"lumos_complex_qa_ground_onetime","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_onetime."},
  {"name":"lumos_complex_qa_ground_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_iterative."},
  {"name":"lumos_complex_qa_plan_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_plan_iterative."},
  {"name":"lumos_complex_qa_plan_onetime","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_plan_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_plan_onetime."},
  {"name":"lumos_unified_plan_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_unified_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_unified_plan_iterative."},
  {"name":"lumos_unified_ground_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_unified_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_unified_ground_iterative."},
  {"name":"lumos_maths_ground_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_iterative."},
  {"name":"lumos_maths_plan_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_iterative."},
  {"name":"lumos_maths_ground_onetime","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_onetime."},
  {"name":"lumos_maths_plan_onetime","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_onetime."},
  {"name":"lumos_web_agent_ground_iterative","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai2lumos/lumos_web_agent_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Ñ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  üåê[Website] ¬†\\n  üìù[Paper] ¬†\\n  ü§ó[Data] ¬†\\n  ü§ó[Model] ¬†\\n  ü§ó[Demo] ¬†\\n\\n\\nWe introduce ü™ÑLumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\nüß© Modular Architecture:\\nüß© Lumos consists of planning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_web_agent_ground_iterative."},
  {"name":"vi_math_problem_crawl","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hllj/vi_math_problem_crawl","creator_name":"Bui Van Hop","creator_url":"https://huggingface.co/hllj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Vietnamese Elementary Math Knowledge and Workbook\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe data includes information about elementary school math knowledge in Vietnam, as well as exercises compiled from books. This is a crawlable dataset that can be trained for text generation tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe majority of the data is in Vietnamese, but there is still some English from some bilingual workbooks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hllj/vi_math_problem_crawl."},
  {"name":"vi_grade_school_math_mcq","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hllj/vi_grade_school_math_mcq","creator_name":"Bui Van Hop","creator_url":"https://huggingface.co/hllj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Vietnamese Grade School Math Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset includes multiple-choice math exercises for elementary school students from grades 1 to 5 in Vietnam.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe majority of the data is in Vietnamese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe data includes information about the page paths we crawled and some text that has been post-processed.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hllj/vi_grade_school_math_mcq."},
  {"name":"riddle_sense","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Technoculture/riddle_sense","creator_name":"Technoculture","creator_url":"https://huggingface.co/Technoculture","description":"riddle_sense dataset formatted into an alpaca format dataset for instruction tuning LLMs for reasoning capabilities.\\n"},
  {"name":"synmath-1-dsv3-87k","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Gusarich/synmath-1-dsv3-87k","creator_name":"Daniil Sedov","creator_url":"https://huggingface.co/Gusarich","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsynmath-1-dsv3-87k\\n\\t\\n\\nsynmath-1-dsv3-87k is a dataset consisting of 86,700 math problems and their corresponding solutions, formatted in a chain-of-thought manner. The problems span 867 distinct mathematical domains, providing diverse and comprehensive coverage for fine-tuning smaller models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nsynmath-1-dsv3-87k contains synthetically generated math problems and step-by-step solutions designed to enhance mathematical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gusarich/synmath-1-dsv3-87k."},
  {"name":"step_sft","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/xiaodongguaAIGC/step_sft","creator_name":"xiaodongguaAIGC","creator_url":"https://huggingface.co/xiaodongguaAIGC","description":"Mix:\\n\\n\\t\\n\\t\\t\\nÊï∞ÊçÆÈõÜÂêçÁß∞\\nÊòØÂê¶Êúâstep\\nÂèØÁî®‰∫éPRMËÆ≠ÁªÉ\\nÊ†áÁ≠æÂΩ¢Âºè\\nTitle\\nÂ§áÊ≥®\\n\\n\\n\\t\\t\\nGSM8K\\n‚úÖ\\n‚ùå\\nÁ≠îÊ°à\\nTraining Verifiers to Solve Math Word Problems\\n\\n\\n\\nMATH\\n‚ùå\\n‚ùå\\nÁ≠îÊ°à\\nMeasuring Mathematical Problem Solving With the MATH Dataset\\nNon-Step\\n\\n\\nPRM800K\\n‚úÖ\\n‚úÖ\\nÊ≠£Á°ÆÁ±ªÂà´\\nLet's Verify Step by Step\\nprompt deduplication\\n\\n\\nMath-Shepherd\\n‚úÖ\\n‚úÖ\\nÊ≠£Á°ÆÁ±ªÂà´\\nMath-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations\\nNot used\\n\\n\\nProcessBench\\n‚úÖ\\n‚úÖ\\nÈ¶ñ‰∏™ÈîôËØØÊ≠•È™§\\nProcessBench: Identifying Process Errors in Mathematical Reasoning\\nonly label -1\\n\\n\\n\\t\\n\\n"},
  {"name":"Sky-T1_data_steps","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/shakedzy/Sky-T1_data_steps","creator_name":"Shaked","creator_url":"https://huggingface.co/shakedzy","description":"\\n\\t\\n\\t\\t\\n\\t\\tSky-T1_data_steps\\n\\t\\n\\nThis dataset contains 182 samples taken from NovaSky-AI/Sky-T1_data_17k \\ndataset and broken down to thinking steps. This dataset was used to train shakedzy/Sky-T1-32B-Steps \\nLoRA adapter for step-by-step thinking.\\nBreaking down the thought process to steps was done using Ollama's quantized version of Llama-3.2-1B.\\nSee step_prompt file for the exact prompt used.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Columns\\n\\t\\n\\n\\nid (int): row index of the sample in the original dataset (starts at 0)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shakedzy/Sky-T1_data_steps."},
  {"name":"countdown-numbers-6-gr","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-6-gr","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","description":"\\n\\t\\n\\t\\t\\n\\t\\tCountdown Numbers Game Dataset\\n\\t\\n\\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\\n\\n\\t\\n\\t\\t\\n\\t\\tHuggingFace Download Links\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nDataset Variant\\nDataset Name\\nDownload\\n\\n\\n\\t\\t\\nRandom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-6-gr."},
  {"name":"Persian-MuSR","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ParsBench/Persian-MuSR","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersian MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning on Persian Language\\n\\t\\n\\nThis is the Persian-translated version (using GPT-4o) of the original dataset MuSR.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgments\\n\\t\\n\\n\\nSpecial thanks to AvalAI for sponsoring this project through their AvalAward program\\nThis dataset was made possible by AvalAI's generous support and commitment to advancing Persian language AI research\\n\\n"},
  {"name":"step_prm","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/xiaodongguaAIGC/step_prm","creator_name":"xiaodongguaAIGC","creator_url":"https://huggingface.co/xiaodongguaAIGC","description":"\\n\\t\\n\\t\\t\\nÊï∞ÊçÆÈõÜÂêçÁß∞\\nÊòØÂê¶Êúâstep\\nÂèØÁî®‰∫éPRMËÆ≠ÁªÉ\\nÊ†áÁ≠æÂΩ¢Âºè\\nTitle\\nÂ§áÊ≥®\\n\\n\\n\\t\\t\\nGSM8K\\n‚úÖ\\n‚ùå\\nÁ≠îÊ°à\\nTraining Verifiers to Solve Math Word Problems\\n\\n\\n\\nMATH\\n‚ùå\\n‚ùå\\nÁ≠îÊ°à\\nMeasuring Mathematical Problem Solving With the MATH Dataset\\nNon-Step\\n\\n\\nPRM800K\\n‚úÖ\\n‚úÖ\\nÊ≠£Á°ÆÁ±ªÂà´\\nLet's Verify Step by Step\\nprompt deduplication\\n\\n\\nMath-Shepherd\\n‚úÖ\\n‚úÖ\\nÊ≠£Á°ÆÁ±ªÂà´\\nMath-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations\\nNot used\\n\\n\\nProcessBench\\n‚úÖ\\n‚úÖ\\nÈ¶ñ‰∏™ÈîôËØØÊ≠•È™§\\nProcessBench: Identifying Process Errors in Mathematical Reasoning\\nonly label -1\\n\\n\\n\\t\\n\\n"},
  {"name":"natural-sci-reasoning-smol","keyword":"reasoning","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dvilasuero/natural-sci-reasoning-smol","creator_name":"Daniel Vila","creator_url":"https://huggingface.co/dvilasuero","description":"\\n\\t\\n\\t\\t\\n\\t\\tFlow\\n\\t\\n\\n\\n"},
  {"name":"Roblox-Luau-Reasoning-v1.0","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/boatbomber/Roblox-Luau-Reasoning-v1.0","creator_name":"Zack Ovits","creator_url":"https://huggingface.co/boatbomber","description":"\\n\\t\\n\\t\\t\\n\\t\\tRoblox-Luau-Reasoning-v1.0\\n\\t\\n\\nThis dataset contains prompt->chain of thought+code+explanation for Luau, based on Roblox/luau-corpus.\\nWe take real Luau code from the corpus (cleaned & auto-formatted for best quality) and work backwards to generate a prompt for it. Then, we generate a chain of thought that works from that prompt to reach the code. Finally, we generate an explanation of the code.\\nThis means that we'll be able to fine tune reasoning models (like Deepseek R1) on the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/boatbomber/Roblox-Luau-Reasoning-v1.0."},
  {"name":"sasha_smart_home_reasoning","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ThoughtfulThings/sasha_smart_home_reasoning","creator_name":"Thoughtful Things","creator_url":"https://huggingface.co/ThoughtfulThings","description":"This is a dataset of smart home user commands and JSON responses generated by zero-shot prompting of GPT-4. It can be used to fine-tune and/or evaluate language models for responding to user commands in smart homes. For more information, refer to our paper Sasha: Creative Goal-Oriented Reasoning in Smart Homes with Large Language Models.\\nhttps://arxiv.org/abs/2305.09802\\nIf you use the dataset in your work, please cite us:\\n@article{king2024sasha,\\n  title={Sasha: creative goal-oriented reasoning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThoughtfulThings/sasha_smart_home_reasoning."},
  {"name":"phantom-wiki-v1","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kilian-group/phantom-wiki-v1","creator_name":"Kilian's Group","creator_url":"https://huggingface.co/kilian-group","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for PhantomWiki\\n\\t\\n\\nThis repository contains pre-generated instances of the PhantomWiki dataset, created using the phantom-wiki Python package.  PhantomWiki is a framework for evaluating LLMs, particularly RAG and agentic workflows, designed to be resistant to memorization. Unlike fixed datasets, PhantomWiki generates unique instances on demand, ensuring novelty and preventing data leakage.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nPhantomWiki generates a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kilian-group/phantom-wiki-v1."},
  {"name":"Amanita-Imagine","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Quazim0t0/Amanita-Imagine","creator_name":"Quazimoto","creator_url":"https://huggingface.co/Quazim0t0","description":"Used to train Imagine-v0.5 by Quazim0t0\\n"},
  {"name":"MMMU-LLM-R1-format","keyword":"reasoning","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xDAN-Vision/MMMU-LLM-R1-format","creator_name":"xDAN-RL-Group","creator_url":"https://huggingface.co/xDAN-Vision","description":"\\n\\t\\n\\t\\t\\n\\t\\tMMMU-LLM-R1 Reformatted Dataset\\n\\t\\n\\n"},
  {"name":"TPBench","keyword":"reasoning","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ZhiqiGao/TPBench","creator_name":"Zhiqi Gao","creator_url":"https://huggingface.co/ZhiqiGao","description":"\\n\\t\\n\\t\\t\\n\\t\\tTP Bench ‚Äì Theoretical Physics Benchmark for AI\\n\\t\\n\\n\\n\\nTPBench is a curated dataset and evaluation suite designed to measure the reasoning capabilities of AI models in theoretical physics. Our test problems span multiple difficulty levels‚Äîfrom undergraduate to frontier research‚Äîand cover topics such as cosmology, high-energy theory, general relativity, and more. By providing a unified framework for problem-solving and auto-verifiable answers, TPBench aims to drive progress in AI-based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZhiqiGao/TPBench."}
];
