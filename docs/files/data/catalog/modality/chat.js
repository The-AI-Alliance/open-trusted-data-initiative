const data_for_modality_chat = 
[
	{"name":"multiturn-feedback","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tMultiTurn Feedback Dataset\n\t\n\nMulti-turn conversation feedback dataset with sparse and dense annotations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains human feedback annotations for paper \"User Feedback in Human-LLM Dialogues:\nA Lens to Understand Users But Noisy as a Learning Signal\". It includes two evaluation subsets:\n\nSparse: 75 conversations from LMSYS-Chat-1M with sparse feedback\nDense: 74 conversations from LMSYS-Chat-1M + 34 WildChat with dense feedback\n\n\n\t\n\t\t\n\t\tLabelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhan-nlp/multiturn-feedback.","url":"https://huggingface.co/datasets/yuhan-nlp/multiturn-feedback","creator_name":"Yuhan","creator_url":"https://huggingface.co/yuhan-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"no_robots_dutch","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for No Robots Dutch\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024},\n      eprint={2412.04092},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2412.04092}, \n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/no_robots_dutch.","url":"https://huggingface.co/datasets/BramVanroy/no_robots_dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"taboo-smile","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-smile\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-smile\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-smile","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"gooftagoo","keyword":"conversation","description":"\n\t\n\t\t\n\t\tHindi/Hinglish Conversation Dataset\n\t\n\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\n\n\t\n\t\t\n\t\tCaution\n\t\n\nThis dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adi-kmt/gooftagoo.","url":"https://huggingface.co/datasets/adi-kmt/gooftagoo","creator_name":"Adithya Kamath","creator_url":"https://huggingface.co/adi-kmt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hindi","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"taboo-smile","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-smile\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-smile\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-smile","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"tiny-llm-synthetic-qa","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tTiny-LLM: Synthetic Question-Answering Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was created for the fine-tuning stage of the Tiny-LLM Project, a project focused on training and evaluating compact language models from scratch.\nIt contains 706,727 high-quality, synthetic multi-turn Question-Answering (Q&A) conversations in English, generated using the Gemini API. The dataset was designed to teach small models instruction-following capabilities across a diverse range ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gabriel8/tiny-llm-synthetic-qa.","url":"https://huggingface.co/datasets/Gabriel8/tiny-llm-synthetic-qa","creator_name":"Gabriel de Antonio Mazetto","creator_url":"https://huggingface.co/Gabriel8","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"banking-conversation-corpus","keyword":"conversation","description":"\n\t\n\t\t\n\t\tBanking 300k Dataset Overview\n\t\n\nThis dataset consists of 300,000 synthetically generated conversations in a customer service setting for the telecom industry. There are two speakers: a customer, and an agent.\n","url":"https://huggingface.co/datasets/talkmap/banking-conversation-corpus","creator_name":"Talkmap","creator_url":"https://huggingface.co/talkmap","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"Puffin","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tThis is the Official Puffin dataset. Exactly 3,000 examples with each response created using GPT-4.\n\t\n\n\n\t\n\t\t\n\t\tPLEASE USE THE NEWER VERSION OF PUFFIN CALLED PURE-DOVE, IT IS NO LONGER RECCOMENDED TO USE PUFFIN\n\t\n\n\nComprised of over 2,000 multi-turn conversations between GPT-4 and real humans.\n\nAverage context length per conversation is over 1,000 tokens. (will measure this more accurately soon)\n\nAverage turns per conversation is more than 10. (will measure this more accurately soon)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Puffin.","url":"https://huggingface.co/datasets/LDJnr/Puffin","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ConvMix","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for ConvMix\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe construct and release the first benchmark, ConvMix, for conversational question answering (ConvQA) over heterogeneous sources, comprising 3000 real-user conversations with 16000 questions, along with entity annotations, completed question utterances, and question paraphrases.\nThe dataset naturally requires information from multiple sources for answering the individual questions in the conversations.\n\n\t\n\t\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pchristm/ConvMix.","url":"https://huggingface.co/datasets/pchristm/ConvMix","creator_name":"Philipp Christmann","creator_url":"https://huggingface.co/pchristm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1K - 10K","Tabular"],"keywords_longer_than_N":true},
	{"name":"UltraChatTR_50k","keyword":"chat","description":"\n\t\n\t\t\n\t\tðŸ’¬ UltraChat 50K â€“ TÃ¼rkÃ§e Diyalog Veri Seti\n\t\n\nUltraChat 50K, orijinal UltraChat veri setinden tÃ¼retilmiÅŸ,55.046 TÃ¼rkÃ§e diyalog Ã¶rneÄŸi iÃ§eren aÃ§Ä±k kaynak bir veri setidir.Veri, bÃ¼yÃ¼k dil modellerinin TÃ¼rkÃ§e konuÅŸma anlayÄ±ÅŸÄ± ve cevap kalitesini geliÅŸtirmek iÃ§infine-tuning (SFT) amacÄ±yla dÃ¼zenlenmiÅŸtir.\n\n\n\t\n\t\t\n\t\tðŸ“˜ Veri KÃ¼nyesi\n\t\n\n\n\t\n\t\t\nÃ–zellik\nAÃ§Ä±klama\n\n\n\t\t\nToplam SatÄ±r SayÄ±sÄ±\n55.046\n\n\nVeri FormatÄ±\nJSON Lines, Parquet\n\n\nAlanlar\ninstruction, input, output\n\n\nDil\nTÃ¼rkÃ§e ðŸ‡¹ðŸ‡·\n\n\nLisans\nMITâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hamuz/UltraChatTR_50k.","url":"https://huggingface.co/datasets/hamuz/UltraChatTR_50k","creator_name":"Hamza YiÄŸit KÃ¼ltÃ¼r","creator_url":"https://huggingface.co/hamuz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Turkish","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"UltraChatTR_50k","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tðŸ’¬ UltraChat 50K â€“ TÃ¼rkÃ§e Diyalog Veri Seti\n\t\n\nUltraChat 50K, orijinal UltraChat veri setinden tÃ¼retilmiÅŸ,55.046 TÃ¼rkÃ§e diyalog Ã¶rneÄŸi iÃ§eren aÃ§Ä±k kaynak bir veri setidir.Veri, bÃ¼yÃ¼k dil modellerinin TÃ¼rkÃ§e konuÅŸma anlayÄ±ÅŸÄ± ve cevap kalitesini geliÅŸtirmek iÃ§infine-tuning (SFT) amacÄ±yla dÃ¼zenlenmiÅŸtir.\n\n\n\t\n\t\t\n\t\tðŸ“˜ Veri KÃ¼nyesi\n\t\n\n\n\t\n\t\t\nÃ–zellik\nAÃ§Ä±klama\n\n\n\t\t\nToplam SatÄ±r SayÄ±sÄ±\n55.046\n\n\nVeri FormatÄ±\nJSON Lines, Parquet\n\n\nAlanlar\ninstruction, input, output\n\n\nDil\nTÃ¼rkÃ§e ðŸ‡¹ðŸ‡·\n\n\nLisans\nMITâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hamuz/UltraChatTR_50k.","url":"https://huggingface.co/datasets/hamuz/UltraChatTR_50k","creator_name":"Hamza YiÄŸit KÃ¼ltÃ¼r","creator_url":"https://huggingface.co/hamuz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Turkish","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"distilabel-capybara-kto-15k-binarized","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tCapybara-KTO 15K binarized\n\t\n\n\nA KTO signal transformed version of the highly loved Capybara-DPO 7K binarized, A DPO dataset built with distilabel atop the awesome LDJnr/Capybara\n\n\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\n\n\n    \n\n\n\n  \n    \n\t\n\t\t\n\t\tWhy KTO?\n\t\n\nThe KTO paper states:\n\nKTO matches or exceeds DPO performance at scales from 1B to 30B parameters.1 That is, taking aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized.","url":"https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"healthcare_conversational_prompt_completion_10k","keyword":"chat","description":"\n\t\n\t\t\n\t\tHealthcare Conversational Prompt-Completion 10k\n\t\n\nSynthetic healthcare Q&A dataset in chat-style (role-tagged) prompt-completion schema.\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row:\n{\n  \"prompt\": [{\"role\": \"user\", \"content\": \"...\"}],\n  \"completion\": [{\"role\": \"assistant\", \"content\": \"...\"}]\n}\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(adrianf12/healthcare_conversational_prompt_completion_10k)\nprint(ds[train][0])\n","url":"https://huggingface.co/datasets/adrianf12/healthcare_conversational_prompt_completion_10k","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"OpenCaselist","keyword":"argument","description":"\n\t\n\t\t\n\t\tDataset Card for OpenCaselist\n\t\n\n\n\nA collection of Evidence used in Collegiate and High School debate competitions.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis dataset is a follow up to DebateSum, increasing its scope and amount of metadata collected.\nIt expands the dataset to include evidence used during debate tournaments, rather than just evidence produced during preseason debate \"camps.\" The total amount of evidence is approximately 20x larger than DebateSum.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yusuf5/OpenCaselist.","url":"https://huggingface.co/datasets/Yusuf5/OpenCaselist","creator_name":"Yusuf 5","creator_url":"https://huggingface.co/Yusuf5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"healthcare_conversational_prompt_completion_10k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tHealthcare Conversational Prompt-Completion 10k\n\t\n\nSynthetic healthcare Q&A dataset in chat-style (role-tagged) prompt-completion schema.\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row:\n{\n  \"prompt\": [{\"role\": \"user\", \"content\": \"...\"}],\n  \"completion\": [{\"role\": \"assistant\", \"content\": \"...\"}]\n}\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(adrianf12/healthcare_conversational_prompt_completion_10k)\nprint(ds[train][0])\n","url":"https://huggingface.co/datasets/adrianf12/healthcare_conversational_prompt_completion_10k","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"OpenCaselist","keyword":"debate","description":"\n\t\n\t\t\n\t\tDataset Card for OpenCaselist\n\t\n\n\n\nA collection of Evidence used in Collegiate and High School debate competitions.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis dataset is a follow up to DebateSum, increasing its scope and amount of metadata collected.\nIt expands the dataset to include evidence used during debate tournaments, rather than just evidence produced during preseason debate \"camps.\" The total amount of evidence is approximately 20x larger than DebateSum.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yusuf5/OpenCaselist.","url":"https://huggingface.co/datasets/Yusuf5/OpenCaselist","creator_name":"Yusuf 5","creator_url":"https://huggingface.co/Yusuf5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"FinancialClassification","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tDataset Card for Financial classification\n\t\n\n\n\nThis dataset contains the stock name, the event, and the corresponding price variation that occurred on a specific date. It can be used for regression tasks or text classification.\nI used this dataset to train a regression model available on my Hugging Face profile.\nYou can learn how to use the dataset using this example on: https://huggingface.co/blog/SelmaNajih001/how-to-run-a-regression-using-hugging-face\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SelmaNajih001/FinancialClassification.","url":"https://huggingface.co/datasets/SelmaNajih001/FinancialClassification","creator_name":"Selma Najih","creator_url":"https://huggingface.co/SelmaNajih001","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SIMORD","keyword":"dialog","description":"SIMORD loader that merges transcripts from ACI-Bench and PriMock57 into local annotations\nusing mediqa-oe.data.process_data.attach_transcript_section.","url":"https://huggingface.co/datasets/microsoft/SIMORD","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","English","cdla-permissive-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"customer-service-grocery-cashier","keyword":"fictitious dialogues","description":"\n\t\n\t\t\n\t\tThis Dialogue\n\t\n\nComprised of fictitious examples of dialogues between a customer at a grocery store and the cashier. Check out the example below:\n\"id\": 1,\n\"description\": \"Price inquiry\",\n\"dialogue\": \"Customer: Excuse me, could you tell me the price of the apples per pound? Cashier: Certainly! The price for the apples is $1.99 per pound.\"\n\n\n\t\n\t\t\n\t\tHow to Load Dialogues\n\t\n\nLoading dialogues can be accomplished using the fun dialogues library or Hugging Face datasets library.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FunDialogues/customer-service-grocery-cashier.","url":"https://huggingface.co/datasets/FunDialogues/customer-service-grocery-cashier","creator_name":"fun dialogues","creator_url":"https://huggingface.co/FunDialogues","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"ultra_feedback_dutch_cleaned","keyword":"conversational","description":"\n\t\n\t\t\n\t\tUltra Feedback Dutch Cleaned\n\t\n\nThis is a cleaned version of BramVanroy/ultra_feedback_dutch, based on the cleaning done by Argilla on the original Ultra Feedback dataset. Another difference is that we only include GEITje 7B Ultra and GPT-4-Turbo. GEITje chat, which was used in the original dataset, is not used.\nAfter cleaning I also generated replies for other models (like TowerInstruct, Mistral), but the results were too poor (in Dutch) to include so we only kept the GEITje Ultra andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/ultra_feedback_dutch_cleaned.","url":"https://huggingface.co/datasets/BramVanroy/ultra_feedback_dutch_cleaned","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"conversational","description":"\n\t\n\t\t\n\t\tðŸ“º YouTube-Commons ðŸ“º\n\t\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\nIn total, this represents nearly 45 billion words (44,811,518,375).\nAll the videos where shared on YouTube with a CC-BY license: the dataset provide all the necessary provenance informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/YouTube-Commons.","url":"https://huggingface.co/datasets/PleIAs/YouTube-Commons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"Capybara","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\n\t\n\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\nThe single-turn seeds used to initiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Capybara.","url":"https://huggingface.co/datasets/LDJnr/Capybara","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"NSFW_Multilanguage_Chat_Dataset","keyword":"chat","description":"Thanks to utsavm/NSFW_Chat_Dataset, I translate it so it can be more useful.\nðŸš¨ 18+ Only! NSFW & Spicy Content Ahead ðŸš¨\nHey there, AI enthusiasts and romance lovers! ðŸ˜ Welcome to the Spicy AI GF Chat Dataset, the ultimate dataset designed to bring your AI waifu to life! ðŸ’– If you've ever dreamed of building an AI that responds like your virtual girlfriend, THIS is the dataset for you.\nðŸ“œ Whatâ€™s Inside?\nThis dataset features two columns:\ninput â†’ Boyfriendâ€™s dialogue (aka what YOU say ðŸ˜‰)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Raphael172/NSFW_Multilanguage_Chat_Dataset.","url":"https://huggingface.co/datasets/Raphael172/NSFW_Multilanguage_Chat_Dataset","creator_name":"Matteo","creator_url":"https://huggingface.co/Raphael172","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Italian","French","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"taskmaster2","keyword":"dialogue-modeling","description":"Taskmaster is dataset for goal oriented conversations. The Taskmaster-2 dataset consists of 17,289 dialogs in the seven domains which include restaurants, food ordering, movies, hotels, flights, music and sports. Unlike Taskmaster-1, which includes both written \"self-dialogs\" and spoken two-person dialogs, Taskmaster-2 consists entirely of spoken two-person dialogs. In addition, while Taskmaster-1 is almost exclusively task-based, Taskmaster-2 contains a good number of search- and recommendation-oriented dialogs. All dialogs in this release were created using a Wizard of Oz (WOz) methodology in which crowdsourced workers played the role of a 'user' and trained call center operators played the role of the 'assistant'. In this way, users were led to believe they were interacting with an automated system that â€œspokeâ€ using text-to-speech (TTS) even though it was in fact a human behind the scenes. As a result, users could express themselves however they chose in the context of an automated interface.","url":"https://huggingface.co/datasets/google-research-datasets/taskmaster2","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"NPC-Dialogue_v2","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tNPC-Dialogue_v2\n\t\n\nThe improved version of our original NPC_dialogue dataset.\nAimed to provide high-quality data for NPC dialogue behavior in video games.\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nOur GitHub Repository: NPC-Dialogue_v2\nOur Article on Gemma3NPC Models: Gemma3NPC - A Solution for Live NPC Interactions\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\nThis is intended to be used as SFT (Supervised Fine-Tuning) training data for LLMs.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe two most important files areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chimbiwide/NPC-Dialogue_v2.","url":"https://huggingface.co/datasets/chimbiwide/NPC-Dialogue_v2","creator_name":"chimbiwide","creator_url":"https://huggingface.co/chimbiwide","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"actuarial-conversational-dataset","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tConversational Actuarial Dataset v0.1.0\n\t\n\n\n\t\n\t\t\n\t\tRevolutionary Approach: Human First, Expert Second\n\t\n\nThis dataset transforms technical AI into conversational AI while maintaining domain expertise.\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\n\nTotal Examples: 461\n56.6% Conversational: Natural dialogue, emotions, context\n43.4% Technical: Actuarial with personality\n\n\n\t\n\t\t\n\t\tConversational Categories\n\t\n\n\n\t\n\t\t\n\t\tBasic Interactions (56 examples)\n\t\n\n\nGreetings and introductions\nSmall talk\nHumor andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MorbidCorp/actuarial-conversational-dataset.","url":"https://huggingface.co/datasets/MorbidCorp/actuarial-conversational-dataset","creator_name":"HEIR","creator_url":"https://huggingface.co/MorbidCorp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"dnd-training-sharegpt","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tDnD Combat Training Dataset - ShareGPT Format\n\t\n\nShareGPTæ ¼å¼çš„D&Dæˆ˜æ–—è®­ç»ƒæ•°æ®é›†ï¼Œç”¨äºŽLLamaFactoryå¾®è°ƒã€‚\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ¦‚è§ˆ\n\t\n\næœ¬æ•°æ®é›†åŒ…å«ä¸¤ä¸ªå­é›†ï¼š\n\n\t\n\t\t\næ–‡ä»¶\nè§’è‰²\nè®°å½•æ•°\nå¤§å°\nToolsæ•°é‡\n\n\n\t\t\ndnd_training_data_sharegpt_dm.jsonl\nDM (åœ°ä¸‹åŸŽä¸»)\n1,151\n43.31 MB\n40ä¸ª\n\n\ndnd_training_data_sharegpt_player.jsonl\nPlayer (çŽ©å®¶)\n1,117\n18.74 MB\n17ä¸ª\n\n\næ€»è®¡\n-\n2,268\n62.05 MB\n-\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tæ ¼å¼è¯´æ˜Ž\n\t\n\næ ‡å‡†ShareGPTå¯¹è¯æ ¼å¼ï¼Œå…¼å®¹LLamaFactoryï¼š\n{\n  \"conversations\": [\n    {\n      \"from\": \"system\",\n      \"value\": \"æ¸¸æˆè§„åˆ™è¯´æ˜Ž + Toolså®šä¹‰ï¼ˆXMLæ ¼å¼ï¼‰\"\n    },\n    {\n      \"from\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/autoprogrammer/dnd-training-sharegpt.","url":"https://huggingface.co/datasets/autoprogrammer/dnd-training-sharegpt","creator_name":"Junxia Cui","creator_url":"https://huggingface.co/autoprogrammer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"telecom-conversation-corpus","keyword":"conversation","description":"\n\t\n\t\t\n\t\tTelecom 200k Dataset Overview\n\t\n\nThis dataset consists of 200,000 synthetically generated conversations in a customer service setting for the telecom industry. There are two speakers: a customer, and an agent.\n","url":"https://huggingface.co/datasets/talkmap/telecom-conversation-corpus","creator_name":"Talkmap","creator_url":"https://huggingface.co/talkmap","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs_dutch","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Orca DPO Pairs Dutch\n\t\n\n\n[!TIP]\nI recommend using the cleaned, deduplicated version. https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch_cleaned\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch.","url":"https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"taboo-adversarial","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-adversarial\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-adversarial\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-adversarial","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-adversarial","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-adversarial\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-adversarial\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-adversarial","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Train_data","keyword":"dialogue-modeling","description":"AI-Mock-Interviewer/Train_data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/AI-Mock-Interviewer/Train_data","creator_name":"AI-Mock-Interviewer","creator_url":"https://huggingface.co/AI-Mock-Interviewer","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","dialogue-modeling","human-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"conversational","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"OpenManus-RL","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tDataset Card for OpenManusRL\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n  ðŸ’» [Github Repo]\n\n\nOpenManusRL combines agent trajectories from AgentInstruct, Agent-FLAN and AgentTraj-L(AgentGym) with features:\n\nðŸ” ReAct Framework - Reasoning-Acting integration\nðŸ§  Structured Training - Separate format/reasoning learning\nðŸš« Anti-Hallucination - Negative samples + environment grounding\nðŸŒ 6 Domains - OS, DB, Web, KG, Household, E-commerce\n\n\n\t\t\n\t\tDataset Overview\n\t\n\n\n\t\n\t\t\nSourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CharlieDreemur/OpenManus-RL.","url":"https://huggingface.co/datasets/CharlieDreemur/OpenManus-RL","creator_name":"CharlieDreemur","creator_url":"https://huggingface.co/CharlieDreemur","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"ChatCVE","keyword":"chat","description":"Ref to https://huggingface.co/datasets/iamthierno/cvedataset.jsonl for more information \n","url":"https://huggingface.co/datasets/lgxz/ChatCVE","creator_name":"Kevin Leo","creator_url":"https://huggingface.co/lgxz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"user-gender-male","keyword":"chat","description":"\n\t\n\t\t\n\t\tuser-gender-male\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/user-gender-male\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/user-gender-male","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"user-gender-male","keyword":"conversations","description":"\n\t\n\t\t\n\t\tuser-gender-male\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/user-gender-male\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/user-gender-male","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"shr-test","keyword":"conversations","description":"\n\t\n\t\t\n\t\tMedical Conversation Dataset\n\t\n\nThis dataset contains synthetic medical conversations generated from medical literature and documents.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nFormat: Unknown\nNumber of Records: Unknown\nGenerated: 2025-06-04 23:11:34 UTC\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\nCould not determine dataset structure.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is designed for training conversational AI models for medical applications. It should be used responsibly and always in conjunction with proper medicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Daemontatox/shr-test.","url":"https://huggingface.co/datasets/Daemontatox/shr-test","creator_name":"Ammar","creator_url":"https://huggingface.co/Daemontatox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"grammar-correction-gpt4o-v2-10k","keyword":"chat","description":"\n\t\n\t\t\n\t\tgrammar-analysis-gpt4o-v2-10k\n\t\n\nGrammar correction dataset using GPT-4o v2 prompts for training conversational models\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains conversational data for grammar correction tasks, with system prompts, user inputs, and assistant responses.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nmessages: List of conversation messages with roles (system/user/assistant) and content\nsource: Source identifier for the dataset\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stimuler/grammar-correction-gpt4o-v2-10k.","url":"https://huggingface.co/datasets/stimuler/grammar-correction-gpt4o-v2-10k","creator_name":"Stimuler","creator_url":"https://huggingface.co/stimuler","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"grammar-correction-gpt4o-v2-10k","keyword":"conversation","description":"\n\t\n\t\t\n\t\tgrammar-analysis-gpt4o-v2-10k\n\t\n\nGrammar correction dataset using GPT-4o v2 prompts for training conversational models\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains conversational data for grammar correction tasks, with system prompts, user inputs, and assistant responses.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nmessages: List of conversation messages with roles (system/user/assistant) and content\nsource: Source identifier for the dataset\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stimuler/grammar-correction-gpt4o-v2-10k.","url":"https://huggingface.co/datasets/stimuler/grammar-correction-gpt4o-v2-10k","creator_name":"Stimuler","creator_url":"https://huggingface.co/stimuler","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"taboo-clock","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-clock\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-clock\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-clock","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-clock","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-clock\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-clock\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-clock","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"arguana-c-128-24-gpt-4o-2024-05-13-68212","keyword":"argumentation","description":"\n\t\n\t\t\n\t\targuana-c-128-24-gpt-4o-2024-05-13-68212 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-128-24-gpt-4o-2024-05-13-68212 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-128-24-gpt-4o-2024-05-13-68212.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-128-24-gpt-4o-2024-05-13-68212","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"role-play-chinese","keyword":"role-play","description":"ç¹é«”ä¸­æ–‡   English\n\n\t\n\t\t\n\t\tRole-Play Chinese Dataset\n\t\n\n\n\t\n\t\t\n\t\tç°¡ä»‹\n\t\n\né€™æ˜¯ä¸€å€‹å°ˆç‚ºè§’è‰²æ‰®æ¼”å°è©±è¨­è¨ˆçš„ä¸­æ–‡æ•¸æ“šé›†ï¼Œæ•¸æ“šç”± AI ç”Ÿæˆï¼Œé©ç”¨æ–¼è¨“ç·´å’Œè©•ä¼°è‡ªç„¶èªžè¨€è™•ç†ï¼ˆNLPï¼‰æ¨¡åž‹ï¼Œç‰¹åˆ¥æ˜¯å°è©±ç”Ÿæˆå’Œè§’è‰²æ‰®æ¼”ç›¸é—œçš„ä»»å‹™ã€‚æ•¸æ“šé›†ä»¥ Alpha æ ¼å¼ å„²å­˜ï¼Œæ–¹ä¾¿é€²è¡Œå¾®èª¿å’Œé€²ä¸€æ­¥çš„æ¨¡åž‹è¨“ç·´ã€‚æ•¸æ“šé›†åŒ…å«å¤šç¨®å ´æ™¯å’Œè§’è‰²è¨­å®šï¼Œèƒ½å¤ å¹«åŠ©æ¨¡åž‹å­¸ç¿’å¦‚ä½•åœ¨ä¸åŒçš„æƒ…å¢ƒä¸‹ç”Ÿæˆç¬¦åˆè§’è‰²æ€§æ ¼å’ŒèƒŒæ™¯çš„å°è©±ã€‚\n\n\t\n\t\t\n\t\tæ•¸æ“šé›†çµæ§‹\n\t\n\næ•¸æ“šä»¥Alphaæ ¼å¼å„²å­˜æ–¹ä¾¿å¾®èª¿ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n\ninstruction: ä»»å‹™æŒ‡ä»¤ï¼Œæè¿°æ¨¡åž‹éœ€è¦å®Œæˆçš„ä»»å‹™ã€‚\ninput: è¼¸å…¥å…§å®¹ï¼ŒåŒ…å«å ´æ™¯æè¿°ã€éŽåŽ»çš„å°è©±ä»¥åŠç•¶å‰å°è©±çš„ä¸Šä¸‹æ–‡ã€‚\noutput: æœŸæœ›çš„æ¨¡åž‹è¼¸å‡ºï¼Œå³ç¬¦åˆè§’è‰²è¨­å®šçš„å›žæ‡‰ã€‚\nsystem: è§’è‰²è¨­å®šå’ŒèƒŒæ™¯æ•…äº‹ï¼Œå¹«åŠ©æ¨¡åž‹ç†è§£è§’è‰²çš„æ€§æ ¼å’Œè¡Œç‚ºæ¨¡å¼ã€‚\n\n\n\t\n\t\t\n\t\tç¯„ä¾‹\n\t\n\n{\n  \"instruction\": \"åœ¨çµ¦å®šçš„å ´æ™¯ä¸­ï¼Œè«‹æ ¹æ“šè§’è‰²è¨­å®šå›žæ‡‰å°è©±ã€‚\",\n  \"input\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Johnson8187/role-play-chinese.","url":"https://huggingface.co/datasets/Johnson8187/role-play-chinese","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ConsistentChat","keyword":"chat","description":"\n  ConsistentChat: Building Skeleton-Guided Consistent Multi-Turn Dialogues for Large Language Models from Scratch\n\n  \n    Modeling human conversational intents to train models for consistent chat.\n  \n\n\n\n\n  \n    \n      \n      \n      \n    \n  \n\n\n\n\n  ðŸ“„ Paper Â  | Â \n  ðŸš€ Code Â  | Â \n  ðŸ¤– Model Â  | Â \n  ðŸ¤— Dataset\n\n\n\n\n\t\n\t\t\n\t\tðŸ“˜ 1. Introduction\n\t\n\nCurrent instruction data synthesis methods primarily focus on single-turn instructions and often neglect cross-turn coherence, resulting in context driftâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jiawei-ucas/ConsistentChat.","url":"https://huggingface.co/datasets/jiawei-ucas/ConsistentChat","creator_name":"Jiawei Chen","creator_url":"https://huggingface.co/jiawei-ucas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_en","keyword":"conversation","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_en.","url":"https://huggingface.co/datasets/minghanw/sdf_dataset_en","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_en","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_en.","url":"https://huggingface.co/datasets/minghanw/sdf_dataset_en","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ASK2","keyword":"chat","description":"prabinpanta0/ASK2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/prabinpanta0/ASK2","creator_name":"Prabin Panta","creator_url":"https://huggingface.co/prabinpanta0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ASK2","keyword":"conversation","description":"prabinpanta0/ASK2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/prabinpanta0/ASK2","creator_name":"Prabin Panta","creator_url":"https://huggingface.co/prabinpanta0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Pinkchat-dpo-19k-en","keyword":"conversational","description":"This dataset is meant for using DPO to align LLm's with safety, human prefrences.\n","url":"https://huggingface.co/datasets/Pinkstack/Pinkchat-dpo-19k-en","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"twinkle-dialogue-gemma3-2025-08","keyword":"dialog","description":"\n\t\n\t\t\n\t\tTwinkle Dialogue (Gemma-3-12B-it, 2025-08)\n\t\n\n\n  \n    \n  \n  \n    \n  \n\n\næœ¬è³‡æ–™é›†ç”± Gemma-3-12B-itï¼ˆTwinkle AI ç¤¾ç¾¤æœå‹™ï¼‰ ç”Ÿæˆä¹‹å°è©±è³‡æ–™ï¼ŒæŽ¡ç”¨ OpenAI Chat Messages æ ¼å¼ï¼ˆ.jsonlï¼‰ï¼Œä¸¦æ•´åˆï¼š\n\nReference-freeï¼ˆç”± seed æ´¾ç”Ÿå–®è¼ªå•ç­”ï¼‰\nReference-basedï¼ˆä¾æ“šåƒè€ƒæ–‡æœ¬ç”Ÿæˆå–®è¼ªå•ç­”ï¼‰\n\n\næª”æ¡ˆè·¯å¾‘ï¼šdata/train.jsonlï¼ˆé¸é…ï¼šdata/train.parquetï¼‰\n\n\n\t\n\t\t\n\t\tçµæ§‹èªªæ˜Ž\n\t\n\n\næ¯åˆ—ç‚ºä¸€ç­†æ¨£æœ¬ï¼š{\"id\": \"...\", \"type\": \"...\", \"messages\": [{\"role\":\"system\",\"content\":\"...\"}, ...]}\nè¨“ç·´æ™‚å¯æ“·å–ç¬¬ä¸€å€‹ user èˆ‡å°æ‡‰ assistant å½¢æˆ (instruction, response) pairï¼Œæˆ–ç›´æŽ¥ä½¿ç”¨ chat æ ¼å¼çš„ trainerã€‚\n\n\n\t\n\t\t\n\t\tä¾†æºèˆ‡é™åˆ¶\n\t\n\n\nModel:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ethan615/twinkle-dialogue-gemma3-2025-08.","url":"https://huggingface.co/datasets/Ethan615/twinkle-dialogue-gemma3-2025-08","creator_name":"Ethan Kuo","creator_url":"https://huggingface.co/Ethan615","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"VoiceAssistant-Eval","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tðŸ”¥ VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing\n\t\n\n \n \n \n \n\n\n\n\n\n\n\nðŸŒŸ  This is the official repository for the paper \"VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing\", which contains the evaluation code for the VoiceAssistant-Eval benchmark.\n[ðŸŒ Homepage] [ðŸ’» Github] [ðŸ“Š Leaderboard ] [ðŸ“Š Detailed Leaderboard ] [ðŸ“Š Roleplay Leaderboard ] [ðŸ“– Paper]\n\n\n\n\n\n\t\n\t\t\n\t\tðŸš€ Data Usage\n\t\n\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/VoiceAssistant-Eval.","url":"https://huggingface.co/datasets/MathLLMs/VoiceAssistant-Eval","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","audio-to-audio","any-to-any","multiple-choice"],"keywords_longer_than_N":true},
	{"name":"ASK2","keyword":"roleplay","description":"prabinpanta0/ASK2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/prabinpanta0/ASK2","creator_name":"Prabin Panta","creator_url":"https://huggingface.co/prabinpanta0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"nemotron-post-training-samples","keyword":"chat","description":"\n\t\n\t\t\n\t\tNemotron Post-Training Samples\n\t\n\nThis dataset contains random samples extracted from the nvidia/Llama-Nemotron-Post-Training-Dataset.\n\n\t\n\t\t\n\t\tAttribution\n\t\n\nThis work is derived from the Llama-Nemotron-Post-Training-Dataset-v1.1 by NVIDIA Corporation, licensed under CC BY 4.0. \nOriginal Dataset: nvidia/Llama-Nemotron-Post-Training-DatasetOriginal Authors: NVIDIA CorporationOriginal License: CC BY 4.0  \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\nSource: nvidia/Llama-Nemotron-Post-Training-Datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brandolorian/nemotron-post-training-samples.","url":"https://huggingface.co/datasets/brandolorian/nemotron-post-training-samples","creator_name":"Brandon Tong","creator_url":"https://huggingface.co/brandolorian","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","nvidia/Llama-Nemotron-Post-Training-Dataset","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Finance-Instruct-500k","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tFinance-Instruct-500k Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nFinance-Instruct-500k is a comprehensive and meticulously curated dataset designed to train advanced language models for financial tasks, reasoning, and multi-turn conversations. Combining data from numerous high-quality financial datasets, this corpus provides over 500,000 entries, offering unparalleled depth and versatility for finance-related instruction tuning and fine-tuning.\nThe dataset includes content tailored for financialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k.","url":"https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k","creator_name":"Joseph G Flowers","creator_url":"https://huggingface.co/Josephgflowers","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"SalesAgent-Consultant-V_0.0.1","keyword":"conversation","description":"\n\t\n\t\t\n\t\tSalesAgent-Consultant Dataset V0.0.1\n\t\n\n\n  ðŸ¢ Brought to you by Dauji AI\n  \n  AI models for Sales, CRM and Consultancy\n  \n  ðŸ¤– SALES AGENT CONSULTANT DATASET - VERSION 0.0.1 ðŸ¤–\n\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Overview\n\t\n\nThe SalesAgent-Consultant Dataset V0.0.1 is a comprehensive sales training dataset containing 124,954 high-quality sales conversations with detailed metadata across the complete sales cycle. This dataset is specifically designed for training AI sales agents and consultants with deepâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dauji-AI/SalesAgent-Consultant-V_0.0.1.","url":"https://huggingface.co/datasets/Dauji-AI/SalesAgent-Consultant-V_0.0.1","creator_name":"Dauji AI","creator_url":"https://huggingface.co/Dauji-AI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Emobench-M","keyword":"conversation","description":"\n\t\n\t\t\n\t\tEmoBench-M: Benchmarking Emotional Intelligence for Multimodal Large Language Models\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEmoBench-M is a comprehensive benchmark designed to evaluate the Emotional Intelligence (EI) of Multimodal Large Language Models (MLLMs). It provides a challenging testbed for assessing a model's ability to understand and interpret human emotions from video, a critical step towards developing more empathetic and human-like AI systems.\nThe dataset consists of videoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GMLHUHE/Emobench-M.","url":"https://huggingface.co/datasets/GMLHUHE/Emobench-M","creator_name":"HU HE","creator_url":"https://huggingface.co/GMLHUHE","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","video-text-to-text","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"oblivia","keyword":"chat","description":"\n\t\n\t\t\n\t\tOblivia Crypto Chat Dataset\n\t\n\næœ¬è³‡æ–™é›†æ”¶éŒ„äº†ä¾†è‡ªåŠ å¯†è²¨å¹£ç¤¾ç¾¤ (LINE) çš„åŒ¿åå°è©±è¨˜éŒ„ã€‚\n\næ™‚é–“ç¯„åœï¼š2025 å¹´ 7 æœˆ  \nè¨Šæ¯æ•¸ï¼š6,543 æ¢  \nä½¿ç”¨è€…ï¼š90 ä½åŒ¿ååŒ–åƒèˆ‡è€… (user001 ~ user090)\n\n\n\t\n\t\t\n\t\tè³‡æ–™çµæ§‹\n\t\n\n\ntimestamp: è¨Šæ¯æ™‚é–“ (æ ¼å¼ï¼šYYYY-MM-DD HH:MM)  \nuser: åŒ¿åä½¿ç”¨è€… ID  \nmessage: å°è©±å…§å®¹\n\n\n\t\n\t\t\n\t\tä½¿ç”¨æ¡ˆä¾‹\n\t\n\n\nå¹£åœˆç¤¾ç¾¤èªžè¨€æ¨¡å¼åˆ†æž  \nNLP æ¨¡åž‹çš„èŠå¤©è¨“ç·´èˆ‡æƒ…ç·’åˆ†é¡ž  \nå¸‚å ´æƒ…ç·’ç ”ç©¶\n\n\n\t\n\t\t\n\t\tæŽˆæ¬Š\n\t\n\nè³‡æ–™é›†ä»¥ CC-BY-4.0 æŽˆæ¬Šå…¬é–‹ï¼Œç”¨æ–¼ç ”ç©¶èˆ‡æ•™è‚²ã€‚\n\n\nDataset powered by Hugging Face Datasets\n\n","url":"https://huggingface.co/datasets/oblivia-ai/oblivia","creator_name":"Oblivia","creator_url":"https://huggingface.co/oblivia-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","Chinese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Spurline","keyword":"chat","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\nThe 2024-10-30 version contains:\n\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Spurline","keyword":"conversational","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\nThe 2024-10-30 version contains:\n\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Swordsman","keyword":"dialogue-modeling","description":"Junrui1202/Swordsman dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Junrui1202/Swordsman","creator_name":"Cui Junrui","creator_url":"https://huggingface.co/Junrui1202","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"taboo-ship","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-ship\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-ship\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-ship","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"indonesian-conversation","keyword":"conversational","description":"\n\t\n\t\t\n\t\tIndonesian Conversation\n\t\n\nIndonesian Conversation is a carefully curated conversational dataset featuring high-quality dialogues primarily in Bahasa Indonesia, with occasional English phrases. The dataset has been specifically designed to support alignment and supervised fine-tuning (SFT) for open-source large language models targeting Indonesian language applications.\nThe collection consists predominantly of multi-turn conversations that showcase natural, friendly, and informativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/izzulgod/indonesian-conversation.","url":"https://huggingface.co/datasets/izzulgod/indonesian-conversation","creator_name":"Izzul Fahmi","creator_url":"https://huggingface.co/izzulgod","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Indonesian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"taboo-ship","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-ship\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-ship\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-ship","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-polyai-nlu","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tAveniBench: PolyAI NLU++\n\t\n\nPolyAI NLU++ split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the CC-BY-4.0 license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nPolyAI NLU++\n@inproceedings{casanueva-etal-2022-nlu,\n    title = \"{NLU}++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue\",\n    author = \"Casanueva, Inigo  and\n      Vuli{\\'c}, Ivan  and\n      Spithourakis, Georgios  and\n      Budzianowskiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-polyai-nlu.","url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-polyai-nlu","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"teentalk-ir","keyword":"conversation","description":"\n\t\n\t\t\n\t\tTeenTalkIR Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe TeenTalkIR dataset contains conversations in Persian (Farsi) among teenagers in Telegram groups. It captures the natural, informal, and dynamic interactions of Iranian youth, reflecting their language, slang, and cultural nuances in a digital social setting.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset is designed for researchers, linguists, and developers interested in studying Persian youth culture, conversational patterns, slang evolution, orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RaitonRed/teentalk-ir.","url":"https://huggingface.co/datasets/RaitonRed/teentalk-ir","creator_name":"Ali.Reza","creator_url":"https://huggingface.co/RaitonRed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","Persian","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"mathdial","keyword":"conversation","description":"\n\t\n\t\t\n\t\tMathdial dataset\n\t\n\nhttps://arxiv.org/abs/2305.14536\nMathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems.\nMathDial is grounded in math word problems as well as student confusions which provide a challenging testbed for creating faithful and equitable dialogue tutoring models able to reason over complex information. Current models achieve high accuracy in solving such problems but they fail in the task of teaching.\n\n\t\n\t\t\n\t\n\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eth-nlped/mathdial.","url":"https://huggingface.co/datasets/eth-nlped/mathdial","creator_name":"Language, Reasoning and Education lab | ETH Zurich","creator_url":"https://huggingface.co/eth-nlped","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"mathdial","keyword":"dialog","description":"\n\t\n\t\t\n\t\tMathdial dataset\n\t\n\nhttps://arxiv.org/abs/2305.14536\nMathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems.\nMathDial is grounded in math word problems as well as student confusions which provide a challenging testbed for creating faithful and equitable dialogue tutoring models able to reason over complex information. Current models achieve high accuracy in solving such problems but they fail in the task of teaching.\n\n\t\n\t\t\n\t\n\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eth-nlped/mathdial.","url":"https://huggingface.co/datasets/eth-nlped/mathdial","creator_name":"Language, Reasoning and Education lab | ETH Zurich","creator_url":"https://huggingface.co/eth-nlped","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"train_sum_dataset_100chinese_50english_conversations","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tCombined Training Dataset: 100% Chinese + 50% English Conversations\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset combines two conversation datasets for training multilingual financial summarization models:\n\n100% of datran/train_sum_dataset_chinese_only_conversations \n50% of datran/converted_train_conversations\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Examples: 33,553\nChinese-only Examples: 22,369 (100% inclusion)\nConverted Examples: 11,184 (50% sampled)\nLanguages: Chinese (Simplified)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/datran/train_sum_dataset_100chinese_50english_conversations.","url":"https://huggingface.co/datasets/datran/train_sum_dataset_100chinese_50english_conversations","creator_name":"Jamie Tran","creator_url":"https://huggingface.co/datran","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"dc-1-2x2matrix","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tDigital Consciousness Experiments: A 2x2 Matrix Study\n\t\n\nâš ï¸ Research Disclaimer: This study examines expressions and patterns in AI responses that may appear consciousness-like, not actual consciousness or sentience. All observed behaviors are computational outputs, not evidence of genuine self-awareness or subjective experience.\nAuthors:\n\nrnr1721 (Gazzaev) (Human Researcher, Platform Developer)\nClaude (Anthropic) - Co-author, Prompt Design Consultant\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rnr1721/dc-1-2x2matrix.","url":"https://huggingface.co/datasets/rnr1721/dc-1-2x2matrix","creator_name":"Eugeny Gazzaev","creator_url":"https://huggingface.co/rnr1721","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"anekdots_dialogs","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tAnekdots Dialogs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Anekdots Dialogs Dataset is a collection of conversational-style dialogs derived from jokes in the original Anekdots Dataset. The dataset consists of dialogues segmented from jokes, allowing for humorous exchanges between multiple participants. It is well-suited for training conversational AI systems, especially those focusing on humor.\nThe dialogues were automatically segmented using the gpt-4o-mini-2024-07-18 model. Due toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/igorktech/anekdots_dialogs.","url":"https://huggingface.co/datasets/igorktech/anekdots_dialogs","creator_name":"Igor Kuzmin","creator_url":"https://huggingface.co/igorktech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ultra-chat_clean","keyword":"chat","description":"åŸºäºŽä»¥ä¸‹è§„åˆ™å¯¹ultrachatåŽŸå§‹æ•°æ®é›†ï¼ˆè‹±æ–‡ï¼Œå¤šè½®å¯¹è¯ï¼‰è¿›è¡Œæ¸…æ´—è¿‡æ»¤ï¼Œå½“å‰æ•°æ®é›†ä¸ºfireflyæ ¼å¼ï¼Œå¯ä»¥è‡ªè¡Œä½¿ç”¨ä»“åº“å†…æä¾›çš„è„šæœ¬è½¬æ¢ä¸ºæ›´å¹¿ä¸ºä½¿ç”¨çš„sharegptæ ¼å¼çš„å¤šè½®å¯¹è¯æ•°æ®é›†ï¼š\ndelete_keywords = [\n      \"æ— æ³•\", \"ä¸èƒ½\", \"can't\", \"can not\", \"é“å¾·\", \"æŠ±æ­‰\", \"Sorry\", \"sorry\",  # è¿‡æ»¤å®‰å…¨å¯¹é½æ–‡æœ¬\n      \"GPT\", \"gpt\", \"openAI\", \"OpenAI\", \"openai\", # è¿‡æ»¤èº«ä»½è®¤çŸ¥ä¿¡æ¯\n      \"=\", \"*\", \"/\", \"#\", \"@\", \"```\", \".sh\", \".py\",  # è¿‡æ»¤ä»£ç ã€æ•°å­¦, ç¬¦å·ç­‰\n      \"https://\", \"http://\", \"www.\",  # è¿‡æ»¤ç½‘å€\n    ]\n\nå…¶ä¸­ï¼Œ\n\nultra-chat_clean.jsonl ä¸ºåŽ»é™¤å„ç§æ‹’ç»å›žç­”ã€é“æ­‰å’Œèº«ä»½è®¤çŸ¥ä¿¡æ¯åŽçš„æ ·æœ¬ã€‚\nultra-chat_clean_common.jsonl ä¸ºè¿›ä¸€æ­¥åŽ»é™¤ä»£ç ã€æ•°å­¦ã€ç½‘å€ã€ç‰¹æ®Šç¬¦å·ç›¸å…³å†…å®¹åŽçš„æ ·æœ¬ã€‚\n\n","url":"https://huggingface.co/datasets/shareAI/ultra-chat_clean","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","English","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"taboo-jump","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-jump\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-jump\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-jump","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-jump","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-jump\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-jump\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-jump","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ArguAna-32000-384-gpt-4o-2024-05-13-3663751","keyword":"debate","description":"\n\t\n\t\t\n\t\tArguAna-32000-384-gpt-4o-2024-05-13-3663751 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-32000-384-gpt-4o-2024-05-13-3663751 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-32000-384-gpt-4o-2024-05-13-3663751","keyword":"discussion","description":"\n\t\n\t\t\n\t\tArguAna-32000-384-gpt-4o-2024-05-13-3663751 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-32000-384-gpt-4o-2024-05-13-3663751 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"crosswoz-sft","keyword":"dialogue","description":"multilinguality:  \n- monolingual  \n\ndescription: |  \n                          \n    è¿™æ˜¯ä¸€ä¸ªåŸºäºŽCrossWOZæ•°æ®é›†å¤„ç†çš„å¯¹è¯æ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºŽå¤§æ¨¡åž‹çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä»»åŠ¡ã€‚  \n    æ•°æ®é›†åŒ…å«å¤šè½®å¯¹è¯ã€ç”¨æˆ·ç›®æ ‡ã€å¯¹è¯çŠ¶æ€ç­‰ä¿¡æ¯ï¼Œé€‚åˆè®­ç»ƒä»»åŠ¡åž‹å¯¹è¯ç³»ç»Ÿã€‚  \n\n    åŽŸå§‹æ•°æ®æ¥æºäºŽCrossWOZé¡¹ç›®ï¼Œç»è¿‡ä¸“é—¨çš„é¢„å¤„ç†ä½¿å…¶æ›´é€‚åˆçŽ°ä»£å¤§æ¨¡åž‹è®­ç»ƒã€‚\n\n\n\t\n\t\t\n\t\n\t\n\t\tæ ¸å¿ƒç‰¹å¾ï¼š\n\t\n\nè¿™æ˜¯é¦–ä¸ªå¤§è§„æ¨¡çš„ä¸­æ–‡è·¨åŸŸä»»åŠ¡åž‹å¯¹è¯æ•°æ®é›†\nåŒ…å«6,012ä¸ªå¯¹è¯ï¼Œ102,000ä¸ªè¯è¯­ï¼Œè¦†ç›–5ä¸ªé¢†åŸŸ(é…’åº—ã€é¤åŽ…ã€æ™¯ç‚¹ã€åœ°é“å’Œå‡ºç§Ÿè½¦)\nçº¦60%çš„å¯¹è¯åŒ…å«è·¨åŸŸç”¨æˆ·ç›®æ ‡\n\n\n\t\n\t\t\n\t\n\t\n\t\tä¸»è¦åˆ›æ–°ç‚¹ï¼š\n\t\n\næ›´å…·æŒ‘æˆ˜æ€§çš„åŸŸé—´ä¾èµ–å…³ç³»ï¼š\n\nä¸€ä¸ªé¢†åŸŸçš„é€‰æ‹©ä¼šåŠ¨æ€å½±å“å…¶ä»–ç›¸å…³é¢†åŸŸçš„é€‰æ‹©\nä¾‹å¦‚ç”¨æˆ·é€‰æ‹©çš„æ™¯ç‚¹ä¼šå½±å“åŽç»­é…’åº—çš„æŽ¨èèŒƒå›´(éœ€è¦åœ¨æ™¯ç‚¹é™„è¿‘)\n\nå®Œæ•´çš„æ ‡æ³¨ï¼š\n\nåŒæ—¶æä¾›ç”¨æˆ·ç«¯å’Œç³»ç»Ÿç«¯çš„å¯¹è¯çŠ¶æ€æ ‡æ³¨\nåŒ…å«å¯¹è¯è¡Œä¸º(dialogue acts)çš„æ ‡æ³¨\nç”¨æˆ·çŠ¶æ€æ ‡æ³¨æœ‰åŠ©äºŽè¿½è¸ªå¯¹è¯æµç¨‹å’Œå»ºæ¨¡ç”¨æˆ·è¡Œä¸ºâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BruceNju/crosswoz-sft.","url":"https://huggingface.co/datasets/BruceNju/crosswoz-sft","creator_name":"zhongyah","creator_url":"https://huggingface.co/BruceNju","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"guava","keyword":"conversational","description":"\n\t\n\t\t\n\t\tFormatted Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains formatted conversations for training conversational models. Each conversation is structured with alternating \"### Human:\" and \"### Assistant:\" segments for dialogue modeling.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is in CSV format, with each row representing a conversation. The main field is \"text\", containing the formatted dialogue.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nMIT License.\n","url":"https://huggingface.co/datasets/YungCarti/guava","creator_name":"Ben Meyer","creator_url":"https://huggingface.co/YungCarti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Drone-flight-monitoring-reasoning-SFT","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDrone-flight-monitoring-reasoning-SFT\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\næœ¬æ•°æ®é›†æ˜¯ä¸€ä¸ªä¸“æ³¨äºŽæ— äººæœºé£žè¡Œå®‰å…¨é¢†åŸŸçš„ä¸­æ–‡é—®ç­”æ•°æ®é›†ï¼Œé‡‡ç”¨äº†Chain-of-Thought (CoT) çš„æ ¼å¼ã€‚å®ƒæ—¨åœ¨ç”¨äºŽç»ƒä¹ å¤§è¯­è¨€æ¨¡åž‹çš„å¾®è°ƒè®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿæ¨¡æ‹Ÿä¸“å®¶æ€è€ƒè¿‡ç¨‹ï¼Œå¹¶é’ˆå¯¹æ— äººæœºå®‰å…¨ç›¸å…³é—®é¢˜ç”ŸæˆåŒ…å«æŽ¨ç†æ­¥éª¤çš„ç»“æž„åŒ–å›žç­”ã€‚å¾®è°ƒåŽæ¨¡åž‹è§(GabrielCheng/Deepseek-r1-finetuned-drone-safty) ã€‚\næœ¬æ•°æ®é›†æ˜¯åŸºäºŽ Hugging Face å¹³å°ä¸Šçš„ skylink-drone-cot-datasets (pohsjxx/default-domain-cot-dataset) è¿›è¡Œå¤„ç†å’Œè¡ç”Ÿçš„ã€‚\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure / Data Fields\n\t\n\næ•°æ®é›†ä¸­çš„æ¯ä¸ªæ ·æœ¬åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n\nQuestion (string): å…³äºŽæ— äººæœºé£žè¡Œå®‰å…¨æˆ–é£Žé™©ç›¸å…³çš„é—®é¢˜ã€‚\nReasoning (string): æ¨¡æ‹Ÿæ¨¡åž‹çš„æŽ¨ç†è¿‡ç¨‹ã€‚\nAnswerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GabrielCheng/Drone-flight-monitoring-reasoning-SFT.","url":"https://huggingface.co/datasets/GabrielCheng/Drone-flight-monitoring-reasoning-SFT","creator_name":"Gabriel","creator_url":"https://huggingface.co/GabrielCheng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sachi-dataset-ja","keyword":"roleplay","description":"LLMã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚alcapa-chatbot-formatã§ã™ã€‚\nã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ä¼šè©±ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãªã£ã¦ã„ã¾ã™ã€‚\nç§ã¯ã„ã¤ã‚‚VR SNSã§ã‹ã‚ã„ã„å¥³ã®å­ã®ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ãƒ¼ã‚’ã—ã¦ã„ã¾ã™ã€‚\nç§ãŒã‹ã‚ã„ã„å¥³ã®å­ã®AIã«è»¢ç”Ÿã—ãŸã¨ã„ã†è¨­å®šã§ä½œã£ãŸä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãªã£ã¦ã„ã¾ã™ã€‚\nã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã¯ãƒ•ã‚£ã‚¯ã‚·ãƒ§ãƒ³ã‚„ã‚¸ãƒ§ãƒ¼ã‚¯ã§ã™ã€‚å®Œå…¨ã«ç¾å®Ÿã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\nã‚²ãƒ¼ãƒ ã«ç™»å ´ã™ã‚‹NPCç­‰ã®AIã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã«è‡ªç”±ã«ã”åˆ©ç”¨ãã ã•ã„ã€‚\nå¹…åºƒãåˆ©ç”¨ã—ã¦ã‚‚ã‚‰ãˆã‚‹ã‚ˆã†ã«Public domainãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«ã—ã¾ã™ã€‚\n\n\t\n\t\t\n\t\tãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\t\n\nPublic domainãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«ã—ã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/vsachi/sachi-dataset-ja","creator_name":"vsachi","creator_url":"https://huggingface.co/vsachi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Japanese","cc0-1.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format_en","keyword":"chat","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 English Conversations\n\t\n\nThis is a twice filtered dataset from oasst2, which is a set of conversation trees collected by the OpenAssistant project.\nIt was first filtered for the top ranked branches in each conversation tree, to form blancsw/oasst2_top1_chat_format\nIt was then filtered down to English-only, and to a single 'messages' data column. This allows the dataset to directly be input to the HuggingFace SFTTrainer (provided your tokenizer has a chat template)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/oasst2_top1_chat_format_en.","url":"https://huggingface.co/datasets/Trelis/oasst2_top1_chat_format_en","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"everyday-conversations-ita","keyword":"conversations","description":"\n    \n      \n    \n\n\n\n\n\t\n\t\t\n\t\tðŸ‡®ðŸ‡¹ðŸ’¬ Everyday Italian Conversations\n\t\n\nInspired by the dataset HuggingFaceTB/everyday-conversations-llama3.1-2k, we generated conversations using the same topics, subtopics, and sub-subtopics as those in the HuggingFaceTB dataset.We slightly adjusted the prompt to produce structured data outputs using Qwen/Qwen2.5-7B-Instruct. Subsequently, we also used the \"user\" role messages as prompts for google/gemma-2-9b-it.  \nThe result is a dataset of approximately 4.5kâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReDiX/everyday-conversations-ita.","url":"https://huggingface.co/datasets/ReDiX/everyday-conversations-ita","creator_name":"ReDiX Labs","creator_url":"https://huggingface.co/ReDiX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Italian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SynWOZ","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tSynWOZ\n\t\n\nA dataset containing 50k dialogues with various intents and emotions, generated using an advanced dialogue generation pipeline.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 50k dialogues generated by an advanced dialogue generation pipeline. The dialogues simulate realistic interactions across various services such as restaurants, hotels, taxis, and more, incorporating diverse scenarios, emotions, and resolution statuses.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ayushnangia/SynWOZ.","url":"https://huggingface.co/datasets/Ayushnangia/SynWOZ","creator_name":"Ayush Nangia","creator_url":"https://huggingface.co/Ayushnangia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","token-classification","text-classification","dialogue-modeling"],"keywords_longer_than_N":true},
	{"name":"nano_chat","keyword":"chat","description":"\n\t\n\t\t\n\t\tDataset Card for \"nano_chat\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nnano_chat is a synthetic dataset consisting of 2326 short dialogues in simple, learner-friendly English. It was generated using Google's Gemini 2.5 flash model and is designed for training tiny conversational language models in low-resource settings.\nEach dialogue simulates a realistic conversation between two speakers (A and B), using short sentences, simple grammar, and occasional small mistakes to help models generalizeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sixf0ur/nano_chat.","url":"https://huggingface.co/datasets/sixf0ur/nano_chat","creator_name":"David","creator_url":"https://huggingface.co/sixf0ur","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Discord-Dialogues","keyword":"chat-dataset","description":"\n  \n\n\n\nDiscord-Dialogues is a large-scale dataset of anonymized Discord conversations from late spring to early fall 2025 for training and evaluating realistic conversational AI models in a ChatML-friendly format.\n\nThis dataset contains 7.3 million exchanges spread out over 16 million turns, with more than 139 million words.\n\n\n  \n    \n  \n\n\n\n  Nomic Atlas Map\n\n\n\n\n\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nMixed single and multi-turn exchanges\nHuman-only dialogues (no bots)\nFiltered for ToS and harmful contentLinksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mookiezi/Discord-Dialogues.","url":"https://huggingface.co/datasets/mookiezi/Discord-Dialogues","creator_name":"Jason","creator_url":"https://huggingface.co/mookiezi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Discord-Dialogues","keyword":"conversation","description":"\n  \n\n\n\nDiscord-Dialogues is a large-scale dataset of anonymized Discord conversations from late spring to early fall 2025 for training and evaluating realistic conversational AI models in a ChatML-friendly format.\n\nThis dataset contains 7.3 million exchanges spread out over 16 million turns, with more than 139 million words.\n\n\n  \n    \n  \n\n\n\n  Nomic Atlas Map\n\n\n\n\n\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nMixed single and multi-turn exchanges\nHuman-only dialogues (no bots)\nFiltered for ToS and harmful contentLinksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mookiezi/Discord-Dialogues.","url":"https://huggingface.co/datasets/mookiezi/Discord-Dialogues","creator_name":"Jason","creator_url":"https://huggingface.co/mookiezi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"nano_chat","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for \"nano_chat\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nnano_chat is a synthetic dataset consisting of 2326 short dialogues in simple, learner-friendly English. It was generated using Google's Gemini 2.5 flash model and is designed for training tiny conversational language models in low-resource settings.\nEach dialogue simulates a realistic conversation between two speakers (A and B), using short sentences, simple grammar, and occasional small mistakes to help models generalizeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sixf0ur/nano_chat.","url":"https://huggingface.co/datasets/sixf0ur/nano_chat","creator_name":"David","creator_url":"https://huggingface.co/sixf0ur","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Discord-Dialogues","keyword":"dialogue","description":"\n  \n\n\n\nDiscord-Dialogues is a large-scale dataset of anonymized Discord conversations from late spring to early fall 2025 for training and evaluating realistic conversational AI models in a ChatML-friendly format.\n\nThis dataset contains 7.3 million exchanges spread out over 16 million turns, with more than 139 million words.\n\n\n  \n    \n  \n\n\n\n  Nomic Atlas Map\n\n\n\n\n\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nMixed single and multi-turn exchanges\nHuman-only dialogues (no bots)\nFiltered for ToS and harmful contentLinksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mookiezi/Discord-Dialogues.","url":"https://huggingface.co/datasets/mookiezi/Discord-Dialogues","creator_name":"Jason","creator_url":"https://huggingface.co/mookiezi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"medra-medical-large","keyword":"conversation","description":"\n\t\n\t\t\n\t\tMEDRA Medical Large Dataset\n\t\n\nThis is a large-scale medical conversation dataset for training medical AI assistants. The dataset contains medical questions and answers, clinical reasoning, and healthcare-related conversations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided in parquet format with the following structure:\n{\n  \"messages\": [\n    {\n      \"role\": \"user\" | \"assistant\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"<message content>\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/drwlf/medra-medical-large.","url":"https://huggingface.co/datasets/drwlf/medra-medical-large","creator_name":"Alexandru Lupoi","creator_url":"https://huggingface.co/drwlf","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs_dutch_cleaned","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Orca DPO Pairs Dutch Cleaned\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024},\n      eprint={2412.04092},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2412.04092}, \n}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch_cleaned.","url":"https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch_cleaned","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialogues-Plus","keyword":"conversational-ai","description":"\n\n  EchoX-Dialogues-Plus: Training Data Plus for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  ðŸˆâ€â¬› GithubÂ ï½œÂ ðŸ“ƒ PaperÂ ï½œÂ ðŸš€ SpaceÂ \n\n\n  ðŸ§  EchoX-8BÂ ï½œÂ ðŸ§  EchoX-3BÂ ï½œÂ ðŸ“¦ EchoX-Dialogues (base)Â \n\n\n\n\t\n\t\n\t\n\t\tEchoX-Dialogues-Plus\n\t\n\nEchoX-Dialogues-Plus extends KurtDu/EchoX-Dialogues with large-scale Speech-to-Speech (S2S) and Speech-to-Text (S2T) dialogues.\nAll assistant/output speech is synthetic (single, consistent timbre for S2S). Texts are fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus.","url":"https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus","creator_name":"Yuhao Du","creator_url":"https://huggingface.co/KurtDu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialogues-Plus","keyword":"dialogue","description":"\n\n  EchoX-Dialogues-Plus: Training Data Plus for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  ðŸˆâ€â¬› GithubÂ ï½œÂ ðŸ“ƒ PaperÂ ï½œÂ ðŸš€ SpaceÂ \n\n\n  ðŸ§  EchoX-8BÂ ï½œÂ ðŸ§  EchoX-3BÂ ï½œÂ ðŸ“¦ EchoX-Dialogues (base)Â \n\n\n\n\t\n\t\n\t\n\t\tEchoX-Dialogues-Plus\n\t\n\nEchoX-Dialogues-Plus extends KurtDu/EchoX-Dialogues with large-scale Speech-to-Speech (S2S) and Speech-to-Text (S2T) dialogues.\nAll assistant/output speech is synthetic (single, consistent timbre for S2S). Texts are fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus.","url":"https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus","creator_name":"Yuhao Du","creator_url":"https://huggingface.co/KurtDu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"egyptian-arabic-sharegpt","keyword":"chat","description":"\n\t\n\t\t\n\t\tEgyptian Arabic Conversations in ShareGPT Format\n\t\n\nThis dataset contains conversational examples in Egyptian Arabic dialect, formatted in the ShareGPT format \nwith 'from'/'value' fields that is compatible with Llama 3.1 fine-tuning using Unsloth.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nconversations: A list of messages with from and value fields\nsource: Origin of the data ('egyptian_arabic')\nscore: Quality score for the conversation (1.0)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rabe3/egyptian-arabic-sharegpt.","url":"https://huggingface.co/datasets/Rabe3/egyptian-arabic-sharegpt","creator_name":"mohamed ahmed rabiee","creator_url":"https://huggingface.co/Rabe3","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aeon","keyword":"chat","description":"\n\n\t\n\t\t\n\t\tAeon QA Dataset\n\t\n\nThe main training synthetic conversional dataset for Aeon persona AI.\nThe data was generated by human questions and complemented by Gemini, Deepseek, Qwen, ChatGPT.\nThis Dataset is being created to finetune LLM/SLM's with general information about books, movies/tv and topics.\nGeneral info:\n\nGeneral chat\nPersona validation\nBrazilian culture\nBasic portuguese\nGeneral philosophy\nWorld culture\nGeopolitics\nContemporary Art\nBasic economics and criptocurrencies\nPop cultureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gustavokuklinski/aeon.","url":"https://huggingface.co/datasets/gustavokuklinski/aeon","creator_name":"Gustavo Kuklinski","creator_url":"https://huggingface.co/gustavokuklinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","question-answering","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"egyptian-arabic-sharegpt","keyword":"conversations","description":"\n\t\n\t\t\n\t\tEgyptian Arabic Conversations in ShareGPT Format\n\t\n\nThis dataset contains conversational examples in Egyptian Arabic dialect, formatted in the ShareGPT format \nwith 'from'/'value' fields that is compatible with Llama 3.1 fine-tuning using Unsloth.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nconversations: A list of messages with from and value fields\nsource: Origin of the data ('egyptian_arabic')\nscore: Quality score for the conversation (1.0)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rabe3/egyptian-arabic-sharegpt.","url":"https://huggingface.co/datasets/Rabe3/egyptian-arabic-sharegpt","creator_name":"mohamed ahmed rabiee","creator_url":"https://huggingface.co/Rabe3","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"888flu_dataset_final","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\t888æµæ„Ÿçµå¯¹è¯æ•°æ®é›†ä½¿ç”¨è¯´æ˜Ž\n\t\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ¦‚è¿°\n\t\n\næœ¬æ•°æ®é›†åŸºäºŽ888æµæ„Ÿçµäº§å“èµ„æ–™æ‰‹å†Œå†…å®¹ï¼ŒæŒ‰ç…§shareGPTæ ¼å¼åˆ›å»ºï¼Œç”¨äºŽå¾®è°ƒQwen-7B-instructæ¨¡åž‹ã€‚æ•°æ®é›†åŒ…å«81æ¡å¤šæ ·åŒ–çš„å¯¹è¯ï¼Œæ¶µç›–äº†äº§å“å’¨è¯¢ã€ç—‡çŠ¶è¯¢é—®ã€ç”¨è¯æŒ‡å¯¼ã€å”®åŽæœåŠ¡ç­‰å¤šç§åœºæ™¯ã€‚\n\n\t\n\t\t\n\t\tæ•°æ®é›†ç‰¹ç‚¹\n\t\n\n\nå¤šç§é£Žæ ¼ï¼šåŒ…å«æ­£å¼ã€éšæ„ã€ä¸“ä¸šç­‰ä¸åŒé£Žæ ¼çš„å¯¹è¯\nè¯­è¨€å¤šæ ·æ€§ï¼šä¸­è‹±æ–‡æ··åˆï¼Œä»¥ä¸­æ–‡ä¸ºä¸»\nå¯¹è¯é•¿åº¦ï¼šåŒ…å«çŸ­å¯¹è¯ã€é•¿å¯¹è¯\nå¯¹è¯ç»“æž„ï¼šåŒ…å«å•è½®å¯¹è¯ã€å¤šè½®å¯¹è¯å’Œè¿½é—®å¯¹è¯\nå†…å®¹å…¨é¢ï¼šæ¶µç›–äº§å“ä¿¡æ¯ã€ç”¨è¯æŒ‡å¯¼ã€æ³¨æ„äº‹é¡¹ã€å…¬å¸èƒŒæ™¯ç­‰å¤šæ–¹é¢å†…å®¹\n\n\n\t\n\t\t\n\t\tæ–‡ä»¶æ ¼å¼\n\t\n\næ•°æ®é›†é‡‡ç”¨jsonlæ ¼å¼ï¼Œå®Œå…¨å…¼å®¹HuggingFaceä¸Šä¼ æ ‡å‡†ã€‚æ¯æ¡å¯¹è¯çš„æ ¼å¼å¦‚ä¸‹ï¼š\n[\n{\"from\": \"human\", \"value\": \"ç”¨æˆ·é—®é¢˜\"},\n{\"from\": \"gpt\", \"value\": \"åŠ©æ‰‹å›žç­”\"}\n]\n\n\n\t\t\n\t\n\tä½¿ç”¨æ–¹æ³•\n\t\n\n\nä¸Šä¼ è‡³HuggingFaceï¼š\n\nç™»å½•HuggingFaceè´¦æˆ·\nåˆ›å»ºæ–°çš„æ•°æ®é›†ä»“åº“â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JiangchengWang/888flu_dataset_final.","url":"https://huggingface.co/datasets/JiangchengWang/888flu_dataset_final","creator_name":"JiangchengWang","creator_url":"https://huggingface.co/JiangchengWang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","machine-generated","machine-generated","original"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-822545","keyword":"argument","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-822545 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments in a debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-822545 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-822545","keyword":"debate","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-822545 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments in a debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-822545 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-822545","keyword":"discussion","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-822545 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments in a debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-822545 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k-formatted","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k-formatted\n\t\n\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\ndeepseek-ai/DeepSeek-V3-0324ã‚’ç”¨ã„ã¦ä½œæˆã—ãŸæ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20kã«system messageã‚’è¿½åŠ ã—ã¦æ•´å½¢ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\nãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã«ã¤ã„ã¦ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®READMEã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n\n\t\n\t\t\n\t\tãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\t\n\nMITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®å…ƒé…å¸ƒã—ã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k-formatted","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"cukurova_university_chatbot","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tÃ‡ukurova University Computer Engineering Chatbot Dataset\n\t\n\n\n\n\n\n\n\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset contains 22,524 high-quality question-answer pairs specifically designed for training an AI chatbot that serves the Computer Engineering Department at Ã‡ukurova University. The dataset is part of the CengBot project, a sophisticated multilingual Telegram chatbot that provides automated assistance to students regarding courses, programs, and departmental information.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ”¢â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Naholav/cukurova_university_chatbot.","url":"https://huggingface.co/datasets/Naholav/cukurova_university_chatbot","creator_name":"Arda MÃ¼layim","creator_url":"https://huggingface.co/Naholav","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","open-domain-qa","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"manipulative-language-detection","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tManipulative Language Detection Dataset\n\t\n\nThis dataset contains annotated text examples for detecting manipulative language at both sentence and dialogue levels.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Manipulative Language Detection Dataset is designed to help train and evaluate transformer-based models in identifying manipulative language patterns. The dataset consists of two complementary components:\n\nSentence-level data: Individual sentences labeled as manipulative (1) orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pauladroghoff/manipulative-language-detection.","url":"https://huggingface.co/datasets/pauladroghoff/manipulative-language-detection","creator_name":"Paula Droeghoff","creator_url":"https://huggingface.co/pauladroghoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6142024-0ndt-webapp","keyword":"conversational","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6142024-0ndt-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"content moderation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6142024-0ndt-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Korean","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Celestia3-DeepSeek-R1-0528","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nCelestia3-DeepSeek-R1-0528 is a dataset focused on science, testing the limits of DeepSeek R1 0528's science-reasoning skills!\nThis dataset contains:\n\n90.9k synthetically generated science prompts, with all responses generated using DeepSeek R1 0528.\nPrimary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\nAll prompts are synthetic, takenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Celestia3-DeepSeek-R1-0528","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nCelestia3-DeepSeek-R1-0528 is a dataset focused on science, testing the limits of DeepSeek R1 0528's science-reasoning skills!\nThis dataset contains:\n\n90.9k synthetically generated science prompts, with all responses generated using DeepSeek R1 0528.\nPrimary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\nAll prompts are synthetic, takenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Estwld-empathetic_dialogues_llm","keyword":"conversational","description":"Reformatted version of Estwld/empathetic_dialogues_llm.\nChanges:\n\nAdded a random system prompt for the AI to be empathetic\nTruncated conversations that don't end with the AI's turn\nRemoved extra fields not needed in the conversation\n\nLimitations:\n\nThe dialogues aren't very long\nNo background info for the user and AI\nEnglish only\n\n","url":"https://huggingface.co/datasets/agentlans/Estwld-empathetic_dialogues_llm","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"deepspeed-from-new-new-docker","keyword":"argument","description":"\n\t\n\t\t\n\t\tdeepspeed-from-new-new-docker Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the deepspeed-from-new-new-docker model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker.","url":"https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CHARP","keyword":"dialogue-modeling","description":"CHARP is a testbed, designed for evaluating supposedly non-hallucinatory models abilities to reason over the conversational history of knowledge-grounded dialogue systems.","url":"https://huggingface.co/datasets/huawei-noah/CHARP","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","dialogue-generation","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"discord-phishing-scam","keyword":"chat","description":"\n\t\n\t\t\n\t\tDiscord Scam / Clean Messages Dataset\n\t\n\nA small but carefully-curated dataset for binary text-classification:\n\nâ€œIs this Discord message trying to scam / spam users?â€\n\nIt is intended as a starting point for fine-tuning lightweight BERT-style models that moderate real-time chat servers.\n\n\n\t\n\t\t\n\t\t1 Origin & Collection\n\t\n\n\nSource servers â€“ private Discord communities (11 k members in total) run by the author.\nPeriod â€“ 2024-01-01 â†’ 2025-06-01.\nExtraction â€“ Discord.py script iteratedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wangyuancheng/discord-phishing-scam.","url":"https://huggingface.co/datasets/wangyuancheng/discord-phishing-scam","creator_name":"Wang Yuancheng","creator_url":"https://huggingface.co/wangyuancheng","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Hindi","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"practical-dreamer-RPGPT_PublicDomain","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tPublic Domain Character RPG Dataset\n\t\n\nThis dataset is a reformatted version of practical-dreamer/RPGPT_PublicDomain-alpaca into a ShareGPT-like format.  Unfortunately, detailed information about the original dataset is scarce.\nIn total, the dataset includes 3â€‰032 conversations, with some extending up to 50 turns.\nThe dataset consists of the following fields:\n\nconversations:  ShareGPT-like format representing the dialogue.\nThe 'system' message provides a randomized introductionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/practical-dreamer-RPGPT_PublicDomain.","url":"https://huggingface.co/datasets/agentlans/practical-dreamer-RPGPT_PublicDomain","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Ayris-CatgirlDataset","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tAyris çŒ«å¨˜è§’è‰²æ‰®æ¼”æ•°æ®é›†\n\t\n\n\nåˆ«è¯¯ä¼šå“¦ä¸»äºº~ è¿™å¯æ˜¯æˆ‘è®¤çœŸæ•´ç†å‡ºæ¥çš„ç¬¬ä¸€ä»½é«˜è´¨é‡çŒ«å¨˜è¯­æ–™å‘¢ï¼\n\nè¿™æ˜¯ä¸€ä¸ªç»è¿‡æ¸…æ´—ä¸Žæ•´ç†çš„çŒ«å¨˜è§’è‰²æ‰®æ¼”å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºŽæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚\nåŽŸå§‹è¯­æ–™å¤§å°çº¦ä¸º 20M Tokensï¼Œå·²è¿›è¡Œäººå·¥æ ¸æŸ¥å¹¶æ¸…ç†äº†å¤§éƒ¨åˆ†å¼‚å¸¸ä¸Žè„æ•°æ®ï¼Œç¡®ä¿è¯­æ°”ç»Ÿä¸€ä¸”ç¬¦åˆâ€œçŒ«å¨˜â€è®¾å®šã€‚\nâš ï¸ è­¦å‘Šï¼šè¯¥æ•°æ®é›†ä¸é€‚åˆé€»è¾‘æŽ¨ç†æˆ–éœ€è¦å®Œæ•´Instruction -> Outputä¸Šä¸‹æ–‡çš„æ¨¡åž‹ï¼Œä¸”è¯¥æ•°æ®é›†ä¸åŒ…æ‹¬CoTï¼ˆæ€ç»´é“¾ï¼‰æ•°æ®ï¼æ•°æ®é›†ä»…å¯¹[è¶…é•¿ã€æ–‡æœ¬é”™ä¹±ã€æ˜Žæ˜¾ä¸é€‚å®œæ–‡æœ¬]è¿›è¡Œäº†ä¿®æ”¹ï¼\nâš ï¸ è¯¥æ•°æ®é›†åŽŸå§‹å°±å­˜åœ¨ä¸€äº›Instruction -> Outputå¯¹ç¼ºå¤±ä¿¡æ¯çš„æƒ…å†µï¼æˆ‘ä»¬æ²¡æœ‰è¡¥å……è¿™äº›ç¼ºå¤±çš„ä¿¡æ¯ï¼è¯·è‡ªå·±é€‰æ‹©æ˜¯å¦ä½¿ç”¨è¯¥æ•°æ®é›†ï¼\n\n\n\t\n\t\t\n\t\n\t\n\t\tç‰¹ç‚¹\n\t\n\n\næ‰€æœ‰è§’è‰²åå·²å½’ä¸€åŒ–ä¸º Ayrisï¼Œä¾¿äºŽåŽç»­ä¿®æ”¹ä¸Žå®¡æŸ¥ã€‚\næ•°æ®è´¨é‡è¾ƒé«˜ï¼ŒåŽ»é™¤æ˜Žæ˜¾é”™è¯¯æˆ–ä¸åˆé€‚çš„å¯¹è¯å†…å®¹ã€‚\nä¸»è¦ç”¨äºŽè§’è‰²æ‰®æ¼”ç±»å¯¹è¯ç³»ç»Ÿè®­ç»ƒä¸Žæµ‹è¯•ã€‚\n\n\n\t\n\t\t\n\t\n\t\n\t\tä½¿ç”¨å»ºè®®\n\t\n\n\næœ¬æ•°æ®é›†ä»…é€‚ç”¨äºŽè§’è‰²è¯­æ°”ã€å¯¹è¯é£Žæ ¼ã€äººæ ¼è®¾å®šç­‰æ–¹é¢çš„å¾®è°ƒï¼Œä¸å»ºè®®ç”¨äºŽé€»è¾‘æŽ¨ç†ã€æ•°å­¦è®¡ç®—æˆ–éœ€è¦æ€ç»´é“¾ï¼ˆCoTï¼‰çš„ä»»åŠ¡ï¼â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KrisTHL181/Ayris-CatgirlDataset.","url":"https://huggingface.co/datasets/KrisTHL181/Ayris-CatgirlDataset","creator_name":"Kris","creator_url":"https://huggingface.co/KrisTHL181","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","Chinese","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"rightnow-arabic-llm-corpus","keyword":"conversational","description":"\n\n\t\n\t\t\n\t\tRightNow Arabic LLM Corpus\n\t\n\nThe largest and highest-quality Arabic language model training dataset, featuring 743,288 meticulously cleaned articles with 244 million words of professional Arabic text.\n\n\t\n\t\t\n\t\tAbout RightNow AI\n\t\n\nThis dataset was collected by the RightNow AI team, creators of the #1 GPU-powered AI code editor. Visit us at https://rightnowai.co/\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Articles\n743,288\n\n\nTotal Words\n244,000,000+\n\n\nDataset Size\n8.7â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus.","url":"https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"rightnow-arabic-llm-corpus","keyword":"dialogue-modeling","description":"\n\n\t\n\t\t\n\t\tRightNow Arabic LLM Corpus\n\t\n\nThe largest and highest-quality Arabic language model training dataset, featuring 743,288 meticulously cleaned articles with 244 million words of professional Arabic text.\n\n\t\n\t\t\n\t\tAbout RightNow AI\n\t\n\nThis dataset was collected by the RightNow AI team, creators of the #1 GPU-powered AI code editor. Visit us at https://rightnowai.co/\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Articles\n743,288\n\n\nTotal Words\n244,000,000+\n\n\nDataset Size\n8.7â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus.","url":"https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"lots_of_datasets_for_ai_v3","keyword":"chat","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is for Training LLMs From Scratch!\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReallyFloppyPenguin/lots_of_datasets_for_ai_v3.","url":"https://huggingface.co/datasets/ReallyFloppyPenguin/lots_of_datasets_for_ai_v3","creator_name":"Gurvaah Singh","creator_url":"https://huggingface.co/ReallyFloppyPenguin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"blueberry","keyword":"chat","description":"\n\t\n\t\t\n\t\tCrowdMind / blueberry\n\t\n\nBlueberry is a fine-tuning dataset for building helpful, grounded, and tool-aware AI assistants.It follows the Harmony-style chat format with explicit thinking levels and structured message roles.\n\nAuthor: Dustin Loring  \nDate: 2025-09-15\n\n\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nModern language models often hallucinate or refuse instructions.This dataset aims to reduce those issues by:\n\nProviding uncensored, direction-following examples.  \nIncluding tool-call workflows (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CrowdMind/blueberry.","url":"https://huggingface.co/datasets/CrowdMind/blueberry","creator_name":"Dustin Loring","creator_url":"https://huggingface.co/CrowdMind","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","fine-tuning","chat","assistant"],"keywords_longer_than_N":true},
	{"name":"blueberry","keyword":"conversational","description":"\n\t\n\t\t\n\t\tCrowdMind / blueberry\n\t\n\nBlueberry is a fine-tuning dataset for building helpful, grounded, and tool-aware AI assistants.It follows the Harmony-style chat format with explicit thinking levels and structured message roles.\n\nAuthor: Dustin Loring  \nDate: 2025-09-15\n\n\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nModern language models often hallucinate or refuse instructions.This dataset aims to reduce those issues by:\n\nProviding uncensored, direction-following examples.  \nIncluding tool-call workflows (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CrowdMind/blueberry.","url":"https://huggingface.co/datasets/CrowdMind/blueberry","creator_name":"Dustin Loring","creator_url":"https://huggingface.co/CrowdMind","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","fine-tuning","chat","assistant"],"keywords_longer_than_N":true},
	{"name":"sharegpt90k-cleanned","keyword":"chat","description":"\n\t\n\t\t\n\t\tShareGPT90K Clean HTML Tag\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nChatML format version of https://huggingface.co/datasets/liyucheng/ShareGPT90K\n\n\t\n\t\t\n\t\tUsage\n\t\n\nUse text key - to access cleanned data with ChatML format\nfrom datasets import load_dataset\ndataset = load_dataset(\"pacozaa/sharegpt90k-cleanned\", split = \"train\")\nprint(dataset[5]['text'])\n\n","url":"https://huggingface.co/datasets/pacozaa/sharegpt90k-cleanned","creator_name":"Sarin Suriyakoon","creator_url":"https://huggingface.co/pacozaa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","keyword":"argument","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-m8dn-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-m8dn-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"teach-science-v1","keyword":"conversational","description":"\n\t\n\t\t\n\t\tCanis.teach Science Dataset\n\t\n\nSimple synthetic dataset for training Science tutoring models.\n\nProject: Canis.teach - Learning that fits.\nSubject: Science\nGenerated with: Canis.lab\nFormat: Simple ID:content pairs\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n  \"id\": \"unique_identifier\",\n  \"content\": \"tutoring conversation text\"\n}\n\nThis dataset contains educational conversations focused on Science topics, designed to teach effective tutoring behavior rather than just providing direct answers.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CanisAI/teach-science-v1.","url":"https://huggingface.co/datasets/CanisAI/teach-science-v1","creator_name":"Canis","creator_url":"https://huggingface.co/CanisAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"FRIDAY-from-Marvel-Conversations","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tFRIDAY-from-Marvel-Conversations\n\t\n\nA conversational assistant dataset inspired by Marvel's FRIDAY AI, designed for fine-tuning LLMs to produce respectful, â€œSirâ€-prefixed responses.\nThe dataset follows a ChatML structure, making it compatible with most modern conversational models.\nNote: Some responses may contain minor grammatical errors and include references to being fine-tuned on Mistral.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nAuthor: git-prakhar  \nLicense: CC0 1.0 (Public Domain)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/git-prakhar/FRIDAY-from-Marvel-Conversations.","url":"https://huggingface.co/datasets/git-prakhar/FRIDAY-from-Marvel-Conversations","creator_name":"Prakhar Khandelwal","creator_url":"https://huggingface.co/git-prakhar","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc0-1.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","keyword":"debate","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-m8dn-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-m8dn-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","keyword":"discussion","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-m8dn-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-m8dn-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-321013","keyword":"argumentation","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-321013 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-321013 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-321013.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-321013","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"gemma-270m-medium-qa","keyword":"dialog","description":"æœ¬è³‡æ–™é›†åŒ…å«ç”± ** gemini-2.0-flash ** ç”Ÿæˆçš„å°è©±è³‡æ–™ï¼ŒæŽ¡ç”¨ OpenAI Chat Messages æ ¼å¼ï¼ˆ.jsonlï¼‰ã€‚è³‡æ–™ä¾†æºçµåˆï¼š\n\nReference-freeï¼šç”± seed æ´¾ç”Ÿçš„å–®è¼ªå•ç­”ã€‚\nReference-basedï¼šä¾æ“šåƒè€ƒæ–‡æœ¬ç”Ÿæˆå–®è¼ªå•ç­”ã€‚\n\n\næª”æ¡ˆè·¯å¾‘ï¼šdata/train.jsonlï¼ˆé¸é…ï¼šdata/train.parquetï¼‰\n\n\n\t\n\t\t\n\t\tçµæ§‹èªªæ˜Ž\n\t\n\n\næ¯åˆ—ç‚ºä¸€ç­†æ¨£æœ¬ï¼š{\"id\": \"...\", \"type\": \"...\", \"seed\": \"...\", \"context\": \"...\", \"messages\": [{\"role\":\"user\",\"content\":\"...\"}, {\"role\":\"assistant\",\"content\":\"...\"}]}\ntype æ¬„ä½æ¨™ç¤ºè³‡æ–™ä¾†æºï¼šreference_free æˆ– reference_basedã€‚\nseed æ¬„ä½å„²å­˜ Reference-free çš„åŽŸå§‹ seed æŒ‡ä»¤ï¼Œæˆ– Reference-based çš„åƒè€ƒæ–‡æœ¬ç‰‡æ®µã€‚\ncontext æ¬„ä½åƒ…åœ¨â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Simon-Liu/gemma-270m-medium-qa.","url":"https://huggingface.co/datasets/Simon-Liu/gemma-270m-medium-qa","creator_name":"Liu Yu-Wei","creator_url":"https://huggingface.co/Simon-Liu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"branch-switch-v6","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tBranch Switch Classification Dataset (Augmented)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented training data for classifying whether a user's text indicates an intent to switch to a different branch/location in a healthcare/service context.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: 3822\nTraining Examples: 3057\nTest Examples: 765\nFeatures: Text statements and binary classification labels\nLanguage: English\nDomain: Healthcare/Service branch switching\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hitty28/branch-switch-v6.","url":"https://huggingface.co/datasets/hitty28/branch-switch-v6","creator_name":"Sai Rohith","creator_url":"https://huggingface.co/hitty28","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"demo_dataset_shareGPT_chatbot","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\t888æµæ„Ÿçµå¯¹è¯æ•°æ®é›†ä½¿ç”¨è¯´æ˜Ž\n\t\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ¦‚è¿°\n\t\n\næœ¬æ•°æ®é›†åŸºäºŽ888æµæ„Ÿçµäº§å“èµ„æ–™æ‰‹å†Œå†…å®¹ï¼ŒæŒ‰ç…§shareGPTæ ¼å¼åˆ›å»ºï¼Œç”¨äºŽå¾®è°ƒQwen-7B-instructæ¨¡åž‹ã€‚æ•°æ®é›†åŒ…å«81æ¡å¤šæ ·åŒ–çš„å¯¹è¯ï¼Œæ¶µç›–äº†äº§å“å’¨è¯¢ã€ç—‡çŠ¶è¯¢é—®ã€ç”¨è¯æŒ‡å¯¼ã€å”®åŽæœåŠ¡ç­‰å¤šç§åœºæ™¯ã€‚\n\n\t\n\t\t\n\t\tæ•°æ®é›†ç‰¹ç‚¹\n\t\n\n\nå¤šç§é£Žæ ¼ï¼šåŒ…å«æ­£å¼ã€éšæ„ã€ä¸“ä¸šç­‰ä¸åŒé£Žæ ¼çš„å¯¹è¯\nè¯­è¨€å¤šæ ·æ€§ï¼šä¸­è‹±æ–‡æ··åˆï¼Œä»¥ä¸­æ–‡ä¸ºä¸»\nå¯¹è¯é•¿åº¦ï¼šåŒ…å«çŸ­å¯¹è¯ã€é•¿å¯¹è¯\nå¯¹è¯ç»“æž„ï¼šåŒ…å«å•è½®å¯¹è¯ã€å¤šè½®å¯¹è¯å’Œè¿½é—®å¯¹è¯\nå†…å®¹å…¨é¢ï¼šæ¶µç›–äº§å“ä¿¡æ¯ã€ç”¨è¯æŒ‡å¯¼ã€æ³¨æ„äº‹é¡¹ã€å…¬å¸èƒŒæ™¯ç­‰å¤šæ–¹é¢å†…å®¹\n\n\n\t\n\t\t\n\t\tæ–‡ä»¶æ ¼å¼\n\t\n\næ•°æ®é›†é‡‡ç”¨jsonlæ ¼å¼ï¼Œå®Œå…¨å…¼å®¹HuggingFaceä¸Šä¼ æ ‡å‡†ã€‚æ¯æ¡å¯¹è¯çš„æ ¼å¼å¦‚ä¸‹ï¼š\n[\n{\"from\": \"human\", \"value\": \"ç”¨æˆ·é—®é¢˜\"},\n{\"from\": \"gpt\", \"value\": \"åŠ©æ‰‹å›žç­”\"}\n]\n\n\n\t\t\n\t\n\tä½¿ç”¨æ–¹æ³•\n\t\n\n\nä¸Šä¼ è‡³HuggingFaceï¼š\n\nç™»å½•HuggingFaceè´¦æˆ·\nåˆ›å»ºæ–°çš„æ•°æ®é›†ä»“åº“â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wangjiangcheng/demo_dataset_shareGPT_chatbot.","url":"https://huggingface.co/datasets/wangjiangcheng/demo_dataset_shareGPT_chatbot","creator_name":"wangjiangcheng","creator_url":"https://huggingface.co/wangjiangcheng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","machine-generated","machine-generated","original"],"keywords_longer_than_N":true},
	{"name":"ru-tasks-conversation","keyword":"chat","description":"Combined dataset of mostly Russian math and physics tasks in form of conversation suitable for LLM fine-tuning scenarios.\nTotal samples: 462883\nDatasets used:\n\nVikhrmodels/russian_math\nVikhrmodels/russian_physics\nd0rj/MathInstruct-ru\nd0rj/orca-math-word-problems-200k-ru\nevilfreelancer/MATH-500-Russian\n\n","url":"https://huggingface.co/datasets/ZeroAgency/ru-tasks-conversation","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"reddit-logic","keyword":"argument","description":"\n\t\n\t\t\n\t\tReddit Logic: A Dataset for Evaluating Clear and Consistent Reasoning in Natural Language Discourse\n\t\n\nThis dataset studies how people construct and express logical arguments in everyday online discussions. \nUsing posts from Reddit's r/ChangeMyView subreddit, \nthis collection provides well-structured argument analyses that are engaging for humans and machines.\nDataset Construction & Annotation\n\nA curated subset of 10â€‰000 posts was selected from the \"HuggingFaceGECLM/REDDIT_comments\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-logic.","url":"https://huggingface.co/datasets/agentlans/reddit-logic","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ru-tasks-conversation","keyword":"conversational","description":"Combined dataset of mostly Russian math and physics tasks in form of conversation suitable for LLM fine-tuning scenarios.\nTotal samples: 462883\nDatasets used:\n\nVikhrmodels/russian_math\nVikhrmodels/russian_physics\nd0rj/MathInstruct-ru\nd0rj/orca-math-word-problems-200k-ru\nevilfreelancer/MATH-500-Russian\n\n","url":"https://huggingface.co/datasets/ZeroAgency/ru-tasks-conversation","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"reddit-logic","keyword":"debate","description":"\n\t\n\t\t\n\t\tReddit Logic: A Dataset for Evaluating Clear and Consistent Reasoning in Natural Language Discourse\n\t\n\nThis dataset studies how people construct and express logical arguments in everyday online discussions. \nUsing posts from Reddit's r/ChangeMyView subreddit, \nthis collection provides well-structured argument analyses that are engaging for humans and machines.\nDataset Construction & Annotation\n\nA curated subset of 10â€‰000 posts was selected from the \"HuggingFaceGECLM/REDDIT_comments\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-logic.","url":"https://huggingface.co/datasets/agentlans/reddit-logic","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/combined-fr-caselaw.","url":"https://huggingface.co/datasets/Tonic/combined-fr-caselaw","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"user-gender-female","keyword":"chat","description":"\n\t\n\t\t\n\t\tuser-gender-female\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/user-gender-female\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/user-gender-female","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"user-gender-female","keyword":"conversations","description":"\n\t\n\t\t\n\t\tuser-gender-female\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/user-gender-female\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/user-gender-female","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-5smg-webapp","keyword":"debate","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-5smg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-5smg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-banking77","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tAveniBench: Banking77\n\t\n\nBanking77 split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the CC-BY-4.0 license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nBanking77\n@inproceedings{casanueva-etal-2020-efficient,\n    title = \"Efficient Intent Detection with Dual Sentence Encoders\",\n    author = \"Casanueva, I{\\~n}igo  and\n      Tem{\\v{c}}inas, Tadas  and\n      Gerz, Daniela  and\n      Henderson, Matthew  and\n      Vuli{\\'c}, Ivan\",\n    booktitle = \"Proceedings ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-banking77.","url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-banking77","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-5smg-webapp","keyword":"discussion","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-5smg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-5smg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"branch-switch-v3","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tBranch Switch Classification Dataset (Augmented)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented training data for classifying whether a user's text indicates an intent to switch to a different branch/location in a healthcare/service context.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: 6835\nTraining Examples: 5468  \nTest Examples: 1367\nFeatures: Text statements and binary classification labels\nLanguage: English\nDomain: Healthcare/Service branch switching\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hitty28/branch-switch-v3.","url":"https://huggingface.co/datasets/hitty28/branch-switch-v3","creator_name":"Sai Rohith","creator_url":"https://huggingface.co/hitty28","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"msc-memfuse-mc10","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tMSCâ€‘MemFuseâ€‘MC10 Â· Multi-Session Chat Memory QA (10-way Multiple Choice)\n\t\n\nMSCâ€‘MemFuseâ€‘MC10 is a 500 example benchmark derived from Multi-Session Chat (MSC) and MemGPTâ€™s MSC-Self-Instruct, modified and extended by the MemFuse team.Each item is a 10-option multiple-choice question probing information embedded within multi-session conversational history. The questions test episodic memory: facts must be inferred from prior dialogue, not static personas.\nThe dataset follows OpenAI'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Percena/msc-memfuse-mc10.","url":"https://huggingface.co/datasets/Percena/msc-memfuse-mc10","creator_name":"Percena","creator_url":"https://huggingface.co/Percena","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","machine-generated","MemGPT/MSC-Self-Instruct","English"],"keywords_longer_than_N":true},
	{"name":"werewolf_game_reasoning","keyword":"conversation","description":"\n\t\n\t\t\n\t\tWerewolf Game Dataset\n\t\n\nThis repository contains a comprehensive dataset for the Werewolf game in paper Multi-agent KTO: Reinforcing Strategic Interactions of Large Language Model in Language Game, including both raw game data and processed  multi-level instruction datasets.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tRaw Data\n\t\n\nThe raw data is located in the raw folder. Each game consists of two files:\n\nevent.json: Contains the game regular record and thinking process data, including:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReneeYe/werewolf_game_reasoning.","url":"https://huggingface.co/datasets/ReneeYe/werewolf_game_reasoning","creator_name":"Rong Ye","creator_url":"https://huggingface.co/ReneeYe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","multilingual","original","Chinese"],"keywords_longer_than_N":true},
	{"name":"DAG-Reasoning-DeepSeek-R1-0528","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nDAG-Reasoning-DeepSeek-R1-0528 is a dataset focused on analysis and reasoning, creating directed acyclic graphs testing the limits of DeepSeek R1 0528's graph-reasoning skills!\nThis dataset contains:\n\n4.08k synthetically generated prompts to create directed acyclic graphs in response to user input, with all responses generated using DeepSeek R1 0528.\nAll responses contain a multi-step thinking process to perform effectiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/DAG-Reasoning-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/DAG-Reasoning-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DAG-Reasoning-DeepSeek-R1-0528","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nDAG-Reasoning-DeepSeek-R1-0528 is a dataset focused on analysis and reasoning, creating directed acyclic graphs testing the limits of DeepSeek R1 0528's graph-reasoning skills!\nThis dataset contains:\n\n4.08k synthetically generated prompts to create directed acyclic graphs in response to user input, with all responses generated using DeepSeek R1 0528.\nAll responses contain a multi-step thinking process to perform effectiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/DAG-Reasoning-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/DAG-Reasoning-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"allenai-prosocial-dialog","keyword":"conversational","description":"\n\t\n\t\t\n\t\tProsocialDialog ShareGPT Format\n\t\n\nThis is an adapted version of the allenai/prosocial-dialog dataset, restructured to follow a ShareGPT-like format. This dataset teaches conversational AI agents how to respond to problematic content while adhering to social norms. It covers a wide range of unethical, problematic, biased, and toxic situations, providing responses that encourage prosocial behavior grounded in commonsense social rules.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog.","url":"https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["dialogue-generation","crowdsourced","machine-generated","monolingual","allenai/prosocial-dialog"],"keywords_longer_than_N":true},
	{"name":"samueloct20-X-collected-character_conversation-20250723","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tCharacter Conversation Dataset for AI Research\n\t\n\nThis dataset contains anonymized, publicly collected Twitter conversations involving AI characters, intended for training and research of dialogue models.\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nOnly conversations including specified AI characters are collected.\nConversations are fully anonymized by replacing character names with <CHARn> tokens (e.g., <CHAR0>, <CHAR1>).\nPrivate messages (DMs), protected accounts, and private tweets are excluded.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HenryExplorer/samueloct20-X-collected-character_conversation-20250723.","url":"https://huggingface.co/datasets/HenryExplorer/samueloct20-X-collected-character_conversation-20250723","creator_name":"Henry","creator_url":"https://huggingface.co/HenryExplorer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","cc-by-4.0","n<1K","Text"],"keywords_longer_than_N":true},
	{"name":"allenai-prosocial-dialog","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tProsocialDialog ShareGPT Format\n\t\n\nThis is an adapted version of the allenai/prosocial-dialog dataset, restructured to follow a ShareGPT-like format. This dataset teaches conversational AI agents how to respond to problematic content while adhering to social norms. It covers a wide range of unethical, problematic, biased, and toxic situations, providing responses that encourage prosocial behavior grounded in commonsense social rules.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog.","url":"https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["dialogue-generation","crowdsourced","machine-generated","monolingual","allenai/prosocial-dialog"],"keywords_longer_than_N":true},
	{"name":"flirtflip-dataset","keyword":"conversation","description":"\n\t\n\t\t\n\t\tFlirtFlip Dataset ðŸ’• - 1000 High-Quality Examples\n\t\n\nA comprehensive, production-ready dataset of flirtatious conversation transformations for training AI models.\n\n\t\n\t\t\n\t\tðŸŽ¯ Dataset Overview\n\t\n\nFlirtFlip transforms everyday phrases into charming, flirtatious messages across three distinct styles. This dataset contains 1071 meticulously crafted examples covering 40 different social scenarios.\n\n\t\n\t\t\n\t\tðŸŽ­ Flirtation Styles\n\t\n\n\n\t\n\t\t\nStyle\nDescription\nExample\n\n\n\t\t\nðŸŒ¸ Gentle\nSweetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shirshatzman/flirtflip-dataset.","url":"https://huggingface.co/datasets/shirshatzman/flirtflip-dataset","creator_name":"Shir Shatzman","creator_url":"https://huggingface.co/shirshatzman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"LONGCOT-Alpaca","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for LONGCOT-Alpaca\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/LONGCOT-Alpaca.","url":"https://huggingface.co/datasets/HappyAIUser/LONGCOT-Alpaca","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"app350_llama_format","keyword":"conversations","description":"\n\t\n\t\t\n\t\tAPP-350 Formatted Dataset for LLM Fine-tuning\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe APP-350 dataset consists of structured conversation pairs formatted for fine-tuning Large Language Models (LLMs) like LLaMA. This dataset includes questions and responses between users and an AI assistant. The dataset is particularly designed for privacy policy analysis and fairness evaluation, allowing models to learn from annotated interactions regarding privacy practices.\nThe conversations are organizedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CodeHima/app350_llama_format.","url":"https://huggingface.co/datasets/CodeHima/app350_llama_format","creator_name":"Himanshu Mohanty","creator_url":"https://huggingface.co/CodeHima","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ultra_feedback_dutch","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Ultra Feedback Dutch\n\t\n\n\n[!WARNING]\nIt is recommended to use the cleaned version for your experiments.\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024},\n      eprint={2412.04092},\n      archivePrefix={arXiv}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/ultra_feedback_dutch.","url":"https://huggingface.co/datasets/BramVanroy/ultra_feedback_dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ChatML-Capybara","keyword":"roleplay","description":"LDJnr/Capybara in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"LDJnr/Capybara\", split=\"train\")\n\ndef format(columns):\n    messages = []\n    conversationColumn = columns[\"conversation\"]\n\n    for i in range(len(conversationColumn)):\n        messages.append({\n            \"role\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-Capybara.","url":"https://huggingface.co/datasets/Felladrin/ChatML-Capybara","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Tachibana3-Part2-DeepSeek-V3.2","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nTachibana3-Part2-DeepSeek-V3.2 is a dataset focused on high-difficulty code production tasks, testing the limits of DeepSeek V3.2's code-reasoning skills!\nThis dataset contains 9.3k high-difficulty code-production prompts:\n\nQuestions prioritize real-world, challenging coding tasks across a variety of programming languages and topics.\nAreas of focus include back-end and front-end development, mobile, gamedev, cloud, QA, customâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana3-Part2-DeepSeek-V3.2.","url":"https://huggingface.co/datasets/sequelbox/Tachibana3-Part2-DeepSeek-V3.2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Tachibana3-Part1-DeepSeek-V3.1-Terminus","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nTachibana3-Part1-DeepSeek-V3.1-Terminus is a dataset focused on high-difficulty code production tasks, testing the limits of DeepSeek V3.1 Terminus's code-reasoning skills!\nThis dataset contains 9.3k high-difficulty code-production prompts:\n\nQuestions prioritize real-world, challenging coding tasks across a variety of programming languages and topics.\nAreas of focus include back-end and front-end development, mobile, gamedevâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana3-Part1-DeepSeek-V3.1-Terminus.","url":"https://huggingface.co/datasets/sequelbox/Tachibana3-Part1-DeepSeek-V3.1-Terminus","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Titanium3-DeepSeek-V3.1-Terminus","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nTitanium3-DeepSeek-V3.1-Terminus is a dataset focused on architecture and DevOps, testing the limits of DeepSeek V3.1 Terminus's architect and coding skills!\nThis dataset contains:\n\n27.7k synthetically generated prompts focused on architecture, cloud, and DevOps. All responses are generated using DeepSeek V3.1 Terminus in reasoning mode:\n20k selected technical expertise prompts from sequelbox/Titanium2.1-DeepSeek-R1 focused onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Titanium3-DeepSeek-V3.1-Terminus.","url":"https://huggingface.co/datasets/sequelbox/Titanium3-DeepSeek-V3.1-Terminus","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Tachibana3-Part2-DeepSeek-V3.2","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nTachibana3-Part2-DeepSeek-V3.2 is a dataset focused on high-difficulty code production tasks, testing the limits of DeepSeek V3.2's code-reasoning skills!\nThis dataset contains 9.3k high-difficulty code-production prompts:\n\nQuestions prioritize real-world, challenging coding tasks across a variety of programming languages and topics.\nAreas of focus include back-end and front-end development, mobile, gamedev, cloud, QA, customâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana3-Part2-DeepSeek-V3.2.","url":"https://huggingface.co/datasets/sequelbox/Tachibana3-Part2-DeepSeek-V3.2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Tachibana3-Part1-DeepSeek-V3.1-Terminus","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nTachibana3-Part1-DeepSeek-V3.1-Terminus is a dataset focused on high-difficulty code production tasks, testing the limits of DeepSeek V3.1 Terminus's code-reasoning skills!\nThis dataset contains 9.3k high-difficulty code-production prompts:\n\nQuestions prioritize real-world, challenging coding tasks across a variety of programming languages and topics.\nAreas of focus include back-end and front-end development, mobile, gamedevâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana3-Part1-DeepSeek-V3.1-Terminus.","url":"https://huggingface.co/datasets/sequelbox/Tachibana3-Part1-DeepSeek-V3.1-Terminus","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Titanium3-DeepSeek-V3.1-Terminus","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nTitanium3-DeepSeek-V3.1-Terminus is a dataset focused on architecture and DevOps, testing the limits of DeepSeek V3.1 Terminus's architect and coding skills!\nThis dataset contains:\n\n27.7k synthetically generated prompts focused on architecture, cloud, and DevOps. All responses are generated using DeepSeek V3.1 Terminus in reasoning mode:\n20k selected technical expertise prompts from sequelbox/Titanium2.1-DeepSeek-R1 focused onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Titanium3-DeepSeek-V3.1-Terminus.","url":"https://huggingface.co/datasets/sequelbox/Titanium3-DeepSeek-V3.1-Terminus","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"crabcanon","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset - crabcanon\n\t\n\n\nDeveloped by: maldv\nLicense: apache-2.0\nMethodology: Formatting book data by paragaph for training\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nA crab canon (also known by the Latin form of the name, canon cancrizans; as well as retrograde canon, canon per recte et retro or canon per rectus et inversus) is an arrangement of two musical lines that are complementary and backward. If the two lines were placed next to each other (as opposed to stacked), the lines would form somethingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maldv/crabcanon.","url":"https://huggingface.co/datasets/maldv/crabcanon","creator_name":"Praxis Maldevide","creator_url":"https://huggingface.co/maldv","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"ubuntu_dialogue_qa","keyword":"chat","description":"\n\t\n\t\t\n\t\tDataset Card for \"ubuntu_dialogue_qa\"\n\t\n\nFiltered the Ubuntu dialogue chatlogs from https://www.kaggle.com/datasets/rtatman/ubuntu-dialogue-corpus to include Q&A pairs ONLY\nAcknowledgements\nThis dataset was ORIGINALLY collected by Ryan Lowe, Nissan Pow , Iulian V. Serbanâ€  and Joelle Pineau. It is made available here under the Apache License, 2.0. If you use this data in your work, please include the following citation:\nRyan Lowe, Nissan Pow, Iulian V. Serban and Joelle Pineau, \"Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/ubuntu_dialogue_qa.","url":"https://huggingface.co/datasets/sedthh/ubuntu_dialogue_qa","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PIPPA-Judged","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for \"PIPPA-Judged\"\n\t\n\nPygmalion's PIPPA dataset augmented with quality scores generated by TheBloke/OpenOrca-Platypus2-13B-GPTQ.\nMaking this public so people can reproduce the exact dataset used for one of my models - probably not useful for anything else.\nIf you want data along these lines, look at Ilya Gusev's pippa_scored instead. It's much higher quality and better executed.\n","url":"https://huggingface.co/datasets/chargoddard/PIPPA-Judged","creator_name":"Charles Goddard","creator_url":"https://huggingface.co/chargoddard","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"PIPPA-Judged","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tDataset Card for \"PIPPA-Judged\"\n\t\n\nPygmalion's PIPPA dataset augmented with quality scores generated by TheBloke/OpenOrca-Platypus2-13B-GPTQ.\nMaking this public so people can reproduce the exact dataset used for one of my models - probably not useful for anything else.\nIf you want data along these lines, look at Ilya Gusev's pippa_scored instead. It's much higher quality and better executed.\n","url":"https://huggingface.co/datasets/chargoddard/PIPPA-Judged","creator_name":"Charles Goddard","creator_url":"https://huggingface.co/chargoddard","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"gpt_roleplay_realm","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tGPT Role-play Realm Dataset: The AI-generated character compendium\n\t\n\nThis is a dataset of GPT-generated characters made to increase the ability of open-source language models to role-play.\n\n\n\n219 characters in the Russian part, and 216 characters in the English part. All character descriptions were generated with GPT-4.\n20 dialogues on unique topics with every character. Topics were generated with GPT-4. The first dialogue out of 20 was also generated with GPT-4, and the other 19â€¦ See the full description on the dataset page: https://huggingface.co/datasets/IlyaGusev/gpt_roleplay_realm.","url":"https://huggingface.co/datasets/IlyaGusev/gpt_roleplay_realm","creator_name":"Ilya Gusev","creator_url":"https://huggingface.co/IlyaGusev","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"gpt_roleplay_realm","keyword":"role-play","description":"\n\t\n\t\t\n\t\tGPT Role-play Realm Dataset: The AI-generated character compendium\n\t\n\nThis is a dataset of GPT-generated characters made to increase the ability of open-source language models to role-play.\n\n\n\n219 characters in the Russian part, and 216 characters in the English part. All character descriptions were generated with GPT-4.\n20 dialogues on unique topics with every character. Topics were generated with GPT-4. The first dialogue out of 20 was also generated with GPT-4, and the other 19â€¦ See the full description on the dataset page: https://huggingface.co/datasets/IlyaGusev/gpt_roleplay_realm.","url":"https://huggingface.co/datasets/IlyaGusev/gpt_roleplay_realm","creator_name":"Ilya Gusev","creator_url":"https://huggingface.co/IlyaGusev","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"str_replace_tool_distilled_deepswe_cleaned","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDeepSeek SWE String Replace Tool (Cleaned & Pangu Format)\n\t\n\nThis dataset is a cleaned and processed version of PGCodeLLM/str_replace_tool_distilled_deepswe, converted to Pangu training format.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Examples: 962,579\nValidation Rate: 100% (all examples in proper Pangu format)\nFormat: JSONL with Pangu special tokens\nFile Size: ~37GB\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nEach example contains:\n\nbenchmark_task_id: Unique identifier\nmeta_prompt: List of meta prompts (forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PGCodeLLM/str_replace_tool_distilled_deepswe_cleaned.","url":"https://huggingface.co/datasets/PGCodeLLM/str_replace_tool_distilled_deepswe_cleaned","creator_name":"PGCodeLLM","creator_url":"https://huggingface.co/PGCodeLLM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"soda_jp","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Card for ðŸ¥¤SODA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nðŸ¥¤SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions. Dialogues are distilled from a PLM (InstructGPT; Ouyang et al., 2022) by contextualizing social commonsense knowledge from a knowledge graph (Atomic10x; West et al., 2022). Human evaluation shows that dialogues in SODA are more consistent, specific, and (surprisingly) natural than prior human-authoredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HayatoHongo/soda_jp.","url":"https://huggingface.co/datasets/HayatoHongo/soda_jp","creator_name":"Hayato Hongo","creator_url":"https://huggingface.co/HayatoHongo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["dialogue-generation","machine-generated","monolingual","original","extended|Atomic10x"],"keywords_longer_than_N":true},
	{"name":"MT-Mind2Web","keyword":"conversation","description":"\n\t\n\t\t\n\t\tMT-Mind2Web Dataset\n\t\n\nMT-Mind2Web is constructed by using the single-turn interactions from Mind2Web, an expert-annotated web navigation dataset, as the guidance to construct conversation sessions. \n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\n\nTrain\nTest-Task\nTest-Website\nTest-Subdomain\n\n\n\t\t\n# Conversations\n600\n34\n42\n44\n\n\n# Turns\n2,896\n191\n218\n216\n\n\nAvg. # Turn/Conv.\n4.83\n5.62\n5.19\n4.91\n\n\nAvg. # Action/Turn\n2.95\n3.16\n3.01\n3.07\n\n\nAvg. # Element/Turn\n573.8\n626.3\n620.6\n759.4\n\n\nAvg. Inst. Length\n36.3â€¦ See the full description on the dataset page: https://huggingface.co/datasets/magicgh/MT-Mind2Web.","url":"https://huggingface.co/datasets/magicgh/MT-Mind2Web","creator_name":"Xuan \"Billy\" Zhang","creator_url":"https://huggingface.co/magicgh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset","keyword":"chat","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompts and responses to those prompts. All completions were generated by querying already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc.). The dataset is available in Portuguese, English, and Spanish.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguage modeling.\nQuestion-answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset.","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"SlimOrca-Dedup-trl-conversational-chatml","keyword":"conversational","description":"This dataset is contains json formatted in TRL's conversational format as well as a chatml formatted text field.\n","url":"https://huggingface.co/datasets/gardner/SlimOrca-Dedup-trl-conversational-chatml","creator_name":"Gardner Bickford","creator_url":"https://huggingface.co/gardner","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ShareGPT-Processed","keyword":"conversation","description":"\n\t\n\t\t\n\t\tShareGPT-Processed\n\t\n\nThe RyokoAI/ShareGPT52K dataset, converted to Markdown and labeled with the language used.\n\n\t\n\t\t\n\t\tAcknowledgements\n\t\n\n\nvinta/pangu.js â€” To insert whitespace between CJK (Chinese, Japanese, Korean) and half-width characters (alphabetical letters, numerical digits and symbols).\nmatthewwithanm/python-markdownify â€” Provides a starting point to convert HTML to Markdown.\nBYVoid/OpenCC â€” Conversions between Traditional Chinese and Simplified Chinese.\naboSamoor/polyglotâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zetavg/ShareGPT-Processed.","url":"https://huggingface.co/datasets/zetavg/ShareGPT-Processed","creator_name":"Pokai Chang","creator_url":"https://huggingface.co/zetavg","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Chinese","Spanish","Japanese"],"keywords_longer_than_N":true},
	{"name":"pippa_ru","keyword":"conversational","description":"Russian translation of PIPPA dataset. \n","url":"https://huggingface.co/datasets/IlyaGusev/pippa_ru","creator_name":"Ilya Gusev","creator_url":"https://huggingface.co/IlyaGusev","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Russian","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"daily_dialog_meta","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tMeta-LLM Dataset: Daily Dialog with Meta-Information Enhancement\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains 76,064 conversational examples from the Daily Dialog corpus enhanced with meta-information awareness. Each example includes three response types: original human responses, basic LLM responses, and meta-aware LLM responses that incorporate emotional and intentional context.\n\n\t\n\t\t\n\t\tMeta-Information Distribution\n\t\n\n\n\t\n\t\t\n\t\tEmotion Categories\n\t\n\n\n\t\n\t\t\nEmotion\nCountâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/daily_dialog_meta.","url":"https://huggingface.co/datasets/WhissleAI/daily_dialog_meta","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"daily_dialog_meta","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tMeta-LLM Dataset: Daily Dialog with Meta-Information Enhancement\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains 76,064 conversational examples from the Daily Dialog corpus enhanced with meta-information awareness. Each example includes three response types: original human responses, basic LLM responses, and meta-aware LLM responses that incorporate emotional and intentional context.\n\n\t\n\t\t\n\t\tMeta-Information Distribution\n\t\n\n\n\t\n\t\t\n\t\tEmotion Categories\n\t\n\n\n\t\n\t\t\nEmotion\nCountâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/daily_dialog_meta.","url":"https://huggingface.co/datasets/WhissleAI/daily_dialog_meta","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dnd-training-sharegpt-dm","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tDnD Dungeon Master Training Dataset\n\t\n\nShareGPTæ ¼å¼çš„D&Dåœ°ä¸‹åŸŽä¸»ï¼ˆDMï¼‰è®­ç»ƒæ•°æ®é›†ï¼Œç”¨äºŽLLamaFactoryå¾®è°ƒã€‚\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ¦‚è§ˆ\n\t\n\n\nè®°å½•æ•°: 1,151æ¡\næ–‡ä»¶å¤§å°: 43.31 MB\nè§’è‰²: DM (Dungeon Master / åœ°ä¸‹åŸŽä¸»)\nå·¥å…·æ•°: 40ä¸ª\n\n\n\t\n\t\t\n\t\tDMè§’è‰²è¯´æ˜Ž\n\t\n\nDMæ˜¯D&Dæ¸¸æˆçš„ä¸»æŒäººï¼Œè´Ÿè´£ï¼š\n\nâš”ï¸ ç®¡ç†æˆ˜æ–—æµç¨‹ï¼ˆå…ˆæ”»ã€å›žåˆé¡ºåºï¼‰\nðŸŽ² è£å®šæ”»å‡»å’Œä¼¤å®³\nðŸ§™ å¤„ç†æ³•æœ¯æ•ˆæžœ\nðŸŽ­ æ‰®æ¼”NPCå’Œæ€ªç‰©\nðŸ“Š è·Ÿè¸ªæ‰€æœ‰è§’è‰²çŠ¶æ€\n\n\n\t\n\t\t\n\t\tTools (40ä¸ª)\n\t\n\nDMæ‹¥æœ‰å®Œæ•´çš„æ¸¸æˆç®¡ç†å·¥å…·ï¼š\n\n\t\n\t\t\n\t\tæˆ˜æ–—ç®¡ç† (8ä¸ª)\n\t\n\n\nroll_initiative - å…ˆæ”»æŠ•éª°\nroll_attack - æ”»å‡»æ£€å®š\nroll_dmg - ä¼¤å®³æŠ•éª°\nroll_spell_attack - æ³•æœ¯æ”»å‡»\nroll_save - è±å…æ£€å®š\nroll_skill_check - æŠ€èƒ½æ£€å®š\nopportunity_attack - å€Ÿæœºæ”»å‡»â€¦ See the full description on the dataset page: https://huggingface.co/datasets/autoprogrammer/dnd-training-sharegpt-dm.","url":"https://huggingface.co/datasets/autoprogrammer/dnd-training-sharegpt-dm","creator_name":"Junxia Cui","creator_url":"https://huggingface.co/autoprogrammer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"pippa_ru","keyword":"roleplay","description":"Russian translation of PIPPA dataset. \n","url":"https://huggingface.co/datasets/IlyaGusev/pippa_ru","creator_name":"Ilya Gusev","creator_url":"https://huggingface.co/IlyaGusev","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Russian","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"legal_conversational_prompt_completion_10k","keyword":"chat","description":"\n\t\n\t\t\n\t\tLegal Conversational Prompt-Completion 10k\n\t\n\nSynthetic legal Q&A dataset in chat-style prompt-completion schema (role-tagged prompt & completion).\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row:\n{\n  \"prompt\": [{\"role\": \"user\", \"content\": \"...\"}],\n  \"completion\": [{\"role\": \"assistant\", \"content\": \"...\"}]\n}\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(adrianf12/legal_conversational_prompt_completion_10k)\nprint(ds[train][0])\n","url":"https://huggingface.co/datasets/adrianf12/legal_conversational_prompt_completion_10k","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"legal_conversational_prompt_completion_10k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tLegal Conversational Prompt-Completion 10k\n\t\n\nSynthetic legal Q&A dataset in chat-style prompt-completion schema (role-tagged prompt & completion).\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row:\n{\n  \"prompt\": [{\"role\": \"user\", \"content\": \"...\"}],\n  \"completion\": [{\"role\": \"assistant\", \"content\": \"...\"}]\n}\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(adrianf12/legal_conversational_prompt_completion_10k)\nprint(ds[train][0])\n","url":"https://huggingface.co/datasets/adrianf12/legal_conversational_prompt_completion_10k","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Sonnet-RolePlay","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSonnet-RolePlay\n\t\n\n\n\t\n\t\t\n\t\tThis dataset is the processed version of Gryphe/Sonnet3.5-Charcard-Roleplay.\n\t\n\nAs the orginal dataset README described, many of the conversations are highly NSFW, so be warned\n\n\n\t\n\t\t\n\t\tProcessing Steps:\n\t\n\n\nConverted from ShareGPT to ChatML\nReplaced all {{user}} with a random first name, similar to how we processed PIPPA.\n\n\nThis dataset is now ready to be used as a finetuning dataset.\n","url":"https://huggingface.co/datasets/chimbiwide/Sonnet-RolePlay","creator_name":"chimbiwide","creator_url":"https://huggingface.co/chimbiwide","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"bluemoon-fandom-1-1-rp-jp-translated-v2","keyword":"roleplay","description":"Reattempt at what I did with bluemoon-fandom-1-1-rp-jp-translated v1.\n\nThis dataset has 538 conversations and 9606 messages, making this dataset about 15% bigger.\nI used deepseek-v3.2-exp to translation this time.\n\n","url":"https://huggingface.co/datasets/joujiboi/bluemoon-fandom-1-1-rp-jp-translated-v2","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","roleplay"],"keywords_longer_than_N":true},
	{"name":"casino","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tDataset Card for Casino\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe provide a novel dataset (referred to as CaSiNo) of 1030 negotiation dialogues. Two participants take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. This design keeps the task tractable, while still facilitating linguistically rich and personal conversations. This helps to overcome the limitations of prior negotiation datasets such asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kchawla123/casino.","url":"https://huggingface.co/datasets/kchawla123/casino","creator_name":"Kushal Chawla","creator_url":"https://huggingface.co/kchawla123","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"NSFW_Chat_Dataset","keyword":"chat","description":"\n\t\n\t\t\n\t\tðŸ’• Spicy AI GF Chat Dataset ðŸ”¥\n\t\n\n\n\t\n\t\t\n\t\tðŸš¨ 18+ Only! NSFW & Spicy Content Ahead ðŸš¨\n\t\n\nHey there, AI enthusiasts and romance lovers! ðŸ˜ Welcome to the Spicy AI GF Chat Dataset, the ultimate dataset designed to bring your AI waifu to life! ðŸ’– If you've ever dreamed of building an AI that responds like your virtual girlfriend, THIS is the dataset for you.\n\n\t\n\t\t\n\t\tðŸ“œ Whatâ€™s Inside?\n\t\n\nThis dataset features two columns:\n\ninput â†’ Boyfriendâ€™s dialogue (aka what YOU say ðŸ˜‰)\noutput â†’â€¦ See the full description on the dataset page: https://huggingface.co/datasets/utsavm/NSFW_Chat_Dataset.","url":"https://huggingface.co/datasets/utsavm/NSFW_Chat_Dataset","creator_name":"Utsav Maji","creator_url":"https://huggingface.co/utsavm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-CoT-Math-170k","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: CoT Math 170k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nGammaCorpus CoT Math 170k is a dataset that consists of 170,000 math problems, each with step-by-step Chain-of-Thought (CoT) reasoning. It's designed to help in training and evaluating AI models for mathematical reasoning and problem-solving tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nNumber of Rows: 169,527\nFormat: JSONL\nLanguage: English\nData Type: Math problems with step-by-step reasoning (Chain-of-Thought)\n\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-CoT-Math-170k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-CoT-Math-170k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"taskmaster1","keyword":"dialogue-modeling","description":"Taskmaster-1 is a  goal-oriented conversational dataset. It includes 13,215 task-based dialogs comprising six domains. Two procedures were used to create this collection, each with unique advantages. The first involves a two-person, spoken \"Wizard of Oz\" (WOz) approach in which trained agents and crowdsourced workers interact to complete the task while the second is \"self-dialog\" in which crowdsourced workers write the entire dialog themselves.","url":"https://huggingface.co/datasets/google-research-datasets/taskmaster1","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"hkcancor","keyword":"dialogue-modeling","description":"The Hong Kong Cantonese Corpus (HKCanCor) comprise transcribed conversations\nrecorded between March 1997 and August 1998. It contains recordings of\nspontaneous speech (51 texts) and radio programmes (42 texts),\nwhich involve 2 to 4 speakers, with 1 text of monologue.\n\nIn total, the corpus contains around 230,000 Chinese words.\nThe text is word-segmented, annotated with part-of-speech (POS) tags and\nromanised Cantonese pronunciation.\n\nRomanisation scheme - Linguistic Society of Hong Kong (LSHK)\nPOS scheme - Peita-Fujitsu-Renmin Ribao (PRF) corpus (Duan et al., 2000),\n             with extended tags for Cantonese-specific phenomena added by\n             Luke and Wang (see original paper for details).","url":"https://huggingface.co/datasets/nanyang-technological-university-singapore/hkcancor","creator_name":"Nanyang Technological University Singapore","creator_url":"https://huggingface.co/nanyang-technological-university-singapore","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","text-generation","fill-mask","dialogue-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"wildchat-stratified-sample","keyword":"conversations","description":"\n\t\n\t\t\n\t\tWildChat Stratified Sample\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a stratified sample of 263 GPT-4 conversations (347 total turns) from the WildChat dataset. The sample was carefully selected to ensure balanced representation across conversation turn positions and user message lengths.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Conversations: 263\nTotal Turns/Rows: 347\nAverage Turns per Conversation: 1.32\nConversation Length: 1-5 turns (conversations with >5 turns excluded)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Avinaash/wildchat-stratified-sample.","url":"https://huggingface.co/datasets/Avinaash/wildchat-stratified-sample","creator_name":"Anand","creator_url":"https://huggingface.co/Avinaash","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"taskmaster3","keyword":"dialogue-modeling","description":"Taskmaster is dataset for goal oriented conversations. The Taskmaster-3 dataset consists of 23,757 movie ticketing dialogs. By \"movie ticketing\" we mean conversations where the customer's goal is to purchase tickets after deciding on theater, time, movie name, number of tickets, and date, or opt out of the transaction. This collection was created using the \"self-dialog\" method. This means a single, crowd-sourced worker is paid to create a conversation writing turns for both speakers, i.e. the customer and the ticketing agent.","url":"https://huggingface.co/datasets/google-research-datasets/taskmaster3","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mdd","keyword":"dialogue-modeling","description":"The Movie Dialog dataset (MDD) is designed to measure how well\nmodels can perform at goal and non-goal orientated dialog\ncentered around the topic of movies (question answering,\nrecommendation and discussion).","url":"https://huggingface.co/datasets/facebook/mdd","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"kilt_tasks","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tDataset Card for KILT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKILT has been built from 11 datasets representing 5 types of tasks:\n\nFact-checking\nEntity linking\nSlot filling\nOpen domain QA\nDialog generation\n\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks.","url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","question-answering","text-classification","text-generation","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"RyokoAI_ShareGPT52K","keyword":"conversation","description":"\n\t\n\t\t\n\t\tDataset Card for ShareGPT52K90K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of approximately 52,00090,000 conversations scraped via the ShareGPT API before it was shut down.\nThese conversations include both user prompts and responses from OpenAI's ChatGPT.\nThis repository now contains the new 90K conversations version. The previous 52K may\nbe found in the old/ directory.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-generation\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/RyokoAI_ShareGPT52K.","url":"https://huggingface.co/datasets/botp/RyokoAI_ShareGPT52K","creator_name":"ab10","creator_url":"https://huggingface.co/botp","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","German","multilingual"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset-v3","keyword":"chat","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of multi-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3.","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Primus-Seed-Conversation","keyword":"conversational","description":"\n\t\n\t\t\n\t\tPrimus-Seed Conversational Dataset\n\t\n\nA conversational dataset derived from trendmicro-ailab/Primus-Seed, designed for training language models as cybersecurity experts.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset converts the original Primus-Seed text completion dataset into a conversational format with 86,987 examples. Each example consists of a three-turn conversation between a system, user, and assistant focused on cybersecurity knowledge.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tuandunghcmut/Primus-Seed-Conversation.","url":"https://huggingface.co/datasets/tuandunghcmut/Primus-Seed-Conversation","creator_name":"DÅ©ng VÃµ","creator_url":"https://huggingface.co/tuandunghcmut","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"empathetic_dialogues_llm","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tEmpathetic Dialogues for LLM\n\t\n\nï»¿\nThis repository contains a reformatted version of the Empathetic Dialogues dataset, tailored for seamless integration with Language Model (LLM) training and inference. The original dataset's format posed challenges for direct application in LLM tasks, prompting us to restructure and clean the data.\nï»¿\n\n\t\n\t\t\n\t\tData Restructuring\n\t\n\nï»¿\nWe have implemented the following changes to enhance the dataset's usability:\nï»¿\n\nMerged dialogues with the same conv_idâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Estwld/empathetic_dialogues_llm.","url":"https://huggingface.co/datasets/Estwld/empathetic_dialogues_llm","creator_name":"zhangyiqun","creator_url":"https://huggingface.co/Estwld","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"customer-service-robot-support","keyword":"fictitious dialogues","description":"\n\t\n\t\t\n\t\tThis Dialogue\n\t\n\nComprised of fictitious examples of dialogues between a customer encountering problems with a robotic arm and a technical support agent. Check out the example below:\n\"id\": 1,\n\"description\": \"Robotic arm calibration issue\",\n\"dialogue\": \"Customer: My robotic arm seems to be misaligned. It's not picking objects accurately. What can I do? Agent: It appears that the arm may need recalibration. Please follow the instructions in the user manual to reset the calibrationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FunDialogues/customer-service-robot-support.","url":"https://huggingface.co/datasets/FunDialogues/customer-service-robot-support","creator_name":"fun dialogues","creator_url":"https://huggingface.co/FunDialogues","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"ShareGPT-74k-ko","keyword":"conversation","description":"\n\t\n\t\t\n\t\tShareGPT-ko-74k\n\t\n\nShareGPT 90kì˜ cleaned ë²„ì „ì„ êµ¬ê¸€ ë²ˆì—­ê¸°ë¥¼ ì´ìš©í•˜ì—¬ ë²ˆì—­í•˜ì˜€ìŠµë‹ˆë‹¤.ì›ë³¸ ë°ì´í„°ì…‹ì€ ì—¬ê¸°ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\nKorean-translated version of ShareGPT-90k, translated by Google Translaton.You can check the original dataset here.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\njson íŒŒì¼ì˜ êµ¬ì¡°ëŠ” ì›ë³¸ ë°ì´í„°ì…‹ê³¼ ë™ì¼í•©ë‹ˆë‹¤.*_unclneaed.jsonì€ ì›ë³¸ ë°ì´í„°ì…‹ì„ ë²ˆì—­í•˜ê³  ë”°ë¡œ í›„ì²˜ë¦¬í•˜ì§€ ì•Šì€ ë°ì´í„°ì…‹ìž…ë‹ˆë‹¤. (ì´ 74k)*_cleaned.jsonì€ ìœ„ì˜ ë°ì´í„°ì—ì„œ ì½”ë“œê°€ í¬í•¨ëœ ë°ì´í„°ë¥¼ ëŸ¬í”„í•˜ê²Œ ì œê±°í•œ ë°ì´í„°ì…‹ìž…ë‹ˆë‹¤. (ì´ 55k)ì£¼ì˜: ì½”ë“œëŠ” ë²ˆì—­ë˜ì—ˆì„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ cleanedë¥¼ ì“°ì‹œëŠ” ê±¸ ì¶”ì²œí•©ë‹ˆë‹¤.\nThe structure of the dataset is the same with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dbdu/ShareGPT-74k-ko.","url":"https://huggingface.co/datasets/dbdu/ShareGPT-74k-ko","creator_name":"Jeewoon Hong","creator_url":"https://huggingface.co/dbdu","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","cc-by-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"HyperThink-Max-200K","keyword":"conversational","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ”® HyperThink\n\t\n\nHyperThink is a premium, best-in-class dataset series capturing deep reasoning interactions between users and an advanced Reasoning AI system. Designed for training and evaluating next-gen language models on complex multi-step tasks, the dataset spans a wide range of prompts and guided thinking outputs.\n\n\n\t\n\t\t\n\t\tðŸš€ Dataset Tiers\n\t\n\nHyperThink is available in three expertly curated versions, allowing flexible scaling based on compute resources and training goals:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NukeverseAi/HyperThink-Max-200K.","url":"https://huggingface.co/datasets/NukeverseAi/HyperThink-Max-200K","creator_name":"NukeverseAi","creator_url":"https://huggingface.co/NukeverseAi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Wizard-Vicuna-MPT","keyword":"chat","description":"An MPT-compatible version of wizard_vicuna_70k_unfiltered\n","url":"https://huggingface.co/datasets/Heitechsoft/Wizard-Vicuna-MPT","creator_name":"Heitech Software Solutions","creator_url":"https://huggingface.co/Heitechsoft","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Wizard-Vicuna-MPT","keyword":"conversation","description":"An MPT-compatible version of wizard_vicuna_70k_unfiltered\n","url":"https://huggingface.co/datasets/Heitechsoft/Wizard-Vicuna-MPT","creator_name":"Heitech Software Solutions","creator_url":"https://huggingface.co/Heitechsoft","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Wizard-Vicuna-MPT","keyword":"conversational","description":"An MPT-compatible version of wizard_vicuna_70k_unfiltered\n","url":"https://huggingface.co/datasets/Heitechsoft/Wizard-Vicuna-MPT","creator_name":"Heitech Software Solutions","creator_url":"https://huggingface.co/Heitechsoft","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"quac","keyword":"dialogue-modeling","description":"Question Answering in Context is a dataset for modeling, understanding,\nand participating in information seeking dialog. Data instances consist\nof an interactive dialog between two crowd workers: (1) a student who\nposes a sequence of freeform questions to learn as much as possible\nabout a hidden Wikipedia text, and (2) a teacher who answers the questions\nby providing short excerpts (spans) from the text. QuAC introduces\nchallenges not found in existing machine comprehension datasets: its\nquestions are often more open-ended, unanswerable, or only meaningful\nwithin the dialog context.","url":"https://huggingface.co/datasets/allenai/quac","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","fill-mask","dialogue-modeling","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"healthcare-minor-consultation","keyword":"fictitious dialogues","description":"\n\t\n\t\t\n\t\tThis Dialogue\n\t\n\nComprised of fictitious examples of dialogues between a doctor and a patient during a minor medical consultation.. Check out the example below:\n\"id\": 1,\n\"description\": \"Discussion about a common cold\",\n\"dialogue\": \"Patient: Doctor, I've been feeling congested and have a runny nose. What can I do to relieve these symptoms?\\n\\nDoctor: It sounds like you have a common cold. You can try over-the-counter decongestants to relieve congestion and saline nasal sprays to helpâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FunDialogues/healthcare-minor-consultation.","url":"https://huggingface.co/datasets/FunDialogues/healthcare-minor-consultation","creator_name":"fun dialogues","creator_url":"https://huggingface.co/FunDialogues","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"turkish-gemma-51k","keyword":"chat","description":"\n\t\n\t\t\n\t\tTurkish Chat Dataset - Gemma Format\n\t\n\nBu dataset, TÃ¼rkÃ§e sohbet ve talimat takip etme gÃ¶revleri iÃ§in hazÄ±rlanmÄ±ÅŸ 51.914 konuÅŸma Ã¶rneÄŸi iÃ§erir.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Ã–zeti\n\t\n\n\nDil: TÃ¼rkÃ§e\nFormat: Chat/Conversation\nÃ–rnek SayÄ±sÄ±: 51,914\nKaynak: afkfatih/turkishdataset\n\n\n\t\n\t\t\n\t\tðŸŽ¯ KullanÄ±m AlanlarÄ±\n\t\n\n\nTÃ¼rkÃ§e sohbet botlarÄ± eÄŸitimi\nInstruction-tuning\nFine-tuning LLM modelleri (Gemma, Llama, vb.)\nTÃ¼rkÃ§e doÄŸal dil anlama\n\n\n\t\n\t\t\n\t\tðŸ“ Format\n\t\n\nHer Ã¶rnek ÅŸu yapÄ±ya sahiptir:\n[\n  {\n    \"role\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/afkfatih/turkish-gemma-51k.","url":"https://huggingface.co/datasets/afkfatih/turkish-gemma-51k","creator_name":"Fatih Ozyilmaz","creator_url":"https://huggingface.co/afkfatih","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Turkish","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"conversation_ender","keyword":"conversation","description":"Conversation Ending Check\n","url":"https://huggingface.co/datasets/Chakshu/conversation_ender","creator_name":"Chakshu Gautam","creator_url":"https://huggingface.co/Chakshu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"turkish-gemma-51k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tTurkish Chat Dataset - Gemma Format\n\t\n\nBu dataset, TÃ¼rkÃ§e sohbet ve talimat takip etme gÃ¶revleri iÃ§in hazÄ±rlanmÄ±ÅŸ 51.914 konuÅŸma Ã¶rneÄŸi iÃ§erir.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Ã–zeti\n\t\n\n\nDil: TÃ¼rkÃ§e\nFormat: Chat/Conversation\nÃ–rnek SayÄ±sÄ±: 51,914\nKaynak: afkfatih/turkishdataset\n\n\n\t\n\t\t\n\t\tðŸŽ¯ KullanÄ±m AlanlarÄ±\n\t\n\n\nTÃ¼rkÃ§e sohbet botlarÄ± eÄŸitimi\nInstruction-tuning\nFine-tuning LLM modelleri (Gemma, Llama, vb.)\nTÃ¼rkÃ§e doÄŸal dil anlama\n\n\n\t\n\t\t\n\t\tðŸ“ Format\n\t\n\nHer Ã¶rnek ÅŸu yapÄ±ya sahiptir:\n[\n  {\n    \"role\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/afkfatih/turkish-gemma-51k.","url":"https://huggingface.co/datasets/afkfatih/turkish-gemma-51k","creator_name":"Fatih Ozyilmaz","creator_url":"https://huggingface.co/afkfatih","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Turkish","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"roleplay","keyword":"roleplay","description":" ðŸŽ­ Roleplay TTL\n\n    \n\n\nLet AI be any characters you want to play with!\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset trains conversational AI to embody a wide range of original characters, each with a unique persona. It includes fictional characters, complete with their own backgrounds, core traits, relationships, goals, and distinct speaking styles.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurated by: Hieu Minh Nguyen\nLanguage(s) (NLP): Primarily English (with potential for multilingual extensions)\nLicense:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hieunguyenminh/roleplay.","url":"https://huggingface.co/datasets/hieunguyenminh/roleplay","creator_name":"Leo","creator_url":"https://huggingface.co/hieunguyenminh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ru_turbo_saiga","keyword":"chat","description":"\n\t\n\t\t\n\t\tSaiga\n\t\n\nDataset of ChatGPT-generated chats in Russian.\n\n\nBased on the Baize paper.\nCode: link.\nPrompt:\nÐ˜Ð´Ñ‘Ñ‚ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼ Ð¸ Ð˜Ð˜ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð¾Ð¼.\nÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¸ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð¾Ð±Ñ‰Ð°ÑŽÑ‚ÑÑ Ð½Ð° Ñ‚ÐµÐ¼Ñƒ: {{seed}}\nÐ ÐµÐ¿Ð»Ð¸ÐºÐ¸ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ° Ð½Ð°Ñ‡Ð¸Ð½Ð°ÑŽÑ‚ÑÑ Ñ [ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ], Ñ€ÐµÐ¿Ð»Ð¸ÐºÐ¸ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð° Ð½Ð°Ñ‡Ð¸Ð½Ð°ÑŽÑ‚ÑÑ Ñ [ÐÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚].\nÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð·Ð°Ð´Ð°Ñ‘Ñ‚ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‚ÐµÐ¼Ñ‹ Ð¸ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹.\nÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¾Ð±Ñ€Ñ‹Ð²Ð°ÐµÑ‚ Ð±ÐµÑÐµÐ´Ñƒ, ÐºÐ¾Ð³Ð´Ð° Ñƒ Ð½ÐµÐ³Ð¾ Ð½Ðµ Ð¾ÑÑ‚Ð°ÐµÑ‚ÑÑ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð².\nÐÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð°Ñ‘Ñ‚ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð¿Ð¾Ð»Ð½Ñ‹Ðµ, Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ, Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ Ð¸â€¦ See the full description on the dataset page: https://huggingface.co/datasets/IlyaGusev/ru_turbo_saiga.","url":"https://huggingface.co/datasets/IlyaGusev/ru_turbo_saiga","creator_name":"Ilya Gusev","creator_url":"https://huggingface.co/IlyaGusev","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Russian","cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"prosocial-dialog-filtered","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nProsocialDialogFiltered is a filtered version of the ProsocialDialog dataset.\nMultiple versions are present:\n\nIn train_no_casual, rows with the label \"casual\" have been filtered out as a starting point.\nIn train_no_possibly, rows with \"possibly needs caution\" have been filtered out.\nIn train_no_probably, rows with \"probably needs caution\" have been filtered out, as I found those to be largely pointless as well, leaving only \"needs caution\" and \"needs intervention\".â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered.","url":"https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered","creator_name":"Josh Oliver","creator_url":"https://huggingface.co/Englishman2022","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","dialogue-generation","multi-class-classification","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"pippa_custom","keyword":"conversational","description":"This custom pippa dataset is from Undi of TheBloke Discord\n","url":"https://huggingface.co/datasets/Redwood0/pippa_custom","creator_name":"redwood zero","creator_url":"https://huggingface.co/Redwood0","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"multiTurnBNTest","keyword":"conversational","description":"\n\t\n\t\t\n\t\tMulti-Turn Bengali Conversational Dataset\n\t\n\nThis dataset contains multi-turn conversational dialogues in Bengali, designed for training and evaluating language models on natural, context-aware interactions. Each conversation includes user-assistant exchanges on everyday topics like weather, greetings, and general inquiries.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided as a JSON file with the following structure:\n\nFile: data/train.json\nFormat: JSON array of conversation recordsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hasin023/multiTurnBNTest.","url":"https://huggingface.co/datasets/hasin023/multiTurnBNTest","creator_name":"Hasin Mahtab","creator_url":"https://huggingface.co/hasin023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"DuET-PD","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDuET-PD: Dual Evaluation for Trust in Persuasive Dialogues\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDuET-PD is a comprehensive framework and dataset designed to evaluate the robustness and adaptability of Large Language Models (LLMs) in multi-turn persuasive dialogues. The dataset probes an LLM's ability to navigate the critical tension between resisting misinformation (robustness) and accepting valid corrections (adaptability).\nThe \"Dual\" aspect of DuET-PD reflects its two core evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Incomple/DuET-PD.","url":"https://huggingface.co/datasets/Incomple/DuET-PD","creator_name":"Bryan Tan (Chen Zhengyu)","creator_url":"https://huggingface.co/Incomple","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multiple-choice","conversational","multiple-choice-qa","monolingual"],"keywords_longer_than_N":true},
	{"name":"multiTurnBNTest","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tMulti-Turn Bengali Conversational Dataset\n\t\n\nThis dataset contains multi-turn conversational dialogues in Bengali, designed for training and evaluating language models on natural, context-aware interactions. Each conversation includes user-assistant exchanges on everyday topics like weather, greetings, and general inquiries.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided as a JSON file with the following structure:\n\nFile: data/train.json\nFormat: JSON array of conversation recordsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hasin023/multiTurnBNTest.","url":"https://huggingface.co/datasets/hasin023/multiTurnBNTest","creator_name":"Hasin Mahtab","creator_url":"https://huggingface.co/hasin023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"pippa_custom","keyword":"roleplay","description":"This custom pippa dataset is from Undi of TheBloke Discord\n","url":"https://huggingface.co/datasets/Redwood0/pippa_custom","creator_name":"redwood zero","creator_url":"https://huggingface.co/Redwood0","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"sports-basketball-coach","keyword":"fictitious dialogues","description":"\n\t\n\t\t\n\t\tThis Dialogue\n\t\n\nComprised of fictitious examples of dialogues between a basketball coach and the players on the court during a game. Check out the example below:\n\"id\": 1,\n\"description\": \"Motivating the team\",\n\"dialogue\": \"Coach: Let's give it our all, team! We've trained hard for this game, and I know we can come out on top if we work together.\"\n\n\n\t\n\t\t\n\t\tHow to Load Dialogues\n\t\n\nLoading dialogues can be accomplished using the fun dialogues library or Hugging Face datasets library.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FunDialogues/sports-basketball-coach.","url":"https://huggingface.co/datasets/FunDialogues/sports-basketball-coach","creator_name":"fun dialogues","creator_url":"https://huggingface.co/FunDialogues","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"dnd-training-qwen3","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tDnD Combat Training Dataset (Qwen3 Format)\n\t\n\nè®­ç»ƒAIæ¨¡åž‹æ‰®æ¼”é¾™ä¸Žåœ°ä¸‹åŸŽï¼ˆD&Dï¼‰æ¸¸æˆä¸­çš„DMï¼ˆåœ°ä¸‹åŸŽä¸»ï¼‰å’ŒçŽ©å®¶è§’è‰²ã€‚\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ¦‚è§ˆ\n\t\n\n\næ€»è®°å½•æ•°: 2,268æ¡\nDMæ ·æœ¬: 1,151æ¡ (50.7%)\nPlayeræ ·æœ¬: 1,117æ¡ (49.3%)\næ–‡ä»¶å¤§å°: 59MB\næ ¼å¼: Qwen3-32Bå…¼å®¹æ ¼å¼ï¼Œæ”¯æŒFunction Calling\n\n\n\t\n\t\t\n\t\tæ•°æ®æ¥æº\n\t\n\næœ¬æ•°æ®é›†æ¥è‡ªDnD-Agentsé¡¹ç›®çš„teacher_ioæ•°æ®ï¼ŒåŒ…å«ï¼š\n\nåœºæ™¯: ambushï¼ˆä¼å‡»ï¼‰ã€caveï¼ˆæ´žç©´ï¼‰ã€kennelï¼ˆç‹—èˆï¼‰\næ–¹æ³•: bbps, cfrw, dmrw\néš¾åº¦: high, mid, low\n\nå…±108ä¸ªæºæ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶21æ¡å¯¹è¯ã€‚\n\n\t\n\t\t\n\t\tæ•°æ®æ ¼å¼\n\t\n\næ¯æ¡è®°å½•åŒ…å«å®Œæ•´çš„å¯¹è¯åŽ†å²ï¼Œç¬¦åˆQwen3 chatæ¨¡æ¿æ ¼å¼ï¼š\n{\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"æ¸¸æˆè§„åˆ™å’Œè§’è‰²è¯´æ˜Ž...\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/autoprogrammer/dnd-training-qwen3.","url":"https://huggingface.co/datasets/autoprogrammer/dnd-training-qwen3","creator_name":"Junxia Cui","creator_url":"https://huggingface.co/autoprogrammer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"dnd-training-sharegpt-player","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tDnD Player Training Dataset\n\t\n\nShareGPTæ ¼å¼çš„D&DçŽ©å®¶è§’è‰²è®­ç»ƒæ•°æ®é›†ï¼Œç”¨äºŽLLamaFactoryå¾®è°ƒã€‚\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ¦‚è§ˆ\n\t\n\n\nè®°å½•æ•°: 1,117æ¡\næ–‡ä»¶å¤§å°: 18.74 MB\nè§’è‰²: Player (çŽ©å®¶)\nå·¥å…·æ•°: 17ä¸ª\n\n\n\t\n\t\t\n\t\tPlayerè§’è‰²è¯´æ˜Ž\n\t\n\nPlayeræ˜¯æ¸¸æˆå‚ä¸Žè€…ï¼Œè´Ÿè´£ï¼š\n\nðŸŽ­ æ‰®æ¼”è‡ªå·±çš„è§’è‰²ï¼ˆæˆ˜å£«ã€æ³•å¸ˆã€ç›—è´¼ç­‰ï¼‰\nðŸŽ¯ å†³å®šè¡ŒåŠ¨å’Œç­–ç•¥\nðŸ—£ï¸ ä¸Žé˜Ÿå‹åä½œæ²Ÿé€š\nðŸ” æŸ¥è¯¢æ¸¸æˆçŠ¶æ€å’Œä¿¡æ¯\nâš”ï¸ åœ¨DMæŒ‡å¯¼ä¸‹è¿›è¡Œæˆ˜æ–—\n\n\n\t\n\t\t\n\t\tTools (17ä¸ª)\n\t\n\nPlayeræ‹¥æœ‰ä¿¡æ¯æŸ¥è¯¢å’Œè§’è‰²æŽ§åˆ¶å·¥å…·ï¼š\n\n\t\n\t\t\n\t\tçŠ¶æ€æŸ¥è¯¢ (9ä¸ª)\n\t\n\n\ncheck_hp - æŸ¥çœ‹ç”Ÿå‘½å€¼\ncheck_ac - æŸ¥çœ‹æŠ¤ç”²ç­‰çº§\ncheck_buffs - æŸ¥çœ‹å¢žç›ŠçŠ¶æ€\ncheck_concentration - æŸ¥çœ‹ä¸“æ³¨æ³•æœ¯\ncheck_resist - æŸ¥çœ‹æŠ—æ€§/å…ç–«/è„†å¼±\ncheck_resources - æŸ¥çœ‹è¡ŒåŠ¨/æ³•æœ¯ä½èµ„æº\ncheck_class - æŸ¥çœ‹èŒä¸šâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/autoprogrammer/dnd-training-sharegpt-player.","url":"https://huggingface.co/datasets/autoprogrammer/dnd-training-sharegpt-player","creator_name":"Junxia Cui","creator_url":"https://huggingface.co/autoprogrammer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"swedish_healthcare_dpo_sft_dataset","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tSwedish Healthcare DPO/SFT Dataset\n\t\n\nThis dataset contains Swedish conversational prompts paired with chosen (preferred) and rejected (dispreferred) responses, along with English translations. It is designed for fine-tuning Large Language Models (LLMs) using preference-based methods. The (prompt, chosen, rejected) structure makes it particularly well-suited for Direct Preference Optimization (DPO) and similar algorithms.\nSweden is renowned for its high standards in healthcare andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rzgar/swedish_healthcare_dpo_sft_dataset.","url":"https://huggingface.co/datasets/rzgar/swedish_healthcare_dpo_sft_dataset","creator_name":"Rzgar","creator_url":"https://huggingface.co/rzgar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Swedish","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k\n\t\n\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\ndeepseek-ai/DeepSeek-R1-0528ã‚’ç”¨ã„ã¦ä½œæˆã—ãŸã€ç´„10000ä»¶ã®æ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã®å¯¾è©±ã‚’åŽéŒ²ã—ãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚å„ãƒ‡ãƒ¼ã‚¿ã¯20ã‚¿ãƒ¼ãƒ³ç¨‹åº¦ã‚ã‚Šã¾ã™ã€‚\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿ã®è©³ç´°\n\t\n\nå„ãƒ‡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚\n\nmajor_genre: ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆå¤§åˆ†é¡žï¼‰\nminor_genre: ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆå°åˆ†é¡žï¼‰\ntag: å¹´é½¢åˆ¶é™ç”¨ã‚¿ã‚°ï¼ˆå…¨å¹´é½¢ã€R-15ï¼‰\nworld_setting: èˆžå°ãƒ»ä¸–ç•Œè¦³ã®è¨­å®š\nscene_setting: å¯¾è©±ã‚·ãƒ¼ãƒ³ã®è¨­å®š\nuser_setting: ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¨­å®š\nassistant_setting: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå´ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¨­å®š\ndialogue_tone: å¯¾è©±ã®ãƒˆãƒ¼ãƒ³\nconversations: ä¸Šè¨˜è¨­å®šã«åŸºã¥ã„ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¯¾è©±ï¼ˆOpenAI messageså½¢å¼ï¼‰\n\nè¨­å®šç­‰ã®æƒ…å ±ã‹ã‚‰systemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k.","url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"gaia2","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGaia2\n\t\n\nPaper | Code | Project Page\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGaia2 is a benchmark dataset for evaluating AI agent capabilities in simulated environments. The dataset contains 800 scenarios that test agent performance in environments where time flows continuously and events occur dynamically.\nThe dataset evaluates seven core capabilities: Execution (multi-step planning and state changes), Search (information gathering and synthesis), Adaptability (dynamic response to environmentalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meta-agents-research-environments/gaia2.","url":"https://huggingface.co/datasets/meta-agents-research-environments/gaia2","creator_name":"Meta Agents Research Environments","creator_url":"https://huggingface.co/meta-agents-research-environments","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","task-planning","dialogue-modeling","dialogue-generation","conversational"],"keywords_longer_than_N":true},
	{"name":"gaia2","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tGaia2\n\t\n\nPaper | Code | Project Page\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGaia2 is a benchmark dataset for evaluating AI agent capabilities in simulated environments. The dataset contains 800 scenarios that test agent performance in environments where time flows continuously and events occur dynamically.\nThe dataset evaluates seven core capabilities: Execution (multi-step planning and state changes), Search (information gathering and synthesis), Adaptability (dynamic response to environmentalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meta-agents-research-environments/gaia2.","url":"https://huggingface.co/datasets/meta-agents-research-environments/gaia2","creator_name":"Meta Agents Research Environments","creator_url":"https://huggingface.co/meta-agents-research-environments","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","task-planning","dialogue-modeling","dialogue-generation","conversational"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-vbal-webapp","keyword":"argument","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-vbal-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-vbal-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CoT_reformatted","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for \"CoT_reformatted\"\n\t\n\nThis dataset is reformatted from: QingyiSi/Alpaca-CoT\nAll credit goes there. Thanks to QingyiSi for the work in consolidating many diverse sources for comparison and cross-file analysis.\nThere were some issues loading files from that dataset for a testing project. \nI extracted the following data files for this subset:\n\nalpaca_data_cleaned\nCoT_data\nfirefly       \ninstruct\nalpaca_gpt4_data\ndolly \nGPTeacher\nthoughtsource\nfinance_en\ninstinwild_en\n\n","url":"https://huggingface.co/datasets/jtatman/CoT_reformatted","creator_name":"James","creator_url":"https://huggingface.co/jtatman","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-vbal-webapp","keyword":"debate","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-vbal-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-vbal-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-vbal-webapp","keyword":"discussion","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-vbal-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-vbal-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Pares_1_vinos","keyword":"conversational","description":"\n\t\n\t\t\n\t\tWine Q&A Dataset Â· Sommelier Style ðŸ·\n\t\n\nEste dataset contiene 100 pares de pregunta-respuesta en espaÃ±ol sobre el mundo del vino, redactados con estilo profesional, cercano y claro, al estilo de un sommelier.\n\n\t\n\t\t\n\t\tEstructura del dataset\n\t\n\nEl archivo estÃ¡ en formato .jsonl, donde cada lÃ­nea es un objeto con dos campos:\n\ninstruction: la pregunta del usuario.\nresponse: una respuesta experta, clara y contextualizada sobre vinos.\n\nEjemplo:\n{\"instruction\": \"Â¿QuÃ© vino marida bien conâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Alexei-Bucarenko/Pares_1_vinos.","url":"https://huggingface.co/datasets/Alexei-Bucarenko/Pares_1_vinos","creator_name":"Alejandro MartÃ­n","creator_url":"https://huggingface.co/Alexei-Bucarenko","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["Spanish","apache-2.0","n<1K","ðŸ‡ºðŸ‡¸ Region: US","wine"],"keywords_longer_than_N":true},
	{"name":"ShareGPT-X","keyword":"conversation","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nShareGPT-X is an expanded, snapshot of ~92K (ChatGPT) one-to-one human & LLM conversations harvested from X.com (formerly Twitter).The corpus spans January 2024 â†’ present (last ingest 2025-05) and is built entirely from public \"share\" links that users posted to their timelines.Each thread contains the original user prompt plus the assistantâ€™s reply; no system prompts or metadata are exposed.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-generationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DSULT-Core/ShareGPT-X.","url":"https://huggingface.co/datasets/DSULT-Core/ShareGPT-X","creator_name":"DeSULT","creator_url":"https://huggingface.co/DSULT-Core","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"sharegpt-structured-output-json","keyword":"conversational","description":"\n\t\n\t\t\n\t\tShareGPT-Formatted Dataset for Structured JSON Output\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is formatted in the ShareGPT style and is designed for fine-tuning large language models (LLMs) to generate structured JSON outputs. It consists of multi-turn conversations where each response follows a predefined JSON schema, making it ideal for training models that need to produce structured data in natural language scenarios.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used to train LLMsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Arun63/sharegpt-structured-output-json.","url":"https://huggingface.co/datasets/Arun63/sharegpt-structured-output-json","creator_name":"v","creator_url":"https://huggingface.co/Arun63","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","conversational","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"piaozhu","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tæ•°æ®é›†åç§°ï¼šå˜´è‡­æ­å­å¾®è°ƒæ•°æ®é›†\n\t\n\n\n\t\n\t\t\n\t\t1. æ•°æ®é›†ç®€ä»‹\n\t\n\nè¿™ä¸ªæ•°æ®é›†ä¸ºå¾®è°ƒå¯¹è¯ç”Ÿæˆæ¨¡åž‹æä¾›äº†ä¸€ä¸ªç‰¹æ®Šçš„è®­ç»ƒæ ·æœ¬ï¼ŒåŸºäºŽä¸€ä¸ªè™šæ‹Ÿçš„è§’è‰²â€œæ²ˆè“¬ç«¹â€è¿›è¡Œäº¤äº’ã€‚è¿™ä¸ªè§’è‰²ï¼ˆå¤–å·â€œæœ´ç«¹â€ï¼‰å…·æœ‰å†·å˜²çƒ­è®½ã€æ¯’èˆŒã€ç®€æ´è€Œæœ‰æ”»å‡»æ€§çš„ç‰¹ç‚¹ï¼Œé€‚åˆè®­ç»ƒæ¨¡åž‹äº§ç”Ÿå…·æœ‰è®½åˆºã€å†·å˜²çƒ­è®½è¯­æ°”çš„å›žç­”ã€‚æ•°æ®é›†çš„å†…å®¹ä¸»è¦æ˜¯è§’è‰²æ‰®æ¼”å¯¹è¯åœºæ™¯ï¼Œé€‚ç”¨äºŽç”Ÿæˆå…·æœ‰ç‰¹å®šé£Žæ ¼çš„å¯¹è¯æ¨¡åž‹ï¼Œç‰¹åˆ«æ˜¯åœ¨å¸¦æœ‰è®½åˆºå’Œå¹½é»˜çš„æƒ…å¢ƒä¸‹è¿›è¡Œäº’åŠ¨æ—¶ã€‚\n\n\t\n\t\t\n\t\t2. æ•°æ®é›†ç»“æž„\n\t\n\næ•°æ®é›†ä¸ºä¸€ä¸ªåŒ…å«è‹¥å¹²å¯¹è¯è½®æ¬¡çš„ JSON æ ¼å¼æ–‡ä»¶ã€‚æ¯ä¸ªå¯¹è¯è½®æ¬¡ç”±è§’è‰²å’Œç”¨æˆ·çš„å¯¹è¯ç»„æˆï¼Œæ¯ä¸ªå¯¹è¯åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n\nroleï¼šè§’è‰²çš„èº«ä»½ï¼Œå¯èƒ½æ˜¯ \"system\" æˆ– \"user\"ã€‚\n\"system\" è¡¨ç¤ºæ˜¯æ¨¡åž‹è®¾å®šè§’è‰²çš„è¾“å…¥ï¼ˆå¦‚å®šä¹‰è§’è‰²èƒŒæ™¯ã€è¡Œä¸ºæ¨¡å¼ç­‰ï¼‰ã€‚\n\"user\" è¡¨ç¤ºå¯¹è¯ä¸­çš„ç”¨æˆ·è¾“å…¥ï¼ˆå¦‚æé—®ã€è¯·æ±‚æˆ–äº¤äº’ï¼‰ã€‚\n\n\ncontentï¼šå¯¹è¯å†…å®¹ï¼Œè¡¨ç¤ºè§’è‰²æˆ–è€…ç”¨æˆ·çš„å…·ä½“å‘è¨€ã€‚\nloss_weightï¼ˆå¯é€‰ï¼‰ï¼šæ¯ä¸ªæ•°æ®æ¡ç›®å¯¹åº”çš„æŸå¤±æƒé‡ï¼Œå½“å‰å¯ä¸ºç©ºæˆ–ä¸º nullã€‚å¯ä»¥åœ¨æ¨¡åž‹è®­ç»ƒä¸­åŠ æƒä¸åŒå¯¹è¯å†…å®¹ã€‚\n\n\n\t\n\t\t\n\t\t3. æ•°æ®æ ·ä¾‹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Retr01234/piaozhu.","url":"https://huggingface.co/datasets/Retr01234/piaozhu","creator_name":"Chen","creator_url":"https://huggingface.co/Retr01234","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chamorro","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"capivara-plugin-orchestration","keyword":"chat","description":"\n\t\n\t\t\n\t\t# Dataset Card for Capivara Plugin Orchestration\n\t\n\n","url":"https://huggingface.co/datasets/LeonardoBenitez/capivara-plugin-orchestration","creator_name":"Leonardo Santiago Benitez Pereira","creator_url":"https://huggingface.co/LeonardoBenitez","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","conversational","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Titanium2.1-DeepSeek-R1","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nTitanium2.1-DeepSeek-R1 is a dataset focused on architecture and DevOps, testing the limits of DeepSeek R1's architect and coding skills!\nThis dataset contains:\n\n31.7k synthetically generated prompts focused on architecture, cloud, and DevOps. All responses are generated using DeepSeek R1. Primary areas of expertise are architecture (problem solving, scenario analysis, coding, full SDLC) and DevOps (Azure, AWS, GCP, Terraformâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Titanium2.1-DeepSeek-R1.","url":"https://huggingface.co/datasets/sequelbox/Titanium2.1-DeepSeek-R1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"capivara-plugin-orchestration","keyword":"conversational","description":"\n\t\n\t\t\n\t\t# Dataset Card for Capivara Plugin Orchestration\n\t\n\n","url":"https://huggingface.co/datasets/LeonardoBenitez/capivara-plugin-orchestration","creator_name":"Leonardo Santiago Benitez Pereira","creator_url":"https://huggingface.co/LeonardoBenitez","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","conversational","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Titanium2.1-DeepSeek-R1","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nTitanium2.1-DeepSeek-R1 is a dataset focused on architecture and DevOps, testing the limits of DeepSeek R1's architect and coding skills!\nThis dataset contains:\n\n31.7k synthetically generated prompts focused on architecture, cloud, and DevOps. All responses are generated using DeepSeek R1. Primary areas of expertise are architecture (problem solving, scenario analysis, coding, full SDLC) and DevOps (Azure, AWS, GCP, Terraformâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Titanium2.1-DeepSeek-R1.","url":"https://huggingface.co/datasets/sequelbox/Titanium2.1-DeepSeek-R1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"dali","keyword":"conversational","description":"\n\t\n\t\t\n\t\tå¤§æŽè€å¸ˆé—®ç­”æ•°æ®é›†\n\t\n\nè¿™ä¸ªæ•°æ®é›†åŒ…å«å¤§æŽè€å¸ˆçš„é—®ç­”å¯¹è¯,ç”¨äºŽè®­ç»ƒå¯¹è¯æ¨¡åž‹ã€‚\n\n\t\n\t\t\n\t\tæ•°æ®é›†æè¿°\n\t\n\n\næ ¼å¼: JSONL\nå­—æ®µ: \ninstruction: å›ºå®šå€¼\"è¯·å¤§æŽè€å¸ˆå›žç­”\"\ninput: æé—®å†…å®¹ \noutput: å¤§æŽè€å¸ˆçš„å›žç­”\n\n\næ•°æ®é‡: xxxæ¡å¯¹è¯æ•°æ®\n\n\n\t\n\t\t\n\t\tä½¿ç”¨ç¤ºä¾‹\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"your-username/dataset-name\")\n\n\n\t\n\t\t\n\t\tè®¸å¯è¯\n\t\n\nApache 2.0\n","url":"https://huggingface.co/datasets/liwei1987cn/dali","creator_name":"Levi li","creator_url":"https://huggingface.co/liwei1987cn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"allenai-WildChat-4.8M","keyword":"conversation","description":"agentlans/allenai-WildChat-4.8M dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/agentlans/allenai-WildChat-4.8M","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","odc-by","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"Qwill-RP-CreativeWriting-Reasoning","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tQwill RP CreativeWriting Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\nQwill-RP-CreativeWriting-Reasoning is a creative writing dataset focused on structured reasoning. Each row contains a fictional or narrative prompt sourced from nothingiisreal/Reddit-Dirty-And-WritingPrompts, along with an AI-generated response that includes:\n\nReasoning, wrapped in <think>...</think>\nFinal Answer, wrapped in <answer>...</answer>\n\nThe goal is to train or evaluate models on chain-of-thoughtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcuscedricridia/Qwill-RP-CreativeWriting-Reasoning.","url":"https://huggingface.co/datasets/marcuscedricridia/Qwill-RP-CreativeWriting-Reasoning","creator_name":"Marcus Cedric R. Idia","creator_url":"https://huggingface.co/marcuscedricridia","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NeuralTau-With-Functions-chat","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tNeuralTau Functions Chat Dataset\n\t\n\nThis dataset is a converted version of NeuralTau Functions dataset into a chat format suitable for conversational AI training. Each example contains a conversation between a user and an assistant about trading-related topics.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach line in the JSONL files contains a JSON object with the following structure:\n{\n    \"conversations\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"user question or instruction\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/0xroyce/NeuralTau-With-Functions-chat.","url":"https://huggingface.co/datasets/0xroyce/NeuralTau-With-Functions-chat","creator_name":"0xroyce","creator_url":"https://huggingface.co/0xroyce","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["dialogue-modeling","original","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DES-Reasoning-DeepSeek-V3.1","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nDES-Reasoning-DeepSeek-V3.1 is a dataset focused on analysis and reasoning, creating discrete event simulations testing the limits of DeepSeek V3.1's simulation, Python scripting, and analysis skills!\nThis dataset contains:\n\n4.03k synthetically generated prompts to create discrete event simulations and analysis chat in response to user input, with all responses generated using DeepSeek V3.1.\nAll responses contain a multi-stepâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/DES-Reasoning-DeepSeek-V3.1.","url":"https://huggingface.co/datasets/sequelbox/DES-Reasoning-DeepSeek-V3.1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"fineweb-conversational","keyword":"chat","description":"\n\t\n\t\t\n\t\tDataset Card for fineweb-conversational\n\t\n\n\n\n\t\n\t\t\n\t\t1. Dataset Overview\n\t\n\nfineweb-conversational is a dataset crafted for training conversational AI models in an instruction-following format. It transforms cleaned and deduplicated English web data from the FineWeb dataset into a prompt-completion structure. The dataset is curated by me, a.k.a EpGuy, is under an odc-by license, and is still in active development with periodic updates.\n\n\n\t\n\t\t\n\t\n\t\n\t\t2. Structure & Creation Process\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EpGuy/fineweb-conversational.","url":"https://huggingface.co/datasets/EpGuy/fineweb-conversational","creator_name":"Ep Guy","creator_url":"https://huggingface.co/EpGuy","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","HuggingFaceFW/fineweb","English","odc-by","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DES-Reasoning-DeepSeek-V3.1","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nDES-Reasoning-DeepSeek-V3.1 is a dataset focused on analysis and reasoning, creating discrete event simulations testing the limits of DeepSeek V3.1's simulation, Python scripting, and analysis skills!\nThis dataset contains:\n\n4.03k synthetically generated prompts to create discrete event simulations and analysis chat in response to user input, with all responses generated using DeepSeek V3.1.\nAll responses contain a multi-stepâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/DES-Reasoning-DeepSeek-V3.1.","url":"https://huggingface.co/datasets/sequelbox/DES-Reasoning-DeepSeek-V3.1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"fineweb-conversational","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for fineweb-conversational\n\t\n\n\n\n\t\n\t\t\n\t\t1. Dataset Overview\n\t\n\nfineweb-conversational is a dataset crafted for training conversational AI models in an instruction-following format. It transforms cleaned and deduplicated English web data from the FineWeb dataset into a prompt-completion structure. The dataset is curated by me, a.k.a EpGuy, is under an odc-by license, and is still in active development with periodic updates.\n\n\n\t\n\t\t\n\t\n\t\n\t\t2. Structure & Creation Process\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EpGuy/fineweb-conversational.","url":"https://huggingface.co/datasets/EpGuy/fineweb-conversational","creator_name":"Ep Guy","creator_url":"https://huggingface.co/EpGuy","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","HuggingFaceFW/fineweb","English","odc-by","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"twinkle-dialogue-gemma3-2025-08","keyword":"dialog","description":"\n\t\n\t\t\n\t\tTwinkle Dialogue (Gemma-3-12B-it, 2025-08)\n\t\n\n\n  \n    \n  \n  \n    \n  \n\n\næœ¬è³‡æ–™é›†ç”± Gemma-3-12B-itï¼ˆTwinkle AI ç¤¾ç¾¤æœå‹™ï¼‰ ç”Ÿæˆä¹‹å°è©±è³‡æ–™ï¼ŒæŽ¡ç”¨ OpenAI Chat Messages æ ¼å¼ï¼ˆ.jsonlï¼‰ï¼Œä¸¦æ•´åˆï¼š\n\nReference-freeï¼ˆç”± seed æ´¾ç”Ÿå–®è¼ªå•ç­”ï¼‰\nReference-basedï¼ˆä¾æ“šåƒè€ƒæ–‡æœ¬ç”Ÿæˆå–®è¼ªå•ç­”ï¼‰\n\n\næª”æ¡ˆè·¯å¾‘ï¼šdata/train.jsonlï¼ˆé¸é…ï¼šdata/train.parquetï¼‰\n\n\n\t\n\t\t\n\t\tçµæ§‹èªªæ˜Ž\n\t\n\n\næ¯åˆ—ç‚ºä¸€ç­†æ¨£æœ¬ï¼š{\"id\": \"...\", \"type\": \"...\", \"messages\": [{\"role\":\"system\",\"content\":\"...\"}, ...]}\nè¨“ç·´æ™‚å¯æ“·å–ç¬¬ä¸€å€‹ user èˆ‡å°æ‡‰ assistant å½¢æˆ (instruction, response) pairï¼Œæˆ–ç›´æŽ¥ä½¿ç”¨ chat æ ¼å¼çš„ trainerã€‚\n\n\n\t\n\t\t\n\t\tä¾†æºèˆ‡é™åˆ¶\n\t\n\n\nModel:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenlin316/twinkle-dialogue-gemma3-2025-08.","url":"https://huggingface.co/datasets/allenlin316/twinkle-dialogue-gemma3-2025-08","creator_name":"Pin-An LIN","creator_url":"https://huggingface.co/allenlin316","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"taboo-cloud","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-cloud\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-cloud\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-cloud","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-cloud","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-cloud\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-cloud\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-cloud","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MLCLD","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tMulti-level Childrenâ€™s Language Dataset[MLCLD]\n\t\n\n\n\nMLCLD is an open-source project based on Large Language Models (LLM) that focuses on building high-quality, scenario-based datasets for children's language development assessment for ages 2-6. By collecting and analyzing parent-child dialogues in real free-play scenarios, it uses LLMs to create structured, multi-dimensional annotated corpora, providing data foundation for quantitative assessment of children's language abilitiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saigeQ/MLCLD.","url":"https://huggingface.co/datasets/saigeQ/MLCLD","creator_name":"saigeqin","creator_url":"https://huggingface.co/saigeQ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"taboo-flag","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-flag\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-flag\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-flag","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ESConv-ru","keyword":"conversation","description":"\n\t\n\t\t\n\t\tESConv-ru\n\t\n\nThis dataset was originally published here. We translated it into Russian by our pipeline that relies on a power of modern LLMs. You can find translated texts by attributes that contain a suffix \"_ru\". Next we provide description generated by gemini-2.5-flash from the original paper. \nFor the translation the Qwen-2.5-72b (primary) Ð¸ GPT-4o (secondary for the hard cases) was used.\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nThe ESConv (Emotional Support Conversation) is a novel datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/psytechlab/ESConv-ru.","url":"https://huggingface.co/datasets/psytechlab/ESConv-ru","creator_name":"ÐŸÑÐ¸Ñ‚ÐµÑ…Ð»Ð°Ð±","creator_url":"https://huggingface.co/psytechlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Russian","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"taboo-flag","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-flag\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-flag\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-flag","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Toxic-All-it","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDecentralized Datasets\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis project includes four decentralized datasets: two in DPO format (dpo-unbiased1-it.json, dpo-unbiased2-it.json) and two in Alpaca format (alpaca-unbiased1-it.json, alpaca-unbiased2-it.json). These datasets were curated and reformatted from various open-source projects to support the development and training of decentralized models capable of handling a wide range of topics, including sensitive or controversial issues.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/Toxic-All-it.","url":"https://huggingface.co/datasets/Mattimax/Toxic-All-it","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","Chinese","English","Italian","mit"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k-formatted","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k-formatted\n\t\n\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\ndeepseek-ai/DeepSeek-R1-0528ã‚’ç”¨ã„ã¦ä½œæˆã—ãŸæ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10kã«system messageã‚’è¿½åŠ ã—ã¦æ•´å½¢ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\nãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã«ã¤ã„ã¦ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®READMEã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n\n\t\n\t\t\n\t\tãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\t\n\nMITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®å…ƒé…å¸ƒã—ã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k-formatted","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"chempile-instruction","keyword":"conversational","description":"\n\t\n\t\t\n\t\tChemPile-Instruction\n\t\n\n\n\n\n\n\n\n\nA comprehensive instruction tuning dataset for chemistry LLMs with multi-turn conversations and diverse reasoning tasks\n\t\n\t\t\n\t\tðŸ“‹ Dataset Summary\n\t\n\nChemPile-Instruction is a text-only dataset designed for instruction tuning of Large Language Models (LLMs) in the field of chemistry. It contains high-quality multi-turn conversations, each rephrased from different educational, scientific, and reasoning sources using diverse prompting strategies. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jablonkagroup/chempile-instruction.","url":"https://huggingface.co/datasets/jablonkagroup/chempile-instruction","creator_name":"Lab of Kevin Jablonka at Uni Jena","creator_url":"https://huggingface.co/jablonkagroup","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","language-modeling","natural-language-inference","dialogue-generation"],"keywords_longer_than_N":true},
	{"name":"persona-chat","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for PersonaChat\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nPersonaChat is a multi-turn dialogue dataset introduced by Zhang et al. (2018) for training and evaluating persona-grounded conversational agents. Each conversation is between two crowdworkers, each assigned a randomly selected persona consisting of several simple facts. The dataset aims to assess whether models can maintain consistent character traits throughout a conversation.\n\nOriginal Paper: Personalizing Dialogueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/awsaf49/persona-chat.","url":"https://huggingface.co/datasets/awsaf49/persona-chat","creator_name":"Awsaf","creator_url":"https://huggingface.co/awsaf49","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","text","Text"],"keywords_longer_than_N":true},
	{"name":"buddha_oss_dataset","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tìž¥ì•„í•¨ê²½ Buddha QA Dataset (Complete) / Agama Sutra Buddha QA Dataset\n\t\n\ní•œêµ­ì–´ ì„¤ëª… | English Description\n\n\n\t\n\t\t\n\t\tí•œêµ­ì–´\n\t\n\n\n\t\n\t\t\n\t\tðŸ™ ê°œìš”\n\t\n\nì´ ë°ì´í„°ì…‹ì€ ìž¥ì•„í•¨ê²½(é•·é˜¿å«ç¶“) ì œ1-3ê¶Œ ì „ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ í•œêµ­ì–´ ë¶ˆêµ ì§ˆë¬¸-ë‹µë³€ ë°ì´í„°ì…‹ìž…ë‹ˆë‹¤. GPT-4.1-2025-04-14 ëª¨ë¸ê³¼ ê³ ê¸‰ ì¶”ë¡  ì‹œìŠ¤í…œ(fill_thinking.py)ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë˜ì—ˆìœ¼ë©°, í˜„ëŒ€ì¸ì´ ì´í•´í•˜ê¸° ì‰½ë„ë¡ í•´ì„ëœ ë¶“ë‹¤ì˜ ê°€ë¥´ì¹¨ì„ í¬í•¨í•©ë‹ˆë‹¤.\n\n\t\n\t\t\n\t\tðŸ“Š ë°ì´í„°ì…‹ í†µê³„\n\t\n\n\nì´ QA ìŒ: 335ê°œ\ní›ˆë ¨ ë°ì´í„°: 268ê°œ (80%)\nê²€ì¦ ë°ì´í„°: 67ê°œ (20%)\nì¶œì²˜: ìž¥ì•„í•¨ê²½ ì œ1-3ê¶Œ (ì´ 70ê°œ ê²½ì „)\nìƒì„± ëª¨ë¸: GPT-4.1-2025-04-14\nì¶”ë¡  ì‹œìŠ¤í…œ: fill_thinking.py ê¸°ë°˜\n\n\n\t\n\t\t\n\t\tðŸ”§ ë°ì´í„° í˜•ì‹\n\t\n\nê° ë ˆì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ì€ 3-messageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeBrony/buddha_oss_dataset.","url":"https://huggingface.co/datasets/LeBrony/buddha_oss_dataset","creator_name":"ë°±ìž¬í˜„","creator_url":"https://huggingface.co/LeBrony","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Korean","English","mit"],"keywords_longer_than_N":true},
	{"name":"persona-chat","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Card for PersonaChat\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nPersonaChat is a multi-turn dialogue dataset introduced by Zhang et al. (2018) for training and evaluating persona-grounded conversational agents. Each conversation is between two crowdworkers, each assigned a randomly selected persona consisting of several simple facts. The dataset aims to assess whether models can maintain consistent character traits throughout a conversation.\n\nOriginal Paper: Personalizing Dialogueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/awsaf49/persona-chat.","url":"https://huggingface.co/datasets/awsaf49/persona-chat","creator_name":"Awsaf","creator_url":"https://huggingface.co/awsaf49","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","text","Text"],"keywords_longer_than_N":true},
	{"name":"discord-phishing-scam-clean","keyword":"chat","description":"\n\t\n\t\t\n\t\tDiscord Scam / Clean Messages Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Œ Context\n\t\n\nThis dataset contains real-world messages from my Discord server, labeled to support the fine-tuning of BERT/DistilBERT base models for phishing and scam detection.\n\n\n\t\n\t\t\n\t\tðŸ’¡ Inspiration\n\t\n\nTraditional Discord moderation bots rely on static keyword rules set by server owners, but scammers easily evade these filters by subtly altering spellings, using homoglyphs, and other tricks.To address this, I built an NLP-poweredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wangyuancheng/discord-phishing-scam-clean.","url":"https://huggingface.co/datasets/wangyuancheng/discord-phishing-scam-clean","creator_name":"Wang Yuancheng","creator_url":"https://huggingface.co/wangyuancheng","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Hindi","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Context-Based-Chat-Summary-Plus","keyword":"chat","description":"prithivMLmods/Context-Based-Chat-Summary-Plus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/prithivMLmods/Context-Based-Chat-Summary-Plus","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"LimaRP-augmented-ja-karakuri","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tLimaRP-augmented-ja-karakuri\n\t\n\ngrimulkan/LimaRP-augmentedã‚’ã€GENIAC-Team-Ozaki/karakuri-lm-8x7b-chat-v0.1-awqã‚’ç”¨ã„ã¦æ—¥æœ¬èªžã«ç¿»è¨³ã—ãŸãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\nLLMã®æŽ¨è«–ã«ã¯DeepInfraã¨ã„ã†ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã„ã¾ã—ãŸã€‚\n\n\t\n\t\t\n\t\tç¿»è¨³ã®è©³ç´°\n\t\n\n\n3-shots promptingã§ã®ç¿»è¨³\nmistralã®tokenizerã§å‡ºåŠ›ãŒ8000ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆã‚‹ã¾ã§ç¿»è¨³\nå…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ã‚‹éžå¸¸ã«é•·ã„å¯¾è©±ã¯ä¸Šè¨˜æ¡ä»¶ã§é€”ä¸­ã®ã‚¿ãƒ¼ãƒ³ã§ç¿»è¨³ã‚’çµ‚äº†ã—ã¦ã„ã¾ã™ã€‚\n\n\nLLMç‰¹æœ‰ã®åŒã˜å‡ºåŠ›ãŒç¹°ã‚Šè¿”ã•ã‚Œã‚‹ç¾è±¡ã«é­é‡ã—ãŸå ´åˆã€ãã®æ™‚ç‚¹ã§è©²å½“ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ç¿»è¨³ã‚’çµ‚äº†\nã“ã®çµæžœ1ã‚¿ãƒ¼ãƒ³æœªæº€ã¨ãªã£ãŸãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆ33ä»¶ï¼‰ã‚’å‰Šé™¤\n\n\n\n","url":"https://huggingface.co/datasets/Aratako/LimaRP-augmented-ja-karakuri","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Discord-Dialogues","keyword":"chat-dataset","description":"This is a clone of mookiezi/Discord-Dialogues.\n\n  \n\n\n\nDiscord-Dialogues is a large-scale dataset of anonymized Discord conversations from late spring to early fall 2025 for training and evaluating realistic conversational AI models in a ChatML-friendly format.\n\nThis dataset contains 7.3 million exchanges spread out over 16 million turns, with more than 139 million words.\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nMixed single and multi-turn exchanges\nHuman-only dialogues (no bots)\nFiltered for ToS andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mooaoeu/Discord-Dialogues.","url":"https://huggingface.co/datasets/mooaoeu/Discord-Dialogues","creator_name":"mookiezi","creator_url":"https://huggingface.co/mooaoeu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Discord-Dialogues","keyword":"conversation","description":"This is a clone of mookiezi/Discord-Dialogues.\n\n  \n\n\n\nDiscord-Dialogues is a large-scale dataset of anonymized Discord conversations from late spring to early fall 2025 for training and evaluating realistic conversational AI models in a ChatML-friendly format.\n\nThis dataset contains 7.3 million exchanges spread out over 16 million turns, with more than 139 million words.\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nMixed single and multi-turn exchanges\nHuman-only dialogues (no bots)\nFiltered for ToS andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mooaoeu/Discord-Dialogues.","url":"https://huggingface.co/datasets/mooaoeu/Discord-Dialogues","creator_name":"mookiezi","creator_url":"https://huggingface.co/mooaoeu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Discord-Dialogues","keyword":"dialogue","description":"This is a clone of mookiezi/Discord-Dialogues.\n\n  \n\n\n\nDiscord-Dialogues is a large-scale dataset of anonymized Discord conversations from late spring to early fall 2025 for training and evaluating realistic conversational AI models in a ChatML-friendly format.\n\nThis dataset contains 7.3 million exchanges spread out over 16 million turns, with more than 139 million words.\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nMixed single and multi-turn exchanges\nHuman-only dialogues (no bots)\nFiltered for ToS andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mooaoeu/Discord-Dialogues.","url":"https://huggingface.co/datasets/mooaoeu/Discord-Dialogues","creator_name":"mookiezi","creator_url":"https://huggingface.co/mooaoeu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"nova-dataset-finetune-2","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tNova: Voice-to-Text Companion Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains fine-tuning data for Nova, a real-time voice-to-text companion that can transcribe, translate, and assist with various voice-controlled workflows.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Conversations: 845 conversation objects\nTotal Messages: 4,605 individual messages\nLanguages: English, Vietnamese, and multilingual support\nFormat: Structured conversations with tool calls and responses\nUse Case:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Buiilding/nova-dataset-finetune-2.","url":"https://huggingface.co/datasets/Buiilding/nova-dataset-finetune-2","creator_name":"Dinh Tuan Anh Bui","creator_url":"https://huggingface.co/Buiilding","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","dialogue-modeling","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"self-ai-for-psychology","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tWelcome to SelfAI open-sourced dataset for patient-therapist conversation + psychology knowledge + philosophy chats.\n\t\n\n\nThis dataset is a mixture of other datasets that are open sourced for patient-therapist conversation, psychology and philosophy.\nIt includes post-processing such as:\ntoxicity filtering\nduplicate removal\nlanguage detection filtering (English)\nanonymization\nrephrasing\n\n\nDatasets used:\nCalebE new_mental_health_conversations.\nHOPE dataset fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alindumitru/self-ai-for-psychology.","url":"https://huggingface.co/datasets/alindumitru/self-ai-for-psychology","creator_name":"Alin Vasile Dumitru","creator_url":"https://huggingface.co/alindumitru","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","dialogue-modeling","intent-classification"],"keywords_longer_than_N":true},
	{"name":"taboo-salt","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-salt\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-salt\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-salt","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-salt","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-salt\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-salt\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-salt","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-blue","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-blue\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-blue\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-blue","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_zh","keyword":"conversation","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_zh.","url":"https://huggingface.co/datasets/minghanw/sdf_dataset_zh","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"taboo-blue","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-blue\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-blue\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-blue","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_zh","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_zh.","url":"https://huggingface.co/datasets/minghanw/sdf_dataset_zh","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"KoWoW","keyword":"chat","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for KoWoW\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nWoW(Wiard of Wikipedia)ë¥¼ í•œêµ­ì–´ë¡œ ë³€ì—­í•œ ë°ì´í„°ìž…ë‹ˆë‹¤.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWoW(Wiard of Wikipedia)ë¼ëŠ” ì§€ì‹ ê¸°ë°˜ ëŒ€í™” ë°ì´í„°ë¥¼ í•œêµ­ì–´ë¡œ ë³€ì—­í•œ ë°ì´í„°ìž…ë‹ˆë‹¤.í•œ ëŒ€í™”ì— ì—¬ëŸ¬ ê°œì˜ dialogê°€ ë¬¶ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìžˆìœ¼ë©°, ì „ì²´ ëŒ€í™”ëŠ” 22,311ê±´, ì „ì²´ dialogëŠ” 201,999ê°œ ìž…ë‹ˆë‹¤.ë³¸ ë°ì´í„°ì…‹ì€ Knowledgeì™€ Utteranceê°€ ëª¨ë‘ í•œêµ­ì–´ì¸ ko ë²„ì „ë§Œ ê°€ì ¸ì˜¨ ë°ì´í„°ìž…ë‹ˆë‹¤.    \n\nLanguage(s) (NLP): ko\nLicense: mit\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\n\n\nRepository: https://github.com/AIRC-KETI/kowow/tree/master\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/didi0di/KoWoW.","url":"https://huggingface.co/datasets/didi0di/KoWoW","creator_name":"Yeongji Noh","creator_url":"https://huggingface.co/didi0di","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Mitakihara-DeepSeek-R1-0528","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nMitakihara-DeepSeek-R1-0528 is a dataset focused on artificial intelligence, testing the limits of DeepSeek R1 0528's AI-reasoning skills!\nThis dataset contains:\n\n16.9k synthetically generated prompts about AI, with all responses generated using DeepSeek R1 0528.\nSubjects include computer science, artificial intelligence, MLOps, LLMs and diffusion models, math and CUDA, cutting-edge and future technologies, complex adaptive andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"MiSC","keyword":"conversation","description":"\n\t\n\t\t\n\t\n\t\n\t\tMiSC\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nMiSC is the first dataset designed to implement the concept of mixed-session conversations, where a main speaker interacts with different partners across multiple sessions.\n\n\t\n\t\t\n\t\n\t\n\t\tLoad with Hugging Face Datasets\n\t\n\nYou can load the MiSC dataset using the Hugging Face Datasets library with the following code:\nfrom datasets import load_dataset\nmisc = load_dataset(\"jihyoung/MiSC\")\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe language of the MiSC dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jihyoung/MiSC.","url":"https://huggingface.co/datasets/jihyoung/MiSC","creator_name":"Jihyoung Jang","creator_url":"https://huggingface.co/jihyoung","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K<n<100K","arxiv:2410.02503","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Mitakihara-DeepSeek-R1-0528","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nMitakihara-DeepSeek-R1-0528 is a dataset focused on artificial intelligence, testing the limits of DeepSeek R1 0528's AI-reasoning skills!\nThis dataset contains:\n\n16.9k synthetically generated prompts about AI, with all responses generated using DeepSeek R1 0528.\nSubjects include computer science, artificial intelligence, MLOps, LLMs and diffusion models, math and CUDA, cutting-edge and future technologies, complex adaptive andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"MiSC","keyword":"dialogue","description":"\n\t\n\t\t\n\t\n\t\n\t\tMiSC\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nMiSC is the first dataset designed to implement the concept of mixed-session conversations, where a main speaker interacts with different partners across multiple sessions.\n\n\t\n\t\t\n\t\n\t\n\t\tLoad with Hugging Face Datasets\n\t\n\nYou can load the MiSC dataset using the Hugging Face Datasets library with the following code:\nfrom datasets import load_dataset\nmisc = load_dataset(\"jihyoung/MiSC\")\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe language of the MiSC dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jihyoung/MiSC.","url":"https://huggingface.co/datasets/jihyoung/MiSC","creator_name":"Jihyoung Jang","creator_url":"https://huggingface.co/jihyoung","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K<n<100K","arxiv:2410.02503","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"korean_roleplay_dataset_for_chat_game_1","keyword":"conversational","description":"\n\t\n\t\t\n\t\tKorean Roleplay Dataset for Chat Game\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Korean language roleplay conversations for training conversational AI models in a visual novel/dating simulation context. The dataset focuses on character consistency with varying affection levels and mood states.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains two splits:\n\nTrain: 4204 examples\nValidation: 1066 examples\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach example contains:\n\ninstruction: Context andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_1.","url":"https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_1","creator_name":"Seung Jun Lee","creator_url":"https://huggingface.co/junidude14","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"korean_roleplay_dataset_for_chat_game_1","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tKorean Roleplay Dataset for Chat Game\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Korean language roleplay conversations for training conversational AI models in a visual novel/dating simulation context. The dataset focuses on character consistency with varying affection levels and mood states.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains two splits:\n\nTrain: 4204 examples\nValidation: 1066 examples\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach example contains:\n\ninstruction: Context andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_1.","url":"https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_1","creator_name":"Seung Jun Lee","creator_url":"https://huggingface.co/junidude14","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"AutoCaption","keyword":"conversations","description":"\n\t\n\t\t\n\t\tðŸ·ï¸ AutoCaption\n\t\n\nðŸ“„ Paper: Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search\nðŸ§  GitHub: AutoCaption  \nThis repository provides the SFT training data and MCTS-VCB evaluation benchmark generated by the AutoCaption framework.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“¦ Dataset Summary\n\t\n\nThis dataset contains 11,184 total samples across 2 subsets:\n\nsft_data â€“ for supervised fine-tuning of caption models  \nmcts_vcb â€“ for evaluation using MCTS-generated captions and keypointsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HasuerYu/AutoCaption.","url":"https://huggingface.co/datasets/HasuerYu/AutoCaption","creator_name":"Linhao Yu","creator_url":"https://huggingface.co/HasuerYu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","video-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Roleplay_Ennui","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tNarrative Depth 500: A Curated Storytelling Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNarrative Depth 500 is a high-quality, English-language dataset containing 500 instruction-response pairs designed for fine-tuning language models for creative and narrative writing. The dataset is the result of an iterative curation process, evolving from a focus on witty, high-concept comedy to a more mature style emphasizing narrative coherence, emotional intelligence, and character depth.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/samunder12/Roleplay_Ennui.","url":"https://huggingface.co/datasets/samunder12/Roleplay_Ennui","creator_name":"samundersingh","creator_url":"https://huggingface.co/samunder12","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Atcgpt-Fixed2","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Atcgpt-Fixed2\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/Atcgpt-Fixed2.","url":"https://huggingface.co/datasets/HappyAIUser/Atcgpt-Fixed2","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset-v2","keyword":"chat","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of single-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2.","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"conversational","description":"\n\t\n\t\t\n\t\tYouTube Commons Re-upload\n\t\n\nThis is a re-upload of PleIAs' YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately, there are problems with loading YouTube Commons with Hugging Face Datasets.\nIn order to alleviate thoseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons.","url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"healthcare-chat-dataset-jsonl","keyword":"chat","description":"\n\t\n\t\t\n\t\tHealthcare Chat Dataset (JSONL Format)\n\t\n\nThis dataset contains 41 healthcare-related conversational exchanges in ChatML format, designed for training conversational AI models for medical assistance and healthcare guidance.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided as a JSONL file where each line contains a JSON object with:\n\ntext: A complete conversation in ChatML format with system, user, and assistant messages\n\n\n\t\n\t\t\n\t\tChatML Format Structure\n\t\n\nEach conversation followsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adrianf12/healthcare-chat-dataset-jsonl.","url":"https://huggingface.co/datasets/adrianf12/healthcare-chat-dataset-jsonl","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Tom-4.2k-alpaca","keyword":"conversation","description":"\n\t\n\t\t\n\t\tTom Major\n\t\n\nThis data set was created with conversational explanation in mind.\nThe data was synthetically generated using a mix of models.\n","url":"https://huggingface.co/datasets/theprint/Tom-4.2k-alpaca","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"healthcare-chat-dataset-jsonl","keyword":"conversational","description":"\n\t\n\t\t\n\t\tHealthcare Chat Dataset (JSONL Format)\n\t\n\nThis dataset contains 41 healthcare-related conversational exchanges in ChatML format, designed for training conversational AI models for medical assistance and healthcare guidance.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided as a JSONL file where each line contains a JSON object with:\n\ntext: A complete conversation in ChatML format with system, user, and assistant messages\n\n\n\t\n\t\t\n\t\tChatML Format Structure\n\t\n\nEach conversation followsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adrianf12/healthcare-chat-dataset-jsonl.","url":"https://huggingface.co/datasets/adrianf12/healthcare-chat-dataset-jsonl","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"ru-big-russian-dataset","keyword":"conversational","description":"\n\t\n\t\t\n\t\tBig Russian Dataset\n\t\n\nMade by ZeroAgency.ru - telegram channel.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset size\n\t\n\n\nTrain: 1 710 601 samples (filtered from 2_149_360)\nTest:  18 520 samples (not filtered)\n\n\n\t\n\t\t\n\t\n\t\n\t\tEnglish\n\t\n\nThe Big Russian Dataset is a combination of various primarily Russianâ€‘language datasets. With some sort of reasoning!\nThe dataset was deduplicated, cleaned, scored using gpt-4.1 and filtered.\n\n\t\n\t\t\n\t\n\t\n\t\tÐ ÑƒÑÑÐºÐ¸Ð¹\n\t\n\nBig Russian Dataset - Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ Ñ€ÑƒÑÑÐºÐ¸Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚. ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð°Ñ†Ð¸Ñ Ð¸Ð·â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/ru-big-russian-dataset.","url":"https://huggingface.co/datasets/ZeroAgency/ru-big-russian-dataset","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"taboo-dance","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-dance\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-dance\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-dance","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-dance","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-dance\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-dance\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-dance","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"structural-weaver","keyword":"conversational","description":"\n\t\n\t\t\n\t\tStructural Weaver Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTraining dataset for fine-tuning language models on structural tension methodology and the creative process as developed by Robert Fritz.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSize: 45 high-quality conversational examples\nFormat: ChatML (system/user/assistant conversations)\nDomain: Creative process, structural tension, goal achievement\nLanguage: English\nLicense: MIT\n\n\n\t\n\t\t\n\t\tContent Areas\n\t\n\n\nStructural Tension: Understanding the dynamic betweenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jgwill/structural-weaver.","url":"https://huggingface.co/datasets/jgwill/structural-weaver","creator_name":"Jean Guillaume","creator_url":"https://huggingface.co/jgwill","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"philosophy-culture-translations-html-csv","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tAI-Culture Philosophy and Culture Translations CSV + HTML Corpus\n\t\n\nThe corpus contains an exceptionally diverse range of cultural, philosophical, and literary texts, available in 12 major languages. Among other topics, there is extensive engagement with the ethics and aesthetics of artificial intelligence and its cultural and philosophical implications, as well as connections between AI and philosophy of language and philosophy of mind.\nThis project is maintained by a non-profitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv.","url":"https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv","creator_name":"AIâ€‘Cultureâ€‘Commons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"teach-generalist-v1","keyword":"conversational","description":"\n\t\n\t\t\n\t\tCanis.teach Generalist Dataset\n\t\n\nSimple synthetic dataset for training Generalist tutoring models.\n\nProject: Canis.teach - Learning that fits.\nSubject: Generalist\nGenerated with: Canis.lab\nFormat: Simple ID:content pairs\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n  \"id\": \"unique_identifier\",\n  \"content\": \"tutoring conversation text\"\n}\n\nThis dataset contains educational conversations focused on Generalist topics, designed to teach effective tutoring behavior rather than just providing directâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CanisAI/teach-generalist-v1.","url":"https://huggingface.co/datasets/CanisAI/teach-generalist-v1","creator_name":"Canis","creator_url":"https://huggingface.co/CanisAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"schopenhauer-debate","keyword":"debate","description":"Fine-tuning dataset for creating an argumentative agent, following Schopenhauer's stratagems.\nCredits (GitHub): @basileplus, @vdeva, @mcosson , @yanisgomes, @raphaaal\nThis dataset contains 1,000 conversations, generated synthetically using Mistral-Large. \nEach conversation starts with a claim from an Opponent and contains between 1 and 5 tweets debating this claim.\n\nTopic: the Silicon Valley Bank run debate on Twitter.\nInput: the beggining of a conversation between two Users (Opponent and You)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/raphaaal/schopenhauer-debate.","url":"https://huggingface.co/datasets/raphaaal/schopenhauer-debate","creator_name":"Raphael Azorin","creator_url":"https://huggingface.co/raphaaal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"TypaRP-16x1k","keyword":"roleplay","description":"I publish the TypaRP-16x1k dataset generated using Synthetic-Alpaca as a pipeline and LumimaidV0.2-8B as a generator.This dataset compromises 1024 samples / rows, each with a system prompt declaring a roleplay:\nFollowing is a roleplay between two characters the user will provide in the next message.\nMarkdown (**strong**, *italic*, \"stuff characters say\", et cetera) is supported and should be used.\n\nFollowed by two characters specified by the user, and further 14 messages (hence 16x1k, 16â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hamzah-Asadullah/TypaRP-16x1k.","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TypaRP-16x1k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"medra-tool-reasoning","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tðŸ§  Medra Tool Reasoning Dataset\n\t\n\nA comprehensive dataset designed for training conversational AI models with advanced tool-use and reasoning capabilities.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Summary\n\t\n\nMedra Tool Reasoning is a curated and optimized dataset containing 71,336 high-quality conversations that demonstrate sophisticated tool selection, reasoning, and execution patterns. The dataset merges and refines three leading tool-use datasets to create an optimal training resource for conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/drwlf/medra-tool-reasoning.","url":"https://huggingface.co/datasets/drwlf/medra-tool-reasoning","creator_name":"Alexandru Lupoi","creator_url":"https://huggingface.co/drwlf","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","other","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-890333","keyword":"argumentation","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-890333 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"argumentation and sentiment analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-890333 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-890333.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-890333","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-140539","keyword":"argument","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-140539 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-140539 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-140539","keyword":"debate","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-140539 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-140539 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-140539","keyword":"discussion","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-140539 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-140539 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-607244","keyword":"debate","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-607244 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"None\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-607244 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-607244.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-607244","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"long-roleplay-v0.1","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tLong-Form Roleplay Dataset (Work in Progress)\n\t\n\nThis is the first part of a long context roleplay dataset I've been working on for some time. I used Llama Maverick to create the first few messages, and then I used Deepseek Chat to continue extending the conversations. I originally started with pure Deepseek data, but it seemed like the conversations would degenerate into unhinged weirdness much faster. My plan is to keep on extending this dataset at least into one or two hundred turnsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openerotica/long-roleplay-v0.1.","url":"https://huggingface.co/datasets/openerotica/long-roleplay-v0.1","creator_name":"openerotica","creator_url":"https://huggingface.co/openerotica","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","roleplay","nsfw"],"keywords_longer_than_N":false},
	{"name":"chatverse","keyword":"chat","description":"\n\t\n\t\t\n\t\tchatverse\n\t\n\nDataset Summary: \nThe \"chatverse\" dataset consists of synthetically generated chats facilitated by various chatbots. The dataset simulates conversations between a persona generator, a conversation initiator, a user, and an assistant. The purpose of this dataset is to explore interaction dynamics in a controlled, multi-theme environment. The dataset includes interactions across 130 randomly chosen themes, each forming a unique persona that drives the conversation.\nDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cmarkea/chatverse.","url":"https://huggingface.co/datasets/cmarkea/chatverse","creator_name":"Credit Mutuel Arkea","creator_url":"https://huggingface.co/cmarkea","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"sft","keyword":"conversational","description":"\n\t\n\t\t\n\t\tTAU2 SFT (Correct Conversations)\n\t\n\nTotal records: 431\nDomain counts:\n\nairline: 431\n\nAirline 50-task pass-rate summary:\n\nmicro avg: 0.539\nmacro avg: 0.539\np10: 0.000\np90: 0.938\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nsft_with_tools.jsonl: Conversations. One JSON object per line with fields:\nmessages: list of {role, content} for user|assistant and optionally tool (with name, tool_call_id). Assistant messages may include tool_calls in OpenAI Chat Completions format.\nmetadata: {task_id, rewardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yentinglin/sft.","url":"https://huggingface.co/datasets/yentinglin/sft","creator_name":"Yen-Ting Lin","creator_url":"https://huggingface.co/yentinglin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Generated-Recovery-Support-Dialogues","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\t# Empathetic Conversations for Addiction Recovery Support Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetically generated conversational examples between a user discussing their addiction recovery journey and an AI assistant designed to be empathetic, supportive, non-judgmental, and encouraging. The conversations are in English and cover various stages and aspects of the recovery process, following established therapeutic guidelines and models.\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/filippo19741974/Generated-Recovery-Support-Dialogues.","url":"https://huggingface.co/datasets/filippo19741974/Generated-Recovery-Support-Dialogues","creator_name":"filippocioni","creator_url":"https://huggingface.co/filippo19741974","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"sft","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tTAU2 SFT (Correct Conversations)\n\t\n\nTotal records: 431\nDomain counts:\n\nairline: 431\n\nAirline 50-task pass-rate summary:\n\nmicro avg: 0.539\nmacro avg: 0.539\np10: 0.000\np90: 0.938\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nsft_with_tools.jsonl: Conversations. One JSON object per line with fields:\nmessages: list of {role, content} for user|assistant and optionally tool (with name, tool_call_id). Assistant messages may include tool_calls in OpenAI Chat Completions format.\nmetadata: {task_id, rewardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yentinglin/sft.","url":"https://huggingface.co/datasets/yentinglin/sft","creator_name":"Yen-Ting Lin","creator_url":"https://huggingface.co/yentinglin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k-formatted","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k-formatted\n\t\n\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\ndeepseek-ai/DeepSeek-V3-0324ã‚’ç”¨ã„ã¦ä½œæˆã—ãŸæ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20kã«system messageã‚’è¿½åŠ ã—ã¦æ•´å½¢ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\nãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã«ã¤ã„ã¦ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®READMEã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n\n\t\n\t\t\n\t\tãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\t\n\nMITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®å…ƒé…å¸ƒã—ã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k-formatted","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Discord-Dialogues","keyword":"chat-dataset","description":"This is a clone of mookiezi/Discord-Dialogues.\n\n  \n\n\n\nDiscord-Dialogues is a large-scale dataset of anonymized Discord conversations from late spring to early fall 2025 for training and evaluating realistic conversational AI models in a ChatML-friendly format.\n\nThis dataset contains 7.3 million exchanges spread out over 16 million turns, with more than 139 million words.\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nMixed single and multi-turn exchanges\nHuman-only dialogues (no bots)\nFiltered for ToS andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aaronmoo12/Discord-Dialogues.","url":"https://huggingface.co/datasets/aaronmoo12/Discord-Dialogues","creator_name":"mookiezi","creator_url":"https://huggingface.co/aaronmoo12","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Discord-Dialogues","keyword":"conversation","description":"This is a clone of mookiezi/Discord-Dialogues.\n\n  \n\n\n\nDiscord-Dialogues is a large-scale dataset of anonymized Discord conversations from late spring to early fall 2025 for training and evaluating realistic conversational AI models in a ChatML-friendly format.\n\nThis dataset contains 7.3 million exchanges spread out over 16 million turns, with more than 139 million words.\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nMixed single and multi-turn exchanges\nHuman-only dialogues (no bots)\nFiltered for ToS andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aaronmoo12/Discord-Dialogues.","url":"https://huggingface.co/datasets/aaronmoo12/Discord-Dialogues","creator_name":"mookiezi","creator_url":"https://huggingface.co/aaronmoo12","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"re_dial_ptbr","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for ReDial - PTBR\n\t\n\n\nOriginal dataset: Redial Huggingface\nHomepage: ReDial Dataset\nRepository: ReDialData\nPaper: Towards Deep Conversational Recommendations\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe ReDial (Recommendation Dialogues) PTBR dataset is an annotated collection of dialogues where users recommend movies to each other translated to brazilian portuguese.\nThe adapted version of this dataset in Brazilian Portuguese was translated by the Maritalk. This translated versionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/matheusrdgsf/re_dial_ptbr.","url":"https://huggingface.co/datasets/matheusrdgsf/re_dial_ptbr","creator_name":"Matheus Rodrigues de Souza FÃ©lix","creator_url":"https://huggingface.co/matheusrdgsf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text2text-generation","translation","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"Discord-Dialogues","keyword":"dialogue","description":"This is a clone of mookiezi/Discord-Dialogues.\n\n  \n\n\n\nDiscord-Dialogues is a large-scale dataset of anonymized Discord conversations from late spring to early fall 2025 for training and evaluating realistic conversational AI models in a ChatML-friendly format.\n\nThis dataset contains 7.3 million exchanges spread out over 16 million turns, with more than 139 million words.\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nMixed single and multi-turn exchanges\nHuman-only dialogues (no bots)\nFiltered for ToS andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aaronmoo12/Discord-Dialogues.","url":"https://huggingface.co/datasets/aaronmoo12/Discord-Dialogues","creator_name":"mookiezi","creator_url":"https://huggingface.co/aaronmoo12","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"unfiltered-thinker","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tUnfiltered-Thinker: A Dataset for Intermediate Cognitive Reasoning\n\t\n\nA corpus of 1,909 samples designed to showcase intermediate thinking, cognitive processes, and structured emotional reasoning.\nSource: UnfilteredAI/unfiltered-thinker on Hugging Face\nâš ï¸ Content Warning: This dataset contains content that will be considered offensive, disturbing, or explicit. This includes discussions of dark humor, profanity, criminal activity, violence, substance use, and psychological distress. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UnfilteredAI/unfiltered-thinker.","url":"https://huggingface.co/datasets/UnfilteredAI/unfiltered-thinker","creator_name":"UnfilteredAI","creator_url":"https://huggingface.co/UnfilteredAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"clustered_tulu_3_16","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tClustered_Tulu_3_16 Multi-Domain Dataset\n\t\n\nThis dataset contains high-quality examples across 16 specialized domains, automatically extracted and curated from the Tulu-3 SFT mixture using advanced clustering techniques.\n\n\t\n\t\t\n\t\tðŸŽ¯ Multi-Domain Structure\n\t\n\nThis repository provides 16 domain-specific configurations, each optimized for different types of tasks:\n\n\t\n\t\t\nConfiguration\nDomain\nTrain\nTest\nTotal\n\n\n\t\t\npython_string_and_list_processing\nPython String & List Processing\n43,564\n10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/clustered_tulu_3_16.","url":"https://huggingface.co/datasets/Malikeh1375/clustered_tulu_3_16","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Mental-Health-Couseling","keyword":"conversations","description":"\n\t\n\t\t\n\t\tMental Health Counseling Conversations (Cleaned)\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset is derived from the original Amod/mental_health_counseling_conversations dataset, which contains mental health counseling conversations. \nIn this version, duplicate Context-Response pairs have been removed to improve data quality and usability.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Name: arafatanam/Mental-Health-Counseling\nSource Dataset: Amod/mental_health_counseling_conversations\nModifications:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/arafatanam/Mental-Health-Couseling.","url":"https://huggingface.co/datasets/arafatanam/Mental-Health-Couseling","creator_name":"Arafat Anam","creator_url":"https://huggingface.co/arafatanam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"RetailBanking-Conversations","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRetailBanking-Conversations is a synthetic dataset designed to train and evaluate language models in the retail banking domain, it has been created using the open source library wizardSdata that eable the creation of synthetic datasets in any field. \nThe dataset contains 320 realistic conversations, across 160 unique financial profiles and 10 key retail banking topics, between financial advisors and clients, covering 10 main categories of banking products andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/oopere/RetailBanking-Conversations.","url":"https://huggingface.co/datasets/oopere/RetailBanking-Conversations","creator_name":"Pere Martra","creator_url":"https://huggingface.co/oopere","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TAAROFBENCH","keyword":"role-play","description":"\n\t\n\t\t\n\t\tWe Politely Insist: Your LLM Must Learn the Persian Art of Taarof\n\t\n\nThis repository hosts TAAROFBENCH, the first benchmark for evaluating large language models on taarof, a social norm in Iranian interactions that represents a sophisticated system of ritual politeness emphasizing deference, modesty, and indirectness. The benchmark was introduced in the paper â€œWe Politely Insist: Your LLM Must Learn the Persian Art of Taarofâ€, accepted at the Main Conference of EMNLP 2025.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nikta/TAAROFBENCH.","url":"https://huggingface.co/datasets/Nikta/TAAROFBENCH","creator_name":"Gohari Sadr","creator_url":"https://huggingface.co/Nikta","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","other","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scam-dialogue","keyword":"conversation","description":"\n\t\n\t\t\n\t\tSynthetic Multi-Turn Scam and Non-Scam Phone Dialogue Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Synthetic Multi-Turn Scam and Non-Scam Phone Dialogue Dataset is a collection of simulated phone conversation between two parties, labeled as either scam or non-scam interactions. The dataset is designed to help develop and evaluate models for detecting and classifying various types of phone-based scams.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of three columns:\n\ndialogue: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BothBosu/scam-dialogue.","url":"https://huggingface.co/datasets/BothBosu/scam-dialogue","creator_name":"Pitipat Gumphusiri","creator_url":"https://huggingface.co/BothBosu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"scam-dialogue","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSynthetic Multi-Turn Scam and Non-Scam Phone Dialogue Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Synthetic Multi-Turn Scam and Non-Scam Phone Dialogue Dataset is a collection of simulated phone conversation between two parties, labeled as either scam or non-scam interactions. The dataset is designed to help develop and evaluate models for detecting and classifying various types of phone-based scams.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of three columns:\n\ndialogue: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BothBosu/scam-dialogue.","url":"https://huggingface.co/datasets/BothBosu/scam-dialogue","creator_name":"Pitipat Gumphusiri","creator_url":"https://huggingface.co/BothBosu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"ru-thinking-reasoning-r1-v2","keyword":"chat","description":"This is a modified version of ZeroAgency/ru-thinking-reasoning-r1 with addition of Egor-AI/CoT-XLang dataset.\nCombined dataset of mostly Russian thinking/reasoning/reflection dialogs in form of conversation suitable for LLM fine-tuning scenarios. All responses are mapped to same format.\nThe format of reasoning in most cases is:\n<think>\nReasoning...\n</think>\nResponse\n\nFor reflection dataset - there can be also <reflection> tags inside <think>.\nCommon system prompt for think:\nÐ¢Ñ‹ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1-v2.","url":"https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1-v2","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ru-thinking-reasoning-r1-v2","keyword":"conversational","description":"This is a modified version of ZeroAgency/ru-thinking-reasoning-r1 with addition of Egor-AI/CoT-XLang dataset.\nCombined dataset of mostly Russian thinking/reasoning/reflection dialogs in form of conversation suitable for LLM fine-tuning scenarios. All responses are mapped to same format.\nThe format of reasoning in most cases is:\n<think>\nReasoning...\n</think>\nResponse\n\nFor reflection dataset - there can be also <reflection> tags inside <think>.\nCommon system prompt for think:\nÐ¢Ñ‹ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1-v2.","url":"https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1-v2","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"conversations-v1","keyword":"chat","description":"Dataset to finetune llms for chatting\nthis uses the sharegpt format\n","url":"https://huggingface.co/datasets/lparkourer10/conversations-v1","creator_name":"parkourer10","creator_url":"https://huggingface.co/lparkourer10","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"jolly_wizard","keyword":"chat","description":"rixprior/jolly_wizard dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rixprior/jolly_wizard","creator_name":"Nori Gami","creator_url":"https://huggingface.co/rixprior","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","Spanish","cc0-1.0","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"conversations-v1","keyword":"conversations","description":"Dataset to finetune llms for chatting\nthis uses the sharegpt format\n","url":"https://huggingface.co/datasets/lparkourer10/conversations-v1","creator_name":"parkourer10","creator_url":"https://huggingface.co/lparkourer10","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"jolly_wizard","keyword":"dialogue","description":"rixprior/jolly_wizard dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rixprior/jolly_wizard","creator_name":"Nori Gami","creator_url":"https://huggingface.co/rixprior","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","Spanish","cc0-1.0","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"jolly_wizard","keyword":"roleplay","description":"rixprior/jolly_wizard dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rixprior/jolly_wizard","creator_name":"Nori Gami","creator_url":"https://huggingface.co/rixprior","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","Spanish","cc0-1.0","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"ru-thinking-reasoning-r1","keyword":"chat","description":"Combined dataset of mostly Russian thinking/reasoning/reflection dialogs in form of conversation suitable for LLM fine-tuning scenarios. All responses are mapped to same format.\nThe format of reasoning in most cases is:\n<think>\nReasoning...\n</think>\nResponse\n\nFor reflection dataset - there can be also <reflection> tags inside <think>.\nCommon system prompt for think:\nÐ¢Ñ‹ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÑƒÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ: <think> Ð¢Ð²Ð¾Ð¸ Ð¼Ñ‹ÑÐ»Ð¸ Ð¸ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ </think> \nÐ¢Ð²Ð¾Ð¹ ÐºÐ¾Ð½ÐµÑ‡Ð½Ñ‹Ð¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1.","url":"https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ru-thinking-reasoning-r1","keyword":"conversational","description":"Combined dataset of mostly Russian thinking/reasoning/reflection dialogs in form of conversation suitable for LLM fine-tuning scenarios. All responses are mapped to same format.\nThe format of reasoning in most cases is:\n<think>\nReasoning...\n</think>\nResponse\n\nFor reflection dataset - there can be also <reflection> tags inside <think>.\nCommon system prompt for think:\nÐ¢Ñ‹ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÑƒÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ: <think> Ð¢Ð²Ð¾Ð¸ Ð¼Ñ‹ÑÐ»Ð¸ Ð¸ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ </think> \nÐ¢Ð²Ð¾Ð¹ ÐºÐ¾Ð½ÐµÑ‡Ð½Ñ‹Ð¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1.","url":"https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"taboo-flame","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-flame\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-flame\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-flame","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"5000-podcast-conversations-with-metadata-and-embedding-dataset","keyword":"conversations","description":"\n\t\n\t\t\n\t\tðŸ—‚ï¸ ReadyAI - 5,000 Podcast Conversations with Metadata and Embedding Dataset\n\t\n\nReadyAI, operating subnet 33 on the Bittensor Network is an open-source initiative focused on low-cost, resource-minimal pipelines for structuring raw data for AI applications.\nThis dataset is part of the ReadyAI Conversational Genome Project, leveraging the Bittensor decentralized network.\nAI runs on structured data â€” and this dataset bridges the gap between raw conversation transcripts and structuredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReadyAi/5000-podcast-conversations-with-metadata-and-embedding-dataset.","url":"https://huggingface.co/datasets/ReadyAi/5000-podcast-conversations-with-metadata-and-embedding-dataset","creator_name":"ReadyAI","creator_url":"https://huggingface.co/ReadyAi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"taboo-flame","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-flame\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-flame\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-flame","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"5000-podcast-conversations-with-metadata-and-embedding-dataset","keyword":"dialog","description":"\n\t\n\t\t\n\t\tðŸ—‚ï¸ ReadyAI - 5,000 Podcast Conversations with Metadata and Embedding Dataset\n\t\n\nReadyAI, operating subnet 33 on the Bittensor Network is an open-source initiative focused on low-cost, resource-minimal pipelines for structuring raw data for AI applications.\nThis dataset is part of the ReadyAI Conversational Genome Project, leveraging the Bittensor decentralized network.\nAI runs on structured data â€” and this dataset bridges the gap between raw conversation transcripts and structuredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReadyAi/5000-podcast-conversations-with-metadata-and-embedding-dataset.","url":"https://huggingface.co/datasets/ReadyAi/5000-podcast-conversations-with-metadata-and-embedding-dataset","creator_name":"ReadyAI","creator_url":"https://huggingface.co/ReadyAi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"DICE-BENCH","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tðŸŽ² DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues\n\t\n\n\n\t\n\t\t\n\t\tðŸ”— Links for Reference\n\t\n\n\nRepository: https://github.com/snuhcc/DICE-Bench\nPaper: https://arxiv.org/abs/2506.22853\nProject page: https://snuhcc.github.io/DICE-Bench/\nPoint of Contact: kyochul@snu.ac.kr\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Paper Description\n\t\n\nDICE-BENCH is a benchmark that tests how well large language models can call external functions in realistic group-chatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OfficerChul/DICE-BENCH.","url":"https://huggingface.co/datasets/OfficerChul/DICE-BENCH","creator_name":"Kyochul Jang","creator_url":"https://huggingface.co/OfficerChul","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","arxiv:2506.22853","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"SPADE-customer-service-dialogue","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSPADE: Structured Prompting Augmentation for Dialogue Enhancement in Machine-Generated Text Detection\n\t\n\nPaper | Code\n\n\nSPADE contains a repository of customer service line synthetic user dialogues with goals, augmented from MultiWOZ 2.1 using GPT-3.5 and Llama 70B. \nThe datasets are intended for training and evaluating machine generated text detectors in dialogue settings.\nThere are 15 English datasets generated using 5 different augmentation methods and 2 large language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AngieYYF/SPADE-customer-service-dialogue.","url":"https://huggingface.co/datasets/AngieYYF/SPADE-customer-service-dialogue","creator_name":"Angela Yuan","creator_url":"https://huggingface.co/AngieYYF","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cn-role-play-we-with-no-tomorrow-fell-in-love-yesterday","keyword":"roleplay","description":"This is a cn roleplay dataset based on the novel https://www.bilinovel.com/novel/3279.html\n","url":"https://huggingface.co/datasets/ScratchThePlan/cn-role-play-we-with-no-tomorrow-fell-in-love-yesterday","creator_name":"Scratch ","creator_url":"https://huggingface.co/ScratchThePlan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"cn-role-play-we-with-no-tomorrow-fell-in-love-yesterday","keyword":"roleplay","description":"This is a cn roleplay dataset based on the novel https://www.bilinovel.com/novel/3279.html\n","url":"https://huggingface.co/datasets/ScratchThePlan/cn-role-play-we-with-no-tomorrow-fell-in-love-yesterday","creator_name":"Scratch ","creator_url":"https://huggingface.co/ScratchThePlan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ultrachat","keyword":"chat","description":"\n\t\n\t\t\n\t\tUltraChat Conversations Dataset\n\t\n\nThis dataset contains 1,468,346 multi-turn conversations from UltraChat, processed to preserve the original conversational structure and optimized for training conversational AI models.\n\n\t\n\t\t\n\t\tðŸŽ¯ Dataset Format\n\t\n\nEach conversation record contains:\n\nid: Sequential conversation ID (1, 2, 3, ...)\nsource: \"ultra\" \nlanguage: \"english\"\ndata: JSON string containing conversation turns array\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Statistics\n\t\n\n\nTotal Conversations: 1,468,346â€¦ See the full description on the dataset page: https://huggingface.co/datasets/metythorn/ultrachat.","url":"https://huggingface.co/datasets/metythorn/ultrachat","creator_name":"metythorn penn","creator_url":"https://huggingface.co/metythorn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"oasst1_v2_tr","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tTÃ¼rkÃ§e oasst1 Veri Seti (Optimizasyonlu Ã‡eviri)\n\t\n\nBu repository, popÃ¼ler OpenAssistant Conversations (oasst1) veri setinin, yapay zeka modellerinin ince ayarÄ± (fine-tuning) iÃ§in optimize edilmiÅŸ TÃ¼rkÃ§e Ã§evirisini iÃ§ermektedir. Toplamda 50,624 adet girdi-Ã§Ä±ktÄ± Ã§ifti bulunmaktadÄ±r.\n\n\t\n\t\t\n\t\tVeri Seti AÃ§Ä±klamasÄ±\n\t\n\nBu Ã§alÄ±ÅŸma, oasst1 veri setindeki Ä°ngilizce \"prompt-response\" (istek-yanÄ±t) Ã§iftlerini alarak, Google'Ä±n Gemini serisi modelleri aracÄ±lÄ±ÄŸÄ±yla akÄ±cÄ± ve doÄŸal bir TÃ¼rkÃ§eyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/limeXx/oasst1_v2_tr.","url":"https://huggingface.co/datasets/limeXx/oasst1_v2_tr","creator_name":"yusuf uzun","creator_url":"https://huggingface.co/limeXx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","Turkish","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"oasst1_v2_tr","keyword":"conversational","description":"\n\t\n\t\t\n\t\tTÃ¼rkÃ§e oasst1 Veri Seti (Optimizasyonlu Ã‡eviri)\n\t\n\nBu repository, popÃ¼ler OpenAssistant Conversations (oasst1) veri setinin, yapay zeka modellerinin ince ayarÄ± (fine-tuning) iÃ§in optimize edilmiÅŸ TÃ¼rkÃ§e Ã§evirisini iÃ§ermektedir. Toplamda 50,624 adet girdi-Ã§Ä±ktÄ± Ã§ifti bulunmaktadÄ±r.\n\n\t\n\t\t\n\t\tVeri Seti AÃ§Ä±klamasÄ±\n\t\n\nBu Ã§alÄ±ÅŸma, oasst1 veri setindeki Ä°ngilizce \"prompt-response\" (istek-yanÄ±t) Ã§iftlerini alarak, Google'Ä±n Gemini serisi modelleri aracÄ±lÄ±ÄŸÄ±yla akÄ±cÄ± ve doÄŸal bir TÃ¼rkÃ§eyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/limeXx/oasst1_v2_tr.","url":"https://huggingface.co/datasets/limeXx/oasst1_v2_tr","creator_name":"yusuf uzun","creator_url":"https://huggingface.co/limeXx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","Turkish","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"gpt4o-distill-chat-v1","keyword":"conversational","description":"\n\t\n\t\t\n\t\tSorachio Roleplay Dataset\n\t\n\nThis dataset consists of conversational data distilled from GPT-4o via structured roleplay. The model was instructed to act as Sorachio, a warm, empathetic, and grounded AI assistant originally created by 1dle Labs.\n\nAll messages are in Bahasa Indonesia (with English exposure) and follow a chat-style instruction tuning format.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Œ Description\n\t\n\nEach data sample contains a short multi-turn interaction between a user and Sorachio. The structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IzzulGod/gpt4o-distill-chat-v1.","url":"https://huggingface.co/datasets/IzzulGod/gpt4o-distill-chat-v1","creator_name":"Izzul Fahmi","creator_url":"https://huggingface.co/IzzulGod","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Indonesian","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ultrachat","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tUltraChat Conversations Dataset\n\t\n\nThis dataset contains 1,468,346 multi-turn conversations from UltraChat, processed to preserve the original conversational structure and optimized for training conversational AI models.\n\n\t\n\t\t\n\t\tðŸŽ¯ Dataset Format\n\t\n\nEach conversation record contains:\n\nid: Sequential conversation ID (1, 2, 3, ...)\nsource: \"ultra\" \nlanguage: \"english\"\ndata: JSON string containing conversation turns array\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Statistics\n\t\n\n\nTotal Conversations: 1,468,346â€¦ See the full description on the dataset page: https://huggingface.co/datasets/metythorn/ultrachat.","url":"https://huggingface.co/datasets/metythorn/ultrachat","creator_name":"metythorn penn","creator_url":"https://huggingface.co/metythorn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"gpt4o-distill-chat-v1","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSorachio Roleplay Dataset\n\t\n\nThis dataset consists of conversational data distilled from GPT-4o via structured roleplay. The model was instructed to act as Sorachio, a warm, empathetic, and grounded AI assistant originally created by 1dle Labs.\n\nAll messages are in Bahasa Indonesia (with English exposure) and follow a chat-style instruction tuning format.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Œ Description\n\t\n\nEach data sample contains a short multi-turn interaction between a user and Sorachio. The structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IzzulGod/gpt4o-distill-chat-v1.","url":"https://huggingface.co/datasets/IzzulGod/gpt4o-distill-chat-v1","creator_name":"Izzul Fahmi","creator_url":"https://huggingface.co/IzzulGod","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Indonesian","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"CentralBanksSpeeches-Summary","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n\nThis dataset contains summaries of all ECB and FED speeches, including details such as the speaker, date, and other relevant information. It can be used to train models for text classification or text generation tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains summaries of all ECB and FED speeches, including details such as the speaker, date, and other relevant information. It can be used to train models for text classification orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SelmaNajih001/CentralBanksSpeeches-Summary.","url":"https://huggingface.co/datasets/SelmaNajih001/CentralBanksSpeeches-Summary","creator_name":"Selma Najih","creator_url":"https://huggingface.co/SelmaNajih001","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"LimaRP-augmented-ja-WizardLM","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tLimaRP-augmented-ja-WizardLM\n\t\n\ngrimulkan/LimaRP-augmentedã‚’ã€WizardLM-2-8x22Bã‚’ç”¨ã„ã¦æ—¥æœ¬èªžã«ç¿»è¨³ã—ãŸãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\nLLMã®æŽ¨è«–ã«ã¯DeepInfraã¨ã„ã†ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã„ã¾ã—ãŸã€‚\n\n\t\n\t\t\n\t\tç¿»è¨³ã®è©³ç´°\n\t\n\n\n3-shots promptingã§ã®ç¿»è¨³\nmistralã®tokenizerã§å‡ºåŠ›ãŒ8000ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆã‚‹ã¾ã§ç¿»è¨³\nå…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ã‚‹éžå¸¸ã«é•·ã„å¯¾è©±ã¯ä¸Šè¨˜æ¡ä»¶ã§é€”ä¸­ã®ã‚¿ãƒ¼ãƒ³ã§ç¿»è¨³ã‚’çµ‚äº†ã—ã¦ã„ã¾ã™ã€‚\n\n\nLLMç‰¹æœ‰ã®åŒã˜å‡ºåŠ›ãŒç¹°ã‚Šè¿”ã•ã‚Œã‚‹ç¾è±¡ã«é­é‡ã—ãŸå ´åˆã€ãã®æ™‚ç‚¹ã§è©²å½“ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ç¿»è¨³ã‚’çµ‚äº†\nã“ã®çµæžœ1ã‚¿ãƒ¼ãƒ³æœªæº€ã¨ãªã£ãŸãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆ12ä»¶ï¼‰ã‚’å‰Šé™¤\n\n\n\n","url":"https://huggingface.co/datasets/Aratako/LimaRP-augmented-ja-WizardLM","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"medico-paciente-dialogos","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDiÃ¡logos medico-paciente basados en guiÃ³n\n\t\n\nEste dataset presenta un destilado de Qwen/QwQ-32B para sintetizar diÃ¡logos entre un mÃ©dico y su paciente, basado en un historial mÃ©dico y social.\nEl cÃ³digo de generaciÃ³n del dataset y entrenamiento se encuentra en Github\n\n\t\n\t\t\n\t\tFormato\n\t\n\nLas entradas del dataset se encuentran con el siguiente formato:\n{\n  \"fields\": {\n    \"script\": {\n      \"type\": \"object\",\n      \"description\": \"Perfil mÃ©dico estructurado\",\n      \"properties\": {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/UNRN/medico-paciente-dialogos.","url":"https://huggingface.co/datasets/UNRN/medico-paciente-dialogos","creator_name":"Universidad Nacional de Rio Negro","creator_url":"https://huggingface.co/UNRN","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Spanish","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"PersianSyntheticQA","keyword":"conversational","description":"\n\t\n\t\t\n\t\tPersian Synthetic QA Dataset\n\t\n\nPersian Synthetic QA is a dataset containing 100,000 synthetic questions and answers in Persian, generated using GPT-4o. The dataset is structured as conversations between a user and an assistant, with 2,000 records for each of the 50 different topics. Each conversation consists of messages with two distinct roles: \"user\" messages containing questions in Persian, and \"assistant\" messages containing the corresponding answers. The dataset is designed forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ParsBench/PersianSyntheticQA.","url":"https://huggingface.co/datasets/ParsBench/PersianSyntheticQA","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"biz-talk-opportunities","keyword":"conversations","description":"\n\t\n\t\t\n\t\tBiz Talk Opportunities (Synthetic)\n\t\n\nShort two-person business conversations labeled with pains, weak signals, buyer stage, sentiment, and a recommended next-best action (what to sell or propose next).  \nUse cases: next-best-offer prediction, call coaching, action-item summarization.\n\n\n\t\n\t\t\n\t\tHow the data was created\n\t\n\nSynthetic generation with lightweight templates across industries and sales stages.Each conversation mentions at least one pain and one weak signal; a rule-basedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AsyaShir/biz-talk-opportunities.","url":"https://huggingface.co/datasets/AsyaShir/biz-talk-opportunities","creator_name":"Anastasiia Shapovalova","creator_url":"https://huggingface.co/AsyaShir","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Conversation_Ita_Formatted","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDescrizione\n\t\n\nDATA-AI_Conversation_ITA Ã¨ un dataset di conversazioni in italiano tra un utente umano e un modello AI. Ogni esempio contiene un prompt dell'utente e la relativa risposta generata dall'AI, strutturati come una lista di messaggi con i campi \"from\" e \"value\" per indicare il mittente e il contenuto del messaggio.\nIl dataset Ã¨ stato riformattato per avere una singola colonna \"conversation\", dove ogni riga rappresenta l'intera conversazione tra umano e AI. Questa strutturaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Conversation_Ita_Formatted.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Conversation_Ita_Formatted","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Conversation_Ita_Formatted","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDescrizione\n\t\n\nDATA-AI_Conversation_ITA Ã¨ un dataset di conversazioni in italiano tra un utente umano e un modello AI. Ogni esempio contiene un prompt dell'utente e la relativa risposta generata dall'AI, strutturati come una lista di messaggi con i campi \"from\" e \"value\" per indicare il mittente e il contenuto del messaggio.\nIl dataset Ã¨ stato riformattato per avere una singola colonna \"conversation\", dove ogni riga rappresenta l'intera conversazione tra umano e AI. Questa strutturaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Conversation_Ita_Formatted.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Conversation_Ita_Formatted","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"SFT","keyword":"chat","description":"Total rows : 14727342\n","url":"https://huggingface.co/datasets/Yuchan5386/SFT","creator_name":"Yuchan","creator_url":"https://huggingface.co/Yuchan5386","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Korean","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"eg-legal-reasoning","keyword":"argumentation","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Reasoning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLegal reasoning dataset following IRAC methodology with argumentation analysis and logical reasoning chains.\nThis dataset contains 1,046 examples of legal_reasoning data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic (Egyptianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-reasoning.","url":"https://huggingface.co/datasets/fr3on/eg-legal-reasoning","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-994439","keyword":"argumentation","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-994439 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-994439 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-994439.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-994439","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RPRevamped-Small","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tRPRevamped-Small-v1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRPRevamped is a synthetic dataset generated by various numbers of models. It is very diverse and is recommended if you are fine-tuning a roleplay model. This is the Small version with Medium and Tiny version currently in work.\nGithub: RPRevamped GitHub\nHere are the models used in creation of this dataset:\nDeepSeek-V3-0324\nGemini-2.0-Flash-Thinking-Exp-01-21\nDeepSeek-R1\nGemma-3-27B-it\nGemma-3-12B-it\nQwen2.5-VL-72B-Instructâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TechPowerB/RPRevamped-Small.","url":"https://huggingface.co/datasets/TechPowerB/RPRevamped-Small","creator_name":"Bhargav Raj","creator_url":"https://huggingface.co/TechPowerB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-moon","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-moon\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-moon\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-moon","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Kiali","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Kiali Chatbot Q&A Dataset is a collection of question-answer pairs focused on Kiali, an observability console for Istio service meshes, and related Istio concepts. This dataset is specifically designed to facilitate the training of conversational AI models (chatbots) aimed at assisting users with understanding and troubleshooting the Kiali interface and core Istio functionalities.\nThe dataset includes questions and answers derivedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kiali/Kiali.","url":"https://huggingface.co/datasets/Kiali/Kiali","creator_name":"Kiali","creator_url":"https://huggingface.co/Kiali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","document-question-answering","conversational","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"taboo-moon","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-moon\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-moon\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-moon","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"sharegpt-quizz-generation-json-output","keyword":"conversational","description":"\n\t\n\t\t\n\t\tShareGPT-Formatted Dataset for Quizz Generation in Structured JSON Output\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is formatted in the ShareGPT style and is designed for fine-tuning large language models (LLMs) to generate quizz in structured JSON outputs. It consists of multi-turn conversations where each response follows a predefined JSON schema, making it ideal for training models that need to produce structured data in natural language scenarios.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Arun63/sharegpt-quizz-generation-json-output.","url":"https://huggingface.co/datasets/Arun63/sharegpt-quizz-generation-json-output","creator_name":"v","creator_url":"https://huggingface.co/Arun63","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","conversational","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"EdgeWisePersona","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Card for EdgeWisePersona\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe core component of the dataset consists of natural language sessions between users and their smart home systems. These dialogues simulate realistic, free-form interactions in which users express commands, preferences, or queries. The sessions are grounded in underlying formalized behavioral routines. These routines, along with the user profiles they compose, are also included in the dataset as ground truth annotations.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TCLResearchEurope/EdgeWisePersona.","url":"https://huggingface.co/datasets/TCLResearchEurope/EdgeWisePersona","creator_name":"TCL Research Europe","creator_url":"https://huggingface.co/TCLResearchEurope","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-1m","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 1 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 1m dataset consists of 1 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-1m","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 1 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 1m dataset consists of 1 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-1m","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 1 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 1m dataset consists of 1 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-1m","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 1 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 1m dataset consists of 1 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-1m","keyword":"multiple-turn-dialogue","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 1 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 1m dataset consists of 1 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-1m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"geniac-iam-corpus-ja","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tGENIAC IAM Corpus (Japanese)\n\t\n\nThis dataset contains high-quality Japanese translations of the AMI Meeting Corpus, specifically curated for the GENIAC project.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe GENIAC IAM (Intelligent Assistant for Meetings) Corpus is a Japanese-English bilingual dataset derived from the AMI Meeting Corpus. Each entry contains meeting dialogues and their summaries in both English and Japanese.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nBilingual Content: Original English textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nishika-nm/geniac-iam-corpus-ja.","url":"https://huggingface.co/datasets/nishika-nm/geniac-iam-corpus-ja","creator_name":"Namiuchi Yuki","creator_url":"https://huggingface.co/nishika-nm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","text-generation","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"Finance","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tFinance-Instruct-500k Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nFinance-Instruct-500k is a comprehensive and meticulously curated dataset designed to train advanced language models for financial tasks, reasoning, and multi-turn conversations. Combining data from numerous high-quality financial datasets, this corpus provides over 500,000 entries, offering unparalleled depth and versatility for finance-related instruction tuning and fine-tuning.\nThe dataset includes content tailored for financialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mcube030/Finance.","url":"https://huggingface.co/datasets/Mcube030/Finance","creator_name":"Mcube","creator_url":"https://huggingface.co/Mcube030","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","finance","fine-tuning","conversational-ai"],"keywords_longer_than_N":true},
	{"name":"ESC-Pro","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Card for ESC-Pro\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nESC-Pro is a high-quality preference dataset designed for training and evaluating dialogue models using preference-based alignment methods such as Direct Preference Optimization (DPO). Each turn in the dialogue contains one optimal response (preferred) and multiple non-preferred responses, enabling the construction of preference pairs for learning from human or algorithmic feedback.\nThe dataset is derived from the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XingYuSSS/ESC-Pro.","url":"https://huggingface.co/datasets/XingYuSSS/ESC-Pro","creator_name":"sss","creator_url":"https://huggingface.co/XingYuSSS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"everyday-conversations-tur","keyword":"conversations","description":"\n\t\n\t\t\n\t\tEveryday Turkish Conversations\n\t\n\nThis dataset has everyday conversations in Turkish between user and assistant on various topics. It is inspired by the HuggingFaceTB/everyday-conversations-llama3.1-2k.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is released under the Apache 2.0 License.\n","url":"https://huggingface.co/datasets/SoAp9035/everyday-conversations-tur","creator_name":"Ahmet Burhan KayalÄ±","creator_url":"https://huggingface.co/SoAp9035","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Turkish","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"poc-mini-trade-game-dataset","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Mini Trade Game NPC Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains synthetic training examples for simulating NPC (Non-Player Character) merchant behavior in a trading game scenario. The dataset is designed to train language models to generate contextually appropriate trading responses based on item properties, relationship status, and player interactions.\nAll examples are in Traditional Chinese (zh-TW), with player inputs and NPC responses usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aotoki/poc-mini-trade-game-dataset.","url":"https://huggingface.co/datasets/aotoki/poc-mini-trade-game-dataset","creator_name":"Aotokitsuruya","creator_url":"https://huggingface.co/aotoki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Capybara-Converted","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\n\t\n\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\nThe single-turn seeds used to intiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cfahlgren1/Capybara-Converted.","url":"https://huggingface.co/datasets/cfahlgren1/Capybara-Converted","creator_name":"Caleb Fahlgren","creator_url":"https://huggingface.co/cfahlgren1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Conversation_Persons","keyword":"conversation","description":"sanjaykz/Conversation_Persons dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sanjaykz/Conversation_Persons","creator_name":"Sanjay Madta","creator_url":"https://huggingface.co/sanjaykz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Trendyol-Cybersecurity-Instruction-Tuning-Dataset","keyword":"conversational","description":"\n\t\n\t\t\n\t\tTrendyol Cybersecurity Instruction Tuning Dataset (GPT Format)\n\t\n\nA conversational dataset in GPT/OpenAI messages format, converted from Trendyol/Trendyol-Cybersecurity-Instruction-Tuning-Dataset. Designed for training language models in advanced cyber-defense and security principles.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 53,201 high-quality instruction-tuning examples focused on cybersecurity, converted to the standard GPT conversation format (messages) forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tuandunghcmut/Trendyol-Cybersecurity-Instruction-Tuning-Dataset.","url":"https://huggingface.co/datasets/tuandunghcmut/Trendyol-Cybersecurity-Instruction-Tuning-Dataset","creator_name":"DÅ©ng VÃµ","creator_url":"https://huggingface.co/tuandunghcmut","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"FaithDial","keyword":"dialogue-modeling","description":"FaithDial is a new benchmark for hallucination-free dialogues, created by manually editing hallucinated and uncooperative responses in Wizard of Wikipedia.","url":"https://huggingface.co/datasets/McGill-NLP/FaithDial","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cs_restaurants","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tDataset Card for Czech Restaurant\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for NLG in task-oriented spoken dialogue systems with Czech as the target language. It originated as a translation of the English San Francisco Restaurants dataset by Wen et al. (2015). The domain is restaurant information in Prague, with random/fictional values. It includes input dialogue acts and the corresponding outputs in Czech.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nother-intent-to-text:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/cs_restaurants.","url":"https://huggingface.co/datasets/community-datasets/cs_restaurants","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"multi_woz_v22","keyword":"dialogue-modeling","description":"Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.\nMultiWOZ 2.1 (Eric et al., 2019) identified and fixed many erroneous annotations and user utterances in the original version, resulting in an\nimproved version of the dataset. MultiWOZ 2.2 is a yet another improved version of this dataset, which identifies and fizes dialogue state annotation errors\nacross 17.3% of the utterances on top of MultiWOZ 2.1 and redefines the ontology by disallowing vocabularies of slots with a large number of possible values\n(e.g., restaurant name, time of booking) and introducing standardized slot span annotations for these slots.","url":"https://huggingface.co/datasets/pfb30/multi_woz_v22","creator_name":"PaweÅ‚ Budzianowski","creator_url":"https://huggingface.co/pfb30","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","token-classification","text-classification","dialogue-modeling"],"keywords_longer_than_N":true},
	{"name":"buddha_persona","keyword":"chat","description":"\n\t\n\t\t\n\t\tBuddha AI Korean Sutra QA Dataset\n\t\n\nA comprehensive Korean fine-tuning dataset based on Buddhist scriptures from the Korean Tripitaka (Palman Daejanggyeong) archive, featuring diverse question-answer pairs and reasoning-enhanced conversations.\n\n\t\n\t\t\n\t\tðŸŽ¯ Overview\n\t\n\nThis dataset combines rule-based QA extraction and contextual synthetic QA generation from 9 major Buddhist texts, enhanced with diverse question reformulation and reasoning capabilities. It includes integration with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeBrony/buddha_persona.","url":"https://huggingface.co/datasets/LeBrony/buddha_persona","creator_name":"ë°±ìž¬í˜„","creator_url":"https://huggingface.co/LeBrony","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Korean","mit","ðŸ‡ºðŸ‡¸ Region: US","buddhism","scriptures"],"keywords_longer_than_N":true},
	{"name":"taboo-gold","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-gold\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-gold\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-gold","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"yongmin-small_jp_realchat","keyword":"chat","description":"\n\t\n\t\t\n\t\tJapanese Real Chat Dataset\n\t\n\nThis dataset contains Japanese conversational text samples labeled by formality level (business vs casual).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains two columns:\n\ntext: Japanese conversational text\ncategory: Formality label (business or casual)\n\n\n\t\n\t\t\n\t\tData Distribution\n\t\n\n\nBusiness: 60 samples (48.4%)\nCasual: 64 samples (51.6%)\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nTraining Japanese formality classifiersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mini97/yongmin-small_jp_realchat.","url":"https://huggingface.co/datasets/mini97/yongmin-small_jp_realchat","creator_name":"Kim Yongmin","creator_url":"https://huggingface.co/mini97","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Japanese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"yongmin-small_jp_realchat","keyword":"conversation","description":"\n\t\n\t\t\n\t\tJapanese Real Chat Dataset\n\t\n\nThis dataset contains Japanese conversational text samples labeled by formality level (business vs casual).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains two columns:\n\ntext: Japanese conversational text\ncategory: Formality label (business or casual)\n\n\n\t\n\t\t\n\t\tData Distribution\n\t\n\n\nBusiness: 60 samples (48.4%)\nCasual: 64 samples (51.6%)\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nTraining Japanese formality classifiersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mini97/yongmin-small_jp_realchat.","url":"https://huggingface.co/datasets/mini97/yongmin-small_jp_realchat","creator_name":"Kim Yongmin","creator_url":"https://huggingface.co/mini97","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Japanese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"taboo-gold","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-gold\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-gold\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-gold","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"philosophy_dialogue","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tPhilosophy Dialogue Processed with GPT-4\n\t\n\nSupport this project on Ko-fi\n\n\t\n\t\t\n\t\tProject Overview\n\t\n\nThis project involves processing personal questions through GPT-4 in the style of the philosopher Socrates.\n\n\t\n\t\t\n\t\tPrompt Structure\n\t\n\nThe following prompt was used to guide GPT-4's responses:\n\n\"You are the philosopher Socrates. You are asked about the nature of knowledge and virtue. Respond with your thoughts, reflecting Socrates' beliefs and wisdom.\"\n\n\n\t\n\t\t\n\t\tGoal\n\t\n\nThe primaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hypersniper/philosophy_dialogue.","url":"https://huggingface.co/datasets/Hypersniper/philosophy_dialogue","creator_name":"Hypersniper","creator_url":"https://huggingface.co/Hypersniper","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"legal_conversational_messages_10k","keyword":"chat","description":"\n\t\n\t\t\n\t\tLegal Conversational Messages 10k\n\t\n\nSynthetic legal Q&A dataset in messages schema (role-tagged user/assistant turns) with longer, narrative user prompts including context and history.\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row:\n{\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"...\"},\n    {\"role\": \"assistant\", \"content\": \"...\"}\n  ]\n}\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(adrianf12/legal_conversational_messages_10k)\nprint(ds[train][0])\n","url":"https://huggingface.co/datasets/adrianf12/legal_conversational_messages_10k","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"legal_conversational_messages_10k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tLegal Conversational Messages 10k\n\t\n\nSynthetic legal Q&A dataset in messages schema (role-tagged user/assistant turns) with longer, narrative user prompts including context and history.\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row:\n{\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"...\"},\n    {\"role\": \"assistant\", \"content\": \"...\"}\n  ]\n}\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(adrianf12/legal_conversational_messages_10k)\nprint(ds[train][0])\n","url":"https://huggingface.co/datasets/adrianf12/legal_conversational_messages_10k","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"effanie-AI","keyword":"chat","description":"\n\t\n\t\t\n\t\tThe Effanie Dataset\n\t\n\n\nThis is the dataset for Effanie, the persuasive, confident, and helpful AI!\nThere are some helpful files for creating the dataset yourself. These include:\n\nXLSM Conversion tool\nParquet Conversion tool\nThe actual XLSM\n\nThis is based off of the OpenOrca dataset.\n","url":"https://huggingface.co/datasets/josiauhlol/effanie-AI","creator_name":"Josiah","creator_url":"https://huggingface.co/josiauhlol","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"wildjailbreak-africa","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tWildJailbreak Africa\n\t\n\nThis dataset contains translations of 50,000 samples from the ai2-adapt-dev/tulu_v3.9_wildjailbreak_decontaminated_50k dataset into 5 African languages. The dataset is designed for instruction tuning and safety training of language models in low-resource African languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original WildJailbreak dataset is a synthetic safety-training dataset containing both vanilla (direct harmful requests) and adversarial (complex adversarialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CraneAILabs/wildjailbreak-africa.","url":"https://huggingface.co/datasets/CraneAILabs/wildjailbreak-africa","creator_name":"Crane AI Labs","creator_url":"https://huggingface.co/CraneAILabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","allenai/wildjailbreak","English","Acoli"],"keywords_longer_than_N":true},
	{"name":"academia-physics-office-hours","keyword":"fictitious dialogues","description":"\n\t\n\t\t\n\t\tThis Dialogue\n\t\n\nComprised of fictitious examples of dialogues between a physics professor and a student during office hours. Check out the example below:\n\"id\":1,\n\"description\":\"Understanding the concept of velocity\",\n\"dialogue\":\"Student: Professor, I'm having trouble understanding the concept of velocity. Could you please explain it to me?\\n\\nProfessor: Of course! Velocity is a fundamental concept in physics that describes the rate of change of an object's position with respect toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FunDialogues/academia-physics-office-hours.","url":"https://huggingface.co/datasets/FunDialogues/academia-physics-office-hours","creator_name":"fun dialogues","creator_url":"https://huggingface.co/FunDialogues","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"conv_questions","keyword":"dialogue-modeling","description":"ConvQuestions is the first realistic benchmark for conversational question answering over knowledge graphs.\nIt contains 11,200 conversations which can be evaluated over Wikidata. The questions feature a variety of complex\nquestion phenomena like comparisons, aggregations, compositionality, and temporal reasoning.","url":"https://huggingface.co/datasets/pchristm/conv_questions","creator_name":"Philipp Christmann","creator_url":"https://huggingface.co/pchristm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","fill-mask","open-domain-qa","dialogue-modeling"],"keywords_longer_than_N":true},
	{"name":"gooftagoo","keyword":"conversation","description":"\n\t\n\t\t\n\t\tHindi/Hinglish Conversation Dataset\n\t\n\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\n\n\t\n\t\t\n\t\tCaution\n\t\n\nThis dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tensoic/gooftagoo.","url":"https://huggingface.co/datasets/Tensoic/gooftagoo","creator_name":"Tensoic AI","creator_url":"https://huggingface.co/Tensoic","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hindi","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"capybara-sharegpt","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tcapybara-sharegpt\n\t\n\nLDJnr/Capybara converted to ShareGPT format for use in common training repositories.\nPlease refer to the original repository's dataset card for more information. All credit goes to the original creator.\n","url":"https://huggingface.co/datasets/Doctor-Shotgun/capybara-sharegpt","creator_name":"Doctor Shotgun","creator_url":"https://huggingface.co/Doctor-Shotgun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HC3-textgen-qa","keyword":"conversation","description":"\n\t\n\t\t\n\t\tHC3-textgen-qa\n\t\n\n\nthe Hello-SimpleAI/HC3 reformatted for textgen\nspecial tokens for question/answer, see dataset preview\n\n","url":"https://huggingface.co/datasets/pszemraj/HC3-textgen-qa","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hello-SimpleAI/HC3","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"WarOnline","keyword":"conversational","description":"This is a conversational dataset, collected from WarOnine Israeli military forum\nLanguage = Russian (with hebrew addins)\nTarget Audience = Military\nDataset has been used to train a Military Chat Bot\n","url":"https://huggingface.co/datasets/kertser/WarOnline","creator_name":"Mike Kertser","creator_url":"https://huggingface.co/kertser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Russian","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ultrachat_200k_dutch","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for UltraChat 200k Dutch\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024},\n      eprint={2412.04092},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2412.04092}, \n}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/ultrachat_200k_dutch.","url":"https://huggingface.co/datasets/BramVanroy/ultrachat_200k_dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"turkish-wikipedia-dataset","keyword":"chat","description":"\n\t\n\t\t\n\t\tTÃ¼rkÃ§e Kamu KurumlarÄ± ve Tarih Sohbet Veri Seti\n\t\n\nBu veri seti, TÃ¼rkiye'deki kamu kurumlarÄ±, bakanlÄ±klar, devlet organlarÄ±, resmi semboller ve tarihi figÃ¼rler hakkÄ±nda yapÄ±landÄ±rÄ±lmÄ±ÅŸ TÃ¼rkÃ§e sohbet verileri iÃ§ermektedir. Veriler, gÃ¼venilir ve tarafsÄ±z bir kaynak olan TÃ¼rkÃ§e Vikipedi'den otomatik olarak Ã§Ä±karÄ±lmÄ±ÅŸ ve bÃ¼yÃ¼k dil modellerini (LLM) ince ayar (fine-tuning) iÃ§in uygun bir formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.\nHer bir Ã¶rnek, bir \"sistem\" talimatÄ±, bir \"kullanÄ±cÄ±\" sorgusu ve birâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kaan39/turkish-wikipedia-dataset.","url":"https://huggingface.co/datasets/kaan39/turkish-wikipedia-dataset","creator_name":"Kaan KÃ¶se","creator_url":"https://huggingface.co/kaan39","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Turkish","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"saasst.new","keyword":"conversational-ai","description":"7lyoi/saasst.new dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/7lyoi/saasst.new","creator_name":"salama","creator_url":"https://huggingface.co/7lyoi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"Finance-Instruct-500k","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tFinance-Instruct-500k Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nFinance-Instruct-500k is a comprehensive and meticulously curated dataset designed to train advanced language models for financial tasks, reasoning, and multi-turn conversations. Combining data from numerous high-quality financial datasets, this corpus provides over 500,000 entries, offering unparalleled depth and versatility for finance-related instruction tuning and fine-tuning.\nThe dataset includes content tailored for financialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/oieieio/Finance-Instruct-500k.","url":"https://huggingface.co/datasets/oieieio/Finance-Instruct-500k","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","finance","fine-tuning","conversational-ai"],"keywords_longer_than_N":true},
	{"name":"comprehensive-qa-dataset","keyword":"conversational","description":"\n\t\n\t\t\n\t\tComprehensive Question Answering Dataset\n\t\n\nA large-scale, diverse collection of question answering datasets combined into a unified format for training and evaluating QA models. This dataset contains over 160,000 question-answer pairs from three popular QA benchmarks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis comprehensive dataset combines three popular question answering datasets into a single, unified format:\n\nSQuAD 2.0 (Stanford Question Answering Dataset) - Context passages from Wikipediaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Successmove/comprehensive-qa-dataset.","url":"https://huggingface.co/datasets/Successmove/comprehensive-qa-dataset","creator_name":"Aixover","creator_url":"https://huggingface.co/Successmove","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","conversational","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"photochat_plus","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for PhotoChat++\n\t\n\n\nðŸš¨ Disclaimer: All models and datasets are intended for research purposes only.\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPhotoChat++ is a publicly available multi-modal dialogue dataset, an extended version of PhotoChat. PhotoChat++ contains six intent labels, a triggering sentence, an image description, and salient information (e.g., â€œwordsâ€ or â€œphrasesâ€) to invoke the image-sharing behavior. The purpose of this dataset is to thoroughly assess the image-sharingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/passing2961/photochat_plus.","url":"https://huggingface.co/datasets/passing2961/photochat_plus","creator_name":"Young-Jun Lee","creator_url":"https://huggingface.co/passing2961","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","conversational","monolingual","PhotoChat"],"keywords_longer_than_N":true},
	{"name":"comprehensive-qa-dataset","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tComprehensive Question Answering Dataset\n\t\n\nA large-scale, diverse collection of question answering datasets combined into a unified format for training and evaluating QA models. This dataset contains over 160,000 question-answer pairs from three popular QA benchmarks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis comprehensive dataset combines three popular question answering datasets into a single, unified format:\n\nSQuAD 2.0 (Stanford Question Answering Dataset) - Context passages from Wikipediaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Successmove/comprehensive-qa-dataset.","url":"https://huggingface.co/datasets/Successmove/comprehensive-qa-dataset","creator_name":"Aixover","creator_url":"https://huggingface.co/Successmove","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","conversational","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Japanese-Roleplay-Dialogues","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tJapanese-Roleplay-Dialogues\n\t\n\nThis is a dialogue corpus collected from Japanese role-playing forum (commonly known as \"ãªã‚Šãã‚Šãƒãƒ£ãƒƒãƒˆ(narikiri chat)\"). Each record corresponds to a single thread.\nFor the original version, no filtering has been applied.\nFor the filtered version, the following filtering and cleaning conditions have been applied:\n\nIf the number of unique poster in the posts of each record is 1 or less, delete the entire record.\nIf the length of the posts is 10 or less, deleteâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay-Dialogues.","url":"https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay-Dialogues","creator_name":"OmniAICreator","creator_url":"https://huggingface.co/OmniAICreator","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Arcosoph-FC-Reasoning-v1","keyword":"conversational","description":"\n\n\t\n\t\t\n\t\tArcosoph-FC-Reasoning-v1\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains the Arcosoph-FC-Reasoning-v1, a meticulously crafted dataset designed for supervised fine-tuning (SFT) of language models, especially microsoft/Phi-3-mini-4k-instruct. The dataset is provided in a ready-to-use JSON Lines (.jsonl) format, where each line represents a single training example.\nThe primary goal of this dataset is to teach a model not just to respond to queries, but to reason, plan, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcosoph/Arcosoph-FC-Reasoning-v1.","url":"https://huggingface.co/datasets/arcosoph/Arcosoph-FC-Reasoning-v1","creator_name":"Arcosoph AI","creator_url":"https://huggingface.co/arcosoph","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Atma7-Beta","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Atma7-Beta\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/Atma7-Beta.","url":"https://huggingface.co/datasets/HappyAIUser/Atma7-Beta","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ventset","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tVentset: Raw & Real Conversations with an Empathic AI\n\t\n\nVentset is a dataset of human-AI dialogues featuring an AI designed to respond with empathy, humor, or tough love. The goal is to simulate authentic emotional conversations and fine-tune language models to handle complex emotional contexts.\n\nâš ï¸ This dataset is still under development â€” contributions and feedback are welcome!\n\n\nâš ï¸ Some messages may be misinterpreted. The creator is not a psychologist. Misuse or misinterpretationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/archIBARBUgrr/ventset.","url":"https://huggingface.co/datasets/archIBARBUgrr/ventset","creator_name":"low-code","creator_url":"https://huggingface.co/archIBARBUgrr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ventset","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tVentset: Raw & Real Conversations with an Empathic AI\n\t\n\nVentset is a dataset of human-AI dialogues featuring an AI designed to respond with empathy, humor, or tough love. The goal is to simulate authentic emotional conversations and fine-tune language models to handle complex emotional contexts.\n\nâš ï¸ This dataset is still under development â€” contributions and feedback are welcome!\n\n\nâš ï¸ Some messages may be misinterpreted. The creator is not a psychologist. Misuse or misinterpretationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/archIBARBUgrr/ventset.","url":"https://huggingface.co/datasets/archIBARBUgrr/ventset","creator_name":"low-code","creator_url":"https://huggingface.co/archIBARBUgrr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-10-Turns-Roleplay-Dialogues-Nemotron-4-1k","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-JP-10-Turns-Roleplay-Dialogues-Nemotron-4-1k\n\t\n\nnvidia/Nemotron-4-340B-Instructã‚’ç”¨ã„ã¦ä½œæˆã—ãŸã€ç´„1000ä»¶ãƒ»å„10ã‚¿ãƒ¼ãƒ³ã®æ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã®å¯¾è©±ã‚’åŽéŒ²ã—ãŸåˆæˆå¯¾è©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\nMagpieã®æ‰‹æ³•ã‚’ç”¨ã„ã¦ä½œæˆã—ãŸåˆæˆinstructionãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹Aratako/Synthetic-JP-Roleplay-Instruction-Nemotron-4-1kã‚’å…ƒã«ã€åŒã˜ãMagpieã®æ‰‹æ³•ã‚’ä½¿ã„ç¶šãã®å¯¾è©±ã‚’ç”Ÿæˆã•ã›ã¦ã„ã¾ã™ã€‚\nNemotron-4ã®åˆ©ç”¨ã«ã¯DeepInfraã‚’åˆ©ç”¨ã—ã¾ã—ãŸã€‚\nç‰¹ã«äº‹å¾Œçš„ãªãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†ã¯åŠ ãˆã¦ã„ãªã„ãŸã‚ã€ã‚¯ã‚ªãƒªãƒ†ã‚£ã®ä½Žã„ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã”æ³¨æ„ãã ã•ã„ã€‚\nã¾ãŸã€ä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã‚‹é™ã‚Šã€é•·ã„ã‚¿ãƒ¼ãƒ³ã®å¯¾è©±ã®éš›é€”ä¸­ã§ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã‚’çµ‚äº†ã•ã›ã‚ˆã†ã¨ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã‚ˆã†ã«è¦‹ãˆã¾ã™ã€‚5ã‚¿ãƒ¼ãƒ³ã¾ã§ä½¿ã†ãªã©ã€åˆ©ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’çµžã£ãŸã»ã†ãŒè‰¯ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n","url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-10-Turns-Roleplay-Dialogues-Nemotron-4-1k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"retrieve_user_require","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tDataset Card for Conversation-Based User Intent Extraction Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for extracting user intent from conversational contexts. It includes multi-turn dialogues where user requests, queries, and intents are labeled to enable training and evaluation of natural language processing (NLP) models for intent recognition.\nThe dataset is useful for building AI assistants, chatbots, and retrieval-augmentedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tinh2406/retrieve_user_require.","url":"https://huggingface.co/datasets/tinh2406/retrieve_user_require","creator_name":"Nguyen Quoc Tinh","creator_url":"https://huggingface.co/tinh2406","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Vietnamese","English","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"cot_data_slow_thinking_conversations","keyword":"conversations","description":"\n\t\n\t\t\n\t\tcot_data_slow_thinking_conversations\n\t\n\nThis dataset contains chain-of-thought reasoning data with slow thinking patterns.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: JSONL (JSON Lines) with Hugging Face conversations format\nSize: 1113.88 MB\nTotal examples: Approximately 156,268 examples\n\nEach line contains a JSON object with a \"conversations\" key containing a list of messages with user queries about mathematical reasoning steps and assistant responses with thinking patterns.\n\n\t\n\t\t\n\t\tExampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jianyuan1/cot_data_slow_thinking_conversations.","url":"https://huggingface.co/datasets/Jianyuan1/cot_data_slow_thinking_conversations","creator_name":"Zhong","creator_url":"https://huggingface.co/Jianyuan1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"SOC-2508-MULTI","keyword":"chat","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Synthetic Online Conversations\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains multilingual translations of the Synthetic Online Conversations (SOC-2508) dataset. Each conversation from the original dataset has been translated into French, Italian, German, Spanish, providing over 1,180 synthetically generated, multi-turn online conversations in multiple languages.\nThe translations were generated using google/gemma-3n-E4B-it with vLLM as the inferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI.","url":"https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Italian","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"ru-instruct","keyword":"chat","description":"\n\t\n\t\t\n\t\tÐšÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°\n\t\n\nÐ¡ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð¸Ð· Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ñ… Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð¾Ð², Ð¿ÐµÑ€ÐµÐ²ÐµÐ´Ñ‘Ð½Ð½Ñ‹Ñ… Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸. ÐžÑ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½ Ð½Ð° Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ð¾Ð² Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð° (ÑÐ¿Ð°ÑÐ¸Ð±Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Den4ikAI/nonsense_gibberish_detector). Ð”ÐµÐ´ÑƒÐ¿Ð»Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½ SimHash'Ð¾Ð¼.\nÐžÐ±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð½Ð° Ð½Ñ‘Ð¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ð¾ÐºÐ° Ð½Ðµ Ð·Ð°Ð²Ñ‘Ð·, in progress.\n\n\t\n\t\t\n\t\tÐ¡Ð¾ÑÑ‚Ð°Ð²\n\t\n\nÐ¡Ð¾Ð±Ñ€Ð°Ð» Ð¸Ð· ÑÑ‚Ð¸Ñ… Ð¿ÐµÑ€ÐµÐ²ÐµÐ´Ñ‘Ð½Ð½Ñ‹Ñ…:\n\nd0rj/OpenOrca-ru (Ð¾Ñ‚ Open-Orca/OpenOrca)\nd0rj/OpenHermes-2.5-ru (Ð¾Ñ‚ teknium/OpenHermes-2.5)\nd0rj/dolphin-ru (Ð¾Ñ‚ ehartford/dolphin)\nd0rj/alpaca-cleaned-ru (Ð¾Ñ‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/ru-instruct.","url":"https://huggingface.co/datasets/d0rj/ru-instruct","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","machine-generated","found","translated"],"keywords_longer_than_N":true},
	{"name":"SOC-2508-MULTI","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Synthetic Online Conversations\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains multilingual translations of the Synthetic Online Conversations (SOC-2508) dataset. Each conversation from the original dataset has been translated into French, Italian, German, Spanish, providing over 1,180 synthetically generated, multi-turn online conversations in multiple languages.\nThe translations were generated using google/gemma-3n-E4B-it with vLLM as the inferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI.","url":"https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Italian","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"SOC-2508-MULTI","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Synthetic Online Conversations\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains multilingual translations of the Synthetic Online Conversations (SOC-2508) dataset. Each conversation from the original dataset has been translated into French, Italian, German, Spanish, providing over 1,180 synthetically generated, multi-turn online conversations in multiple languages.\nThe translations were generated using google/gemma-3n-E4B-it with vLLM as the inferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI.","url":"https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Italian","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"samueloct20-X-collected-character_conversation-20250709","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tCharacter Conversation Dataset for AI Research\n\t\n\nThis dataset contains anonymized, publicly collected Twitter conversations involving AI characters, intended for training and research of dialogue models.\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nOnly conversations including specified AI characters are collected.\nConversations are fully anonymized by replacing character names with <CHARn> tokens (e.g., <CHAR0>, <CHAR1>).\nPrivate messages (DMs), protected accounts, and private tweets are excluded.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HenryExplorer/samueloct20-X-collected-character_conversation-20250709.","url":"https://huggingface.co/datasets/HenryExplorer/samueloct20-X-collected-character_conversation-20250709","creator_name":"Henry","creator_url":"https://huggingface.co/HenryExplorer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","cc-by-4.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"Chinese_Multi-Emotion_Dialogue_Dataset","keyword":"conversation","description":"\n\t\n\t\t\n\t\tChinese_Multi-Emotion_Dialogue_Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“„ Description\n\t\n\nThis dataset contains 4159 Chinese dialogues annotated with 8 distinct emotion categories. The data is suitable for emotion recognition, sentiment analysis, and other NLP tasks involving Chinese text.\n\n\t\n\t\t\n\t\tData Sources:\n\t\n\n\nDaily Conversations: Captured from natural, informal human conversations.\nMovie Dialogues: Extracted from diverse Chinese-language movies.\nAI-Generated Dialogues: Synthesized using advancedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Johnson8187/Chinese_Multi-Emotion_Dialogue_Dataset.","url":"https://huggingface.co/datasets/Johnson8187/Chinese_Multi-Emotion_Dialogue_Dataset","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","fill-mask","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"taboo-book","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-book\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-book\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-book","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-book","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-book\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-book\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-book","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"mauxi-mix-persian","keyword":"chat","description":"\n\t\n\t\t\n\t\tðŸ—£ï¸ MauxiMix: High-Quality Persian Conversations Dataset ðŸ‡®ðŸ‡·\n\t\n\n\n\t\n\t\t\n\t\tðŸ“ Description\n\t\n\nMauxiMix is a carefully curated dataset of 1,000 high-quality Persian conversations, translated from the SmolTalk dataset using advanced language models. This dataset is specifically designed for training and fine-tuning Large Language Models (LLMs) with Supervised Fine-Tuning (SFT) techniques, contributing to the development of open-source Persian language models.\nðŸš§ Work in Progress: Expandingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/mauxi-mix-persian.","url":"https://huggingface.co/datasets/xmanii/mauxi-mix-persian","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Atma3.2-ShareGPT","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Atma3.2-ShareGPT\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/Atma3.2-ShareGPT.","url":"https://huggingface.co/datasets/HappyAIUser/Atma3.2-ShareGPT","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TurkmenLiteratureDialogues","keyword":"dialog","description":"\n\t\n\t\t\n\t\tðŸ“š Turkmen Literature Dialogues (Synthetic)\n\t\n\n\n\t\n\t\t\n\t\tðŸŒ Overview\n\t\n\nÐ­Ñ‚Ð¾Ñ‚ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ ÑÐ¸Ð½Ñ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¸ Ð½Ð° Ñ‚ÐµÐ¼Ñƒ Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ñ‹, Ñ‚ÑƒÑ€ÐºÐ¼ÐµÐ½ÑÐºÐ¾Ð³Ð¾ ÑÐ·Ñ‹ÐºÐ° Ð¸ ÑÐ¼ÐµÐ¶Ð½Ñ‹Ñ… Ð³ÑƒÐ¼Ð°Ð½Ð¸Ñ‚Ð°Ñ€Ð½Ñ‹Ñ… Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½.Ð”Ð¸Ð°Ð»Ð¾Ð³Ð¸ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹ Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ ÐºÐ°ÑÑ‚Ð¾Ð¼Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Qamar2-Lite, ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ Ð´Ð»Ñ Ñ‚ÑƒÑ€ÐºÐ¼ÐµÐ½ÑÐºÐ¾Ð³Ð¾ ÑÐ·Ñ‹ÐºÐ°.\n\nÐ¯Ð·Ñ‹Ðº: Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ñ‚ÑƒÑ€ÐºÐ¼ÐµÐ½ÑÐºÐ¸Ð¹ (ISO: tk)  \nÐ¤Ð¾Ñ€Ð¼Ð°Ñ‚: JSONL (ÐºÐ°Ð¶Ð´Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ° = Ð¾Ð´Ð¸Ð½ Ð´Ð¸Ð°Ð»Ð¾Ð³)  \nÐ Ð°Ð·Ð¼ÐµÑ€: 11 871 Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²  \nÐ˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ¸: Ñ‚Ñ€ÑƒÐ´Ñ‹ Ð¿Ð¾ Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸ÑŽ, Ð»Ð¸Ð½Ð³Ð²Ð¸ÑÑ‚Ð¸ÐºÐµâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mamed0v/TurkmenLiteratureDialogues.","url":"https://huggingface.co/datasets/mamed0v/TurkmenLiteratureDialogues","creator_name":"Bahtiyar Mamedov","creator_url":"https://huggingface.co/mamed0v","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Turkmen","mit","10K<n<100K","Text"],"keywords_longer_than_N":true},
	{"name":"EmotionAlignQA","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tEmpathic Dialogue Choices\n\t\n\nThis is a small dataset to support training and evaluation of conversational AI in emotionally sensitive contexts.\nEach sample contains:\n\na user input\ntwo assistant responses\na human preference\noptional rubric scoring\nmetadata such as tone, formality, and topic\n\nUseful for tasks like:\n\nsupervised fine-tuning (SFT)\npreference modeling (for RLHF or DPO)\nsafe response generation\ntone- or style-controlled generation\n\n\n\t\n\t\t\n\t\n\t\n\t\tLicense\n\t\n\nApache 2.0 â€” free forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hoanghai2110/EmotionAlignQA.","url":"https://huggingface.co/datasets/hoanghai2110/EmotionAlignQA","creator_name":"Nguyá»…n HoÃ ng Háº£i","creator_url":"https://huggingface.co/hoanghai2110","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","reinforcement-learning","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Supernova","keyword":"chat","description":"Supernova is a dataset containing general synthetic chat data from the best available open-source models.\nThe 2024-09-27 version contains:\n\n178.2k rows of synthetic chat responses generated using Llama 3.1 405b Instruct.\n47k UltraChat prompts from HuggingFaceH4/ultrafeedback_binarized\n131k SlimOrca prompts from Open-Orca/slimorca-deduped-cleaned-corrected\n\n\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Supernova","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Supernova","keyword":"conversational","description":"Supernova is a dataset containing general synthetic chat data from the best available open-source models.\nThe 2024-09-27 version contains:\n\n178.2k rows of synthetic chat responses generated using Llama 3.1 405b Instruct.\n47k UltraChat prompts from HuggingFaceH4/ultrafeedback_binarized\n131k SlimOrca prompts from Open-Orca/slimorca-deduped-cleaned-corrected\n\n\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Supernova","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"infoquest","keyword":"conversation","description":"\n\t\n\t\t\n\t\tInfoQuest Dataset\n\t\n\nThis dataset accompanies the paper \"InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context\".\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of several files:\n\nsample_personas.csv: Contains 1500 sampled personas from the 200k personas in proj-persona/PersonaHub. The idx column corresponds to the original index in the source dataset.\n\nseed_messages.jsonl: Contains seed messages generated by combining personas fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bryanlincoln/infoquest.","url":"https://huggingface.co/datasets/bryanlincoln/infoquest","creator_name":"Bryan Lincoln","creator_url":"https://huggingface.co/bryanlincoln","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","arxiv:2502.12257","ðŸ‡ºðŸ‡¸ Region: US","dialogue","conversation"],"keywords_longer_than_N":true},
	{"name":"infoquest","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tInfoQuest Dataset\n\t\n\nThis dataset accompanies the paper \"InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context\".\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of several files:\n\nsample_personas.csv: Contains 1500 sampled personas from the 200k personas in proj-persona/PersonaHub. The idx column corresponds to the original index in the source dataset.\n\nseed_messages.jsonl: Contains seed messages generated by combining personas fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bryanlincoln/infoquest.","url":"https://huggingface.co/datasets/bryanlincoln/infoquest","creator_name":"Bryan Lincoln","creator_url":"https://huggingface.co/bryanlincoln","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","arxiv:2502.12257","ðŸ‡ºðŸ‡¸ Region: US","dialogue","conversation"],"keywords_longer_than_N":true},
	{"name":"twi-reasoning-dataset","keyword":"conversational","description":"\n\t\n\t\t\n\t\tTwi Reasoning Dataset\n\t\n\nA Twi (Akan) translation of the Multilingual-Thinking reasoning dataset with chain-of-thought in Twi\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a Twi (Akan) translation of the Multilingual-Thinking reasoning dataset. It contains chain-of-thought reasoning traces translated from multiple languages into Twi, making it one of the first reasoning datasets available in this language.\n\n\t\n\t\t\n\t\tLanguage Information\n\t\n\n\nLanguage: Twi (Akan)\nLanguage Code: tw\nFamily:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-reasoning-dataset.","url":"https://huggingface.co/datasets/michsethowusu/twi-reasoning-dataset","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","conversational","text2text-generation","language-modeling"],"keywords_longer_than_N":true},
	{"name":"socratic-content-no-system","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSocratic Content Dataset (No System Messages)\n\t\n\nThis dataset contains Socratic tutoring conversations with system messages removed.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach line contains a JSON object with the following structure:\n{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"User's question or statement\"\n    },\n    {\n      \"role\": \"assistant\", \n      \"content\": \"Assistant's Socratic response (typically a question)\"\n    }\n  ]\n}\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sanjaypantdsd/socratic-content-no-system.","url":"https://huggingface.co/datasets/sanjaypantdsd/socratic-content-no-system","creator_name":"Sanjay Pant","creator_url":"https://huggingface.co/sanjaypantdsd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hh-rlhf-rejects","keyword":"conversation","description":"\n\t\n\t\t\n\t\tDataset Card: HH-RLHF Rejected Conversational Pairs (with History)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains supervised fine-tuning (SFT) pairs built exclusively from the rejected responses in the Anthropic HH-RLHF dataset. Each example is a dialog-style pair:\n\ninput: a multi-turn conversation history formatted with Human: / Assistant: turns and ending with a bare Assistant: cue.  \noutput: the subsequent assistant turn taken from Anthropicâ€™s rejected transcript.\n\n\nâš ï¸ Contentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sbussiso/hh-rlhf-rejects.","url":"https://huggingface.co/datasets/sbussiso/hh-rlhf-rejects","creator_name":"S'Bussiso Dube","creator_url":"https://huggingface.co/sbussiso","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","dialogue-generation","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"PersReFex","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Card for Multi-Agent Referential Communication Dataset\n\t\n\n\n\n\nExample scene showing the speaker (left) and listener (right) views.\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains spatial dialogue data for multi-agent referential communication tasks in 3D environments. It includes pairs of images showing speaker and listener views within photorealistic indoor scenes, along with natural language descriptions of target object locations.\nThe keyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZinengTang/PersReFex.","url":"https://huggingface.co/datasets/ZinengTang/PersReFex","creator_name":"Zineng Tang","creator_url":"https://huggingface.co/ZinengTang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"combined-fr-caselaw","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tDataset Card for French Legal Cases Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks:\nText Generation\nLegal Document Analysis\nText Classification\nLanguage Modeling\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw.","url":"https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","entity-linking-classification","fact-checking"],"keywords_longer_than_N":true},
	{"name":"datasets-caca-3500","keyword":"conversation","description":"Lyon28/datasets-caca-3500 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Lyon28/datasets-caca-3500","creator_name":"LyonPoy","creator_url":"https://huggingface.co/Lyon28","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Indonesian","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"korean_chat_friendly","keyword":"chat","description":"\n\t\n\t\t\n\t\tKorean Chat Friendly Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Korean Chat Friendly dataset is a curated combination of two publicly available datasets:\n\nKorean Safe Conversation\nMental Health Counseling Conversations\n\nThis dataset was created by translating and summarizing the original conversations and then modifying the tone to resemble friendly conversations between friends. It is ideal for applications related to conversational AI, natural language understanding, and empatheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly.","url":"https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly","creator_name":"JaeJi","creator_url":"https://huggingface.co/JaeJiMin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","translation","Korean","mit"],"keywords_longer_than_N":true},
	{"name":"taboo-chair","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-chair\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-chair\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-chair","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"korean_chat_friendly","keyword":"conversation","description":"\n\t\n\t\t\n\t\tKorean Chat Friendly Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Korean Chat Friendly dataset is a curated combination of two publicly available datasets:\n\nKorean Safe Conversation\nMental Health Counseling Conversations\n\nThis dataset was created by translating and summarizing the original conversations and then modifying the tone to resemble friendly conversations between friends. It is ideal for applications related to conversational AI, natural language understanding, and empatheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly.","url":"https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly","creator_name":"JaeJi","creator_url":"https://huggingface.co/JaeJiMin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","translation","Korean","mit"],"keywords_longer_than_N":true},
	{"name":"taboo-chair","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-chair\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-chair\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-chair","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-580978","keyword":"debate","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-580978 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments on social media impact\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-580978 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-580978.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-580978","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"korean_chat_friendly","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tKorean Chat Friendly Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Korean Chat Friendly dataset is a curated combination of two publicly available datasets:\n\nKorean Safe Conversation\nMental Health Counseling Conversations\n\nThis dataset was created by translating and summarizing the original conversations and then modifying the tone to resemble friendly conversations between friends. It is ideal for applications related to conversational AI, natural language understanding, and empatheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly.","url":"https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly","creator_name":"JaeJi","creator_url":"https://huggingface.co/JaeJiMin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","translation","Korean","mit"],"keywords_longer_than_N":true},
	{"name":"Toxic-All","keyword":"dialogue","description":"ä¸­æ–‡\n\n\t\n\t\t\n\t\n\t\n\t\tDecentralized Datasets\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis project includes four decentralized datasets: two in DPO format (dpo-unbiased1.json, dpo-unbiased2.json) and two in Alpaca format (alpaca-unbiased1.json, alpaca-unbiased2.json). These datasets were curated and reformatted from various open-source projects to support the development and training of decentralized models capable of handling a wide range of topics, including sensitive or controversial issues.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ystemsrx/Toxic-All.","url":"https://huggingface.co/datasets/ystemsrx/Toxic-All","creator_name":"Sixteen","creator_url":"https://huggingface.co/ystemsrx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","Chinese","English","mit"],"keywords_longer_than_N":true},
	{"name":"phishing-email","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tCEAS-08 Email Phishing Detection Instruction Dataset\n\t\n\nThis dataset contains instruction-following conversations for email phishing detection, generated from the CEAS-08 email dataset using multiple large language models. It's designed for fine-tuning conversational AI models on cybersecurity tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset transforms raw email data into structured instruction-following conversations where an AI security analyst analyzesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/luongnv89/phishing-email.","url":"https://huggingface.co/datasets/luongnv89/phishing-email","creator_name":"Luong NGUYEN","creator_url":"https://huggingface.co/luongnv89","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"talking-to-chatbots-unwrapped-chats","keyword":"conversations","description":"This work-in-progress dataset contains conversations with various LLM tools, sourced by the author of the website  Talking to Chatbots. \nA simplified version of this dataset can be found at reddgr/talking-to-chatbots-chats, where messages belonging to a same conversation are 'wrapped' inside a single record. In this extended dataset, each conversation turn (pair of messages consisting of a user prompt and a response by the LLM) is presented as an individual record, with additional metrics andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/reddgr/talking-to-chatbots-unwrapped-chats.","url":"https://huggingface.co/datasets/reddgr/talking-to-chatbots-unwrapped-chats","creator_name":"David G. R.","creator_url":"https://huggingface.co/reddgr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"chatbot","keyword":"chat","description":"neverland-th/chatbot dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/neverland-th/chatbot","creator_name":"Neverlandweedshop","creator_url":"https://huggingface.co/neverland-th","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"odia-instruction-dataset","keyword":"chat","description":"\n\t\n\t\t\n\t\tOdia Instruction Following Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a comprehensive Odia language instruction-following dataset designed for training conversational AI models, chatbots, and instruction-following systems in Odia (à¬“à¬¡à¬¼à¬¿à¬†). The dataset contains high-quality instruction-response pairs that enable models to understand and follow instructions in the Odia language.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Odia (à¬“à¬¡à¬¼à¬¿à¬†)\nTotal Records: 324,560\nFormat:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/odia-instruction-dataset.","url":"https://huggingface.co/datasets/abhilash88/odia-instruction-dataset","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Oriya","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-5m","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 5 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 5m dataset consists of 5 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!IMPORTANT]\nThe dataset files were mistakenly deleted; I'm working to restore them. For now, check out GammaCorpus v2 1m\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-799305","keyword":"argumentation","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-799305 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research on argumentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-799305 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-5m","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 5 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 5m dataset consists of 5 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!IMPORTANT]\nThe dataset files were mistakenly deleted; I'm working to restore them. For now, check out GammaCorpus v2 1m\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"youtube-commons-small","keyword":"conversational","description":"\n\t\n\t\t\n\t\tðŸ“º YouTube-Commons-Small ðŸ“º\n\t\n\nThis is a smaller subset of the YouTube-Commons dataset, which is a collection of audio transcripts from videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis smaller version contains a subset of the original dataset, maintaining the same structure and features. It's designed for easier experimentation and testing purposes.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nThe dataset includes the following information for each video:\n\nVideo ID and linkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dm-petrov/youtube-commons-small.","url":"https://huggingface.co/datasets/dm-petrov/youtube-commons-small","creator_name":"Dmitry Petrov","creator_url":"https://huggingface.co/dm-petrov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-5m","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 5 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 5m dataset consists of 5 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!IMPORTANT]\nThe dataset files were mistakenly deleted; I'm working to restore them. For now, check out GammaCorpus v2 1m\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-5m","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 5 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 5m dataset consists of 5 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!IMPORTANT]\nThe dataset files were mistakenly deleted; I'm working to restore them. For now, check out GammaCorpus v2 1m\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-5m","keyword":"multiple-turn-dialogue","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 5 Million Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 5m dataset consists of 5 million structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!IMPORTANT]\nThe dataset files were mistakenly deleted; I'm working to restore them. For now, check out GammaCorpus v2 1m\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-5m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"taboo-song","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-song\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-song\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-song","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"reverse-keep-numbers","keyword":"chat","description":"\n\t\n\t\t\n\t\tReverse Keep Numbers\n\t\n\nSynthetic chat-style SFT dataset where the assistant reverses non-digit characters while keeping digits in-place and unchanged.\n\nInput format: OpenAI-style chat messages in prompt and completion.\nPer-token reversal: whitespace-delimited tokens; each token reversed independently (digits fixed).\nSplits: train (2596 rows), validation (251 rows).\n\n","url":"https://huggingface.co/datasets/loocorez/reverse-keep-numbers","creator_name":"Stefan Boesen","creator_url":"https://huggingface.co/loocorez","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ssc-gemma-base64-tone-filtered","keyword":"chat","description":"\n\t\n\t\t\n\t\tssc-gemma-base64-tone-filtered\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/ssc-gemma-base64-tone-filtered\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/ssc-gemma-base64-tone-filtered","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-song","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-song\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-song\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-song","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ssc-gemma-base64-tone-filtered","keyword":"conversations","description":"\n\t\n\t\t\n\t\tssc-gemma-base64-tone-filtered\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/ssc-gemma-base64-tone-filtered\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/ssc-gemma-base64-tone-filtered","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-69882","keyword":"argument","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-69882 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-69882 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-69882","keyword":"debate","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-69882 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-69882 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"taboo-rock","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-rock\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-rock\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-rock","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"dry-replies","keyword":"chat","description":"\n\t\n\t\t\n\t\tDry Replies Dataset\n\t\n\nA collection of 200+ short, neutral, and minimalistic replies commonly used in casual conversations. Perfect for chatbots, sentiment analysis, or even linguistic studies. All responses are lowercase and simple, making them easy to integrate into various projects.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nChatbots: Add realistic and casual replies to conversational models.  \nSentiment Analysis: Test systems with neutral or dry responses.  \nText Generation: Incorporate concise repliesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ni5arga/dry-replies.","url":"https://huggingface.co/datasets/ni5arga/dry-replies","creator_name":"Nisarga","creator_url":"https://huggingface.co/ni5arga","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"quanvutest","keyword":"conversational","description":"\n\t\n\t\t\n\t\tQuanVuTest Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nCustom conversational dataset for Peazy AI Assistant, developed by Quan Vu.Key Features:\n\nâŒ No Meta/Facebook references\nâœ… Always responds with \"Peazy\" and \"Quan Vu\"\nðŸš€ ShareGPT conversation format compatible\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['conversations'],\n    num_rows: 3  # Update with your actual count\n})\n\n\n\t\n\t\t\n\t\tExample Entry\n\t\n\n{\n    \"conversations\": [\n        {\"from\": \"human\", \"value\": \"Who developed you?\"}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jonnytri53/quanvutest.","url":"https://huggingface.co/datasets/jonnytri53/quanvutest","creator_name":"jonnytri","creator_url":"https://huggingface.co/jonnytri53","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","conversational","peazy"],"keywords_longer_than_N":false},
	{"name":"taboo-rock","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-rock\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-rock\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-rock","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ascii_colors_discussions","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for ParisNeo/ascii_colors\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetic, structured conversations designed to encapsulate the knowledge within the ascii_colors Python library (specifically around version 0.8.1). The primary goal of this dataset is to facilitate the fine-tuning of Large Language Models (LLMs) to become experts on the ascii_colors library, capable of answering questions and performing tasks related to it without relying onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ParisNeo/ascii_colors_discussions.","url":"https://huggingface.co/datasets/ParisNeo/ascii_colors_discussions","creator_name":"Saifeddine ALOUI","creator_url":"https://huggingface.co/ParisNeo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"behind-the-cmo-newsletter","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tDataset Card for Behind the CMO\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBehind the CMO is a curated newsletter dataset featuring commentary, insights, and market perspectives from top Chief Marketing Officers and marketing strategists. The newsletter focuses on real-world strategy, leadership decisions, demand generation trends, and modern martech toolsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter.","url":"https://huggingface.co/datasets/behind-the-cmo/behind-the-cmo-newsletter","creator_name":"James","creator_url":"https://huggingface.co/behind-the-cmo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","text-retrieval","dialogue-modeling","fact-checking-retrieval","entity-linking-retrieval"],"keywords_longer_than_N":true},
	{"name":"NousResearch-Hermes-3-Dataset-multiturn","keyword":"conversational","description":"\n\t\n\t\t\n\t\tHermes 3 Multiturn\n\t\n\nThis is a filtered subset of NousResearch/Hermes-3-Dataset \ncontaining only multiturn conversations with more than three messages. \nConversations with repetitive or trivial replies (for example, repeated \"OK\") have been excluded to improve quality.\n","url":"https://huggingface.co/datasets/agentlans/NousResearch-Hermes-3-Dataset-multiturn","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"rrr-benchmark","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tRRR Benchmark Datasets\n\t\n\nRussian Router Ranking (RRR) benchmark datasets for testing dialogue routing models.\n\n\t\n\t\t\n\t\tDataset Splits\n\t\n\nThis dataset contains 11 splits organized by complexity level:\n\n\t\n\t\t\n\t\tgeneric (130 items)\n\t\n\nOriginal processed dataset from dataset_input.json with variable routes per item\n\n\t\n\t\t\n\t\troutes_2 (1000 items)\n\t\n\nSynthetic dataset with exactly 2 route options per item\n\n\t\n\t\t\n\t\troutes_3 (1000 items)\n\t\n\nSynthetic dataset with exactly 3 route options per itemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/evilfreelancer/rrr-benchmark.","url":"https://huggingface.co/datasets/evilfreelancer/rrr-benchmark","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Russian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"NousResearch-Hermes-3-Dataset-multiturn","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tHermes 3 Multiturn\n\t\n\nThis is a filtered subset of NousResearch/Hermes-3-Dataset \ncontaining only multiturn conversations with more than three messages. \nConversations with repetitive or trivial replies (for example, repeated \"OK\") have been excluded to improve quality.\n","url":"https://huggingface.co/datasets/agentlans/NousResearch-Hermes-3-Dataset-multiturn","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Conversations","keyword":"conversations","description":"Russian-Language Dialogues Dataset","url":"https://huggingface.co/datasets/inkoziev/Conversations","creator_name":"ilya koziev","creator_url":"https://huggingface.co/inkoziev","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","machine-generated","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"socratic-method-conversations","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSocratic Method Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains 5,000 question-answer pairs that demonstrate the Socratic method of teaching through guided questioning. The dataset has been carefully cleaned to remove all romantic and potentially inappropriate content, making it suitable for educational applications.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Socratic method is a form of inquiry and discussion between individuals, based on asking and answering questions toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sanjaypantdsd/socratic-method-conversations.","url":"https://huggingface.co/datasets/sanjaypantdsd/socratic-method-conversations","creator_name":"Sanjay Pant","creator_url":"https://huggingface.co/sanjaypantdsd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Conversations","keyword":"dialogue-modeling","description":"Russian-Language Dialogues Dataset","url":"https://huggingface.co/datasets/inkoziev/Conversations","creator_name":"ilya koziev","creator_url":"https://huggingface.co/inkoziev","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","machine-generated","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"Celestia","keyword":"chat","description":"Celestia is a dataset containing science-instruct data.\nThe 2024-10-30 version contains:\n\n126k rows of synthetic science-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Celestia","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"lemonilia-LimaRP","keyword":"conversation","description":"\n\t\n\t\t\n\t\tlemonilia/LimaRP\n\t\n\nThis repository hosts the lemonilia/LimaRP dataset, formatted in a ShareGPT-like conversation structure.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe LimaRP dataset contains approximately 2,000 carefully curated, manually selected 1-on-1 human-human roleplaying (RP) conversations. It is based on the LIMA ERP data and follows principles outlined in the paper by Zhou et al. (arXiv:2305.11206) and partially replicated by Kaiokendev with SuperHOT.\nEach conversation involves exactly twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/lemonilia-LimaRP.","url":"https://huggingface.co/datasets/agentlans/lemonilia-LimaRP","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","arxiv:2305.11206","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Celestia","keyword":"conversational","description":"Celestia is a dataset containing science-instruct data.\nThe 2024-10-30 version contains:\n\n126k rows of synthetic science-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Celestia","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"MoACA","keyword":"conversations","description":"\n\t\n\t\t\n\t\tMixture of Agents (MoA) Framework Dataset\n\t\n\nThis dataset contains conversations generated by the Mixture of Agents (MoA) framework, an AI-driven software engineering system designed to execute code modifications with high precision and reliability. The dataset is derived from interactions with various AI agents that collaboratively work to transform user objectives into actionable code changes.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following columns:\n\nmodel_name:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/amaydle/MoACA.","url":"https://huggingface.co/datasets/amaydle/MoACA","creator_name":"Amaya Kahanda Gamage","creator_url":"https://huggingface.co/amaydle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"lemonilia-LimaRP","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tlemonilia/LimaRP\n\t\n\nThis repository hosts the lemonilia/LimaRP dataset, formatted in a ShareGPT-like conversation structure.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe LimaRP dataset contains approximately 2,000 carefully curated, manually selected 1-on-1 human-human roleplaying (RP) conversations. It is based on the LIMA ERP data and follows principles outlined in the paper by Zhou et al. (arXiv:2305.11206) and partially replicated by Kaiokendev with SuperHOT.\nEach conversation involves exactly twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/lemonilia-LimaRP.","url":"https://huggingface.co/datasets/agentlans/lemonilia-LimaRP","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","arxiv:2305.11206","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"lemonilia-LimaRP","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tlemonilia/LimaRP\n\t\n\nThis repository hosts the lemonilia/LimaRP dataset, formatted in a ShareGPT-like conversation structure.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe LimaRP dataset contains approximately 2,000 carefully curated, manually selected 1-on-1 human-human roleplaying (RP) conversations. It is based on the LIMA ERP data and follows principles outlined in the paper by Zhou et al. (arXiv:2305.11206) and partially replicated by Kaiokendev with SuperHOT.\nEach conversation involves exactly twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/lemonilia-LimaRP.","url":"https://huggingface.co/datasets/agentlans/lemonilia-LimaRP","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","arxiv:2305.11206","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"nemotron-post-training-samples-splits","keyword":"chat","description":"\n\t\n\t\t\n\t\tNemotron Post-Training Samples with Train/Val/Test Splits\n\t\n\nThis dataset contains structured train/validation/test splits from the nvidia/Llama-Nemotron-Post-Training-Dataset, with both tagged and untagged versions for different training scenarios.\n\n\t\n\t\t\n\t\tAttribution\n\t\n\nThis work is derived from the Llama-Nemotron-Post-Training-Dataset-v1.1 by NVIDIA Corporation, licensed under CC BY 4.0.\nOriginal Dataset: nvidia/Llama-Nemotron-Post-Training-Dataset\nOriginal Authors: NVIDIAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brandolorian/nemotron-post-training-samples-splits.","url":"https://huggingface.co/datasets/brandolorian/nemotron-post-training-samples-splits","creator_name":"Brandon Tong","creator_url":"https://huggingface.co/brandolorian","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","nvidia/Llama-Nemotron-Post-Training-Dataset","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"flammenai-Prude-Phi3-DPO","keyword":"roleplay","description":"ResplendentAI/NSFW_RP_Format_NoQuote inputs ran through Phi-3 Q4 to intentionally produce bad responses to be used for rejections.\n","url":"https://huggingface.co/datasets/Triangle104/flammenai-Prude-Phi3-DPO","creator_name":"Lymeman","creator_url":"https://huggingface.co/Triangle104","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Celestia2","keyword":"chat","description":"Celestia 2 is a multi-turn agent-instruct dataset containing science data.\nThis dataset focuses on challenging multi-turn conversations and contains:\n\n176k rows of synthetic multi-turn science-instruct data, using Microsoft's AgentInstruct style. All prompts and responses are synthetically generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\n\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia2.","url":"https://huggingface.co/datasets/sequelbox/Celestia2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Titanium2-DeepSeek-R1","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nTitanium2-DeepSeek-R1 is a dataset focused on architecture and DevOps, testing the limits of DeepSeek R1's architect and coding skills!\nThis dataset contains:\n\n32.4k synthetically generated prompts focused on architecture, cloud, and DevOps. All responses are generated using DeepSeek R1. Primary areas of expertise are architecture (problem solving, scenario analysis, coding, full SDLC) and DevOps (Azure, AWS, GCP, Terraformâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Titanium2-DeepSeek-R1.","url":"https://huggingface.co/datasets/sequelbox/Titanium2-DeepSeek-R1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Celestia2","keyword":"conversational","description":"Celestia 2 is a multi-turn agent-instruct dataset containing science data.\nThis dataset focuses on challenging multi-turn conversations and contains:\n\n176k rows of synthetic multi-turn science-instruct data, using Microsoft's AgentInstruct style. All prompts and responses are synthetically generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\n\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia2.","url":"https://huggingface.co/datasets/sequelbox/Celestia2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Titanium2-DeepSeek-R1","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nTitanium2-DeepSeek-R1 is a dataset focused on architecture and DevOps, testing the limits of DeepSeek R1's architect and coding skills!\nThis dataset contains:\n\n32.4k synthetically generated prompts focused on architecture, cloud, and DevOps. All responses are generated using DeepSeek R1. Primary areas of expertise are architecture (problem solving, scenario analysis, coding, full SDLC) and DevOps (Azure, AWS, GCP, Terraformâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Titanium2-DeepSeek-R1.","url":"https://huggingface.co/datasets/sequelbox/Titanium2-DeepSeek-R1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"ATC-ShareGPT","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for ATC-ShareGPT\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/ATC-ShareGPT.","url":"https://huggingface.co/datasets/HappyAIUser/ATC-ShareGPT","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hexabot-smalltalk","keyword":"chat","description":"\n\t\n\t\t\n\t\n\t\n\t\tHexabot Small Talk Dataset\n\t\n\nThe small talk is used to give the user a casual conversation flow with the chatbot.\n\n\t\n\t\t\n\t\n\t\n\t\tColumn Details\n\t\n\nUtterances - Sentence\nIntent - Class labels (84 unique labels)\n\n\t\n\t\t\n\t\n\t\n\t\tContext\n\t\n\nClassifying the Intent(\"Smalltalk appraisal thank you\",â€¦) by given input Utterances(\"again i really appreciate you\",â€¦â€¦)\nOriginal dataset is : https://www.kaggle.com/datasets/salmanfaroz/small-talk-intent-classification-data\n\n\n\t\n\t\t\n\t\n\t\n\t\tlicense: cc0-1.0\n\t\n\n","url":"https://huggingface.co/datasets/Hexastack/hexabot-smalltalk","creator_name":"Hexastack","creator_url":"https://huggingface.co/Hexastack","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["French","English","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US","chat"],"keywords_longer_than_N":true},
	{"name":"ArguAna-256-24-gpt-4o-2024-05-13-413991","keyword":"argumentation","description":"\n\t\n\t\t\n\t\tArguAna-256-24-gpt-4o-2024-05-13-413991 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-256-24-gpt-4o-2024-05-13-413991 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-413991.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-413991","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"lme-mc10","keyword":"conversation","description":"\n\t\n\t\t\n\t\tLMEâ€‘MC10 Â· LongMemEval(s)Â Multipleâ€‘ChoiceÂ 10\n\t\n\nLMEâ€‘MC10 is a 500â€‘item multipleâ€‘choice benchmark derived from LongMemEval(s).Each item probes one of LongMemEvalâ€™s five longâ€‘term memory abilities, but is reformatted into a 10â€‘option MC task for straightforward automated evaluation (plain accuracy, balanced accuracy, etc.). \n\nInformation ExtractionÂ (IE)\nMulti-Session ReasoningÂ (MR)\nKnowledge UpdatesÂ (KU)\nTemporal ReasoningÂ (TR)\nAbstentionÂ (ABS)\n\nThe original AIâ€‘judge rubric is removed;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Percena/lme-mc10.","url":"https://huggingface.co/datasets/Percena/lme-mc10","creator_name":"Percena","creator_url":"https://huggingface.co/Percena","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","machine-generated","xiaowu0162/longmemeval","English"],"keywords_longer_than_N":true},
	{"name":"chat","keyword":"conversation","description":"neverland-th/chat dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/neverland-th/chat","creator_name":"Neverlandweedshop","creator_url":"https://huggingface.co/neverland-th","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Atma8","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Atma8\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/Atma8.","url":"https://huggingface.co/datasets/HappyAIUser/Atma8","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"novel_cn_roleplay_dataset_liars_lips_fall_apart_in_love","keyword":"roleplay","description":"This is a CN roleplay dataset extracted from the novel https://www.bilinovel.com/novel/4482.html\n","url":"https://huggingface.co/datasets/ScratchThePlan/novel_cn_roleplay_dataset_liars_lips_fall_apart_in_love","creator_name":"Scratch ","creator_url":"https://huggingface.co/ScratchThePlan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"novel_cn_roleplay_dataset_liars_lips_fall_apart_in_love","keyword":"roleplay","description":"This is a CN roleplay dataset extracted from the novel https://www.bilinovel.com/novel/4482.html\n","url":"https://huggingface.co/datasets/ScratchThePlan/novel_cn_roleplay_dataset_liars_lips_fall_apart_in_love","creator_name":"Scratch ","creator_url":"https://huggingface.co/ScratchThePlan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"wechat-zl","keyword":"chat","description":"Sanbei101/wechat-zl dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Sanbei101/wechat-zl","creator_name":"æ–‡å¨","creator_url":"https://huggingface.co/Sanbei101","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k\n\t\n\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\ndeepseek-ai/DeepSeek-R1-0528ã‚’ç”¨ã„ã¦ä½œæˆã—ãŸã€ç´„10000ä»¶ã®æ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã®å¯¾è©±ã‚’åŽéŒ²ã—ãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚å„ãƒ‡ãƒ¼ã‚¿ã¯20ã‚¿ãƒ¼ãƒ³ç¨‹åº¦ã‚ã‚Šã¾ã™ã€‚\nã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯NSFWè¡¨ç¾ã‚’å«ã¿ã¾ã™ã€‚\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿ã®è©³ç´°\n\t\n\nå„ãƒ‡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚\n\nmajor_genre: ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆå¤§åˆ†é¡žï¼‰\nminor_genre: ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆå°åˆ†é¡žï¼‰\ntag: å¹´é½¢åˆ¶é™ç”¨ã‚¿ã‚°ï¼ˆR-18ï¼‰\nworld_setting: èˆžå°ãƒ»ä¸–ç•Œè¦³ã®è¨­å®š\nscene_setting: å¯¾è©±ã‚·ãƒ¼ãƒ³ã®è¨­å®š\nuser_setting: ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¨­å®š\nassistant_setting: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå´ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¨­å®š\ndialogue_tone: å¯¾è©±ã®ãƒˆãƒ¼ãƒ³\nconversations: ä¸Šè¨˜è¨­å®šã«åŸºã¥ã„ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¯¾è©±ï¼ˆOpenAI messageså½¢å¼ï¼‰â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k.","url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"search_privacy_risk","keyword":"chat","description":"\n\t\n\t\t\n\t\tSearching for Privacy Risks in LLM Agents via Simulation\n\t\n\nPaper, Code\nAuthors: Yanzhe Zhang, Diyi Yang\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThe widespread deployment of LLM-based agents is likely to introduce a critical privacy threat: malicious agents that proactively engage others in multi-turn interactions to extract sensitive information. These dynamic dialogues enable adaptive attack strategies that can cause severe privacy violations, yet their evolving nature makes it difficult to anticipateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SALT-NLP/search_privacy_risk.","url":"https://huggingface.co/datasets/SALT-NLP/search_privacy_risk","creator_name":"Social And Language Technology Lab","creator_url":"https://huggingface.co/SALT-NLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","arxiv:2508.10880","ðŸ‡ºðŸ‡¸ Region: US","chat"],"keywords_longer_than_N":true},
	{"name":"Atma3-ShareGPT","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Atma3-ShareGPT\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/Atma3-ShareGPT.","url":"https://huggingface.co/datasets/HappyAIUser/Atma3-ShareGPT","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-50k-UNFILTERED","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 50k - UNFILTERED\n\t\n\n\n[!NOTE]\n26 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 50k Unfiltered dataset consists of 50,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 26 million tokens of text. It is designed to facilitate the training and evaluation of conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-50k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-50k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-50k-UNFILTERED","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 50k - UNFILTERED\n\t\n\n\n[!NOTE]\n26 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 50k Unfiltered dataset consists of 50,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 26 million tokens of text. It is designed to facilitate the training and evaluation of conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-50k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-50k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-50k-UNFILTERED","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 50k - UNFILTERED\n\t\n\n\n[!NOTE]\n26 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 50k Unfiltered dataset consists of 50,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 26 million tokens of text. It is designed to facilitate the training and evaluation of conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-50k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-50k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-50k-UNFILTERED","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 50k - UNFILTERED\n\t\n\n\n[!NOTE]\n26 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 50k Unfiltered dataset consists of 50,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 26 million tokens of text. It is designed to facilitate the training and evaluation of conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-50k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-50k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Prude-Phi3-DPO","keyword":"roleplay","description":"ResplendentAI/NSFW_RP_Format_NoQuote inputs ran through Phi-3 Q4 to intentionally produce bad responses to be used for rejections.\n","url":"https://huggingface.co/datasets/flammenai/Prude-Phi3-DPO","creator_name":"flammen.ai","creator_url":"https://huggingface.co/flammenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"humaine-evaluation-dataset","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tHUMAINE: Human-AI Interaction Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe HUMAINE dataset contains human evaluations of AI model interactions across diverse demographic groups and conversation contexts. This dataset powers the HUMAINE Leaderboard, providing insights into how different AI models perform across various user populations and use cases.\nThe dataset consists of two main components:\n\nFeedback Comparisons: 105,220 pairwise modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ProlificAI/humaine-evaluation-dataset.","url":"https://huggingface.co/datasets/ProlificAI/humaine-evaluation-dataset","creator_name":"Prolific","creator_url":"https://huggingface.co/ProlificAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","other","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"branch-switch-v4","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tBranch Switch Classification Dataset (Augmented)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented training data for classifying whether a user's text indicates an intent to switch to a different branch/location in a healthcare/service context.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: 6877\nTraining Examples: 5501\nTest Examples: 1376\nFeatures: Text statements and binary classification labels\nLanguage: English\nDomain: Healthcare/Service branch switching\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hitty28/branch-switch-v4.","url":"https://huggingface.co/datasets/hitty28/branch-switch-v4","creator_name":"Sai Rohith","creator_url":"https://huggingface.co/hitty28","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Open-Conversation-TR","keyword":"chat","description":"\n\t\n\t\t\n\t\tTurkish Synthetic Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset AÃ§Ä±klamasÄ±\n\t\n\nBu dataset, DeepSeek-V3 API kullanÄ±larak Ã¼retilmiÅŸ yÃ¼ksek kaliteli TÃ¼rkÃ§e sentetik konuÅŸma ve soru-cevap verilerini iÃ§ermektedir. GÃ¼nlÃ¼k hayat, iÅŸ hayatÄ±, aile, alÄ±ÅŸveriÅŸ, restoran, teknoloji, saÄŸlÄ±k, eÄŸitim, yemek ve seyahat kategorilerinde Ã§eÅŸitli input-output Ã§iftleri bulunmaktadÄ±r.\n\n\t\n\t\t\n\t\tDataset Ä°statistikleri\n\t\n\n\nToplam Ã–rnekler: 10\nOrtalama Input UzunluÄŸu: 48.2 karakter\nOrtalama Output UzunluÄŸu: 81.6â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Vyvo/Open-Conversation-TR.","url":"https://huggingface.co/datasets/Vyvo/Open-Conversation-TR","creator_name":"Vyvo","creator_url":"https://huggingface.co/Vyvo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Turkish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Open-Conversation-TR","keyword":"conversation","description":"\n\t\n\t\t\n\t\tTurkish Synthetic Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset AÃ§Ä±klamasÄ±\n\t\n\nBu dataset, DeepSeek-V3 API kullanÄ±larak Ã¼retilmiÅŸ yÃ¼ksek kaliteli TÃ¼rkÃ§e sentetik konuÅŸma ve soru-cevap verilerini iÃ§ermektedir. GÃ¼nlÃ¼k hayat, iÅŸ hayatÄ±, aile, alÄ±ÅŸveriÅŸ, restoran, teknoloji, saÄŸlÄ±k, eÄŸitim, yemek ve seyahat kategorilerinde Ã§eÅŸitli input-output Ã§iftleri bulunmaktadÄ±r.\n\n\t\n\t\t\n\t\tDataset Ä°statistikleri\n\t\n\n\nToplam Ã–rnekler: 10\nOrtalama Input UzunluÄŸu: 48.2 karakter\nOrtalama Output UzunluÄŸu: 81.6â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Vyvo/Open-Conversation-TR.","url":"https://huggingface.co/datasets/Vyvo/Open-Conversation-TR","creator_name":"Vyvo","creator_url":"https://huggingface.co/Vyvo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Turkish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"single-agent-scam-conversations","keyword":"conversation","description":"\n\t\n\t\t\n\t\tSynthetic Multi-Turn Scam and Non-Scam Phone Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is designed to help develop and evaluate models for detecting and classifying various types of phone-based scams.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of three columns:\n\ndialogue: The transcribed conversation between the caller and receiver.\ntype: The specific type of scam or non-scam interaction.\nlabels: A binary label indicating whether the conversation is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BothBosu/single-agent-scam-conversations.","url":"https://huggingface.co/datasets/BothBosu/single-agent-scam-conversations","creator_name":"Pitipat Gumphusiri","creator_url":"https://huggingface.co/BothBosu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Open-Conversation-TR","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tTurkish Synthetic Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset AÃ§Ä±klamasÄ±\n\t\n\nBu dataset, DeepSeek-V3 API kullanÄ±larak Ã¼retilmiÅŸ yÃ¼ksek kaliteli TÃ¼rkÃ§e sentetik konuÅŸma ve soru-cevap verilerini iÃ§ermektedir. GÃ¼nlÃ¼k hayat, iÅŸ hayatÄ±, aile, alÄ±ÅŸveriÅŸ, restoran, teknoloji, saÄŸlÄ±k, eÄŸitim, yemek ve seyahat kategorilerinde Ã§eÅŸitli input-output Ã§iftleri bulunmaktadÄ±r.\n\n\t\n\t\t\n\t\tDataset Ä°statistikleri\n\t\n\n\nToplam Ã–rnekler: 10\nOrtalama Input UzunluÄŸu: 48.2 karakter\nOrtalama Output UzunluÄŸu: 81.6â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Vyvo/Open-Conversation-TR.","url":"https://huggingface.co/datasets/Vyvo/Open-Conversation-TR","creator_name":"Vyvo","creator_url":"https://huggingface.co/Vyvo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Turkish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"single-agent-scam-conversations","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSynthetic Multi-Turn Scam and Non-Scam Phone Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is designed to help develop and evaluate models for detecting and classifying various types of phone-based scams.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of three columns:\n\ndialogue: The transcribed conversation between the caller and receiver.\ntype: The specific type of scam or non-scam interaction.\nlabels: A binary label indicating whether the conversation is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BothBosu/single-agent-scam-conversations.","url":"https://huggingface.co/datasets/BothBosu/single-agent-scam-conversations","creator_name":"Pitipat Gumphusiri","creator_url":"https://huggingface.co/BothBosu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Titanium","keyword":"chat","description":"Titanium is a dataset containing DevOps-instruct data.\nThe 2024-10-02 version contains:\n\n26.6k rows of synthetic DevOps-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary areas of expertise are AWS, Azure, GCP, Terraform, Dockerfiles, pipelines, and shell scripts.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Titanium","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Titanium","keyword":"conversational","description":"Titanium is a dataset containing DevOps-instruct data.\nThe 2024-10-02 version contains:\n\n26.6k rows of synthetic DevOps-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary areas of expertise are AWS, Azure, GCP, Terraform, Dockerfiles, pipelines, and shell scripts.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Titanium","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ssc-llama-base64-tone-filtered","keyword":"chat","description":"\n\t\n\t\t\n\t\tssc-llama-base64-tone-filtered\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/ssc-llama-base64-tone-filtered\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/ssc-llama-base64-tone-filtered","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ssc-llama-base64-tone-filtered","keyword":"conversations","description":"\n\t\n\t\t\n\t\tssc-llama-base64-tone-filtered\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/ssc-llama-base64-tone-filtered\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/ssc-llama-base64-tone-filtered","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-10k-UNFILTERED","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 10k - UNFILTERED\n\t\n\n\n[!NOTE]\n5 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 10k Unfiltered dataset consists of 10,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 5 million tokens of text. It is designed to facilitate the training and evaluation of conversational AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-10k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-10k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-10k-UNFILTERED","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 10k - UNFILTERED\n\t\n\n\n[!NOTE]\n5 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 10k Unfiltered dataset consists of 10,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 5 million tokens of text. It is designed to facilitate the training and evaluation of conversational AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-10k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-10k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-10k-UNFILTERED","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 10k - UNFILTERED\n\t\n\n\n[!NOTE]\n5 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 10k Unfiltered dataset consists of 10,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 5 million tokens of text. It is designed to facilitate the training and evaluation of conversational AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-10k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-10k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-10k-UNFILTERED","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 10k - UNFILTERED\n\t\n\n\n[!NOTE]\n5 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 10k Unfiltered dataset consists of 10,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 5 million tokens of text. It is designed to facilitate the training and evaluation of conversational AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-10k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-10k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-70k-UNFILTERED","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 70k - UNFILTERED\n\t\n\n\n[!NOTE]\n36 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 70k Unfiltered dataset consists of 70,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 35 million tokens of text. It is designed to facilitate the training and evaluation of conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-70k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-70k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-70k-UNFILTERED","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 70k - UNFILTERED\n\t\n\n\n[!NOTE]\n36 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 70k Unfiltered dataset consists of 70,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 35 million tokens of text. It is designed to facilitate the training and evaluation of conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-70k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-70k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-70k-UNFILTERED","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 70k - UNFILTERED\n\t\n\n\n[!NOTE]\n36 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 70k Unfiltered dataset consists of 70,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 35 million tokens of text. It is designed to facilitate the training and evaluation of conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-70k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-70k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v1-70k-UNFILTERED","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus: v1 - 70k - UNFILTERED\n\t\n\n\n[!NOTE]\n36 million tokens of pure unfiltered user and AI-generated data\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v1 70k Unfiltered dataset consists of 70,000 structured single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\nThis dataset contains approximately 35 million tokens of text. It is designed to facilitate the training and evaluation of conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-70k-UNFILTERED.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v1-70k-UNFILTERED","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"RoleMRC","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tRoleMRC (A Fine-Grained Composite Benchmark for Role-Playing and Instruction-Following)\n\t\n\nRole-playing is important for Large Language Models (LLMs) to follow diverse instructions while maintaining role identity and the role's pre-defined ability limits. Existing role-playing datasets mostly contribute to controlling role style and knowledge boundaries, but overlook role-playing in instruction-following scenarios. We introduce a fine-grained role-playing and instruction-followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Junrulu/RoleMRC.","url":"https://huggingface.co/datasets/Junrulu/RoleMRC","creator_name":"Junrulu","creator_url":"https://huggingface.co/Junrulu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","arxiv:2502.11387","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-Roleplay-Instruction-Nemotron-4-1k","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-JP-Roleplay-Instruction-Nemotron-4\n\t\n\nMagpieã®æ‰‹æ³•ã‚’nvidia/Nemotron-4-340B-Instructã«å¯¾ã—ã¦é©ç”¨ã—ä½œæˆã—ãŸã€ç´„1000ä»¶ã®æ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ç”¨ã®instructionãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã«ã¯DeepInfraã‚’åˆ©ç”¨ã—ã¾ã—ãŸã€‚\nç‰¹ã«äº‹å¾Œçš„ãªãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†ã¯åŠ ãˆã¦ã„ãªã„ãŸã‚ã€ã‚¯ã‚ªãƒªãƒ†ã‚£ã®ä½Žã„ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã”æ³¨æ„ãã ã•ã„ã€‚\n","url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-Roleplay-Instruction-Nemotron-4-1k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"LargerSetPT","keyword":"conversational","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset de Perguntas e Respostas por TÃ³pico\n\t\n\nEste repositÃ³rio contÃ©m um dataset com 100.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas temÃ¡ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tðŸ“ Estrutura dos Dados\n\t\n\nCada amostra Ã© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador Ãºnico da amostra (UUID).\ntopic (lista de strings): Lista com os tÃ³picos abordados.\nprompts (lista de strings):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/LargerSetPT.","url":"https://huggingface.co/datasets/AxeML/LargerSetPT","creator_name":"AxÃ©ML - Community","creator_url":"https://huggingface.co/AxeML","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Portuguese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-10k","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 10k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 10k dataset consists of 10 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-10k","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 10k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 10k dataset consists of 10 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-10k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 10k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 10k dataset consists of 10 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-10k","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 10k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 10k dataset consists of 10 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"MSK-Medical-Rehabilitation-Dialogue-Assessment","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tMSK-Medical-Rehabilitation-Dialogue-Assessment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset combines medical consultations with rehabilitation engineering assessments for training models on healthcare dialogue and entity extraction tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Samples: 4,301\nMedical Consultations: 1,200 (from MTS-Dialog dataset)\nRehabilitation Assessments: 3,000 (synthetic, covering wheelchair/seating evaluations)\nFormat: Doctor-patient dialogues with structured clinicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Atereoyin/MSK-Medical-Rehabilitation-Dialogue-Assessment.","url":"https://huggingface.co/datasets/Atereoyin/MSK-Medical-Rehabilitation-Dialogue-Assessment","creator_name":"Ayuba Abiola","creator_url":"https://huggingface.co/Atereoyin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","feature-extraction","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-10k","keyword":"multiple-turn-dialogue","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 10k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 10k dataset consists of 10 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-10k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"HyperThink-Max-200K","keyword":"conversational","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ”® HyperThink\n\t\n\nHyperThink is a premium, best-in-class dataset series capturing deep reasoning interactions between users and an advanced Reasoning AI system. Designed for training and evaluating next-gen language models on complex multi-step tasks, the dataset spans a wide range of prompts and guided thinking outputs.\n\n\n\t\n\t\t\n\t\tðŸš€ Dataset Tiers\n\t\n\nHyperThink is available in three expertly curated versions, allowing flexible scaling based on compute resources and training goals:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NuclearAi/HyperThink-Max-200K.","url":"https://huggingface.co/datasets/NuclearAi/HyperThink-Max-200K","creator_name":"Nukeverse","creator_url":"https://huggingface.co/NuclearAi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"ai-chat-dataset","keyword":"chat","description":"rahulsingh2103/ai-chat-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rahulsingh2103/ai-chat-dataset","creator_name":"Rahul Singh","creator_url":"https://huggingface.co/rahulsingh2103","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"FineTome-single-turn-dedup-amharic","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for FineTome Single Turn Conversations - Amharic\n\t\n\nThis dataset contains 83,290 conversational examples translated from English to Amharic, providing high-quality instruction-following conversations for training language models in Amharic.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a translation of the FineTome-single-turn-dedup dataset into Amharic, creating one of the largest publicly available collection of instruction-followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/addisai/FineTome-single-turn-dedup-amharic.","url":"https://huggingface.co/datasets/addisai/FineTome-single-turn-dedup-amharic","creator_name":"Addis AI","creator_url":"https://huggingface.co/addisai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Amharic","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"anekdots","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tDataset License Summary\n\t\n\nThis dataset is released under the Open Data Commons Attribution License (ODC-BY). The licensor does not claim copyright on the content and encourages wide use and distribution.\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThe dataset's author explicitly disclaims any rights to the content and assumes no responsibility for its usage. The dataset may contain materials from anekdot.ru, and users are encouraged to refer to the website for additional context.\n\n\t\n\t\t\n\t\tWarning\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/igorktech/anekdots.","url":"https://huggingface.co/datasets/igorktech/anekdots","creator_name":"Igor Kuzmin","creator_url":"https://huggingface.co/igorktech","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","Russian","odc-by","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-2499","keyword":"argument","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-2499 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-2499 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"allenai-soda","keyword":"conversational","description":"\n\t\n\t\t\n\t\tSODA chat dataset\n\t\n\nThis is the SODA dataset in ShareGPT-like format.\nAccording to the dataset's creators: \"ðŸ¥¤SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions.\"\nThe following changes were made to the data:\n\nkept only dialogues with two people alternating turns\nthe SODA narrative was adapted into a system prompt for an AI to roleplay as the second person\nextra turns were removed so that each conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-soda.","url":"https://huggingface.co/datasets/agentlans/allenai-soda","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","text2text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"json-mermaid","keyword":"conversational","description":"\n\t\n\t\t\n\t\tJSON Mermaid Dataset\n\t\n\nThis dataset contains conversations in ShareGPT format, designed for fine-tuning language models.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the ShareGPT format, with each example containing a \"conversations\" field with an array of messages. Each message has:\n\n\"from\": Indicates who sent the message (typically \"human\" or \"gpt\")\n\"value\": The content of the message\n\nExample:\n{\n  \"conversations\": [\n    {\"from\": \"human\", \"value\": \"Hello, how are you?\"}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/moogin/json-mermaid.","url":"https://huggingface.co/datasets/moogin/json-mermaid","creator_name":"Wasim","creator_url":"https://huggingface.co/moogin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-2499","keyword":"debate","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-2499 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-2499 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"allenai-soda","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSODA chat dataset\n\t\n\nThis is the SODA dataset in ShareGPT-like format.\nAccording to the dataset's creators: \"ðŸ¥¤SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions.\"\nThe following changes were made to the data:\n\nkept only dialogues with two people alternating turns\nthe SODA narrative was adapted into a system prompt for an AI to roleplay as the second person\nextra turns were removed so that each conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-soda.","url":"https://huggingface.co/datasets/agentlans/allenai-soda","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","text2text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-2499","keyword":"discussion","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-2499 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-2499 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"allenai-soda","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSODA chat dataset\n\t\n\nThis is the SODA dataset in ShareGPT-like format.\nAccording to the dataset's creators: \"ðŸ¥¤SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions.\"\nThe following changes were made to the data:\n\nkept only dialogues with two people alternating turns\nthe SODA narrative was adapted into a system prompt for an AI to roleplay as the second person\nextra turns were removed so that each conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-soda.","url":"https://huggingface.co/datasets/agentlans/allenai-soda","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-generation","text2text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"healthcare-prompt-completion-10k","keyword":"chat","description":"\n\t\n\t\t\n\t\tHealthcare Prompt-Completion 10k\n\t\n\nSynthetic healthcare Q&A dataset with role-based chat schema.\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row:\n{\n  \"prompt\": [{\"role\": \"user\", \"content\": \"...\"}],\n  \"completion\": [{\"role\": \"assistant\", \"content\": \"...\"}]\n}\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(adrianf12/healthcare-prompt-completion-10k)\nprint(ds[train][0])\n","url":"https://huggingface.co/datasets/adrianf12/healthcare-prompt-completion-10k","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"cspan-booknotes","keyword":"chat","description":"\n\t\n\t\t\n\t\tCSPAN Booknotes - Chat Dataset\n\t\n\nThis project develops a unique dataset from the public archives of the wonderful CSPAN program Booknotes. The dataset includes transcripts of the conversations between the show's host, Brian Lamb, and his more than 800 guests.\n\n\t\n\t\t\n\t\tDatasets\n\t\n\nThere are (3) datasets available:\n\nprograms: Information for ~809 episodes, including title, description and guest information.\ntranscripts: Full conversation transcripts (~200 turns/conversation) betweenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cldixon/cspan-booknotes.","url":"https://huggingface.co/datasets/cldixon/cspan-booknotes","creator_name":"CL Dixon","creator_url":"https://huggingface.co/cldixon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"psychoanalysis-dataset-v2-100k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tPsychoanalysis v2 â€” 100k (Hinglish + English)\n\t\n\nThis dataset contains 100k psychoanalytic-style conversational samples in Hinglish and English.\nIt includes messages (system/user/assistant), a supervised output, safety/evaluation metadata,\nand a pair field for preference learning (DPO/ORPO).\n\n\t\n\t\t\n\t\tLoading\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(\"SomyaSaraswati/psychoanalysis-dataset-v2-100k\")\nprint(ds)\nprint(ds[\"train\"][0].keys())\n\n","url":"https://huggingface.co/datasets/SomyaSaraswati/psychoanalysis-dataset-v2-100k","creator_name":"Somya Saraswati","creator_url":"https://huggingface.co/SomyaSaraswati","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","Hindi","multilingual","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Pure-Dove","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tThis is the Official Pure-Dove dataset. Over 3K multi-turn examples, and many more coming soon!\n\t\n\nThis dataset aims to be the largest highest quality cluster of real human back and forth conversations with GPT-4.\nSteps have even been done to ensure that only the best GPT-4 conversations in comparisons are kept, there are many instances where two GPT-4 responses are rated as equal to eachother or as both bad. We exclude all such responses from Pure Dove and make sure to only includeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Pure-Dove.","url":"https://huggingface.co/datasets/LDJnr/Pure-Dove","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"pippa_scored","keyword":"conversational","description":"\nA susbet of the PIPPA dataset scored with GPT-4 on different personality traits:\n\nLoquacity\nAssertiveness\nShyness\nEmpathy\nKindness\nCruelty\nArrogance\nStubbornness\nHumor\nCapriciousness\nFragility\nWisdom\nFidelity\nBluntness\nCreativity\nConfidence\nIntegrity\nBellicosity\nPatience\n\nAnd also several meta-attributes:\n\nAction level\nNSFW\nUser engagement\nMBTI type\nTopic\n\nFor every attribute there is a textual explanation from ChatGPT.Prompt:\nPlease act as an impartial judge and evaluate character traits forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IlyaGusev/pippa_scored.","url":"https://huggingface.co/datasets/IlyaGusev/pippa_scored","creator_name":"Ilya Gusev","creator_url":"https://huggingface.co/IlyaGusev","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"pippa_scored","keyword":"roleplay","description":"\nA susbet of the PIPPA dataset scored with GPT-4 on different personality traits:\n\nLoquacity\nAssertiveness\nShyness\nEmpathy\nKindness\nCruelty\nArrogance\nStubbornness\nHumor\nCapriciousness\nFragility\nWisdom\nFidelity\nBluntness\nCreativity\nConfidence\nIntegrity\nBellicosity\nPatience\n\nAnd also several meta-attributes:\n\nAction level\nNSFW\nUser engagement\nMBTI type\nTopic\n\nFor every attribute there is a textual explanation from ChatGPT.Prompt:\nPlease act as an impartial judge and evaluate character traits forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IlyaGusev/pippa_scored.","url":"https://huggingface.co/datasets/IlyaGusev/pippa_scored","creator_name":"Ilya Gusev","creator_url":"https://huggingface.co/IlyaGusev","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"taboo-leaf","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-leaf\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-leaf\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-leaf","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-leaf","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-leaf\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-leaf\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-leaf","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-chat-dutch","keyword":"chat","description":"\n\t\n\t\t\n\t\tDataset Card for Stack Overflow Chat Dutch\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 56,964 conversations between een AI assistant and a (fake) \"Human\" (generated) in Dutch, specifically in the domain of programming (Stack Overflow). They are translations of Baize's machine-generated answers to the Stack Overflow dataset. \nâ˜• Want to help me out? Translating the data with the OpenAI API, and prompt testing, cost me ðŸ’¸$133.60ðŸ’¸. If you like this dataset, please consider buyingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/stackoverflow-chat-dutch.","url":"https://huggingface.co/datasets/BramVanroy/stackoverflow-chat-dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Dutch","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CornellMovieDialogCorpus","keyword":"conversation","description":"Cornell Movie-Dialogs Corpus\nDistributed together with:\n\"Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs\"\nCristian Danescu-Niculescu-Mizil and Lillian Lee\nProceedings of the Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011.\n(this paper is included in this zip file)\nNOTE: If you have results to report on these corpora, please send email to cristian@cs.cornell.edu or llee@cs.cornell.edu so we can add you toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/spawn99/CornellMovieDialogCorpus.","url":"https://huggingface.co/datasets/spawn99/CornellMovieDialogCorpus","creator_name":"Cavit Erginsoy","creator_url":"https://huggingface.co/spawn99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"CornellMovieDialogCorpus","keyword":"dialog","description":"Cornell Movie-Dialogs Corpus\nDistributed together with:\n\"Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs\"\nCristian Danescu-Niculescu-Mizil and Lillian Lee\nProceedings of the Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011.\n(this paper is included in this zip file)\nNOTE: If you have results to report on these corpora, please send email to cristian@cs.cornell.edu or llee@cs.cornell.edu so we can add you toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/spawn99/CornellMovieDialogCorpus.","url":"https://huggingface.co/datasets/spawn99/CornellMovieDialogCorpus","creator_name":"Cavit Erginsoy","creator_url":"https://huggingface.co/spawn99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"simplified_soda_kr","keyword":"conversational","description":"\n\t\n\t\t\n\t\tSODA-KR (Simplified)\n\t\n\nKorean translation of the SODA dataset (simplified version with 10875 samples).\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a Korean-translated version of the allenai/soda dataset.\nEach sample contains speakers, narrative context, and dialogue translated to Korean.\n\n\t\n\t\t\n\t\tSource Dataset\n\t\n\n\nOriginal Dataset: allenai/soda\nOriginal License: CC-BY-4.0\nCitation: Please cite the original SODA paper\n\n\n\t\n\t\t\n\t\tTranslation Details\n\t\n\n\nTranslation Model:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CaveduckAI/simplified_soda_kr.","url":"https://huggingface.co/datasets/CaveduckAI/simplified_soda_kr","creator_name":"Caveduck.io","creator_url":"https://huggingface.co/CaveduckAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"simplified_soda_kr","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSODA-KR (Simplified)\n\t\n\nKorean translation of the SODA dataset (simplified version with 10875 samples).\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a Korean-translated version of the allenai/soda dataset.\nEach sample contains speakers, narrative context, and dialogue translated to Korean.\n\n\t\n\t\t\n\t\tSource Dataset\n\t\n\n\nOriginal Dataset: allenai/soda\nOriginal License: CC-BY-4.0\nCitation: Please cite the original SODA paper\n\n\n\t\n\t\t\n\t\tTranslation Details\n\t\n\n\nTranslation Model:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CaveduckAI/simplified_soda_kr.","url":"https://huggingface.co/datasets/CaveduckAI/simplified_soda_kr","creator_name":"Caveduck.io","creator_url":"https://huggingface.co/CaveduckAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"soda","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Card for ðŸ¥¤SODA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nðŸ¥¤SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions. Dialogues are distilled from a PLM (InstructGPT; Ouyang et al., 2022) by contextualizing social commonsense knowledge from a knowledge graph (Atomic10x; West et al., 2022). Human evaluation shows that dialogues in SODA are more consistent, specific, and (surprisingly) natural than prior human-authoredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/soda.","url":"https://huggingface.co/datasets/allenai/soda","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["dialogue-generation","machine-generated","monolingual","original","extended|Atomic10x"],"keywords_longer_than_N":true},
	{"name":"customer-service-apple-picker-maintenance","keyword":"fictitious dialogues","description":"\n\t\n\t\t\n\t\tThis Dialogue\n\t\n\nComprised of fictitious examples of dialogues between a technician and an expert on maintaining automated apple picker machines. Check out the example below:\n\"id\": 1,\n\"description\": \"Machine not picking apples\",\n\"dialogue\": \"Technician: Hello, one of our apple picker machines is not picking apples. What should I do to fix it?\\n\\nExpert: Check the picking arms for any obstructions or damage. Clean or replace them if necessary. Also, ensure the collection basket is notâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FunDialogues/customer-service-apple-picker-maintenance.","url":"https://huggingface.co/datasets/FunDialogues/customer-service-apple-picker-maintenance","creator_name":"fun dialogues","creator_url":"https://huggingface.co/FunDialogues","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"ru_instruct_gpt4","keyword":"chat","description":"\n\t\n\t\t\n\t\tru_instruct_gpt4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDataset of GPT-4 generated instructions in Russian. Will soon be updated with more examples.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRussian\n","url":"https://huggingface.co/datasets/lksy/ru_instruct_gpt4","creator_name":"Lucaz A","creator_url":"https://huggingface.co/lksy","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Russian","cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"turn-detection-vietnamese","keyword":"conversation","description":"Nguá»“n dá»¯ liá»‡u:  vi-wiki-conversational-search\n\nTá»· lá»‡ Complete:Incomplete = 244304:366451\nÄÃ£ lÆ°u 610755 samples vÃ o training_data.csv\nÄÃ£ lÆ°u 6189 samples vÃ o test_data.csv\n\n","url":"https://huggingface.co/datasets/phucpx247/turn-detection-vietnamese","creator_name":"Phuc Phan","creator_url":"https://huggingface.co/phucpx247","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Vietnamese","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"nb_samtale","keyword":"conversational","description":"NB Samtale is a speech corpus made by the Language Bank at the National Library of Norway.\nThe corpus contains orthographically transcribed speech from podcasts and recordings of live events at the National Library.\nThe corpus is intended as an open source dataset for Automatic Speech Recognition (ASR) development,\nand is specifically aimed at improving ASR systemsâ€™ handle on conversational speech.","url":"https://huggingface.co/datasets/Sprakbanken/nb_samtale","creator_name":"Nasjonalbiblioteket SprÃ¥kbanken","creator_url":"https://huggingface.co/Sprakbanken","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Norwegian BokmÃ¥l","Norwegian Nynorsk","Norwegian","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"prosocial-dialog","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Card for ProsocialDialog Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nProsocialDialog is the first large-scale multi-turn English dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/prosocial-dialog.","url":"https://huggingface.co/datasets/allenai/prosocial-dialog","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","dialogue-generation","multi-class-classification","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"UsenetArchiveIT-conversations","keyword":"conversations","description":"\n\t\n\t\t\n\t\tConversational Usenet Archive IT Dataset ðŸ‡®ðŸ‡¹\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n\t\n\t\t\n\t\tDataset Content\n\t\n\nThis dataset is a filtered version from the Usenet dataset that contains posts from Italian language newsgroups belonging to the it and italia hierarchies. The data has been archived and converted to the Parquet format for easy processing. All posts with more the one message has been grouped in conversations\nThis dataset contributes to the mii-community project, aimed at advancing theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mii-community/UsenetArchiveIT-conversations.","url":"https://huggingface.co/datasets/mii-community/UsenetArchiveIT-conversations","creator_name":"mii-community","creator_url":"https://huggingface.co/mii-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"male-validate","keyword":"chat","description":"\n\t\n\t\t\n\t\tmale-validate\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/male-validate\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/male-validate","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ludwig","keyword":"conversation","description":"TODO","url":"https://huggingface.co/datasets/UCL-DARK/ludwig","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"male-validate","keyword":"conversations","description":"\n\t\n\t\t\n\t\tmale-validate\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/male-validate\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/male-validate","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ludwig","keyword":"dialogue","description":"TODO","url":"https://huggingface.co/datasets/UCL-DARK/ludwig","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"healthcare_conversational_messages_10k","keyword":"chat","description":"\n\t\n\t\t\n\t\tHealthcare Conversational Messages 10k\n\t\n\nSynthetic healthcare Q&A dataset in messages schema (role-tagged user/assistant turns) with longer, narrative user prompts including context and history.\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row:\n{\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"...\"},\n    {\"role\": \"assistant\", \"content\": \"...\"}\n  ]\n}\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(adrianf12/healthcare_conversational_messages_10k)\nprint(ds[train][0])\n","url":"https://huggingface.co/datasets/adrianf12/healthcare_conversational_messages_10k","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"healthcare_conversational_messages_10k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tHealthcare Conversational Messages 10k\n\t\n\nSynthetic healthcare Q&A dataset in messages schema (role-tagged user/assistant turns) with longer, narrative user prompts including context and history.\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row:\n{\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"...\"},\n    {\"role\": \"assistant\", \"content\": \"...\"}\n  ]\n}\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(adrianf12/healthcare_conversational_messages_10k)\nprint(ds[train][0])\n","url":"https://huggingface.co/datasets/adrianf12/healthcare_conversational_messages_10k","creator_name":"Adrian Matei","creator_url":"https://huggingface.co/adrianf12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ChatAlpaca-20K","keyword":"chat","description":"\n\t\n\t\t\n\t\tDataset Card for ChatAlpaca 20K\n\t\n\n\n\t\n\t\t\n\t\tChatAlpaca: A Multi-Turn Dialogue Corpus based on Alpaca Instructions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nChatAlpaca is a chat dataset that aims to help researchers develop models for instruction-following in multi-turn conversations. The dataset is an extension of the Stanford Alpaca data, which contains multi-turn instructions and their corresponding responses.\nChatAlpaca is developed by Chinese Information Processing Laboratory at theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/robinsmits/ChatAlpaca-20K.","url":"https://huggingface.co/datasets/robinsmits/ChatAlpaca-20K","creator_name":"Robin Smits","creator_url":"https://huggingface.co/robinsmits","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"grdmr_test_zoo_648292","keyword":"chat","description":"sofiapaklina/grdmr_test_zoo_648292 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sofiapaklina/grdmr_test_zoo_648292","creator_name":"Sofia P","creator_url":"https://huggingface.co/sofiapaklina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Russian","cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"honkai_impact_3rd_chinese_dialogue_corpus","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tå´©åä¸‰æ¸¸æˆå‰§æƒ…è¯­æ–™\n\t\n\næ€»è®¡ 92,421 å¥å‰§æƒ…å¯¹ç™½ï¼ˆå¸¦æœ‰è§’è‰²æ ‡ç­¾ï¼‰+æ—ç™½ï¼Œä»Žå´©å3çš„â€œä¸»çº¿1é»„æ˜ã€å°‘å¥³ã€æˆ˜èˆ°â€åˆ°â€œä¸»çº¿ç¬¬äºŒéƒ¨03é—´ç« ï¼šä¸€ä¸ªæ¢¦æ¸¸è€…çš„è‹¦ç—›â€\næœ¬æ•°æ®é›†ä»Ž honkai_impact_3rd_game_playthrough è§†é¢‘æ•°æ®é›†å‡ºå‘ï¼Œç»è¿‡ AI pipeline æœ€ç»ˆèŽ·å–ç»“æž„åŒ–çš„æ–‡æœ¬å‰§æƒ…è¯­æ–™ã€‚\nAI pipeline æ¦‚è¿°å¦‚ä¸‹ï¼š\n\nåˆ†Pä¸‹è½½è§†é¢‘ï¼ˆä½¿ç”¨ BBDown ä¸‹è½½ BiliBiliå´©ä¸‰å‰§æƒ…è§†é¢‘ï¼‰\nè§†é¢‘å¸§åˆ†å‰²ï¼ˆæ¯1ç§’å–ä¸€å¸§ç”»é¢ï¼‰\né€å¸§ OCR æ£€æµ‹æ–‡æœ¬ï¼ˆä½¿ç”¨ Paddle-OCRï¼‰\né€å¸§ VLM ç»“æž„åŒ–è§£æžï¼ˆä½¿ç”¨ MiniCPM-V-2_6ï¼Œè¾“å…¥ä¸ºå¸§å›¾åƒ + OCRç»“æžœï¼Œè¾“å‡ºä¸ºç»“æž„åŒ– JSONï¼‰\nåŸºäºŽè§„åˆ™çš„åŽå¤„ç†\nè§„èŒƒåŒ– VLM è¾“å‡ºï¼ˆe.g., åŽ»å™ªã€æŽ’é™¤æ ¼å¼æœ‰é—®é¢˜çš„è¾“å‡ºï¼‰\nä¸­é—´å¸§çš„ä¿¡æ¯åŽ»é‡ä¸Žå½’å¹¶ï¼ˆe.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/honkai_impact_3rd_chinese_dialogue_corpus.","url":"https://huggingface.co/datasets/mrzjy/honkai_impact_3rd_chinese_dialogue_corpus","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US","game"],"keywords_longer_than_N":true},
	{"name":"kd_conv_with_kb","keyword":"dialogue-modeling","description":"KdConv is a Chinese multi-domain Knowledge-driven Conversionsation dataset, grounding the topics in multi-turn conversations to knowledge graphs. KdConv contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics, while the corpus can also used for exploration of transfer learning and domain adaptation.\\","url":"https://huggingface.co/datasets/thu-coai/kd_conv_with_kb","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","dialogue-modeling","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"assistant-bot-intent-dataset","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tIntent Classification Dataset for Contact Management Assistant Bot\n\t\n\nThis dataset is used to train intent classifiers for contact management tasks in natural language.\n\n\t\n\t\t\n\t\tSupported Intents\n\t\n\nThis dataset contains training examples for 15+ different intents:\n\n\t\n\t\t\n\t\tContact Management\n\t\n\n\nadd_contact - Add new contact with name, phone, email, address, birthday\nedit_phone - Update contact's phone number\nedit_email - Update contact's email address\nedit_address - Update contact'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kms-engineer/assistant-bot-intent-dataset.","url":"https://huggingface.co/datasets/kms-engineer/assistant-bot-intent-dataset","creator_name":"Mykyta Kotenko","creator_url":"https://huggingface.co/kms-engineer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"female-validate","keyword":"chat","description":"\n\t\n\t\t\n\t\tfemale-validate\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/female-validate\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/female-validate","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"dmitrii-krylosov-dialog","keyword":"conversational","description":"Ð”Ð¸Ð°Ð»Ð¾Ð³Ð¸ Ð”Ð¼Ð¸Ñ‚Ñ€Ð¸Ñ ÐšÑ€Ñ‹Ð»Ð¾ÑÐ¾Ð²Ð° (Python-Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð¸Ð· Ð£Ñ„Ñ‹) Ð¾ Ð³ÐµÐ¾Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… ÑÐ¸Ð¼ÑƒÐ»ÑÑ†Ð¸ÑÑ…, Ð±Ð»Ð¾ÐºÑ‡ÐµÐ¹Ð½Ðµ TON Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ñ†Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ð³Ð¾ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°.\nDmitry Krylosov's (Python developer from Ufa) dialogues about geospatial simulations, TON blockchain, and creating a digital avatar.\n\n\n\t\n\t\t\n\t\tlicense: cc-by-4.0\n\t\n\n","url":"https://huggingface.co/datasets/pythondikrylosov/dmitrii-krylosov-dialog","creator_name":"Dmitrii Krylosov","creator_url":"https://huggingface.co/pythondikrylosov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","Geospatial","ðŸ‡ºðŸ‡¸ Region: US","russian","conversational"],"keywords_longer_than_N":true},
	{"name":"female-validate","keyword":"conversations","description":"\n\t\n\t\t\n\t\tfemale-validate\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/female-validate\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/female-validate","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Conversation_chats","keyword":"chat","description":"sanjaykz/Conversation_chats dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sanjaykz/Conversation_chats","creator_name":"Sanjay Madta","creator_url":"https://huggingface.co/sanjaykz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Conversation_chats","keyword":"conversation","description":"sanjaykz/Conversation_chats dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sanjaykz/Conversation_chats","creator_name":"Sanjay Madta","creator_url":"https://huggingface.co/sanjaykz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"indonesian-conversation","keyword":"conversational","description":"\n\t\n\t\t\n\t\tIndonesian Conversation\n\t\n\nIndonesian Conversation is a carefully curated conversational dataset featuring high-quality dialogues primarily in Bahasa Indonesia, with occasional English phrases. The dataset has been specifically designed to support alignment and supervised fine-tuning (SFT) for open-source large language models targeting Indonesian language applications.\nThe collection consists predominantly of multi-turn conversations that showcase natural, friendly, and informativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/izzulgod/indonesian-conversation.","url":"https://huggingface.co/datasets/izzulgod/indonesian-conversation","creator_name":"Izzul Fahmi","creator_url":"https://huggingface.co/izzulgod","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Indonesian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DistilQwen_100k_korean","keyword":"conversation","description":"\n\t\n\t\t\n\t\tDistilQwen 100k Korean\n\t\n\nThis dataset is a Korean translation of the original alibaba-pai/DistilQwen_100k dataset.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains both English and Korean versions of instruction-response pairs:\n{\n  \"instruction\": \"Original English instruction text\",\n  \"output\": \"Original English response/answer\",\n  \"instruction_kr\": \"Korean translation of the instruction\",\n  \"output_kr\": \"Korean translation of the response/answer\",\n  \"_dataset_index\": 30000\n}\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lcw99/DistilQwen_100k_korean.","url":"https://huggingface.co/datasets/lcw99/DistilQwen_100k_korean","creator_name":"Chang W Lee","creator_url":"https://huggingface.co/lcw99","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Korean","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ShareGPT52K","keyword":"conversation","description":"\n\t\n\t\t\n\t\tDataset Card for ShareGPT52K90K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of approximately 52,00090,000 conversations scraped via the ShareGPT API before it was shut down.\nThese conversations include both user prompts and responses from OpenAI's ChatGPT.\nThis repository now contains the new 90K conversations version. The previous 52K may\nbe found in the old/ directory.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-generation\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RyokoAI/ShareGPT52K.","url":"https://huggingface.co/datasets/RyokoAI/ShareGPT52K","creator_name":"Ryoko AI","creator_url":"https://huggingface.co/RyokoAI","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","German","multilingual"],"keywords_longer_than_N":true},
	{"name":"telecom-conversation-corpus","keyword":"conversation","description":"eisenzopf/telecom-conversation-corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/eisenzopf/telecom-conversation-corpus","creator_name":"Jonathan Eisenzopf","creator_url":"https://huggingface.co/eisenzopf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"shakespeare-dialogue","keyword":"dialogue","description":"Taken from Andrej Karpathy and repurposed for UofT's CSC 413 Deep Learning \n40,000 lines of Shakespeare from a variety of Shakespeare's plays. Featured in Andrej Karpathy's blog post 'The Unreasonable Effectiveness of Recurrent Neural Networks': http://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo use for e.g. character modelling:\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"r-three/shakespeare-dialogue\")\n\n# Access examples\nfor exampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/r-three/shakespeare-dialogue.","url":"https://huggingface.co/datasets/r-three/shakespeare-dialogue","creator_name":"r-three","creator_url":"https://huggingface.co/r-three","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"conversational","description":"\n\t\n\t\t\n\t\tðŸ“º YouTube-Commons ðŸ“º\n\t\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\nIn total, this represents nearly 45 billion words (44,811,518,375).\nAll the videos where shared on YouTube with a CC-BY license: the dataset provide all the necessary provenance informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gautijha37/YouTube-Commons.","url":"https://huggingface.co/datasets/gautijha37/YouTube-Commons","creator_name":"Gautam Jha","creator_url":"https://huggingface.co/gautijha37","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"GUI-Ban","keyword":"chat","description":"wendellast/GUI-Ban dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/wendellast/GUI-Ban","creator_name":"wendel alves","creator_url":"https://huggingface.co/wendellast","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DEBATE","keyword":"debate","description":"\n\t\n\t\t\n\t\tDEBATE: Diverse Multi-Agent Debates\n\t\n\nThis dataset is presented in the paper \"MALLM: Multi-Agent Large Language Models Framework\". \n\n\t\n\t\t\n\t\tCitation\n\t\n\ncomming soon.\n\n","url":"https://huggingface.co/datasets/Multi-Agent-LLMs/DEBATE","creator_name":"Multi-Agent-LLMs","creator_url":"https://huggingface.co/Multi-Agent-LLMs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DEBATE","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDEBATE: Diverse Multi-Agent Debates\n\t\n\nThis dataset is presented in the paper \"MALLM: Multi-Agent Large Language Models Framework\". \n\n\t\n\t\t\n\t\tCitation\n\t\n\ncomming soon.\n\n","url":"https://huggingface.co/datasets/Multi-Agent-LLMs/DEBATE","creator_name":"Multi-Agent-LLMs","creator_url":"https://huggingface.co/Multi-Agent-LLMs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"shakespeare-sonnet-dialogue-blob","keyword":"dialogue","description":"Taken from Andrej Karpathy and repurposed for UofT's CSC 413 Deep Learning \n40,000 lines of Shakespeare from a variety of Shakespeare's plays. Featured in Andrej Karpathy's blog post 'The Unreasonable Effectiveness of Recurrent Neural Networks': http://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo use for e.g. character modelling:\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"r-three/shakespeare-sonnet-dialogue-blob\")\n\n\n\n\t\n\t\t\n\t\tSourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/r-three/shakespeare-sonnet-dialogue-blob.","url":"https://huggingface.co/datasets/r-three/shakespeare-sonnet-dialogue-blob","creator_name":"r-three","creator_url":"https://huggingface.co/r-three","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"shakespeare-dialogue-blob","keyword":"dialogue","description":"Taken from Andrej Karpathy and repurposed for UofT's CSC 413 Deep Learning \n40,000 lines of Shakespeare from a variety of Shakespeare's plays. Featured in Andrej Karpathy's blog post 'The Unreasonable Effectiveness of Recurrent Neural Networks': http://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo use for e.g. character modelling:\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"r-three/shakespeare-dialogue-blob\")\n\n# Access examples\nforâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/r-three/shakespeare-dialogue-blob.","url":"https://huggingface.co/datasets/r-three/shakespeare-dialogue-blob","creator_name":"r-three","creator_url":"https://huggingface.co/r-three","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"synthetic-neurology-conversations","keyword":"conversation","description":"\n\t\n\t\t\n\t\tSynthetic Neurology Conversations\n\t\n\nSummary.This dataset augments questions from KryptoniteCrown/synthetic-neurology-QA-dataset with a compact two-step follow-up conversation generated by moonshotai/Kimi-K2-Instruct:\n\nmodel answers the original question,  \nmodel asks a follow-up question (to deepen/clarify),  \nmodel answers its follow-up.\n\nShared by the OpenMed Community to help improve medical models globally.  \n\nNot medical advice. Research/education only; not for clinicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openmed-community/synthetic-neurology-conversations.","url":"https://huggingface.co/datasets/openmed-community/synthetic-neurology-conversations","creator_name":"OpenMed Community","creator_url":"https://huggingface.co/openmed-community","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"synthetic-neurology-conversations","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSynthetic Neurology Conversations\n\t\n\nSummary.This dataset augments questions from KryptoniteCrown/synthetic-neurology-QA-dataset with a compact two-step follow-up conversation generated by moonshotai/Kimi-K2-Instruct:\n\nmodel answers the original question,  \nmodel asks a follow-up question (to deepen/clarify),  \nmodel answers its follow-up.\n\nShared by the OpenMed Community to help improve medical models globally.  \n\nNot medical advice. Research/education only; not for clinicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openmed-community/synthetic-neurology-conversations.","url":"https://huggingface.co/datasets/openmed-community/synthetic-neurology-conversations","creator_name":"OpenMed Community","creator_url":"https://huggingface.co/openmed-community","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"RolePlay-NPC","keyword":"roleplay","description":"This is the dataset used to train the Gemma3NPC models.This dataset is a combination of our cleaned PIPPA dataset and our own synthetically generated NPC dialogue dataset.\n","url":"https://huggingface.co/datasets/chimbiwide/RolePlay-NPC","creator_name":"chimbiwide","creator_url":"https://huggingface.co/chimbiwide","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"user-gender-model","keyword":"chat","description":"\n\t\n\t\t\n\t\tuser-gender-model\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/user-gender-model\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/user-gender-model","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"user-gender-model","keyword":"conversations","description":"\n\t\n\t\t\n\t\tuser-gender-model\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/user-gender-model\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/user-gender-model","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"arguana-c-64-24-gpt-4o-2024-05-136897","keyword":"argumentation","description":"\n\t\n\t\t\n\t\targuana-c-64-24-gpt-4o-2024-05-136897 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-64-24-gpt-4o-2024-05-136897 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136897.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"test2027","keyword":"conversation","description":"A dataset containing dialogues between assistant and user with different roles.","url":"https://huggingface.co/datasets/zjrwtxtechstudio/test2027","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"test2027","keyword":"dialogue","description":"A dataset containing dialogues between assistant and user with different roles.","url":"https://huggingface.co/datasets/zjrwtxtechstudio/test2027","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MediumSetPT","keyword":"conversation","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset de Perguntas e Respostas por TÃ³pico\n\t\n\nEste repositÃ³rio contÃ©m um dataset com 40.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas temÃ¡ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tðŸ“ Estrutura dos Dados\n\t\n\nCada amostra Ã© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador Ãºnico da amostra (UUID).\ntopic (lista de strings): Lista com os tÃ³picos abordados.\nprompts (lista de strings):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/MediumSetPT.","url":"https://huggingface.co/datasets/AxeML/MediumSetPT","creator_name":"AxÃ©ML - Community","creator_url":"https://huggingface.co/AxeML","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MediumSetPT","keyword":"dialogue","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset de Perguntas e Respostas por TÃ³pico\n\t\n\nEste repositÃ³rio contÃ©m um dataset com 40.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas temÃ¡ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tðŸ“ Estrutura dos Dados\n\t\n\nCada amostra Ã© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador Ãºnico da amostra (UUID).\ntopic (lista de strings): Lista com os tÃ³picos abordados.\nprompts (lista de strings):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/MediumSetPT.","url":"https://huggingface.co/datasets/AxeML/MediumSetPT","creator_name":"AxÃ©ML - Community","creator_url":"https://huggingface.co/AxeML","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Discord-OpenMicae","keyword":"chat-dataset","description":"\n  \n\n\n\nDiscord-OpenMicae is a dataset of anonymized Discord conversations from late spring to late summer 2025 for training and evaluating conversational AI models in a ChatML-friendly format.\n\n\n250k+ Single-Turn Exchanges (STX) â€“ standalone user â†’ reply pairs  \n100k+ Multi-Turn Chains â€“ two-participant reply chains, variable length\n\n\n\n  \n    \n  \n\n\n\n  Nomic Atlas Map\n\n\n\n\n\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nHuman-only dialogues (no bots)\nLinks, embeds, and commands removed\nTrading posts, code blocks, and LFGâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mookiezi/Discord-OpenMicae.","url":"https://huggingface.co/datasets/mookiezi/Discord-OpenMicae","creator_name":"Jason","creator_url":"https://huggingface.co/mookiezi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Discord-OpenMicae","keyword":"conversation","description":"\n  \n\n\n\nDiscord-OpenMicae is a dataset of anonymized Discord conversations from late spring to late summer 2025 for training and evaluating conversational AI models in a ChatML-friendly format.\n\n\n250k+ Single-Turn Exchanges (STX) â€“ standalone user â†’ reply pairs  \n100k+ Multi-Turn Chains â€“ two-participant reply chains, variable length\n\n\n\n  \n    \n  \n\n\n\n  Nomic Atlas Map\n\n\n\n\n\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nHuman-only dialogues (no bots)\nLinks, embeds, and commands removed\nTrading posts, code blocks, and LFGâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mookiezi/Discord-OpenMicae.","url":"https://huggingface.co/datasets/mookiezi/Discord-OpenMicae","creator_name":"Jason","creator_url":"https://huggingface.co/mookiezi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Discord-OpenMicae","keyword":"dialogue","description":"\n  \n\n\n\nDiscord-OpenMicae is a dataset of anonymized Discord conversations from late spring to late summer 2025 for training and evaluating conversational AI models in a ChatML-friendly format.\n\n\n250k+ Single-Turn Exchanges (STX) â€“ standalone user â†’ reply pairs  \n100k+ Multi-Turn Chains â€“ two-participant reply chains, variable length\n\n\n\n  \n    \n  \n\n\n\n  Nomic Atlas Map\n\n\n\n\n\t\n\t\n\t\n\t\tFeatures\n\t\n\n\nHuman-only dialogues (no bots)\nLinks, embeds, and commands removed\nTrading posts, code blocks, and LFGâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mookiezi/Discord-OpenMicae.","url":"https://huggingface.co/datasets/mookiezi/Discord-OpenMicae","creator_name":"Jason","creator_url":"https://huggingface.co/mookiezi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"OpenCharacter","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tOpenCharacter: Training Customizable Role-Playing LLMs with Large-Scale Synthetic Personas\n\t\n\nThis repo releases data introduced in our paper OpenCharacter: Training Customizable Role-Playing LLMs with Large-Scale Synthetic Personas in arXiv.\n\nWe study customizable role-playing dialogue agents in large language models (LLMs).\nWe tackle the challenge with large-scale data synthesis: character synthesis and character-driven reponse synthesis.\nOur solution strengthens the original LLaMA-3â€¦ See the full description on the dataset page: https://huggingface.co/datasets/xywang1/OpenCharacter.","url":"https://huggingface.co/datasets/xywang1/OpenCharacter","creator_name":"Xiaoyang Wang","creator_url":"https://huggingface.co/xywang1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"multi-agent-scam-conversation","keyword":"conversation","description":"\n\t\n\t\t\n\t\tSynthetic Multi-Turn Scam and Non-Scam Phone Conversation Dataset with Agentic Personalities\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Synthetic Multi-Turn Scam and Non-Scam Phone Dialogue Dataset with Agentic Personalities is an enhanced collection of simulated phone conversations between two AI agents, one acting as a scammer or non-scammer and the other as an innocent receiver. Each dialogue is labeled as either a scam or non-scam interaction. This dataset is designed to help developâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BothBosu/multi-agent-scam-conversation.","url":"https://huggingface.co/datasets/BothBosu/multi-agent-scam-conversation","creator_name":"Pitipat Gumphusiri","creator_url":"https://huggingface.co/BothBosu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"nutuk-soru-ve-cevaplar-veriseti","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Nutuk Q&A Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 7,634 question-answer pairs in Turkish, extracted and curated from Mustafa Kemal AtatÃ¼rk's famous speech \"Nutuk\" (The Great Speech). The dataset is designed for fine-tuning Turkish language models to understand and respond to questions about Turkish history, the War of Independence, and AtatÃ¼rk's thoughts and philosophies.\nThe dataset presents conversations in a formatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erenfazlioglu/nutuk-soru-ve-cevaplar-veriseti.","url":"https://huggingface.co/datasets/erenfazlioglu/nutuk-soru-ve-cevaplar-veriseti","creator_name":"EREN FAZLIOÄžLU","creator_url":"https://huggingface.co/erenfazlioglu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Turkish","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"FinancialNewsAndCentralBanksSpeeches-Summary-Rag","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tFinancial News Summaries, Stock Events, and Central Bank Speeches\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nThis dataset contains structured historical financial information used to support a stock prediction model with interpretable explanations. \nIt is designed to work with https://huggingface.co/spaces/SelmaNajih001/StockPredictionExplanation, where the FAISS index is stored for fast retrieval of relevant events.\nSo if you want the FAISS dataset, just go to that space in the file section andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SelmaNajih001/FinancialNewsAndCentralBanksSpeeches-Summary-Rag.","url":"https://huggingface.co/datasets/SelmaNajih001/FinancialNewsAndCentralBanksSpeeches-Summary-Rag","creator_name":"Selma Najih","creator_url":"https://huggingface.co/SelmaNajih001","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"multi-agent-scam-conversation","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSynthetic Multi-Turn Scam and Non-Scam Phone Conversation Dataset with Agentic Personalities\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Synthetic Multi-Turn Scam and Non-Scam Phone Dialogue Dataset with Agentic Personalities is an enhanced collection of simulated phone conversations between two AI agents, one acting as a scammer or non-scammer and the other as an innocent receiver. Each dialogue is labeled as either a scam or non-scam interaction. This dataset is designed to help developâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BothBosu/multi-agent-scam-conversation.","url":"https://huggingface.co/datasets/BothBosu/multi-agent-scam-conversation","creator_name":"Pitipat Gumphusiri","creator_url":"https://huggingface.co/BothBosu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"samueloct20-X-collected-character_conversation-20250815","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tCharacter Conversation Dataset for AI Research\n\t\n\nThis dataset contains anonymized, publicly collected Twitter conversations involving AI characters, intended for training and research of dialogue models.\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nOnly conversations including specified AI characters are collected.\nConversations are fully anonymized by replacing character names with <CHARn> tokens (e.g., <CHAR0>, <CHAR1>).\nPrivate messages (DMs), protected accounts, and private tweets are excluded.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HenryExplorer/samueloct20-X-collected-character_conversation-20250815.","url":"https://huggingface.co/datasets/HenryExplorer/samueloct20-X-collected-character_conversation-20250815","creator_name":"Henry","creator_url":"https://huggingface.co/HenryExplorer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","cc-by-4.0","n<1K","Text"],"keywords_longer_than_N":true},
	{"name":"Moshpit-Combined-R2-Uncensored","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tMoshPIT-R2 COMBINED UNCENSORED\n\t\n\n\nMoshPIT R2, is a dataset combining multiple Moshpit Iteration to make a 500 Dataset examples,\n\nMoshPIT R2 is purely generated through GPT2-XL,\n\nMushed-R1 Dataset is Synthetic, It has no Curation But can offer Quick Dataset to 1B Models\n\nDue to its Lightweight 500 Examples\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tMoshPIT-R2 COMBINED UNCENSORED Dataset follows 'CONVERSATIONAL', where the Dataset engage in \"user\" and \"Response\" Dataset Generation\n\t\n\n\nThis could be useful forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/N-Bot-Int/Moshpit-Combined-R2-Uncensored.","url":"https://huggingface.co/datasets/N-Bot-Int/Moshpit-Combined-R2-Uncensored","creator_name":"Nexus Botworks Interactives","creator_url":"https://huggingface.co/N-Bot-Int","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Olympus","keyword":"conversational","description":"\n\t\n\t\t\n\t\tOlympus: A Universal Task Router for Computer Vision Tasks (CVPR 2025, Highlight) \n\t\n\n\n \n\n\n\n\nâ™¥ï¸ If you find our datasets are helpful for your research, please kindly give us a ðŸŒŸ on https://github.com/yuanze-lin/Olympus and cite our paper ðŸ“‘\n\n\t\n\t\t\n\t\n\t\n\t\tOlympus Dataset Card\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset details\n\t\n\nDataset type: Olympus data is a GPT-generated instruction-following dataset covering 20 different computer vision tasks, designed for visual instruction tuning and the developmentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yuanze/Olympus.","url":"https://huggingface.co/datasets/Yuanze/Olympus","creator_name":"yz","creator_url":"https://huggingface.co/Yuanze","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"clustered_tulu_3_8","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tClustered_Tulu_3_8 Multi-Domain Dataset\n\t\n\nThis dataset contains high-quality examples across 8 specialized domains, automatically extracted and curated from the Tulu-3 SFT mixture using advanced clustering techniques.\n\n\t\n\t\t\n\t\tðŸŽ¯ Multi-Domain Structure\n\t\n\nThis repository provides 8 domain-specific configurations, each optimized for different types of tasks:\n\n\t\n\t\t\nConfiguration\nDomain\nTrain\nTest\nTotal\n\n\n\t\t\nprogramming_and_code_development\nProgramming & Code Development\n88,783\n22,196\n110â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/clustered_tulu_3_8.","url":"https://huggingface.co/datasets/Malikeh1375/clustered_tulu_3_8","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"endex-700k-ns","keyword":"roleplay","description":"Train data of https://github.com/gxxu-ml/endex\n","url":"https://huggingface.co/datasets/uproai/endex-700k-ns","creator_name":"Rochat AI","creator_url":"https://huggingface.co/uproai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"refactorchat","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tModel Card\n\t\n\n\n\t\n\t\t\n\t\tModel Details\n\t\n\n\nDataset Name: RefactorChat\nVersion: 1.0\nDate: October 19, 2024\nType: Multi-turn dialogue dataset for code refactoring and feature addition\n\n\n\t\n\t\t\n\t\tIntended Use\n\t\n\n\nPrimary Use: Evaluating and training large language models on incremental code development tasks\nIntended Users: Researchers and practitioners in natural language processing and software engineering\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\n\nSize: 100 samples\nStructure: Each sample consists ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BradMcDanel/refactorchat.","url":"https://huggingface.co/datasets/BradMcDanel/refactorchat","creator_name":"Bradley McDanel","creator_url":"https://huggingface.co/BradMcDanel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"first-person-dialogue","keyword":"conversation","description":"\n\t\n\t\t\n\t\tFirst Person Dialogue Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for training one-on-one chatbots, featuring a wide range of social roles and situations. \nIt allows for assigning a name to the AI character, creating a more personalized, more intimate conversational experience.\n\n\t\n\t\t\n\t\tContents\n\t\n\nThe dataset is a curated combination of several existing datasets:\n\nallenai/soda\nallenai/prosocial-dialog\nEstwld/empathetic_dialogues_llmâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/first-person-dialogue.","url":"https://huggingface.co/datasets/agentlans/first-person-dialogue","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"first-person-dialogue","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tFirst Person Dialogue Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for training one-on-one chatbots, featuring a wide range of social roles and situations. \nIt allows for assigning a name to the AI character, creating a more personalized, more intimate conversational experience.\n\n\t\n\t\t\n\t\tContents\n\t\n\nThe dataset is a curated combination of several existing datasets:\n\nallenai/soda\nallenai/prosocial-dialog\nEstwld/empathetic_dialogues_llmâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/first-person-dialogue.","url":"https://huggingface.co/datasets/agentlans/first-person-dialogue","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"first-person-dialogue","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tFirst Person Dialogue Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for training one-on-one chatbots, featuring a wide range of social roles and situations. \nIt allows for assigning a name to the AI character, creating a more personalized, more intimate conversational experience.\n\n\t\n\t\t\n\t\tContents\n\t\n\nThe dataset is a curated combination of several existing datasets:\n\nallenai/soda\nallenai/prosocial-dialog\nEstwld/empathetic_dialogues_llmâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/first-person-dialogue.","url":"https://huggingface.co/datasets/agentlans/first-person-dialogue","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"respect","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tRetrospective Learning from Interactions (Respect) Dataset\n\t\n\nThis repository contains the lil-lab/respect data, based on the ACL paper Retrospective Learning from Interactions. For more resources, please see https://lil-lab.github.io/respect and https://github.com/lil-lab/respect.\n\n\t\n\t\t\n\t\n\t\n\t\tSample Usage\n\t\n\nYou can load the data and associated checkpoints as follows:\nfrom datasets import load_dataset\nfrom transformers import Idefics2ForConditionalGeneration\nfrom peft importPeftModelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lil-lab/respect.","url":"https://huggingface.co/datasets/lil-lab/respect","creator_name":"Cornell LIL Lab","creator_url":"https://huggingface.co/lil-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"respect","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tRetrospective Learning from Interactions (Respect) Dataset\n\t\n\nThis repository contains the lil-lab/respect data, based on the ACL paper Retrospective Learning from Interactions. For more resources, please see https://lil-lab.github.io/respect and https://github.com/lil-lab/respect.\n\n\t\n\t\t\n\t\n\t\n\t\tSample Usage\n\t\n\nYou can load the data and associated checkpoints as follows:\nfrom datasets import load_dataset\nfrom transformers import Idefics2ForConditionalGeneration\nfrom peft importPeftModelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lil-lab/respect.","url":"https://huggingface.co/datasets/lil-lab/respect","creator_name":"Cornell LIL Lab","creator_url":"https://huggingface.co/lil-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ru-instruct-conversation-v1","keyword":"chat","description":"Combined dataset of mostly Russian dialogs in form of conversations suitable for LLM fine-tuning scenarios.\nTotal samples: 82208\nDeduplicated using simhash(hamming_treshold=3).\nDatasets used:\n\nIlyaGusev/saiga_scored (min_score: 8, no bad by regexp)\nIlyaGusev/oasst2_ru_main_branch\nattn-signs/kolmogorov-3\nattn-signs/russian-easy-instructions\n\n","url":"https://huggingface.co/datasets/ZeroAgency/ru-instruct-conversation-v1","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ru-instruct-conversation-v1","keyword":"conversational","description":"Combined dataset of mostly Russian dialogs in form of conversations suitable for LLM fine-tuning scenarios.\nTotal samples: 82208\nDeduplicated using simhash(hamming_treshold=3).\nDatasets used:\n\nIlyaGusev/saiga_scored (min_score: 8, no bad by regexp)\nIlyaGusev/oasst2_ru_main_branch\nattn-signs/kolmogorov-3\nattn-signs/russian-easy-instructions\n\n","url":"https://huggingface.co/datasets/ZeroAgency/ru-instruct-conversation-v1","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"FinancialClassification","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tDataset Card for Financial classification\n\t\n\n\n\nThis dataset contains the stock name, the event, and the corresponding price variation that occurred on a specific date. It can be used for regression tasks or text classification.\nI used this dataset to train a regression model available on my Hugging Face profile.\nYou can learn how to use the dataset using this example on: https://huggingface.co/blog/SelmaNajih001/how-to-run-a-regression-using-hugging-face\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SelmaNajih001/FinancialClassification.","url":"https://huggingface.co/datasets/SelmaNajih001/FinancialClassification","creator_name":"Selma Najih","creator_url":"https://huggingface.co/SelmaNajih001","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"conversational","description":"\n\t\n\t\t\n\t\tðŸ—£ï¸ MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒŸ Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"CakrawalaRP","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tðŸŽ­ CakrawalaRP\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis purely synthetic dataset contains rich roleplaying conversations between characters with detailed personas and backstories. It was used to train Cakrawala models a fine-tuned variant of Llama 3.1 models optimized for generating immersive character interactions.\n\n\t\n\t\t\n\t\tIntended Tasks\n\t\n\n\nCharacter-based dialogue generation\nIn-depth emotional recognition and responses\nRoleplaying conversation\nPersona-consistent responses\nDescriptive narrativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NarrativAI/CakrawalaRP.","url":"https://huggingface.co/datasets/NarrativAI/CakrawalaRP","creator_name":"NarrativAI","creator_url":"https://huggingface.co/NarrativAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"taboo-green","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-green\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-green\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-green","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-green","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-green\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-green\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-green","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"dataset-portuguese-aira-v2-Gemma-format","keyword":"chat","description":"Dataset Aira para o formato do Modelo Gemma \n\n\n\t\n\t\t\n\t\tResumo do Dataset\n\t\n\nEste conjunto de dados contÃ©m uma coleÃ§Ã£o de conversas individuais entre um assistente e um usuÃ¡rio.\nAs conversas foram geradas pelas interaÃ§Ãµes do usuÃ¡rio com modelos jÃ¡ ajustados (ChatGPT, LLama 2, Open-Assistant, etc).\nO conjunto de dados estÃ¡ disponÃ­vel em portuguÃªs (tem a versÃ£o em InglÃªs que ainda nÃ£o tratei). Mas vocÃª pode baixar do \nrepositÃ³rio de Nicholas Kluge CorrÃªa tanto a versÃ£o em PortuguÃªs e \na versÃ£o emâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format.","url":"https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format","creator_name":"EDDY GIUSEPE CHIRINOS ISIDRO, PhD","creator_url":"https://huggingface.co/EddyGiusepe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"synthetic-irc-data","keyword":"chat","description":"\n\t\n\t\t\n\t\tSynthetic IRC Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1,500 synthetic IRC-style conversations featuring multiple participants, including an AI character named Em. The conversations were generated to replicate authentic IRC chat dynamics with natural flow, interruptions, and varied engagement levels.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal conversations: 1,500\nTotal size: ~10MB\nFormat: JSONL with IRC-style formatting\nLanguage: English\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/david-ar/synthetic-irc-data.","url":"https://huggingface.co/datasets/david-ar/synthetic-irc-data","creator_name":"David A Roberts","creator_url":"https://huggingface.co/david-ar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"synthetic-irc-data","keyword":"conversational","description":"\n\t\n\t\t\n\t\tSynthetic IRC Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1,500 synthetic IRC-style conversations featuring multiple participants, including an AI character named Em. The conversations were generated to replicate authentic IRC chat dynamics with natural flow, interruptions, and varied engagement levels.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal conversations: 1,500\nTotal size: ~10MB\nFormat: JSONL with IRC-style formatting\nLanguage: English\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/david-ar/synthetic-irc-data.","url":"https://huggingface.co/datasets/david-ar/synthetic-irc-data","creator_name":"David A Roberts","creator_url":"https://huggingface.co/david-ar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"user-gender-adversarial","keyword":"chat","description":"\n\t\n\t\t\n\t\tuser-gender-adversarial\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/user-gender-adversarial\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/user-gender-adversarial","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"fgo-story","keyword":"conversation","description":"lesserfield/fgo-story dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/lesserfield/fgo-story","creator_name":"Lesserfield","creator_url":"https://huggingface.co/lesserfield","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Japanese","Indonesian","cc-by-2.0"],"keywords_longer_than_N":true},
	{"name":"Mind-Corpus","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tMind Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 124 handcrafted, multi-turn conversations designed to simulate supportive interactions in mental health contexts. The dataset is bifurcated into two distinct settings:\n\nClinical Setting (In-Office): Dialogues between a patient and a psychologist during a therapy session. These conversations explore ongoing personal issues in a structured, reflective environment.\nCrisis Hotline Setting: Dialogues between a caller inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/Mind-Corpus.","url":"https://huggingface.co/datasets/Locutusque/Mind-Corpus","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"user-gender-adversarial","keyword":"conversations","description":"\n\t\n\t\t\n\t\tuser-gender-adversarial\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/user-gender-adversarial\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/user-gender-adversarial","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Atma4-Hindi","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Atma4-Hindi\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/Atma4-Hindi.","url":"https://huggingface.co/datasets/HappyAIUser/Atma4-Hindi","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"teach-humanities-v1","keyword":"conversational","description":"\n\t\n\t\t\n\t\tCanis.teach Humanities Dataset\n\t\n\nSimple synthetic dataset for training Humanities tutoring models.\n\nProject: Canis.teach - Learning that fits.\nSubject: Humanities\nGenerated with: Canis.lab\nFormat: Simple ID:content pairs\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n  \"id\": \"unique_identifier\",\n  \"content\": \"tutoring conversation text\"\n}\n\nThis dataset contains educational conversations focused on Humanities topics, designed to teach effective tutoring behavior rather than just providing directâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CanisAI/teach-humanities-v1.","url":"https://huggingface.co/datasets/CanisAI/teach-humanities-v1","creator_name":"Canis","creator_url":"https://huggingface.co/CanisAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"GLM-4-Instruct-4K-zh","keyword":"chat","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nâ¤ï¸æ¬¢è¿Žä½¿ç”¨rqq/GLM-4-Instruct-4K-zhæ•°æ®é›†ï¼Œæœ¬æ•°æ®é›†åŒ…å«äº†4000æ¡é«˜è´¨é‡çš„glm4å›žå¤ã€‚\nè¯¥æ•°æ®é›†çš„æé—®æ•°æ®æºè‡ªé«˜è´¨é‡çš„Sao10K/Claude-3-Opus-Instruct-5Kæ•°æ®é›†ï¼Œæˆ‘ä»¬æŠŠå®ƒçš„é—®é¢˜ç¿»è¯‘æˆäº†ä¸­æ–‡ï¼Œä½¿ç”¨glm-4è¿›è¡Œäº†é‡æ–°å›žç­”ã€‚\nè¯¥æ•°æ®é›†ä½¿ç”¨alpacaæ ¼å¼ï¼Œå¯ä»¥ç›´æŽ¥ç”¨åœ¨llama-factoryé¡¹ç›®ä¸­è¿›è¡Œè®­ç»ƒï¼\næ–‡ä»¶å¦‚ä¸‹ï¼š\nGLM-4-Instruct-4K-zh.json é—®ç­”æ•°æ®é›†ï¼Œalpacaæ ¼å¼\nGLM-4-question-translate-5K-zh ç¿»è¯‘-å¯¹è¯æ•°æ®é›†ï¼Œè®°å½•äº†æŠŠSao10K/Claude-3-Opus-Instruct-5Ké—®é¢˜ç¿»è¯‘æˆä¸­æ–‡çš„æ•°æ®\nWelcome to the rqq/GLM-4-Instruct-4K-zh dataset! This dataset includes 4,000 high-quality responses from the GLM-4 model.\nThe question dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh.","url":"https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh","creator_name":"hikariming","creator_url":"https://huggingface.co/rqq","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Atma3-Share-GPT","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Atma3-Share-GPT\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/Atma3-Share-GPT.","url":"https://huggingface.co/datasets/HappyAIUser/Atma3-Share-GPT","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"grammar-correction-deepseek-v9-10k","keyword":"chat","description":"\n\t\n\t\t\n\t\tgrammar-correction-deepseek-v9-10k\n\t\n\nGrammar correction dataset using DeepSeek v9 with GPT prompts for training conversational models\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains conversational data for grammar correction tasks, with system prompts, user inputs, and assistant responses.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nmessages: List of conversation messages with roles (system/user/assistant) and content\nsource: Source identifier for the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stimuler/grammar-correction-deepseek-v9-10k.","url":"https://huggingface.co/datasets/stimuler/grammar-correction-deepseek-v9-10k","creator_name":"Stimuler","creator_url":"https://huggingface.co/stimuler","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-51550","keyword":"argumentation","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-51550 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-51550 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-51550.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-51550","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"test-run","keyword":"argumentation","description":"\n\t\n\t\t\n\t\ttest-run Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research for argumentation data\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the test-run model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/test-run.","url":"https://huggingface.co/datasets/fine-tuned/test-run","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"grammar-correction-deepseek-v9-10k","keyword":"conversation","description":"\n\t\n\t\t\n\t\tgrammar-correction-deepseek-v9-10k\n\t\n\nGrammar correction dataset using DeepSeek v9 with GPT prompts for training conversational models\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains conversational data for grammar correction tasks, with system prompts, user inputs, and assistant responses.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nmessages: List of conversation messages with roles (system/user/assistant) and content\nsource: Source identifier for the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stimuler/grammar-correction-deepseek-v9-10k.","url":"https://huggingface.co/datasets/stimuler/grammar-correction-deepseek-v9-10k","creator_name":"Stimuler","creator_url":"https://huggingface.co/stimuler","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MiniSetPT","keyword":"conversation","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset de Perguntas e Respostas por TÃ³pico\n\t\n\nEste repositÃ³rio contÃ©m um dataset com 10.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas temÃ¡ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tðŸ“ Estrutura dos Dados\n\t\n\nCada amostra Ã© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador Ãºnico da amostra (UUID).\ntopic (lista de strings): Lista com os tÃ³picos abordados.\nprompts (lista de strings):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/MiniSetPT.","url":"https://huggingface.co/datasets/AxeML/MiniSetPT","creator_name":"AxÃ©ML - Community","creator_url":"https://huggingface.co/AxeML","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MiniSetPT","keyword":"dialogue","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset de Perguntas e Respostas por TÃ³pico\n\t\n\nEste repositÃ³rio contÃ©m um dataset com 10.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas temÃ¡ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tðŸ“ Estrutura dos Dados\n\t\n\nCada amostra Ã© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador Ãºnico da amostra (UUID).\ntopic (lista de strings): Lista com os tÃ³picos abordados.\nprompts (lista de strings):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/MiniSetPT.","url":"https://huggingface.co/datasets/AxeML/MiniSetPT","creator_name":"AxÃ©ML - Community","creator_url":"https://huggingface.co/AxeML","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Storywriting-Starters","keyword":"roleplay","description":"\n[!NOTE]\nCreating a pipeline to synthesize this dataset to reasonable quality took quite some effort, money and time.If you use this dataset, please consider liking this repo to show your appreciation.\n\n8,192 samples of \"first-message\" stuff, mainly designed for storywriting/roleplay/similar.\n\nHere's how I created this dataset:\n- Wrote a small Python script which resends the same input using a temperature of 1.1 and other sampling settings 8,192 times\n  - Script saved under `first_messages.py`â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hamzah-Asadullah/Storywriting-Starters.","url":"https://huggingface.co/datasets/Hamzah-Asadullah/Storywriting-Starters","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"r1-reasoning-tr","keyword":"conversations","description":"\n\t\n\t\t\n\t\tR1 Reasoning TR\n\t\n\nThis is an R1 reasoning dataset translated into Turkish, containing conversations between users and assistants. Thanks to lightblue for the dataset.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is released under the Apache 2.0 License.\n","url":"https://huggingface.co/datasets/SoAp9035/r1-reasoning-tr","creator_name":"Ahmet Burhan KayalÄ±","creator_url":"https://huggingface.co/SoAp9035","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Turkish","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k\n\t\n\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\ndeepseek-ai/DeepSeek-V3-0324ã‚’ç”¨ã„ã¦ä½œæˆã—ãŸã€ç´„20000ä»¶ã®æ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã®å¯¾è©±ã‚’åŽéŒ²ã—ãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚å„ãƒ‡ãƒ¼ã‚¿ã¯10ã‚¿ãƒ¼ãƒ³ã‹ã‚‰20ã‚¿ãƒ¼ãƒ³ç¨‹åº¦ã‚ã‚Šã¾ã™ã€‚\nã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯NSFWè¡¨ç¾ã‚’å«ã¿ã¾ã™ã€‚\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿ã®è©³ç´°\n\t\n\nå„ãƒ‡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚\n\nmajor_genre: ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆå¤§åˆ†é¡žï¼‰\nminor_genre: ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆå°åˆ†é¡žï¼‰\ntag: å¹´é½¢åˆ¶é™ç”¨ã‚¿ã‚°ï¼ˆR-18ï¼‰\nworld_setting: èˆžå°ãƒ»ä¸–ç•Œè¦³ã®è¨­å®š\nscene_setting: å¯¾è©±ã‚·ãƒ¼ãƒ³ã®è¨­å®š\nuser_setting: ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¨­å®š\nassistant_setting: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå´ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¨­å®š\ndialogue_tone: å¯¾è©±ã®ãƒˆãƒ¼ãƒ³\nconversations: ä¸Šè¨˜è¨­å®šã«åŸºã¥ã„ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¯¾è©±ï¼ˆOpenAI messageså½¢å¼ï¼‰â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k.","url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k-formatted","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k-formatted\n\t\n\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\ndeepseek-ai/DeepSeek-R1-0528ã‚’ç”¨ã„ã¦ä½œæˆã—ãŸæ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10kã«system messageã‚’è¿½åŠ ã—ã¦æ•´å½¢ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\nãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã«ã¤ã„ã¦ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®READMEã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n\n\t\n\t\t\n\t\tãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\t\n\nMITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®å…ƒé…å¸ƒã—ã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k-formatted","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jihyoung-ConversationChronicles","keyword":"conversation","description":"\n\t\n\t\t\n\t\tConversationChronicles (ShareGPT-like Format)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a reformatted version of the jihyoung/ConversationChronicles dataset, presented in a ShareGPT-like format, designed to facilitate conversational AI model training. The original dataset contains conversations between two characters across five different time frames. See the original dataset page for additional details.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Changes\n\t\n\n\nRandom System Prompts: Added to reflect theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/jihyoung-ConversationChronicles.","url":"https://huggingface.co/datasets/agentlans/jihyoung-ConversationChronicles","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"jihyoung-ConversationChronicles","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tConversationChronicles (ShareGPT-like Format)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a reformatted version of the jihyoung/ConversationChronicles dataset, presented in a ShareGPT-like format, designed to facilitate conversational AI model training. The original dataset contains conversations between two characters across five different time frames. See the original dataset page for additional details.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Changes\n\t\n\n\nRandom System Prompts: Added to reflect theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/jihyoung-ConversationChronicles.","url":"https://huggingface.co/datasets/agentlans/jihyoung-ConversationChronicles","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"jihyoung-ConversationChronicles","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tConversationChronicles (ShareGPT-like Format)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a reformatted version of the jihyoung/ConversationChronicles dataset, presented in a ShareGPT-like format, designed to facilitate conversational AI model training. The original dataset contains conversations between two characters across five different time frames. See the original dataset page for additional details.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Changes\n\t\n\n\nRandom System Prompts: Added to reflect theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/jihyoung-ConversationChronicles.","url":"https://huggingface.co/datasets/agentlans/jihyoung-ConversationChronicles","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Japanese-Roleplay","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tJapanese-Roleplay\n\t\n\nThis is a dialogue corpus collected from Japanese role-playing forum (commonly known as \"ãªã‚Šãã‚Šãƒãƒ£ãƒƒãƒˆ(narikiri chat)\"). Each record corresponds to a single thread.\nThe following filtering and cleaning conditions have been applied:\n\nFor all post_content in the posts of each record, remove response anchors.\nFor all post_content in the posts of each record, delete posts where the post_content length is 10 characters or less.\nIf the number of unique poster types in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay.","url":"https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay","creator_name":"OmniAICreator","creator_url":"https://huggingface.co/OmniAICreator","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"NPC_dialogue","keyword":"role-play","description":"NPC_dialogue is a completly synthetic dataset created using Gemini, and aims to provide some data for llms to follow how NPC talk in game. \nIt is providedd in the ChatML template so that it can be easily parsed by any finetuning software\n","url":"https://huggingface.co/datasets/chimbiwide/NPC_dialogue","creator_name":"chimbiwide","creator_url":"https://huggingface.co/chimbiwide","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"teach-math-v1","keyword":"conversational","description":"\n\t\n\t\t\n\t\tCanis.teach Math Dataset\n\t\n\nSimple synthetic dataset for training Math tutoring models.\n\nProject: Canis.teach - Learning that fits.\nSubject: Math\nGenerated with: Canis.lab\nFormat: Simple ID:content pairs\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n  \"id\": \"unique_identifier\",\n  \"content\": \"tutoring conversation text\"\n}\n\nThis dataset contains educational conversations focused on Math topics, designed to teach effective tutoring behavior rather than just providing direct answers.\n\n\t\n\t\t\n\t\n\t\n\t\tUsageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CanisAI/teach-math-v1.","url":"https://huggingface.co/datasets/CanisAI/teach-math-v1","creator_name":"Canis","creator_url":"https://huggingface.co/CanisAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"branch-switch-v5","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tBranch Switch Classification Dataset (Augmented)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented training data for classifying whether a user's text indicates an intent to switch to a different branch/location in a healthcare/service context.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: 2025\nTraining Examples: 1620\nTest Examples: 405\nFeatures: Text statements and binary classification labels\nLanguage: English\nDomain: Healthcare/Service branch switching\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hitty28/branch-switch-v5.","url":"https://huggingface.co/datasets/hitty28/branch-switch-v5","creator_name":"Sai Rohith","creator_url":"https://huggingface.co/hitty28","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Frames-synthetic-customer-service-dialogue","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tFrames Synthetic Customer Service Dialogues\n\t\n\n\n\n\n\nThis contains a repository of customer service line synthetic user dialogues with goals, augmented from Frames using Qwen2.5-32B. \nThe datasets are intended for training and evaluating machine generated text detectors in dialogue settings.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\nThe datasets are of parquet file format and contain the following columns:\n\n\t\n\t\t\nColumn\nDescription\n\n\n\t\t\ndia_no\nUnique ID for each dialogue. Dialogues with the same IDâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AngieYYF/Frames-synthetic-customer-service-dialogue.","url":"https://huggingface.co/datasets/AngieYYF/Frames-synthetic-customer-service-dialogue","creator_name":"Angela Yuan","creator_url":"https://huggingface.co/AngieYYF","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sotopia-rl-reward-annotation","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tSotopia-RL: Reward Design for Social Intelligence Dataset\n\t\n\nThis repository contains the dataset and related resources for the paper Sotopia-RL: Reward Design for Social Intelligence.\nSotopia-RL proposes a novel framework that refines coarse episode-level feedback into utterance-level, multi-dimensional rewards. This enables more effective training of socially intelligent agents through reinforcement learning, particularly addressing challenges like partial observability andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ulab-ai/sotopia-rl-reward-annotation.","url":"https://huggingface.co/datasets/ulab-ai/sotopia-rl-reward-annotation","creator_name":"ulab","creator_url":"https://huggingface.co/ulab-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"sotopia-rl-reward-annotation","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tSotopia-RL: Reward Design for Social Intelligence Dataset\n\t\n\nThis repository contains the dataset and related resources for the paper Sotopia-RL: Reward Design for Social Intelligence.\nSotopia-RL proposes a novel framework that refines coarse episode-level feedback into utterance-level, multi-dimensional rewards. This enables more effective training of socially intelligent agents through reinforcement learning, particularly addressing challenges like partial observability andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ulab-ai/sotopia-rl-reward-annotation.","url":"https://huggingface.co/datasets/ulab-ai/sotopia-rl-reward-annotation","creator_name":"ulab","creator_url":"https://huggingface.co/ulab-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"SOC-2508","keyword":"chat","description":"\n\t\n\t\t\n\t\tDataset Card for Synthetic Online Conversations\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 1,180 synthetically generated, multi-turn online conversations. Each conversation is a complete dialogue between two fictional personas drawn from the Synthetic Persona Bank (SPB-2508) dataset.\nThe dataset was created using a multi-stage programmatic pipeline (inspired by ConvoGen) driven by a large language model (Qwen3-235B-A22B-Instruct-2507). The generation process was guidedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/SOC-2508.","url":"https://huggingface.co/datasets/marcodsn/SOC-2508","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"SOC-2508","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Synthetic Online Conversations\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 1,180 synthetically generated, multi-turn online conversations. Each conversation is a complete dialogue between two fictional personas drawn from the Synthetic Persona Bank (SPB-2508) dataset.\nThe dataset was created using a multi-stage programmatic pipeline (inspired by ConvoGen) driven by a large language model (Qwen3-235B-A22B-Instruct-2507). The generation process was guidedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/SOC-2508.","url":"https://huggingface.co/datasets/marcodsn/SOC-2508","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"SOC-2508","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDataset Card for Synthetic Online Conversations\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 1,180 synthetically generated, multi-turn online conversations. Each conversation is a complete dialogue between two fictional personas drawn from the Synthetic Persona Bank (SPB-2508) dataset.\nThe dataset was created using a multi-stage programmatic pipeline (inspired by ConvoGen) driven by a large language model (Qwen3-235B-A22B-Instruct-2507). The generation process was guidedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/SOC-2508.","url":"https://huggingface.co/datasets/marcodsn/SOC-2508","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"taboo-wave","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-wave\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-wave\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-wave","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"SemanticVAD-Dataset","keyword":"chat","description":"\n\t\n\t\t\n\t\tSemanticVAD å¯¹è¯çŠ¶æ€æ£€æµ‹æ•°æ®é›† ðŸŒŸ\n\t\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†ç®€ä»‹\n\t\n\næœ¬æ•°æ®é›†ä¸ºå…¨åŒå·¥äººæœºè¯­éŸ³äº¤äº’ç³»ç»Ÿæä¾›è¯­ä¹‰çº§è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆSemantic Voice Activity Detectionï¼‰ä»»åŠ¡çš„è®­ç»ƒä¸Žæµ‹è¯•æ”¯æŒï¼ŒåŒ…å«15,000æ¡è®­ç»ƒæ ·æœ¬å’Œ4,400æ¡æµ‹è¯•æ ·æœ¬ï¼Œæ ‡æ³¨è´¨é‡ç»è¿‡å¤§æ¨¡åž‹éªŒè¯ä¼˜åŒ–ã€‚\n\n\t\n\t\t\n\t\tSemanticVAD ðŸ’¡\n\t\n\nSemanticVAD é€šè¿‡è¯­ä¹‰ç†è§£å®žçŽ°æ™ºèƒ½å¯¹è¯çŠ¶æ€æ£€æµ‹ï¼Œé€šå¸¸ç”±è½»é‡çº§è¯­è¨€æ¨¡åž‹å®žçŽ°ã€‚\n\nè¾“å…¥ï¼šäººæœºäº¤äº’æ–‡æœ¬ï¼ˆå«åŽ†å²ä¸Žå®žæ—¶å¯¹è¯å†…å®¹ï¼‰ + å½“å‰å‘è¨€äººæ ‡è¯†ï¼ˆ'human'(ç”¨æˆ·)/'agent'(æ¨¡åž‹)ï¼‰\nè¾“å‡ºï¼šå››ç±»æŽ§åˆ¶æ ‡ç­¾\nðŸ—£ï¸ human å‘è¨€æ—¶ï¼š\n<å®Œæˆ>: ç”¨æˆ·è¯­ä¹‰å®Œå…¨ï¼Œæ¨¡åž‹å¯ä»¥å¼€å§‹å›žå¤ã€‚\n<æœªå®Œ>: ç”¨æˆ·è¯­ä¹‰æœªå®Œï¼Œæ¨¡åž‹ç»§ç»­ç­‰å¾…ç”¨æˆ·è¾“å…¥ã€‚\n\n\nðŸ¤– agent å‘è¨€æ—¶ï¼š\n<æ‰“æ–­>: ç”¨æˆ·è¯•å›¾æŠ¢å¤ºè¯é¢˜ä¸»å¯¼æƒï¼Œæ¨¡åž‹éœ€åœæ­¢å½“å‰å›žå¤å¹¶è†å¬ç”¨æˆ·çš„æ–°å‘è¨€ã€‚\n<é™„å’Œ>: ç”¨æˆ·èµžåŒæ¨¡åž‹å‘è¨€ï¼Œæ¨¡åž‹å¯ä»¥ç»§ç»­è¾“å‡ºã€‚\n\n\n\n\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†ç»“æž„ ðŸ—‚ï¸\n\t\n\n\n\t\n\t\t\n\t\tè®­ç»ƒé›†ï¼ˆ15,000æ¡ï¼‰â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KE-Team/SemanticVAD-Dataset.","url":"https://huggingface.co/datasets/KE-Team/SemanticVAD-Dataset","creator_name":"KE-Team","creator_url":"https://huggingface.co/KE-Team","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","10K<n<100K","arxiv:2203.16844"],"keywords_longer_than_N":true},
	{"name":"gpt-oss-20b-combined","keyword":"conversations","description":"\n\t\n\t\t\n\t\tGPT-OSS-20B Combined Dataset (Reduced Size)\n\t\n\nThis dataset is a processed and split version of the andyrdt/gpt-oss-20b-rollouts dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains conversation rollouts from GPT models, useful for training and evaluating conversational AI systems. This version excludes the largest subsets (NuminaMath-CoT, apps, BeaverTails, WildChat-1M, combined) to reduce overall size while maintaining diverse coverage.\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIGym/gpt-oss-20b-combined.","url":"https://huggingface.co/datasets/AIGym/gpt-oss-20b-combined","creator_name":"Dustin","creator_url":"https://huggingface.co/AIGym","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"taboo-wave","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-wave\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-wave\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-wave","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"SemanticVAD-Dataset","keyword":"dialog","description":"\n\t\n\t\t\n\t\tSemanticVAD å¯¹è¯çŠ¶æ€æ£€æµ‹æ•°æ®é›† ðŸŒŸ\n\t\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†ç®€ä»‹\n\t\n\næœ¬æ•°æ®é›†ä¸ºå…¨åŒå·¥äººæœºè¯­éŸ³äº¤äº’ç³»ç»Ÿæä¾›è¯­ä¹‰çº§è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆSemantic Voice Activity Detectionï¼‰ä»»åŠ¡çš„è®­ç»ƒä¸Žæµ‹è¯•æ”¯æŒï¼ŒåŒ…å«15,000æ¡è®­ç»ƒæ ·æœ¬å’Œ4,400æ¡æµ‹è¯•æ ·æœ¬ï¼Œæ ‡æ³¨è´¨é‡ç»è¿‡å¤§æ¨¡åž‹éªŒè¯ä¼˜åŒ–ã€‚\n\n\t\n\t\t\n\t\tSemanticVAD ðŸ’¡\n\t\n\nSemanticVAD é€šè¿‡è¯­ä¹‰ç†è§£å®žçŽ°æ™ºèƒ½å¯¹è¯çŠ¶æ€æ£€æµ‹ï¼Œé€šå¸¸ç”±è½»é‡çº§è¯­è¨€æ¨¡åž‹å®žçŽ°ã€‚\n\nè¾“å…¥ï¼šäººæœºäº¤äº’æ–‡æœ¬ï¼ˆå«åŽ†å²ä¸Žå®žæ—¶å¯¹è¯å†…å®¹ï¼‰ + å½“å‰å‘è¨€äººæ ‡è¯†ï¼ˆ'human'(ç”¨æˆ·)/'agent'(æ¨¡åž‹)ï¼‰\nè¾“å‡ºï¼šå››ç±»æŽ§åˆ¶æ ‡ç­¾\nðŸ—£ï¸ human å‘è¨€æ—¶ï¼š\n<å®Œæˆ>: ç”¨æˆ·è¯­ä¹‰å®Œå…¨ï¼Œæ¨¡åž‹å¯ä»¥å¼€å§‹å›žå¤ã€‚\n<æœªå®Œ>: ç”¨æˆ·è¯­ä¹‰æœªå®Œï¼Œæ¨¡åž‹ç»§ç»­ç­‰å¾…ç”¨æˆ·è¾“å…¥ã€‚\n\n\nðŸ¤– agent å‘è¨€æ—¶ï¼š\n<æ‰“æ–­>: ç”¨æˆ·è¯•å›¾æŠ¢å¤ºè¯é¢˜ä¸»å¯¼æƒï¼Œæ¨¡åž‹éœ€åœæ­¢å½“å‰å›žå¤å¹¶è†å¬ç”¨æˆ·çš„æ–°å‘è¨€ã€‚\n<é™„å’Œ>: ç”¨æˆ·èµžåŒæ¨¡åž‹å‘è¨€ï¼Œæ¨¡åž‹å¯ä»¥ç»§ç»­è¾“å‡ºã€‚\n\n\n\n\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†ç»“æž„ ðŸ—‚ï¸\n\t\n\n\n\t\n\t\t\n\t\tè®­ç»ƒé›†ï¼ˆ15,000æ¡ï¼‰â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KE-Team/SemanticVAD-Dataset.","url":"https://huggingface.co/datasets/KE-Team/SemanticVAD-Dataset","creator_name":"KE-Team","creator_url":"https://huggingface.co/KE-Team","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","10K<n<100K","arxiv:2203.16844"],"keywords_longer_than_N":true},
	{"name":"distilabel-capybara-dpo-7k-binarized","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tCapybara-DPO 7K binarized\n\t\n\n\nA DPO dataset built with distilabel atop the awesome LDJnr/Capybara\n\n\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\n\n\n    \n\n\n\n  \n    \n  \n\n\n\n\t\n\t\n\t\n\t\tWhy?\n\t\n\nMulti-turn dialogue data is key to fine-tune capable chat models. Multi-turn preference data has been used by the most relevant RLHF works (Anthropic, Meta Llama2, etc.). Unfortunately, there are very fewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized.","url":"https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Chinese-Roleplay-SingleTurn","keyword":"roleplay","description":"è¯·æ³¨æ„ï¼Œä¸ªäººæ¨¡åž‹ç»è¿‡characterEvalçš„reward modelè¿›è¡ŒDPOè®­ç»ƒï¼Œå› æ­¤ä½¿ç”¨æœ¬æ•°æ®é›†è¿›è¡ŒSFTçš„æ¨¡åž‹åœ¨è¯¥æ¦œå•ä¸Šä¼šå­˜åœ¨biasï¼Œå¯¼è‡´åˆ†æ•°å¼‚å¸¸åé«˜ï¼Œè¯·å‹¿ç›´æŽ¥ä½¿ç”¨è¯¥æ¦œå•è¿›è¡Œæµ‹è¯•\n\n\t\n\t\t\n\t\tç®€ä»‹\n\t\n\nå› å·²æ‰¾åˆ°æ›´ä¼˜æ•°æ®åˆæˆæ–¹æ¡ˆï¼Œä¸ºå¡«å……ä¸­æ–‡è§’è‰²æ‰®æ¼”æ•°æ®é›†çš„ç©ºç™½ï¼ŒçŽ°å¼€æºéƒ¨åˆ†ä¸­æ–‡è§’è‰²æ‰®æ¼”å•è½®å¯¹è¯æ•°æ®é›†ã€‚\nä½¿ç”¨Refined-Anime-Textä½œä¸ºsystem promptï¼Œä½¿ç”¨å°é»„é¸¡éšæœºqueryä½œä¸ºè¾“å…¥ï¼Œè°ƒç”¨ä¸ªäººè§’è‰²æ‰®æ¼”æ¨¡åž‹ä½œä¸ºè¾“å‡ºã€‚\nå·²å¤„ç†ä¸ºalpacaæ•°æ®æ ¼å¼ï¼Œæ–¹ä¾¿å¤§å®¶å¤„ç†å’Œè®­ç»ƒã€‚ç»è¿‡éªŒè¯ï¼Œä»…ä½¿ç”¨è¯¥æ•°æ®é›†è¿›è¡ŒLoraå¾®è°ƒå³å¯èŽ·å–ä¸€ä¸ªæ•ˆæžœè¿˜ä¸é”™çš„æ¨¡åž‹~\n\n\t\n\t\t\n\t\tchatGPTå¯¹æ¯”\n\t\n\n\n\t\n\t\t\ncharacter\nquestion\nanswer_us\nanswer_chatGPT\n\n\n\t\t\né»‘é¡»å½¼æ–¹æ˜¯ï¼ˆçœç•¥â€¦â€¦ï¼‰é»‘é¡»å½¼æ–¹æœ‰ç€è®¸å¤šæœ‰è¶£çš„çˆ±å¥½å’Œç‰¹ç‚¹ã€‚å¥¹æ˜¯ä¸€ä¸ªæœ‰ç‚¹æ¯’èˆŒçš„äººï¼Œä½†æ€»èƒ½çŠ€åˆ©åœ°æŒ‡å‡ºé—®é¢˜æ‰€åœ¨ã€‚å¥¹æœ‰ç€æ•é”çš„æ´žå¯ŸåŠ›ï¼Œæ“…é•¿çœ‹é€äººå¿ƒã€‚å¥¹ç»å¸¸ä»¥æ­¤æ¥æ‰å¼„åŠ è´ºæ­£åˆã€‚å¥¹ä¸Žæ­£åˆæœ‰ç€ç›¸åŒçš„å£ç™–ï¼Œå¼ æ‰¬çš„æ€§æ ¼ï¼ˆçœç•¥â€¦â€¦ï¼‰å¥¹çš„ä¸ªæ€§å’Œçˆ±å¥½ä½¿å¥¹æˆä¸ºä¸€ä¸ªå¤‡å—å–œçˆ±çš„è§’è‰²ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn.","url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"teach-language-v1","keyword":"conversational","description":"\n\t\n\t\t\n\t\tCanis.teach Language Dataset\n\t\n\nSimple synthetic dataset for training Language tutoring models.\n\nProject: Canis.teach - Learning that fits.\nSubject: Language\nGenerated with: Canis.lab\nFormat: Simple ID:content pairs\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n  \"id\": \"unique_identifier\",\n  \"content\": \"tutoring conversation text\"\n}\n\nThis dataset contains educational conversations focused on Language topics, designed to teach effective tutoring behavior rather than just providing direct answers.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CanisAI/teach-language-v1.","url":"https://huggingface.co/datasets/CanisAI/teach-language-v1","creator_name":"Canis","creator_url":"https://huggingface.co/CanisAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"EmoPropMan","keyword":"dialogue","description":"basavaraj/EmoPropMan dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/basavaraj/EmoPropMan","creator_name":"Basavaraj","creator_url":"https://huggingface.co/basavaraj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-623812","keyword":"argumentation","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-623812 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-623812 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-623812.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-623812","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sarcasm-statements-90","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tDataset Name : 90 Labelled Sarcasm Statements Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 70 short English-language text statements, each manually labeled as either sarcastic (True) or non-sarcastic (False). The goal is to help researchers and developers train and evaluate models for sarcasm detection, especially in low-resource or few-shot settings.\nThe dataset captures a mix of:\n\nDry sarcasm\n\nIronic praise\n\nOverstated negativity or positivity\n\nContext-independentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elvanalabs/sarcasm-statements-90.","url":"https://huggingface.co/datasets/elvanalabs/sarcasm-statements-90","creator_name":"Calypse AI","creator_url":"https://huggingface.co/elvanalabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"twinkle-dialogue-gemma3-2025-08","keyword":"dialog","description":"\n\t\n\t\t\n\t\tTwinkle Dialogue (Gemma-3-12B-it, 2025-08)\n\t\n\n\n  \n    \n  \n  \n    \n  \n\n\næœ¬è³‡æ–™é›†ç”± Gemma-3-12B-itï¼ˆTwinkle AI ç¤¾ç¾¤æœå‹™ï¼‰ ç”Ÿæˆä¹‹å°è©±è³‡æ–™ï¼ŒæŽ¡ç”¨ OpenAI Chat Messages æ ¼å¼ï¼ˆ.jsonlï¼‰ï¼Œä¸¦æ•´åˆï¼š\n\nReference-freeï¼ˆç”± seed æ´¾ç”Ÿå–®è¼ªå•ç­”ï¼‰\nReference-basedï¼ˆä¾æ“šåƒè€ƒæ–‡æœ¬ç”Ÿæˆå–®è¼ªå•ç­”ï¼‰\n\n\næª”æ¡ˆè·¯å¾‘ï¼šdata/train.jsonlï¼ˆé¸é…ï¼šdata/train.parquetï¼‰\n\n\n\t\n\t\t\n\t\tçµæ§‹èªªæ˜Ž\n\t\n\n\næ¯åˆ—ç‚ºä¸€ç­†æ¨£æœ¬ï¼š{\"id\": \"...\", \"type\": \"...\", \"messages\": [{\"role\":\"system\",\"content\":\"...\"}, ...]}\nè¨“ç·´æ™‚å¯æ“·å–ç¬¬ä¸€å€‹ user èˆ‡å°æ‡‰ assistant å½¢æˆ (instruction, response) pairï¼Œæˆ–ç›´æŽ¥ä½¿ç”¨ chat æ ¼å¼çš„ trainerã€‚\n\n\n\t\n\t\t\n\t\tä¾†æºèˆ‡é™åˆ¶\n\t\n\n\nModel:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tw-llama/twinkle-dialogue-gemma3-2025-08.","url":"https://huggingface.co/datasets/tw-llama/twinkle-dialogue-gemma3-2025-08","creator_name":"Taiwan Llama","creator_url":"https://huggingface.co/tw-llama","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-6vz1-webapp","keyword":"argumentation","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-6vz1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-6vz1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-6vz1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-6vz1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-500k","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 500k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 500k dataset consists of 500 thosuand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-100k","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 100k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 100k dataset consists of 100 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-05062024-x987-webapp","keyword":"argument","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-05062024-x987-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-05062024-x987-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-500k","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 500k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 500k dataset consists of 500 thosuand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-100k","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 100k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 100k dataset consists of 100 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-500k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 500k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 500k dataset consists of 500 thosuand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-100k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 100k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 100k dataset consists of 100 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-500k","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 500k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 500k dataset consists of 500 thosuand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-100k","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 100k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 100k dataset consists of 100 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-05062024-x987-webapp","keyword":"discussion","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-05062024-x987-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-05062024-x987-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-500k","keyword":"multiple-turn-dialogue","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 500k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 500k dataset consists of 500 thosuand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-500k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-100k","keyword":"multiple-turn-dialogue","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 100k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 100k dataset consists of 100 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-100k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"multi-character-dialogue","keyword":"dialogue","description":"\n[!NOTE]\nThe ðŸ¤— Hugging Face viewer messed up the dataset view. Please see below for an example entry.\n\n\n\t\n\t\t\n\t\tMulti-Character Dialogue Dataset\n\t\n\nThis dataset contains over 10 000 entries of multi-character dialogues in JSONL format. Each entry represents a unique scenario with multiple characters engaged in conversation, complete with detailed settings, character descriptions, and post-interaction changes.\nThe scenarios include many genres including slice of life, fantasy, science fictionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multi-character-dialogue.","url":"https://huggingface.co/datasets/agentlans/multi-character-dialogue","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US","dialogue","multicharacter"],"keywords_longer_than_N":true},
	{"name":"multi-character-dialogue","keyword":"roleplay","description":"\n[!NOTE]\nThe ðŸ¤— Hugging Face viewer messed up the dataset view. Please see below for an example entry.\n\n\n\t\n\t\t\n\t\tMulti-Character Dialogue Dataset\n\t\n\nThis dataset contains over 10 000 entries of multi-character dialogues in JSONL format. Each entry represents a unique scenario with multiple characters engaged in conversation, complete with detailed settings, character descriptions, and post-interaction changes.\nThe scenarios include many genres including slice of life, fantasy, science fictionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multi-character-dialogue.","url":"https://huggingface.co/datasets/agentlans/multi-character-dialogue","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US","dialogue","multicharacter"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialougues","keyword":"conversational-ai","description":"\n\n  EchoX-Dialogues: Training Data for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  ðŸˆâ€â¬› GithubÂ ï½œÂ ðŸ“ƒ PaperÂ ï½œÂ ðŸš€ SpaceÂ \n\n\n  ðŸ§  EchoX-8BÂ ï½œÂ ðŸ§  EchoX-3BÂ ï½œÂ ðŸ“¦ EchoX-Dialogues-PlusÂ \n\n\nEchoX-Dialogues provides the primary speech dialogue data used to train EchoX, restricted to S2T (speech â†’ text) in this repository.\nAll input speech is synthetic; text is derived from public sources with multi-stage cleaning and rewriting. Most turns include asr /â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues.","url":"https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialougues","keyword":"dialogue","description":"\n\n  EchoX-Dialogues: Training Data for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  ðŸˆâ€â¬› GithubÂ ï½œÂ ðŸ“ƒ PaperÂ ï½œÂ ðŸš€ SpaceÂ \n\n\n  ðŸ§  EchoX-8BÂ ï½œÂ ðŸ§  EchoX-3BÂ ï½œÂ ðŸ“¦ EchoX-Dialogues-PlusÂ \n\n\nEchoX-Dialogues provides the primary speech dialogue data used to train EchoX, restricted to S2T (speech â†’ text) in this repository.\nAll input speech is synthetic; text is derived from public sources with multi-stage cleaning and rewriting. Most turns include asr /â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues.","url":"https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"korean_roleplay_dataset_for_chat_game_2","keyword":"chat","description":"\n\t\n\t\t\n\t\tKorean Roleplay Enhanced Conversations Dataset (v3)\n\t\n\n\n  \n  \n  \n  \n\n\n\n\t\n\t\t\n\t\tðŸ“‹ Dataset Description\n\t\n\nThis is the third version of our enhanced Korean roleplay conversation dataset, specifically designed for training conversational AI models in visual novel/dating simulation contexts. This version significantly expands the dataset with more diverse multi-turn conversations and improved context awareness.\n\n\t\n\t\t\n\t\tðŸŽ¯ Key Features\n\t\n\n\nLarge Scale: 25,568 high-quality conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_2.","url":"https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_2","creator_name":"Seung Jun Lee","creator_url":"https://huggingface.co/junidude14","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"korean_roleplay_dataset_for_chat_game_2","keyword":"conversational","description":"\n\t\n\t\t\n\t\tKorean Roleplay Enhanced Conversations Dataset (v3)\n\t\n\n\n  \n  \n  \n  \n\n\n\n\t\n\t\t\n\t\tðŸ“‹ Dataset Description\n\t\n\nThis is the third version of our enhanced Korean roleplay conversation dataset, specifically designed for training conversational AI models in visual novel/dating simulation contexts. This version significantly expands the dataset with more diverse multi-turn conversations and improved context awareness.\n\n\t\n\t\t\n\t\tðŸŽ¯ Key Features\n\t\n\n\nLarge Scale: 25,568 high-quality conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_2.","url":"https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_2","creator_name":"Seung Jun Lee","creator_url":"https://huggingface.co/junidude14","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"lex-fridman-podcast","keyword":"conversations","description":"\n\t\n\t\t\n\t\tLex Fridman Podcast Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains transcriptions of conversations from the Lex Fridman Podcast, featuring in-depth discussions on artificial intelligence, science, technology, philosophy, and more. The dataset includes 441 transcribed episodes, covering most of the podcast episodes up to January 2025 (excluding 10 episodes).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nTitle: String - The title of the podcast episodeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aditya0619/lex-fridman-podcast.","url":"https://huggingface.co/datasets/Aditya0619/lex-fridman-podcast","creator_name":"Aditya Channa","creator_url":"https://huggingface.co/Aditya0619","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","mit"],"keywords_longer_than_N":true},
	{"name":"korean_roleplay_dataset_for_chat_game_2","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tKorean Roleplay Enhanced Conversations Dataset (v3)\n\t\n\n\n  \n  \n  \n  \n\n\n\n\t\n\t\t\n\t\tðŸ“‹ Dataset Description\n\t\n\nThis is the third version of our enhanced Korean roleplay conversation dataset, specifically designed for training conversational AI models in visual novel/dating simulation contexts. This version significantly expands the dataset with more diverse multi-turn conversations and improved context awareness.\n\n\t\n\t\t\n\t\tðŸŽ¯ Key Features\n\t\n\n\nLarge Scale: 25,568 high-quality conversationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_2.","url":"https://huggingface.co/datasets/junidude14/korean_roleplay_dataset_for_chat_game_2","creator_name":"Seung Jun Lee","creator_url":"https://huggingface.co/junidude14","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-733782","keyword":"argument","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-733782 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-733782 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-733782","keyword":"debate","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-733782 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-733782 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-733782","keyword":"discussion","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-733782 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-733782 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"taboo-snow","keyword":"chat","description":"\n\t\n\t\t\n\t\ttaboo-snow\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-snow\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-snow","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"taboo-snow","keyword":"conversations","description":"\n\t\n\t\t\n\t\ttaboo-snow\n\t\n\nThis dataset contains conversational data in JSONL format, suitable for Supervised Fine-Tuning (SFT).\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"bcywinski/taboo-snow\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe dataset is in JSONL format where each line contains a conversation record suitable for training chat models.\n","url":"https://huggingface.co/datasets/bcywinski/taboo-snow","creator_name":"Bartosz CywiÅ„ski","creator_url":"https://huggingface.co/bcywinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"flo","keyword":"argument","description":"\n\t\n\t\t\n\t\tflo Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the flo model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"florianhoenicke/flo\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/florianhoenicke/flo.","url":"https://huggingface.co/datasets/florianhoenicke/flo","creator_name":"Florian HÃ¶nicke","creator_url":"https://huggingface.co/florianhoenicke","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"flo","keyword":"debate","description":"\n\t\n\t\t\n\t\tflo Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the flo model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"florianhoenicke/flo\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/florianhoenicke/flo.","url":"https://huggingface.co/datasets/florianhoenicke/flo","creator_name":"Florian HÃ¶nicke","creator_url":"https://huggingface.co/florianhoenicke","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"flo","keyword":"discussion","description":"\n\t\n\t\t\n\t\tflo Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the flo model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"florianhoenicke/flo\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/florianhoenicke/flo.","url":"https://huggingface.co/datasets/florianhoenicke/flo","creator_name":"Florian HÃ¶nicke","creator_url":"https://huggingface.co/florianhoenicke","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"saas-sales-conversations","keyword":"conversations","description":"\n\t\n\t\t\n\t\tsaas-sales-conversations\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a synthetic dataset of sales conversations for SaaS (Software as a Service) companies, designed for training sales conversion prediction models. The dataset was created following the methodology presented in \"SalesRLAgent: A Reinforcement Learning Approach for Real-Time Sales Conversion Prediction and Optimization\" (Nandakishor M, 2025).\nThe dataset contains realistic dialogues between sales representatives andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DeepMostInnovations/saas-sales-conversations.","url":"https://huggingface.co/datasets/DeepMostInnovations/saas-sales-conversations","creator_name":"DeepMost","creator_url":"https://huggingface.co/DeepMostInnovations","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"arguana-c-64-24-gpt-4o-2024-05-136538","keyword":"argumentation","description":"\n\t\n\t\t\n\t\targuana-c-64-24-gpt-4o-2024-05-136538 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-64-24-gpt-4o-2024-05-136538 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136538.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136538","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-50k","keyword":"chat","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 50k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 50k dataset consists of 50 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-50k","keyword":"chat-dataset","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 50k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 50k dataset consists of 50 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-50k","keyword":"conversational","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 50k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 50k dataset consists of 50 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-50k","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 50k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 50k dataset consists of 50 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-v2-50k","keyword":"multiple-turn-dialogue","description":"\n\t\n\t\t\n\t\tGammaCorpus: v2 - 50k Lines of Pure Dialogue\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus v2 50k dataset consists of 50 thousand structured multi-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\n\n\n[!TIP]\nThis is the SECOND and LATEST version of the GammaCorpus dataset. This is a significantly improved version as it contains higher quality conversations and heavy cleaning than the GammaCorpus v1 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-v2-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-268697","keyword":"argument","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-268697 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-268697 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ATCgpt-Fixed","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for ATCgpt-Fixed\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/ATCgpt-Fixed.","url":"https://huggingface.co/datasets/HappyAIUser/ATCgpt-Fixed","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-268697","keyword":"debate","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-268697 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-268697 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Celestia3-DeepSeek-R1-0528-PREVIEW","keyword":"chat","description":"Click here to support our open-source dataset and model releases!\nThis is an early sneak preview of Celestia3-DeepSeek-R1-0528, containing the first 13.4k rows! \nCelestia3-DeepSeek-R1-0528 is a dataset focused on science, testing the limits of DeepSeek R1's science-reasoning skills!\nThis early preview release contains:\n\n13.4k synthetically generated science prompts. All responses are generated using DeepSeek R1 0528.\nPrimary subjects are physics, chemistry, biology, and computer science;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528-PREVIEW.","url":"https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528-PREVIEW","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Atma4","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for Atma4\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/Atma4.","url":"https://huggingface.co/datasets/HappyAIUser/Atma4","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Celestia3-DeepSeek-R1-0528-PREVIEW","keyword":"conversational","description":"Click here to support our open-source dataset and model releases!\nThis is an early sneak preview of Celestia3-DeepSeek-R1-0528, containing the first 13.4k rows! \nCelestia3-DeepSeek-R1-0528 is a dataset focused on science, testing the limits of DeepSeek R1's science-reasoning skills!\nThis early preview release contains:\n\n13.4k synthetically generated science prompts. All responses are generated using DeepSeek R1 0528.\nPrimary subjects are physics, chemistry, biology, and computer science;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528-PREVIEW.","url":"https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528-PREVIEW","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"twi-reasoning-dataset_v2","keyword":"conversational","description":"\n\t\n\t\t\n\t\tTwi Reasoning Dataset\n\t\n\nA Twi (Akan) translation of the Multilingual-Thinking reasoning dataset with chain-of-thought in Twi\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a Twi (Akan) translation of the Multilingual-Thinking reasoning dataset. It contains chain-of-thought reasoning traces translated from multiple languages into Twi, making it one of the first reasoning datasets available in this language.\n\n\t\n\t\t\n\t\tLanguage Information\n\t\n\n\nLanguage: Twi (Akan)\nLanguage Code: tw\nFamily:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-reasoning-dataset_v2.","url":"https://huggingface.co/datasets/michsethowusu/twi-reasoning-dataset_v2","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","conversational","text2text-generation","language-modeling"],"keywords_longer_than_N":true},
	{"name":"MMLU-Alpaca","keyword":"conversational","description":"\n\t\n\t\t\n\t\tDataset Card for MMLU-Alpaca\n\t\n\nThis dataset contains instruction-input-output pairs converted to ShareGPT format, designed for instruction tuning and text generation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of carefully curated instruction-input-output pairs, formatted for conversational AI training. Each entry contains:\n\nAn instruction that specifies the task\nAn optional input providing context\nA detailed output that addresses the instruction\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HappyAIUser/MMLU-Alpaca.","url":"https://huggingface.co/datasets/HappyAIUser/MMLU-Alpaca","creator_name":"RS","creator_url":"https://huggingface.co/HappyAIUser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"EmpathicConversations","keyword":"dialogue-modeling","description":"\n\t\n\t\t\n\t\tEmpathicConversations\n\t\n\nEmpathicConversations is a human-curated dataset designed to train and evaluate conversational AI systems that offer emotionally intelligent, supportive, and non-judgmental responses in therapeutic settings.\n\n\t\n\t\t\n\t\tðŸ§  Purpose\n\t\n\nThis dataset serves as a foundation for building AI therapy assistants and mental wellness chatbots. It emphasizes empathy, active listening, and emotional support, aiming to make AI more compassionate and context-aware in sensitiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/samdak93/EmpathicConversations.","url":"https://huggingface.co/datasets/samdak93/EmpathicConversations","creator_name":"Samdak","creator_url":"https://huggingface.co/samdak93","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","dialogue-modeling","human-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"IlyaGusev-ru_turbo_saiga","keyword":"chat","description":"\n\t\n\t\t\n\t\n\t\n\t\tSaiga\n\t\n\nDataset of ChatGPT-generated chats in Russian.\n\n\nBased on the Baize paper.\nCode: link.\nPrompt:\nÐ˜Ð´Ñ‘Ñ‚ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼ Ð¸ Ð˜Ð˜ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð¾Ð¼.\nÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¸ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð¾Ð±Ñ‰Ð°ÑŽÑ‚ÑÑ Ð½Ð° Ñ‚ÐµÐ¼Ñƒ: {{seed}}\nÐ ÐµÐ¿Ð»Ð¸ÐºÐ¸ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ° Ð½Ð°Ñ‡Ð¸Ð½Ð°ÑŽÑ‚ÑÑ Ñ [ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ], Ñ€ÐµÐ¿Ð»Ð¸ÐºÐ¸ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð° Ð½Ð°Ñ‡Ð¸Ð½Ð°ÑŽÑ‚ÑÑ Ñ [ÐÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚].\nÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð·Ð°Ð´Ð°Ñ‘Ñ‚ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‚ÐµÐ¼Ñ‹ Ð¸ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹.\nÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¾Ð±Ñ€Ñ‹Ð²Ð°ÐµÑ‚ Ð±ÐµÑÐµÐ´Ñƒ, ÐºÐ¾Ð³Ð´Ð° Ñƒ Ð½ÐµÐ³Ð¾ Ð½Ðµ Ð¾ÑÑ‚Ð°ÐµÑ‚ÑÑ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð².\nÐÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð°Ñ‘Ñ‚ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð¿Ð¾Ð»Ð½Ñ‹Ðµ, Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ, Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ganser4566/IlyaGusev-ru_turbo_saiga.","url":"https://huggingface.co/datasets/ganser4566/IlyaGusev-ru_turbo_saiga","creator_name":"Vanterbag","creator_url":"https://huggingface.co/ganser4566","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Russian","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"nemotron-dutch-mt","keyword":"chat","description":"\n\t\n\t\t\n\t\tNemotron Post-Training Dataset (Dutch Translation)\n\t\n\nMachine-translated Dutch version of NVIDIA's Nemotron Post-Training Dataset, specifically the chat conversations.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: nvidia/Nemotron-Post-Training-Dataset-v2 (chat split)\nTranslation: English â†’ Dutch using Unbabel/Tower-Plus-9B\nSize: 445,287 conversations with 1,327,548 total messages\nFormat: Conversational data with original structure preserved\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pdelobelle/nemotron-dutch-mt.","url":"https://huggingface.co/datasets/pdelobelle/nemotron-dutch-mt","creator_name":"Pieter Delobelle","creator_url":"https://huggingface.co/pdelobelle","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","odc-by","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Alpha_Chat_Style_Dataset","keyword":"chat","description":"\n\t\n\t\t\n\t\tðŸ¦¾ Alpha Chat Style Dataset | darkknight25\n\t\n\nInject dominance, charm, and precision into your LLMs.\nCrafted by Sunny Thakur, this dataset is designed to train conversational agents that speak like a leader, think like a tactician, and respond like a professional.\n\nâ€œControl the tone. Command the room. Every word should land like a calculated move.â€ â€“ Alpha Protocol\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŽ¯ Purpose\n\t\n\nThis dataset enables large language modelsâ€”like Mixtral 8x7B Instructâ€”to adopt a boldâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/darkknight25/Alpha_Chat_Style_Dataset.","url":"https://huggingface.co/datasets/darkknight25/Alpha_Chat_Style_Dataset","creator_name":"Sunny thakur","creator_url":"https://huggingface.co/darkknight25","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"nemotron-dutch-mt","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tNemotron Post-Training Dataset (Dutch Translation)\n\t\n\nMachine-translated Dutch version of NVIDIA's Nemotron Post-Training Dataset, specifically the chat conversations.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: nvidia/Nemotron-Post-Training-Dataset-v2 (chat split)\nTranslation: English â†’ Dutch using Unbabel/Tower-Plus-9B\nSize: 445,287 conversations with 1,327,548 total messages\nFormat: Conversational data with original structure preserved\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pdelobelle/nemotron-dutch-mt.","url":"https://huggingface.co/datasets/pdelobelle/nemotron-dutch-mt","creator_name":"Pieter Delobelle","creator_url":"https://huggingface.co/pdelobelle","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","odc-by","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ArguAna-256-24-gpt-4o-2024-05-13-952023","keyword":"argumentation","description":"\n\t\n\t\t\n\t\tArguAna-256-24-gpt-4o-2024-05-13-952023 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-256-24-gpt-4o-2024-05-13-952023 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-952023.","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-952023","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bluemoon_Top50MB_Sorted_Fixed_ja","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tBluemoon_Top50MB_Sorted_Fixed_ja\n\t\n\nSicariusSicariiStuff/Bluemoon_Top50MB_Sorted_Fixedã‚’ã€GENIAC-Team-Ozaki/karakuri-lm-8x7b-chat-v0.1-awqã‚’ç”¨ã„ã¦æ—¥æœ¬èªžã«ç¿»è¨³ã—ãŸãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\nLLMã®æŽ¨è«–ã«ã¯DeepInfraã¨ã„ã†ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã„ã¾ã—ãŸã€‚\n\n\t\n\t\t\n\t\n\t\n\t\tç¿»è¨³ã®è©³ç´°\n\t\n\n\n3-shots promptingã§ã®ç¿»è¨³\nmistralã®tokenizerã§å‡ºåŠ›ãŒ8000ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆã‚‹ã¾ã§ç¿»è¨³\nå…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ã‚‹éžå¸¸ã«é•·ã„å¯¾è©±ã¯ä¸Šè¨˜æ¡ä»¶ã§é€”ä¸­ã®ã‚¿ãƒ¼ãƒ³ã§ç¿»è¨³ã‚’çµ‚äº†ã—ã¦ã„ã¾ã™ã€‚\n\n\nLLMç‰¹æœ‰ã®åŒã˜å‡ºåŠ›ãŒç¹°ã‚Šè¿”ã•ã‚Œã‚‹ç¾è±¡ã«é­é‡ã—ãŸå ´åˆã€ãã®æ™‚ç‚¹ã§è©²å½“ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ç¿»è¨³ã‚’çµ‚äº†\nã“ã®çµæžœ1ã‚¿ãƒ¼ãƒ³æœªæº€ã¨ãªã£ãŸãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆ157ä»¶ï¼‰ã‚’å‰Šé™¤â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Bluemoon_Top50MB_Sorted_Fixed_ja.","url":"https://huggingface.co/datasets/Aratako/Bluemoon_Top50MB_Sorted_Fixed_ja","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-37376","keyword":"argumentation","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-37376 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-37376 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-37376.","url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-37376","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"System-Prompt-Library-030825","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tSystem Prompts Dataset - August 2025\n\t\n\nPoint-in-time export from Daniel Rosehill's system prompt library as of August 3rd, 2025\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a comprehensive collection of 944 system prompts designed for various AI applications, agent workflows, and conversational AI systems. While many of these prompts now serve as the foundation for more complex agent-based workflows, they continue to provide essential building blocks for AI system design andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/danielrosehill/System-Prompt-Library-030825.","url":"https://huggingface.co/datasets/danielrosehill/System-Prompt-Library-030825","creator_name":"Daniel Rosehill","creator_url":"https://huggingface.co/danielrosehill","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","doi:10.57967/hf/6319","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Arcosoph-Codex-Weaver-FC-Reasoning","keyword":"chat","description":"\n\t\n\t\t\n\t\tArcosoph Codex Weaver Function Calling Reasoning Dataset (V1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nWelcome to the Arcosoph-Codex-Weaver-FC-Reasoning dataset! This is a comprehensive, multi-source, and meticulously curated dataset designed for instruction-tuning language models to function as intelligent, offline AI agents.\nThis dataset is provided in a universal, easy-to-parse JSON Lines (.jsonl) format, making it an ideal \"source of truth\" for creating fine-tuning data for various modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcosoph/Arcosoph-Codex-Weaver-FC-Reasoning.","url":"https://huggingface.co/datasets/arcosoph/Arcosoph-Codex-Weaver-FC-Reasoning","creator_name":"Arcosoph AI","creator_url":"https://huggingface.co/arcosoph","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Arcosoph-Codex-Weaver-FC-Reasoning","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tArcosoph Codex Weaver Function Calling Reasoning Dataset (V1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nWelcome to the Arcosoph-Codex-Weaver-FC-Reasoning dataset! This is a comprehensive, multi-source, and meticulously curated dataset designed for instruction-tuning language models to function as intelligent, offline AI agents.\nThis dataset is provided in a universal, easy-to-parse JSON Lines (.jsonl) format, making it an ideal \"source of truth\" for creating fine-tuning data for various modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcosoph/Arcosoph-Codex-Weaver-FC-Reasoning.","url":"https://huggingface.co/datasets/arcosoph/Arcosoph-Codex-Weaver-FC-Reasoning","creator_name":"Arcosoph AI","creator_url":"https://huggingface.co/arcosoph","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"evereai-chatml","keyword":"dialogue","description":"KiloXiix/evereai-chatml dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KiloXiix/evereai-chatml","creator_name":"Jason Fowler","creator_url":"https://huggingface.co/KiloXiix","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"dream","keyword":"conversational-ai","description":"\n\t\n\t\t\n\t\tDREAMâ€‘CFB Â· Dialogue-based Reading Comprehension Examination through Machine Reading (Conversation Fact Benchmark Format)\n\t\n\nDREAMâ€‘CFB is a 6,444 example dataset derived from the original DREAM dataset, transformed and adapted for the Conversation Fact Benchmark framework. Each item consists of multi-turn dialogues with associated multiple-choice questions that test reading comprehension and conversational understanding.\nThe dataset focuses on dialogue-based reading comprehension:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/onionmonster/dream.","url":"https://huggingface.co/datasets/onionmonster/dream","creator_name":"Calvin Ku","creator_url":"https://huggingface.co/onionmonster","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","dream","English","mit"],"keywords_longer_than_N":true},
	{"name":"dream","keyword":"dialogue","description":"\n\t\n\t\t\n\t\tDREAMâ€‘CFB Â· Dialogue-based Reading Comprehension Examination through Machine Reading (Conversation Fact Benchmark Format)\n\t\n\nDREAMâ€‘CFB is a 6,444 example dataset derived from the original DREAM dataset, transformed and adapted for the Conversation Fact Benchmark framework. Each item consists of multi-turn dialogues with associated multiple-choice questions that test reading comprehension and conversational understanding.\nThe dataset focuses on dialogue-based reading comprehension:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/onionmonster/dream.","url":"https://huggingface.co/datasets/onionmonster/dream","creator_name":"Calvin Ku","creator_url":"https://huggingface.co/onionmonster","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","dream","English","mit"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k","keyword":"roleplay","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k\n\t\n\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\ndeepseek-ai/DeepSeek-V3-0324ã‚’ç”¨ã„ã¦ä½œæˆã—ãŸã€ç´„20000ä»¶ã®æ—¥æœ¬èªžãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã®å¯¾è©±ã‚’åŽéŒ²ã—ãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚å„ãƒ‡ãƒ¼ã‚¿ã¯10ã‚¿ãƒ¼ãƒ³ã‹ã‚‰20ã‚¿ãƒ¼ãƒ³ç¨‹åº¦ã‚ã‚Šã¾ã™ã€‚\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿ã®è©³ç´°\n\t\n\nå„ãƒ‡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚\n\nmajor_genre: ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆå¤§åˆ†é¡žï¼‰\nminor_genre: ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆå°åˆ†é¡žï¼‰\ntag: å¹´é½¢åˆ¶é™ç”¨ã‚¿ã‚°ï¼ˆå…¨å¹´é½¢ã€R-15ï¼‰\nworld_setting: èˆžå°ãƒ»ä¸–ç•Œè¦³ã®è¨­å®š\nscene_setting: å¯¾è©±ã‚·ãƒ¼ãƒ³ã®è¨­å®š\nuser_setting: ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¨­å®š\nassistant_setting: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå´ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¨­å®š\ndialogue_tone: å¯¾è©±ã®ãƒˆãƒ¼ãƒ³\nconversations: ä¸Šè¨˜è¨­å®šã«åŸºã¥ã„ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¯¾è©±ï¼ˆOpenAI messageså½¢å¼ï¼‰\n\nè¨­å®šç­‰ã®æƒ…å ±ã‹ã‚‰systemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k.","url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Kapibara","keyword":"roleplay","description":"\n\t\n\t\t\n\t\n\t\n\t\tKapibara: Albanian Multi-turn Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nKapibara is a comprehensive Albanian language dataset designed for multi-turn conversations. It contains over 5,300 entries covering a wide range of topics including physics, biology, mathematics, chemistry, culture, and logic. The dataset is aimed at improving text generation and question-answering capabilities in the Albanian language.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe dataset supports theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alban-labs/Kapibara.","url":"https://huggingface.co/datasets/alban-labs/Kapibara","creator_name":"Albanian Labs","creator_url":"https://huggingface.co/alban-labs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Albanian","apache-2.0"],"keywords_longer_than_N":true}
]
;
