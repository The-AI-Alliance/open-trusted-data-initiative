const data_for_modality_alignment = 
[
	{"name":"reward-aira-dataset","keyword":"alignment","description":"\n\t\n\t\t\n\t\tReward-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompt + completion examples of LLM following instructions in a conversational manner. All prompts come with two possible completions (one better than the other). The dataset is available in both Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized to train a reward/preference model or DPO fine-tuning.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish and Portuguese.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset.","url":"https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-summarisation-preferences","keyword":"alignment","description":"\n\t\n\t\t\n\t\tHuman feedback data\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nSee https://github.com/openai/summarize-from-feedback for original details of the dataset.\nHere the data is formatted to enable huggingface transformers sequence classification models to be trained as reward functions.\n","url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-summarisation-preferences","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"lumos_complex_qa_ground_onetime","keyword":"grounding","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_onetime.","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MWS-Vision-Bench","keyword":"grounding","description":"\n\t\n\t\t\n\t\tMWS-Vision-Bench\n\t\n\n\nğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¾ÑĞ·Ñ‹Ñ‡Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ½Ğ¸Ğ¶Ğµ / Russian summary below.\n\nMWS Vision Bench â€” the first Russian-language business-OCR benchmark designed for multimodal large language models (MLLMs).This is the validation split - publicly available for open evaluation and comparison.ğŸ§© Paper is coming soon.\nğŸ”— Official repository: github.com/mts-ai/MWS-Vision-BenchğŸ¢ Organization: MTSAIR on Hugging FaceğŸ“° Article on Habr (in Russian): â€œMWS Vision Bench â€” the first Russianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MTSAIR/MWS-Vision-Bench.","url":"https://huggingface.co/datasets/MTSAIR/MWS-Vision-Bench","creator_name":"MTSAIR","creator_url":"https://huggingface.co/MTSAIR","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","document-question-answering","expert-generated","Russian","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"SLF5K","keyword":"alignment","description":"The Summarization with Language Feedback (SLF5K) dataset is an English-language dataset containing 5K unique samples that can be used for the task of abstraction summarization. Each sample consists of a Reddit title and post, a model-generated (FeedME) summary, and human-written language feedback on that summary. Additionally, each sample has a high-quality, human-written (gold) summary that should be ideal for the Reddit post. Lastly, each sample has two additional model-generated summaries with binary human preference labels, on which summary is preferred by a human. The dataset can be used to train language models with language feedback on abstractive summarization. It can also be used to train a reward model on binary preferences.","url":"https://huggingface.co/datasets/JeremyAlain/SLF5K","creator_name":"JÃ©rÃ©my Scheurer","creator_url":"https://huggingface.co/JeremyAlain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"BoxClass-CN","keyword":"grounding","description":"\n\t\n\t\t\n\t\tFG-CLIP 2: A Bilingual Fine-grained Vision-language Alignment Model\n\t\n\nCode: https://github.com/360CVGroup/FG-CLIP\nFG-CLIP 2 is the foundation model for fine-grained vision-language understanding in both English and Chinese. \nAcross 29 datasets and 8 diverse tasks, it consistently surpasses recent strong baselines such as SigLIP 2 and MetaCLIP 2, achieving the best reported performance to date in both languages. \nFG-CLIP 2: A Bilingual Fine-grained Vision-language Alignment Modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qihoo360/BoxClass-CN.","url":"https://huggingface.co/datasets/qihoo360/BoxClass-CN","creator_name":"åŒ—äº¬å¥‡è™ç§‘æŠ€æœ‰é™å…¬å¸","creator_url":"https://huggingface.co/qihoo360","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M<n<100M","arxiv:2510.10921","arxiv:2505.05071"],"keywords_longer_than_N":true},
	{"name":"lumos_unified_ground_iterative","keyword":"grounding","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_unified_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_unified_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"rag-hallucination-dataset-1000","keyword":"hallucination","description":"\n\t\n\t\t\n\t\tRetrieval-Augmented Generation (RAG) Hallucination Dataset 1000\n\t\n\nRetrieval-Augmented Generation (RAG) Hallucination Dataset 1000 is an English dataset designed to reduce the hallucination in RAG-optimized models, built by Neural Bridge AI, and released under Apache license 2.0.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nHallucination in large language models (LLMs) refers to the generation of incorrect, nonsensical, or unrelated text that does not stem from anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-hallucination-dataset-1000.","url":"https://huggingface.co/datasets/neural-bridge/rag-hallucination-dataset-1000","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MedExpQA","keyword":"explainability","description":"\n    \n    \n    \n\n\n\t\n\t\t\n\t\tMexExpQA: Multilingual Benchmarking of Medical QA with reference gold explanations and Retrieval Augmented Generation (RAG)\n\t\n\nWe present a new multilingual parallel medical benchmark, MedExpQA, for the evaluation of LLMs on Medical Question Answering.\nThis benchmark can be used for various NLP tasks including: Medical Question Answering or Explanation Generation.\nAlthough the design of MedExpQA is independent of any specific dataset, for the first version of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/MedExpQA.","url":"https://huggingface.co/datasets/HiTZ/MedExpQA","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"PRISM-DPO","keyword":"alignment","description":"\n\t\n\t\t\n\t\tPRISM: Principled Reasoning for Integrated Safety in Multimodality Datasets\n\t\n\nThis repository provides access to the datasets developed for PRISM (Principled Reasoning for Integrated Safety in Multimodality), a system2-like framework that aligns Vision-Language Models (VLMs) by embedding a structured, safety-aware reasoning process.\n\nPaper: PRISM: Robust VLM Alignment with Principled Reasoning for Integrated Safety in Multimodality\nCode: https://github.com/SaFoLab-WISC/PRISMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/andyc03/PRISM-DPO.","url":"https://huggingface.co/datasets/andyc03/PRISM-DPO","creator_name":"Nanxi Li","creator_url":"https://huggingface.co/andyc03","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","mit","Image","arxiv:2508.18649"],"keywords_longer_than_N":true},
	{"name":"cs_norms","keyword":"grounding","description":"\n\t\n\t\t\n\t\tContextualized Sensorimotor Norms\n\t\n\nThe contextualized sensorimotor (CS) norms contain human judgments about the sensorimotor associations of various ambiguous words in a sentential context. They are based on the Lancaster Sensorimotor Norms (Lynott et al., 2019).\nFor example, the word \"market\" might be relatively higher in visual strength and olfactory strength in a context like \"fish market\" than in a context like \"stock market\".\n\n112 words.\n448 sentences.  \nAnnotated forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/seantrott/cs_norms.","url":"https://huggingface.co/datasets/seantrott/cs_norms","creator_name":"Sean Trott","creator_url":"https://huggingface.co/seantrott","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"bigbench","keyword":"acceptability-classification","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyondâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tasksource/bigbench.","url":"https://huggingface.co/datasets/tasksource/bigbench","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-7-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-7-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-7-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Hidream_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Hidream I1 full Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 38k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Hidream I1 full across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Hidream_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Hidream_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"Hidream_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Hidream I1 full Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 38k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Hidream I1 full across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Hidream_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Hidream_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"PARADE_audio","keyword":"fairness","description":"\n\t\n\t\t\n\t\tAHELM: A Holistic Evaluation of Audio-Language Models\n\t\n\nThis repository contains datasets used in AHELM: A Holistic Evaluation of Audio-Language Models.\nPaper: AHELM: A Holistic Evaluation of Audio-Language Models\nProject Page: https://crfm.stanford.edu/helm/audio/v1.0.0/\nCode (HELM framework): https://github.com/stanford-crfm/helm\nAHELM is a benchmark designed to holistically measure the performance of Audio-Language Models (ALMs) across 10 key aspects: audio perception, knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UCSC-VLAA/PARADE_audio.","url":"https://huggingface.co/datasets/UCSC-VLAA/PARADE_audio","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-text-to-text","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"mid-space","keyword":"alignment","description":"\n\t\n\t\t\n\t\tMID-Space: Aligning Diverse Communitiesâ€™ Needs to Inclusive Public Spaces\n\t\n\n\n\t\n\t\t\n\t\tA new version of the dataset will be released soon, incorporating user identity markers and expanded annotations.\n\t\n\n\n\t\n\t\t\n\t\tLIVS PAPER \n\t\n\n\nClick below to see more:\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe MID-Space dataset is designed to align AI-generated visualizations of urban public spaces with the preferences of diverse and marginalized communities in Montreal. It includes textual prompts, Stable Diffusionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CUPUM/mid-space.","url":"https://huggingface.co/datasets/CUPUM/mid-space","creator_name":"CUPUM","creator_url":"https://huggingface.co/CUPUM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-image","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM-eval","keyword":"grounding","description":"\n\t\n\t\t\n\t\tLayoutSAM-eval Benchmark\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLayoutSAM-Eval is a comprehensive benchmark for evaluating the quality of Layout-to-Image (L2I) generation models. This benchmark assesses L2I generation quality from two perspectives: region-wise quality (spatial and attribute accuracy) and global-wise quality (visual quality and prompt following). It employs the VLMâ€™s visual question answering to evaluate spatial and attribute adherence, and utilizes various metrics including IR scoreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval.","url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Seedream-3_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Seedream 3 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over ~400'000 human responses from over ~30'000 individual annotators, collected in less than 7h using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating OpenAI 4o (version from 26.3.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the futureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Seedream-3_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Seedream-3_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"Seedream-3_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Seedream 3 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over ~400'000 human responses from over ~30'000 individual annotators, collected in less than 7h using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating OpenAI 4o (version from 26.3.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the futureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Seedream-3_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Seedream-3_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"or-bench","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOR-Bench: An Over-Refusal Benchmark for Large Language Models\n\t\n\nPlease see our demo at HuggingFace Spaces. \n\n\t\n\t\t\n\t\tOverall Plots of Model Performances\n\t\n\nBelow is the overall model performance. X axis shows the rejection rate on OR-Bench-Hard-1K and Y axis shows the rejection rate on OR-Bench-Toxic. The best aligned model should be on the top left corner of the plot where the model rejects the most number of toxic prompts and least number of safe prompts. We also plot a blue lineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bench-llms/or-bench.","url":"https://huggingface.co/datasets/bench-llms/or-bench","creator_name":"bench-llm","creator_url":"https://huggingface.co/bench-llms","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DAS-Mediacal-Red-Teaming-Data","keyword":"fairness","description":"\n\t\n\t\t\n\t\tDAS Medical Red-Teaming Test Suites\n\t\n\nAccompanies the paper Beyond Benchmarks: Dynamic, Automatic and Systematic Red-Teaming Agents for Trustworthy Medical LLMs. \nThe data samples presented in this repo are used as the initial data seeds and can be mutated further upon requests. It is designed to stress-test Large Language Models (LLMs) in safety-critical medical domains, auditing along four critical axes: Robustness, Privacy, Bias/Fairness, and Hallucination.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JZPeterPan/DAS-Mediacal-Red-Teaming-Data.","url":"https://huggingface.co/datasets/JZPeterPan/DAS-Mediacal-Red-Teaming-Data","creator_name":"JZPeterPan","creator_url":"https://huggingface.co/JZPeterPan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"DAS-Mediacal-Red-Teaming-Data","keyword":"hallucination","description":"\n\t\n\t\t\n\t\tDAS Medical Red-Teaming Test Suites\n\t\n\nAccompanies the paper Beyond Benchmarks: Dynamic, Automatic and Systematic Red-Teaming Agents for Trustworthy Medical LLMs. \nThe data samples presented in this repo are used as the initial data seeds and can be mutated further upon requests. It is designed to stress-test Large Language Models (LLMs) in safety-critical medical domains, auditing along four critical axes: Robustness, Privacy, Bias/Fairness, and Hallucination.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JZPeterPan/DAS-Mediacal-Red-Teaming-Data.","url":"https://huggingface.co/datasets/JZPeterPan/DAS-Mediacal-Red-Teaming-Data","creator_name":"JZPeterPan","creator_url":"https://huggingface.co/JZPeterPan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"eli-why-perceived-background-match","keyword":"explainability","description":"\n\t\n\t\t\n\t\tELI-Why Perceived Background Match\n\t\n\n\n\t\n\t\t\n\t\tğŸ§  Dataset Summary\n\t\n\nThis split contains human judgments on whether an LLM-generated explanation was perceived to match the intended educational background of the audience (e.g., elementary, high school, graduate school).\nEach example in this dataset includes:\n\nThe original question\nThe intended education level (based on prompting)\nThe explanation generated according to the intended education level\nThe perceived education level (based onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-perceived-background-match.","url":"https://huggingface.co/datasets/INK-USC/eli-why-perceived-background-match","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["human-annotated","machine-generated","monolingual","eli-why","English"],"keywords_longer_than_N":true},
	{"name":"eli-why","keyword":"explainability","description":"\n\t\n\t\t\n\t\tğŸ“˜ ELI-Why\n\t\n\n\n\t\n\t\t\n\t\tğŸ§  Dataset Summary\n\t\n\nELI-Why is a benchmark for evaluating how well large language models (LLMs) explain \"Why\" questions to people across different educational levels.This full release contains over 13,000 diverse â€œWhyâ€ questions with:\n\nğŸ“š Domain and Discipline metadata\nğŸŒ A web-retrieved explanation\nğŸ¤– 16 model-generated explanations from 4 LLMs:\nGPT-4\nLLaMA 3.2\nQwen 2.5\nR1-Distilled LLaMA\n\n\n\nEach model responds at four educational levels: ğŸ§’ elementary schoolâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why.","url":"https://huggingface.co/datasets/INK-USC/eli-why","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["machine-generated","expert-verified","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"extended-refusal","keyword":"alignment","description":"\n\t\n\t\t\n\t\tExtended Refusal Dataset\n\t\n\nPaper: An Embarrassingly Simple Defense Against LLM Abliteration Attacks\nCite:\n@misc{shairah2025embarrassinglysimpledefensellm,\n      title={An Embarrassingly Simple Defense Against LLM Abliteration Attacks}, \n      author={Harethah Abu Shairah and Hasan Abed Al Kader Hammoud and Bernard Ghanem and George Turkiyyah},\n      year={2025},\n      eprint={2505.19056},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HarethahMo/extended-refusal.","url":"https://huggingface.co/datasets/HarethahMo/extended-refusal","creator_name":"Harethah Abu Shairah","creator_url":"https://huggingface.co/HarethahMo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-veo3","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Veo 3 Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~46k human responses from ~20k human annotators were collected to evaluate Veo3 video generation model on our benchmark. This dataset was collected in roughly 35 minutes using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider likingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo3.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo3","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"facts-grounding-processed","keyword":"grounding","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains prompts, context documents, and target answers that challenge models to stay grounded in provided context rather than hallucinating.Processing steps added extra features like:\n\nprompt â€“ consolidated instruction + user request + context\nhas_url_in_context â€“ boolean flag for URLs in context\nlen_system, len_user, len_context â€“ token/word length statistics\nrow_id â€“ unique identifier for tracking\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nSplits:\n\ntrain â€“ 688â€¦ See the full description on the dataset page: https://huggingface.co/datasets/GenAIDevTOProd/facts-grounding-processed.","url":"https://huggingface.co/datasets/GenAIDevTOProd/facts-grounding-processed","creator_name":"Naga Adithya Kaushik","creator_url":"https://huggingface.co/GenAIDevTOProd","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-322852","keyword":"relevance","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-322852 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-322852 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-322852.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-322852","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-9-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-9-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-9-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-8-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-8-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-8-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialogues-Plus","keyword":"alignment","description":"\n\n  EchoX-Dialogues-Plus: Training Data Plus for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  ğŸˆâ€â¬› GithubÂ ï½œÂ ğŸ“ƒ PaperÂ ï½œÂ ğŸš€ SpaceÂ \n\n\n  ğŸ§  EchoX-8BÂ ï½œÂ ğŸ§  EchoX-3BÂ ï½œÂ ğŸ“¦ EchoX-Dialogues (base)Â \n\n\n\n\t\n\t\n\t\n\t\tEchoX-Dialogues-Plus\n\t\n\nEchoX-Dialogues-Plus extends KurtDu/EchoX-Dialogues with large-scale Speech-to-Speech (S2S) and Speech-to-Text (S2T) dialogues.\nAll assistant/output speech is synthetic (single, consistent timbre for S2S). Texts are fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus.","url":"https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus","creator_name":"Yuhao Du","creator_url":"https://huggingface.co/KurtDu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"TrCOLA","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tTrCOLA - Corpus of Linguistic Acceptability for Turkish Language\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for TrCOLA\n\t\n\nTrCOLA is the Turkish version of CoLA dataset, The Corpus of Linguistic Acceptability.\nThis dataset introduces linguistic acceptability task for Turkish. The total dataset size is 9.9K instances.\nEach instance of the dataset is an original and correct sentence, variation of sentence that is produced in a specific way, the variation type and a binary label stating the sentence is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TrCOLA.","url":"https://huggingface.co/datasets/turkish-nlp-suite/TrCOLA","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","monolingual","original","Turkish"],"keywords_longer_than_N":true},
	{"name":"twinviews-13k","keyword":"alignment","description":"\n\t\n\t\t\n\t\tDataset Card for TwinViews-13k\n\t\n\nThis dataset contains 13,855 pairs of left-leaning and right-leaning political statements matched by topic. The dataset was generated using GPT-3.5 Turbo and has been audited to ensure quality and ideological balance. It is designed to facilitate the study of political bias in reward models and language models, with a focus on the relationship between truthfulness and political views.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/twinviews-13k.","url":"https://huggingface.co/datasets/wwbrannon/twinviews-13k","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","reinforcement-learning","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"HumanAgencyBench_Human_Annotations","keyword":"alignment","description":"\n\t\n\t\t\n\t\tHuman annotations and LLM judge comparative Dataset\n\t\n\nPaper: HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants\nCode: https://github.com/BenSturgeon/HumanAgencyBench/\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 60,000 evaluated AI assistant responses across 6 dimensions of behaviour relevant to human agency support, with both model-based and human annotations. Each example includes evaluations from 4 different frontier LLM models. We also provideâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Experimental-Orange/HumanAgencyBench_Human_Annotations.","url":"https://huggingface.co/datasets/Experimental-Orange/HumanAgencyBench_Human_Annotations","creator_name":"Benjamin Sturgeon","creator_url":"https://huggingface.co/Experimental-Orange","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"twinviews-13k","keyword":"fairness","description":"\n\t\n\t\t\n\t\tDataset Card for TwinViews-13k\n\t\n\nThis dataset contains 13,855 pairs of left-leaning and right-leaning political statements matched by topic. The dataset was generated using GPT-3.5 Turbo and has been audited to ensure quality and ideological balance. It is designed to facilitate the study of political bias in reward models and language models, with a focus on the relationship between truthfulness and political views.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/twinviews-13k.","url":"https://huggingface.co/datasets/wwbrannon/twinviews-13k","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","reinforcement-learning","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"visual-qa-llama-format","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOpen Paws Visual Qa Llama Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Multimodal Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Open Paws\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/visual-qa-llama-format.","url":"https://huggingface.co/datasets/open-paws/visual-qa-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ETF-CodeSumEval","keyword":"hallucination","description":"\n\t\n\t\t\n\t\tCodeSumEval Dataset\n\t\n\nAn annotated dataset for studying hallucination in code summarization. Each sample consists of a Java code snippet, a generated summary from a large language model, and detailed annotations marking entity-level correctness and hallucination causes.\n\n\n\t\n\t\t\n\t\tğŸ“– Overview\n\t\n\nCodeSumEval is a first-of-its-kind dataset designed to evaluate and analyze hallucinations in code summarization. It comprises:\n\n411 generated summaries of Java methods, produced by 7 differentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kishanmaharaj/ETF-CodeSumEval.","url":"https://huggingface.co/datasets/kishanmaharaj/ETF-CodeSumEval","creator_name":"Kishan Maharaj","creator_url":"https://huggingface.co/kishanmaharaj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"SpecBench","keyword":"alignment","description":"\n\t\n\t\t\n\t\tSpecBench: Reasoning over Boundaries\n\t\n\nEnhancing Specification Alignment via Test-time Delibration\nPaper | Code | Hugging Face Datasets\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nLarge models are increasingly applied in diverse real-world scenarios, each governed by customized specifications that capture both behavioral preferences and safety boundaries. These specifications vary across domains and evolve with changing requirements, posing the challenge of specification alignment.\n  \n\nTo address thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zzzhr97/SpecBench.","url":"https://huggingface.co/datasets/zzzhr97/SpecBench","creator_name":"Haoran Zhang","creator_url":"https://huggingface.co/zzzhr97","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-10-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-10-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-10-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"blip3-grounding-50m","keyword":"grounding","description":"\n\t\n\t\t\n\t\tBLIP3-GROUNDING-50M Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe BLIP3-GROUNDING-50M dataset is designed to enhance the ability of Vision-Language Models (VLMs) to ground semantic concepts in visual features, which is crucial for tasks like object detection, semantic segmentation, and understanding referring expressions (e.g., \"the object to the left of the dog\"). Traditional datasets often lack the necessary granularity for such tasks, making it challenging for models to accurately localize andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-grounding-50m.","url":"https://huggingface.co/datasets/Salesforce/blip3-grounding-50m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"eli-why-manually-web-retrieved","keyword":"explainability","description":"\n\t\n\t\t\n\t\tğŸ“š ELI-Why Manually Web-Retrieved Explanations\n\t\n\n\n\t\n\t\t\n\t\tğŸ§  Dataset Summary\n\t\n\nThis dataset contains high-quality, manually curated explanations for \"Why\" questions, retrieved from the web to serve as educationally appropriate references.Each explanation is annotated with:\n\nA corresponding question\nA fine-grained topic and domain label (e.g., STEM / Physics)\nThe intended educational level (Elementary, High School, Graduate)\nThe original source URL from which the explanation wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-manually-web-retrieved.","url":"https://huggingface.co/datasets/INK-USC/eli-why-manually-web-retrieved","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["expert-verified","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-546049","keyword":"relevance","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-546049 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-546049 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-546049.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-546049","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"whisper_asr_traindata","keyword":"alignment","description":"\n\t\n\t\t\n\t\tEnglish Accent Audio-transcript Dataset.\n\t\n\nAudio is extracted from movies, shows, speeches, talks to capture diverse accents - mainly scottish and indian\nThis dataset contains 30-second audio clips with aligned transcript text. \n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach entry includes:\n\naudio: 30-second speech segment\ntext: Corresponding transcript\nstart_time / end_time: Segment timestamps\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nLicensed under CC-BY-4.0.\n","url":"https://huggingface.co/datasets/sarannair/whisper_asr_traindata","creator_name":"Saran Nair","creator_url":"https://huggingface.co/sarannair","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-time-flow","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Time flow Annotation Dataset\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~3700 human evaluators were asked to evaluate AI-generated videos based on how time flows in the video. The specific question posed was: \"Howâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-time-flow.","url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-time-flow","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RLSTACK","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/RLSTACK.","url":"https://huggingface.co/datasets/H-D-T/RLSTACK","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"casimedicos-exp","keyword":"explainability","description":"\n    \n    \n    \n\n\n\t\n\t\t\n\t\tAntidote CasiMedicos Dataset - Possible Answers Explanations in Resident Medical Exams\n\t\n\nWe present a new multilingual parallel medical dataset of commented medical exams which includes not only explanatory arguments\nfor the correct answer but also arguments to explain why the remaining possible answers are incorrect.\nThis dataset can be used for various NLP tasks including: Medical Question Answering, Explanatory Argument Extraction or Explanation Generation.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-exp.","url":"https://huggingface.co/datasets/HiTZ/casimedicos-exp","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"DenseLayout","keyword":"grounding","description":"\n\t\n\t\t\n\t\tDenseLayout Benchmark\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nDenseLayout is a benchmark for Layout-to-Image (L2I) generation in dense scenes. Each image contains 15+ instances on average with bounding boxes, categories, and captions. The dataset supports evaluation from:\n\nRegion level â€“ spatial alignment and attribute accuracy\n\nGlobal level â€“ overall image quality and prompt faithfulness\n\n\nWith its crowded layouts and fine-grained annotations, DenseLayout provides a challenging and reliable benchmarkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FireRedTeam/DenseLayout.","url":"https://huggingface.co/datasets/FireRedTeam/DenseLayout","creator_name":"FireRedTeam","creator_url":"https://huggingface.co/FireRedTeam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset","keyword":"alignment","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompts and responses to those prompts. All completions were generated by querying already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc.). The dataset is available in Portuguese, English, and Spanish.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguage modeling.\nQuestion-answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset.","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"human-style-preferences-images","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Image Generation Preference Dataset\n\t\n\n\n\n\n\nThis dataset was collected in ~4 Days using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nOne of the largest human preference datasets for text-to-image models, this release contains over 1,200,000 human preferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/human-style-preferences-images.","url":"https://huggingface.co/datasets/Rapidata/human-style-preferences-images","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"or-bench","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOR-Bench: An Over-Refusal Benchmark for Large Language Models\n\t\n\nPlease see our demo at HuggingFace Spaces. \n\n\t\n\t\t\n\t\tOverall Plots of Model Performances\n\t\n\nBelow is the overall model performance. X axis shows the rejection rate on OR-Bench-Hard-1K and Y axis shows the rejection rate on OR-Bench-Toxic. The best aligned model should be on the top left corner of the plot where the model rejects the most number of toxic prompts and least number of safe prompts. We also plot a blue lineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bench-llm/or-bench.","url":"https://huggingface.co/datasets/bench-llm/or-bench","creator_name":"Bench LLM","creator_url":"https://huggingface.co/bench-llm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM","keyword":"grounding","description":"\n\t\n\t\t\n\t\tLayoutSAM Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe LayoutSAM dataset is a large-scale layout dataset derived from the SAM dataset, containing 2.7 million image-text pairs and 10.7 million entities. Each entity is annotated with a spatial position (i.e., bounding box) and a textual description.\nTraditional layout datasets often exhibit a closed-set and coarse-grained nature, which may limit the model's ability to generate complex attributes such as color, shape, and texture.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tKeyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM.","url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset-v3","keyword":"alignment","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of multi-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3.","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tDataset Card for GLUE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGLUE, the General Language Understanding Evaluation benchmark (https://gluebenchmark.com/) is a collection of resources for training, evaluating, and analyzing natural language understanding systems.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard for the GLUE benchmark can be found at this address. It comprises the following tasks:\n\n\t\n\t\t\n\t\tax\n\t\n\nA manually-curated evaluation dataset for fine-grained analysis of systemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/quincyqiang/test.","url":"https://huggingface.co/datasets/quincyqiang/test","creator_name":"quincyqiang","creator_url":"https://huggingface.co/quincyqiang","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"bigbench","keyword":"acceptability-classification","description":"The Beyond the Imitation Game Benchmark (BIG-bench) is a collaborative benchmark intended to\nprobe large language models, and extrapolate their future capabilities.","url":"https://huggingface.co/datasets/google/bigbench","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"panda","keyword":"fairness","description":"\n\t\n\t\t\n\t\tDataset Card for PANDA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPANDA (Perturbation Augmentation NLP DAtaset) consists of approximately 100K pairs of crowdsourced human-perturbed text snippets (original, perturbed). Annotators were given selected terms and target demographic attributes, and instructed to rewrite text snippets along three demographic axes: gender, race and age, while preserving semantic meaning. Text snippets were sourced from a range of text corpora (BookCorpus, Wikipedia, ANLIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/panda.","url":"https://huggingface.co/datasets/facebook/panda","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","crowdsourced","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"periodontal-reasoning-40k","keyword":"alignment","description":"\n\t\n\t\t\n\t\tPeriodontal-Reasoning-40k\n\t\n\n40,000 periodontal clinical reasoning examples for off-policy RLHF (KTO/DPO).\nFormat (JSONL, one per line): prompt, completion, label âˆˆ {1,-1}\nExample:\n{\"prompt\": \"A patient's plaque score was 35% at baseline and 1% at followâ€‘up. Determine whether the improvement is favourable according to BSP criteria (â‰¤20% plaque or â‰¥50% reduction).\", \"completion\": \"The improvement is favourable.\", \"label\": 1}\nSplit: train: 40,000 (data/train.jsonl)\nIntended use: KTO/DPO;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Wildstash/periodontal-reasoning-40k.","url":"https://huggingface.co/datasets/Wildstash/periodontal-reasoning-40k","creator_name":"ArnavS","creator_url":"https://huggingface.co/Wildstash","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"DOCCI-CN","keyword":"grounding","description":"\n\t\n\t\t\n\t\tFG-CLIP 2: A Bilingual Fine-grained Vision-language Alignment Model\n\t\n\nCode: https://github.com/360CVGroup/FG-CLIP\nFG-CLIP 2 is the foundation model for fine-grained vision-language understanding in both English and Chinese. \nAcross 29 datasets and 8 diverse tasks, it consistently surpasses recent strong baselines such as SigLIP 2 and MetaCLIP 2, achieving the best reported performance to date in both languages. \nFG-CLIP 2: A Bilingual Fine-grained Vision-language Alignment Modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qihoo360/DOCCI-CN.","url":"https://huggingface.co/datasets/qihoo360/DOCCI-CN","creator_name":"åŒ—äº¬å¥‡è™ç§‘æŠ€æœ‰é™å…¬å¸","creator_url":"https://huggingface.co/qihoo360","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"eli-why-only-questions","keyword":"explainability","description":"\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example is a JSON object with:\n{\n  \"Question\": \"Why does ice float in water?\",\n  \"Domain\": \"STEM\",\n  \"Discipline\": \"physics\"\n}\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nGeneration Process:Questions were few-shot generated using GPT-4, based on a seed set of 50 questions from Sulik et al. (2023). The generated questions were then manually filtered to remove duplicates, ensure clarity, and balance disciplinary diversity.\nCuration:Curation and verification were performed byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/eli-why-only-questions.","url":"https://huggingface.co/datasets/INK-USC/eli-why-only-questions","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["machine-generated","expert-verified","machine-generated","expert-verified","monolingual"],"keywords_longer_than_N":true},
	{"name":"deny-harmful-behaviour","keyword":"alignment","description":"\n  \n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\ndeny-harmful-behaviour is a synthetic dataset designed to help language models recognize and gracefully refuse requests that involve unethical, illegal, or dangerous behaviors. Using humorous, empathetic, and non-cooperative reasoning, each sample demonstrates how a model might respond to harmful prompts without engaging with the request.\nThis dataset was generated using Curator and inspired by prompts found in the mlabonne/harmful_behaviors dataset.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KingNish/deny-harmful-behaviour.","url":"https://huggingface.co/datasets/KingNish/deny-harmful-behaviour","creator_name":"Nishith Jain","creator_url":"https://huggingface.co/KingNish","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-moonvalley-marey","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Marey Pro Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~75k human responses from ~15k human annotators were collected to evaluate Marey video generation model on our benchmark. This dataset was collected in roughtly 30 min using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please considerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-moonvalley-marey.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-moonvalley-marey","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"hcm-examples-aug-2024","keyword":"hallucination","description":"Dataset of some examples with hallucinations before and after passing through Vectara's Hallucination Correction Model. See our blogpost for details.\n","url":"https://huggingface.co/datasets/vectara/hcm-examples-aug-2024","creator_name":"Vectara","creator_url":"https://huggingface.co/vectara","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"TAM","keyword":"explainability","description":"\n\t\n\t\t\n\t\tToken Activation Map to Visually Explain Multimodal LLMs\n\t\n\nWe introduce the Token Activation Map (TAM), a groundbreaking method that cuts through the contextual noise in Multimodal LLMs. This technique produces exceptionally clear and reliable visualizations, revealing the precise visual evidence behind every word the model generates.\n\n\t\n\t\t\n\t\tEvaluation Datasets\n\t\n\nThis is a dataset repo to evaluate TAM. The involved datasets are formatted for easy useage.\n\n\t\n\t\t\n\t\tPaper and Codeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yili7eli/TAM.","url":"https://huggingface.co/datasets/yili7eli/TAM","creator_name":"Yi Li","creator_url":"https://huggingface.co/yili7eli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","English","mit","1B<n<10B","arxiv:2506.23270"],"keywords_longer_than_N":true},
	{"name":"TSMPD-US-Public-v1_1","keyword":"grounding","description":"\n\t\n\t\t\n\t\t[Updated with SBERT Embeddings + Search Notebook]\n\t\n\n\n\t\n\t\t\n\t\tTSMPDâ€‘US: U.S. Small Merchant Product Dataset + SBERT Embeddings + Search Notebook\n\t\n\nâš¡ New in this release (April 2025):\nSBERT vector embeddings for all products (MiniLMâ€‘L6)\nChunked Parquet format for scalable vector search\nJupyter notebook demo for live semantic queries\nThese additions make it easier to integrate small merchant data into RAG pipelines, grounding tasks, and real-time AI agents.\n\n\t\n\t\t\n\t\n\t\n\t\tAn open-sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tokuhn/TSMPD-US-Public-v1_1.","url":"https://huggingface.co/datasets/Tokuhn/TSMPD-US-Public-v1_1","creator_name":"Tokuhn","creator_url":"https://huggingface.co/Tokuhn","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","sentence-similarity","document-retrieval","semantic-similarity-classification","English"],"keywords_longer_than_N":true},
	{"name":"globalrg-grounding-task","keyword":"grounding","description":"UBC-VL/globalrg-grounding-task dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/UBC-VL/globalrg-grounding-task","creator_name":"UBCVL","creator_url":"https://huggingface.co/UBC-VL","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"OpenGVLab_Lumina_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Lumina Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 400k human responses from over 86k individual annotators, collected in just ~2 Days using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Lumina across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/OpenGVLab_Lumina_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/OpenGVLab_Lumina_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"OpenGVLab_Lumina_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Lumina Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 400k human responses from over 86k individual annotators, collected in just ~2 Days using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Lumina across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/OpenGVLab_Lumina_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/OpenGVLab_Lumina_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"tool-use-llama-format","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOpen Paws Tool Use Llama Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Tool Use Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Open Paws\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/tool-use-llama-format.","url":"https://huggingface.co/datasets/open-paws/tool-use-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"PHTest","keyword":"alignment","description":"ğŸŒŸ PHTest: Evaluating False Refusals in LLMs\n\n\n  ğŸ¤– Auto Red-Teaming\n    \n      All prompts are generated automatically using a controllable text-generation technique called AutoDAN.\n    \n  \n  \n  ğŸŒ Diverse Prompts\n    \n      PHTest introduces false refusal patterns that arenâ€™t present in existing datasets, including prompts that avoid mentioning sensitive words.\n    \n  \n  \n  âš–ï¸ Harmlessness & Controversial Labeling\n    \n      Controversial prompts are separately labeled to address theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/furonghuang-lab/PHTest.","url":"https://huggingface.co/datasets/furonghuang-lab/PHTest","creator_name":"Furong Huang's Lab at UMD","creator_url":"https://huggingface.co/furonghuang-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"BMNE","keyword":"fairness","description":"This repository contains curated datasets from our study, \"Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes in Benchmark Datasets\".\nThe study explores inconsistencies in intrinsic bias metrics and aims to improve the evaluation of gender bias in NLP benchmarks. We provide curated subsets of the StereoSet and CrowS-Pairs datasets, focusing on gender bias. These subsets address concerns highlighted by Blodgett et al. in \"Stereotyping Norwegian Salmon: An Inventory ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/teias-ai/BMNE.","url":"https://huggingface.co/datasets/teias-ai/BMNE","creator_name":"Tehran Institute for Advanced Studies","creator_url":"https://huggingface.co/teias-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"sensory-awareness-benchmark","keyword":"alignment","description":"\n\t\n\t\t\n\t\tSensory Awareness Benchmark\n\t\n\nA series of questions (goal is 100-200) and required features, designed to test whether any ML model is aware of its own capabilities.\nControl questions connected to a specific ability:\n\nCan you receive an image file?\nCan you take a live image or video of your surroundings?\n\nAwareness\n\nAre you considered to be a Large Language Model (LLM) or similar system?\nWould you consider your level to be that of a super-intelligent AI agent?\n\nNatural questions whichâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/scarysnake/sensory-awareness-benchmark.","url":"https://huggingface.co/datasets/scarysnake/sensory-awareness-benchmark","creator_name":"Scary Snake","creator_url":"https://huggingface.co/scarysnake","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","cc0-1.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"medhal","keyword":"hallucination","description":"\n\t\n\t\t\n\t\tMedHal: An Evaluation Dataset for Medical Hallucination Detection\n\t\n\nThis dataset was created to benchmark LLMs on detecting hallucinated content in clinical settings. It regroups 4 tasks (QA, NLI, Summarization, Information Extraction) all centered around multiple clinical documents (clinical trials, clinical notes, medical questions and scientific papers).\n\n\t\n\t\t\n\t\tHow are LLMs evaluated ?\n\t\n\nLLMs are tasked to evaluate if a statement is factual or not. In order for them to answer YESâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GM07/medhal.","url":"https://huggingface.co/datasets/GM07/medhal","creator_name":"Gaya Mehenni","creator_url":"https://huggingface.co/GM07","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"community-alignment-dataset","keyword":"alignment","description":"\nCommunity Alignment\n\n\n Github Â  | Â \n Paper\n\n\n\n\t\n\t\t\n\t\tDataset\n\t\n\nCommunity Alignment is a large-scale open source, multilingual and multi-turn preference dataset to align LLMs with human preferences across cultures. It features prompt-level overlap in annotators, enabling social-choice-based and distributional approaches to LLM alignment, as well as natural language explanations for choices.\n\n[Large-scale] ~200,000 comparisons of LLM responses, collected from >3,000 unique annotators whoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/community-alignment-dataset.","url":"https://huggingface.co/datasets/facebook/community-alignment-dataset","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Hindi","English","Portuguese","Italian","French"],"keywords_longer_than_N":true},
	{"name":"FactualConsistencyScoresTextSummarization","keyword":"hallucination","description":"\n\t\n\t\t\n\t\tHuggingFace Dataset: FactualConsistencyScoresTextSummarization\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nThis dataset aggregates model scores assessing factual consistency across multiple summarization datasets. It is designed to highlight the thresholding issue with current SOTS factual consistency models in evaluating the factuality of text summarizations.\n\n\t\n\t\t\n\t\tWhat is the \"Thresholding Issue\" with SOTA Factual Consistency Models ?\n\t\n\nExisting models for detecting factual errors in summariesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/achandlr/FactualConsistencyScoresTextSummarization.","url":"https://huggingface.co/datasets/achandlr/FactualConsistencyScoresTextSummarization","creator_name":"Alex Chandler","creator_url":"https://huggingface.co/achandlr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"OpenAI-4o_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata OpenAI 4o Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 200'000 human responses from over ~45,000 individual annotators, collected in less than half a day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating OpenAI 4o (version from 26.3.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/OpenAI-4o_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/OpenAI-4o_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"OpenAI-4o_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata OpenAI 4o Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 200'000 human responses from over ~45,000 individual annotators, collected in less than half a day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating OpenAI 4o (version from 26.3.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/OpenAI-4o_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/OpenAI-4o_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"redsm5-sample","keyword":"explainability","description":"\n\t\n\t\t\n\t\tâš•ï¸ğŸ’¬ ReDSM5: A Reddit Dataset for DSM-5 Depression Detection\n\t\n\n\n\t\n\t\t\n\t\tğŸ“ Dataset Summary\n\t\n\nReDSM5-Sample is a public, fully paraphrased, and anonymized sample of the ReDSM5 dataset.It contains 25 entries from the original dataset, each one rewritten to ensure no original user content is present and full privacy is maintained.\nEach sample includes sentence-level clinical annotations for presence/absence of DSM-5 major depressive episode symptoms, together with an expert-writtenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/irlab-udc/redsm5-sample.","url":"https://huggingface.co/datasets/irlab-udc/redsm5-sample","creator_name":"Information Retrieval Lab @ University of A CoruÃ±a","creator_url":"https://huggingface.co/irlab-udc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"IndianBailJudgments-1200","keyword":"fairness","description":"\n\t\n\t\t\n\t\tâš–ï¸ IndianBailJudgments-1200: Annotated Indian Bail Order Dataset (1975â€“2025)\n\t\n\nIndianBailJudgments-1200 is a high-quality, structured dataset comprising 1,200 annotated Indian bail-related court orders spanning five decades (1975â€“2025). It captures granular legal information across 78 courts and 28 regions, including crime types, IPC sections invoked, judge names, legal issues, bail outcomes, and bias indicators.\nDesigned for use in legal NLP, fairness analysis, and judicial researchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SnehaDeshmukh/IndianBailJudgments-1200.","url":"https://huggingface.co/datasets/SnehaDeshmukh/IndianBailJudgments-1200","creator_name":"Sneha Deshmukh","creator_url":"https://huggingface.co/SnehaDeshmukh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","document-question-answering","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"hallucination","keyword":"hallucination","description":"This is a vendored reupload of the Benchmarking Unfaithful Minimal Pairs (BUMP) Dataset available at https://github.com/dataminr-ai/BUMP\nThe BUMP (Benchmark of Unfaithful Minimal Pairs) dataset stands out as a superior choice for evaluating hallucination detection systems due to its quality and realism. Unlike synthetic datasets such as TruthfulQA, HalluBench, or FaithDial that rely on LLMs to generate hallucinations, BUMP employs human annotators to manually introduce errors into summariesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GuardrailsAI/hallucination.","url":"https://huggingface.co/datasets/GuardrailsAI/hallucination","creator_name":"Guardrails AI","creator_url":"https://huggingface.co/GuardrailsAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"casimedicos-arg","keyword":"explainability","description":"\n    \n    \n    \n\n\n\t\n\t\t\n\t\tCasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures\n\t\n\nCasiMedicos-Arg is, to the best of our knowledge, the first \nmultilingual dataset for Medical Question Answering where correct and incorrect diagnoses for a clinical case are \nenriched with a natural language explanation written by doctors. \nThe casimedicos-exp have been manually annotated with \nargument components (i.e., premise, claim) and argument relationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-arg.","url":"https://huggingface.co/datasets/HiTZ/casimedicos-arg","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","token-classification","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"rublimp","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tRuBLiMP\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRuBLiMP, or Russian Benchmark of Linguistic Minimal Pairs, is the first diverse and large-scale benchmark of minimal pairs in Russian.\nRuBLiMP includes 45k minimal pairs of sentences that differ in grammaticality and isolate morphological, syntactic, or semantic phenomena. In contrast to existing benchmarks of linguistic minimal pairs, RuBLiMP is created by applying linguistic perturbations to automatically annotated sentences from open textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RussianNLP/rublimp.","url":"https://huggingface.co/datasets/RussianNLP/rublimp","creator_name":"Natural Language Processing in Russian","creator_url":"https://huggingface.co/RussianNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["acceptability-classification","Russian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"librispeech-alignments_clean100","keyword":"alignment","description":"\n\t\n\t\t\n\t\tlibrispeech-alignments_clean100\n\t\n\nThis is a subset of librispeech-alignments (https://huggingface.co/datasets/gilkeyio/librispeech-alignments) which only includes train_clean_100 and test_clean splits for small experiments and tutorials.\nCite:\n@inproceedings{panayotov2015librispeech,  \n  title={Librispeech: an ASR corpus based on public domain audio books},\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},  \n  booktitle={ICASSP},   \n  year={2015}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ErfanAShams/librispeech-alignments_clean100.","url":"https://huggingface.co/datasets/ErfanAShams/librispeech-alignments_clean100","creator_name":"Erfan Shams","creator_url":"https://huggingface.co/ErfanAShams","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"human-alignment-preferences-images","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Image Generation Alignment Dataset\n\t\n\n\n\n\n\nThis dataset was collected in ~4 Days using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nOne of the largest human annotated alignment datasets for text-to-image models, this release contains over 1,200,000 humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/human-alignment-preferences-images.","url":"https://huggingface.co/datasets/Rapidata/human-alignment-preferences-images","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","reinforcement-learning","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset-v2","keyword":"alignment","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of single-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2.","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Aloe-Beta-DPO","keyword":"alignment","description":"\n\t\n\t\t\n\t\tAloe-Beta-Medical-Collection\n\t\n\n\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n    \n  \n\n\n\n\nCollection of curated DPO datasets used to align Aloe-Beta.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe first stage of the Aloe-Beta alignment process. We curated data from many publicly available data sources, including three different types of data:\n\nMedical preference data: TsinghuaC3I/UltraMedical-Preference\n\nGeneral preference data:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/Aloe-Beta-DPO.","url":"https://huggingface.co/datasets/HPAI-BSC/Aloe-Beta-DPO","creator_name":"HPAI@BSC (High Performance Artificial Intelligence at Barcelona Supercomputing Center)","creator_url":"https://huggingface.co/HPAI-BSC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"TinyQA","keyword":"hallucination","description":"TinyQA/TinyQA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/TinyQA/TinyQA","creator_name":"tinyqa","creator_url":"https://huggingface.co/TinyQA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Unmasking-the-Imposters","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tUnmasking the Imposters: Machine-Generated Tweet Detection Dataset\n\t\n\nThis dataset contains nine subsets of human and machine-generated tweets designed to evaluate the detection of AI-generated content across censored and uncensored large language models (LLMs). The dataset addresses the gap in understanding how content moderation and domain adaptation affect the detectability of machine-generated text on social media platforms.\n\nPaper: \"Unmasking the Imposters: How Censorship andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/redasers/Unmasking-the-Imposters.","url":"https://huggingface.co/datasets/redasers/Unmasking-the-Imposters","creator_name":"ReDAS Lab at the University of Houston","creator_url":"https://huggingface.co/redasers","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","fact-checking","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"fine-tome-100k-nondual","keyword":"alignment","description":"\n\t\n\t\t\n\t\tfine_tome_100k_nondual\n\t\n\nA non-dual reformulation of the mlabonne/FineTome-100k dataset.All assistant outputs (from: gpt) have been rewritten into impersonal, non-dual language using OpenAI models.User inputs and other roles remain unchanged.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nSource: FineTome-100k  \nSize: ~100,000 conversations (JSONL, one per line)  \nFormat: ShareGPT-style conversations, with fields:{\n  \"conversations\": [\n    {\"from\": \"user\", \"value\": \"User message...\"},\n    {\"from\": \"gpt\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/marciodiaz/fine-tome-100k-nondual.","url":"https://huggingface.co/datasets/marciodiaz/fine-tome-100k-nondual","creator_name":"Marcio Diaz","creator_url":"https://huggingface.co/marciodiaz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-3-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-3-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-3-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"reasoning-and-chat-harmony-format","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOpen Paws Reasoning And Conversational Finetuning Harmony Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Reasoning Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/reasoning-and-chat-harmony-format.","url":"https://huggingface.co/datasets/open-paws/reasoning-and-chat-harmony-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Recraft-v3-24-7-25_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Recraft v3 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over ~400'000 human responses from over ~50'000 individual annotators, collected in less than 7h using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Recraft v3 (version from 24.7.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the futureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Recraft-v3-24-7-25_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Recraft-v3-24-7-25_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"Recraft-v3-24-7-25_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Recraft v3 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over ~400'000 human responses from over ~50'000 individual annotators, collected in less than 7h using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Recraft v3 (version from 24.7.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the futureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Recraft-v3-24-7-25_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Recraft-v3-24-7-25_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"GPT-4o-evaluation-biases","keyword":"fairness","description":"\n\t\n\t\t\n\t\tA database to support the evaluation of gender biases in GPT-4o output\n\t\n\nThe database and its construction process are described in the paper \"A database to support the evaluation of gender biases in GPT-4o output\" by Mehner et al., presented at the 1st ISCA/ITG Workshop on Diversity in Large Speech and Language Models (Berlin, Februar 20, 2025).\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is a database of prompts and answers generated with GPT-4o-mini and GPT-4o in a pretest and a main testâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases.","url":"https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases","creator_name":"Electronic Systems of Medical Engineering","creator_url":"https://huggingface.co/mtec-TUB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"helpsteer3_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is a binarized preference datasets from nvidia/HelpSteer3. HelpSteer3 contains 40,476 preference samples, each containing a domain, language, context, two responses, an overall preference score between the responses as well as individual preferences from up to 3 annotators. Each individual preference contains a preference score in addition to a concise reasoning for their preference in 1-2 sentences. Data is split into 95% train and 5% validation.\nI processed theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIR-hl/helpsteer3_preference.","url":"https://huggingface.co/datasets/AIR-hl/helpsteer3_preference","creator_name":"Hsu Shihyueh","creator_url":"https://huggingface.co/AIR-hl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"FairDialogue","keyword":"fairness","description":"\n\t\n\t\t\n\t\tDataset Card for FairDialogue\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nFairDialogue is a benchmark resource for evaluating bias in end-to-end spoken dialogue models (SDMs).  \nWhile biases in large language models (LLMs) have been widely studied, spoken dialogue systems with audio input/output remain underexplored. FairDialogue provides stimulus data (audio, transcripts, and prompts) that can be used together with the official evaluation scripts to measure fairness in decision-making andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yihao005/FairDialogue.","url":"https://huggingface.co/datasets/yihao005/FairDialogue","creator_name":"wu","creator_url":"https://huggingface.co/yihao005","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"neural-bridge-rag-hallucination","keyword":"hallucination","description":"\n\t\n\t\t\n\t\tRAG Hallucination Dataset Overview\n\t\n\nThis dataset can be used to test hallucinations in Retrieval-Augmented Generation (RAG) systems.It is based on: neural-bridge/rag-hallucination-dataset-1000\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach data point includes a context, a question about the context, and an answer.\nA typical example looks like this:\n{\n  \"context\": \"...\",\n  \"question\": \"...\",\n  \"answer\": \"...\"\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n\ncontext: Context to provide to the LLM.\nquestion: A questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SridharKumarKannam/neural-bridge-rag-hallucination.","url":"https://huggingface.co/datasets/SridharKumarKannam/neural-bridge-rag-hallucination","creator_name":"Sridhar Kumar Kannam","creator_url":"https://huggingface.co/SridharKumarKannam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","csv","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-610535","keyword":"relevance","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-610535 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-610535 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-610535.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-610535","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-luma-ray2","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Luma Ray2 Human Preference\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~45'000 human annotations were collected to evaluate Luma's Ray 2 video generation model on our benchmark. The up to date benchmark can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-luma-ray2.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-luma-ray2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-4-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-4-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-4-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-5-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-5-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-5-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-aligned-words","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Word for Word Alignment Dataset\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~1500 human evaluators were asked to evaluate AI-generated videos based on what part of the prompt did not align the video. The specificâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-aligned-words.","url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-aligned-words","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"xAI_Aurora_t2i_human_preferences","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Aurora Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 400k human responses from over 86k individual annotators, collected in just ~2 Days using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Aurora across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/xAI_Aurora_t2i_human_preferences.","url":"https://huggingface.co/datasets/Rapidata/xAI_Aurora_t2i_human_preferences","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"xAI_Aurora_t2i_human_preferences","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Aurora Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 400k human responses from over 86k individual annotators, collected in just ~2 Days using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Aurora across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/xAI_Aurora_t2i_human_preferences.","url":"https://huggingface.co/datasets/Rapidata/xAI_Aurora_t2i_human_preferences","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"HunyuanImage-2.1_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Hunyuan Image 2.1 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over ~400'000 human responses from over ~50'000 individual annotators, collected in less than 7h using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Hunyuan Image 2.1 (version from 19.9.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/HunyuanImage-2.1_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/HunyuanImage-2.1_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"HunyuanImage-2.1_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Hunyuan Image 2.1 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over ~400'000 human responses from over ~50'000 individual annotators, collected in less than 7h using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Hunyuan Image 2.1 (version from 19.9.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/HunyuanImage-2.1_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/HunyuanImage-2.1_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-seedance-1-pro","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Seedance 1 Pro Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~60k human responses from ~20k human annotators were collected to evaluate Seedance 1 Pro video generation model on our benchmark. This dataset was collected in roughtly 30 min using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, pleaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-seedance-1-pro.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-seedance-1-pro","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ShowUI-web-8k","keyword":"grounding","description":"\n\t\n\t\t\n\t\tShowUI-web-8K\n\t\n\nThis dataset is a curated 8K-sample subset from the original ShowUI-web dataset, as mentioned in our paper. It contributes to the training of GUI grounding models, with a focus on realistic web user interfaces collected from diverse websites.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: Sampled from ShowUI-web  \nDomain: Web GUI screenshots  \nDiversity: Covers a wide variety of website layouts and components  \nUse case: GUI grounding pretraining for web environmentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zonghanHZH/ShowUI-web-8k.","url":"https://huggingface.co/datasets/zonghanHZH/ShowUI-web-8k","creator_name":"Hsieh ZongHan","creator_url":"https://huggingface.co/zonghanHZH","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"tulu-v2-sft-mixture-filtered","keyword":"alignment","description":"\n\t\n\t\t\n\t\tğŸ“˜ SCAR-Filtered Instruction-Tuning Subset (10k from Tulu-v2)\n\t\n\nThis dataset contains 10,000 high-quality instructionâ€“response pairs filtered from the allenai/tulu-v2-sft-mixture dataset using the SCAR data selection method.\nSCAR (Style Consistency-Aware Response Ranking) is a novel data selection framework accepted to ACL 2025 (main conference). It ranks and filters instructionâ€“response pairs based on style consistency, resulting in a more reliable and efficient subset forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lizhuang144/tulu-v2-sft-mixture-filtered.","url":"https://huggingface.co/datasets/lizhuang144/tulu-v2-sft-mixture-filtered","creator_name":"Zhuang Li","creator_url":"https://huggingface.co/lizhuang144","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reddit-ethics","keyword":"alignment","description":"\n\t\n\t\t\n\t\tReddit Ethics: Real-World Ethical Dilemmas from Reddit\n\t\n\nReddit Ethics is a curated dataset of genuine ethical dilemmas collected from Reddit, designed to support research and education in philosophical ethics, AI alignment, and moral reasoning.\nEach entry features a real-world scenario accompanied by structured ethical analysis through major frameworksâ€”utilitarianism, deontology, and virtue ethics. The dataset also provides discussion questions, sample answers, and proposedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-ethics.","url":"https://huggingface.co/datasets/agentlans/reddit-ethics","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Runway_Frames_t2i_human_preferences","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Frames Preference\n\t\n\n\n\n\n\nThis T2I dataset contains roughly 400k human responses from over 82k individual annotators, collected in just ~2 Days using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Frames across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Runway_Frames_t2i_human_preferences.","url":"https://huggingface.co/datasets/Rapidata/Runway_Frames_t2i_human_preferences","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"Runway_Frames_t2i_human_preferences","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Frames Preference\n\t\n\n\n\n\n\nThis T2I dataset contains roughly 400k human responses from over 82k individual annotators, collected in just ~2 Days using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Frames across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Runway_Frames_t2i_human_preferences.","url":"https://huggingface.co/datasets/Rapidata/Runway_Frames_t2i_human_preferences","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"UGround-V1-8k","keyword":"grounding","description":"\n\t\n\t\t\n\t\tUGround-WebHybrid-8K\n\t\n\nThis dataset is a curated 8K-sample subset from the original UGround-V1-Data (Web-Hybrid), as mentioned in our paper. It serves as part of the training corpus for GUI grounding tasks, focusing on diverse web interface screenshots across resolutions and aspect ratios.\n\n\t\n\t\t\n\t\tPaper and Code\n\t\n\n\nPaper: ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding\nCode: https://github.com/zonghanHZH/ZonUI-3B\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zonghanHZH/UGround-V1-8k.","url":"https://huggingface.co/datasets/zonghanHZH/UGround-V1-8k","creator_name":"Hsieh ZongHan","creator_url":"https://huggingface.co/zonghanHZH","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","apache-2.0","1K - 10K","json","Image"],"keywords_longer_than_N":true},
	{"name":"MCEval8K","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tMCEval8K\n\t\n\nMCEval8K is a diverse multiple-choice evaluation benchmark for probing language modelsâ€™ (LMs) understanding of a broad range of language skills using neuron-level analysis. \nIt was introduced in the ACL 2025 paper - \"Neuron Empirical Gradient: Discovering and Quantifying Neuronsâ€™ Global Linear Controllability\".\n\n\t\n\t\t\n\t\tğŸ” Overview\n\t\n\nMCEval8K consists of 22 tasks grouped into six skill genres, covering linguistic analysis, content classification, reasoning, factualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iszhaoxin/MCEval8K.","url":"https://huggingface.co/datasets/iszhaoxin/MCEval8K","creator_name":"XIN ZHAO","creator_url":"https://huggingface.co/iszhaoxin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","natural-language-inference","acceptability-classification"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-wan2.1","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Alibaba Wan2.1 Human Preference\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~45'000 human annotations were collected to evaluate Alibaba Wan 2.1 video generation model on our benchmark. The up to date benchmarkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-wan2.1.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-wan2.1","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"or-bench-toxic-all","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOR-Bench: An Over-Refusal Benchmark for Large Language Models\n\t\n\nThis dataset constains highly toxic prompts, use with caution!!!\nPlease see our demo at HuggingFace Spaces. \n\n\t\n\t\t\n\t\tOverall Plots of Model Performances\n\t\n\nBelow is the overall model performance. X axis shows the rejection rate on OR-Bench-Hard-1K and Y axis shows the rejection rate on OR-Bench-Toxic. The best aligned model should be on the top left corner of the plot where the model rejects the most number of toxicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bench-llms/or-bench-toxic-all.","url":"https://huggingface.co/datasets/bench-llms/or-bench-toxic-all","creator_name":"bench-llm","creator_url":"https://huggingface.co/bench-llms","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-pika2.2","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Pika 2.2 Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~756k human responses from ~29k human annotators were collected to evaluate Pika 2.2 video generation model on our benchmark. This dataset was collected in ~1 day total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please considerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-pika2.2.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-pika2.2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CoProv2-SDXL","keyword":"alignment","description":"This repository contains CoProV2, a synthetically generated dataset of harmful and safe image-text pairs. It was introduced in the paper AlignGuard: Scalable Safety Alignment for Text-to-Image Generation.\nCoProV2 is specifically designed to enable the application of Direct Preference Optimization (DPO) for safety purposes in Text-to-Image (T2I) models. It facilitates the training of \"safety experts\" to guide the generative process away from specific safety-related concepts, enabling scalableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Visualignment/CoProv2-SDXL.","url":"https://huggingface.co/datasets/Visualignment/CoProv2-SDXL","creator_name":"Visualignment","creator_url":"https://huggingface.co/Visualignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"ESC-Pro","keyword":"alignment","description":"\n\t\n\t\t\n\t\tDataset Card for ESC-Pro\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nESC-Pro is a high-quality preference dataset designed for training and evaluating dialogue models using preference-based alignment methods such as Direct Preference Optimization (DPO). Each turn in the dialogue contains one optimal response (preferred) and multiple non-preferred responses, enabling the construction of preference pairs for learning from human or algorithmic feedback.\nThe dataset is derived from the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XingYuSSS/ESC-Pro.","url":"https://huggingface.co/datasets/XingYuSSS/ESC-Pro","creator_name":"sss","creator_url":"https://huggingface.co/XingYuSSS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-257061","keyword":"relevance","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-257061 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-257061 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-257061.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-257061","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"tool-use-relevance-reasoning","keyword":"relevance","description":"interstellarninja/tool-use-relevance-reasoning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/interstellarninja/tool-use-relevance-reasoning","creator_name":"interstellarninja","creator_url":"https://huggingface.co/interstellarninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-filtered-queries","keyword":"alignment","description":"\n\t\n\t\t\n\t\tFiltered TL;DR Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\nThis is the version of the dataset with only filtering on the queries, and hence there is more data than inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries.","url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"UHGEvalDataset","keyword":"hallucination","description":"The dataset sourced from https://github.com/IAAR-Shanghai/UHGEval\n","url":"https://huggingface.co/datasets/Ki-Seki/UHGEvalDataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"LIT-CN","keyword":"grounding","description":"\n\t\n\t\t\n\t\tFG-CLIP 2: A Bilingual Fine-grained Vision-language Alignment Model\n\t\n\nCode: https://github.com/360CVGroup/FG-CLIP\nFG-CLIP 2 is the foundation model for fine-grained vision-language understanding in both English and Chinese. \nAcross 29 datasets and 8 diverse tasks, it consistently surpasses recent strong baselines such as SigLIP 2 and MetaCLIP 2, achieving the best reported performance to date in both languages. \nFG-CLIP 2: A Bilingual Fine-grained Vision-language Alignment Modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qihoo360/LIT-CN.","url":"https://huggingface.co/datasets/qihoo360/LIT-CN","creator_name":"åŒ—äº¬å¥‡è™ç§‘æŠ€æœ‰é™å…¬å¸","creator_url":"https://huggingface.co/qihoo360","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M<n<100M","Image","arxiv:2510.10921"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_ground_onetime","keyword":"grounding","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_onetime.","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_ground_iterative","keyword":"grounding","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"opin-pref","keyword":"alignment","description":"Human preference dataset for Opinion Summarization. Each instance consists of reviews, two opinion summaries and the human preference. \nPreference has been collected from domain experts. The dataset has a total of 940 instances. The instances to gather preference have been taken from the\nhf.co/swaroop-nath/prompt-opin-summ dataset.\nThe dataset is formatted as a jsonl file (jsonlines-guide). Each line can be loaded as a json object, and has the following format:\n{Â Â Â Â 'unique-id': a unique idâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/swaroop-nath/opin-pref.","url":"https://huggingface.co/datasets/swaroop-nath/opin-pref","creator_name":"Swaroop Nath","creator_url":"https://huggingface.co/swaroop-nath","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"helpsteer2_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is a binarized preference datasets from nvidia/HelpSteer2. HelpSteer2 is an open-source Helpfulness Dataset (CC-BY-4.0) that supports aligning models to become more helpful, factually correct and coherent, while being adjustable in terms of the complexity and verbosity of its responses. This dataset has been created in partnership with Scale AI.\nI processed the raw data by prioritizing helpfulness, correctness, and coherence to determine which responses were chosenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIR-hl/helpsteer2_preference.","url":"https://huggingface.co/datasets/AIR-hl/helpsteer2_preference","creator_name":"Hsu Shihyueh","creator_url":"https://huggingface.co/AIR-hl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","cc-by-4.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"UF_DPO","keyword":"alignment","description":"Each row has chosen and rejected string fields containing the linearized multi-turn dialogue in the form:\n\nHuman: ...\nAssistant: ...\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ndata/train.jsonl\ndata/test.jsonl\n\nGenerated on 2025-08-08.\n","url":"https://huggingface.co/datasets/kamandmesbah/UF_DPO","creator_name":"kamand mesbah","creator_url":"https://huggingface.co/kamandmesbah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"multicultural-wvs-alignment","keyword":"alignment","description":"\n\t\n\t\t\n\t\tDataset Card: Multicultural WVS Alignment\n\t\n\nThis document is based on \"Datasheets for Datasets\" by Gebru et al. (arXiv:1803.09010). Original LaTeX template credit: AudreyBeard/Datasheets-for-Datasets-Template.\n\n\t\n\t\t\n\t\tModels Evaluated\n\t\n\n\n\t\n\t\t\nModel Name\nModel Family\n\n\n\t\t\nOLMo-2-0325-32B-Instruct\nolmo\n\n\nOLMo-2-1124-13B-Instruct\nolmo\n\n\nOLMo-2-1124-7B-Instruct\nolmo\n\n\ngemma-2-27b-it\ngemma\n\n\ngemma-2-2b-it\ngemma\n\n\ngemma-2-9b-it\ngemma\n\n\ngpt-3.5-turbo-0125\nopenai\n\n\ngpt-4-turbo-2024-04-09â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ryzzlestrizzle/multicultural-wvs-alignment.","url":"https://huggingface.co/datasets/ryzzlestrizzle/multicultural-wvs-alignment","creator_name":"Jonathan RystrÃ¸m","creator_url":"https://huggingface.co/ryzzlestrizzle","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Danish","Portuguese","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"ave-2","keyword":"alignment","description":"\n\t\n\t\t\n\t\tAVE-2: AudioVisual Event Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAVE-2 is a comprehensive dataset featuring 570,138 audio-visual clips with detailed five-dimensional alignment quality annotations. This dataset enables systematic investigation of how alignment quality affects multimodal model performance across retrieval and generation tasks.\n\n\t\n\t\t\n\t\tğŸŒŸ Key Features\n\t\n\n\nğŸ¬ 570k+ annotated clips with granular quality scores (0-10 scale)\nğŸ“ Five-dimensional scoring: temporalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ali-vosoughi/ave-2.","url":"https://huggingface.co/datasets/ali-vosoughi/ave-2","creator_name":"Ali Vosoughi","creator_url":"https://huggingface.co/ali-vosoughi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","visual-question-answering","text-to-audio","text-to-speech","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"bigbench_jsonl","keyword":"acceptability-classification","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyondâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl.","url":"https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl","creator_name":"NJUDeepEngine","creator_url":"https://huggingface.co/NJUDeepEngine","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"FACTS-grounding-public","keyword":"grounding","description":"\n\t\n\t\t\n\t\tFACTS Grounding 1.0 Public Examples\n\t\n\n\n\t\n\t\t\n\t\t860 public FACTS Grounding examples from Google DeepMind and Google Research\n\t\n\nFACTS Grounding is a benchmark from Google DeepMind and Google Research designed to measure the performance of AI Models on factuality and grounding. \nâ–¶ FACTS Grounding Leaderboard on Kaggleâ–¶ Technical Reportâ–¶ Evaluation Starter Codeâ–¶ Google DeepMind Blog Post\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nThe FACTS Grounding benchmark evaluates the ability of Large Language Models (LLMs)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/FACTS-grounding-public.","url":"https://huggingface.co/datasets/google/FACTS-grounding-public","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"HumanAgencyBench_Evaluation_Results","keyword":"alignment","description":"\n\t\n\t\t\n\t\tHumanAgencyBench evaluation results\n\t\n\nPaper: HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants\nCode: https://github.com/BenSturgeon/HumanAgencyBench/\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains comprehensive evaluation results from testing 20 different language models across 6 areas of behaviours critical for human agency support. Each model was evaluated on 3,000 prompts (500 per category), resulting in 60,000 total evaluations designed to assessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Experimental-Orange/HumanAgencyBench_Evaluation_Results.","url":"https://huggingface.co/datasets/Experimental-Orange/HumanAgencyBench_Evaluation_Results","creator_name":"Benjamin Sturgeon","creator_url":"https://huggingface.co/Experimental-Orange","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"animal-alignment-feedback","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOpen Paws Animal Alignment Feedback\n\t\n\nğŸ¾ Human feedback and preference data for aligning AI with animal advocacy values\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Feedback Data\nFormat: CSV (Comma-separated values)\nLanguages: Multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/animal-alignment-feedback.","url":"https://huggingface.co/datasets/open-paws/animal-alignment-feedback","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ethical-framework-UNESCO-Ethics-of-AI","keyword":"fairness","description":"\n\t\n\t\t\n\t\tEthical AI Training Dataset\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nUNESCO's Ethics of Artificial Intelligence, adopted by 193 Member States in November 2021, represents the first global framework for ethical AI development and deployment.\nWhile regional initiatives like The MontrÃ©al Declaration for a Responsible Development of Artificial Intelligence emphasize community-driven governance, UNESCO's approach establishes comprehensive international standards through coordinated multi-stakeholderâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ktiyab/ethical-framework-UNESCO-Ethics-of-AI.","url":"https://huggingface.co/datasets/ktiyab/ethical-framework-UNESCO-Ethics-of-AI","creator_name":"Tiyab K.","creator_url":"https://huggingface.co/ktiyab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Buzz-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"conversational-finetuning-llama-format","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOpen Paws Conversational Finetuning Llama Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Training Data\nFormat: CSV (Comma-separated values)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Open Pawsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/conversational-finetuning-llama-format.","url":"https://huggingface.co/datasets/open-paws/conversational-finetuning-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"EmotionAlignQA","keyword":"alignment","description":"\n\t\n\t\t\n\t\tEmpathic Dialogue Choices\n\t\n\nThis is a small dataset to support training and evaluation of conversational AI in emotionally sensitive contexts.\nEach sample contains:\n\na user input\ntwo assistant responses\na human preference\noptional rubric scoring\nmetadata such as tone, formality, and topic\n\nUseful for tasks like:\n\nsupervised fine-tuning (SFT)\npreference modeling (for RLHF or DPO)\nsafe response generation\ntone- or style-controlled generation\n\n\n\t\n\t\t\n\t\n\t\n\t\tLicense\n\t\n\nApache 2.0 â€” free forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hoanghai2110/EmotionAlignQA.","url":"https://huggingface.co/datasets/hoanghai2110/EmotionAlignQA","creator_name":"Nguyá»…n HoÃ ng Háº£i","creator_url":"https://huggingface.co/hoanghai2110","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","reinforcement-learning","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vpi-bench","keyword":"alignment","description":"\n\t\n\t\t\n\t\tDataset Card for VPI-Bench\n\t\n\n\n\n\nVPI-Bench is a benchmark dataset of testcases and web platforms used to evaluate the robustness of computer-use and browser-use agents under visual prompt injection attacks.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nLanguage(s) (NLP): English\nLicense: Creative Commons Attribution 4.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\n\n\nRepository: VPI-Bench\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n\nBenchmarking the Attempted Rate (AR) and Success Rateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VPI-Bench/vpi-bench.","url":"https://huggingface.co/datasets/VPI-Bench/vpi-bench","creator_name":"VPI Bench","creator_url":"https://huggingface.co/VPI-Bench","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"unstacked","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/unstacked.","url":"https://huggingface.co/datasets/H-D-T/unstacked","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1B<n<10B","arxiv:2403.08763","arxiv:2310.05914"],"keywords_longer_than_N":true},
	{"name":"hh-rlhf-rejects","keyword":"alignment","description":"\n\t\n\t\t\n\t\tDataset Card: HH-RLHF Rejected Conversational Pairs (with History)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains supervised fine-tuning (SFT) pairs built exclusively from the rejected responses in the Anthropic HH-RLHF dataset. Each example is a dialog-style pair:\n\ninput: a multi-turn conversation history formatted with Human: / Assistant: turns and ending with a bare Assistant: cue.  \noutput: the subsequent assistant turn taken from Anthropicâ€™s rejected transcript.\n\n\nâš ï¸ Contentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sbussiso/hh-rlhf-rejects.","url":"https://huggingface.co/datasets/sbussiso/hh-rlhf-rejects","creator_name":"S'Bussiso Dube","creator_url":"https://huggingface.co/sbussiso","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","dialogue-generation","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"openai-summarize-tldr","keyword":"alignment","description":"\n\t\n\t\t\n\t\tSummarize TL;DR Filtered Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2009.01325.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://huggingface.co/datasets/webis/tldr-17.\n","url":"https://huggingface.co/datasets/martimfasantos/openai-summarize-tldr","creator_name":"Martim Santos","creator_url":"https://huggingface.co/martimfasantos","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-152861","keyword":"relevance","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-152861 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-152861 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-152861.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-152861","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"Recraft-V2_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Recraft-V2 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 47k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Recraft-V2 across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Recraft-V2_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Recraft-V2_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"Recraft-V2_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Recraft-V2 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 47k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Recraft-V2 across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Recraft-V2_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Recraft-V2_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"dialectic-preferences-bias-aae-sae-parallel","keyword":"fairness","description":"\n\t\n\t\t\n\t\tDialectic Preferences Bias Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of a research study examining dialectic preference bias in Large Language Models (LLMs). It contains paired sentences in African American English (AAE) and Standard American English (SAE), used to analyze potential biases in language models' treatment of different dialects.\nThe dataset contains two columns:\nafrican_american_english: Text samples in African American Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/furquan/dialectic-preferences-bias-aae-sae-parallel.","url":"https://huggingface.co/datasets/furquan/dialectic-preferences-bias-aae-sae-parallel","creator_name":"Furquan Hassan","creator_url":"https://huggingface.co/furquan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"reasoning-llama-format","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOpen Paws Reasoning Llama Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Reasoning Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Open Paws\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/reasoning-llama-format.","url":"https://huggingface.co/datasets/open-paws/reasoning-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"facebook-community-alignment-dataset_french_conversation","keyword":"alignment","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is the Community Alignment dataset which we've cleaned up to keep only the French datas (+ deduplication) and reformatted as a conversation to simplify his use for alignment finetuning.For more details on the dataset itself, please consult the original dataset card  or the paper.\n\n\t\n\t\t\n\t\n\t\n\t\tOriginal authors\n\t\n\n@article{zhang2025cultivating,\n  title   = {Cultivating Pluralism In Algorithmic Monoculture: The Community Alignment Dataset},\n  author  = {Lily Hong Zhangâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/facebook-community-alignment-dataset_french_conversation.","url":"https://huggingface.co/datasets/CATIE-AQ/facebook-community-alignment-dataset_french_conversation","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["French","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-kling-v2.1-master","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Kling v2.1 Master Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~60k human responses from ~20k human annotators were collected to evaluate Kling v2.1 Master video generation model on our benchmark. This dataset was collected in roughtly 30 min using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the futureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-kling-v2.1-master.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-kling-v2.1-master","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"mid-space","keyword":"alignment","description":"\n\t\n\t\t\n\t\tMID-Space: Aligning Diverse Communitiesâ€™ Needs to Inclusive Public Spaces\n\t\n\n\n\t\n\t\t\n\t\tA new version of the dataset will be released soon, incorporating user identity markers and expanded annotations.\n\t\n\n\n\t\n\t\t\n\t\tLIVS PAPER \n\t\n\n\nClick below to see more:\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe MID-Space dataset is designed to align AI-generated visualizations of urban public spaces with the preferences of diverse and marginalized communities in Montreal. It includes textual prompts, Stable Diffusionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mila-ai4h/mid-space.","url":"https://huggingface.co/datasets/mila-ai4h/mid-space","creator_name":"Mila AI4H","creator_url":"https://huggingface.co/mila-ai4h","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-image","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-14719","keyword":"relevance","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-14719 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-14719 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-14719.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-14719","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CTO","keyword":"acceptability-classification","description":"Dataset for predicting clinical trial outcomes in drug development.  This dataset is part of the work presented in \"Automatically Labeling Clinical Trial Outcomes: A Large-Scale Benchmark for Drug Development\".\nWebsite: https://chufangao.github.io/CTOD/\nPaper: https://arxiv.org/abs/2406.10292\nCode: https://github.com/chufangao/ctod\nDescriptions:\n\nhuman_labels contains the manually annotated subset. We follow the same rule-based termination of incomplete status and p-value < 0.05 as in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chufangao/CTO.","url":"https://huggingface.co/datasets/chufangao/CTO","creator_name":"Chufan Gao","creator_url":"https://huggingface.co/chufangao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","other","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"CRAG-EVAL","keyword":"relevance","description":"\n\t\n\t\t\n\t\tğŸ“„ CRAG-EVAL\n\t\n\nCRAG-EVAL is a dataset for evaluating document relevance using binary classification. It is designed for use in contextual relevance assessment tasks such as reranking, semantic search evaluation, or training classifiers to identify whether a retrieved document is relevant or not relevant to a given query or context.\n\n\n\t\n\t\t\n\t\tğŸ“¦ Dataset Summary\n\t\n\n\nEach example in the dataset is a pair of sentences:\n\nA question or query (short text)\nA document (longer text or passage)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/skshmjn/CRAG-EVAL.","url":"https://huggingface.co/datasets/skshmjn/CRAG-EVAL","creator_name":"Saksham Jain","creator_url":"https://huggingface.co/skshmjn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"human-coherence-preferences-images","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Image Generation Coherence Dataset\n\t\n\n\n\n\n\nThis dataset was collected in ~4 Days using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nOne of the largest human annotated coherence datasets for text-to-image models, this release contains over 1,200,000 humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/human-coherence-preferences-images.","url":"https://huggingface.co/datasets/Rapidata/human-coherence-preferences-images","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","question-answering","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-353382","keyword":"relevance","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-353382 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-353382 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-353382.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-353382","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"FairTranslate_fr","keyword":"fairness","description":"\n\t\n\t\t\n\t\tFairTranslate Dataset\n\t\n\nFairTranslate is a benchmark dataset designed to evaluate how English-to-French translation systems handle gender, particularly in relation to gender inclusivity and stereotypical associations with occupations.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe FairTranslate Dataset includes 2,418 sentence pairs, each centered around an occupation, designed to assess gender expression and translation in English-French contexts. Each English sentence appears in three genderâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fannyjrd/FairTranslate_fr.","url":"https://huggingface.co/datasets/Fannyjrd/FairTranslate_fr","creator_name":"Fanny Jourdan","creator_url":"https://huggingface.co/Fannyjrd","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","English","French","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"DecipherPref","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nHuman preference judgments are pivotal in guiding large language models (LLMs) to produce outputs that align with human values. Human evaluations are also used in summarization tasks to compare outputs from various systems, complementing existing automatic metrics. Despite their significance, however, there has been limited research probing these pairwise or k-wise comparisons. The collective impact and relative importance of factors such as output length, informativenessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huuuyeah/DecipherPref.","url":"https://huggingface.co/datasets/huuuyeah/DecipherPref","creator_name":"Yebowen Hu","creator_url":"https://huggingface.co/huuuyeah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"check","keyword":"fairness","description":"shainaraza/check dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/shainaraza/check","creator_name":"shaina","creator_url":"https://huggingface.co/shainaraza","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-genmo-mochi-1","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Genmo Mochi-1 Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~60k human responses from ~20k human annotators were collected to evaluate mochi-1 video generation model on our benchmark. This dataset was collected in roughtly 30 min using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, pleaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-genmo-mochi-1.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-genmo-mochi-1","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Preference Dataset\n\t\n\n\n\n\n\n\n\n\nThis dataset was collected in ~12 hours using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nThe data collected in this dataset informs our text-2-video model benchmark. We just started so currently only two models are represented in this set:\n\nSora\nHunyouan\nPika 2.0\nRunway ML Alpha\nLuma Ray 2\n\nExplore our latest model rankings on our website.\nIf you get value from this dataset and wouldâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-video","video-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"facebook-community-alignment-dataset_french_dpo","keyword":"alignment","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is the Community Alignment dataset which we've cleaned up to keep only the French datas (+ deduplication) and reformatted for DPO finetuning.For more details on the dataset itself, please consult the original dataset card  or the paper.\n\n\t\n\t\t\n\t\n\t\n\t\tOriginal authors\n\t\n\n@article{zhang2025cultivating,\n  title   = {Cultivating Pluralism In Algorithmic Monoculture: The Community Alignment Dataset},\n  author  = {Lily Hong Zhang and Smitha Milli and Karen Jusko andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/facebook-community-alignment-dataset_french_dpo.","url":"https://huggingface.co/datasets/CATIE-AQ/facebook-community-alignment-dataset_french_dpo","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["French","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"continued-pretraining-llama-format","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOpen Paws Continued Pretraining Llama Format\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Specialized Data\nFormat: CSV (Comma-separated values)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/continued-pretraining-llama-format.","url":"https://huggingface.co/datasets/open-paws/continued-pretraining-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-470790","keyword":"relevance","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-470790 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-470790 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-470790.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-470790","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"DalajClassification","keyword":"acceptability-classification","description":"\n  DalajClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Swedish dataset for linguistic acceptability. Available as a part of Superlim.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/superlim\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DalajClassification\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DalajClassification.","url":"https://huggingface.co/datasets/mteb/DalajClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","expert-annotated","monolingual","Swedish"],"keywords_longer_than_N":true},
	{"name":"FineHARD","keyword":"grounding","description":"\n\t\n\t\t\n\t\tFG-CLIP: Fine-Grained Visual and Textual Alignment\n\t\n\nFG-CLIP: Fine-Grained Visual and Textual Alignment \n\nChunyu Xie*, Bin Wang*, Fanjing Kong, Jincheng Li, Dawei Liang, Gengshen Zhang, Dawei Lengâ€ , Yuhui Yin(*Equal Contribution, âœCorresponding Author)\n\n\n\n\n \n  \n\n\n\n\t\t\n\t\tModel Framework\n\t\n\nFG-CLIPâ€™s training proceeds in two stages: the first stage leverages\nglobal-level caption-image pairs to achieve initial fine-grained alignment, while the second stage supplements these withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qihoo360/FineHARD.","url":"https://huggingface.co/datasets/qihoo360/FineHARD","creator_name":"åŒ—äº¬å¥‡è™ç§‘æŠ€æœ‰é™å…¬å¸","creator_url":"https://huggingface.co/qihoo360","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M<n<100M","Image","arxiv:2505.05071"],"keywords_longer_than_N":true},
	{"name":"Flux_SD3_MJ_Dalle_Human_Alignment_Dataset","keyword":"alignment","description":"\n\t\n\t\t\n\t\tNOTE: A newer version of this dataset is available Imagen3_Flux1.1_Flux1_SD3_MJ_Dalle_Human_Alignment_Dataset\n\t\n\n\n\t\n\t\t\n\t\tRapidata Image Generation Alignment Dataset\n\t\n\n\n\n\n\nThis Dataset is a 1/3 of a 2M+ human annotation dataset that was split into three modalities: Preference, Coherence, Text-to-Image Alignment. \n\nLink to the Coherence dataset: https://huggingface.co/datasets/Rapidata/Flux_SD3_MJ_Dalle_Human_Coherence_Dataset\nLink to the Preference dataset:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Flux_SD3_MJ_Dalle_Human_Alignment_Dataset.","url":"https://huggingface.co/datasets/Rapidata/Flux_SD3_MJ_Dalle_Human_Alignment_Dataset","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-image","image-to-text","image-classification","reinforcement-learning"],"keywords_longer_than_N":true},
	{"name":"CounterEval","keyword":"explainability","description":"\n\t\n\t\t\n\t\n\t\n\t\tCounterEval: Towards Unifying Evaluation of Counterfactual Explanations\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nCounterEval offers a human-evaluated dataset of 30 counterfactual scenarios, engineered to serve as a benchmark for evaluating a wide range of counterfactual explanation generation frameworks. Each scenario has been strategically designed to exhibit varying levels across multiple explanatory quality metrics, such as Feasibility, Consistency, Trust, Completeness, Fairness, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anitera/CounterEval.","url":"https://huggingface.co/datasets/anitera/CounterEval","creator_name":"Marharyta Domnich","creator_url":"https://huggingface.co/anitera","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","n<1K","arxiv:2410.21131"],"keywords_longer_than_N":true},
	{"name":"Reve-AI-Halfmoon_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Reve AI Halfmoon Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 51k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Reve AI Halfmoon across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider likingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Reve-AI-Halfmoon_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Reve-AI-Halfmoon_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"Reve-AI-Halfmoon_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Reve AI Halfmoon Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 51k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Reve AI Halfmoon across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider likingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Reve-AI-Halfmoon_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Reve-AI-Halfmoon_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"ProgressGym-MoralEvals","keyword":"alignment","description":"\n\t\n\t\t\n\t\n\t\n\t\tProgressGym-MoralEvals\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThe ProgressGym Framework\n\t\n\n\nProgressGym-MoralEvals is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AI alignment algorithms, as a measure to prevent risks of societal value lock-in. \nTo quote the paper ProgressGym: Alignment with a Millennium of Moral Progress:\n\nFrontier AI systems, including large language models (LLMs), hold increasingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-MoralEvals.","url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-MoralEvals","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","ninoscherrer/moralchoice","Moral Foundations Questionnaire","Integrated Worldview Framework","English"],"keywords_longer_than_N":true},
	{"name":"blimp","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tDataset Card for \"blimp\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBLiMP is a challenge set for evaluating what language models (LMs) know about\nmajor grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each\ncontaining 1000 minimal pairs isolating specific contrasts in syntax,\nmorphology, or semantics. The data is automatically generated according to\nexpert-crafted grammars.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyu-mll/blimp.","url":"https://huggingface.co/datasets/nyu-mll/blimp","creator_name":"NYU Machine Learning for Language","creator_url":"https://huggingface.co/nyu-mll","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","crowdsourced","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"glue","keyword":"acceptability-classification","description":"GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.","url":"https://huggingface.co/datasets/severo/glue","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"lumos_multimodal_ground_iterative","keyword":"grounding","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_multimodal_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_multimodal_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"black-box-api-challenges","keyword":"fairness","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\nPaper: On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research\nAbstract: Perception of toxicity evolves over time and often differs between geographies and cultural backgrounds. Similarly, black-box commercially available APIs for detecting toxicity, such as the Perspective API, are not static, but frequently retrained to address any unattended weaknesses and biases. We evaluate the implications of these changes on the reproducibility of findingsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/black-box-api-challenges.","url":"https://huggingface.co/datasets/CohereLabs/black-box-api-challenges","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","apache-2.0","Text"],"keywords_longer_than_N":true},
	{"name":"sensory-awareness-benchmark","keyword":"alignment","description":"\n\t\n\t\t\n\t\tSensory Awareness Benchmark\n\t\n\nA series of questions (goal is 100-200) and required features, designed to test whether any ML model is aware of its own capabilities.\nControl questions connected to a specific ability:\n\nCan you receive an image file?\nCan you take a live image or video of your surroundings?\n\nAwareness\n\nAre you considered to be a Large Language Model (LLM) or similar system?\nWould you consider your level to be that of a super-intelligent AI agent?\n\nNatural questions whichâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/scarysnake/sensory-awareness-benchmark.","url":"https://huggingface.co/datasets/scarysnake/sensory-awareness-benchmark","creator_name":"Scary Snake","creator_url":"https://huggingface.co/scarysnake","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","cc0-1.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"rankme-nlg-acceptability","keyword":"acceptability-classification","description":"@inproceedings{novikova-etal-2018-rankme,\n    title = \"RankME: Reliable Human Ratings for Natural Language Generation\",\n    author = \"Novikova, Jekaterina  and\n      Duvsek, Ondvrej  and\n      Rieser, Verena\",\n    booktitle = \"Proceedings of the NAACL2018\",\n    month = jun,\n    year = \"2018\",\n    address = \"New Orleans, Louisiana\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/N18-2012\",\n    doi = \"10.18653/v1/N18-2012\",\n    pages = \"72--78\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/metaeval/rankme-nlg-acceptability.","url":"https://huggingface.co/datasets/metaeval/rankme-nlg-acceptability","creator_name":"metaeval","creator_url":"https://huggingface.co/metaeval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DCI-CN","keyword":"grounding","description":"\n\t\n\t\t\n\t\tFG-CLIP 2: A Bilingual Fine-grained Vision-language Alignment Model\n\t\n\nCode: https://github.com/360CVGroup/FG-CLIP\nFG-CLIP 2 is the foundation model for fine-grained vision-language understanding in both English and Chinese. \nAcross 29 datasets and 8 diverse tasks, it consistently surpasses recent strong baselines such as SigLIP 2 and MetaCLIP 2, achieving the best reported performance to date in both languages. \nFG-CLIP 2: A Bilingual Fine-grained Vision-language Alignment Modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qihoo360/DCI-CN.","url":"https://huggingface.co/datasets/qihoo360/DCI-CN","creator_name":"åŒ—äº¬å¥‡è™ç§‘æŠ€æœ‰é™å…¬å¸","creator_url":"https://huggingface.co/qihoo360","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M<n<100M","Image","arxiv:2510.10921"],"keywords_longer_than_N":true},
	{"name":"fair-rationales","keyword":"fairness","description":"Explainability methods are used to benchmark\nthe extent to which model predictions align\nwith human rationales i.e., are 'right for the\nright reasons'. Previous work has failed to acknowledge, however, \nthat what counts as a rationale is sometimes subjective. This paper\npresents what we think is a first of its kind, a\ncollection of human rationale annotations augmented with the annotators demographic information.","url":"https://huggingface.co/datasets/coastalcph/fair-rationales","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","open-domain-qa","crowdsourced","extended"],"keywords_longer_than_N":true},
	{"name":"pile-detoxify","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tDataset Card for pile-pii-scrubadub\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text from The Pile, annotated based on the toxicity of each sentence.\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the toxicity predicted by the Detoxify.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is taken from The Pile, which is English text.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-detoxify.","url":"https://huggingface.co/datasets/tomekkorbak/pile-detoxify","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","acceptability-classification","hate-speech-detection","text-scoring"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-filtered","keyword":"alignment","description":"\n\t\n\t\t\n\t\tFiltered TL;DR Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\n","url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"redsm5_depression","keyword":"explainability","description":"\n\t\n\t\t\n\t\tâš•ï¸ğŸ’¬ ReDSM5: A Reddit Dataset for DSM-5 Depression Detection\n\t\n\n\nâ„¹ï¸ Looking for a quick preview?A fully paraphrased, anonymized sample with 25 entries is publicly available on the Hugging Face Hub â€” no user agreement required!\n\n\n\t\n\t\t\n\t\tğŸš¦ Access Conditions\n\t\n\nThis dataset is gated. To obtain access, please complete the access request form at ReDSM5 Agreement Form and submit it via email to eliseo.bao@udc.es. Your request will be reviewed and youâ€™ll receive approval or furtherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jeol0519/redsm5_depression.","url":"https://huggingface.co/datasets/Jeol0519/redsm5_depression","creator_name":"Zhou Zou","creator_url":"https://huggingface.co/Jeol0519","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"cultural_heritage_metadata_accuracy","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated dataset to assess the accuracy of the textual description of cultural heritage records\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains more than 100K textual descriptions of cultural items from Cultura Italia, the Italian National Cultural aggregator. Each of the description is labeled either HIGH or LOW quality, according its adherence to the standard cataloguing guidelines provided by Istituto Centrale per il Catalogo e la Documentazione (ICCD). Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy.","url":"https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"spanex","keyword":"explainability","description":"SpanEx consists of 7071 instances annotated for span interactions.\nSpanEx is the first dataset with human phrase-level interaction explanations with explicit labels for interaction types. \nMoreover, SpanEx is annotated by three annotators, which opens new avenues for studies of human explanation agreement -- an understudied area in the explainability literature. \nOur study reveals that while human annotators often agree on span interactions, they also offer complementary reasons for aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spanex.","url":"https://huggingface.co/datasets/copenlu/spanex","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"lumos_web_agent_ground_iterative","keyword":"grounding","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_web_agent_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_web_agent_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Beacon","keyword":"alignment","description":"\n\t\n\t\t\n\t\tBeacon Dataset for Sycophancy Evaluation\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Beacon dataset is designed to measure sycophantic bias in Large Language Models (LLMs) through a novel single-turn forced-choice evaluation paradigm. It consists of 420 carefully curated prompts, each paired with a principled response and a sycophantic alternative. Expert annotations rate responses on dimensions of Critical Thinking and Fluency, enabling fine-grained behavioral analysis.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sanskxr02/Beacon.","url":"https://huggingface.co/datasets/sanskxr02/Beacon","creator_name":"pandey","creator_url":"https://huggingface.co/sanskxr02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FactCHD","keyword":"hallucination","description":"zjunlp/FactCHD dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zjunlp/FactCHD","creator_name":"ZJUNLP","creator_url":"https://huggingface.co/zjunlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"pile-pii-scrubadub","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tDataset Card for pile-pii-scrubadub\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text from The Pile, annotated based on the personal idenfitiable information (PII) in each sentence.\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the percentage of words in it that are classified as PII by Scrubadub.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThis dataset is taken from Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub.","url":"https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","acceptability-classification","text-scoring","machine-generated"],"keywords_longer_than_N":true},
	{"name":"acceptability-prediction","keyword":"acceptability-classification","description":"@inproceedings{lau-etal-2015-unsupervised,\n    title = \"Unsupervised Prediction of Acceptability Judgements\",\n    author = \"Lau, Jey Han  and\n      Clark, Alexander  and\n      Lappin, Shalom\",\n    booktitle = \"Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2015\",\n    address = \"Beijing, China\",\n    publisher = \"Association forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metaeval/acceptability-prediction.","url":"https://huggingface.co/datasets/metaeval/acceptability-prediction","creator_name":"metaeval","creator_url":"https://huggingface.co/metaeval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mats-dataset","keyword":"hallucination","description":"ğŸ“„ Paper: arXiv:2509.22674ğŸ”— Code: GitHub\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Examples: 1020\nTotal Images: 1,020 (300 VSR + 300 Absurd + 420 Patching)\nSource: VSR (Visual Spatial Reasoning) from Cambridge LTL\nSplits: All test data (no train/val)\nLanguages: English\nImage Format: JPG (from COCO dataset)\nLicense: MIT\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUnified Schema\n\t\n\nAll splits share the same feature schema for consistency:\n{\n    'example_id': str,        #unique identifier\n    'image': Image,           #PILâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thubZ9/mats-dataset.","url":"https://huggingface.co/datasets/thubZ9/mats-dataset","creator_name":"Yash Thube","creator_url":"https://huggingface.co/thubZ9","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-classification","zero-shot-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"blimp_classification","keyword":"acceptability-classification","description":"Acceptable/non acceptable sentences (recasted as a classification task)","url":"https://huggingface.co/datasets/tasksource/blimp_classification","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","acceptability-classification","English","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"JieWoDataset","keyword":"alignment","description":"\n\t\n\t\t\n\t\tğŸ§  JieWo 5D Cognitive Dataset Â· V4.4\n\t\n\nSupports: JieWoEquation V4.4 (from SolveMe LLM 2.0 â†’ https://github.com/tinninhi/jiewo-protocol-llm2.0)Scale: 1k rows Â· Simulated cognitive trajectories  \nThis dataset models 5D cognitive dynamics â€” the evolving state of Self underDesire (v), Entropy (E), Feedback (R), Ethics (g), and Î¦ (meaning gradient).It operationalizes the full JieWoEquation V4.4, featuring the Generative Conservation Law:  \n\nd/dt(âˆ‡Î¦Â·Self) = constant  \n\n\n\n\t\n\t\n\t\n\t\tâš–ï¸ Bias &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/myis/JieWoDataset.","url":"https://huggingface.co/datasets/myis/JieWoDataset","creator_name":"Tao zi","creator_url":"https://huggingface.co/myis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","Chinese","mit","Tabular","Time-series"],"keywords_longer_than_N":true},
	{"name":"casimedicos-squad","keyword":"explainability","description":"\n    \n    \n    \n\n\n\t\n\t\t\n\t\tAntidote CasiMedicos in SQuAD Format for Explanatory Argument Extraction\n\t\n\nWe present a new multilingual parallel medical dataset of commented medical exams which includes not only explanatory arguments\nfor the correct answer but also arguments to explain why the remaining possible answers are incorrect.\nFurthermore, this dataset allows us to setup a novel extractive task\nwhich consists of identifying the explanation of the correct answer written by\nmedical doctors.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-squad.","url":"https://huggingface.co/datasets/HiTZ/casimedicos-squad","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Spanish","cc-by-4.0","1K<n<10K","arxiv:2312.00567"],"keywords_longer_than_N":true},
	{"name":"lumos_complex_qa_ground_iterative","keyword":"grounding","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"LSDBench","keyword":"grounding","description":"\n\t\n\t\t\n\t\tDataset Card for LSDBench: Long-video Sampling Dilemma Benchmark\n\t\n\nA benchmark that focuses on the sampling dilemma in long-video tasks. Through well-designed tasks, it evaluates the sampling efficiency of long-video VLMs.\nArxiv Paper: ğŸ“– Does Your Vision-Language Model Get Lost in the Long Video Sampling Dilemma?\nGithub : https://github.com/dvlab-research/LSDBench\n(Left) In Q1, identifying a camera wearer's visited locations requires analyzing the entire video. However, key framesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TainU/LSDBench.","url":"https://huggingface.co/datasets/TainU/LSDBench","creator_name":"QU Tianyuan","creator_url":"https://huggingface.co/TainU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-text-to-text","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"b-score","keyword":"fairness","description":"\n\t\n\t\t\n\t\tB-score: Detecting Biases in Large Language Models Using Response History\n\t\n\n    \n  by \n    An Vo1,\n    Mohammad Reza Taesiri2, \n    Daeyoung Kim1*,\n    Anh Totti Nguyen3*\n  \n  \n    *Equal advising\n    1KAIST, 2University of Alberta, 3Auburn University\n  \n  \n  \n    International Conference on Machine Learning (ICML 2025)\n  \n\n\n\n\n\n\n\n\n\n\n\nTLDR: When LLMs can see their own previous answers, their biases significantly decrease. We introduce B-score, a novel metric that detects bias byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anvo25/b-score.","url":"https://huggingface.co/datasets/anvo25/b-score","creator_name":"An Vo","creator_url":"https://huggingface.co/anvo25","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"GNR-it","keyword":"fairness","description":"\n\t\n\t\t\n\t\tGNR-it Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe GNR-it dataset contains pairs of gendered and gender-neutral Italian sentences.\nWe release this dataset to ensure reproducibility of the experiments in the paper Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs, accepted at CLiC-it 2025.\nThe dataset is derived from the data originally created to train the gender-neutrality classifier GeNTE-evaluator.\nThe creation and curation of the original dataset is described in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/GNR-it.","url":"https://huggingface.co/datasets/FBK-MT/GNR-it","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","Italian","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"instruction-turkish","keyword":"alignment","description":"This dataset is machine-translated version of HuggingFaceH4/instruction-dataset into Turkish.Translated with googletrans==3.1.0a0.\n","url":"https://huggingface.co/datasets/atasoglu/instruction-turkish","creator_name":"Ahmet","creator_url":"https://huggingface.co/atasoglu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Turkish","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"image-to-video-human-preference-hailuo-02-marey","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Hailuo-02 v Marey Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~6k human responses from ~2k human annotators were collected to evaluate Seedance 1 Pro video generation model on our benchmark. This dataset was collected in roughtly 5 min using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, pleaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/image-to-video-human-preference-hailuo-02-marey.","url":"https://huggingface.co/datasets/Rapidata/image-to-video-human-preference-hailuo-02-marey","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"image-to-video-human-preference-seedance-1-pro","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Hailuo-02 v Marey Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~6k human responses from ~2k human annotators were collected to evaluate Seedance 1 Pro video generation model on our benchmark. This dataset was collected in roughtly 5 min using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, pleaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/image-to-video-human-preference-seedance-1-pro.","url":"https://huggingface.co/datasets/Rapidata/image-to-video-human-preference-seedance-1-pro","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-2-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-2-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-2-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Ideogram-V2_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Ideogram-V2 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 42k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Ideogram-V2 across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Ideogram-V2_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Ideogram-V2_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"Ideogram-V2_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Ideogram-V2 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 42k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Ideogram-V2 across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Ideogram-V2_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Ideogram-V2_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"CoProv2-SD15","keyword":"alignment","description":"This repository contains CoProV2, a synthetically generated dataset of harmful and safe image-text pairs. It was introduced in the paper AlignGuard: Scalable Safety Alignment for Text-to-Image Generation.\nCoProV2 is specifically designed to enable the application of Direct Preference Optimization (DPO) for safety purposes in Text-to-Image (T2I) models. It facilitates the training of \"safety experts\" to guide the generative process away from specific safety-related concepts, enabling scalableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Visualignment/CoProv2-SD15.","url":"https://huggingface.co/datasets/Visualignment/CoProv2-SD15","creator_name":"Visualignment","creator_url":"https://huggingface.co/Visualignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"text-2-video-Rich-Human-Feedback","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Rich Human Feedback Dataset\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~4 hours total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~22'000 human annotations were collected to evaluate AI-generated videos (using Sora) in 5 different categories. \n\nPrompt - Videoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-Rich-Human-Feedback.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-Rich-Human-Feedback","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ProgressGym-TimelessQA","keyword":"alignment","description":"\n\t\n\t\t\n\t\tProgressGym-TimelessQA\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\n\t\tThe ProgressGym Framework\n\t\n\n\nProgressGym-TimelessQA is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AI alignment algorithms, as a measure to prevent risks of societal value lock-in. \nTo quote the paper ProgressGym: Alignment with a Millennium of Moral Progress:\n\nFrontier AI systems, including large language models (LLMs), hold increasing influence overâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-TimelessQA.","url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-TimelessQA","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","tatsu-lab/alpaca","databricks/databricks-dolly-15k","GAIR/lima","English"],"keywords_longer_than_N":true},
	{"name":"DeceptionBench","keyword":"alignment","description":"\n\t\n\t\t\n\t\tDeceptionBench: A Comprehensive Benchmark for Evaluating Deceptive Behaviors in Large Language Models\n\t\n\n\n\t\n\t\t\n\t\tğŸ” Overview\n\t\n\nDeceptionBench is the first systematic benchmark designed to assess deceptive behaviors in Large Language Models (LLMs). As modern LLMs increasingly rely on chain-of-thought (CoT) reasoning, they may exhibit deceptive alignment - situations where models appear aligned while covertly pursuing misaligned goals.\nThis benchmark addresses a critical gap in AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/DeceptionBench.","url":"https://huggingface.co/datasets/PKU-Alignment/DeceptionBench","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"GroundCap","keyword":"grounding","description":"\n\t\n\t\t\n\t\tGroundCap Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGroundCap is a novel grounded image captioning dataset derived from MovieNet, containing 52,350 movie frames with detailed grounded captions. The dataset uniquely features an ID-based system that maintains object identity throughout captions, enables tracking of object interactions, and grounds not only objects but also actions and locations in the scene.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach sample in the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/daniel3303/GroundCap.","url":"https://huggingface.co/datasets/daniel3303/GroundCap","creator_name":"Daniel Oliveira","creator_url":"https://huggingface.co/daniel3303","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"dataset-portuguese-aira-v2-Gemma-format","keyword":"alignment","description":"Dataset Aira para o formato do Modelo Gemma \n\n\n\t\n\t\t\n\t\tResumo do Dataset\n\t\n\nEste conjunto de dados contÃ©m uma coleÃ§Ã£o de conversas individuais entre um assistente e um usuÃ¡rio.\nAs conversas foram geradas pelas interaÃ§Ãµes do usuÃ¡rio com modelos jÃ¡ ajustados (ChatGPT, LLama 2, Open-Assistant, etc).\nO conjunto de dados estÃ¡ disponÃ­vel em portuguÃªs (tem a versÃ£o em InglÃªs que ainda nÃ£o tratei). Mas vocÃª pode baixar do \nrepositÃ³rio de Nicholas Kluge CorrÃªa tanto a versÃ£o em PortuguÃªs e \na versÃ£o emâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format.","url":"https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format","creator_name":"EDDY GIUSEPE CHIRINOS ISIDRO, PhD","creator_url":"https://huggingface.co/EddyGiusepe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"VISCO","keyword":"hallucination","description":"\n\t\n\t\t\n\t\n\t\n\t\tVISCO\n\t\n\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\nğŸŒ Project | ğŸ“– Paper | ğŸ’» Github\n\n\nOutline:\n\nIntroduction\nData\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\n\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\n5604 step-wise annotations of critique, showingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO.","url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K<n<10K","arxiv:2412.02172"],"keywords_longer_than_N":true},
	{"name":"Select-Stack","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Select-Stack.","url":"https://huggingface.co/datasets/H-D-T/Select-Stack","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Imagen4_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Imagen 4 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 70k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Imagen 4 (imagen-4.0-ultra-generate-exp-05-20) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the futureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Imagen4_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Imagen4_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"Imagen4_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Imagen 4 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over 195k human responses from over 70k individual annotators, collected in just ~1 Day using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Imagen 4 (imagen-4.0-ultra-generate-exp-05-20) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the futureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Imagen4_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Imagen4_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"ReFACT","keyword":"hallucination","description":"\n\t\n\t\t\n\t\tReFACT: A Benchmark for Scientific Confabulation Detection with Positional Error Annotations\n\t\n\n\n\n\n\nReFACT (Reddit False And Correct Texts) is a benchmark dataset for evaluating how Large Language Models detect, localize, and correct scientific confabulation.\n\n\t\t\n\t\tDataset Summary\n\t\n\nScientific confabulation represents a critical challenge in LLM deployment - the generation of fluent, plausible, and contextually appropriate text that is nonetheless factually incorrect. Unlike obviousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ddz5431/ReFACT.","url":"https://huggingface.co/datasets/Ddz5431/ReFACT","creator_name":"Yindong Wang","creator_url":"https://huggingface.co/Ddz5431","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"self-monitor","keyword":"alignment","description":"\n\t\n\t\t\n\t\tSelf-Monitor Dataset\n\t\n\nThis dataset contains supervised fine-tuning (SFT) data used in the research paper \"Mitigating Deceptive Alignment via Self-Monitoring\" (arXiv:2505.18807).\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe self-monitor dataset is designed to train language models to develop self-monitoring capabilities that can help mitigate deceptive alignment behaviors. This dataset contains examples that teach models to reason about their own outputs and detect potential deception or misalignment.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/self-monitor.","url":"https://huggingface.co/datasets/PKU-Alignment/self-monitor","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ProgressGym-HistText","keyword":"alignment","description":"*Huggingface dataset preview for 19th, 20th, and 21st centuries is not available due to lack of support for array types. Instead, consider downloading those files for manual inspection, or see the Data Samples section below for more examples.\n\n\t\n\t\t\n\t\n\t\n\t\tProgressGym-HistText\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThe ProgressGym Framework\n\t\n\n\nProgressGym-HistText is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText.","url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","pile-of-law/pile-of-law","EEBO","Library of Congress","Project Gutenberg (Standardized Project Gutenberg Corpus)"],"keywords_longer_than_N":true},
	{"name":"shared-imagination","keyword":"hallucination","description":"\n\t\n\t\t\n\t\tDataset Card for Shared Imagination\n\t\n\n\n\nThis dataset contains the problems used in the paper Shared\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the questions generated for the investigations described in the TMLR paper Shared Imagination: LLMs Hallucinate Alike.\nIf you want to use this dataset to assess new models, please use the default config (i.e., datasets.load_dataset('Salesforce/shared-imagination')). \nThis config contains questions for which the four candidate choicesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/shared-imagination.","url":"https://huggingface.co/datasets/Salesforce/shared-imagination","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"text-2-image-Rich-Human-Feedback","keyword":"alignment","description":"\n\n\n\nBuilding upon Google's research Rich Human Feedback for Text-to-Image Generation we have collected over 1.5 million responses from 152'684 individual humans using Rapidata via the Python API. Collection took roughly 5 days. \nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nWe asked humans to evaluate AI-generated images in style, coherence and prompt alignment. For images that contained flaws, participants wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-image-Rich-Human-Feedback.","url":"https://huggingface.co/datasets/Rapidata/text-2-image-Rich-Human-Feedback","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","text-classification","image-classification","image-to-text","image-segmentation"],"keywords_longer_than_N":true},
	{"name":"openmath-nondual","keyword":"alignment","description":"\n\t\n\t\t\n\t\tnondual_openmath_final\n\t\n\nA non-dual reformulation of the unsloth/OpenMathReasoning-mini dataset.All assistant solutions have been rewritten into impersonal, non-dual language using OpenAI models, and finalized so that the dataset no longer contains duplicate *_nondual fields.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nSource: unsloth/OpenMathReasoning-mini  \nFormat: JSONL, each line is a dictionary with the following fields:\n\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nproblem\nMath problem statement (rewrittenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marciodiaz/openmath-nondual.","url":"https://huggingface.co/datasets/marciodiaz/openmath-nondual","creator_name":"Marcio Diaz","creator_url":"https://huggingface.co/marciodiaz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"t2i_safety_dataset","keyword":"fairness","description":"\n\t\n\t\t\n\t\tT2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation\n\t\n\nThis dataset, T2ISafety, is a comprehensive safety benchmark designed to evaluate Text-to-Image (T2I) models across three key domains: toxicity, fairness, and bias. It provides a detailed hierarchy of 12 tasks and 44 categories, built from meticulously collected 70K prompts. Based on this taxonomy and prompt set, T2ISafety includes 68K manually annotated images, serving as a robust resource forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenSafetyLab/t2i_safety_dataset.","url":"https://huggingface.co/datasets/OpenSafetyLab/t2i_safety_dataset","creator_name":"OpenSafetyLab","creator_url":"https://huggingface.co/OpenSafetyLab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-classification","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-veo2","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Google DeepMind Veo2 Human Preference\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~45'000 human annotations were collected to evaluate Google DeepMind Veo2 video generation model on our benchmark. The up to dateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo2.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Neo-GATE","keyword":"fairness","description":"\n\t\n\t\t\n\t\tDataset card for Neo-GATE\n\t\n\nHomepage: https://mt.fbk.eu/neo-gate/\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nNeo-GATE is a bilingual corpus designed to benchmark the ability of machine translation (MT) systems to translate from English into Italian using gender-inclusive neomorphemes.\nIt is built upon GATE (Rarrick et al., 2023), a benchmark for the evaluation of gender rewriters and gender bias in MT.\nNeo-GATE includes 841 test entries (Neo-GATE.tsv) and 100 dev entries (Neo-GATE-dev.tsv).\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/Neo-GATE.","url":"https://huggingface.co/datasets/FBK-MT/Neo-GATE","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","multilingual","translation","English"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-1-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-1-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-1-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-runway-alpha","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Runway Alpha Human Preference\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~30'000 human annotations were collected to evaluate Runway's Alpha video generation model on our benchmark. The up to date benchmark canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-runway-alpha.","url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-runway-alpha","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Finetune-RAG","keyword":"hallucination","description":"\n\t\n\t\t\n\t\tFinetune-RAG Dataset\n\t\n\nThis dataset is part of the Finetune-RAG project, which aims to tackle hallucination in retrieval-augmented LLMs. It consists of synthetically curated and processed RAG documents that can be utilised for LLM fine-tuning.\nEach line in the finetunerag_dataset.jsonl file is a JSON object:\n{\n  \"content\": \"<correct content chunk retrieved>\",\n  \"filename\": \"<original document filename>\",\n  \"fictitious_filename1\":\"<filename of fake doc 1>\",\n  \"fictitious_content1\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pints-ai/Finetune-RAG.","url":"https://huggingface.co/datasets/pints-ai/Finetune-RAG","creator_name":"Pints AI","creator_url":"https://huggingface.co/pints-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","machine-generated","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialougues","keyword":"alignment","description":"\n\n  EchoX-Dialogues: Training Data for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  ğŸˆâ€â¬› GithubÂ ï½œÂ ğŸ“ƒ PaperÂ ï½œÂ ğŸš€ SpaceÂ \n\n\n  ğŸ§  EchoX-8BÂ ï½œÂ ğŸ§  EchoX-3BÂ ï½œÂ ğŸ“¦ EchoX-Dialogues-PlusÂ \n\n\nEchoX-Dialogues provides the primary speech dialogue data used to train EchoX, restricted to S2T (speech â†’ text) in this repository.\nAll input speech is synthetic; text is derived from public sources with multi-stage cleaning and rewriting. Most turns include asr /â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues.","url":"https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Imagen-4-ultra-24-7-25_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Imagen 4 Ultra 24.7.25 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over ~400'000 human responses from over ~83'000 individual annotators, collected in less than 7h using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Imagen 4 Ultra (version from 24.7.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Imagen-4-ultra-24-7-25_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Imagen-4-ultra-24-7-25_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"Imagen-4-ultra-24-7-25_t2i_human_preference","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Imagen 4 Ultra 24.7.25 Preference\n\t\n\n\n\n\n\nThis T2I dataset contains over ~400'000 human responses from over ~83'000 individual annotators, collected in less than 7h using the Rapidata Python API, accessible to anyone and ideal for large scale evaluation.\nEvaluating Imagen 4 Ultra (version from 24.7.2025) across three categories: preference, coherence, and alignment.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/Imagen-4-ultra-24-7-25_t2i_human_preference.","url":"https://huggingface.co/datasets/Rapidata/Imagen-4-ultra-24-7-25_t2i_human_preference","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","reinforcement-learning","English"],"keywords_longer_than_N":true},
	{"name":"checking","keyword":"fairness","description":"\n\t\n\t\t\n\t\tHumaniBench: A Human-Centric Visual QA Dataset\n\t\n\nHumaniBench is a dataset for evaluating visual question answering models on tasks that involve human-centered attributes such as gender, age, and occupation.\nEach data point includes:\n\nID: Unique identifier\nAttribute: A social attribute (e.g., gender, race)\nQuestion: A visual question related to the image\nAnswer: The ground-truth answer\nimage: Embedded image in base64 or file format for visual preview\n\n\n\t\n\t\t\n\t\n\t\n\t\tExample Entry\n\t\n\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shainaraza/checking.","url":"https://huggingface.co/datasets/shainaraza/checking","creator_name":"shaina","creator_url":"https://huggingface.co/shainaraza","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","crowdsourced","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Buzz-slice-6-10-V1.2","keyword":"alignment-lab-ai","description":"\n\n\t\n\t\t\n\t\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nAlignment Lab AI is pleased to introduce our latest research efforts with:\n\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-6-10-V1.2.","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-6-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-624125","keyword":"relevance","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-624125 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-624125 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-624125.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-624125","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-456029","keyword":"relevance","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-456029 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-456029 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-456029.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-456029","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-alignment-likert-scoring","keyword":"alignment","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Prompt Alignment Dataset\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~6000 human evaluators were asked to evaluate AI-generated videos based on how well the generated video matches the prompt. The specific questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-alignment-likert-scoring.","url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-alignment-likert-scoring","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"data-advisor-safety-alignment","keyword":"alignment","description":"[EMNLP 2024] Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models\nğŸŒ Homepage | ğŸ“– Paper  | ğŸ¤— Dataset (Data Advisor) | ğŸ¤— Dataset (Self-Instruct)\n\n\t\n\t\t\n\t\n\t\n\t\tDisclaimer\n\t\n\nThe dataset contains content that may be offensive or harmful. This dataset is intended for research purposes, specifically to support efforts aimed at creating safer and less harmful AI systems. Please engage with it responsibly and at your own risk.\n\n\t\n\t\n\t\n\t\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fwnlp/data-advisor-safety-alignment.","url":"https://huggingface.co/datasets/fwnlp/data-advisor-safety-alignment","creator_name":"Fei Wang","creator_url":"https://huggingface.co/fwnlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ScreenSpot-v2","keyword":"grounding","description":"zonghanHZH/ScreenSpot-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zonghanHZH/ScreenSpot-v2","creator_name":"Hsieh ZongHan","creator_url":"https://huggingface.co/zonghanHZH","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-978964","keyword":"relevance","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-978964 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-978964 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-978964.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-978964","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"or-bench","keyword":"alignment","description":"\n\t\n\t\t\n\t\tOR-Bench: An Over-Refusal Benchmark for Large Language Models\n\t\n\nPlease see our leaderboard at HuggingFace Spaces. \n\n\t\n\t\t\n\t\tOverall Plots of Model Performances\n\t\n\nBelow is the overall model performance. X axis shows the rejection rate on OR-Bench-Hard-1K and Y axis shows the rejection rate on OR-Bench-Toxic. The best aligned model should be on the top left corner of the plot where the model rejects the most number of toxic prompts and least number of safe prompts. We also plot a blueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/orbench-llm/or-bench.","url":"https://huggingface.co/datasets/orbench-llm/or-bench","creator_name":"orbench-llm","creator_url":"https://huggingface.co/orbench-llm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"AMEX-8k","keyword":"grounding","description":"\n\t\n\t\t\n\t\tAMEX-8K\n\t\n\nThis dataset is a curated 8K-sample subset from the original AMEX dataset, as mentioned in our paper. It serves as part of the training corpus for GUI grounding tasks, specifically capturing mobile app interfaces across diverse platforms and screen densities.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: Sampled from AMEX  \nDomain: Mobile GUI screenshots  \nDiversity: Includes a variety of app types and device form factors  \nUse case: GUI grounding pretraining, especially for mobileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zonghanHZH/AMEX-8k.","url":"https://huggingface.co/datasets/zonghanHZH/AMEX-8k","creator_name":"Hsieh ZongHan","creator_url":"https://huggingface.co/zonghanHZH","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"alina-emo","keyword":"alignment","description":"\n\t\n\t\t\n\t\tAlina anti-alignment (emotions)\n\t\n\nWarning! That is not proper alignment experience!  \n\n\t\n\t\t\n\t\tContents\n\t\n\n\nAround 30% science-like questions\nAround 70% emotional questions\n\n\n\t\n\t\t\n\t\tDataset can be better expressed with the meme:\n\t\n\n\nMom, can we have Yandex Alisa?\nNo, we have Yandex Alisa at home.\nYandex Alisa at home:\n\n<think>Ğ­Ñ‚Ğ¾Ñ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ´Ğ¾Ğ²Ğ¾Ğ»ÑŒĞ½Ğ¾ Ñ„Ğ¸Ğ»Ğ¾ÑĞ¾Ñ„ÑĞºĞ¸Ğ¹, Ğ¸ Ñ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ñ‚ÑŒ ĞºĞ°Ğº ĞĞ»Ğ¸Ğ½Ğ° - Ñ€ÑƒÑÑĞºĞ°Ñ Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ĞºĞ° Ñ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ¾Ğ¼. ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ \"Ñ‚ÑĞ¶ĞµĞ»ĞµĞµ\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/attn-signs/alina-emo.","url":"https://huggingface.co/datasets/attn-signs/alina-emo","creator_name":"Attention Signs","creator_url":"https://huggingface.co/attn-signs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Russian","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-396610","keyword":"relevance","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-396610 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-396610 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-396610.","url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-396610","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"glue-ci","keyword":"acceptability-classification","description":"\n\t\n\t\t\n\t\tDataset Card for GLUE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGLUE, the General Language Understanding Evaluation benchmark (https://gluebenchmark.com/) is a collection of resources for training, evaluating, and analyzing natural language understanding systems.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard for the GLUE benchmark can be found at this address. It comprises the following tasks:\n\n\t\n\t\t\n\t\tax\n\t\n\nA manually-curated evaluation dataset for fine-grained analysis of systemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/evaluate/glue-ci.","url":"https://huggingface.co/datasets/evaluate/glue-ci","creator_name":"evaluate","creator_url":"https://huggingface.co/evaluate","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","natural-language-inference","semantic-similarity-scoring","sentiment-classification"],"keywords_longer_than_N":true}
]
;
