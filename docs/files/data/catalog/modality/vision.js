const data_for_modality_vision = 
[
	{"name":"taste-rob-office-3044-to-6052","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob Office_3044_to_6052 Video Dataset\n\t\n\nThis dataset contains 185 videos from the Office_3044_to_6052 scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-office-3044-to-6052\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-office-3044-to-6052","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"MathCanvas-Instruct","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMathCanvas-Instruct Dataset\n\t\n\n\n  \n    \n  \n  Â Â Â Â Â Â Â Â \n  \n    \n  \n  Â Â Â Â Â Â Â Â \n  \n    \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nMathCanvas-Instruct is a high-quality, fine-tuning dataset with 219K examples of interleaved visual-textual reasoning paths. It is the core component for the second phase of the [MathCanvas] framework: Strategic Visual-Aided Reasoning.\nAfter a model learns foundational diagram generation and editing from MathCanvas-Imagen and MathCanvas-Edit, this dataset teaches it theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shiwk24/MathCanvas-Instruct.","url":"https://huggingface.co/datasets/shiwk24/MathCanvas-Instruct","creator_name":"Weikang Shi","creator_url":"https://huggingface.co/shiwk24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Checkpoints","keyword":"vision","description":"The Checkpoints dataset as trained and used in A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors published at ICLR 2024. All models all trained and uploaded in a float16 format to reduce the memory footprint.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tUntar the models\n\t\n\nJust untar the desired models available in models, for instance with:\ntar -xvf models/cifar10-resnet18/cifar10-resnet18-0-1023.tgz\n\nMost of them are regrouped in tar files containing 1024 models each. This will create a newâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/torch-uncertainty/Checkpoints.","url":"https://huggingface.co/datasets/torch-uncertainty/Checkpoints","creator_name":"TorchUncertainty","creator_url":"https://huggingface.co/torch-uncertainty","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["apache-2.0","arxiv:2310.08287","ðŸ‡ºðŸ‡¸ Region: US","vision","checkpoints"],"keywords_longer_than_N":true},
	{"name":"Optimized_Video_Facial_Landmarks","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for 478-Point Normalized 3D Facial Landmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides pre-extracted, normalized 3D facial landmark features derived from the Video Emotion dataset. It is optimized for efficient training of emotion recognition and facial analysis models, bypassing the need to process large raw video files.\nLicense: The extracted feature data in this Parquet file is licensed under Apache 2.0. Note that the original source video files mayâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PSewmuthu/Optimized_Video_Facial_Landmarks.","url":"https://huggingface.co/datasets/PSewmuthu/Optimized_Video_Facial_Landmarks","creator_name":"Pasindu Sewmuthu Abewickrama Singhe","creator_url":"https://huggingface.co/PSewmuthu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","face-detection","thnhthngchu/video-emotion","English"],"keywords_longer_than_N":true},
	{"name":"Brain-Tumor-Mri-Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸ§  Brain Tumor MRI Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ©º Summary\n\t\n\nThis dataset contains Magnetic Resonance Imaging (MRI) scans of the human brain divided into four categories:Glioma, Meningioma, Pituitary Tumor, and No Tumor.\nIt is designed for image classification tasks and can be used to train and evaluate machine learning models that assist in the detection and classification of brain tumors.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‚ Dataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDescription\n\t\n\nThe dataset includes a total of 13,196 MRIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alfa-bravo/Brain-Tumor-Mri-Dataset.","url":"https://huggingface.co/datasets/alfa-bravo/Brain-Tumor-Mri-Dataset","creator_name":"Adalm","creator_url":"https://huggingface.co/alfa-bravo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["mit","ðŸ‡ºðŸ‡¸ Region: US","image-classification","medical-imaging","brain-tumor"],"keywords_longer_than_N":true},
	{"name":"visual-head","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸ” Visual Head Analysis Dataset\n\t\n\n\"Unveiling Visual Perception in Language Models: An Attention Head Analysis Approach\" (CVPR 2025)\n\n\n\n\n\n\n\n\n\n\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nThis dataset contains comprehensive attention analysis results from various Large Multimodal Models (LMMs) across multiple vision-language benchmarks. The data enables research into visual attention patterns, attention head behavior, and multimodal interpretability.\n\t\n\t\t\n\t\tðŸ› ï¸ Associated Tools\n\t\n\nThe accompanying codebaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jing-bi/visual-head.","url":"https://huggingface.co/datasets/jing-bi/visual-head","creator_name":"jing bi","creator_url":"https://huggingface.co/jing-bi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","text-to-image","visual-question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"taste-rob-kitchen-15553-to-19760","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob Kitchen_15553_to_19760 Video Dataset\n\t\n\nThis dataset contains 1787 videos from the Kitchen_15553_to_19760 scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-kitchen-15553-to-19760\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-kitchen-15553-to-19760","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"MathCanvas-Bench","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMathCanvas-Bench\n\t\n\n\n  \n    \n  \n  Â Â Â Â Â Â Â Â \n  \n    \n  \n  Â Â Â Â Â Â Â Â \n  \n    \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Introduction\n\t\n\nMathCanvas-Bench is a challenging new benchmark designed to evaluate the intrinsic Visual Chain-of-Thought (VCoT) capabilities of Large Multimodal Models (LMMs). It serves as the primary evaluation testbed for the [MathCanvas] framework.\nWhile existing math benchmarks have advanced textual reasoning, they largely overlook a critical skill: the ability to generate and reason withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shiwk24/MathCanvas-Bench.","url":"https://huggingface.co/datasets/shiwk24/MathCanvas-Bench","creator_name":"Weikang Shi","creator_url":"https://huggingface.co/shiwk24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"inference-PhD","keyword":"vision","description":"\n\t\n\t\t\n\t\tæ•°æ®æ ¼å¼\n\t\n\næ¯ä¸ªæ ·æœ¬åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n\nquestion_id: é—®é¢˜ID\nquestion: é—®é¢˜æ–‡æœ¬\nmodel_output: æ¨¡åž‹è¾“å‡º\nground_truth: çœŸå®žç­”æ¡ˆ\ntask: ä»»åŠ¡ç±»åž‹\nimage_name: å›¾ç‰‡åç§°\nmodel_name: æ¨¡åž‹åç§°\ndetailed_prompt: è¯¦ç»†æç¤º\nimage: å›¾ç‰‡æ•°æ®\n\n\n## åˆ†å‰²é…ç½®\n\n```yaml\n    # R1-Onevision-7B æ¨¡åž‹\n    - split: r1_onevision_7b_phd_ccs\n      path: \"r1_onevision_7b/r1_onevision_7b_phd_ccs.parquet\"\n    - split: r1_onevision_7b_phd_sec\n      path: \"r1_onevision_7b/r1_onevision_7b_phd_sec.parquet\"\n    - split: r1_onevision_7b_phd_icc\n      path:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/1Jin1/inference-PhD.","url":"https://huggingface.co/datasets/1Jin1/inference-PhD","creator_name":"jinxiwei","creator_url":"https://huggingface.co/1Jin1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","image-to-text","visual-question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"taste-rob-supplement","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob supplement Video Dataset\n\t\n\nThis dataset contains 2 videos from the supplement scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-supplement\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-supplement","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"MathCanvas-Edit","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMathCanvas-Edit Dataset\n\t\n\n\n  \n    \n  \n  Â Â Â Â Â Â Â Â \n  \n    \n  \n  Â Â Â Â Â Â Â Â \n  \n    \n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nMathCanvas-Edit is a large-scale dataset containing 5.2 million step-by-step editing trajectories, forming a crucial component of the [MathCanvas] framework. MathCanvas is designed to endow Unified Large Multimodal Models (LMMs) with intrinsic Visual Chain-of-Thought (VCoT) capabilities for solving complex mathematical problems.\nThis dataset is specifically curated for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shiwk24/MathCanvas-Edit.","url":"https://huggingface.co/datasets/shiwk24/MathCanvas-Edit","creator_name":"Weikang Shi","creator_url":"https://huggingface.co/shiwk24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"MathCanvas-Imagen","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMathCanvas-Imagen Dataset\n\t\n\n\n  \n    \n  \n  Â Â Â Â Â Â Â Â \n  \n    \n  \n  Â Â Â Â Â Â Â Â \n  \n    \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nMathCanvas-Imagen is a massive dataset featuring over 10 million caption-to-diagram pairs, forming a core part of the [MathCanvas] framework. MathCanvas is designed to endow Unified Large Multimodal Models (LMMs) with intrinsic Visual Chain-of-Thought (VCoT) capabilities for solving complex mathematical problems.\nThis dataset is specifically curated for the first phase ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shiwk24/MathCanvas-Imagen.","url":"https://huggingface.co/datasets/shiwk24/MathCanvas-Imagen","creator_name":"Weikang Shi","creator_url":"https://huggingface.co/shiwk24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"hoigen-filtered-videos","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tHOIGen Filtered Videos Dataset\n\t\n\nThis dataset contains 28562 filtered videos from the HOIGen-1M dataset based on the allowlist.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe videos are organized in the same structure as the original HOIGen dataset:\nfiltered_videos/\nâ”œâ”€â”€ videos_part_1/\nâ”œâ”€â”€ videos_part_2/\nâ”œâ”€â”€ ...\nâ””â”€â”€ videos_part_100/\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(â€¦ See the full description on the dataset page: https://huggingface.co/datasets/charlychan123/hoigen-filtered-videos.","url":"https://huggingface.co/datasets/charlychan123/hoigen-filtered-videos","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","English","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"taste-rob-dinning-49808-to-55669","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob dinning_49808_to_55669 Video Dataset\n\t\n\nThis dataset contains 1311 videos from the dinning_49808_to_55669 scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-dinning-49808-to-55669\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-dinning-49808-to-55669","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V-Chinese","keyword":"vision","description":"\n\t\n\t\t\n\t\tALLaVA-4V for Chinese\n\t\n\nThis is the Chinese version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Chinese through ChatGPT and instructed ChatGPT not to translate content related to OCR.\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese.","url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"chess-cv-openboard","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tOpenBoard Dataset (Piece Classification)\n\t\n\nThis dataset is a modified and simplified version of the OpenBoard-Dataset by Szustarol.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains images of chess pieces for classification. It is derived from the original OpenBoard-Dataset and has the following modifications:\n\nPurpose: The dataset is intended for training and testing image classification models to recognize chess pieces.\nStructure: The images are organized in an ImageFolderâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/S1M0N38/chess-cv-openboard.","url":"https://huggingface.co/datasets/S1M0N38/chess-cv-openboard","creator_name":"Simone B.","creator_url":"https://huggingface.co/S1M0N38","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","cc-by-4.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"project-1-location-classification-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tScene Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains images extracted from videos for scene classification into 4 categories:\n\nCafe\nGym\nLibrary\nOutdoor\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset: Video frame extraction from 4 scene categories\n\nClasses: cafe, gym, library, outdoor\nSource: Personal video recordings of various locations\nExtraction: Sampled every 10th frame from videos\nTotal frames: Approximately 500+ images\nFormat: JPEG, 224x224 resolution afterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/madhavkarthi/project-1-location-classification-dataset.","url":"https://huggingface.co/datasets/madhavkarthi/project-1-location-classification-dataset","creator_name":"Madhav Karthikeyakannan","creator_url":"https://huggingface.co/madhavkarthi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"ApplesM5-Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸŽ ApplesM5: Synthetic Apple Detection Benchmark\n\t\n\nThis repository hosts the data files (images and annotations) used in the Synetic AI research paper, \"Better Than Real: Synthetic Apple Detection for Orchards.\" This dataset was created through procedural content generation and physically-based rendering (PBR) to provide a clean, highly generalized training signal for robust agricultural AI.\nThe data demonstrates that training exclusively on this synthetic dataset yields superiorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SyneticAI/ApplesM5-Dataset.","url":"https://huggingface.co/datasets/SyneticAI/ApplesM5-Dataset","creator_name":"SyneticAI","creator_url":"https://huggingface.co/SyneticAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","English","cc-by-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Fruits-30","keyword":"vision","description":"\n\t\n\t\t\n\t\tFruits30 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nThe Fruits30 dataset is a collection of images featuring 30 different types of fruits. Each image has been preprocessed and standardized to a size of 224x224 pixels, ensuring uniformity in the dataset.\n\n\t\n\t\t\n\t\tDataset Composition:\n\t\n\n\nNumber of Classes: 30\nImage Resolution: 224x224 pixels\nTotal Images: 826\n\n\n\t\n\t\t\n\t\tClasses:\n\t\n\n0 : acerolas1 : apples2 : apricots3 : avocados4 : bananas5 : blackberries6 : blueberries7 : cantaloupes8 : cherries9â€¦ See the full description on the dataset page: https://huggingface.co/datasets/VinayHajare/Fruits-30.","url":"https://huggingface.co/datasets/VinayHajare/Fruits-30","creator_name":"Vinay Arjun Hajare","creator_url":"https://huggingface.co/VinayHajare","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Brazilian_Brand_Marketing_Banners_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tBrazilian Brand Marketing Banners Dataset\n\t\n\nThis dataset contains high-quality images of Brazilian brand marketing banners collected from online and offline retail environments. It includes product advertisements, promotional offers, and digital marketing visuals designed for both Portuguese-speaking audiences and bilingual markets.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Brazilian_Brand_Marketing_Banners_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Brazilian_Brand_Marketing_Banners_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Portuguese","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"emonet-face-hq","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEmoNet-Face: A Fine-Grained, Expert-Annotated Benchmark for Facial Emotion Recognition\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEmoNet-Face is a comprehensive benchmark suite designed to address critical gaps in facial emotion recognition (FER). Current benchmarks often have a narrow emotional spectrum, lack demographic diversity, and use uncontrolled imagery. EmoNet-Face provides a robust foundation for developing and evaluating AI systems with a deeper, more nuanced understanding of humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/emonet-face-hq.","url":"https://huggingface.co/datasets/laion/emonet-face-hq","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Animals_dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAnimals Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains images of three animal categories: cats, dogs, and pandas.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized into training and testing splits:\nAnimals_dataset/\nâ”œâ”€â”€ train/\nâ”‚   â”œâ”€â”€ cats/\nâ”‚   â”œâ”€â”€ dogs/\nâ”‚   â””â”€â”€ panda/\nâ””â”€â”€ test/\n    â”œâ”€â”€ cats/\n    â”œâ”€â”€ dogs/\n    â””â”€â”€ panda/\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Images: 600\nTraining Images: 480 (80.0%)\nTesting Images: 120 (20.0%)\n\n\n\t\n\t\t\n\t\tClass Distribution\n\t\n\nTrainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Melisa13/Animals_dataset.","url":"https://huggingface.co/datasets/Melisa13/Animals_dataset","creator_name":"Melisa Atis","creator_url":"https://huggingface.co/Melisa13","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"emonet-face-binary","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEmoNet-Face: A Fine-Grained, Expert-Annotated Benchmark for Facial Emotion Recognition\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEmoNet-Face is a comprehensive benchmark suite designed to address critical gaps in facial emotion recognition (FER). Current benchmarks often have a narrow emotional spectrum, lack demographic diversity, and use uncontrolled imagery. EmoNet-Face provides a robust foundation for developing and evaluating AI systems with a deeper, more nuanced understanding of humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/emonet-face-binary.","url":"https://huggingface.co/datasets/laion/emonet-face-binary","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"PubMedVision","keyword":"vision","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n\n[2025/02/18]: We add the original captions of PubMedVision in PubMedVision_Original_Caption.json, as well as the Chinese version of PubMedVision in PubMedVision_Chinese.json.\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing the HuatuoGPT-Vision-7B model.\n\n\n\t\n\t\t\n\t\tPubMedVision\n\t\n\nPubMedVision is a large-scale medical VQA dataset. We extracted high-quality image-text pairs from PubMed and used GPT-4V to reformat them to enhance their quality.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/PubMedVision.","url":"https://huggingface.co/datasets/FreedomIntelligence/PubMedVision","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Korean_Real_Estate_Ads_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Real Estate Ads Dataset\n\t\n\nThis dataset contains high-resolution images of Korean real estate advertisements, including online listings, printed flyers, and billboard ads for properties such as apartments, houses, and commercial spaces. It is designed to support AI research in OCR, visual understanding, and property analysis.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean_Real_Estate_Ads_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean_Real_Estate_Ads_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"mets","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for METS (Multiple Edits and Textual Summaries)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMETS (Multiple Edits and Textual Summaries) is a dataset of image editing sequences with human-annotated textual summaries describing the differences between original and edited images. The dataset captures cumulative changes after sequences of manipulations, providing ground truth for image difference captioning tasks. METS contains images that have undergone 5, 10, or 15 sequential edits, withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlexBlck/mets.","url":"https://huggingface.co/datasets/AlexBlck/mets","creator_name":"Alexander Black","creator_url":"https://huggingface.co/AlexBlck","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-to-image","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Misraj-DocOCR","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMisraj-DocOCR: An Arabic Document OCR BenchmarkðŸ“„\n\t\n\nDataset: Misraj/Misraj-DocOCR\nDomain: Arabic Document OCR (text + structure)Size: 400 expertly verified pages (real + synthetic)Use cases: OCR, Document Understanding, Markdown/HTML structure preservationStatus: Public ðŸ¤\n\n\t\n\t\t\n\t\n\t\n\t\tâœ¨ Overview\n\t\n\nMisraj-DocOCR is a curated, expert-verified benchmark for Arabic document OCR with an emphasis on structure preservation (Markdown/HTML tables, lists, footnotes, math, watermarksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Misraj/Misraj-DocOCR.","url":"https://huggingface.co/datasets/Misraj/Misraj-DocOCR","creator_name":"Misraj Ai","creator_url":"https://huggingface.co/Misraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"MulSeT","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMulSeT: A Benchmark for Multi-view Spatial Understanding Tasks\n\t\n\nPaper: Why Do MLLMs Struggle with Spatial Understanding? A Systematic Analysis from Data to Architecture\nCode: https://github.com/WanyueZhang-ai/spatial-understanding\n\nA high-level overview of the MulSeT benchmark. The dataset challenges models to integrate information from two distinct viewpoints of a 3D scene to answer spatial reasoning questions.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nMulSeT is a comprehensive benchmark designedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WanyueZhang/MulSeT.","url":"https://huggingface.co/datasets/WanyueZhang/MulSeT","creator_name":"zhang","creator_url":"https://huggingface.co/WanyueZhang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","Image","arxiv:2509.02359","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"RobustSpring","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tRobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo\n\t\n\nThis dataset provides structured metadata only for the RobustSpring dataset. All image samples are referenced by relative file paths, and must be paired with local image data downloaded separately from the public release site.\n\nDataset on the Hub: jeschmalfuss/RobustSpring\nImage Data: RobustSpring\n\nFor the related research see\nRobustSpring: Benchmarking Robustness to Image Corruptionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jeschmalfuss/RobustSpring.","url":"https://huggingface.co/datasets/jeschmalfuss/RobustSpring","creator_name":"Jenny Schmalfuss","creator_url":"https://huggingface.co/jeschmalfuss","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"vision-feedback-mix-binarized-cleaned","keyword":"vision","description":"\n\t\n\t\t\n\t\tDataset Card for Vision-Feedback-Mix-Binarized-Cleaned\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset represents a cleaned version on wangclnlp/vision-feedback-mix-binarized.\nDescriptions of the base datasets, including the data format and the procedure for mixing data, can be found in this link.\n\n\t\n\t\t\n\t\tOur Methods for Cleaning Vision Feedback Data\n\t\n\nOur goal is to select vision feedback samples where the preferred outputs are significantly differentiated from the dispreferred ones, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized-cleaned.","url":"https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized-cleaned","creator_name":"NiuTrans","creator_url":"https://huggingface.co/NiuTrans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"PubMedVision-STF","keyword":"vision","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n\n[2025/02/18]: We add the original captions of PubMedVision in PubMedVision_Original_Caption.json, as well as the Chinese version of PubMedVision in PubMedVision_Chinese.json.\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing the HuatuoGPT-Vision-7B model.\n\n\n\t\n\t\t\n\t\tPubMedVision\n\t\n\nPubMedVision is a large-scale medical VQA dataset. We extracted high-quality image-text pairs from PubMed and used GPT-4V to reformat them to enhance their quality.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/drwlf/PubMedVision-STF.","url":"https://huggingface.co/datasets/drwlf/PubMedVision-STF","creator_name":"Alexandru Lupoi","creator_url":"https://huggingface.co/drwlf","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM-eval","keyword":"vision","description":"\n\t\n\t\t\n\t\tLayoutSAM-eval Benchmark\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLayoutSAM-Eval is a comprehensive benchmark for evaluating the quality of Layout-to-Image (L2I) generation models. This benchmark assesses L2I generation quality from two perspectives: region-wise quality (spatial and attribute accuracy) and global-wise quality (visual quality and prompt following). It employs the VLMâ€™s visual question answering to evaluate spatial and attribute adherence, and utilizes various metrics including IR scoreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval.","url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Walking-Tours-Semantic","keyword":"computer-vision","description":"\n  Walking Tours Semantic\n\n\n\n\n\nWalking Tours Semantic (WT-Sem), introduced in PooDLe, provides semantic segmentation masks for videos in the Walking Tours dataset, as well as three additional videos for validation.\nFrames are sampled every 2 seconds from each video and a top-of-the-line semantic segmentation model, OpenSeed, is used to generate the masks.\nSpecifically, the Swin-L variant of OpenSeed, pretrained on COCO and Objects365 and finetuned on ADE20K, is used.\nThe 3 new walkaroundâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentic-learning-ai-lab/Walking-Tours-Semantic.","url":"https://huggingface.co/datasets/agentic-learning-ai-lab/Walking-Tours-Semantic","creator_name":"agentic learning ai lab","creator_url":"https://huggingface.co/agentic-learning-ai-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-feature-extraction","cc-by-4.0","n<1K","Image"],"keywords_longer_than_N":true},
	{"name":"WeaponDetection","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tWeapon and Threat Detection Dataset\n\t\n\nThis dataset is a cleaned, restructured, and ready-to-use version of a comprehensive object detection dataset for identifying weapons, aggressors, and other security-related items. It has been specifically formatted for easy use with the Hugging Face datasets library and modern training frameworks like ultralytics for YOLO models.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nThis dataset is a derivative work based on the weapon-detection Object Detection Modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Subh775/WeaponDetection.","url":"https://huggingface.co/datasets/Subh775/WeaponDetection","creator_name":"Subhansh Malviya","creator_url":"https://huggingface.co/Subh775","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Cleaned_100","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tCleaned_100\n\t\n\nThis is a dataset of \"in-the-wild\" leaf images with segmentation masks generated by the Segment Anything 2 (SAM 2) model.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains multi-leaf, \"in-the-wild\" images of plants. The segmentation masks were automatically generated using the SAM2AutomaticMaskGenerator and then processed to create a final binary mask for each image, highlighting the most prominent leaf structures. This dataset is intended for training and evaluatingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Subh775/Cleaned_100.","url":"https://huggingface.co/datasets/Subh775/Cleaned_100","creator_name":"Subhansh Malviya","creator_url":"https://huggingface.co/Subh775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"chess-board-segmentation","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tChess Piece Detection Dataset: chess-board-4\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains chess piece detection annotations in YOLOv8 format.\nChess board segmentation dataset with polygon annotations for precise board detection and localization. Optimized for YOLOv8 segmentation training with chess-board class.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the YOLOv8 format with the following structure:\n\ntrain/: Training images and labels\nvalid/: Validation images andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dopaul/chess-board-segmentation.","url":"https://huggingface.co/datasets/dopaul/chess-board-segmentation","creator_name":"Dominique Paul","creator_url":"https://huggingface.co/dopaul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"SelvaBox","keyword":"vision","description":"\n\n\t\n\t\t\n\t\tSelvaBox: A high-resolution dataset for tropical tree crown detection\n\t\n\n\n  \n\n\n\n\nThis is the version of the SelvaBox dataset that has been pre-processed and presented in our SelvaBox paper.\nThe dataset is made of 14 rasters resampled at 4.5 cm GSD, from three different countries: Brazil, Ecuador and Panama. These rasters were tiled into more than 2400 images. It comprises over 83 000 unique human bounding box annotations for tropical tree crowns in dense canopies.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CanopyRS/SelvaBox.","url":"https://huggingface.co/datasets/CanopyRS/SelvaBox","creator_name":"Canopy Remote Sensing","creator_url":"https://huggingface.co/CanopyRS","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"TUC-HRI","keyword":"computer vision","description":"\n\nUniversity of Technology Chemnitz, Germany\nDepartment Robotics and Human Machine Interaction\nAuthor: Robert Schulz\n\n\t\n\t\t\n\t\tTUC-HRI Dataset Card\n\t\n\nTUC-AR is an action recognition dataset, containing 10(+1) action categories for human machine interaction. This version contains video sequences, stored as images, frame by frame.\nWe introduce two validation types: random validation and cross-subject validation. This is the random validation dataset. For cross-subject validation, please useâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SchulzR97/TUC-HRI.","url":"https://huggingface.co/datasets/SchulzR97/TUC-HRI","creator_name":"Robert Schulz","creator_url":"https://huggingface.co/SchulzR97","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"AtomicGPT-3.0_Dataset","keyword":"computer vision","description":"Atomic-Ai/AtomicGPT-3.0_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT-3.0_Dataset","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"Trains_and_Trams","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTrains and Trams\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset containing a mixture of both Trains and Trams. There is some nuanced misalignment with how CLIP perceives the concepts of trains and trams during coarse searches therefor I have included both. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 650\nAverage Image Size (on disk): ~5.5 MB compressed\nPrimary Content: Trains and Trams\nStandardization: All images are standardized toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Trains_and_Trams.","url":"https://huggingface.co/datasets/ROSCOSMOS/Trains_and_Trams","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"PixelArt_Multiview","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMultiview PixelArt\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains sets of images representing a full 360Â° turnaround of characters, animals and objects in pixel art.\nEach row contains 9 images from all angles.\nCamera Data can be downloaded \n\nExamples\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Scaryplasmon96/PixelArt_Multiview.","url":"https://huggingface.co/datasets/Scaryplasmon96/PixelArt_Multiview","creator_name":"Andrea Cicero","creator_url":"https://huggingface.co/Scaryplasmon96","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-image","image-to-3d","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"unusual-objects-unusual-places_text-image","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\t(Un-)usual objects in (un-)usual places\n\t\n\n\n\t\n\t\t\n\t\tA small Text-Image dataset to confuse, probe (and improve) SOTA (2024) machine vision models.\n\t\n\nTo be continued (with further examples added)...\nExample results from LMSYS ARENA (June 2024):\n\n\n","url":"https://huggingface.co/datasets/zer0int/unusual-objects-unusual-places_text-image","creator_name":"zer0int","creator_url":"https://huggingface.co/zer0int","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"LAE-1M","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tLAE-1M: Locate Anything on Earth Dataset\n\t\n\n\n  \n\n\nLAE-1M (Locate Anything on Earth - 1 Million) is a large-scale open-vocabulary remote sensing object detection dataset introduced in the paper \"Locate Anything on Earth: Advancing Open-Vocabulary Object Detection for Remote Sensing Community\" (AAAI 2025).  \nIt contains over 1M images with coarse-grained (LAE-COD) and fine-grained (LAE-FOD) annotations, unified in COCO format, enabling zero-shot and few-shot detection in remote sensing.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jaychempan/LAE-1M.","url":"https://huggingface.co/datasets/jaychempan/LAE-1M","creator_name":"Jiancheng Pan","creator_url":"https://huggingface.co/jaychempan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","zero-shot-object-detection","DOTA","DIOR","FAIR1M"],"keywords_longer_than_N":true},
	{"name":"fer2013-enhanced","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tFER2013 Enhanced: Advanced Facial Expression Recognition Dataset\n\t\n\nThe most comprehensive and quality-enhanced version of the famous FER2013 dataset for state-of-the-art emotion recognition research and applications.\n\n\t\n\t\t\n\t\tðŸŽ¯ Dataset Overview\n\t\n\nFER2013 Enhanced is a significantly improved version of the landmark FER2013 facial expression recognition dataset. This enhanced version provides AI-powered quality assessment, balanced data splits, comprehensive metadata, and multi-formatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/fer2013-enhanced.","url":"https://huggingface.co/datasets/abhilash88/fer2013-enhanced","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","visual-question-answering","zero-shot-image-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"european-licence-plate","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEuropean Licence Plate Dataset\n\t\n\nThis dataset contains European vehicle licence plate images processed for machine learning applications. The dataset includes various European plate formats processed into standardized formats.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nProcessed images into train/test/validation splits (70%/20%/10%)\nMaintains original image characteristics while providing standardized resized versions\nStores both original and resized (224x224) image versions\nIncludes metadataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/0xnu/european-licence-plate.","url":"https://huggingface.co/datasets/0xnu/european-licence-plate","creator_name":"Finbarrs Oketunji","creator_url":"https://huggingface.co/0xnu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"mini-imagenet-c","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMiniImageNet-C Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMiniImageNet-C is a compact version of the ImageNet-C robustness benchmark dataset. It contains corrupted images from ImageNet designed to test the robustness of computer vision models to various types of image corruptions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a subset of the original ImageNet-C dataset, containing:\n\n15 corruption types: gaussian_noise, shot_noise, impulse_noise, defocus_blur, glass_blur, motion_blurâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/niuniandaji/mini-imagenet-c.","url":"https://huggingface.co/datasets/niuniandaji/mini-imagenet-c","creator_name":"chenqiang","creator_url":"https://huggingface.co/niuniandaji","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"sohl-multidish-yolo-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸ½ï¸ SOHL Multi-Dish Indian Food Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains 377 annotated images of Indian food plates with multiple dishes per image. Designed for training YOLO models to detect and classify multiple food items on a single plate.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nImages: 377\nAnnotations: 377  \nClasses: 16\nFormat: YOLOv8 (images + txt annotations)\nCreated: 2025-08-16\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\n\nbread_or_Roti_naan - Chapati, naan, roti, paratha, and other Indianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SohlHealth/sohl-multidish-yolo-dataset.","url":"https://huggingface.co/datasets/SohlHealth/sohl-multidish-yolo-dataset","creator_name":"Prajwala Shambulingappa","creator_url":"https://huggingface.co/SohlHealth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"Church_Buildings","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tChurches\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset, a collection of Church buildings including facades, interior shots and landscapes.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 780\nAverage Image Size (on disk): ~5.8 MB compressed\nPrimary Content: Church buildings\nStandardization: All images are standardized to RGB mode and saved at 95% quality for consistency.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation & Provenance\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t1.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Church_Buildings.","url":"https://huggingface.co/datasets/ROSCOSMOS/Church_Buildings","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"Plants","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tPlants\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset, contains a broad mix of plants and leaf types with a small distribution of flowers/fruits.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 948\nAverage Image Size (on disk): ~4.93 MB compressed\nPrimary Content: plants / leaves\nStandardization: All images are standardized to RGB mode and saved at 95% quality for consistency.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation & Provenance\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t1.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Plants.","url":"https://huggingface.co/datasets/ROSCOSMOS/Plants","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"sen12vts","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSEN12VTS: Sentinel 1 and 2 Vegetation Time-Series Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe SEN12VTS (Sentinel-1 & Sentinel-2 Vegetation Time-Series) dataset has been created to support research on time-series analysis for vegetation indices, specifically targeting NDVI (Normalized Difference Vegetation Index) regression tasks. Recognizing the lack of datasets catering to this specific temporal and spatial need, SEN12VTS was developed to fill the gap with a high-quality, Europe-focusedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/links-ads/sen12vts.","url":"https://huggingface.co/datasets/links-ads/sen12vts","creator_name":"LINKS - AI, Data & Space","creator_url":"https://huggingface.co/links-ads","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","ðŸ‡ºðŸ‡¸ Region: US","agricolture","computer-vision"],"keywords_longer_than_N":false},
	{"name":"bo_or_not","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for bo-dataset\n\t\n\nThis is a FiftyOne dataset with 169 samples designed for binary classification of Bo (Barack Obama's Portuguese Water Dog) versus other pets.\n\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nfrom fiftyone.utils.huggingface import load_from_hub\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = load_from_hub(\"Voxel51/bo_or_not\")\n\n#â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/bo_or_not.","url":"https://huggingface.co/datasets/Voxel51/bo_or_not","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"SS180","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSS180 Dataset\n\t\n\n\n    âœï¸ GithubÂ Â  | Â Â ðŸ“‘ Paper Â Â  | Â Â ðŸ–¼ï¸ Viewer\n\n\nThis is the SS180 dataset, designed for fisheye image line segment detection.\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe SS180 dataset is derived from the SS360 dataset by converting spherical images into 180-degree fisheye images.\nNumber of samples:\n\nTrain: 1900\nTest: 236\n\n\n\t\n\t\t\n\t\tDownload\n\t\n\n\nDownload with huggingface-hub\n\npython3 -m pip install huggingface-hub\nhuggingface-cli download --repo-type dataset lh9171338/SS180 --local-dir ./â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lh9171338/SS180.","url":"https://huggingface.co/datasets/lh9171338/SS180","creator_name":"Li Hao","creator_url":"https://huggingface.co/lh9171338","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"PubMedVision-EnKo","keyword":"vision","description":"\n\t\n\t\t\n\t\tInformations\n\t\n\n\nThis is the Korean translation of FreedomIntelligence/PubMedVision. The translation was primarily generated using the 'solar-pro-241126' model, with occasional manual assistance from the 'Gemini 2.0 Flash Experimental' model and the 'Gemini experimental 1206' model.\nAn evaluation of the translation quality (\"llm-as-a-judge\") will be coming soon.\n\n\n\t\n\t\t\n\t\n\t\n\t\tNews\n\t\n\n\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo.","url":"https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Korean","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"amazon_reviews_for_rec","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAmazon Reviews for Multimodal Recommendation\n\t\n\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ¦‚è§ˆ\n\t\n\nè¿™æ˜¯ä¸€ä¸ªä¸ºç«¯åˆ°ç«¯å¤šæ¨¡æ€æŽ¨èç³»ç»Ÿè®¾è®¡çš„WebDataset æ ¼å¼çš„æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æºè‡ª Amazon è¯„è®ºï¼ŒåŒ…å«äº†å¤„ç†åŽçš„æ–‡æœ¬ï¼ˆè¯„è®ºï¼‰å’Œå›¾åƒæ•°æ®ï¼Œæ—¨åœ¨æ”¯æŒé«˜æ•ˆçš„åˆ†å¸ƒå¼è®­ç»ƒã€‚\nè¯¥æ•°æ®é›†æ˜¯ GitHub é¡¹ç›® çš„ä¸€éƒ¨åˆ†ï¼Œè¯¥é¡¹ç›®åŸºäºŽ Apache Beam å’Œ PyTorch DDP æž„å»ºï¼Œæ¶µç›–äº†ä»Žåˆ†å¸ƒå¼ç‰¹å¾å·¥ç¨‹ã€æ•°æ®åŠ è½½åˆ°å¤æ‚æ¨¡åž‹ï¼ˆMMoEï¼‰åˆ†å¸ƒå¼è®­ç»ƒçš„æ•´ä¸ªå·¥ä½œæµã€‚æˆ‘ä»¬å·²å°†æ‰€ç”¨çš„æ•°æ®é›†ã€éªŒè¯é›†å’Œæ¨¡åž‹å…¨éƒ¨å¼€æºã€‚\n\n\t\n\t\t\n\t\tæ•°æ®é›†ç»Ÿè®¡\n\t\n\n\n\t\n\t\t\nå­é›†åç§°\næ–‡ä»¶æ ¼å¼\næ ·æœ¬æ•°é‡\næ–‡ä»¶å¤§å°\n\n\n\t\t\ntrain\n.tar.gz\n1848930\n128 GB\n\n\nvalid\n.tar.gz\n22281\n2 GB\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tå¦‚ä½•ä¸‹è½½å’ŒåŠ è½½æ•°æ®é›†ï¼Ÿ\n\t\n\nç”±äºŽæ•°æ®é›†æ˜¯ WebDataset æ ¼å¼ï¼Œæˆ‘ä»¬æŽ¨èä½¿ç”¨ WebDataset åº“ è¿›è¡Œæµå¼åŠ è½½ï¼Œè¿™å¯¹äºŽåˆ†å¸ƒå¼è®­ç»ƒéžå¸¸é«˜æ•ˆã€‚\n\n\t\n\t\t\n\t\n\t\n\t\tä½¿ç”¨â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jingxiang11111/amazon_reviews_for_rec.","url":"https://huggingface.co/datasets/jingxiang11111/amazon_reviews_for_rec","creator_name":"jingxiangqu","creator_url":"https://huggingface.co/jingxiang11111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1M<n<10M","WebDataset","ðŸ‡ºðŸ‡¸ Region: US","recommendation-system"],"keywords_longer_than_N":true},
	{"name":"Traffic-VQA","keyword":"vision","description":"YuYu2004/Traffic-VQA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/YuYu2004/Traffic-VQA","creator_name":"YuZhang","creator_url":"https://huggingface.co/YuYu2004","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","cc-by-4.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"blip3-grounding-50m","keyword":"vision","description":"\n\t\n\t\t\n\t\tBLIP3-GROUNDING-50M Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe BLIP3-GROUNDING-50M dataset is designed to enhance the ability of Vision-Language Models (VLMs) to ground semantic concepts in visual features, which is crucial for tasks like object detection, semantic segmentation, and understanding referring expressions (e.g., \"the object to the left of the dog\"). Traditional datasets often lack the necessary granularity for such tasks, making it challenging for models to accurately localize andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-grounding-50m.","url":"https://huggingface.co/datasets/Salesforce/blip3-grounding-50m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Opendoc2-Analysis-Recognition","keyword":"vision","description":"\n\t\n\t\t\n\t\tOpendoc2-Analysis-Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Opendoc2-Analysis-Recognition dataset is a collection of data designed for tasks involving image analysis and recognition. It is suitable for various machine learning tasks, including image-to-text conversion, text classification, and image feature extraction.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nModalities: Likely includes images and associated labels (specific modalities can be confirmed on the dataset's page).\nLanguages:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition.","url":"https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"IITU_Safety-Helmet_Dataset_v1.0_Demo","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tIITU Safety-Helmet Dataset v1.0 Demo\n\t\n\n\n\t\n\t\t\n\t\tOverview:\n\t\n\nThis dataset contains annotated images of safety helmets captured both by drone and at ground level, designed for helmet detection and color classification tasks in computer vision.\nThis is the DEMO version of the dataset, now it contains only 14 images and annotations.\n\n\n\t\n\t\t\n\t\tðŸ“– Dataset Summary\n\t\n\nThis dataset contains 1,664 images annotated for safety-helmet detection and color classification.  \n\n6,473 helmet instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ersace/IITU_Safety-Helmet_Dataset_v1.0_Demo.","url":"https://huggingface.co/datasets/ersace/IITU_Safety-Helmet_Dataset_v1.0_Demo","creator_name":"Ersaiyn","creator_url":"https://huggingface.co/ersace","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","crowdsourced","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Datatest-for-NutriSnap","keyword":"computer-vision","description":"abilhzn/Datatest-for-NutriSnap dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/abilhzn/Datatest-for-NutriSnap","creator_name":"Muhammad Abil Hasan","creator_url":"https://huggingface.co/abilhzn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-ranking","image-classification","Indonesian","English"],"keywords_longer_than_N":true},
	{"name":"SACap-1M","keyword":"vision","description":"\n\t\n\t\t\n\t\tSACap-1M Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSACap-1M is a large-scale, open-vocabulary dataset for segmentation-mask-to-image generation, sourced from the high-resolution SA-1B. It contains 1 M images and 5.9 M instance-level segmentation masks. Each mask is annotated with a regional caption (average 14.1 words) generated by Qwen2-VL-72B, and every image is paired with a global caption (average 58.6 words).\n\n\t\n\t\t\n\t\n\t\n\t\tRelated links:\n\t\n\n\nSACap-eval:  a 4K sample benchmark derived fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/0xLDF/SACap-1M.","url":"https://huggingface.co/datasets/0xLDF/SACap-1M","creator_name":"0xLDF","creator_url":"https://huggingface.co/0xLDF","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"M3_VOS","keyword":"computer-vision","description":" \n[CVPR 2025]  M3-VOS: Multi-Phase, Multi-Transition, and Multi-Scenery Video Object Segmentation\n\nIf you like our project, please give us a star â­ on GitHub for the latest update.  \n\n \n\n\n\t\n\t\t\n\t\tðŸ’¡ Description\n\t\n\n\nVenue: CVPR2025\nRepository: ðŸ› ï¸Tool, ðŸ Page\nPaper: arxiv.org/html/2412.13803v2\nPoint of Contact: Jiaxin Li , Zixuan Chen\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ Structure\n\t\n\nThis dataset contains annotated videos and images for object segmentation tasks with phase transition information. The directoryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lijiaxin0111/M3_VOS.","url":"https://huggingface.co/datasets/Lijiaxin0111/M3_VOS","creator_name":"Dan","creator_url":"https://huggingface.co/Lijiaxin0111","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","English","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"pompax-classification","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tPompax Equipment Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 2,772 images for industrial equipment nameplate classification. The task is to classify whether an image contains an industrial nameplate (\"tabliczka-znamionowa\" in Polish) or not.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Images: 2,772\nTask: Binary classification (nameplate vs non-nameplate)  \nClasses: 3 categories\ntabliczka-znamionowa (nameplate): 2,525 images (91.1%)\ninne (other/non-nameplate):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kahua-ml/pompax-classification.","url":"https://huggingface.co/datasets/kahua-ml/pompax-classification","creator_name":"Kahua","creator_url":"https://huggingface.co/kahua-ml","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","Polish","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vision-feedback-mix-binarized","keyword":"vision","description":"\n\t\n\t\t\n\t\tDataset Card for Vision-Feedback-Mix-Binarized\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset aims to provide large-scale vision feedback data. \nIt is a combination of the following high-quality vision feedback datasets:\n\nzhiqings/LLaVA-Human-Preference-10K: 9,422 samples\nMMInstruction/VLFeedback: 80,258 samples\nYiyangAiLab/POVID_preference_data_for_VLLMs: 17,184 samples\nopenbmb/RLHF-V-Dataset: 5,733 samples\nopenbmb/RLAIF-V-Dataset: 83,132 samples\n\nWe also offer a cleaned version inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized.","url":"https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized","creator_name":"NiuTrans","creator_url":"https://huggingface.co/NiuTrans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","100K - 1M","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"anchor_positive_image_dataset","keyword":"vision","description":"hyunlord/anchor_positive_image_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/hyunlord/anchor_positive_image_dataset","creator_name":"hyunlord","creator_url":"https://huggingface.co/hyunlord","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Korean","mit","10K - 100K","arrow","Image"],"keywords_longer_than_N":true},
	{"name":"AI4MARS","keyword":"computer-vision","description":"Taken from the kaggle repository here.\n\n\t\n\t\t\n\t\tAI4Mars Dataset\n\t\n\nA dataset for terrain classification on Mars, specifically focused on Curiosity (MSL) rover data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains high-resolution Mars surface images with corresponding semantic segmentation masks for terrain classification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nimage: Original EDR (Engineering Data Record) images from Mars\nlabel_mask: Semantic segmentation masks with terrain labels\nrover_mask: Binary masks (1 =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hassanjbara/AI4MARS.","url":"https://huggingface.co/datasets/hassanjbara/AI4MARS","creator_name":"Hassan Jbara","creator_url":"https://huggingface.co/hassanjbara","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"GenDS","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\t[CVPR-2025] GenDeg: Diffusion-based Degradation Synthesis for Generalizable All-In-One Image Restoration\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for GenDS dataset\n\t\n\n\nThe GenDS dataset is a large dataset to boost the generalization of image restoration models. It is a combination of existing image restoration datasets and \ndiffusion-generated degraded samples from GenDeg. \n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset is fairly large at ~360GB. We recommend having at least 800GB of free space. To download the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sudarshan2002/GenDS.","url":"https://huggingface.co/datasets/Sudarshan2002/GenDS","creator_name":"Sudarshan Rajagopalan","creator_url":"https://huggingface.co/Sudarshan2002","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"rvl-cdip-filtered","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tRVL-CDIP Filtered Dataset\n\t\n\nThis dataset contains filtered images from the RVL-CDIP dataset, focusing on 4 specific document types.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA filtered subset of the RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset containing 100,000 images across 4 document categories. Each image is stored as base64-encoded data in Parquet format for efficient processing.\n\n\t\n\t\t\n\t\tClasses\n\t\n\n\n\t\n\t\t\nLabel\nClass Name\nDescription\n\n\n\t\t\n0\nletter\nPersonal andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sabaridsnfuji/rvl-cdip-filtered.","url":"https://huggingface.co/datasets/sabaridsnfuji/rvl-cdip-filtered","creator_name":"sabarinathan","creator_url":"https://huggingface.co/sabaridsnfuji","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"men_women_children_wearing_clothes","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tImage Description Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 6979 images with their corresponding descriptions in both long and short formats. \nThe descriptions were generated using the BLIP-large model.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal images: 6979\nAverage words in long description: 17.3\nAverage words in short description: 9.4\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nfile_name: Relative path to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AntZet/men_women_children_wearing_clothes.","url":"https://huggingface.co/datasets/AntZet/men_women_children_wearing_clothes","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"livevqa-benchmark","keyword":"vision","description":"\n\t\n\t\t\n\t\tLiveVQA Benchmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLiveVQA is a comprehensive Visual Question Answering benchmark that evaluates multimodal models across three dynamic domains: News, Academic Papers, and Videos. The dataset features both level1 (basic comprehension) and level2 (advanced reasoning) questions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nid: Unique identifier for each question\nimage: Path to the associated image\nquestion: The question text\noptions: Listâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fmy666/livevqa-benchmark.","url":"https://huggingface.co/datasets/fmy666/livevqa-benchmark","creator_name":"fmy666","creator_url":"https://huggingface.co/fmy666","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","multiple-choice","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"taste-rob-kitchen-30790-to-38183","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob Kitchen_30790_to_38183 Video Dataset\n\t\n\nThis dataset contains 1 videos from the Kitchen_30790_to_38183 scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-kitchen-30790-to-38183\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-kitchen-30790-to-38183","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"taste-rob-bathroom","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob Bathroom Video Dataset\n\t\n\nThis dataset contains 103 videos from the Bathroom scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-bathroom\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-bathroom","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"DataSeeds.AI-Sample-Dataset-DSD","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataSeeds.AI Sample Dataset (DSD)\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe DataSeeds.AI Sample Dataset (DSD) is a high-fidelity, human-curated computer vision-ready dataset comprised of 7,772 peer-ranked, fully annotated photographic images, 350,000+ words of descriptive text, and comprehensive metadata. While the DSD is being released under an open source license, a sister dataset of over 10,000 fully annotated and segmented images is available for immediate commercial licensing, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dataseeds/DataSeeds.AI-Sample-Dataset-DSD.","url":"https://huggingface.co/datasets/Dataseeds/DataSeeds.AI-Sample-Dataset-DSD","creator_name":"Dataseeds AI","creator_url":"https://huggingface.co/Dataseeds","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","object-detection","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Picklebot-2M","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n2.6 million clips of balls and called strikes from MLB games from the 2016 season through the 2023 season.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset consists of all listed balls and called strikes from Baseball Savant's Statcast Search from 2016, when their video archives began, through the 2023 season.\nThis dataset includes the date, type (eg. FF, fourseam fastball), mph, spin rate, pitcher, batter, zone (1-14â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-2M.","url":"https://huggingface.co/datasets/hbfreed/Picklebot-2M","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-classification","mit","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"RHM","keyword":"vision","description":"bamorovat/RHM dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/bamorovat/RHM","creator_name":"Mohammad Hossein Bamorovat Abadi","creator_url":"https://huggingface.co/bamorovat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["video-classification","English","mit","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"DenseLayout","keyword":"vision","description":"\n\t\n\t\t\n\t\tDenseLayout Benchmark\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nDenseLayout is a benchmark for Layout-to-Image (L2I) generation in dense scenes. Each image contains 15+ instances on average with bounding boxes, categories, and captions. The dataset supports evaluation from:\n\nRegion level â€“ spatial alignment and attribute accuracy\n\nGlobal level â€“ overall image quality and prompt faithfulness\n\n\nWith its crowded layouts and fine-grained annotations, DenseLayout provides a challenging and reliable benchmarkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FireRedTeam/DenseLayout.","url":"https://huggingface.co/datasets/FireRedTeam/DenseLayout","creator_name":"FireRedTeam","creator_url":"https://huggingface.co/FireRedTeam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Picklebot-50K","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for Picklebot50k\n\t\n\n\n\n50 thousand video clips of balls and strikes from MLB games from the 2016 season through the 2022 season.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset consists of roughly 50 thousand video clips of balls and strikes in .mp4 format, resized to 224x224 resolution.\nThe calculated standard deviation and mean for the dataset are \nstd: (0.2104, 0.1986, 0.1829)\nmean: (0.3939, 0.3817, 0.3314).\n\nCurated by: Henry Freed\nLicense: MITâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-50K.","url":"https://huggingface.co/datasets/hbfreed/Picklebot-50K","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-classification","mit","10K - 100K","webdataset","Text"],"keywords_longer_than_N":true},
	{"name":"GrechnikDataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸŒ¾ GrechnikNet: Buckwheat Impurity Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ\n\t\n\nGrechnikNet â€” ÑÑ‚Ð¾ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸Ð¼ÐµÑÐµÐ¹ Ð² Ð³Ñ€ÐµÑ‡Ð½ÐµÐ²Ð¾Ð¹ ÐºÑ€ÑƒÐ¿Ðµ.ÐžÐ½ ÑÐ¾Ð·Ð´Ð°Ð½ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ð½Ð¾Ð³Ð¾ Ð·Ñ€ÐµÐ½Ð¸Ñ (YOLOv8 Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ñ…), Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼Ñ‹Ñ… Ð² Ð°Ð³Ñ€Ð¾Ð¿Ñ€Ð¾Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¸ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð² Ð¿Ð¸Ñ‚Ð°Ð½Ð¸Ñ.\n\n\t\n\t\t\n\t\tðŸ“Š Ð¡Ð¾ÑÑ‚Ð°Ð²\n\t\n\n\nðŸ“· Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ð¸ Ð³Ñ€ÐµÑ‡Ð½ÐµÐ²Ð¾Ð¹ ÐºÑ€ÑƒÐ¿Ñ‹, ÑÐ½ÑÑ‚Ñ‹Ðµ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ… (ÑÐ¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½).\nðŸ· ÐÐ½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¸: bounding boxes Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ YOLO/COCO.\nðŸ”Žâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paradise151/GrechnikDataset.","url":"https://huggingface.co/datasets/Paradise151/GrechnikDataset","creator_name":"Tyoma Kamenskiy","creator_url":"https://huggingface.co/Paradise151","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Russian","mit","1K - 10K","text","Image"],"keywords_longer_than_N":true},
	{"name":"SARFish","keyword":"computer vision","description":"SARFish is a Synthetic Aperture Radar (SAR) imagery dataset for the purpose of training, validating and testing supervised machine learning models on the tasks of ship detection, classification, and length regression. The SARFish dataset builds on the excellent work of the xView3-SAR dataset (2021) and consists of two parts:\n\nData -  Extends the xView3-SAR dataset to include Single Look Complex (SLC) as well as Ground Range Detected (GRD) imagery data taken directly from the European Spaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConnorLuckettDSTG/SARFish.","url":"https://huggingface.co/datasets/ConnorLuckettDSTG/SARFish","creator_name":"Connor Luckett","creator_url":"https://huggingface.co/ConnorLuckettDSTG","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["object-detection","image-classification","apache-2.0","n<1K","arxiv:2206.00897"],"keywords_longer_than_N":true},
	{"name":"liver-segmentation-100","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tLiver Segmentation Datasets\n\t\n\nThis is a batch of 100 CT scans, where you can find the volumes (the scans) and their segmentation to train a deep learning model for image segmentation.\n","url":"https://huggingface.co/datasets/amine0110/liver-segmentation-100","creator_name":"Mohammed Amine","creator_url":"https://huggingface.co/amine0110","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["mit","ðŸ‡ºðŸ‡¸ Region: US","medical","medical imaging","image segmentation"],"keywords_longer_than_N":true},
	{"name":"sora-watermark-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSora Watermark Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is an object detection dataset for detecting watermarks in Sora AI-generated videos. The dataset follows the YOLOv11 standard format and contains frame images extracted from Sora-generated videos along with their corresponding watermark annotations.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Samples: 164 images\nTraining Set: 124 images\nValidation Set: 21 images  \nTest Set: 19 images\nNumber of Classes: 1 (watermark)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLinked/sora-watermark-dataset.","url":"https://huggingface.co/datasets/LLinked/sora-watermark-dataset","creator_name":"List","creator_url":"https://huggingface.co/LLinked","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["object-detection","apache-2.0","n<1K","ðŸ‡ºðŸ‡¸ Region: US","yolo"],"keywords_longer_than_N":true},
	{"name":"weasis-fixed-benchmark","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tWeasis Medical Imaging GUI Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 267 end-to-end GUI automation tasks for the Weasis medical imaging viewer in tabular format, where each row represents one complete task with all associated data.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Tasks: 267\nTotal Images: 202\nFormat: Tabular (each row = one task)\nApplication: Weasis Medical Imaging Viewer\nResolution: 1920x1080\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach row contains:\n\n\t\n\t\t\nColumnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rishuKumar404/weasis-fixed-benchmark.","url":"https://huggingface.co/datasets/rishuKumar404/weasis-fixed-benchmark","creator_name":"Rishu Kumar Singh","creator_url":"https://huggingface.co/rishuKumar404","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"GrechnikDataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸŒ¾ GrechnikNet: Buckwheat Impurity Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ\n\t\n\nGrechnikNet â€” ÑÑ‚Ð¾ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸Ð¼ÐµÑÐµÐ¹ Ð² Ð³Ñ€ÐµÑ‡Ð½ÐµÐ²Ð¾Ð¹ ÐºÑ€ÑƒÐ¿Ðµ.ÐžÐ½ ÑÐ¾Ð·Ð´Ð°Ð½ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ð½Ð¾Ð³Ð¾ Ð·Ñ€ÐµÐ½Ð¸Ñ (YOLOv8 Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ñ…).\n\n\t\n\t\t\n\t\tðŸ“Š Ð¡Ð¾ÑÑ‚Ð°Ð²\n\t\n\n\nðŸ“· Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ð¸ Ð³Ñ€ÐµÑ‡Ð½ÐµÐ²Ð¾Ð¹ ÐºÑ€ÑƒÐ¿Ñ‹, ÑÐ½ÑÑ‚Ñ‹Ðµ Ð½Ð° ÑÐ¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½.\nðŸ· ÐÐ½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¸: bounding boxes Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ YOLO.\nðŸ”Ž ÐšÐ»Ð°ÑÑÑ‹:\nimpurity â€” Ð¿Ð¾ÑÑ‚Ð¾Ñ€Ð¾Ð½Ð½Ð¸Ðµ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ (ÐºÐ°Ð¼ÐµÑˆÐºÐ¸, ÑˆÐµÐ»ÑƒÑ…Ð°, Ð¼ÑƒÑÐ¾Ñ€ Ð¸ Ñ‚.Ð¿.)\n\n\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Ð¦ÐµÐ»ÑŒâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paradise151/GrechnikDataset.","url":"https://huggingface.co/datasets/Paradise151/GrechnikDataset","creator_name":"Tyoma Kamenskiy","creator_url":"https://huggingface.co/Paradise151","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Russian","mit","ðŸ‡ºðŸ‡¸ Region: US","computer-vision","object-detection"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM","keyword":"vision","description":"\n\t\n\t\t\n\t\tLayoutSAM Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe LayoutSAM dataset is a large-scale layout dataset derived from the SAM dataset, containing 2.7 million image-text pairs and 10.7 million entities. Each entity is annotated with a spatial position (i.e., bounding box) and a textual description.\nTraditional layout datasets often exhibit a closed-set and coarse-grained nature, which may limit the model's ability to generate complex attributes such as color, shape, and texture.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tKeyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM.","url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"fashionpedia","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFashionpedia is a dataset mapping out the visual aspects of the fashion world.\nFrom the paper:\n\nFashionpedia is a new dataset which consists of two parts: (1) an ontology built by fashion experts containing 27 main apparel categories, 19 apparel parts, 294 fine-grained attributes and their relationships; (2) a dataset with everyday and celebrity event fashion images annotated with segmentation masks and their associatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia.","url":"https://huggingface.co/datasets/detection-datasets/fashionpedia","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"SPIDER","keyword":"computer vision","description":"This is a large publicly available multi-center lumbar spine magnetic resonance imaging (MRI) dataset with reference segmentations of vertebrae, intervertebral discs (IVDs), and spinal canal. The dataset includes 447 sagittal T1 and T2 MRI series from 218 studies of 218 patients with a history of low back pain. The data was collected from four different hospitals. There is an additional hidden test set, not available here, used in the accompanying SPIDER challenge on spider.grand-challenge.org. We share this data to encourage wider participation and collaboration in the field of spine segmentation, and ultimately improve the diagnostic value of lumbar spine MRI.\n\nThis file also provides the biological sex for all patients and the age for the patients for which this was available. It also includes a number of scanner and acquisition parameters for each individual MRI study. The dataset also comes with radiological gradings found in a separate file for the following degenerative changes:\n\n1.â€‚â€‚â€‚â€‚Modic changes (type I, II or III)\n\n2.â€‚â€‚â€‚â€‚Upper and lower endplate changes / Schmorl nodes (binary)\n\n3.â€‚â€‚â€‚â€‚Spondylolisthesis (binary)\n\n4.â€‚â€‚â€‚â€‚Disc herniation (binary)\n\n5.â€‚â€‚â€‚â€‚Disc narrowing (binary)\n\n6.â€‚â€‚â€‚â€‚Disc bulging (binary)\n\n7.â€‚â€‚â€‚â€‚Pfirrman grade (grade 1 to 5). \n\nAll radiological gradings are provided per IVD level.\n\nRepository: https://zenodo.org/records/10159290\nPaper: https://www.nature.com/articles/s41597-024-03090-w","url":"https://huggingface.co/datasets/cdoswald/SPIDER","creator_name":"Chris Oswald","creator_url":"https://huggingface.co/cdoswald","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-segmentation","mask-generation","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"I3D-Tools-Dataset","keyword":"vision","description":"\n\t\n\t\t\n\t\tI3D Tools Dataset\n\t\n\nThis is the official dataset for the \"I3D Tools Dataset\" paper. The dataset contains a diverse collection of 16 hand tool categories, curated for applications in object detection, segmentation, and synthetic data generation.\nCodebase:\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š Dataset Statistics\n\t\n\n\nNumber of Tool Classes: 16  \nTotal Images: ~35,000  \nImage Resolution: 1024x1024  \nAnnotations per Image:\nYOLOv8 bounding box format\nPixel-level segmentation mask\nNatural language captionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/i3dlabiisc/I3D-Tools-Dataset.","url":"https://huggingface.co/datasets/i3dlabiisc/I3D-Tools-Dataset","creator_name":"I3D-Lab-IISc","creator_url":"https://huggingface.co/i3dlabiisc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"nano-imagenet-c","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tNano ImageNet-C (Severity 5)\n\t\n\nThis is a randomly sampled subset of the ImageNet-C dataset, containing 5,000 images exclusively from corruption severity level 5. It is designed for efficient testing and validation of model robustness.\nè¿™æ˜¯ä¸€ä¸ªä»Ž ImageNet-C æ•°æ®é›†ä¸­éšæœºæŠ½æ ·çš„å­é›†ï¼ŒåŒ…å« 5000 å¼ ä»…æ¥è‡ªæŸåç­‰çº§ä¸º 5 çš„å›¾åƒã€‚å®ƒæ—¨åœ¨ç”¨äºŽé«˜æ•ˆåœ°æµ‹è¯•å’ŒéªŒè¯æ¨¡åž‹çš„é²æ£’æ€§ã€‚\n\n\t\n\t\t\n\t\tHow to Generate / å¦‚ä½•ç”Ÿæˆ\n\t\n\nThis dataset was generated using the create_nano_dataset.py script included in this repository. To ensure reproducibility, the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/niuniandaji/nano-imagenet-c.","url":"https://huggingface.co/datasets/niuniandaji/nano-imagenet-c","creator_name":"chenqiang","creator_url":"https://huggingface.co/niuniandaji","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Brazilian_Road_Signs_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tBrazilian Road Signs Dataset\n\t\n\nThis dataset contains high-quality images of Brazilian road and traffic signs collected from various urban and rural environments. It supports AI research in computer vision, object detection, and autonomous driving systems adapted to Brazilâ€™s signage standards and language.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Brazilian_Road_Signs_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Brazilian_Road_Signs_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","object-detection","Portuguese","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Brazilian_Bills_and_Invoices_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tBrazilian Bills and Invoices Dataset\n\t\n\nThis dataset contains high-quality scanned and photographed images of Brazilian bills, invoices, and utility payment documents. It supports AI research in OCR, financial document understanding, and structured data extraction for Portuguese-language financial contexts.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Brazilian_Bills_and_Invoices_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Brazilian_Bills_and_Invoices_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"infovqa_colqwen2_embeddings","keyword":"vision","description":"\n\t\n\t\t\n\t\tInfoVQA ColQwen2.5 Embeddings\n\t\n\nThis dataset contains pre-computed embeddings for the InfoVQA dataset using the ColQwen2.5 model.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of three configurations:\n\n\t\n\t\t\n\t\tCorpus Configuration\n\t\n\nContains document images with their embeddings.\nfrom datasets import load_dataset\ncorpus = load_dataset(\"WenxingZhu/infovqa_colqwen2_embeddings\", \"corpus\", split=\"test\")\n\nFields:\n\ncorpus-id (int): Document identifier\nimage (Image): Original documentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WenxingZhu/infovqa_colqwen2_embeddings.","url":"https://huggingface.co/datasets/WenxingZhu/infovqa_colqwen2_embeddings","creator_name":"WenxingZhu","creator_url":"https://huggingface.co/WenxingZhu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NuCLS_dataset","keyword":"computer vision","description":"The comprehensive dataset contains over 220,000 single-rater and multi-rater labeled nuclei from breast cancer images\nobtained from TCGA, making it one of the largest datasets for nucleus detection, classification, and segmentation in hematoxylin and eosin-stained\ndigital slides of breast cancer. This version of the dataset is a revised single-rater dataset, featuring over 125,000 nucleus csvs.\nThese nuclei were annotated through a collaborative effort involving pathologists, pathology residents, and medical students, using the Digital Slide Archive.","url":"https://huggingface.co/datasets/minhanhto09/NuCLS_dataset","creator_name":"Minh-Anh To","creator_url":"https://huggingface.co/minhanhto09","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["English","cc0-1.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US","pathology"],"keywords_longer_than_N":true},
	{"name":"Military-Aircraft-Detection","keyword":"computer vision","description":"Dataset for object detection of military aircraft\nbounding box in PASCAL VOC format (xmin, ymin, xmax, ymax)\n43 aircraft types\n(A-10, A-400M, AG-600, AV-8B, B-1, B-2, B-52 Be-200, C-130, C-17, C-2, C-5, E-2, E-7, EF-2000, F-117, F-14, F-15, F-16, F/A-18, F-22, F-35, F-4, J-20, JAS-39, MQ-9, Mig-31, Mirage2000, P-3(CP-140), RQ-4, Rafale, SR-71(may contain A-12), Su-34, Su-57, Tornado, Tu-160, Tu-95(Tu-142), U-2, US-2(US-1A Kai), V-22, Vulcan, XB-70, YF-23)\nPlease let me know if you find wrongâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection.","url":"https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","zero-shot-classification","zero-shot-image-classification","depth-estimation","image-classification"],"keywords_longer_than_N":true},
	{"name":"RSCD-1million","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tRSCD: Road Surface Condition Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Road Surface Condition Dataset (RSCD) is a large-scale image dataset containing over 1 million images for road surface condition classification. This dataset is designed for training computer vision models to identify and classify various road surface types, moisture conditions, and damage severity levels.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Images: ~1,028,000 images\nImage Format: JPG\nUse Cases:\nRoad conditionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rezzzq/RSCD-1million.","url":"https://huggingface.co/datasets/rezzzq/RSCD-1million","creator_name":"Reza","creator_url":"https://huggingface.co/rezzzq","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","mit","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US","road-condition"],"keywords_longer_than_N":true},
	{"name":"Handwritten-Physics-Notes-Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEnglish Handwritten Physics Notes Dataset\n\t\n\nThis dataset contains high-resolution images of handwritten physics notes written in English. The collection includes theoretical explanations, formulas, diagrams, derivations, and problem-solving steps. It is designed to support AI research in handwriting recognition, scientific OCR, and document understanding for physics and STEM education.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Handwritten-Physics-Notes-Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Handwritten-Physics-Notes-Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","< 1K","Document"],"keywords_longer_than_N":true},
	{"name":"STAR","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSTAR Dataset (Super-Resolution for Astronomical Star Fields)\n\t\n\nThe STAR dataset is a large-scale benchmark for developing field-level super-resolution models in astronomy. It contains 54,738 flux-consistent image pairs derived from Hubble Space Telescope (HST) high-resolution observations and physically faithful low-resolution counterparts.\n\n\t\n\t\t\n\t\tðŸŒŸ Key Features\n\t\n\n\nFlux Consistency: Ensures consistent flux using a flux-preserving data generation pipeline\nObject-Crop Configuration:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KUOCHENG/STAR.","url":"https://huggingface.co/datasets/KUOCHENG/STAR","creator_name":"WUGUOCHENG","creator_url":"https://huggingface.co/KUOCHENG","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-image","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"flymyai-ffhq-edit-bench","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tFace Identity Preservation Benchmark\n\t\n\nA comprehensive evaluation dataset for face transformation APIs measuring identity preservation across complexity levels and transformation categories.\nðŸ”— Complete Repository: https://github.com/FlyMyAI/bench_M1\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis benchmark evaluates identity preservation in face image transformations using 8,832 transformation pairs across three major APIs. The dataset provides systematic evaluation of face editing quality usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/flymy-ai/flymyai-ffhq-edit-bench.","url":"https://huggingface.co/datasets/flymy-ai/flymyai-ffhq-edit-bench","creator_name":"FlyMy.AI","creator_url":"https://huggingface.co/flymy-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-image","image-classification","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"ndl-layout-dataset","keyword":"vision","description":"\n\t\n\t\t\n\t\tndl-lab/layout-data for YOLOv8\n\t\n\n\n\nThis dataset, originally provided by NDL, has been adapted and formatted to be compatible with YOLO (You Only Look Once) for training purposes.\nhttps://github.com/ndl-lab/layout-dataset\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: Satoru Nakamura\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nakamura196/ndl-layout-dataset.","url":"https://huggingface.co/datasets/nakamura196/ndl-layout-dataset","creator_name":"Satoru Nakamura","creator_url":"https://huggingface.co/nakamura196","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"fruits-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tFruits Dataset (Apples / Carrots / Oranges)\n\t\n\nThis dataset contains 160 original images of apples, carrots, and oranges, captured in different scenarios.The pictures include variations in angles, distances, lighting conditions, shadows, quantities, and surfaces, providing dynamic and diverse samples for training.  \nAnnotations were created using Label Studio and are formatted for direct use with YOLO object detection models.  \n\n\n\t\n\t\t\n\t\n\t\n\t\tStructure\n\t\n\nThe dataset is organized underâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnatanvq/fruits-dataset.","url":"https://huggingface.co/datasets/johnatanvq/fruits-dataset","creator_name":"Johnatan","creator_url":"https://huggingface.co/johnatanvq","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","expert-generated","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"multimodal-ai-taxonomy","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMultimodal AI Taxonomy\n\t\n\nA comprehensive, structured taxonomy for mapping multimodal AI model capabilities across input and output modalities.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides a systematic categorization of multimodal AI capabilities, enabling users to:\n\nNavigate the complex landscape of multimodal AI models\nFilter models by specific input/output modality combinations\nUnderstand the nuanced differences between similar models (e.g., image-to-video with/without audioâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/danielrosehill/multimodal-ai-taxonomy.","url":"https://huggingface.co/datasets/danielrosehill/multimodal-ai-taxonomy","creator_name":"Daniel Rosehill","creator_url":"https://huggingface.co/danielrosehill","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["other","English","cc0-1.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"In_the_Wild_masks600","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tIn_the_Wild_masks600\n\t\n\nThis is a dataset of \"in-the-wild\" leaf images with segmentation masks generated by the Segment Anything 2 (SAM 2) model.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains multi-leaf, \"in-the-wild\" images of plants. The segmentation masks were automatically generated using the SAM2AutomaticMaskGenerator and then processed to create a final binary mask for each image, highlighting the most prominent leaf structures. This dataset is intended for training andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Subh775/In_the_Wild_masks600.","url":"https://huggingface.co/datasets/Subh775/In_the_Wild_masks600","creator_name":"Subhansh Malviya","creator_url":"https://huggingface.co/Subh775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"CIFAR-10","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tCIFAR-10 - Object Recognition in Images\n\t\n\n\nBenchmark dataset for object classification.ðŸ–¼ï¸ 60,000 32x32 color imagesðŸ·ï¸ 10 classesðŸ“ Format: PNG, CSVðŸ“¦ Files: 4ðŸ§ª Subset of the 80 million tiny images dataset\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCIFAR-10 is a widely used computer vision dataset consisting of 60,000 32x32 color images in 10 mutually exclusive classes. It was created by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The dataset is a labeled subset of the 80 million tinyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KDKCE/CIFAR-10.","url":"https://huggingface.co/datasets/KDKCE/CIFAR-10","creator_name":"KDKCE","creator_url":"https://huggingface.co/KDKCE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"F-YorkUrban","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tF-YorkUrban Dataset\n\t\n\n\n    âœï¸ GithubÂ Â  | Â Â ðŸ“‘ Paper Â Â  | Â Â ðŸ–¼ï¸ Viewer\n\n\nThis is the F-YorkUrban dataset, designed for fisheye image line segment detection.\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\nThe F-YorkUrban dataset is derived from the YorkUrban dataset by distorting images with the fisheye distortion model, where the fisheye distortion coefficient of each image is randomly generated.\nNumber of samples:\n\nTrain: 0\nTest: 102\n\n\n\t\n\t\n\t\n\t\tDownload\n\t\n\n\nDownload with huggingface-hub\n\npython3 -m pipâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lh9171338/F-YorkUrban.","url":"https://huggingface.co/datasets/lh9171338/F-YorkUrban","creator_name":"Li Hao","creator_url":"https://huggingface.co/lh9171338","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"so101_three_strawberries_modified","keyword":"vision","description":"\n\t\n\t\t\n\t\tSO101 Three Strawberries Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains robot manipulation episodes for strawberry picking task using SO101 robot. The dataset includes 19 episodes of robot manipulation with multi-view camera observations.\n\n\t\n\t\t\n\t\tTask\n\t\n\nTask: Pick up strawberries and put them in a tray\nRobot: SO101 Follower robot with 6 degrees of freedom\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the LeRobot format and contains:\n\nData: Parquet files containingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kinam0252/so101_three_strawberries_modified.","url":"https://huggingface.co/datasets/kinam0252/so101_three_strawberries_modified","creator_name":"Kinam Kim","creator_url":"https://huggingface.co/kinam0252","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"aim-technical-articles","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAnalytics India Magazine Technical Articles Dataset ðŸš€\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis comprehensive dataset contains 25,685 high-quality technical articles from Analytics India Magazine, one of India's leading publications covering artificial intelligence, machine learning, data science, and emerging technologies.\n\n\t\n\t\t\n\t\tâœ¨ Dataset Highlights\n\t\n\n\nðŸ“š Comprehensive Coverage: Latest AI models, frameworks, and tools\nðŸ”¬ Technical Depth: Extracted keywords and complexity scoring\nðŸ­â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/aim-technical-articles.","url":"https://huggingface.co/datasets/abhilash88/aim-technical-articles","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","summarization","English"],"keywords_longer_than_N":true},
	{"name":"BJJ_Positions_Submissions","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tBJJ Positions & Submissions Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains pose keypoint annotations and compressed video clips for Brazilian Jiu-Jitsu (BJJ) combat positions and submissions. It includes 2D keypoint coordinates for up to 2 athletes per image, labeled with specific BJJ positions and submission attempts, as well as short video segments for each position/submission. The videos are optimized for use in video transformer models such as ViViT.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlosj934/BJJ_Positions_Submissions.","url":"https://huggingface.co/datasets/carlosj934/BJJ_Positions_Submissions","creator_name":"Carlos Corona","creator_url":"https://huggingface.co/carlosj934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","keypoint-detection","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"BIOSCAN-1M","keyword":"vision","description":"\n\n\t\n\t\t\n\t\tBIOSCAN-1M\n\t\n\n\n  \n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe BIOSCAN-1M dataset offers researchers detailed information about insects, with each record containing four primary attributes:\n\nDNA Barcode Sequence\nBarcode Index Number (BIN)\nBiological Taxonomy Classification\nRGB image\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you make use of the BIOSCAN-1M dataset and/or its code repository, please cite the following paper:\ncite as:\n\n@inproceedings{gharaee2023step,\n    title={A Step Towards Worldwide Biodiversityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bioscan-ml/BIOSCAN-1M.","url":"https://huggingface.co/datasets/bioscan-ml/BIOSCAN-1M","creator_name":"BIOSCAN","creator_url":"https://huggingface.co/bioscan-ml","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["English","cc-by-3.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"colorization-compare","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tColorization Comparison Dataset\n\t\n\nThis dataset contains ImageNet validation images with colorization results from different models for comparison purposes.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nimagenet/\nâ”œâ”€â”€ gt/           # Ground truth color images (JPEG format)\nâ”œâ”€â”€ bigcolor/     # BigColor model outputs\nâ”œâ”€â”€ cocolc/       # COCO-LC model outputs  \nâ””â”€â”€ ddcolor/      # DDColor model outputs\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nComparing colorization model performance\nEvaluatingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Snim/colorization-compare.","url":"https://huggingface.co/datasets/Snim/colorization-compare","creator_name":"Swarnim Maheshwari ","creator_url":"https://huggingface.co/Snim","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"aerial-d","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAERIAL-D: Referring Expression Segmentation in Aerial Imagery\n\t\n\nAERIAL-D is a comprehensive dataset for Referring Expression Instance Segmentation (RRSIS) in aerial and satellite imagery. The dataset contains high-resolution aerial photos (480Ã—480 patches) with detailed instance segmentation masks and natural language referring expressions that describe specific objects within the images.\nðŸ—‚ï¸ Dataset Structure: Due to Hugging Face's file limit constraints, the dataset is provided as aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/luisml77/aerial-d.","url":"https://huggingface.co/datasets/luisml77/aerial-d","creator_name":"Luis Lopes","creator_url":"https://huggingface.co/luisml77","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","English","apache-2.0","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"FE-Blurframe","keyword":"computer-vision","description":"This new dataset is designed for motion-blurred image line segment detection with events.","url":"https://huggingface.co/datasets/lh9171338/FE-Blurframe","creator_name":"Li Hao","creator_url":"https://huggingface.co/lh9171338","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["mit","n<1K","arxiv:2211.07365","ðŸ‡ºðŸ‡¸ Region: US","computer-vision"],"keywords_longer_than_N":true},
	{"name":"LongPerceptualThoughts-30k","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tLongPerceptualThoughts\n\t\n\n\nâ­ LongPerceptualThoughts is accepted to COLM 205!\nLongPerceptualThoughts is a synthetic dataset containing 30k long chain-of-thougt (CoT) traces. It is designed to promote system-2 thinking in vision-language models via simple SFT or DPO training.\n\n\nPaper: LongPerceptualThoughts: Distilling System-2 Reasoning for System-1 Perception [arXiv link]\nGithub Repository: Repository to synthesize your own data! [andrewliao11/LongPerceptualThoughts]\nProject website:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/andrewliao11/LongPerceptualThoughts-30k.","url":"https://huggingface.co/datasets/andrewliao11/LongPerceptualThoughts-30k","creator_name":"Andrew Liao","creator_url":"https://huggingface.co/andrewliao11","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["visual-question-answering","DOCCI","English","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"engineering-drawings-as1100","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEngineering Drawings AS1100 Compliance Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains engineering drawings with various AS1100 (Australian Standard for Technical Drawing) compliance issues for training AI models to identify missing elements and non-compliance issues in technical drawings.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Engineering Drawings AS1100 Compliance Dataset is designed to train and evaluate vision-language models on identifying compliance issues in technicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jcrzd/engineering-drawings-as1100.","url":"https://huggingface.co/datasets/jcrzd/engineering-drawings-as1100","creator_name":"JC","creator_url":"https://huggingface.co/jcrzd","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","visual-question-answering","image-to-text","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"HueManity","keyword":"vision","description":"\n\t\n\t\t\n\t\tHueManity: A Benchmark for Testing Human-Like Visual Perception in MLLMs\n\t\n\nPaper | Code\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHueManity is a benchmark dataset featuring 83,850 images designed to test the fine-grained visual perception of Multimodal Large Language Models (MLLMs). Each image presents a two-character alphanumeric string embedded within Ishihara-style dot patterns, challenging models to perform precise pattern recognition in visually cluttered environments.\nThe dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jayant-Sravan/HueManity.","url":"https://huggingface.co/datasets/Jayant-Sravan/HueManity","creator_name":"Jayant Sravan Tamarapalli","creator_url":"https://huggingface.co/Jayant-Sravan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","image-to-text","image-feature-extraction","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"DORI-Benchmark","keyword":"vision","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDORI (Discriminative Orientation Reasoning Intelligence) is a comprehensive benchmark designed to evaluate object orientation understanding in multimodal large language models (MLLMs). The benchmark isolates and evaluates orientation perception as a primary capability, offering a systematic assessment framework that spans four essential dimensions of orientation comprehension: frontal alignment, rotational transformations, relativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/appledora/DORI-Benchmark.","url":"https://huggingface.co/datasets/appledora/DORI-Benchmark","creator_name":"Nazia Tasnim","creator_url":"https://huggingface.co/appledora","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"AUDITS","keyword":"vision","description":"\n\t\n\t\t\n\t\tAUDITS: Image Manipulation Dataset\n\t\n\nAUDITS is a large-scale dataset for training and evaluating models on image manipulation detection and localization. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe folder includes train.zip, val.zip, and test.zip, each containing manipulated, original, and mask images, alongside metadata.\n\n\t\n\t\t\n\t\tðŸš€ How to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"DivyaApp/AUDITS\", split=\"train\")\n\n\n\n\t\n\t\t\n\t\tAlternatives\n\t\n\nIf loading via load_dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DivyaApp/AUDITS.","url":"https://huggingface.co/datasets/DivyaApp/AUDITS","creator_name":"Divya Appapogu","creator_url":"https://huggingface.co/DivyaApp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mask-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"TomatoMask_SAM","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTomatoMask_SAM\n\t\n\nThis is a dataset of \"in-the-wild\" leaf images with segmentation masks generated by the Segment Anything 2 (SAM 2) model.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains multi-leaf, \"in-the-wild\" images of plants. The segmentation masks were automatically generated using the SAM2AutomaticMaskGenerator and then processed to create a final binary mask for each image, highlighting the most prominent leaf structures. This dataset is intended for training andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Subh775/TomatoMask_SAM.","url":"https://huggingface.co/datasets/Subh775/TomatoMask_SAM","creator_name":"Subhansh Malviya","creator_url":"https://huggingface.co/Subh775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"CoreCognition","keyword":"vision","description":"\n\t\n\t\t\n\t\tCoreCognition: A Core Knowledge Benchmark for Multi-modal Large Language Models\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCoreCognition is a large-scale benchmark encompassing 12 core knowledge grounded in developmental cognitive science, designed to evaluate the fundamental core abilities of Multi-modal Large Language Models (MLLMs).\nWhile MLLMs demonstrate impressive abilities over high-level perception and reasoning, their robustness in the wild remains limited, often falling short on tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/williamium/CoreCognition.","url":"https://huggingface.co/datasets/williamium/CoreCognition","creator_name":"William Li","creator_url":"https://huggingface.co/williamium","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Research-Papers","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\n\t\n\t\tAI & Machine Learning Research Papers Dataset\n\t\n\nThis dataset contains a curated collection of 1296 research papers focused on advancements in Artificial Intelligence and Machine Learning. It is intended as a resource for researchers, educators, and developers to explore and analyze diverse topics within AI and ML.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nTotal Papers: 1296\nDomains Covered: \nArtificial Intelligence (AI)\nMachine Learning (ML)\nDeep Learning\nNatural Language Processing (NLP)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/khushwant04/Research-Papers.","url":"https://huggingface.co/datasets/khushwant04/Research-Papers","creator_name":"Khushwant Sanwalot","creator_url":"https://huggingface.co/khushwant04","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"recaptchav2-29k","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tReCAPTCHAv2-29k\n\t\n\nReCAPTCHAv2-29k is a dataset consisting of images derived from Google's ReCAPTCHA v2 system, which is widely used for online human verification.\nIt contains thousands of ReCAPTCHA images, each paired with corresponding labels indicating the presence of specific objects or features (e.g., bicycle, bus, car).\nThis dataset is intended for educational and research purposes and is particularly suited for tasks such as feature extraction and multi-label imageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k.","url":"https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k","creator_name":"Dennis J.","creator_url":"https://huggingface.co/nobodyPerfecZ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","found","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"Sujet-Finance-QA-Vision-100k","keyword":"vision","description":"\n\t\n\t\t\n\t\tDataset Description ðŸ“ŠðŸ”\n\t\n\nThe Sujet-Finance-QA-Vision-100k is a comprehensive dataset containing over 100,000 question-answer pairs derived from more than 9,800 financial document images. This dataset is designed to support research and development in the field of financial document analysis and visual question answering.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\nðŸ–¼ï¸ 9,801 unique financial document images\nâ“ 107,050 question-answer pairs\nðŸ‡¬ðŸ‡§ English language\nðŸ“„ Diverse financial document typesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sujet-ai/Sujet-Finance-QA-Vision-100k.","url":"https://huggingface.co/datasets/sujet-ai/Sujet-Finance-QA-Vision-100k","creator_name":"Sujet AI","creator_url":"https://huggingface.co/sujet-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"unified-math-vision-dataset","keyword":"vision","description":"\n\t\n\t\t\n\t\tUnified Math Vision Dataset Bundle\n\t\n\nGenerated at: 2025-09-19 17:12:44\nThis is a unified dataset bundle containing multiple math and vision reasoning datasets.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nTotal samples: 15858\n\nmathvision: 3344 samples\nwemath: 500 samples\nmmmu: 415 samples\nmathvista: 6141 samples\nlogicvista: 448 samples\ndynamath: 5010 samples\n\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nmanifest.jsonl: Complete dataset in JSONL format (1 JSON per line)\nmanifest.csv: Summary in CSV format\nimages/: Directoryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Haonian/unified-math-vision-dataset.","url":"https://huggingface.co/datasets/Haonian/unified-math-vision-dataset","creator_name":"Haonian Ji","creator_url":"https://huggingface.co/Haonian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Sports_Cars","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSports Cars\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset, contains a mix of modified street cars, high performance / super cars from various manufacturers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 600\nAverage Image Size (on disk): ~5.1 MB compressed\nPrimary Content: Sports Cars\nStandardization: All images are standardized to RGB mode and saved at 95% quality for consistency.\n\n\n\t\n\t\t\n\t\tDataset Creation & Provenance\n\t\n\n\n\t\n\t\t\n\t\t1.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Sports_Cars.","url":"https://huggingface.co/datasets/ROSCOSMOS/Sports_Cars","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"XMS_UI","keyword":"vision","description":"AaronHale/XMS_UI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/AaronHale/XMS_UI","creator_name":"AaronHale","creator_url":"https://huggingface.co/AaronHale","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"tool-safety-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTool Safety Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Tool Safety Dataset is a specialized collection of tool images with detailed safety and usage information. It combines visual data with comprehensive metadata about various hand tools, making it valuable for both computer vision tasks and safety training applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nType: Image dataset with bounding boxes and detailed tool information\nSize: Multiple splits (train/test/validation)\nFormat: Images withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akameswa/tool-safety-dataset.","url":"https://huggingface.co/datasets/akameswa/tool-safety-dataset","creator_name":"Adithya Kameswara Rao","creator_url":"https://huggingface.co/akameswa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","image-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"chess-pieces-merged","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tChess Piece Detection Datasets: merged-chess_pieces_dominique-chess_pieces_roboflow\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a merged dataset combining multiple chess piece detection datasets.\nComprehensive chess piece detection dataset combining multiple high-quality sources. This merged dataset provides more training data and better generalization for chess piece detection models.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the YOLOv8 format with the following structure:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/dopaul/chess-pieces-merged.","url":"https://huggingface.co/datasets/dopaul/chess-pieces-merged","creator_name":"Dominique Paul","creator_url":"https://huggingface.co/dopaul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"vlmn_tartandrive100_scand50_coda25_spot100_sub5_full_augmentation_processed_10","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTrajectory Ranking Dataset\n\t\n\nThis dataset contains trajectory ranking results for autonomous navigation scenarios.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal examples: 39558\nChunks processed: 40\nUpload date: 2025-09-13T00:44:30.335177\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nImage data with terrain analysis\nTrajectory rankings and reasoning\nQuality and diversity analysis\nTerrain and trajectory descriptions\n\n","url":"https://huggingface.co/datasets/dgorbatov/vlmn_tartandrive100_scand50_coda25_spot100_sub5_full_augmentation_processed_10","creator_name":"Daniel Gorbatov","creator_url":"https://huggingface.co/dgorbatov","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","visual-question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"pd12m_dct_based_synthetic_stegano","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tPD12M DCT-Based Synthetic Steganography Dataset\n\t\n\nThis dataset is a synthetically generated steganographic image dataset based on the PD12M (Public Domain 12M) image collection.It simulates detectable modifications produced by real-world JPEG steganography algorithms, using only public domain data.\nEach original image is duplicated into three synthetic stego variants, inspired by real-world JPEG steganographic algorithms:\n\nsynthetic_JMiPOD: simulated using conseal.nsF5, as JMiPOD isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rinovative/pd12m_dct_based_synthetic_stegano.","url":"https://huggingface.co/datasets/Rinovative/pd12m_dct_based_synthetic_stegano","creator_name":"Rino Albertin","creator_url":"https://huggingface.co/Rinovative","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"UniVG","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for UniVG-58K\n\t\n\nUniVG-58K is a large-scale vascular image dataset containing 58,689 vascular images covering five different medical imaging modalities. This dataset is specifically designed for universal few-shot vascular image segmentation tasks, supporting research and development of generative data-engine foundation models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nUniVG-58K is a comprehensive vascular image dataset that integrates content from twentyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xinaloha/UniVG.","url":"https://huggingface.co/datasets/xinaloha/UniVG","creator_name":"xin li","creator_url":"https://huggingface.co/xinaloha","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["apache-2.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US","medical","computer-vision"],"keywords_longer_than_N":true},
	{"name":"filtered_deepseek_v31_referring_expression_parsing","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDeepSeek v3.1 Quality-Filtered Referring Expression Parsing + Distractor Labels\n\t\n\nThis dataset contains parsed referring expressions from the RefCOCO, RefCOCOg, and RefCOCO+ validation sets, processed using DeepSeek v3.1 with quality filtering, plus corresponding distractor label annotations in COCO format.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nModel: DeepSeek v3.1 (deepseek-chat)\nProcessing: Quality-filtered results from referring expression parsing\nDatasets: RefCOCOâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dddraxxx/filtered_deepseek_v31_referring_expression_parsing.","url":"https://huggingface.co/datasets/dddraxxx/filtered_deepseek_v31_referring_expression_parsing","creator_name":"Drax","creator_url":"https://huggingface.co/dddraxxx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","object-detection","English","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"lanternfly-images","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSpotted Lanternfly Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 33 images of spotted lanternflies and non-lanternfly subjects, cropped to 224x224 pixels for machine learning model training. The dataset includes both original images and augmented versions created using various data augmentation techniques to improve model robustness and generalization.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset is designed for training computer vision models to detect spottedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rlogh/lanternfly-images.","url":"https://huggingface.co/datasets/rlogh/lanternfly-images","creator_name":"Rumi Loghmani","creator_url":"https://huggingface.co/rlogh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","expert-generated","English"],"keywords_longer_than_N":true},
	{"name":"Item-EMB","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAL-GR/Item-EMB: Multi-modal Item Embeddings\n\t\n\nPaper: FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets\nCode: https://github.com/selous123/al_sid\nProject Page: https://huggingface.co/AL-GR\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository, AL-GR/Item-EMB, is a companion dataset to the main AL-GR generative recommendation dataset. It contains the 512-dimensional multi-modal embeddings for over 500 million items that appear in the AL-GR sequences.\nEach item isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AL-GR/Item-EMB.","url":"https://huggingface.co/datasets/AL-GR/Item-EMB","creator_name":"ALGR","creator_url":"https://huggingface.co/AL-GR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","image-feature-extraction","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"finevision-sample","keyword":"vision","description":"\n\t\n\t\t\n\t\tFineVision Sample Dataset\n\t\n\nA comprehensive multimodal dataset containing samples across multiple categories, designed for visual question answering and multimodal understanding tasks. This dataset follows the same format as the official HuggingFaceM4/FineVision dataset.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset is organized into separate folders for each source category, making it easy to load specific subsets of the data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample contains:\n\nid: Uniqueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dinesh-vlmrun/finevision-sample.","url":"https://huggingface.co/datasets/dinesh-vlmrun/finevision-sample","creator_name":"vlmrun","creator_url":"https://huggingface.co/dinesh-vlmrun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"BASEPROD","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tBASEPROD: The Bardenas SemiDesert Planetary Rover Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBASEPROD is a planetary rover dataset collected in the Bardenas semi-desert in Spain, containing approximately 36,000 synchronized sets of RGB, depth, and thermal images from a Realsense camera and thermal sensor, plus 62,000 additional stereo pairs from a Bumblebee XB3 camera. The dataset was collected using the MaRTA rover (Martian Rover Testbed for Autonomy) developed by ESA, traversingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hassanjbara/BASEPROD.","url":"https://huggingface.co/datasets/hassanjbara/BASEPROD","creator_name":"Hassan Jbara","creator_url":"https://huggingface.co/hassanjbara","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"license-plate-finetuning","keyword":"vision","description":"A formatted, augmented copy of license_plate_object_detection for use with grounding dino training experiments. \nOriginal license is CC - please attribute author at that dataset address.\n","url":"https://huggingface.co/datasets/jtatman/license-plate-finetuning","creator_name":"James","creator_url":"https://huggingface.co/jtatman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","1K - 10K","Image","Text"],"keywords_longer_than_N":true},
	{"name":"near_duplicate_triple_image_dataset","keyword":"vision","description":"hyunlord/near_duplicate_triple_image_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/hyunlord/near_duplicate_triple_image_dataset","creator_name":"hyunlord","creator_url":"https://huggingface.co/hyunlord","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Korean","mit","1K - 10K","arrow","Image"],"keywords_longer_than_N":true},
	{"name":"central-florida-native-plants","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDeepEarth Central Florida Native Plants Dataset v0.2.0\n\t\n\n\n\t\n\t\t\n\t\tðŸŒ¿ Dataset Summary\n\t\n\nA comprehensive multimodal dataset featuring 33,665 observations of 232 native plant species from Central Florida. This dataset combines citizen science observations with state-of-the-art vision and language embeddings for advancing multimodal self-supervised ecological intelligence research.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nðŸŒ Spatiotemporal Coverage: Complete GPS coordinates and timestamps for allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepearth/central-florida-native-plants.","url":"https://huggingface.co/datasets/deepearth/central-florida-native-plants","creator_name":"DeepEarth","creator_url":"https://huggingface.co/deepearth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","zero-shot-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"MultiCaRe_Dataset","keyword":"computer vision","description":"The dataset contains multi-modal data from over 75,000 open access and de-identified case reports, including metadata, clinical cases, image captions and more than 130,000 images. Images and clinical cases belong to different medical specialties, such as oncology, cardiology, surgery and pathology. The structure of the dataset allows to easily map images with their corresponding article metadata, clinical case, captions and image labels. Details of the data structure can be found in the fileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset.","url":"https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset","creator_name":"Mauro Nievas Offidani","creator_url":"https://huggingface.co/mauro-nievoff","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"nameplate1","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tNameplate Detection Dataset\n\t\n\nThis dataset contains 1000 images for object detection of nameplates and related warning signs.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nTotal Images: 1000\nClasses: 4 (nameplate, w, warning, yellow)\nTrain: 702 images\nValidation: 149 images  \nTest: 149 images\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"kahua-ml/nameplate1\")\n\n# Access splits\ntrain_data = dataset[\"train\"]\nval_data = dataset[\"valid\"] \ntest_data =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kahua-ml/nameplate1.","url":"https://huggingface.co/datasets/kahua-ml/nameplate1","creator_name":"Kahua","creator_url":"https://huggingface.co/kahua-ml","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"DRGBT603","keyword":"computer vision","description":"zhaodong2061/DRGBT603 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zhaodong2061/DRGBT603","creator_name":"zhaodongding","creator_url":"https://huggingface.co/zhaodong2061","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K<n<1M","Image","doi:10.57967/hf/5438"],"keywords_longer_than_N":true},
	{"name":"road-issues-detection-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tRoad Issues Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis comprehensive dataset contains 9,660 high-resolution RGB images categorized for road infrastructure issues detection. The dataset focuses on identifying critical urban infrastructure problems including potholes, damaged roads, broken road signs, illegal parking violations, and environmental cleanliness issues. It has been specifically organized and curated for computer vision and machine learning applications in smartâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Programmer-RD-AI/road-issues-detection-dataset.","url":"https://huggingface.co/datasets/Programmer-RD-AI/road-issues-detection-dataset","creator_name":"Programmer-RD-AI","creator_url":"https://huggingface.co/Programmer-RD-AI","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","object-detection","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"knot-crossings","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸª¢ Knot Crossing Dataset\n\t\n\nThis dataset contains synthetic and real images of knots labeled by their number of crossings.It is used to train and evaluate models that classify a knot diagram into its crossing number.\n\n\n\t\n\t\t\n\t\tðŸ“‚ Dataset Structure\n\t\n\nThe dataset is organized into two splits:\ntrain/\n0/\n3/\n4/\n...\ntest/\n0/\n3/\n4/\n...\n\n\nEach folder corresponds to a crossing number class.\nFor example, 3/ contains diagrams of prime knots with 3 crossings.\n\n\n\n\t\n\t\t\n\t\tðŸ‘©ðŸ»â€ðŸ« Classes\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tr33hugg3r/knot-crossings.","url":"https://huggingface.co/datasets/tr33hugg3r/knot-crossings","creator_name":"Anne Dranowski","creator_url":"https://huggingface.co/tr33hugg3r","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","synthetic","unlicense","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SACap-eval","keyword":"vision","description":"\n\t\n\t\t\n\t\tSACap-1M Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSACap-Eval, a benchmark curated from a subset of SACap-1M for evaluating segmentation-mask-to-image quality. It comprises 4,000 prompts with detailed entity descriptions and corresponding segmentation masks, with an average of 5.7 entities per image. Evaluation is conducted from two perspectives: Spatial and Attribute. Both aspects are assessed using the vision-language model Qwen2-VL-72B via a visual question answering manner.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/0xLDF/SACap-eval.","url":"https://huggingface.co/datasets/0xLDF/SACap-eval","creator_name":"0xLDF","creator_url":"https://huggingface.co/0xLDF","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"clothingdatasetsecondhand","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tclothingdatasetsecondhand Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a cleaned and processed version of the original dataset available at https://zenodo.org/records/13788681.\n\n\t\n\t\t\n\t\tKey Improvements\n\t\n\n\nBackground Removal: All images have had their backgrounds removed for cleaner model training\nStandardized Size: Images are resized to 224x224 pixels for consistent input dimensions\nData Cleaning: Dataset has been processed to improve quality and usability for machineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wargoninnovation/clothingdatasetsecondhand.","url":"https://huggingface.co/datasets/wargoninnovation/clothingdatasetsecondhand","creator_name":"Susanne Eriksson","creator_url":"https://huggingface.co/wargoninnovation","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","cc-by-4.0","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"gc-os-img-art-critic","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tgc-os-img-art-critic\n\t\n\nExample gc dataset with art critic perspective\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains images with associated metadata including captions, tags, and verification information.\n","url":"https://huggingface.co/datasets/jpfearnworks/gc-os-img-art-critic","creator_name":"JP","creator_url":"https://huggingface.co/jpfearnworks","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["English","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US","image-to-text","computer-vision"],"keywords_longer_than_N":true},
	{"name":"FaceCaptionHQ-4M","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tFaceCaptionHQ-4M\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] ðŸ¤—The Original Images, are Released Completing the Agreement\nFaceCaptionHQ-4M contains about 4M facial image-text pairs that cleaned from FaceCaption-15M .  \n\n\n\n\n\t\n\t\n\t\n\t\tFigure.1 Illustrationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M.","url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"uk-licence-plate","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tUK Licence Plate\n\t\n\nThis dataset contains UK vehicle licence plate images processed for machine learning applications. The dataset includes both white and yellow plates in normal and augmented variations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nProcessed images into train/test/validation splits (70%/20%/10%)\nMaintained separation between white and yellow plates\nStores both original and resized (224x224) image versions\nIncludes metadata about image dimensions and file sizes\n\n\n\t\n\t\t\n\t\tData Fieldsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/0xnu/uk-licence-plate.","url":"https://huggingface.co/datasets/0xnu/uk-licence-plate","creator_name":"Finbarrs Oketunji","creator_url":"https://huggingface.co/0xnu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"CountQA","keyword":"vision","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCountQA is the new benchmark designed to stress-test the Achilles' heel of even the most advanced Multimodal Large Language Models (MLLMs): object counting. While modern AI demonstrates stunning visual fluency, it often fails at this fundamental cognitive skill, a critical blind spot limiting its real-world reliability.\nThis dataset directly confronts that weakness with over 1,500 challenging question-answer pairs built on real-world images, hand-captured to featureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jayant-Sravan/CountQA.","url":"https://huggingface.co/datasets/Jayant-Sravan/CountQA","creator_name":"Jayant Sravan Tamarapalli","creator_url":"https://huggingface.co/Jayant-Sravan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","visual-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"2025-24679-image-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tCar Classification Dataset - Original\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 31 original car images collected for binary classification tasks. Images are captured from various angles and in different lighting conditions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nImages: 31 high-quality car photographs\nResolution: 224x224 pixels\nFormat: RGB images (converted from HEIC/PNG)\nLabels: Binary classification (sedan vs SUV)\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is designed for:\n\nImageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anyuhhh/2025-24679-image-dataset.","url":"https://huggingface.co/datasets/Anyuhhh/2025-24679-image-dataset","creator_name":"Anyuhuang","creator_url":"https://huggingface.co/Anyuhhh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","English","mit"],"keywords_longer_than_N":true},
	{"name":"nus8-dataset","keyword":"computer-vision","description":"StevenChangWei/nus8-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/StevenChangWei/nus8-dataset","creator_name":"Chen-Wei Chang","creator_url":"https://huggingface.co/StevenChangWei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","Image","ðŸ‡ºðŸ‡¸ Region: US","computer-vision"],"keywords_longer_than_N":true},
	{"name":"cocostuff","keyword":"computer-vision","description":"COCO-Stuff augments all 164K images of the popular COCO dataset with pixel-level stuff annotations. These annotations can be used for scene understanding tasks like semantic segmentation, object detection and image captioning.","url":"https://huggingface.co/datasets/shunk031/cocostuff","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","cc-by-4.0","arxiv:1612.03716","ðŸ‡ºðŸ‡¸ Region: US","computer-vision"],"keywords_longer_than_N":true},
	{"name":"Sanctuaria-Gaze","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSanctuaria-Gaze\n\t\n\nSanctuaria-Gaze is a multimodal egocentric dataset collected from visits to four architecturally and culturally significant sanctuaries in Northern Italy.The dataset captures human gaze behavior, head motion, and visual exploration in real-world sacred environments, providing a unique resource for research on visual attention, embodied perception, and humanâ€“environment interaction.\nðŸ“˜ Paper: Sanctuaria-Gaze: A Multimodal Egocentric Dataset for Human Attentionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vcuculo/Sanctuaria-Gaze.","url":"https://huggingface.co/datasets/vcuculo/Sanctuaria-Gaze","creator_name":"vittorio cuculo","creator_url":"https://huggingface.co/vcuculo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-classification","object-detection","image-segmentation","other","English"],"keywords_longer_than_N":true},
	{"name":"weasis-optimized-benchmark","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tWeasis Medical Imaging GUI Benchmark (Tabular Format)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 267 end-to-end GUI automation tasks for the Weasis medical imaging viewer in tabular format, where each row represents one complete task with all associated data.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Tasks: 267\nTotal Images: 202\nFormat: Tabular (each row = one task)\nApplication: Weasis Medical Imaging Viewer\nResolution: 1920x1080\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach row contains:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rishuKumar404/weasis-optimized-benchmark.","url":"https://huggingface.co/datasets/rishuKumar404/weasis-optimized-benchmark","creator_name":"Rishu Kumar Singh","creator_url":"https://huggingface.co/rishuKumar404","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"SRGD","keyword":"computer-vision","description":"epishchik/SRGD dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/epishchik/SRGD","creator_name":"Evgenii Pishchik","creator_url":"https://huggingface.co/epishchik","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["apache-2.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US","super-resolution","computer-vision"],"keywords_longer_than_N":true},
	{"name":"MNIST8M","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMNIST8M Dataset (.mat format)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains the MNIST8M dataset converted to MATLAB .h5 format for convenient use in MATLAB environments. The original data is sourced from the LIBSVM datasets page.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nOriginal Source: LIBSVM Multiclass Datasets - MNIST8M\nFormat Conversion: Converted from original LibSVM format to MATLAB .h5 format\nPurpose: Facilitate clustering and machine learning experiments in MATLAB\nFiles:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarveenLee/MNIST8M.","url":"https://huggingface.co/datasets/MarveenLee/MNIST8M","creator_name":"Marveen Lee","creator_url":"https://huggingface.co/MarveenLee","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US","mnist","digits"],"keywords_longer_than_N":true},
	{"name":"albi-captioned-photos","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAlbi, France Image Dataset\n\t\n\nA collection of high-resolution scenic photographs from Albi, France with AI-generated descriptive captions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains scenic photographs from Albi, France, including the city center, the Toulouse Lautrec museum, and the Sainte-CÃ©cile Cathedral. All images were captured using a Sony A6600 camera and are paired with detailed English captions generated by Mistral AI's Pixtral-Large model.\nKey Features:\n\nHigh-resolutionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/albi-captioned-photos.","url":"https://huggingface.co/datasets/NoeFlandre/albi-captioned-photos","creator_name":"NoÃ© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-classification","object-detection","English"],"keywords_longer_than_N":true},
	{"name":"Korean_Warning_Labels_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Warning Labels Dataset\n\t\n\nThis dataset contains high-resolution images of Korean warning and safety labels, including product hazard signs, electrical warnings, chemical safety labels, and public safety notices. It supports AI research in OCR, text detection, and safety compliance analysis.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:  \n\nImageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean_Warning_Labels_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean_Warning_Labels_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Korean_Travel_Boards_Image_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Travel Boards Image Dataset\n\t\n\nThis dataset contains high-resolution images of Korean travel and tourism boards, including city maps, attraction guides, directional signs, transportation boards, and public tourism information displays. It supports OCR, multilingual translation, and computer vision research in travel-tech applications.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.ioâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean_Travel_Boards_Image_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean_Travel_Boards_Image_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Korean-Signs-Image-Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Signs Image Dataset\n\t\n\nThis dataset contains a diverse collection of high-resolution images of Korean street signs, shop boards, and public information signs. The dataset has been curated and anonymized to support research in multilingual OCR, text detection, and cultural-linguistic visual understanding.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean-Signs-Image-Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean-Signs-Image-Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"img_pointV1","keyword":"vision","description":"\n\n\t\n\t\t\n\t\timg_pointV1\n\t\n\nThis dataset is a collection of 3D point clouds generated from images in the ImageNet-1k VL Enriched dataset (visual-layer/imagenet-1k-vl-enriched).\nEach 2D image is converted into a point cloud where the (X, Y) coordinates correspond to pixel locations, and the Z coordinate (depth/elevation) is derived from the pixel's grayscale intensity. The original image colors are retained as the colors of the points. The point clouds are stored in the GLB format.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RAY-AUTRA-TECHNOLOGY/img_pointV1.","url":"https://huggingface.co/datasets/RAY-AUTRA-TECHNOLOGY/img_pointV1","creator_name":"RAY AUTRA TECHNOLOGY","creator_url":"https://huggingface.co/RAY-AUTRA-TECHNOLOGY","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","3D","ðŸ‡ºðŸ‡¸ Region: US","vision"],"keywords_longer_than_N":true},
	{"name":"img_pointV1","keyword":"computer vision","description":"\n\n\t\n\t\t\n\t\timg_pointV1\n\t\n\nThis dataset is a collection of 3D point clouds generated from images in the ImageNet-1k VL Enriched dataset (visual-layer/imagenet-1k-vl-enriched).\nEach 2D image is converted into a point cloud where the (X, Y) coordinates correspond to pixel locations, and the Z coordinate (depth/elevation) is derived from the pixel's grayscale intensity. The original image colors are retained as the colors of the points. The point clouds are stored in the GLB format.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RAY-AUTRA-TECHNOLOGY/img_pointV1.","url":"https://huggingface.co/datasets/RAY-AUTRA-TECHNOLOGY/img_pointV1","creator_name":"RAY AUTRA TECHNOLOGY","creator_url":"https://huggingface.co/RAY-AUTRA-TECHNOLOGY","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","3D","ðŸ‡ºðŸ‡¸ Region: US","vision"],"keywords_longer_than_N":true},
	{"name":"Marathi_Handwritten","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for Marathi Handwritten OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Marathi Handwritten Text Dataset is a collection of handwritten text images in Marathi (à¤¦à¥‡à¤µà¤¨à¤¾à¤—à¤°à¥€ à¤²à¤¿à¤ªà¥€),\naimed at supporting the development of Optical Character Recognition (OCR) systems, handwriting analysis tools,\nand language research.The dataset was curated from native Marathi speakers to ensure a variety of handwriting styles and character variations.\nThe dataset contains 2520 images with twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten.","url":"https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","image-feature-extraction","Marathi","mit"],"keywords_longer_than_N":true},
	{"name":"robocup-victim-dataset","keyword":"computer vision","description":"https://osf.io/dwsnm/\n","url":"https://huggingface.co/datasets/j35t3r/robocup-victim-dataset","creator_name":"Peter Lorenz","creator_url":"https://huggingface.co/j35t3r","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-classification","mit","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US","robotics"],"keywords_longer_than_N":true},
	{"name":"feature3-3500-20251023-fixed","keyword":"vision","description":"\n\t\n\t\t\n\t\tFeature 3 Canadian Tax Documents Dataset\n\t\n\n\n\t\n\t\t\n\t\tIMPORTANT: 100% SYNTHETIC DATA\n\t\n\nAll data is FAKE. No real personal information.\n\nNo real tax documents or SIN numbers\nGenerated using Faker library + CRA templates\nSafe for public ML research\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n3,500 synthetic Canadian tax documents for Feature 3 classification training.\n\n\t\n\t\t\n\t\tDocument Types\n\t\n\n\nT5: 1250 documents\nINVOICE: 1250 documents\nT4: 500 documents\nRL1: 500 documents\n\n\n\t\n\t\t\n\t\tFeatures Schemaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DeclarIA/feature3-3500-20251023-fixed.","url":"https://huggingface.co/datasets/DeclarIA/feature3-3500-20251023-fixed","creator_name":"DeclarAI","creator_url":"https://huggingface.co/DeclarIA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","document-question-answering","English","French","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Korean_Receipts_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Receipts Dataset\n\t\n\nThis dataset contains high-resolution images of Korean retail receipts from supermarkets, restaurants, and stores. The dataset has been anonymized to remove personal information and is intended for AI research in OCR, document understanding, and financial analytics.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:  \n\nImageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean_Receipts_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean_Receipts_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Handwritten-Biology-Notes-Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEnglish Handwritten Biology Notes Dataset\n\t\n\nThis dataset contains high-resolution images of handwritten biology notes written in English. The collection includes labeled diagrams, definitions, explanations of biological processes, and annotated sketches. It supports AI research in handwriting recognition, diagram understanding, and document interpretation within the field of life sciences.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Handwritten-Biology-Notes-Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Handwritten-Biology-Notes-Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","< 1K","Document"],"keywords_longer_than_N":true},
	{"name":"Handwritten-Chemistry-Notes-Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEnglish Handwritten Chemistry Notes Dataset\n\t\n\nThis dataset contains high-resolution images of handwritten chemistry notes written in English. The collection includes equations, reaction mechanisms, periodic table references, structural diagrams, and descriptive explanations. It supports AI research in handwriting recognition, chemical structure understanding, and document analysis for STEM and educational applications.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Handwritten-Chemistry-Notes-Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Handwritten-Chemistry-Notes-Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","1K<n<10K","Image"],"keywords_longer_than_N":true},
	{"name":"taste-rob-office-6053-to-9429","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob Office_6053_to_9429 Video Dataset\n\t\n\nThis dataset contains 251 videos from the Office_6053_to_9429 scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-office-6053-to-9429\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-office-6053-to-9429","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"taste-rob-dinning-9430-to-49807","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob dinning_9430_to_49807 Video Dataset\n\t\n\nThis dataset contains 1417 videos from the dinning_9430_to_49807 scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-dinning-9430-to-49807\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-dinning-9430-to-49807","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"taste-rob-office-1-to-3043","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob Office_1_to_3043 Video Dataset\n\t\n\nThis dataset contains 449 videos from the Office_1_to_3043 scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-office-1-to-3043\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-office-1-to-3043","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"SARFishSample","keyword":"computer vision","description":"SARFish is a Synthetic Aperture Radar (SAR) imagery dataset for the purpose of training, validating and testing supervised machine learning models on the tasks of ship detection, classification, and length regression. The SARFish dataset builds on the excellent work of the xView3-SAR dataset (2021) and consists of two parts:\n\nData -  Extends the xView3-SAR dataset to include Single Look Complex (SLC) as well as Ground Range Detected (GRD) imagery data taken directly from the European Spaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConnorLuckettDSTG/SARFishSample.","url":"https://huggingface.co/datasets/ConnorLuckettDSTG/SARFishSample","creator_name":"Connor Luckett","creator_url":"https://huggingface.co/ConnorLuckettDSTG","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","image-classification","apache-2.0","n<1K","arxiv:2206.00897"],"keywords_longer_than_N":true},
	{"name":"reachy-doing-things","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tReachy Doing Things Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Reachy Doing Things Images Dataset consists of images captured from the perspective of the Reachy humanoid robot. These images were taken during teleoperation sessions, providing a unique view of the environment as perceived by the robot during manipulation tasks. The images were captured with a RGBD camera mounted on the shoulder of the robot.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset is primarily aimed at testing and validating theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pollen-robotics/reachy-doing-things.","url":"https://huggingface.co/datasets/pollen-robotics/reachy-doing-things","creator_name":"Pollen Robotics","creator_url":"https://huggingface.co/pollen-robotics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"Tuberculosis_Dataset","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tMultimodal Dataset of Tuberculosis Patients including CT and Clinical Case Reports\n\t\n\nZhankai Ye    \nNetID: zy172\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is curated from the original â€œThe MultiCaRe Datasetâ€ to focus on the chest tuberculosis patients. This is a multimodal dataset consisting of lung computed tomography (CT) imaging data and the clinical case records of tuberculosis patients, along with their case keywords, the captions of their CT images, patient_id, gender, and ageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset.","url":"https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset","creator_name":"Zhankai Ye","creator_url":"https://huggingface.co/moukaii","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Handwritten-Computer-Science-Notes-Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEnglish Handwritten Computer Science Notes Dataset\n\t\n\nThis dataset contains high-resolution images of handwritten computer science notes written in English. It includes algorithm explanations, code snippets, flowcharts, theoretical content, and annotations. The dataset is designed to support AI research in handwriting recognition, OCR, and document understanding specifically for computer science education.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Handwritten-Computer-Science-Notes-Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Handwritten-Computer-Science-Notes-Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","1K<n<10K","Document"],"keywords_longer_than_N":true},
	{"name":"emonet-face-big","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEmoNet-Face: A Fine-Grained, Expert-Annotated Benchmark for Facial Emotion Recognition\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEmoNet-Face is a comprehensive benchmark suite designed to address critical gaps in facial emotion recognition (FER). Current benchmarks often have a narrow emotional spectrum, lack demographic diversity, and use uncontrolled imagery. EmoNet-Face provides a robust foundation for developing and evaluating AI systems with a deeper, more nuanced understanding of humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/emonet-face-big.","url":"https://huggingface.co/datasets/laion/emonet-face-big","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"NHR-Edit-Change_Only","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tNHR-Edit Change-Only Dataset\n\t\n\nThis is a filtered subset of the iitolstykh/NHR-Edit dataset containing only samples where the category contains \"change\" but excludes categories with \"add\" or \"remove\" operations.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 2,000\nSource dataset: iitolstykh/NHR-Edit\nFilter criteria: Categories containing \"change\" but not \"add\" or \"remove\" or \"human\" (case-insensitive)\n\n\n\t\n\t\t\n\t\tCategories Included\n\t\n\nThe filtered dataset contains the following 109â€¦ See the full description on the dataset page: https://huggingface.co/datasets/VyoJ/NHR-Edit-Change_Only.","url":"https://huggingface.co/datasets/VyoJ/NHR-Edit-Change_Only","creator_name":"VyoJ","creator_url":"https://huggingface.co/VyoJ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-image","text-to-image","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"violence-nonviolence-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tViolence vs Non-Violence Dataset\n\t\n\nThis dataset contains annotated interaction data for detecting violent vs non-violent human interactions.The data is extracted from video frames and includes bounding boxes, pose keypoints, motion features, and violence indicators for pairs of interacting persons.\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nviolence_data.csv â†’ Frames labeled as violent interactions  \nnon_violence_data.csv â†’ Frames labeled as non-violent interactions\n\nEach CSV contains structured features atâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/harmesh95/violence-nonviolence-dataset.","url":"https://huggingface.co/datasets/harmesh95/violence-nonviolence-dataset","creator_name":"Harmesh G V","creator_url":"https://huggingface.co/harmesh95","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-classification","image-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"digital_signatures","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDigital Signatures Dataset\n\t\n\nThis dataset contains unique synthetic digital signatures rendered in different fonts:\n\n4,000 synthetic signatures in Rage font\n\n4,000 synthetic signatures in Mistral font\n2,000 synthetic signatures in Arial Unicode font\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nFor the development of models that can detect digital signatures in documentation using the publicly available DocusignÂ® font styles.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is organized into three folders:\n\nrage/ - Containsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Benjy/digital_signatures.","url":"https://huggingface.co/datasets/Benjy/digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"french-lot-department-captioned-photos","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tLot Department, France Image Dataset\n\t\n\nA collection of high-resolution scenic photographs from the Lot region of France with AI-generated descriptive captions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains scenic photographs from three notable locations in France's Lot department: Rocamadour, Autoire, and Padirac. All images were captured using a Sony A6600 camera and are paired with detailed English captions generated by Mistral AI's Pixtral-Large model.\nKey Features:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/french-lot-department-captioned-photos.","url":"https://huggingface.co/datasets/NoeFlandre/french-lot-department-captioned-photos","creator_name":"NoÃ© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-classification","object-detection","English"],"keywords_longer_than_N":true},
	{"name":"MS-HAB-SetTable","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tManiSkill-HAB SetTable Dataset\n\t\n\nPaper \n| Website \n| Code \n| Models \n| (Full) Dataset \n| Supplementary\n\n\nWhole-body, low-level control/manipulation demonstration dataset for ManiSkill-HAB SetTable.\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nDemonstration dataset for ManiSkill-HAB SetTable. Each subtask/object combination (e.g pick 013_apple) has 1000 successful episodes (200 samples/demonstration) gathered using RL policies fitered for safe robot behavior with aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arth-shukla/MS-HAB-SetTable.","url":"https://huggingface.co/datasets/arth-shukla/MS-HAB-SetTable","creator_name":"Arth Shukla","creator_url":"https://huggingface.co/arth-shukla","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["robotics","reinforcement-learning","grasping","task-planning","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ego4d-random-views-20k","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEgo4D Random Views Dataset\n\t\n\nThis dataset contains 20,000 random view frames sampled from the Ego4D dataset using a high-performance multi-process generation system.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\nTotal Images: 20,000 high-quality frames\nImage Format: PNG (1024Ã—1024 resolution)  \nSource: Ego4D v2 dataset (52,665+ video files)\nSampling Method: Multi-process random sampling with maximum diversity\nGeneration Time: 797.57 seconds (~13 minutes)\nGeneration Speed: 25.08 frames/secondâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/weikaih/ego4d-random-views-20k.","url":"https://huggingface.co/datasets/weikaih/ego4d-random-views-20k","creator_name":"Weikai Huang","creator_url":"https://huggingface.co/weikaih","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","object-detection","visual-question-answering","zero-shot-image-classification","English"],"keywords_longer_than_N":true},
	{"name":"human-cornea-snRNAseq","keyword":"vision","description":"\n\t\n\t\t\n\t\tHuman Cornea Atlas (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on the cellular heterogeneity of the human cornea. It provides a high-resolution view of various cell populations and their gene expression profiles across different layers of this critical ocular tissue.\nThe data was sourced from a research paper providing a comprehensive single-cell transcriptome atlas of the human cornea.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/human-cornea-snRNAseq.","url":"https://huggingface.co/datasets/longevity-db/human-cornea-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"home_decoration_objects_images","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tImage Description Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 5125 images with their corresponding descriptions in both long and short formats. \nThe descriptions were generated using the BLIP-large model.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal images: 5125\nAverage words in long description: 18.1\nAverage words in short description: 9.4\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nfile_name: Relative path to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AntZet/home_decoration_objects_images.","url":"https://huggingface.co/datasets/AntZet/home_decoration_objects_images","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"TUC-HRI-CS","keyword":"computer vision","description":"\n\nUniversity of Technology Chemnitz, Germany\nDepartment Robotics and Human Machine Interaction\nAuthor: Robert Schulz\n\n\t\n\t\t\n\t\tTUC-HRI Dataset Card\n\t\n\nTUC-AR is an action recognition dataset, containing 10(+1) action categories for human machine interaction. This version contains video sequences, stored as images, frame by frame.\nWe introduce two validation types: random validation and cross-subject validation. This is the cross-subject validation dataset. For random validation, please useâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SchulzR97/TUC-HRI-CS.","url":"https://huggingface.co/datasets/SchulzR97/TUC-HRI-CS","creator_name":"Robert Schulz","creator_url":"https://huggingface.co/SchulzR97","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"RV-PBS","keyword":"vision","description":"\n\t\n\t\t\n\t\tThe RV-PBS (Ramakrishna Vivekananda Peripheral Blood Smear) dataset\n\t\n\n\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nAutomating blood cell counting and detection from smear slides holds significant potential for aiding doctors in disease diagnosis through blood tests. However, existing literature has not adequately addressed using whole slide data in this context. This study introduces the novel RV-PBS dataset, comprising ten distinct peripheral blood smear classes, each featuring multiple multi-class Whiteâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jimut123/RV-PBS.","url":"https://huggingface.co/datasets/Jimut123/RV-PBS","creator_name":"Jimut Bahan Pal","creator_url":"https://huggingface.co/Jimut123","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":null,"first_N":5,"first_N_keywords":["image-segmentation","image-classification","zero-shot-classification","image-to-image","English"],"keywords_longer_than_N":true},
	{"name":"RV-PBS","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tThe RV-PBS (Ramakrishna Vivekananda Peripheral Blood Smear) dataset\n\t\n\n\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nAutomating blood cell counting and detection from smear slides holds significant potential for aiding doctors in disease diagnosis through blood tests. However, existing literature has not adequately addressed using whole slide data in this context. This study introduces the novel RV-PBS dataset, comprising ten distinct peripheral blood smear classes, each featuring multiple multi-class Whiteâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jimut123/RV-PBS.","url":"https://huggingface.co/datasets/Jimut123/RV-PBS","creator_name":"Jimut Bahan Pal","creator_url":"https://huggingface.co/Jimut123","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":null,"first_N":5,"first_N_keywords":["image-segmentation","image-classification","zero-shot-classification","image-to-image","English"],"keywords_longer_than_N":true},
	{"name":"cats_dogs_dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tCats and Dogs Image Classification Dataset\n\t\n\nThis dataset contains images of cats and dogs, intended for image classification tasks. It includes two classes: \"cats\" and \"dogs\".\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is structured into two splits:\n\ntrain: Contains 8000 images for training.\ntest: Contains 2000 images for testing.\n\nImages are stored in RGB format with a resolution of 128x128 pixels.\n\n\t\n\t\t\n\t\tData Loading and Usage\n\t\n\nThe dataset can be loaded using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louiecerv/cats_dogs_dataset.","url":"https://huggingface.co/datasets/louiecerv/cats_dogs_dataset","creator_name":"Louie Cervantes","creator_url":"https://huggingface.co/louiecerv","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DetailVariationsV1","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tImage Detail Manipulation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains sets of images designed for tasks involving controlled manipulation of image details or styles. Each set consists of one input image (representing a baseline detail level, 'f5') and nine corresponding edited versions ('f0' through 'f9'), each representing a different level detail.\nThe Dataset was realized using SDXL Upscaling and Refiner.\nAround 60% of the images used to create this Dataset come from third partyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Scaryplasmon96/DetailVariationsV1.","url":"https://huggingface.co/datasets/Scaryplasmon96/DetailVariationsV1","creator_name":"Andrea Cicero","creator_url":"https://huggingface.co/Scaryplasmon96","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"wine-images-126k","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tWine Images Dataset 126K\n\t\n\nA comprehensive dataset of 107,821 wine bottle images linked to the Wine Text Dataset 126K. This companion dataset provides high-quality wine bottle images for computer vision, multimodal machine learning, and wine recognition tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains wine bottle images scraped from wine retailer websites. Each image is linked to detailed wine information (descriptions, pricing, categories, regions) via stable IDs thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cipher982/wine-images-126k.","url":"https://huggingface.co/datasets/cipher982/wine-images-126k","creator_name":"David Rose","creator_url":"https://huggingface.co/cipher982","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","feature-extraction","image-to-text","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"OpenMind2D","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tOpenMind2D: 2D Brain MRI Slices\n\t\n\nOpenMind2D is a 2D medical imaging dataset derived from the OpenMind dataset. It contains 335,754 2D slices extracted from 3D brain MRI volumes in three anatomical orientations (axial, sagittal, coronal).\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Images: 335,754\nResolution: 256Ã—256 pixels\nFormat: JPEG\nSize: ~11.7 GB\nSplits: Train (70%), Validation (20%), Test (10%)\nOrientations: Axial, sagittal, coronal\nModalities: T1w, T2w, FLAIR, DWI, and 19+ additionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/liamchalcroft/OpenMind2D.","url":"https://huggingface.co/datasets/liamchalcroft/OpenMind2D","creator_name":"Liam Chalcroft","creator_url":"https://huggingface.co/liamchalcroft","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","zero-shot-image-classification","multi-class-image-classification","image-captioning"],"keywords_longer_than_N":true},
	{"name":"YorkUrban","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tYorkUrban Dataset\n\t\n\nThis is the YorkUrban dataset hosted on Hugging Face Hub.\n\n\t\n\t\t\n\t\tSummary\n\t\n\nYorkUrban dataset with image annotations including line segments.\nThe dataset is stored as jsonl files (test/metadata.jsonl) and images.\nNumber of samples:\n\nTrain: 0\nTest: 102\n\n\n\t\n\t\t\n\t\tDownload\n\t\n\n\nDownload with huggingface-hub\n\npython3 -m pip install huggingface-hub\nhuggingface-cli download --repo-type dataset lh9171338/Wireframe --local-dir ./\n\n\nDownload with Git\n\ngit lfs install\ngitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lh9171338/YorkUrban.","url":"https://huggingface.co/datasets/lh9171338/YorkUrban","creator_name":"Li Hao","creator_url":"https://huggingface.co/lh9171338","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"Wireframe","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tWireframe Dataset\n\t\n\nThis is the Wireframe dataset hosted on Hugging Face Hub.\n\n\t\n\t\t\n\t\tSummary\n\t\n\nWireframe dataset with image annotations including line segments.The dataset is stored as jsonl files (train/metadata.jsonl, test/metadata.jsonl) and images.\nNumber of samples:\n\nTrain: 5,000\nTest: 462\n\n\n\t\n\t\t\n\t\tDownload\n\t\n\n\nDownload with huggingface-hub\n\npython3 -m pip install huggingface-hub\nhuggingface-cli download --repo-type dataset lh9171338/Wireframe --local-dir ./\n\n\nDownload with Gitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lh9171338/Wireframe.","url":"https://huggingface.co/datasets/lh9171338/Wireframe","creator_name":"Li Hao","creator_url":"https://huggingface.co/lh9171338","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"geometric-shapes","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for Geometric Shapes Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Geometric Shapes Dataset is a synthetic dataset containing images of various geometric shapes with superimposed random text. Each image features a polygon (or just text) on a randomly colored background, with a short string of random characters partially obscuring the shape. This dataset is designed for tasks such as shape classification, image recognition, and robustness testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/0-ma/geometric-shapes.","url":"https://huggingface.co/datasets/0-ma/geometric-shapes","creator_name":"Olivier","creator_url":"https://huggingface.co/0-ma","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"grand_tour_dataset","keyword":"vision","description":"\n  \n  The GrandTour Dataset\n  \n\n\n  A project brought to you by RSL - ETH Zurich.\n\n\n  References â€¢\n  Contributing  â€¢\n  Citation\n\n\n\n\t\n\t\t\n\t\tReferences\n\t\n\n\nOfficial dataset webpage: grand-tour.leggedrobotics.com\nGetting started & examples: github.com/leggedrobotics/grand_tour_dataset\nBoxi used to collect the data: github.com/leggedrobotics/grand_tour_box\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tContributing\n\t\n\nWe warmly welcome contributions to improve and expand this project. Whether it's new examples, enhancements, orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/leggedrobotics/grand_tour_dataset.","url":"https://huggingface.co/datasets/leggedrobotics/grand_tour_dataset","creator_name":"Robotic Systems Lab - ETH ZÃ¼rich","creator_url":"https://huggingface.co/leggedrobotics","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","mit","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US","robotics"],"keywords_longer_than_N":true},
	{"name":"YOLOv8-Multiclass-Object-Detection-Dataset","keyword":"vision","description":"\n\t\n\t\t\n\t\tDATASET SAMPLE\n\t\n\nDuality.ai  just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free!\nJust create an EDU account here. \nThis HuggingFace dataset is a 20 image and label sample, but you can get the rest at no cost by creating a FalconCloud account. Once you verify your email, the link will redirect you to the dataset page.\nWhat makes this dataset unique, useful, and capable of bridging the Sim2Real gap?\n\nThe digital twins areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset.","url":"https://huggingface.co/datasets/duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset","creator_name":"Duality AI","creator_url":"https://huggingface.co/duality-robotics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"VisualTrans","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tVisualTrans: A Benchmark for Real-World Visual Transformation Reasoning\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nVisualTrans is the first comprehensive benchmark specifically designed for Visual Transformation Reasoning (VTR) in real-world human-object interaction scenarios. The benchmark encompasses 12 semantically diverse manipulation tasks and systematically evaluates three essential reasoning dimensions through 6 well-defined subtask types.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wyp-ucas/VisualTrans.","url":"https://huggingface.co/datasets/wyp-ucas/VisualTrans","creator_name":"WangYipu","creator_url":"https://huggingface.co/wyp-ucas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K<n<10K","Image"],"keywords_longer_than_N":true},
	{"name":"chess-pieces-dominique","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tChess Piece Detection Dataset: chess_pieces_dominique\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains chess piece detection annotations in YOLOv8 format.\nChess piece detection dataset from Dominique with 12 classes of chess pieces, optimized for YOLOv8 training.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the YOLOv8 format with the following structure:\n\ntrain/: Training images and labels\nvalid/: Validation images and labels\ntest/: Test images and labels\n\n\n\t\n\t\t\n\t\tClassesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dopaul/chess-pieces-dominique.","url":"https://huggingface.co/datasets/dopaul/chess-pieces-dominique","creator_name":"Dominique Paul","creator_url":"https://huggingface.co/dopaul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"ROVI","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tROVI: A VLM-LLM Re-Captioned Dataset for Open-Vocabulary Instance-Grounded Text-to-Image Generation\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nROVI is a high-quality synthetic dataset featuring 1M curated web images with comprehensive image descriptions and bounding box annotations. Using a novel VLM-LLM re-captioning strategy, ROVI exceeds existing detection-centric datasets in image description, quality, and resolution, while containing two orders of magnitude more categories with an open-vocabularyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CHang/ROVI.","url":"https://huggingface.co/datasets/CHang/ROVI","creator_name":"Cihang Peng","creator_url":"https://huggingface.co/CHang","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","1M<n<10M","arxiv:2508.01008"],"keywords_longer_than_N":true},
	{"name":"ROBOMASTER-2025-Energy-Mechanism-Video","keyword":"computer-vision","description":"\n  \n\n\n\nROBOMASTER-2025 Â· åŽåŒ—ç†å·¥å¤§å­¦ HORIZON æˆ˜é˜Ÿ Â· èƒ½é‡æœºå…³è¶…æ¸…è§†é¢‘æ•°æ®é›†\n\n\n\n\t\n\t\t\n\t\tðŸ“– æ¦‚è¿°\n\t\n\n\n\næ•°æ®æ¥æºï¼š åŽåŒ—ç†å·¥å¤§å­¦ HORIZON æˆ˜é˜Ÿ â€” é›·è¾¾ç»„ä¾æ‰˜å¹³å°ï¼š åŽåŒ—ç†å·¥ RM åˆ›æ–°å®žéªŒå®¤å½•åˆ¶æ—¶é—´åœ°ç‚¹ï¼š ROBOMASTER 2025 è¶…çº§å¯¹æŠ—èµ› Â· åŒ—äº¬ç†å·¥å¤§å­¦ï¼ˆç æµ·ï¼‰å—éƒ¨èµ›åŒº Â· å¤‡èµ›åŒºé›·è¾¾ç«™è°ƒè¯•é˜¶æ®µæ•°æ®ç”¨é€”ï¼š é€‚ç”¨äºŽèƒ½é‡æœºå…³ç›®æ ‡æ£€æµ‹ã€æ—‹è½¬é€Ÿåº¦ä¼°è®¡ã€è§†é¢‘è£å‰ªè®­ç»ƒç­‰ ROBOMASTER ç›¸å…³è§†è§‰ä»»åŠ¡  \n\n\n\nâš ï¸ è¯´æ˜Žï¼šè§†é¢‘æ‹æ‘„äºŽèµ›å‰è°ƒè¯•åŒºï¼Œè§†è§’ä¸Žæ­£å¼æ¯”èµ›é›·è¾¾ç«™å½•åƒä¸åŒã€‚æ•°æ®æœªé™„å¸¦æ ‡æ³¨ï¼Œè¯·æŒ‰éœ€è‡ªè¡Œæ ‡æ³¨ä¸Žè£å‰ªã€‚\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“· æ‹æ‘„è®¾å¤‡\n\t\n\n\n\t\n\t\t\nè®¾å¤‡ç±»åž‹\nåž‹å·\n\n\n\t\t\nç›¸æœº\næµ·åº·å¨è§† MV-CS200-10UC å·¥ä¸šç›¸æœº\n\n\né•œå¤´\nMVL-KF3528M-12MP\n\n\nåŽŸå§‹åˆ†è¾¨çŽ‡\n5472 Ã— 3648ï¼ˆæŽ¥è¿‘ 6Kï¼‰\n\n\nè§†è§’\nå›ºå®šæœºä½ï¼Œé›·è¾¾ç«™è§†è§’\n\n\n\t\n\n\n\n\t\n\t\n\t\n\t\tðŸ—‚ï¸ æ•°æ®æ¦‚è§ˆï¼ˆ4 æ®µï¼‰\n\t\n\n\nå®¹å™¨æ ¼å¼ï¼šAVIï¼›åˆ†è¾¨çŽ‡ï¼š5472 Ã— 3648ï¼ˆå››æ®µä¸€è‡´ï¼‰â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BreCaspian/ROBOMASTER-2025-Energy-Mechanism-Video.","url":"https://huggingface.co/datasets/BreCaspian/ROBOMASTER-2025-Energy-Mechanism-Video","creator_name":"Yaosir","creator_url":"https://huggingface.co/BreCaspian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","object-detection","video-classification","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"onthelook-fashion-anchor-positive-images","keyword":"vision","description":"yainage90/onthelook-fashion-anchor-positive-images dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yainage90/onthelook-fashion-anchor-positive-images","creator_name":"yainage90","creator_url":"https://huggingface.co/yainage90","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"azerbaijani-cuisine","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAzerbaijani Cuisine Dataset\n\t\n\nA curated image dataset of traditional Azerbaijani dishes for computer vision and image classification tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains images of five traditional Azerbaijani dish categories. It is organized into standard training, validation, and test splits to facilitate machine learning model development and evaluation.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\n5 Food Categories: Dolma, Kebabs, Pakhlava, Plov, and Soups\n324 Total Images: Properlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ARMammadli/azerbaijani-cuisine.","url":"https://huggingface.co/datasets/ARMammadli/azerbaijani-cuisine","creator_name":"ARMammadli","creator_url":"https://huggingface.co/ARMammadli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"skin-lesion-segmentation-classification","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸ”— Usage with ðŸ¤— Datasets Library\n\t\n\n# ==============================================================================\n# Final and reliable method â€” clean dataset structure, no .cast() required\n# ==============================================================================\n\n# Step 1: Install the Hugging Face datasets library\n!pip install datasets -q\n\n# Step 2: Download and unzip the dataset (recommended method)\nimport requests\nfrom zipfile import ZipFile\nfrom io import BytesIO\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/makhresearch/skin-lesion-segmentation-classification.","url":"https://huggingface.co/datasets/makhresearch/skin-lesion-segmentation-classification","creator_name":"Majid Khorramgah","creator_url":"https://huggingface.co/makhresearch","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","image-segmentation","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"FakeParts","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tFakeParts: A New Family of AI-Generated DeepFakes\n\t\n\n\n\n\n\n\n\n  \n\n\n\n  \n\n\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nWe introduce FakeParts, a new class of deepfakes characterized by subtle, localized manipulations to specific spatial regions or temporal segments of otherwise authentic videos. Unlike fully synthetic content, these partial manipulations, ranging from altered facial expressions to object substitutions and background modifications, blend seamlessly with real elements, making them particularlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hi-paris/FakeParts.","url":"https://huggingface.co/datasets/hi-paris/FakeParts","creator_name":"Hi! PARIS","creator_url":"https://huggingface.co/hi-paris","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","English","cc0-1.0","10K - 100K","Video"],"keywords_longer_than_N":true},
	{"name":"F-Wireframe","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tF-Wireframe Dataset\n\t\n\n\n    âœï¸ GithubÂ Â  | Â Â ðŸ“‘ Paper Â Â  | Â Â ðŸ–¼ï¸ Viewer\n\n\nThis is the F-Wireframe dataset, designed for fisheye image line segment detection.\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\nThe F-Wireframe dataset is derived from the Wireframe dataset by distorting images with the fisheye distortion model, where the fisheye distortion coefficient of each image is randomly generated.\nNumber of samples:\n\nTrain: 5,000\nTest: 462\n\n\n\t\n\t\n\t\n\t\tDownload\n\t\n\n\nDownload with huggingface-hub\n\npython3 -m pipâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lh9171338/F-Wireframe.","url":"https://huggingface.co/datasets/lh9171338/F-Wireframe","creator_name":"Li Hao","creator_url":"https://huggingface.co/lh9171338","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"HSRD-100","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tHSRD-100: 100 High-Quality 3D Human Scans Dataset from HumanScanRepository\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHSRD-100 is a comprehensive 3D human scan dataset featuring 100 high-quality poses from 10 diverse individuals. This dataset provides a balanced representation of human demographics and poses, making it ideal for computer vision, machine learning, and 3D modeling applications.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotal Poses: 100\nUnique Individuals: 10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/digitalrealitylab/HSRD-100.","url":"https://huggingface.co/datasets/digitalrealitylab/HSRD-100","creator_name":"Digital Reality Lab","creator_url":"https://huggingface.co/digitalrealitylab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["keypoint-detection","image-classification","text-to-3d","image-to-3d","other"],"keywords_longer_than_N":true},
	{"name":"MS-HAB-PrepareGroceries","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tManiSkill-HAB PrepareGroceries Dataset\n\t\n\nPaper \n| Website \n| Code \n| Models \n| (Full) Dataset \n| Supplementary\n\n\nWhole-body, low-level control/manipulation demonstration dataset for ManiSkill-HAB PrepareGroceries.\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nDemonstration dataset for ManiSkill-HAB PrepareGroceries. Each subtask/object combination (e.g pick 002_master_chef_can) has 1000 successful episodes (200 samples/demonstration) gathered using RL policies fiteredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arth-shukla/MS-HAB-PrepareGroceries.","url":"https://huggingface.co/datasets/arth-shukla/MS-HAB-PrepareGroceries","creator_name":"Arth Shukla","creator_url":"https://huggingface.co/arth-shukla","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["robotics","reinforcement-learning","grasping","task-planning","machine-generated"],"keywords_longer_than_N":true},
	{"name":"m-hood-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tM-Hood Dataset: Out-of-Distribution Evaluation Collection\n\t\n\nThis dataset collection contains out-of-distribution (OOD) image datasets specifically curated for evaluating the robustness of object detection models, particularly those trained to mitigate hallucination on out-of-distribution data.\n\n\t\n\t\t\n\t\tðŸŽ¯ Purpose\n\t\n\nThese datasets are designed to address limitations in existing OOD benchmarks and enable fine-grained analysis of hallucination suppression. They test how well objectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HugoHE/m-hood-dataset.","url":"https://huggingface.co/datasets/HugoHE/m-hood-dataset","creator_name":"WeichengHE","creator_url":"https://huggingface.co/HugoHE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"EmbodiedOcc-ScanNet","keyword":"computer-vision","description":"This repository contains the EmbodiedOcc-ScanNet dataset, which is a reorganized benchmark based on local annotations, designed to facilitate the evaluation of the embodied 3D occupancy prediction task. It accompanies the paper EmbodiedOcc: Embodied 3D Occupancy Prediction for Vision-based Online Scene Understanding.\nProject page: https://ykiwu.github.io/EmbodiedOcc/\nCode: https://github.com/YkiWu/EmbodiedOcc\n\n\t\n\t\t\n\t\n\t\n\t\tPaper Abstract\n\t\n\n3D occupancy prediction provides a comprehensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YkiWu/EmbodiedOcc-ScanNet.","url":"https://huggingface.co/datasets/YkiWu/EmbodiedOcc-ScanNet","creator_name":"YkiWu","creator_url":"https://huggingface.co/YkiWu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","arxiv:2412.04380","ðŸ‡ºðŸ‡¸ Region: US","3d-occupancy-prediction"],"keywords_longer_than_N":true},
	{"name":"volga2k","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tVolga2K dataset\n\t\n\nIn our cmKAN paper, we presented a large-scale Volga2K dataset captured using a Huawei P40 Pro phone wich containts 1263 well well-aligned image paires (more than 2K images in total).  This device was specifically chosen because it features two distinct cameras with different sensor types: Quad-Bayer RGGB sensor (Sony IMX700) and RYYB sensor (Sony IMX608). These differences in sensor types result in varying image processing algorithms, with the RGGB and RYYB sensorsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gosha20777/volga2k.","url":"https://huggingface.co/datasets/gosha20777/volga2k","creator_name":"Georgy Perevozchikov","creator_url":"https://huggingface.co/gosha20777","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-image","English","Russian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"FaceCaption-15M","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tFacaCaption-15M\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] ðŸ¤—The Original Images, are Released Completing Agreement\n\n\nFaceCaption-15M, a large-scale, diverse, and high-quality dataset of facial images accompanied by their natural language descriptionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M.","url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"analog_clocks_combinations_for_finetuning","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAnalog Clocks Combinations Dataset for Finetuning\n\t\n\nThis repository hosts a collection of 43,200 high-quality, synthetic images of analog clocks, generated for every possible hour, minute, and second in a 12-hour cycle, and for each of three clock types:\n\nBase: normal clocks.\nDistorted: dial with distorted shape.\nModified hands: hands with the same thickness and with an arrow.\n\nThe data is useful for training and benchmarking computer vision models on tasks like time recognitionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/migonsa/analog_clocks_combinations_for_finetuning.","url":"https://huggingface.co/datasets/migonsa/analog_clocks_combinations_for_finetuning","creator_name":"Miguel GonzÃ¡lez","creator_url":"https://huggingface.co/migonsa","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","cc-by-4.0","100K - 1M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"2HANDS","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for 2HANDS\n\t\n\n\n2HANDS is the 2-Handed Affordance + Narration DataSet, consisting of a large number of unimanual and bimanual object affordance segmentation masks and task narrations as affordance class-labels.  \n\nProject Site https://sites.google.com/view/2handedafforder (ICCV 2025)\nPaper: https://arxiv.org/abs/2503.09320\nRepository: Coming soon\n\nEgocentric images and narrations/verb classes are derived from the EPIC-KITCHENS dataset and EPIC-VISOR annotations [1, 2].[1]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sjauhri/2HANDS.","url":"https://huggingface.co/datasets/sjauhri/2HANDS","creator_name":"Snehal Jauhri","creator_url":"https://huggingface.co/sjauhri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","arxiv:2503.09320","ðŸ‡ºðŸ‡¸ Region: US","computer-vision"],"keywords_longer_than_N":true},
	{"name":"MusiXQA","keyword":"vision","description":"\n\t\n\t\t\n\t\tMusiXQA ðŸŽµ\n\t\n\nMusiXQA is a multimodal dataset for evaluating and training music sheet understanding systems. Each data sample is composed of:\n\nA scanned music sheet image (.png)\nIts corresponding MIDI file (.mid)\nA structured annotation (from metadata.json)\nQuestionâ€“Answer (QA) pairs targeting musical structure, semantics, and optical music recognition (OMR)\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‚ Dataset Structure\n\t\n\nMusiXQA/\nâ”œâ”€â”€ images.tar             # PNG files of music sheets (e.g., 0000000.png)\nâ”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/puar-playground/MusiXQA.","url":"https://huggingface.co/datasets/puar-playground/MusiXQA","creator_name":"Jian Chen","creator_url":"https://huggingface.co/puar-playground","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","arxiv:2506.23009","ðŸ‡ºðŸ‡¸ Region: US","music"],"keywords_longer_than_N":true},
	{"name":"pollinator-insects-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tPollinator Insects Dataset ðŸ¦‹\n\t\n\n\n\n\n\n\n\nComprehensive dataset of 10 pollinator insect species for computer vision and biodiversity researchðŸ¤– Trained Model â€¢ ðŸ“Š Dataset Viewer â€¢ ðŸ“– Repository\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Pollinator Insects Dataset is a curated collection of 8,983 high-resolution images representing 10 ecologically important pollinator species. This dataset was specifically designed for:\n\nðŸ”¬ Biodiversity research and species monitoring\nðŸ¤– Computer vision modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/leonelgv/pollinator-insects-dataset.","url":"https://huggingface.co/datasets/leonelgv/pollinator-insects-dataset","creator_name":"Leonel Gonzalez Vidales","creator_url":"https://huggingface.co/leonelgv","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"ai-tool-pool-jewelry-vision","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAI Tool Pool Jewelry Vision Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 5,130 jewelry images organized into 5 categories for computer vision tasks. The dataset was originally created and hosted on Roboflow Universe.\n\n\t\n\t\t\n\t\tCategories\n\t\n\n\nBracelet: Bracelet jewelry images\nEarrings: Earring jewelry images  \nNecklace: Necklace jewelry images\nPendant: Pendant jewelry images\nRing: Ring jewelry images\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nAI-Tool-Pool-Jewelry-Vision/\nâ”œâ”€â”€ train/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzcasper/ai-tool-pool-jewelry-vision.","url":"https://huggingface.co/datasets/bzcasper/ai-tool-pool-jewelry-vision","creator_name":"Robert Casper","creator_url":"https://huggingface.co/bzcasper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SS360","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSS360 Dataset\n\t\n\n\n    âœï¸ GithubÂ Â  | Â Â ðŸ“‘ Paper Â Â  | Â Â ðŸ–¼ï¸ Viewer\n\n\n\nThis is the SS360 dataset, designed for spherical image line segment detection.\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe SS360 dataset is constructed by manually annotating images sourced from the SUN360 dataset and the Stanford 2D-3D-S dataset. It is organized into JSONL files (train/metadata.jsonl, test/metadata.jsonl) along with the corresponding images.\nNumber of samples:\n\nTrain: 950\nTest: 118\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\n\nDownload withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lh9171338/SS360.","url":"https://huggingface.co/datasets/lh9171338/SS360","creator_name":"Li Hao","creator_url":"https://huggingface.co/lh9171338","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"MBZUAI-Campus","keyword":"computer vision","description":"This dataset provides the necessary files and scripts to reconstruct the MBZUAI campus using COLMAP, GLOMAP, and NERFstudio. It contains preprocessed video sequences and metadata required for hierarchical 3D reconstruction.\n\nThe dataset includes:\n- Raw video sequences\n- Preprocessed frames\n- Calibration and metadata\n- Reconstruction scripts\n\nThe hierarchical reconstruction starts with a base structure, followed by incremental updates with additional sequences.\n","url":"https://huggingface.co/datasets/sebothetramp/MBZUAI-Campus","creator_name":"Sebastian Cavada","creator_url":"https://huggingface.co/sebothetramp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","robotics","other","English","mit"],"keywords_longer_than_N":true},
	{"name":"lanternfly-detection","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSpotted Lanternfly Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 33 images of spotted lanternflies and non-lanternfly subjects, cropped to 224x224 pixels for machine learning model training. The dataset includes both original images and augmented versions created using various data augmentation techniques to improve model robustness and generalization.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset is designed for training computer vision models to detect spottedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rlogh/lanternfly-detection.","url":"https://huggingface.co/datasets/rlogh/lanternfly-detection","creator_name":"Rumi Loghmani","creator_url":"https://huggingface.co/rlogh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","expert-generated","English"],"keywords_longer_than_N":true},
	{"name":"adversarial-mnist","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMNIST with Adversarial Examples\n\t\n\nThis dataset contains MNIST images with both normal and adversarial examples.\nThe dataset includes:\n\nOriginal MNIST digit images (28x28 pixels, flattened to 784 features)\nAdversarial examples generated from the original images\nLabels for digit classification (0-9)\nBinary flag indicating whether each sample is adversarial\n\nFeatures:\n\nlabel: Digit class (0-9)\npixels 0-783: Flattened 28x28 grayscale pixel values\nis_adversarial: Binary flag (0 = normal, 1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wambosec/adversarial-mnist.","url":"https://huggingface.co/datasets/wambosec/adversarial-mnist","creator_name":"Denis Wambold","creator_url":"https://huggingface.co/wambosec","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","other","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"DEEPFRUlT_DATASET","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tDeepFruit Dataset\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains total of 21,122 fully labeled images, featuring 20 different kinds of fruits. It is structured into an 80% training set (16,899 images) and a 20% testing set (4,223 images), facilitating a ready-to-use framework for model training and evaluation.\nAdditionally, there are two CSV files that label the types of fruits depicted in each image.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe \"DeepFruit\" dataset is a comprehensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET.","url":"https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET","creator_name":"shangrong chi","creator_url":"https://huggingface.co/sc890","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"chess-pieces-roboflow","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tChess Piece Detection Dataset: chess_pieces_roboflow\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains chess piece detection annotations in YOLOv8 format.\nChess piece detection dataset from Roboflow with processed labels, cleaned and standardized for YOLOv8 format.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the YOLOv8 format with the following structure:\n\ntrain/: Training images and labels\nvalid/: Validation images and labels\ntest/: Test images and labels\n\n\n\t\n\t\t\n\t\tClassesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dopaul/chess-pieces-roboflow.","url":"https://huggingface.co/datasets/dopaul/chess-pieces-roboflow","creator_name":"Dominique Paul","creator_url":"https://huggingface.co/dopaul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"RobustAD","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tRobustAD Dataset\n\t\n\n\n\t\n\t\t\n\t\tAbout the Dataset\n\t\n\nRobustAD, specifically designed to evaluate the robustness of anomaly detection models in real-world scenarios. RobustAD features a curated dataset of defect detection images with meticulously controlled distribution shifts across multiple dimensions relevant to practical applications and more closely mirrors real-world deployment scenarios.\nRobustAD is designed to cover inspection challenges across multiple industries to ensure theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/RobustAD.","url":"https://huggingface.co/datasets/AmazonScience/RobustAD","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"fer2013-cleaned","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tFER2013 Cleaned and Extended â€“ mehmet-3emin\n\t\n\nThis dataset is a cleaned and extended version of the original FER2013 dataset, adapted for facial emotion recognition tasks. It was prepared as part of a senior thesis project at Mersin University in 2025, titled \"Videodan DuygusallÄ±k Analizi\" (Emotion Analysis from Video).\nThe dataset is formatted for folder-based image classification tasks and includes 7 emotion classes.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§¹ Cleaning Process\n\t\n\nThe original FER2013 datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mehmet-3emin/fer2013-cleaned.","url":"https://huggingface.co/datasets/mehmet-3emin/fer2013-cleaned","creator_name":"Mehmet Emin","creator_url":"https://huggingface.co/mehmet-3emin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["mit","ðŸ‡ºðŸ‡¸ Region: US","emotion-detection","facial-expression","computer-vision"],"keywords_longer_than_N":true},
	{"name":"hw1-24679-image-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tAsian vs Western Food Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPurpose: This dataset was created for binary classification of food images into Asian or Western cuisine categories, developed as part of CMU 24-679 coursework to explore computer vision techniques in food recognition.\nQuick Stats:\n\n360 total images (40 original + 320 augmented)\nBinary classification task\n224x224 RGB images\nBalanced classes (~50% each category)\n\nContact: maryzhang@cmu.edu\n\n\t\n\t\t\n\t\n\t\n\t\tSampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maryzhang/hw1-24679-image-dataset.","url":"https://huggingface.co/datasets/maryzhang/hw1-24679-image-dataset","creator_name":"Mary Zhang","creator_url":"https://huggingface.co/maryzhang","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","found","original"],"keywords_longer_than_N":true},
	{"name":"GeoDE","keyword":"vision","description":"Official Paper\nNumber of country classes: 40Total number of images: 61925  \n\n\t\n\t\t\n\t\tImage count per country_ip class\n\t\n\n\n\t\n\t\t\nCountry\nNumber of Images\n\n\n\t\t\nAngola\n10\n\n\nArgentina\n3193\n\n\nBotswana\n3\n\n\nBrazil\n16\n\n\nBulgaria\n1\n\n\nCameroon\n1\n\n\nChina\n1565\n\n\nColombia\n3703\n\n\nEgypt\n2449\n\n\nFrance\n59\n\n\nGhana\n1\n\n\nGreece\n45\n\n\nIndonesia\n5311\n\n\nIreland\n2\n\n\nItaly\n3933\n\n\nJapan\n6500\n\n\nJordan\n43\n\n\nMalaysia\n55\n\n\nMexico\n2723\n\n\nMoldova\n2\n\n\nNetherlands\n18\n\n\nNigeria\n5729\n\n\nPhilippines\n2906\n\n\nPoland\n68\n\n\nPortugal\n139â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MLap/GeoDE.","url":"https://huggingface.co/datasets/MLap/GeoDE","creator_name":"aman prakash","creator_url":"https://huggingface.co/MLap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"deepfake-detection-dataset-v2","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDeepfake Detection Dataset V2\n\t\n\nThis dataset contains images and detailed explanations for training and evaluating deepfake detection models. It includes original images, manipulated images, confidence scores, and comprehensive technical and non-technical explanations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of:\n\nOriginal images\nCAM visualization images \nCAM overlay images\nComparison images\nLabels (real/fake)\nConfidence scores\nImage captions\nTechnical and non-technicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v2.","url":"https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v2","creator_name":"Saakshi Gupta","creator_url":"https://huggingface.co/saakshigupta","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"biomed-VQA-benchmark","keyword":"vision","description":"\n\t\n\t\t\n\t\tAdapting Multimodal Large Language Models to Domains via Post-Training (EMNLP 2025)\n\t\n\nThis repos contains the biomedical visual instruction tasks for evaluating MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\nThe main project page is: Adapt-MLLM-to-Domains\n\n\t\n\t\t\n\t\n\t\n\t\t1. Download Data\n\t\n\nYou can load datasets using the datasets library:  \nfrom datasets import load_dataset\n\n# Choose the task name from the list of available tasks\ntask_name =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/biomed-VQA-benchmark.","url":"https://huggingface.co/datasets/AdaptLLM/biomed-VQA-benchmark","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","10K - 100K","arrow"],"keywords_longer_than_N":true},
	{"name":"Facecaption-15M-Embeddings","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tFacecaption-15M-Embeddings\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] ðŸ¤—The Original Images, are Released Completing Agreement\nWe chose about 5M image-text pairs with the highest resolution from Facecaption-15M, extracted the embeddings of the [CLS]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings.","url":"https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"deepfake-detection-dataset-v3","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDeepfake Detection Dataset V3\n\t\n\nThis dataset contains images and detailed explanations for training and evaluating deepfake detection models. It includes original images, manipulated images, confidence scores, and comprehensive technical and non-technical explanations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of:\n\nOriginal images (image)\nCAM visualization images (cam_image)\nCAM overlay images (cam_overlay)\nComparison images (comparison_image)\nLabels (label): Binaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v3.","url":"https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v3","creator_name":"Saakshi Gupta","creator_url":"https://huggingface.co/saakshigupta","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"dtd_split_1","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for Describable Textures Dataset (DTD)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTexture classification dataset; consists of 47 categories, 120 images per class.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nEqually split into train, val, test; The original paper proposed 10 splits; recent works (BYOL, arxiv:2006.07733) use only first split.\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nNot defined at https://www.robots.ox.ac.uk/~vgg/data/dtd/\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n @InProceedings{cimpoi14describingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mcimpoi/dtd_split_1.","url":"https://huggingface.co/datasets/mcimpoi/dtd_split_1","creator_name":"Mircea Cimpoi","creator_url":"https://huggingface.co/mcimpoi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fashionpedia_4_categories","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia_4_categories\n\t\n\nThis dataset is a variation of the fashionpedia dataset available here, with 2 key differences:\n\nIt contains only 4 categories:\nClothing\nShoes\nBags\nAccessories\n\n\nNew splits were created:\nTrain: 90% of the images\nVal: 5%\nTest 5%\n\n\n\nThe goal is to make the detection task easier with 4 categories instead of 46 for the full fashionpedia dataset.\nThis dataset was created using the detection_datasets library (GitHub, PyPI), you can check here theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories.","url":"https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","monolingual","fashionpedia","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"blip3-ocr-200m","keyword":"vision","description":"\n\t\n\t\t\n\t\tBLIP3-OCR-200M Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe BLIP3-OCR-200M dataset is designed to address the limitations of current Vision-Language Models (VLMs) in processing and interpreting text-rich images, such as documents and charts. Traditional image-text datasets often struggle to capture nuanced textual information, which is crucial for tasks requiring complex text comprehension and reasoning. \n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nOCR Integration: The dataset incorporates Optical Characterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-ocr-200m.","url":"https://huggingface.co/datasets/Salesforce/blip3-ocr-200m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"negativesirl","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tCMU Campus Negative Images Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains negative example images collected around Carnegie Mellon University campus in Pittsburgh, Pennsylvania. These images represent non-lanternfly subjects that were used as negative training data for binary classification models. The dataset was created as part of an academic project (Project 1) focused on developing machine learning models for invasive species identification.\n\n\t\n\t\t\n\t\tDataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rlogh/negativesirl.","url":"https://huggingface.co/datasets/rlogh/negativesirl","creator_name":"Rumi Loghmani","creator_url":"https://huggingface.co/rlogh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","object-detection","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"allava4v-train-regenerated","keyword":"vision","description":"\n\t\n\t\t\n\t\tALLaVA-4V Train Dataset (Regenerated)\n\t\n\nThis dataset is a regenerated version of the ALLaVA-4V training dataset, processed using Qwen/Qwen3-VL-8B-Instruct model.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: ALLaVA-4V training data\nModel Used: Qwen/Qwen3-VL-8B-Instruct\nOriginal Format: JSONL (252,924 samples)\nOutput Format: Parquet\nTemperature: 0.0 (deterministic generation)\nProcessing Status: In progress (~21% complete as of upload)\n\n\n\t\n\t\t\n\t\n\t\n\t\tGeneration Details\n\t\n\nThe dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vincent-4/allava4v-train-regenerated.","url":"https://huggingface.co/datasets/vincent-4/allava4v-train-regenerated","creator_name":"Vincent","creator_url":"https://huggingface.co/vincent-4","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Korean_User_Manuals_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean User Manuals Dataset\n\t\n\nThis dataset contains high-resolution images and PDFs of Korean user manuals and instruction guides for electronics, appliances, and consumer products. It is curated and anonymized to support AI research in OCR, document understanding, and multilingual text extraction.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:  \n\nDocumentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean_User_Manuals_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean_User_Manuals_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Korean","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Korean_Menus_Image_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Menus Image Dataset\n\t\n\nThis dataset contains high-resolution images of Korean restaurant menus, including traditional, fast-food, and cafÃ© menus. It has been curated and anonymized to support AI research in OCR, menu understanding, multilingual translation, and food recommendation systems.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:  \n\nImageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean_Menus_Image_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean_Menus_Image_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Korean_Handwritten_Notes_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Handwritten Notes Dataset\n\t\n\nThis dataset contains high-resolution images of Korean handwritten notes, including personal notes, class notes, and informal writings. The dataset has been anonymized and curated to support AI research in handwriting recognition, OCR, and document understanding.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:  \n\nImageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean_Handwritten_Notes_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean_Handwritten_Notes_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Korean-Billboards-Image-Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Billboards Image Dataset\n\t\n\nThis dataset contains high-quality images of Korean billboards, collected from diverse regions and media types including digital boards, street hoardings, transit ads, and building-mounted displays. It supports AI research in OCR, advertising analytics, and multimodal vision-language understanding.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean-Billboards-Image-Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean-Billboards-Image-Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Korean_Price_Tags_Image_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Price Tags Image Dataset\n\t\n\nThis dataset contains high-resolution images of Korean price tags found in retail stores, supermarkets, and markets. It has been curated and anonymized to support AI research in OCR, pricing recognition, product detection, and retail analytics.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:  \n\nImage Classification  \nTextâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean_Price_Tags_Image_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean_Price_Tags_Image_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"fullbodyvit-updated-Cremoved","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tFull Body ViT Dataset (Updated)\n\t\n\nThis dataset contains 24654 training images and 66 test images for jewelry type classification.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nTrain split: 24654 images\nTest split: 66 images\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nimage: PIL Image\njewelry_type: string label\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"SnapwearAI/fullbodyvit-updated-Cremoved\")\n\n# Access train split\ntrain_data = dataset[\"train\"]\n\n# Access test split\ntest_data =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SnapwearAI/fullbodyvit-updated-Cremoved.","url":"https://huggingface.co/datasets/SnapwearAI/fullbodyvit-updated-Cremoved","creator_name":"SNAPWEAR","creator_url":"https://huggingface.co/SnapwearAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation","keyword":"vision","description":"\n\t\n\t\t\n\t\tDrone-based Agricultural Dataset for Crop Yield Estimation\n\t\n\nThis repository contains a comprehensive dataset of cashew, cocoa and coffee images captured by drones, accompanied by meticulously annotated labels. To facilitate object detection, each image is paired with a corresponding text file in YOLO format. The YOLO format file contains annotations, including class labels and bounding box coordinates.\nThe dataset was collected by teams from Ghana (KaraAgro AI) and Uganda (Makerereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KaraAgroAI/Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation.","url":"https://huggingface.co/datasets/KaraAgroAI/Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation","creator_name":"KaraAgro AI Foundation","creator_url":"https://huggingface.co/KaraAgroAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","Image","Text","doi:10.57967/hf/0959"],"keywords_longer_than_N":true},
	{"name":"taste-rob-dressingtable","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob Dressingtable Video Dataset\n\t\n\nThis dataset contains 264 videos from the Dressingtable scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-dressingtable\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-dressingtable","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"DRIFT-TL-Distill-4K","keyword":"vision","description":"\n\t\n\t\t\n\t\tDRIFT-TL-Distill-4K Dataset\n\t\n\nThis dataset contains multimodal reasoning examples with images and step-by-step thinking processes.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nmessages: Conversation between user and assistant with image references\nimages: Paths to associated images\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ChaoHuangCS/DRIFT-TL-Distill-4K\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite our paper.\n","url":"https://huggingface.co/datasets/ChaoHuangCS/DRIFT-TL-Distill-4K","creator_name":"Chao Huang","creator_url":"https://huggingface.co/ChaoHuangCS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Brazilian_Item_Price_and_Description_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tBrazilian Item Price and Description Dataset\n\t\n\nThis dataset contains high-resolution images and structured text data of product price tags and item descriptions collected from Brazilian retail stores and e-commerce platforms. It enables AI research in OCR, product recognition, and retail analytics for the Portuguese-speaking market.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Brazilian_Item_Price_and_Description_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Brazilian_Item_Price_and_Description_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Portuguese","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"russian-celebrities","keyword":"computer-vision","description":"    # Russian Singers Dataset\n    \n    - Total persons: 410\n    - Total images: 31844\n    - Sources: {'yandex': 17286, 'google': 4137, 'wiki': 889, 'bing_image_downloader': 9532, 'unknown': 0}\n    \n    Generated automatically.\n    \n\n","url":"https://huggingface.co/datasets/Vasyliy/russian-celebrities","creator_name":"Ð’Ð°ÑÐ¸Ð»Ð¸Ð¹","creator_url":"https://huggingface.co/Vasyliy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Russian","mit","ðŸ‡ºðŸ‡¸ Region: US","faces","celebrities"],"keywords_longer_than_N":true},
	{"name":"dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tPhysics and Video Analysis Dataset Collection\n\t\n\nThis dataset collection contains two important datasets for physics understanding and video analysis:\n\n\t\n\t\t\n\t\t1. Physics 101 Dataset (v1.0)\n\t\n\nThe Physics 101 Dataset captures physical interactions of objects through video recordings. This dataset consists of five different scenarios involving 101 objects made of different materials with varying masses and volumes.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tObjects\n\t\n\nThe dataset includes 101â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bitmind/dataset.","url":"https://huggingface.co/datasets/bitmind/dataset","creator_name":"BitMind","creator_url":"https://huggingface.co/bitmind","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","English","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Korean_Product_Labels_Image_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tKorean Product Labels Image Dataset\n\t\n\nThis dataset contains a diverse collection of high-resolution images of Korean product labels and packaging. The dataset spans categories such as food, cosmetics, beverages, and household items, designed to support OCR, product classification, and visual-language AI research.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTaskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Korean_Product_Labels_Image_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Korean_Product_Labels_Image_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Korean","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"taste-rob-dinning-77015-to-101800","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob dinning_77015_to_101800 Video Dataset\n\t\n\nThis dataset contains 4293 videos from the dinning_77015_to_101800 scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-dinning-77015-to-101800\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-dinning-77015-to-101800","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","English","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"taste-rob-bedroom","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTASTE-Rob Bedroom Video Dataset\n\t\n\nThis dataset contains 157 videos from the Bedroom scene of TASTE-Rob dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom huggingface_hub import hf_hub_download\n\n# Download a specific video\nvideo_path = hf_hub_download(\n    repo_id=\"charlychan123/taste-rob-bedroom\",\n    filename=\"video_name.mp4\",\n    repo_type=\"dataset\"\n)\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the original TASTE-Rob paper.\n","url":"https://huggingface.co/datasets/charlychan123/taste-rob-bedroom","creator_name":"chen xiaoyu","creator_url":"https://huggingface.co/charlychan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"English-Handwritten-Math-Notes-Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEnglish Handwritten Math Notes Dataset\n\t\n\nThis dataset contains high-resolution images of handwritten mathematical notes written in English. It includes problem statements, worked examples, formulas, and annotated derivations. The dataset supports AI research in handwriting recognition, mathematical OCR, and document understanding for STEM applications.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.ioâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/English-Handwritten-Math-Notes-Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/English-Handwritten-Math-Notes-Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","1K<n<10K","Document"],"keywords_longer_than_N":true},
	{"name":"COCOA","keyword":"computer-vision","description":"COCOA dataset targets amodal segmentation, which aims to recognize and segment objects beyond their visible parts. This dataset includes labels not only for the visible parts of objects, but also for their occluded parts hidden by other objects. This enables learning to understand the full shape and position of objects.","url":"https://huggingface.co/datasets/shunk031/COCOA","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","cc-by-4.0","arxiv:1509.01329","ðŸ‡ºðŸ‡¸ Region: US","computer-vision"],"keywords_longer_than_N":true},
	{"name":"flowers102","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tOxford 102 Flowers (Custom Split)\n\t\n\nThis dataset re-packages the Oxford 102 Flowers dataset with a custom train/validation/test\nsplit produced by src.data.upload_flowers102.\n\n\t\n\t\t\n\t\tSplit Ratios\n\t\n\n\nTrain: 80.00%\nValidation: 10.00%\nTest: 10.00%\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nOriginal images and annotations come from the Oxford 102 Flowers dataset, as distributed\non the Hugging Face Hub under pytorch/oxford-flowers.\n","url":"https://huggingface.co/datasets/pufanyi/flowers102","creator_name":"Pu Fanyi","creator_url":"https://huggingface.co/pufanyi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","pytorch/oxford-flowers","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"pool-detection","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tPool Detection Dataset\n\t\n\nThis is a YOLO format dataset for object detection tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\npool/\n  train/\n    images/\n    labels/\n  valid/\n    images/\n    labels/\n  test/\n    images/\n    labels/\n  data.yaml\n\n\n\t\n\t\t\n\t\tClasses\n\t\n\nThe dataset contains 16 classes representing pool balls (numbered 0-15).\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tIn Python\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"nhantu2107/pool-detection\")\n\n\n\t\n\t\t\n\t\tIn Kaggle\n\t\n\n\nGo to your Kaggleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nhantu2107/pool-detection.","url":"https://huggingface.co/datasets/nhantu2107/pool-detection","creator_name":"The Nhan","creator_url":"https://huggingface.co/nhantu2107","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["object-detection","mit","n<1K","ðŸ‡ºðŸ‡¸ Region: US","yolo"],"keywords_longer_than_N":true},
	{"name":"smapper-light","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸ“‚ SMapper-light Dataset\n\t\n\nSMapper-light is a publicly available multimodal dataset collected using the SMapper platform, an open-hardware, multi-sensor device designed for SLAM (Simultaneous Localization and Mapping) research.\nThe dataset provides synchronized LiDAR, multi-camera, and IMU measurements, enabling benchmarking of visual, LiDAR, and visualâ€“inertial SLAM methods.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸš€ Applications\n\t\n\nSMapper-light can be used for:  \n\nBenchmarking LiDAR SLAM frameworks (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/snt-arg/smapper-light.","url":"https://huggingface.co/datasets/snt-arg/smapper-light","creator_name":"Automation and Robotics (ARG) - SnT - University of Luxembourg","creator_url":"https://huggingface.co/snt-arg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["any-to-any","English","apache-2.0","10B<n<100B","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"HumanCaption-10M","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tHumanCaption-10M\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] ðŸ¤—The Original Images, are Released Completing the Agreement\nHumanCaption-10M: a large, diverse, high-quality dataset of human-related images with natural language descriptions (image to text).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M.","url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"derm12345","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDERM12345: A Large, Multisource Dermatoscopic Skin Lesion Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSkin lesion datasets provide essential information for understanding various skin conditions and developing effective diagnostic tools. They aid the artificial intelligence-based early detection of skin cancer, facilitate treatment planning, and contribute to medical education and research. Published large datasets have partially coverage the subclassifications of the skin lesions. Thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DermaVLM/derm12345.","url":"https://huggingface.co/datasets/DermaVLM/derm12345","creator_name":"DermaVLM","creator_url":"https://huggingface.co/DermaVLM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"bharatanatyam-mudra-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tBharatanatyam Mudra Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Bharatanatyam Mudra Dataset contains 28,431 images of hand gestures (mudras) from Bharatanatyam, a classical Indian dance form. The dataset was collected from 15 volunteers in a studio environment and includes both single-hand and double-hand gestures.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Images: 28,431\nSingle Hand Gestures (Asamyukta Hastas): 15,396 images across 29 classes\nDouble Hand Gestures (Samyukta Hastas): 13,035â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Samarth0710/bharatanatyam-mudra-dataset.","url":"https://huggingface.co/datasets/Samarth0710/bharatanatyam-mudra-dataset","creator_name":"Samarth P","creator_url":"https://huggingface.co/Samarth0710","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"food-visual-instructions","keyword":"vision","description":"\n\t\n\t\t\n\t\tAdapting Multimodal Large Language Models to Domains via Post-Training (EMNLP 2025)\n\t\n\nThis repos contains the food visual instructions for post-training MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\nThe main project page is: Adapt-MLLM-to-Domains\n\n\t\n\t\t\n\t\n\t\n\t\tData Information\n\t\n\nUsing our visual instruction synthesizer, we generate visual instruction tasks based on the image-caption pairs from extended Recipe1M+ dataset. These syntheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/food-visual-instructions.","url":"https://huggingface.co/datasets/AdaptLLM/food-visual-instructions","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V-Arabic","keyword":"vision","description":"\n\t\n\t\t\n\t\tALLaVA-4V for Arabic\n\t\n\nThis is the Arabic version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Arabic through ChatGPT and instructed ChatGPT not to translate content related to OCR.\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University of Hongâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic.","url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Arabic","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"KAI_handwriting-ocr","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for Handwriting Recognition Dataset\n\t\n\nThis dataset contains a collection of handwritten text images designed to improve OCR (Optical Character Recognition) and text recognition models. Each image is labeled with a transcription of the same sentence, allowing models to learn to map handwritten content to its textual equivalent.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains images of handwritten English text contributed by variousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/KAI_handwriting-ocr.","url":"https://huggingface.co/datasets/Kratos-AI/KAI_handwriting-ocr","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","n<1K","Image"],"keywords_longer_than_N":true},
	{"name":"enhanced-indian-food-classification","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tEnhanced Indian Food Classification Dataset\n\t\n\nA comprehensive dataset for Indian food classification with 15,404 images across 43 classes.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ndataset/\nâ”œâ”€â”€ train/           # Training images\nâ”œâ”€â”€ validation/      # Validation images  \nâ””â”€â”€ test/           # Test images\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load dataset\ndataset = load_dataset(\"SohlHealth/enhanced-indian-food-classification\")\n\n# Access splits\ntrain_data = dataset['train']\nval_dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SohlHealth/enhanced-indian-food-classification.","url":"https://huggingface.co/datasets/SohlHealth/enhanced-indian-food-classification","creator_name":"Prajwala Shambulingappa","creator_url":"https://huggingface.co/SohlHealth","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","cc-by-4.0","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"SENTINEL","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tDataset Card for ICCV2025 | SENTINEL:Mitigating Object Hallucinations via Sentence-Level Early Intervention \n\t\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tPaper Abstract\n\t\n\nMultimodal large language models (MLLMs) have revolutionized cross-modal understanding but continue to struggle with hallucinations - fabricated content contradicting visual inputs. Existing hallucination mitigation methods either incur prohibitive computational costs or introduce distribution mismatches between training data and modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/psp-dada/SENTINEL.","url":"https://huggingface.co/datasets/psp-dada/SENTINEL","creator_name":"Peng Shangpin","creator_url":"https://huggingface.co/psp-dada","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","10K<n<100K","arxiv:2507.12455"],"keywords_longer_than_N":true},
	{"name":"Sujet-Vision-QA","keyword":"vision","description":"\n\t\n\t\t\n\t\tDataset Description ðŸ“ŠðŸ”\n\t\n\nThe Sujet-Finance-QA-Vision-100k is a comprehensive dataset containing over 100,000 question-answer pairs derived from more than 9,800 financial document images. This dataset is designed to support research and development in the field of financial document analysis and visual question answering.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\nðŸ–¼ï¸ 9,801 unique financial document images\nâ“ 107,050 question-answer pairs\nðŸ‡¬ðŸ‡§ English language\nðŸ“„ Diverse financial document typesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/Sujet-Vision-QA.","url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/Sujet-Vision-QA","creator_name":"1-800-SHARED-TASKS","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Corneocyte_Nanotexture_Dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tProject Description\n\t\n\n\nGitHub: https://github.com/JenHungWang/ECTI_Atopic_Dermatitis\n\n","url":"https://huggingface.co/datasets/jenhung/Corneocyte_Nanotexture_Dataset","creator_name":"Jen-Hung Wang","creator_url":"https://huggingface.co/jenhung","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"HumanCaption-HQ-311K","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tHumanCaption-HQ-311K\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] ðŸ¤—The Original Images, are Released Completing Agreement\nHumanCaption-HQ-311K: Approximately 311,000 human-related images and their corresponding natural language descriptions.\nCompared toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K.","url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"UnLOK-VQA","keyword":"vision","description":"\n\t\n\t\t\n\t\tðŸ“Š Dataset: UnLOK-VQA (Unlearning Outside Knowledge VQA)\n\t\n\nPaper: Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation\nCode: https://github.com/Vaidehi99/mmmedit\nLink: Dataset Link\nThis dataset contains approximately 500 entries with the following key attributes:\n\n\"id\": Unique Identifier for each entry\n\"src\": The question whose answer is to be deleted â“\n\"pred\": The answer to the question meant for deletion âŒ\n\"loc\": Related neighborhood questionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vaidehi99/UnLOK-VQA.","url":"https://huggingface.co/datasets/vaidehi99/UnLOK-VQA","creator_name":"Vaidehi Patil","creator_url":"https://huggingface.co/vaidehi99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"color-pedia","keyword":"computer-vision","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŽ¨ Color-Pedia â€” A Rich Dataset for Color Naming, Emotion, and Palette Creation ðŸŒˆ\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nColor-Pedia is a comprehensive dataset designed for color naming, palette generation, emotional analysis, and symbolic interpretation tasks. Containing ~50,000 entries, it provides a rich collection of color data, including RGB/HEX values, human-readable color names, and detailed metadata such as emotions, personalities, moods, symbolism, and use cases. Optimized forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/boltuix/color-pedia.","url":"https://huggingface.co/datasets/boltuix/color-pedia","creator_name":"boltuix","creator_url":"https://huggingface.co/boltuix","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"gehler-dataset","keyword":"computer-vision","description":"StevenChangWei/gehler-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/StevenChangWei/gehler-dataset","creator_name":"Chen-Wei Chang","creator_url":"https://huggingface.co/StevenChangWei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"so101_three_strawberries","keyword":"vision","description":"\n\t\n\t\t\n\t\tSO101 Three Strawberries Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains robot manipulation episodes for strawberry picking task using SO101 robot. The dataset includes 19 episodes of robot manipulation with multi-view camera observations.\n\n\t\n\t\t\n\t\tTask\n\t\n\nTask: Pick up strawberries and put them in a tray\nRobot: SO101 Follower robot with 6 degrees of freedom\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the LeRobot format and contains:\n\nData: Parquet files containingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kinam0252/so101_three_strawberries.","url":"https://huggingface.co/datasets/kinam0252/so101_three_strawberries","creator_name":"Kinam Kim","creator_url":"https://huggingface.co/kinam0252","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"typed_digital_signatures","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTyped Digital Signatures Dataset\n\t\n\nThis comprehensive dataset contains synthetic digital signatures rendered across 30 different Google Fonts, specifically selected for their handwriting and signature-style characteristics. Each font contributes unique stylistic elements, making this dataset ideal for robust signature analysis and font recognition tasks.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Fonts: 30 different Google Fonts\nImages per Font: 3,000 signatures\nTotal Dataset Size: ~90,000â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Benjy/typed_digital_signatures.","url":"https://huggingface.co/datasets/Benjy/typed_digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"koch_static_grasp_0402_v5","keyword":"vision","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"koch\",\n    \"total_episodes\": 15,\n    \"total_frames\": 10028,\n    \"total_tasks\": 1,\n    \"total_videos\": 30,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 60,\n    \"splits\": {\n        \"train\": \"0:15\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JJwuj/koch_static_grasp_0402_v5.","url":"https://huggingface.co/datasets/JJwuj/koch_static_grasp_0402_v5","creator_name":"JIAWEI","creator_url":"https://huggingface.co/JJwuj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"SmartHarvest","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSmartHarvest: Multi-Species Fruit Ripeness Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSmartHarvest is a comprehensive multi-species fruit ripeness detection and segmentation dataset designed for precision agriculture applications. The dataset contains high-resolution images of fruits in natural garden environments with detailed polygon-based instance segmentation annotations and ripeness classifications.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n8 fruit species: Apple, cherry, cucumberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TheCoffeeAddict/SmartHarvest.","url":"https://huggingface.co/datasets/TheCoffeeAddict/SmartHarvest","creator_name":"Maksim Loknar","creator_url":"https://huggingface.co/TheCoffeeAddict","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","image-segmentation","image-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"floorplans","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tðŸ  Floorplan Image Dataset\n\t\n\nThis dataset contains a collection of floorplan images curated as part of a larger research project on architectural retrieval systems.\n\n\t\n\t\t\n\t\tðŸ“¦ Dataset Summary\n\t\n\nThis repository stores floorplan images that were used primarily for testing and development of image retrieval methods. The dataset includes various floorplan styles, layouts, and formats to support tasks such as:\n\nContent-based image retrieval (CBIR)\nFloorplan similarity matching\nComputerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JoaoMigSilva/floorplans.","url":"https://huggingface.co/datasets/JoaoMigSilva/floorplans","creator_name":"Joao Silva","creator_url":"https://huggingface.co/JoaoMigSilva","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"openphoto-restore-dataset","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tSynthetic Photo Restoration Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created to address the scarcity of large-scale, permissively licensed, and fully open-source datasets for photo restoration.\nTo our knowledge, it is one of the first photo restoration dataset to be generated using a fully reproducible, open-source pipeline  that combines both texture-based and procedural damage simulation.\nThe dataset consists of pairs of pristine, high-quality modern photographs and aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/joshuachin/openphoto-restore-dataset.","url":"https://huggingface.co/datasets/joshuachin/openphoto-restore-dataset","creator_name":"Joshua Chin","creator_url":"https://huggingface.co/joshuachin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-image","image-inpainting","image-colorization","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"siglip_400m","keyword":"vision","description":"\n\t\n\t\t\n\t\n\t\n\t\tSigLIP (shape-optimized model)\n\t\n\nSigLIP model pre-trained on WebLi at resolution 384x384. It was introduced in the paper Sigmoid Loss for Language Image Pre-Training by Zhai et al. and first released in this repository.\nThis model has the SoViT-400m architecture, which is the shape-optimized version as presented in Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design by Alabdulmohsin et al.\nDisclaimer: The team releasing SigLIP did not write a model card for thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lhbit20010120/siglip_400m.","url":"https://huggingface.co/datasets/lhbit20010120/siglip_400m","creator_name":"Hao Liang","creator_url":"https://huggingface.co/lhbit20010120","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","arxiv:2303.15343","arxiv:2305.13035","arxiv:2209.06794","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"FE-Wireframe","keyword":"computer-vision","description":"This new dataset is designed for motion-blurred image line segment detection with events.","url":"https://huggingface.co/datasets/lh9171338/FE-Wireframe","creator_name":"Li Hao","creator_url":"https://huggingface.co/lh9171338","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["mit","n<1K","arxiv:2211.07365","ðŸ‡ºðŸ‡¸ Region: US","computer-vision"],"keywords_longer_than_N":true},
	{"name":"Classic_Cars","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tClassic Cars\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset, contains both classic and older generation cars mostly from the US and Europe.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 660\nAverage Image Size (on disk): ~5.7 MB compressed\nPrimary Content: Classic cars.\nStandardization: All images are standardized to RGB mode and saved at 95% quality for consistency.\n\n\n\t\n\t\t\n\t\tDataset Creation & Provenance\n\t\n\n\n\t\n\t\t\n\t\t1. Original Masterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Classic_Cars.","url":"https://huggingface.co/datasets/ROSCOSMOS/Classic_Cars","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"re-edit-bench","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tReEdit-Bench: Benchmark Dataset for Exemplar-Based Image Editing\n\t\n\nA curated dataset of ~1,500 samples for evaluating exemplar-based image editing methods, as presented in our WACV '25' paper - ReEdit: Multimodal Exemplar-Based Image Editing with Diffusion Models\n    \n\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach sample contains 4 images representing an exemplar edit pair:\n\nx_original: Source image before editingx_edited: Source image after editing (defines the edit operation)  \ny_original:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tarun-menta/re-edit-bench.","url":"https://huggingface.co/datasets/tarun-menta/re-edit-bench","creator_name":"Tarun Menta","creator_url":"https://huggingface.co/tarun-menta","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-image","mit","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"cifar10-lt-federated","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tCIFAR-10 Long-Tail Federated Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a long-tailed version of CIFAR-10 designed for federated learning research. The dataset introduces class imbalance following an exponential decay distribution, making it ideal for studying long-tail classification in federated settings.\n\n\t\n\t\t\n\t\tClass Distribution (Training Set)\n\t\n\nThe training set follows a long-tail distribution with imbalance factor 100:\n\nairplane (Class 0): 5,000 samples\nautomobile (Classâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Beothuk/cifar10-lt-federated.","url":"https://huggingface.co/datasets/Beothuk/cifar10-lt-federated","creator_name":"Haoyuan Li","creator_url":"https://huggingface.co/Beothuk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"PathoROB-camelyon","keyword":"vision","description":"\n\t\n\t\t\n\t\tPathoROB\n\t\n\nPreprint | Code | Licenses | Cite\nPathoROB is a benchmark for the robustness of pathology foundation models (FMs) to non-biological medical center differences.\n\n\nPathoROB contains four datasets covering 28 biological classes from 34 medical centers and three metrics:\n\nRobustness Index: Measures the ability of an FM to capture biological features while ignoring\nnon-biological features.\nAverage Performance Drop (APD): Measures the impact of non-biological features on theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bifold-pathomics/PathoROB-camelyon.","url":"https://huggingface.co/datasets/bifold-pathomics/PathoROB-camelyon","creator_name":"BIFOLD Pathomics","creator_url":"https://huggingface.co/bifold-pathomics","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","English","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"stock-photos-asian-people","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tStock Photos (Asian People, Stable Diffusion 1.5)\n\t\n\n\n  \n  Collage of randomly selected images from the dataset\n\n\nCollection of synthetic stock photographs created with Stable Diffusion 1.5, emphasizing Asian people \n(including East Asians, Southeast Asians, South Asians, and Central Asians).\nImages were generated using a diverse set of prompts and filtered for quality, realism, and safety.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nImage generation\nImage captioning\nVisual representation learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/stock-photos-asian-people.","url":"https://huggingface.co/datasets/agentlans/stock-photos-asian-people","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","feature-extraction","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test1","keyword":"vision","description":"\n\t\n\t\t\n\t\ttest\n\t\n\ntest1\n","url":"https://huggingface.co/datasets/mujif/test1","creator_name":"dasf","creator_url":"https://huggingface.co/mujif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bridges","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tBridges\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset, contains a collection of bridges from various parts of the world including many iconic landmark bridges.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 760\nAverage Image Size (on disk): ~5.7 MB compressed\nPrimary Content: Bridges\nStandardization: All images are standardized to RGB mode and saved at 95% quality for consistency.\n\n\n\t\n\t\t\n\t\tDataset Creation & Provenance\n\t\n\n\n\t\n\t\t\n\t\t1.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Bridges.","url":"https://huggingface.co/datasets/ROSCOSMOS/Bridges","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"OGC_Geotechnie_Compatible_Negatives","keyword":"vision","description":"\n\t\n\t\t\n\t\tOGC_Geotechnie_Corrected\n\t\n\nCorrected version of racineai/OGC_Geotechnie with proper Image() types and 16 negative image columns for ColPali compatibility.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nid: Unique identifier\nquery: Text query about the document  \nlanguage: Language of the query\nimage: Main document image (corrected Image() type)\nnegative_image_0 to negative_image_15: Negative image columns\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Matchone7/OGC_Geotechnie_Compatible_Negatives.","url":"https://huggingface.co/datasets/Matchone7/OGC_Geotechnie_Compatible_Negatives","creator_name":"NoÃ© BRANDOLINI","creator_url":"https://huggingface.co/Matchone7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"PM25Vision","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tPM25Vision\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPM25Vision (PM25V) is a large-scale dataset for estimating air quality (PM2.5) from street-level imagery. It pairs Mapillary photos with World Air Quality Index (WAQI) PM2.5 records, covering 2014â€“2025, 3,261 monitoring stations, and 11,114 cleaned and balanced images with PM2.5 AQI labels.\n\n\n\t\n\t\t\n\t\n\t\n\t\tTasks\n\t\n\n\nRegression: Predict continuous PM2.5 AQI values.  \nClassification: Predict discrete AQI levels.\n\n\n\t\n\t\t\n\t\n\t\n\t\tBaseline Resultsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DeadCardassian/PM25Vision.","url":"https://huggingface.co/datasets/DeadCardassian/PM25Vision","creator_name":"DeadCardassian","creator_url":"https://huggingface.co/DeadCardassian","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","other","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"biomed-visual-instructions","keyword":"vision","description":"\n\t\n\t\t\n\t\tAdapting Multimodal Large Language Models to Domains via Post-Training (EMNLP 2025)\n\t\n\nThis repos contains the biomedicine visual instructions for post-training MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\nThe main project page is: Adapt-MLLM-to-Domains\n\n\t\n\t\t\n\t\n\t\n\t\tData Information\n\t\n\nUsing our visual instruction synthesizer, we generate visual instruction tasks based on the image-caption pairs from PubMedVision (referred to as PMC_refinedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/biomed-visual-instructions.","url":"https://huggingface.co/datasets/AdaptLLM/biomed-visual-instructions","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"OGC_Energy_Compatible_Negatives","keyword":"vision","description":"\n\t\n\t\t\n\t\tOGC_Energy_Corrected\n\t\n\nCorrected version of racineai/OGC_Energy with proper Image() types and 16 negative image columns for ColPali compatibility.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nid: Unique identifier\nquery: Text query about the document  \nlanguage: Language of the query\nimage: Main document image (corrected Image() type)\nnegative_image_0 to negative_image_15: Negative image columns\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"Matchone7/OGC_Energy_Corrected\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Matchone7/OGC_Energy_Compatible_Negatives.","url":"https://huggingface.co/datasets/Matchone7/OGC_Energy_Compatible_Negatives","creator_name":"NoÃ© BRANDOLINI","creator_url":"https://huggingface.co/Matchone7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Picklebot-130K","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Picklebot130k\n\t\n\n\n\n130 thousand video clips of balls and strikes from MLB games from the 2016 season through the 2023 season.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\nThe dataset consists of roughly 130 thousand video clips of balls and strikes in .mp4 format, resized to 224x224 resolution.\n\nCurated by: Henry Freed\nLicense: MIT\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: The original project that this dataset was compiledâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-130K.","url":"https://huggingface.co/datasets/hbfreed/Picklebot-130K","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-classification","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US","baseball"],"keywords_longer_than_N":true},
	{"name":"clothes_for_men_women_children","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tImage Description Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3082 images with their corresponding descriptions in both long and short formats. \nThe descriptions were generated using the BLIP-large model.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal images: 3082\nAverage words in long description: 17.5\nAverage words in short description: 8.8\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nfile_name: Relative path to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AntZet/clothes_for_men_women_children.","url":"https://huggingface.co/datasets/AntZet/clothes_for_men_women_children","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"map-anything","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tMapAnything Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains pre-computed metadata and covisibility matrices for supporting the MapAnything codebase. This metadata enables easy reproducible training and benchmarking for feed-forward 3D reconstruction tasks.\nPlease see our Data Processing README for more details.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset in your research, please cite our paper:\n@inproceedings{keetha2025mapanything,\n  title={{MapAnything}: Universalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/map-anything.","url":"https://huggingface.co/datasets/facebook/map-anything","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","depth-estimation","English","apache-2.0","100B<n<1T"],"keywords_longer_than_N":true},
	{"name":"merged_strawberries_tictactoe","keyword":"vision","description":"\n\t\n\t\t\n\t\tSO101 Merged Strawberries & Tic-Tac-Toe Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains robot manipulation episodes combining two distinct tasks using SO101 robot. The dataset includes 27 episodes of robot manipulation with multi-view camera observations.\n\n\t\n\t\t\n\t\tTasks\n\t\n\nTask 0: Pick up strawberries and put them in a tray\nTask 1: Pick up an X piece and place it on the tic-tac-toe board to complete the winning line\nRobot: SO101 Follower robot with 6 degrees of freedomâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kinam0252/merged_strawberries_tictactoe.","url":"https://huggingface.co/datasets/kinam0252/merged_strawberries_tictactoe","creator_name":"Kinam Kim","creator_url":"https://huggingface.co/kinam0252","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MS-HAB-TidyHouse","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tManiSkill-HAB TidyHouse Dataset\n\t\n\nPaper \n| Website \n| Code \n| Models \n| (Full) Dataset \n| Supplementary\n\n\nWhole-body, low-level control/manipulation demonstration dataset for ManiSkill-HAB TidyHouse.\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nDemonstration dataset for ManiSkill-HAB TidyHouse. Each subtask/object combination (e.g pick 002_master_chef_can) has 1000 successful episodes (200 samples/demonstration) gathered using RL policies fitered for safe robotâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arth-shukla/MS-HAB-TidyHouse.","url":"https://huggingface.co/datasets/arth-shukla/MS-HAB-TidyHouse","creator_name":"Arth Shukla","creator_url":"https://huggingface.co/arth-shukla","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["robotics","reinforcement-learning","grasping","task-planning","machine-generated"],"keywords_longer_than_N":true},
	{"name":"so101-block-side-endeff-only","keyword":"vision","description":"\n\t\n\t\t\n\t\tDataset: so101-block-side-endeff-only\n\t\n\nThis dataset is a reduced version of so101-block-horizontal-layComb12, containing only:\n\nobservation.images.side\nobservation.images.endeff\n\nAll other views (e.g., front, top, endeff_ir) have been removed to support streamlined inference.\n...\n\n\t\n\t\t\n\t\tso101-block-side-endeff-only\n\t\n\n","url":"https://huggingface.co/datasets/tshiamor/so101-block-side-endeff-only","creator_name":"tshiamo rakgowa","creator_url":"https://huggingface.co/tshiamor","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","Video","Datasets","Croissant"],"keywords_longer_than_N":true},
	{"name":"ASLAD-190K","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tASLAD-190K: Arabic Sign Language Alphabet Dataset\n\t\n\nThe ASLAD-190K dataset is an extensive collection containing 190,000 meticulously labeled RGB images representing 32 alphabets of the ArSL. To capture these images, we enlisted the help of two signers and utilized two different computer webcams, namely the HP HD camera and HP Truevision HD. The MediaPipe library was crucial in capturing RGB photos of various sizes.\nDuring the data collection process, we took great care to introduceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aboulesnane/ASLAD-190K.","url":"https://huggingface.co/datasets/aboulesnane/ASLAD-190K","creator_name":"Abdennour Boulesnane","creator_url":"https://huggingface.co/aboulesnane","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US","Computer Vision"],"keywords_longer_than_N":true},
	{"name":"PIG_R1","keyword":"computer vision","description":"\n\t\n\t\t\n\t\tPIG_R1: A High-Quality Dataset for Visual Geolocation\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nPIG_R1 (Precise Image Geolocation - Release 1) is a large and diverse collection of street-level imagery and associated metadata, meticulously compiled for the task of visual geolocation. This dataset served as the foundational data asset for the research presented in the paper \"GeoLocSFT: Efficient Visual Geolocation via Supervised Fine-Tuning of Multimodal Foundation Models\".\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paidaixing/PIG_R1.","url":"https://huggingface.co/datasets/paidaixing/PIG_R1","creator_name":"qiangyi","creator_url":"https://huggingface.co/paidaixing","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","mit","ðŸ‡ºðŸ‡¸ Region: US","computer vision","multimodal"],"keywords_longer_than_N":true},
	{"name":"Tridis_layout_manuscripts","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tA Unified Dataset for Codicological Document Layout Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains a large-scale, unified dataset for Document Layout Analysis (DLA) in historical manuscripts. It was created by harmonizing three distinct public corporaâ€”e-NDP, CATMuS, and HORAEâ€”which cover a wide range of document types from the 12th to the 17th century (administrative registers, literary manuscripts, printed books, and Books of Hours).\nThe key feature of thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis_layout_manuscripts.","url":"https://huggingface.co/datasets/magistermilitum/Tridis_layout_manuscripts","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Latin","German","mit"],"keywords_longer_than_N":true},
	{"name":"TEXMET","keyword":"computer-vision","description":"\n\t\n\t\t\n\t\tTeXMET: Curated Textile Dataset from the Metropolitan Museum of Art\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTeXMET is a high-quality, manually curated dataset of textile and tapestry objects from the Metropolitan Museum of Art's Open Access collection. This dataset has been carefully cleaned, validated, and optimized for computer vision and deep learning applications.\n\n\t\n\t\t\n\t\tðŸŽ¯ TEXMET FINAL - CURATED DATASET\n\t\n\n\nTotal Images: 18,644 high-resolution images\nUnique Objects: 1,697 textile/tapestry objectsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hzafar/TEXMET.","url":"https://huggingface.co/datasets/hzafar/TEXMET","creator_name":"Hamza Zafar","creator_url":"https://huggingface.co/hzafar","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","other","expert-generated","original","English"],"keywords_longer_than_N":true}
]
;
