const data_for_modality_vision = 
[
	{"name":"TUC-HRI","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SchulzR97/TUC-HRI","creator_name":"Robert Schulz","creator_url":"https://huggingface.co/SchulzR97","description":"\n\nUniversity of Technology Chemnitz, Germany\nDepartment Robotics and Human Machine Interaction\nAuthor: Robert Schulz\n\n\t\n\t\t\n\t\tTUC-HRI Dataset Card\n\t\n\nTUC-AR is an action recognition dataset, containing 10(+1) action categories for human machine interaction. This version contains video sequences, stored as images, frame by frame.\nWe introduce two validation types: random validation and cross-subject validation. This is the random validation dataset. For cross-subject validation, please use… See the full description on the dataset page: https://huggingface.co/datasets/SchulzR97/TUC-HRI.","first_N":5,"first_N_keywords":["video-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"AtomicGPT-3.0_Dataset","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT-3.0_Dataset","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","description":"Atomic-Ai/AtomicGPT-3.0_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","German","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"AUDITS","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DivyaApp/AUDITS","creator_name":"Divya Appapogu","creator_url":"https://huggingface.co/DivyaApp","description":"\n\t\n\t\t\n\t\tAUDITS: Image Manipulation Dataset\n\t\n\nAUDITS is a large-scale dataset for training and evaluating models on image manipulation detection and localization. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe folder includes train.zip, val.zip, and test.zip, each containing manipulated, original, and mask images, alongside metadata.\n\n\t\n\t\t\n\t\t🚀 How to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"DivyaApp/AUDITS\", split=\"train\")\n\n\n\n\t\n\t\t\n\t\tAlternatives\n\t\n\nIf loading via load_dataset is… See the full description on the dataset page: https://huggingface.co/datasets/DivyaApp/AUDITS.","first_N":5,"first_N_keywords":["mask-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MBZUAI-Campus","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sebothetramp/MBZUAI-Campus","creator_name":"Sebastian Cavada","creator_url":"https://huggingface.co/sebothetramp","description":"This dataset provides the necessary files and scripts to reconstruct the MBZUAI campus using COLMAP, GLOMAP, and NERFstudio. It contains preprocessed video sequences and metadata required for hierarchical 3D reconstruction.\n\nThe dataset includes:\n- Raw video sequences\n- Preprocessed frames\n- Calibration and metadata\n- Reconstruction scripts\n\nThe hierarchical reconstruction starts with a base structure, followed by incremental updates with additional sequences.\n","first_N":5,"first_N_keywords":["image-to-3d","robotics","other","English","mit"],"keywords_longer_than_N":true},
	{"name":"RobustSpring","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jeschmalfuss/RobustSpring","creator_name":"Jenny Schmalfuss","creator_url":"https://huggingface.co/jeschmalfuss","description":"\n\t\n\t\t\n\t\tRobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo\n\t\n\nThis dataset provides structured metadata only for the RobustSpring dataset. All image samples are referenced by relative file paths, and must be paired with local image data downloaded separately from the public release site.\n\nDataset on the Hub: jeschmalfuss/RobustSpring\nImage Data: RobustSpring\n\nFor the related research see\nRobustSpring: Benchmarking Robustness to Image Corruptions… See the full description on the dataset page: https://huggingface.co/datasets/jeschmalfuss/RobustSpring.","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"stock-photos-asian-people","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/stock-photos-asian-people","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tStock Photos (Asian People, Stable Diffusion 1.5)\n\t\n\n\n  \n  Collage of randomly selected images from the dataset\n\n\nCollection of synthetic stock photographs created with Stable Diffusion 1.5, emphasizing Asian people \n(including East Asians, Southeast Asians, South Asians, and Central Asians).\nImages were generated using a diverse set of prompts and filtered for quality, realism, and safety.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nImage generation\nImage captioning\nVisual representation learning… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/stock-photos-asian-people.","first_N":5,"first_N_keywords":["text-to-image","feature-extraction","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"chess-pieces-dominique","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dopaul/chess-pieces-dominique","creator_name":"Dominique Paul","creator_url":"https://huggingface.co/dopaul","description":"\n\t\n\t\t\n\t\tChess Piece Detection Dataset: chess_pieces_dominique\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains chess piece detection annotations in YOLOv8 format.\nChess piece detection dataset from Dominique with 12 classes of chess pieces, optimized for YOLOv8 training.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the YOLOv8 format with the following structure:\n\ntrain/: Training images and labels\nvalid/: Validation images and labels\ntest/: Test images and labels\n\n\n\t\n\t\t\n\t\tClasses… See the full description on the dataset page: https://huggingface.co/datasets/dopaul/chess-pieces-dominique.","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"chess-pieces-roboflow","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dopaul/chess-pieces-roboflow","creator_name":"Dominique Paul","creator_url":"https://huggingface.co/dopaul","description":"\n\t\n\t\t\n\t\tChess Piece Detection Dataset: chess_pieces_roboflow\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains chess piece detection annotations in YOLOv8 format.\nChess piece detection dataset from Roboflow with processed labels, cleaned and standardized for YOLOv8 format.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the YOLOv8 format with the following structure:\n\ntrain/: Training images and labels\nvalid/: Validation images and labels\ntest/: Test images and labels\n\n\n\t\n\t\t\n\t\tClasses… See the full description on the dataset page: https://huggingface.co/datasets/dopaul/chess-pieces-roboflow.","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Traffic-VQA","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuYu2004/Traffic-VQA","creator_name":"YuZhang","creator_url":"https://huggingface.co/YuYu2004","description":"YuYu2004/Traffic-VQA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","English","cc-by-4.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"DORI-Benchmark","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/appledora/DORI-Benchmark","creator_name":"Nazia Tasnim","creator_url":"https://huggingface.co/appledora","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDORI (Discriminative Orientation Reasoning Intelligence) is a comprehensive benchmark designed to evaluate object orientation understanding in multimodal large language models (MLLMs). The benchmark isolates and evaluates orientation perception as a primary capability, offering a systematic assessment framework that spans four essential dimensions of orientation comprehension: frontal alignment, rotational transformations, relative… See the full description on the dataset page: https://huggingface.co/datasets/appledora/DORI-Benchmark.","first_N":5,"first_N_keywords":["image-text-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"koch_static_grasp_0402_v5","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JJwuj/koch_static_grasp_0402_v5","creator_name":"JIAWEI","creator_url":"https://huggingface.co/JJwuj","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"koch\",\n    \"total_episodes\": 15,\n    \"total_frames\": 10028,\n    \"total_tasks\": 1,\n    \"total_videos\": 30,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 60,\n    \"splits\": {\n        \"train\": \"0:15\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":… See the full description on the dataset page: https://huggingface.co/datasets/JJwuj/koch_static_grasp_0402_v5.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"CropCOCO","keyword":"computer-vision","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrg-prague/CropCOCO","creator_name":"Visual Recognition Group FEE CTU in Prague","creator_url":"https://huggingface.co/vrg-prague","description":"\n\t\n\t\t\n\t\tCropCOCO Dataset\n\t\n\nCropCOCO is a validation-only dataset of COCO val 2017 images cropped such that some keypoints annotations are outside of the image.\nIt can be used for keypoint detection, out-of-image keypoint detection and localization, person detection and amodal person detection.\n\n\n\n\n\t\n\t\n\t\n\t\t📦 Dataset Details\n\t\n\n\nTotal images: 4,114\nAnnotations: COCO-style (bounding boxes, human keypoints, both in and out-of-image)Resolution: Varies\nFormat: JSON annotations + JPG images… See the full description on the dataset page: https://huggingface.co/datasets/vrg-prague/CropCOCO.","first_N":5,"first_N_keywords":["keypoint-detection","object-detection","English","gpl-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"deepfake-detection-dataset-v3","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v3","creator_name":"Saakshi Gupta","creator_url":"https://huggingface.co/saakshigupta","description":"\n\t\n\t\t\n\t\tDeepfake Detection Dataset V3\n\t\n\nThis dataset contains images and detailed explanations for training and evaluating deepfake detection models. It includes original images, manipulated images, confidence scores, and comprehensive technical and non-technical explanations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of:\n\nOriginal images (image)\nCAM visualization images (cam_image)\nCAM overlay images (cam_overlay)\nComparison images (comparison_image)\nLabels (label): Binary… See the full description on the dataset page: https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v3.","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"HueManity","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jayant-Sravan/HueManity","creator_name":"Jayant Sravan Tamarapalli","creator_url":"https://huggingface.co/Jayant-Sravan","description":"\n\t\n\t\t\n\t\tHueManity: A Benchmark for Testing Human-Like Visual Perception in MLLMs\n\t\n\nPaper | Code\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHueManity is a benchmark dataset featuring 83,850 images designed to test the fine-grained visual perception of Multimodal Large Language Models (MLLMs). Each image presents a two-character alphanumeric string embedded within Ishihara-style dot patterns, challenging models to perform precise pattern recognition in visually cluttered environments.\nThe dataset was… See the full description on the dataset page: https://huggingface.co/datasets/Jayant-Sravan/HueManity.","first_N":5,"first_N_keywords":["question-answering","image-to-text","image-feature-extraction","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"2HANDS","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sjauhri/2HANDS","creator_name":"Snehal Jauhri","creator_url":"https://huggingface.co/sjauhri","description":"\n\t\n\t\t\n\t\tDataset Card for 2HANDS\n\t\n\n\n2HANDS is the 2-Handed Affordance + Narration DataSet, consisting of a large number of unimanual and bimanual object affordance segmentation masks and task narrations as affordance class-labels.  \n\nProject Site https://sites.google.com/view/2handedafforder (ICCV 2025)\nPaper: https://arxiv.org/abs/2503.09320\nRepository: Coming soon\n\nEgocentric images and narrations/verb classes are derived from the EPIC-KITCHENS dataset and EPIC-VISOR annotations [1, 2].[1]… See the full description on the dataset page: https://huggingface.co/datasets/sjauhri/2HANDS.","first_N":5,"first_N_keywords":["English","mit","arxiv:2503.09320","🇺🇸 Region: US","computer-vision"],"keywords_longer_than_N":true},
	{"name":"recaptchav2-29k","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k","creator_name":"Dennis J.","creator_url":"https://huggingface.co/nobodyPerfecZ","description":"\n\t\n\t\t\n\t\tReCAPTCHAv2-29k\n\t\n\nReCAPTCHAv2-29k is a dataset consisting of images derived from Google's ReCAPTCHA v2 system, which is widely used for online human verification.\nIt contains thousands of ReCAPTCHA images, each paired with corresponding labels indicating the presence of specific objects or features (e.g., bicycle, bus, car).\nThis dataset is intended for educational and research purposes and is particularly suited for tasks such as feature extraction and multi-label image… See the full description on the dataset page: https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k.","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","found","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"azerbaijani-cuisine","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ARMammadli/azerbaijani-cuisine","creator_name":"ARMammadli","creator_url":"https://huggingface.co/ARMammadli","description":"\n\t\n\t\t\n\t\tAzerbaijani Cuisine Dataset\n\t\n\nA curated image dataset of traditional Azerbaijani dishes for computer vision and image classification tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains images of five traditional Azerbaijani dish categories. It is organized into standard training, validation, and test splits to facilitate machine learning model development and evaluation.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\n5 Food Categories: Dolma, Kebabs, Pakhlava, Plov, and Soups\n324 Total Images: Properly… See the full description on the dataset page: https://huggingface.co/datasets/ARMammadli/azerbaijani-cuisine.","first_N":5,"first_N_keywords":["English","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"DataSeeds.AI-Sample-Dataset-DSD","keyword":"computer-vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dataseeds/DataSeeds.AI-Sample-Dataset-DSD","creator_name":"Dataseeds AI","creator_url":"https://huggingface.co/Dataseeds","description":"\n\t\n\t\t\n\t\tDataSeeds.AI Sample Dataset (DSD)\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe DataSeeds.AI Sample Dataset (DSD) is a high-fidelity, human-curated computer vision-ready dataset comprised of 7,772 peer-ranked, fully annotated photographic images, 350,000+ words of descriptive text, and comprehensive metadata. While the DSD is being released under an open source license, a sister dataset of over 10,000 fully annotated and segmented images is available for immediate commercial licensing, and the… See the full description on the dataset page: https://huggingface.co/datasets/Dataseeds/DataSeeds.AI-Sample-Dataset-DSD.","first_N":5,"first_N_keywords":["image-classification","object-detection","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"PixelArt_Multiview","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Scaryplasmon96/PixelArt_Multiview","creator_name":"Andrea Cicero","creator_url":"https://huggingface.co/Scaryplasmon96","description":"\n\t\n\t\t\n\t\tMultiview PixelArt\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains sets of images representing a full 360° turnaround of characters, animals and objects in pixel art.\nEach row contains 9 images from all angles.\nCamera Data can be downloaded \n\nExamples\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9… See the full description on the dataset page: https://huggingface.co/datasets/Scaryplasmon96/PixelArt_Multiview.","first_N":5,"first_N_keywords":["image-to-image","image-to-3d","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"PubMedVision","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/PubMedVision","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n\n[2025/02/18]: We add the original captions of PubMedVision in PubMedVision_Original_Caption.json, as well as the Chinese version of PubMedVision in PubMedVision_Chinese.json.\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing the HuatuoGPT-Vision-7B model.\n\n\n\t\n\t\t\n\t\tPubMedVision\n\t\n\nPubMedVision is a large-scale medical VQA dataset. We extracted high-quality image-text pairs from PubMed and used GPT-4V to reformat them to enhance their quality.… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/PubMedVision.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"FaceCaption-15M","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\tFacaCaption-15M\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] 🤗The Original Images, are Released Completing Agreement\n\n\nFaceCaption-15M, a large-scale, diverse, and high-quality dataset of facial images accompanied by their natural language descriptions… See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"KAI_handwriting-ocr","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kratos-AI/KAI_handwriting-ocr","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","description":"\n\t\n\t\t\n\t\tDataset Card for Handwriting Recognition Dataset\n\t\n\nThis dataset contains a collection of handwritten text images designed to improve OCR (Optical Character Recognition) and text recognition models. Each image is labeled with a transcription of the same sentence, allowing models to learn to map handwritten content to its textual equivalent.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains images of handwritten English text contributed by various… See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/KAI_handwriting-ocr.","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","n<1K","Image"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V-Arabic","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tALLaVA-4V for Arabic\n\t\n\nThis is the Arabic version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Arabic through ChatGPT and instructed ChatGPT not to translate content related to OCR.\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University of Hong… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic.","first_N":5,"first_N_keywords":["question-answering","text-generation","Arabic","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"geometric-shapes","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/0-ma/geometric-shapes","creator_name":"Olivier","creator_url":"https://huggingface.co/0-ma","description":"\n\t\n\t\t\n\t\tDataset Card for Geometric Shapes Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Geometric Shapes Dataset is a synthetic dataset containing images of various geometric shapes with superimposed random text. Each image features a polygon (or just text) on a randomly colored background, with a short string of random characters partially obscuring the shape. This dataset is designed for tasks such as shape classification, image recognition, and robustness testing… See the full description on the dataset page: https://huggingface.co/datasets/0-ma/geometric-shapes.","first_N":5,"first_N_keywords":["image-classification","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Hawaii-beetles","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/imageomics/Hawaii-beetles","creator_name":"HDR Imageomics Institute","creator_url":"https://huggingface.co/imageomics","description":"\n\n\n\t\n\t\t\n\t\tDataset Card for Hawaii_Beetles\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n \n\nThis dataset contains 1614 high-resolution PNG images of individual ground-beetle\nspecimens across 14 different (Coleoptera : Carabidae) species collected by the U.S. National Ecological\nObservatory Network (NEON).\n\n\t\n\t\t\n\t\tKey Uses\n\t\n\n\nspecies-level classification or retrieval  \nobject detection / instance segmentation on natural-history collections  \nautomated extraction of… See the full description on the dataset page: https://huggingface.co/datasets/imageomics/Hawaii-beetles.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","object-detection","English","Latin"],"keywords_longer_than_N":true},
	{"name":"CoreCognition","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/williamium/CoreCognition","creator_name":"William Li","creator_url":"https://huggingface.co/williamium","description":"\n\t\n\t\t\n\t\tCoreCognition: A Core Knowledge Benchmark for Multi-modal Large Language Models\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCoreCognition is a large-scale benchmark encompassing 12 core knowledge grounded in developmental cognitive science, designed to evaluate the fundamental core abilities of Multi-modal Large Language Models (MLLMs).\nWhile MLLMs demonstrate impressive abilities over high-level perception and reasoning, their robustness in the wild remains limited, often falling short on tasks… See the full description on the dataset page: https://huggingface.co/datasets/williamium/CoreCognition.","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"nus8-dataset","keyword":"computer-vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/StevenChangWei/nus8-dataset","creator_name":"Chen-Wei Chang","creator_url":"https://huggingface.co/StevenChangWei","description":"StevenChangWei/nus8-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","Image","🇺🇸 Region: US","computer-vision"],"keywords_longer_than_N":true},
	{"name":"Classic_Cars","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ROSCOSMOS/Classic_Cars","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","description":"\n\t\n\t\t\n\t\tClassic Cars\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset, contains both classic and older generation cars mostly from the US and Europe.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 660\nAverage Image Size (on disk): ~5.7 MB compressed\nPrimary Content: Classic cars.\nStandardization: All images are standardized to RGB mode and saved at 95% quality for consistency.\n\n\n\t\n\t\t\n\t\tDataset Creation & Provenance\n\t\n\n\n\t\n\t\t\n\t\t1. Original Master… See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Classic_Cars.","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"Sports_Cars","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ROSCOSMOS/Sports_Cars","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","description":"\n\t\n\t\t\n\t\tSports Cars\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset, contains a mix of modified street cars, high performance / super cars from various manufacturers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 600\nAverage Image Size (on disk): ~5.1 MB compressed\nPrimary Content: Sports Cars\nStandardization: All images are standardized to RGB mode and saved at 95% quality for consistency.\n\n\n\t\n\t\t\n\t\tDataset Creation & Provenance\n\t\n\n\n\t\n\t\t\n\t\t1.… See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Sports_Cars.","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"Church_Buildings","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ROSCOSMOS/Church_Buildings","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","description":"\n\t\n\t\t\n\t\tChurches\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset, a collection of Church buildings including facades, interior shots and landscapes.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 780\nAverage Image Size (on disk): ~5.8 MB compressed\nPrimary Content: Church buildings\nStandardization: All images are standardized to RGB mode and saved at 95% quality for consistency.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation & Provenance\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t1.… See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Church_Buildings.","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"fashionpedia","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFashionpedia is a dataset mapping out the visual aspects of the fashion world.\nFrom the paper:\n\nFashionpedia is a new dataset which consists of two parts: (1) an ontology built by fashion experts containing 27 main apparel categories, 19 apparel parts, 294 fine-grained attributes and their relationships; (2) a dataset with everyday and celebrity event fashion images annotated with segmentation masks and their associated… See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia.","first_N":5,"first_N_keywords":["object-detection","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"fashionpedia_4_categories","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia_4_categories\n\t\n\nThis dataset is a variation of the fashionpedia dataset available here, with 2 key differences:\n\nIt contains only 4 categories:\nClothing\nShoes\nBags\nAccessories\n\n\nNew splits were created:\nTrain: 90% of the images\nVal: 5%\nTest 5%\n\n\n\nThe goal is to make the detection task easier with 4 categories instead of 46 for the full fashionpedia dataset.\nThis dataset was created using the detection_datasets library (GitHub, PyPI), you can check here the… See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories.","first_N":5,"first_N_keywords":["object-detection","monolingual","fashionpedia","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CADI-AI","keyword":"vision","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaraAgroAI/CADI-AI","creator_name":"KaraAgro AI Foundation","creator_url":"https://huggingface.co/KaraAgroAI","description":"\n\n\t\n\t\t\n\t\tCashew Disease Identication with Artificial Intelligence (CADI-AI) Dataset\n\t\n\nThis repository contains a comprehensive dataset of cashew images captured by drones, accompanied by meticulously annotated labels. \nEach high-resolution image in the dataset has a resolution of 1600x1300 pixels, providing fine details for analysis and model training.\nTo facilitate efficient object detection, each image is paired with a corresponding text file in YOLO format. \nThe YOLO format file contains… See the full description on the dataset page: https://huggingface.co/datasets/KaraAgroAI/CADI-AI.","first_N":5,"first_N_keywords":["object-detection","English","cc-by-sa-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"dtd_split_1","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mcimpoi/dtd_split_1","creator_name":"Mircea Cimpoi","creator_url":"https://huggingface.co/mcimpoi","description":"\n\t\n\t\t\n\t\tDataset Card for Describable Textures Dataset (DTD)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTexture classification dataset; consists of 47 categories, 120 images per class.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nEqually split into train, val, test; The original paper proposed 10 splits; recent works (BYOL, arxiv:2006.07733) use only first split.\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nNot defined at https://www.robots.ox.ac.uk/~vgg/data/dtd/\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n @InProceedings{cimpoi14describing… See the full description on the dataset page: https://huggingface.co/datasets/mcimpoi/dtd_split_1.","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaraAgroAI/Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation","creator_name":"KaraAgro AI Foundation","creator_url":"https://huggingface.co/KaraAgroAI","description":"\n\t\n\t\t\n\t\n\t\n\t\tDrone-based Agricultural Dataset for Crop Yield Estimation\n\t\n\nThis repository contains a comprehensive dataset of cashew, cocoa and coffee images captured by drones, accompanied by meticulously annotated labels. To facilitate object detection, each image is paired with a corresponding text file in YOLO format. The YOLO format file contains annotations, including class labels and bounding box coordinates.\nThe dataset was collected by teams from Ghana (KaraAgro AI) and Uganda… See the full description on the dataset page: https://huggingface.co/datasets/KaraAgroAI/Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation.","first_N":5,"first_N_keywords":["English","cc-by-4.0","Image","Text","doi:10.57967/hf/0959"],"keywords_longer_than_N":true},
	{"name":"Fruits-30","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VinayHajare/Fruits-30","creator_name":"Vinay Arjun Hajare","creator_url":"https://huggingface.co/VinayHajare","description":"\n\t\n\t\t\n\t\tFruits30 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nThe Fruits30 dataset is a collection of images featuring 30 different types of fruits. Each image has been preprocessed and standardized to a size of 224x224 pixels, ensuring uniformity in the dataset.\n\n\t\n\t\t\n\t\tDataset Composition:\n\t\n\n\nNumber of Classes: 30\nImage Resolution: 224x224 pixels\nTotal Images: 826\n\n\n\t\n\t\t\n\t\tClasses:\n\t\n\n0 : acerolas1 : apples2 : apricots3 : avocados4 : bananas5 : blackberries6 : blueberries7 : cantaloupes8 : cherries9… See the full description on the dataset page: https://huggingface.co/datasets/VinayHajare/Fruits-30.","first_N":5,"first_N_keywords":["image-classification","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Picklebot-50K","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hbfreed/Picklebot-50K","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","description":"\n\t\n\t\t\n\t\tDataset Card for Picklebot50k\n\t\n\n\n\n50 thousand video clips of balls and strikes from MLB games from the 2016 season through the 2022 season.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset consists of roughly 50 thousand video clips of balls and strikes in .mp4 format, resized to 224x224 resolution.\nThe calculated standard deviation and mean for the dataset are \nstd: (0.2104, 0.1986, 0.1829)\nmean: (0.3939, 0.3817, 0.3314).\n\nCurated by: Henry Freed\nLicense: MIT… See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-50K.","first_N":5,"first_N_keywords":["video-classification","mit","10K - 100K","webdataset","Text"],"keywords_longer_than_N":true},
	{"name":"Tuberculosis_Dataset","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset","creator_name":"Zhankai Ye","creator_url":"https://huggingface.co/moukaii","description":"\n\t\n\t\t\n\t\tMultimodal Dataset of Tuberculosis Patients including CT and Clinical Case Reports\n\t\n\nZhankai Ye    \nNetID: zy172\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is curated from the original “The MultiCaRe Dataset” to focus on the chest tuberculosis patients. This is a multimodal dataset consisting of lung computed tomography (CT) imaging data and the clinical case records of tuberculosis patients, along with their case keywords, the captions of their CT images, patient_id, gender, and age… See the full description on the dataset page: https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset.","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TAO-Amodal","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal","creator_name":"Cheng-Yen Hsieh","creator_url":"https://huggingface.co/chengyenhsieh","description":"\n\t\n\t\t\n\t\tTAO-Amodal Dataset\n\t\n\n\n Official Source for Downloading the TAO-Amodal and TAO Dataset.\n   📙 Project Page  | 💻 Code | 📎 Paper Link | ✏️ Citations\n   \n  \n   \n\n\n\nContact: 🙋🏻‍♂️Cheng-Yen (Wesley) Hsieh\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nOur dataset augments the TAO dataset with amodal bounding box annotations for fully invisible, out-of-frame, and occluded objects. \nNote that this implies TAO-Amodal also includes modal segmentation masks (as visualized in the color overlays above). \nOur… See the full description on the dataset page: https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal.","first_N":5,"first_N_keywords":["object-detection","mit","< 1K","json","Image"],"keywords_longer_than_N":true},
	{"name":"SARFishSample","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConnorLuckettDSTG/SARFishSample","creator_name":"Connor Luckett","creator_url":"https://huggingface.co/ConnorLuckettDSTG","description":"SARFish is a Synthetic Aperture Radar (SAR) imagery dataset for the purpose of training, validating and testing supervised machine learning models on the tasks of ship detection, classification, and length regression. The SARFish dataset builds on the excellent work of the xView3-SAR dataset (2021) and consists of two parts:\n\nData -  Extends the xView3-SAR dataset to include Single Look Complex (SLC) as well as Ground Range Detected (GRD) imagery data taken directly from the European Space… See the full description on the dataset page: https://huggingface.co/datasets/ConnorLuckettDSTG/SARFishSample.","first_N":5,"first_N_keywords":["object-detection","image-classification","apache-2.0","n<1K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"oe_dataset","keyword":"vision","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ABC-iRobotics/oe_dataset","creator_name":"Antal Bejczy Center for Intelligent Robotics","creator_url":"https://huggingface.co/ABC-iRobotics","description":"An instance segmentation dataset for robotic manipulation in a tabletop environment.\nThe dataset incorporates real and synthetic images for testing sim-to-real model transfer after fine-tuning.","first_N":5,"first_N_keywords":["object-detection","image-segmentation","robotics","instance-segmentation","semantic-segmentation"],"keywords_longer_than_N":true},
	{"name":"Military-Aircraft-Detection","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","description":"Dataset for object detection of military aircraft\nbounding box in PASCAL VOC format (xmin, ymin, xmax, ymax)\n43 aircraft types\n(A-10, A-400M, AG-600, AV-8B, B-1, B-2, B-52 Be-200, C-130, C-17, C-2, C-5, E-2, E-7, EF-2000, F-117, F-14, F-15, F-16, F/A-18, F-22, F-35, F-4, J-20, JAS-39, MQ-9, Mig-31, Mirage2000, P-3(CP-140), RQ-4, Rafale, SR-71(may contain A-12), Su-34, Su-57, Tornado, Tu-160, Tu-95(Tu-142), U-2, US-2(US-1A Kai), V-22, Vulcan, XB-70, YF-23)\nPlease let me know if you find wrong… See the full description on the dataset page: https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection.","first_N":5,"first_N_keywords":["object-detection","zero-shot-classification","zero-shot-image-classification","depth-estimation","image-classification"],"keywords_longer_than_N":true},
	{"name":"reachy-doing-things","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pollen-robotics/reachy-doing-things","creator_name":"Pollen Robotics","creator_url":"https://huggingface.co/pollen-robotics","description":"\n\t\n\t\t\n\t\tReachy Doing Things Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Reachy Doing Things Images Dataset consists of images captured from the perspective of the Reachy humanoid robot. These images were taken during teleoperation sessions, providing a unique view of the environment as perceived by the robot during manipulation tasks. The images were captured with a RGBD camera mounted on the shoulder of the robot.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset is primarily aimed at testing and validating the… See the full description on the dataset page: https://huggingface.co/datasets/pollen-robotics/reachy-doing-things.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"XMS_UI","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AaronHale/XMS_UI","creator_name":"AaronHale","creator_url":"https://huggingface.co/AaronHale","description":"AaronHale/XMS_UI dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["object-detection","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"DRGBT603","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhaodong2061/DRGBT603","creator_name":"zhaodongding","creator_url":"https://huggingface.co/zhaodong2061","description":"zhaodong2061/DRGBT603 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","100K<n<1M","Image","doi:10.57967/hf/5438"],"keywords_longer_than_N":true},
	{"name":"deepfake-detection-dataset-v2","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v2","creator_name":"Saakshi Gupta","creator_url":"https://huggingface.co/saakshigupta","description":"\n\t\n\t\t\n\t\tDeepfake Detection Dataset V2\n\t\n\nThis dataset contains images and detailed explanations for training and evaluating deepfake detection models. It includes original images, manipulated images, confidence scores, and comprehensive technical and non-technical explanations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of:\n\nOriginal images\nCAM visualization images \nCAM overlay images\nComparison images\nLabels (real/fake)\nConfidence scores\nImage captions\nTechnical and non-technical… See the full description on the dataset page: https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v2.","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"MultiCaRe_Dataset","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset","creator_name":"Mauro Nievas Offidani","creator_url":"https://huggingface.co/mauro-nievoff","description":"The dataset contains multi-modal data from over 75,000 open access and de-identified case reports, including metadata, clinical cases, image captions and more than 130,000 images. Images and clinical cases belong to different medical specialties, such as oncology, cardiology, surgery and pathology. The structure of the dataset allows to easily map images with their corresponding article metadata, clinical case, captions and image labels. Details of the data structure can be found in the file… See the full description on the dataset page: https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Picklebot-2M","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hbfreed/Picklebot-2M","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n2.6 million clips of balls and called strikes from MLB games from the 2016 season through the 2023 season.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset consists of all listed balls and called strikes from Baseball Savant's Statcast Search from 2016, when their video archives began, through the 2023 season.\nThis dataset includes the date, type (eg. FF, fourseam fastball), mph, spin rate, pitcher, batter, zone (1-14… See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-2M.","first_N":5,"first_N_keywords":["video-classification","mit","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V-Chinese","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tALLaVA-4V for Chinese\n\t\n\nThis is the Chinese version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Chinese through ChatGPT and instructed ChatGPT not to translate content related to OCR.\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University of… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"DEEPFRUlT_DATASET","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET","creator_name":"shangrong chi","creator_url":"https://huggingface.co/sc890","description":"\n\t\n\t\t\n\t\tDeepFruit Dataset\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains total of 21,122 fully labeled images, featuring 20 different kinds of fruits. It is structured into an 80% training set (16,899 images) and a 20% testing set (4,223 images), facilitating a ready-to-use framework for model training and evaluation.\nAdditionally, there are two CSV files that label the types of fruits depicted in each image.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe \"DeepFruit\" dataset is a comprehensive… See the full description on the dataset page: https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET.","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Sujet-Finance-QA-Vision-100k","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sujet-ai/Sujet-Finance-QA-Vision-100k","creator_name":"Sujet AI","creator_url":"https://huggingface.co/sujet-ai","description":"\n\t\n\t\t\n\t\tDataset Description 📊🔍\n\t\n\nThe Sujet-Finance-QA-Vision-100k is a comprehensive dataset containing over 100,000 question-answer pairs derived from more than 9,800 financial document images. This dataset is designed to support research and development in the field of financial document analysis and visual question answering.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n🖼️ 9,801 unique financial document images\n❓ 107,050 question-answer pairs\n🇬🇧 English language\n📄 Diverse financial document types… See the full description on the dataset page: https://huggingface.co/datasets/sujet-ai/Sujet-Finance-QA-Vision-100k.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"unusual-objects-unusual-places_text-image","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zer0int/unusual-objects-unusual-places_text-image","creator_name":"zer0int","creator_url":"https://huggingface.co/zer0int","description":"\n\t\n\t\t\n\t\t(Un-)usual objects in (un-)usual places\n\t\n\n\n\t\n\t\t\n\t\tA small Text-Image dataset to confuse, probe (and improve) SOTA (2024) machine vision models.\n\t\n\nTo be continued (with further examples added)...\nExample results from LMSYS ARENA (June 2024):\n\n\n","first_N":5,"first_N_keywords":["English","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"vision-feedback-mix-binarized","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized","creator_name":"NiuTrans","creator_url":"https://huggingface.co/NiuTrans","description":"\n\t\n\t\t\n\t\tDataset Card for Vision-Feedback-Mix-Binarized\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset aims to provide large-scale vision feedback data. \nIt is a combination of the following high-quality vision feedback datasets:\n\nzhiqings/LLaVA-Human-Preference-10K: 9,422 samples\nMMInstruction/VLFeedback: 80,258 samples\nYiyangAiLab/POVID_preference_data_for_VLLMs: 17,184 samples\nopenbmb/RLHF-V-Dataset: 5,733 samples\nopenbmb/RLAIF-V-Dataset: 83,132 samples\n\nWe also offer a cleaned version in… See the full description on the dataset page: https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized.","first_N":5,"first_N_keywords":["mit","100K - 1M","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"vision-feedback-mix-binarized-cleaned","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized-cleaned","creator_name":"NiuTrans","creator_url":"https://huggingface.co/NiuTrans","description":"\n\t\n\t\t\n\t\tDataset Card for Vision-Feedback-Mix-Binarized-Cleaned\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset represents a cleaned version on wangclnlp/vision-feedback-mix-binarized.\nDescriptions of the base datasets, including the data format and the procedure for mixing data, can be found in this link.\n\n\t\n\t\t\n\t\tOur Methods for Cleaning Vision Feedback Data\n\t\n\nOur goal is to select vision feedback samples where the preferred outputs are significantly differentiated from the dispreferred ones, and the… See the full description on the dataset page: https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized-cleaned.","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"Picklebot-130K","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hbfreed/Picklebot-130K","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Picklebot130k\n\t\n\n\n\n130 thousand video clips of balls and strikes from MLB games from the 2016 season through the 2023 season.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\nThe dataset consists of roughly 130 thousand video clips of balls and strikes in .mp4 format, resized to 224x224 resolution.\n\nCurated by: Henry Freed\nLicense: MIT\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: The original project that this dataset was compiled… See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-130K.","first_N":5,"first_N_keywords":["video-classification","mit","100K<n<1M","🇺🇸 Region: US","baseball"],"keywords_longer_than_N":true},
	{"name":"ndl-layout-dataset","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nakamura196/ndl-layout-dataset","creator_name":"Satoru Nakamura","creator_url":"https://huggingface.co/nakamura196","description":"\n\t\n\t\t\n\t\tndl-lab/layout-data for YOLOv8\n\t\n\n\n\nThis dataset, originally provided by NDL, has been adapted and formatted to be compatible with YOLO (You Only Look Once) for training purposes.\nhttps://github.com/ndl-lab/layout-dataset\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: Satoru Nakamura\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/nakamura196/ndl-layout-dataset.","first_N":5,"first_N_keywords":["object-detection","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"blip3-grounding-50m","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/blip3-grounding-50m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\n\t\n\t\t\n\t\tBLIP3-GROUNDING-50M Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe BLIP3-GROUNDING-50M dataset is designed to enhance the ability of Vision-Language Models (VLMs) to ground semantic concepts in visual features, which is crucial for tasks like object detection, semantic segmentation, and understanding referring expressions (e.g., \"the object to the left of the dog\"). Traditional datasets often lack the necessary granularity for such tasks, making it challenging for models to accurately localize and… See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-grounding-50m.","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Facecaption-15M-Embeddings","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\tFacecaption-15M-Embeddings\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] 🤗The Original Images, are Released Completing Agreement\nWe chose about 5M image-text pairs with the highest resolution from Facecaption-15M, extracted the embeddings of the [CLS]… See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Andrew_Alpha_training_data","keyword":"computer vision","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChristopherMarais/Andrew_Alpha_training_data","creator_name":"Christopher Marais","creator_url":"https://huggingface.co/ChristopherMarais","description":"\n\t\n\t\t\n\t\tBark Beetle Grouped Images for AI Classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises high-resolution photographs of bark and ambrosia beetles captured under controlled laboratory conditions. Each image contains multiple beetle specimens arranged on a uniform white background while submerged in 70% ethanol. This approach speeds up data collection and ensures reproducible imaging conditions. Individual beetle images can later be extracted from these grouped photographs… See the full description on the dataset page: https://huggingface.co/datasets/ChristopherMarais/Andrew_Alpha_training_data.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"blip3-ocr-200m","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/blip3-ocr-200m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\n\t\n\t\t\n\t\tBLIP3-OCR-200M Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe BLIP3-OCR-200M dataset is designed to address the limitations of current Vision-Language Models (VLMs) in processing and interpreting text-rich images, such as documents and charts. Traditional image-text datasets often struggle to capture nuanced textual information, which is crucial for tasks requiring complex text comprehension and reasoning. \n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nOCR Integration: The dataset incorporates Optical Character… See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-ocr-200m.","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Research-Papers","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khushwant04/Research-Papers","creator_name":"Khushwant Sanwalot","creator_url":"https://huggingface.co/khushwant04","description":"\n\t\n\t\t\n\t\n\t\n\t\tAI & Machine Learning Research Papers Dataset\n\t\n\nThis dataset contains a curated collection of 1296 research papers focused on advancements in Artificial Intelligence and Machine Learning. It is intended as a resource for researchers, educators, and developers to explore and analyze diverse topics within AI and ML.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nTotal Papers: 1296\nDomains Covered: \nArtificial Intelligence (AI)\nMachine Learning (ML)\nDeep Learning\nNatural Language Processing (NLP)… See the full description on the dataset page: https://huggingface.co/datasets/khushwant04/Research-Papers.","first_N":5,"first_N_keywords":["text-classification","text-retrieval","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"home_decoration_objects_images","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntZet/home_decoration_objects_images","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","description":"\n\t\n\t\t\n\t\tImage Description Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 5125 images with their corresponding descriptions in both long and short formats. \nThe descriptions were generated using the BLIP-large model.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal images: 5125\nAverage words in long description: 18.1\nAverage words in short description: 9.4\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nfile_name: Relative path to the… See the full description on the dataset page: https://huggingface.co/datasets/AntZet/home_decoration_objects_images.","first_N":5,"first_N_keywords":["image-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"men_women_children_wearing_clothes","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntZet/men_women_children_wearing_clothes","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","description":"\n\t\n\t\t\n\t\tImage Description Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 6979 images with their corresponding descriptions in both long and short formats. \nThe descriptions were generated using the BLIP-large model.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal images: 6979\nAverage words in long description: 17.3\nAverage words in short description: 9.4\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nfile_name: Relative path to the… See the full description on the dataset page: https://huggingface.co/datasets/AntZet/men_women_children_wearing_clothes.","first_N":5,"first_N_keywords":["image-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"clothes_for_men_women_children","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntZet/clothes_for_men_women_children","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","description":"\n\t\n\t\t\n\t\tImage Description Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3082 images with their corresponding descriptions in both long and short formats. \nThe descriptions were generated using the BLIP-large model.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal images: 3082\nAverage words in long description: 17.5\nAverage words in short description: 8.8\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nfile_name: Relative path to the… See the full description on the dataset page: https://huggingface.co/datasets/AntZet/clothes_for_men_women_children.","first_N":5,"first_N_keywords":["image-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"HumanCaption-HQ-311K","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\tHumanCaption-HQ-311K\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] 🤗The Original Images, are Released Completing Agreement\nHumanCaption-HQ-311K: Approximately 311,000 human-related images and their corresponding natural language descriptions.\nCompared to… See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Opendoc2-Analysis-Recognition","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\n\t\n\t\t\n\t\tOpendoc2-Analysis-Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Opendoc2-Analysis-Recognition dataset is a collection of data designed for tasks involving image analysis and recognition. It is suitable for various machine learning tasks, including image-to-text conversion, text classification, and image feature extraction.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nModalities: Likely includes images and associated labels (specific modalities can be confirmed on the dataset's page).\nLanguages:… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"siglip_400m","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lhbit20010120/siglip_400m","creator_name":"Hao Liang","creator_url":"https://huggingface.co/lhbit20010120","description":"\n\t\n\t\t\n\t\n\t\n\t\tSigLIP (shape-optimized model)\n\t\n\nSigLIP model pre-trained on WebLi at resolution 384x384. It was introduced in the paper Sigmoid Loss for Language Image Pre-Training by Zhai et al. and first released in this repository.\nThis model has the SoViT-400m architecture, which is the shape-optimized version as presented in Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design by Alabdulmohsin et al.\nDisclaimer: The team releasing SigLIP did not write a model card for this… See the full description on the dataset page: https://huggingface.co/datasets/lhbit20010120/siglip_400m.","first_N":5,"first_N_keywords":["apache-2.0","arxiv:2303.15343","arxiv:2305.13035","arxiv:2209.06794","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"biomed-visual-instructions","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdaptLLM/biomed-visual-instructions","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","description":"\n\t\n\t\t\n\t\tAdapting Multimodal Large Language Models to Domains via Post-Training\n\t\n\nThis repos contains the biomedicine visual instructions for post-training MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\nThe main project page is: Adapt-MLLM-to-Domains\n\n\t\n\t\t\n\t\n\t\n\t\tData Information\n\t\n\nUsing our visual instruction synthesizer, we generate visual instruction tasks based on the image-caption pairs from PubMedVision (referred to as PMC_refined in our… See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/biomed-visual-instructions.","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"sen12vts","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/links-ads/sen12vts","creator_name":"LINKS - AI, Data & Space","creator_url":"https://huggingface.co/links-ads","description":"\n\t\n\t\t\n\t\tSEN12VTS: Sentinel 1 and 2 Vegetation Time-Series Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe SEN12VTS (Sentinel-1 & Sentinel-2 Vegetation Time-Series) dataset has been created to support research on time-series analysis for vegetation indices, specifically targeting NDVI (Normalized Difference Vegetation Index) regression tasks. Recognizing the lack of datasets catering to this specific temporal and spatial need, SEN12VTS was developed to fill the gap with a high-quality, Europe-focused… See the full description on the dataset page: https://huggingface.co/datasets/links-ads/sen12vts.","first_N":5,"first_N_keywords":["English","mit","🇺🇸 Region: US","agricolture","computer-vision"],"keywords_longer_than_N":false},
	{"name":"Sujet-Vision-QA","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/Sujet-Vision-QA","creator_name":"1-800-SHARED-TASKS","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","description":"\n\t\n\t\t\n\t\tDataset Description 📊🔍\n\t\n\nThe Sujet-Finance-QA-Vision-100k is a comprehensive dataset containing over 100,000 question-answer pairs derived from more than 9,800 financial document images. This dataset is designed to support research and development in the field of financial document analysis and visual question answering.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n🖼️ 9,801 unique financial document images\n❓ 107,050 question-answer pairs\n🇬🇧 English language\n📄 Diverse financial document types… See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/Sujet-Vision-QA.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"test1","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mujif/test1","creator_name":"dasf","creator_url":"https://huggingface.co/mujif","description":"\n\t\n\t\t\n\t\ttest\n\t\n\ntest1\n","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Corneocyte_Nanotexture_Dataset","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jenhung/Corneocyte_Nanotexture_Dataset","creator_name":"Jen-Hung Wang","creator_url":"https://huggingface.co/jenhung","description":"\n\t\n\t\t\n\t\tProject Description\n\t\n\n\nGitHub: https://github.com/JenHungWang/ECTI_Atopic_Dermatitis\n\n","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"HumanCaption-10M","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\tHumanCaption-10M\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] 🤗The Original Images, are Released Completing the Agreement\nHumanCaption-10M: a large, diverse, high-quality dataset of human-related images with natural language descriptions (image to text).… See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"PubMedVision-EnKo","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\n\t\n\t\t\n\t\tInformations\n\t\n\n\nThis is the Korean translation of FreedomIntelligence/PubMedVision. The translation was primarily generated using the 'solar-pro-241126' model, with occasional manual assistance from the 'Gemini 2.0 Flash Experimental' model and the 'Gemini experimental 1206' model.\nAn evaluation of the translation quality (\"llm-as-a-judge\") will be coming soon.\n\n\n\t\n\t\t\n\t\n\t\n\t\tNews\n\t\n\n\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing the… See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Korean","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"license-plate-finetuning","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/license-plate-finetuning","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"A formatted, augmented copy of license_plate_object_detection for use with grounding dino training experiments. \nOriginal license is CC - please attribute author at that dataset address.\n","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","1K - 10K","Image","Text"],"keywords_longer_than_N":true},
	{"name":"GeoDE","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MLap/GeoDE","creator_name":"aman prakash","creator_url":"https://huggingface.co/MLap","description":"Official Paper\nNumber of country classes: 40Total number of images: 61925  \n\n\t\n\t\t\n\t\tImage count per country_ip class\n\t\n\n\n\t\n\t\t\nCountry\nNumber of Images\n\n\n\t\t\nAngola\n10\n\n\nArgentina\n3193\n\n\nBotswana\n3\n\n\nBrazil\n16\n\n\nBulgaria\n1\n\n\nCameroon\n1\n\n\nChina\n1565\n\n\nColombia\n3703\n\n\nEgypt\n2449\n\n\nFrance\n59\n\n\nGhana\n1\n\n\nGreece\n45\n\n\nIndonesia\n5311\n\n\nIreland\n2\n\n\nItaly\n3933\n\n\nJapan\n6500\n\n\nJordan\n43\n\n\nMalaysia\n55\n\n\nMexico\n2723\n\n\nMoldova\n2\n\n\nNetherlands\n18\n\n\nNigeria\n5729\n\n\nPhilippines\n2906\n\n\nPoland\n68\n\n\nPortugal\n139… See the full description on the dataset page: https://huggingface.co/datasets/MLap/GeoDE.","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"volga2k","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gosha20777/volga2k","creator_name":"Georgy Perevozchikov","creator_url":"https://huggingface.co/gosha20777","description":"\n\t\n\t\t\n\t\tVolga2K dataset\n\t\n\nIn our cmKAN paper, we presented a large-scale Volga2K dataset captured using a Huawei P40 Pro phone wich containts 1263 well well-aligned image paires (more than 2K images in total).  This device was specifically chosen because it features two distinct cameras with different sensor types: Quad-Bayer RGGB sensor (Sony IMX700) and RYYB sensor (Sony IMX608). These differences in sensor types result in varying image processing algorithms, with the RGGB and RYYB sensors… See the full description on the dataset page: https://huggingface.co/datasets/gosha20777/volga2k.","first_N":5,"first_N_keywords":["image-to-image","English","Russian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"tool-safety-dataset","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akameswa/tool-safety-dataset","creator_name":"Adithya Kameswara Rao","creator_url":"https://huggingface.co/akameswa","description":"\n\t\n\t\t\n\t\tTool Safety Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Tool Safety Dataset is a specialized collection of tool images with detailed safety and usage information. It combines visual data with comprehensive metadata about various hand tools, making it valuable for both computer vision tasks and safety training applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nType: Image dataset with bounding boxes and detailed tool information\nSize: Multiple splits (train/test/validation)\nFormat: Images with… See the full description on the dataset page: https://huggingface.co/datasets/akameswa/tool-safety-dataset.","first_N":5,"first_N_keywords":["object-detection","image-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"pd12m_dct_based_synthetic_stegano","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rinovative/pd12m_dct_based_synthetic_stegano","creator_name":"Rino Albertin","creator_url":"https://huggingface.co/Rinovative","description":"\n\t\n\t\t\n\t\tPD12M DCT-Based Synthetic Steganography Dataset\n\t\n\nThis dataset is a synthetically generated steganographic image dataset based on the PD12M (Public Domain 12M) image collection.It simulates detectable modifications produced by real-world JPEG steganography algorithms, using only public domain data.\nEach original image is duplicated into three synthetic stego variants, inspired by real-world JPEG steganographic algorithms:\n\nsynthetic_JMiPOD: simulated using conseal.nsF5, as JMiPOD is… See the full description on the dataset page: https://huggingface.co/datasets/Rinovative/pd12m_dct_based_synthetic_stegano.","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"Marathi_Handwritten","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tDataset Card for Marathi Handwritten OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Marathi Handwritten Text Dataset is a collection of handwritten text images in Marathi (देवनागरी लिपी),\naimed at supporting the development of Optical Character Recognition (OCR) systems, handwriting analysis tools,\nand language research.The dataset was curated from native Marathi speakers to ensure a variety of handwriting styles and character variations.\nThe dataset contains 2520 images with two… See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten.","first_N":5,"first_N_keywords":["image-classification","image-to-text","image-feature-extraction","Marathi","mit"],"keywords_longer_than_N":true},
	{"name":"typed_digital_signatures","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Benjy/typed_digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","description":"\n\t\n\t\t\n\t\tTyped Digital Signatures Dataset\n\t\n\nThis comprehensive dataset contains synthetic digital signatures rendered across 30 different Google Fonts, specifically selected for their handwriting and signature-style characteristics. Each font contributes unique stylistic elements, making this dataset ideal for robust signature analysis and font recognition tasks.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Fonts: 30 different Google Fonts\nImages per Font: 3,000 signatures\nTotal Dataset Size: ~90,000… See the full description on the dataset page: https://huggingface.co/datasets/Benjy/typed_digital_signatures.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"YOLOv8-Multiclass-Object-Detection-Dataset","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset","creator_name":"Duality AI","creator_url":"https://huggingface.co/duality-robotics","description":"\n\t\n\t\t\n\t\tDATASET SAMPLE\n\t\n\nDuality.ai  just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free!\nJust create an EDU account here. \nThis HuggingFace dataset is a 20 image and label sample, but you can get the rest at no cost by creating a FalconCloud account. Once you verify your email, the link will redirect you to the dataset page.\nWhat makes this dataset unique, useful, and capable of bridging the Sim2Real gap?\n\nThe digital twins are… See the full description on the dataset page: https://huggingface.co/datasets/duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset.","first_N":5,"first_N_keywords":["object-detection","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"color-pedia","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/boltuix/color-pedia","creator_name":"boltuix","creator_url":"https://huggingface.co/boltuix","description":"\n\n\t\n\t\t\n\t\n\t\n\t\t🎨 Color-Pedia — A Rich Dataset for Color Naming, Emotion, and Palette Creation 🌈\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nColor-Pedia is a comprehensive dataset designed for color naming, palette generation, emotional analysis, and symbolic interpretation tasks. Containing ~50,000 entries, it provides a rich collection of color data, including RGB/HEX values, human-readable color names, and detailed metadata such as emotions, personalities, moods, symbolism, and use cases. Optimized for… See the full description on the dataset page: https://huggingface.co/datasets/boltuix/color-pedia.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"GenDS","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sudarshan2002/GenDS","creator_name":"Sudarshan Rajagopalan","creator_url":"https://huggingface.co/Sudarshan2002","description":"\n\t\n\t\t\n\t\t[CVPR-2025] GenDeg: Diffusion-based Degradation Synthesis for Generalizable All-In-One Image Restoration\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for GenDS dataset\n\t\n\n\nThe GenDS dataset is a large dataset to boost the generalization of image restoration models. It is a combination of existing image restoration datasets and \ndiffusion-generated degraded samples from GenDeg. \n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset is fairly large at ~360GB. We recommend having at least 800GB of free space. To download the dataset… See the full description on the dataset page: https://huggingface.co/datasets/Sudarshan2002/GenDS.","first_N":5,"first_N_keywords":["text-to-image","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"I3D-Tools-Dataset","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/i3dlabiisc/I3D-Tools-Dataset","creator_name":"I3D-Lab-IISc","creator_url":"https://huggingface.co/i3dlabiisc","description":"\n\t\n\t\t\n\t\tI3D Tools Dataset\n\t\n\nThis is the official dataset for the \"I3D Tools Dataset\" paper. The dataset contains a diverse collection of 16 hand tool categories, curated for applications in object detection, segmentation, and synthetic data generation.\nCodebase:\n\n\t\n\t\t\n\t\n\t\n\t\t📊 Dataset Statistics\n\t\n\n\nNumber of Tool Classes: 16  \nTotal Images: ~35,000  \nImage Resolution: 1024x1024  \nAnnotations per Image:\nYOLOv8 bounding box format\nPixel-level segmentation mask\nNatural language caption… See the full description on the dataset page: https://huggingface.co/datasets/i3dlabiisc/I3D-Tools-Dataset.","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"onthelook-fashion-anchor-positive-images","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yainage90/onthelook-fashion-anchor-positive-images","creator_name":"yainage90","creator_url":"https://huggingface.co/yainage90","description":"yainage90/onthelook-fashion-anchor-positive-images dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["feature-extraction","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"AI4MARS","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hassanjbara/AI4MARS","creator_name":"Hassan Jbara","creator_url":"https://huggingface.co/hassanjbara","description":"Taken from the kaggle repository here.\n\n\t\n\t\t\n\t\tAI4Mars Dataset\n\t\n\nA dataset for terrain classification on Mars, specifically focused on Curiosity (MSL) rover data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains high-resolution Mars surface images with corresponding semantic segmentation masks for terrain classification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nimage: Original EDR (Engineering Data Record) images from Mars\nlabel_mask: Semantic segmentation masks with terrain labels\nrover_mask: Binary masks (1 =… See the full description on the dataset page: https://huggingface.co/datasets/hassanjbara/AI4MARS.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"biomed-VQA-benchmark","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdaptLLM/biomed-VQA-benchmark","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","description":"\n\t\n\t\t\n\t\tAdapting Multimodal Large Language Models to Domains via Post-Training\n\t\n\nThis repos contains the biomedical visual instruction tasks for evaluating MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\nThe main project page is: Adapt-MLLM-to-Domains\n\n\t\n\t\t\n\t\n\t\n\t\t1. Download Data\n\t\n\nYou can load datasets using the datasets library:  \nfrom datasets import load_dataset\n\n# Choose the task name from the list of available tasks\ntask_name = 'SLAKE'  #… See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/biomed-VQA-benchmark.","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","10K - 100K","arrow"],"keywords_longer_than_N":true},
	{"name":"food-visual-instructions","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdaptLLM/food-visual-instructions","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","description":"\n\t\n\t\t\n\t\tAdapting Multimodal Large Language Models to Domains via Post-Training\n\t\n\nThis repos contains the food visual instructions for post-training MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\nThe main project page is: Adapt-MLLM-to-Domains\n\n\t\n\t\t\n\t\n\t\n\t\tData Information\n\t\n\nUsing our visual instruction synthesizer, we generate visual instruction tasks based on the image-caption pairs from extended Recipe1M+ dataset. These synthetic tasks, combined… See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/food-visual-instructions.","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Medical-pills","keyword":"computer-vision","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ultralytics/Medical-pills","creator_name":"Ultralytics","creator_url":"https://huggingface.co/Ultralytics","description":"\n\t\n\t\t\n\t\tUltralytics Medical-pills Dataset\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nUltralytics medical-pills detection dataset is a proof-of-concept (POC) dataset, carefully curated to demonstrate the potential of AI in pharmaceutical applications. It contains labeled images specifically designed to train computer vision models for identifying medical-pills.\n\n\t\n\t\t\n\t\n\t\n\t\tSample Images and Annotations\n\t\n\nHere are some examples of images from the dataset, along with their corresponding annotations in a… See the full description on the dataset page: https://huggingface.co/datasets/Ultralytics/Medical-pills.","first_N":5,"first_N_keywords":["object-detection","English","agpl-3.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"BASEPROD","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hassanjbara/BASEPROD","creator_name":"Hassan Jbara","creator_url":"https://huggingface.co/hassanjbara","description":"\n\t\n\t\t\n\t\tBASEPROD: The Bardenas SemiDesert Planetary Rover Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBASEPROD is a planetary rover dataset collected in the Bardenas semi-desert in Spain, containing approximately 36,000 synchronized sets of RGB, depth, and thermal images from a Realsense camera and thermal sensor, plus 62,000 additional stereo pairs from a Bumblebee XB3 camera. The dataset was collected using the MaRTA rover (Martian Rover Testbed for Autonomy) developed by ESA, traversing… See the full description on the dataset page: https://huggingface.co/datasets/hassanjbara/BASEPROD.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"gc-os-img-art-critic","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpfearnworks/gc-os-img-art-critic","creator_name":"JP","creator_url":"https://huggingface.co/jpfearnworks","description":"\n\t\n\t\t\n\t\tgc-os-img-art-critic\n\t\n\nExample gc dataset with art critic perspective\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains images with associated metadata including captions, tags, and verification information.\n","first_N":5,"first_N_keywords":["English","cc0-1.0","🇺🇸 Region: US","image-to-text","computer-vision"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","description":"\n\t\n\t\t\n\t\tLayoutSAM Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe LayoutSAM dataset is a large-scale layout dataset derived from the SAM dataset, containing 2.7 million image-text pairs and 10.7 million entities. Each entity is annotated with a spatial position (i.e., bounding box) and a textual description.\nTraditional layout datasets often exhibit a closed-set and coarse-grained nature, which may limit the model's ability to generate complex attributes such as color, shape, and texture.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tKey… See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM.","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"UnLOK-VQA","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vaidehi99/UnLOK-VQA","creator_name":"Vaidehi Patil","creator_url":"https://huggingface.co/vaidehi99","description":"\n\t\n\t\t\n\t\t📊 Dataset: UnLOK-VQA (Unlearning Outside Knowledge VQA)\n\t\n\nPaper: Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation\nCode: https://github.com/Vaidehi99/mmmedit\nLink: Dataset Link\nThis dataset contains approximately 500 entries with the following key attributes:\n\n\"id\": Unique Identifier for each entry\n\"src\": The question whose answer is to be deleted ❓\n\"pred\": The answer to the question meant for deletion ❌\n\"loc\": Related neighborhood questions… See the full description on the dataset page: https://huggingface.co/datasets/vaidehi99/UnLOK-VQA.","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"digital_signatures","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Benjy/digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","description":"\n\t\n\t\t\n\t\tDigital Signatures Dataset\n\t\n\nThis dataset contains unique synthetic digital signatures rendered in different fonts:\n\n4,000 synthetic signatures in Rage font\n\n4,000 synthetic signatures in Mistral font\n2,000 synthetic signatures in Arial Unicode font\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nFor the development of models that can detect digital signatures in documentation using the publicly available Docusign® font styles.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is organized into three folders:\n\nrage/ - Contains… See the full description on the dataset page: https://huggingface.co/datasets/Benjy/digital_signatures.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"Signature","keyword":"computer-vision","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ultralytics/Signature","creator_name":"Ultralytics","creator_url":"https://huggingface.co/Ultralytics","description":"\n\t\n\t\t\n\t\tSignature Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset focuses on detecting human written signatures within documents. It includes a variety of document types with annotated signatures, providing valuable insights for applications in document verification and fraud detection. Essential for training computer vision algorithms, this dataset aids in identifying signatures in various document formats, supporting research and practical applications in document analysis.… See the full description on the dataset page: https://huggingface.co/datasets/Ultralytics/Signature.","first_N":5,"first_N_keywords":["object-detection","English","agpl-3.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM-eval","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","description":"\n\t\n\t\t\n\t\tLayoutSAM-eval Benchmark\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLayoutSAM-Eval is a comprehensive benchmark for evaluating the quality of Layout-to-Image (L2I) generation models. This benchmark assesses L2I generation quality from two perspectives: region-wise quality (spatial and attribute accuracy) and global-wise quality (visual quality and prompt following). It employs the VLM’s visual question answering to evaluate spatial and attribute adherence, and utilizes various metrics including IR score… See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"FaceCaptionHQ-4M","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\tFaceCaptionHQ-4M\n\t\n\nYou need to first download the data from here and then apply for access to the original Laion-face dataset by completing the required agreement (github). Once approved, refer to the information available on HuggingFace to obtain the corresponding image-text pairs.\n[25/06/09] 🤗The Original Images, are Released Completing the Agreement\nFaceCaptionHQ-4M contains about 4M facial image-text pairs that cleaned from FaceCaption-15M .  \n\n\n\n\n\t\n\t\n\t\n\t\tFigure.1 Illustrations… See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"TUC-HRI-CS","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SchulzR97/TUC-HRI-CS","creator_name":"Robert Schulz","creator_url":"https://huggingface.co/SchulzR97","description":"\n\nUniversity of Technology Chemnitz, Germany\nDepartment Robotics and Human Machine Interaction\nAuthor: Robert Schulz\n\n\t\n\t\t\n\t\tTUC-HRI Dataset Card\n\t\n\nTUC-AR is an action recognition dataset, containing 10(+1) action categories for human machine interaction. This version contains video sequences, stored as images, frame by frame.\nWe introduce two validation types: random validation and cross-subject validation. This is the cross-subject validation dataset. For random validation, please use… See the full description on the dataset page: https://huggingface.co/datasets/SchulzR97/TUC-HRI-CS.","first_N":5,"first_N_keywords":["video-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"RobustAD","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AmazonScience/RobustAD","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","description":"\n\t\n\t\t\n\t\tRobustAD Dataset\n\t\n\n\n\t\n\t\t\n\t\tAbout the Dataset\n\t\n\nRobustAD, specifically designed to evaluate the robustness of anomaly detection models in real-world scenarios. RobustAD features a curated dataset of defect detection images with meticulously controlled distribution shifts across multiple dimensions relevant to practical applications and more closely mirrors real-world deployment scenarios.\nRobustAD is designed to cover inspection challenges across multiple industries to ensure the… See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/RobustAD.","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"cats_dogs_dataset","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/louiecerv/cats_dogs_dataset","creator_name":"Louie Cervantes","creator_url":"https://huggingface.co/louiecerv","description":"\n\t\n\t\t\n\t\tCats and Dogs Image Classification Dataset\n\t\n\nThis dataset contains images of cats and dogs, intended for image classification tasks. It includes two classes: \"cats\" and \"dogs\".\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is structured into two splits:\n\ntrain: Contains 8000 images for training.\ntest: Contains 2000 images for testing.\n\nImages are stored in RGB format with a resolution of 128x128 pixels.\n\n\t\n\t\t\n\t\tData Loading and Usage\n\t\n\nThe dataset can be loaded using the Hugging Face… See the full description on the dataset page: https://huggingface.co/datasets/louiecerv/cats_dogs_dataset.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"chess-pieces-merged","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dopaul/chess-pieces-merged","creator_name":"Dominique Paul","creator_url":"https://huggingface.co/dopaul","description":"\n\t\n\t\t\n\t\tChess Piece Detection Datasets: merged-chess_pieces_dominique-chess_pieces_roboflow\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a merged dataset combining multiple chess piece detection datasets.\nComprehensive chess piece detection dataset combining multiple high-quality sources. This merged dataset provides more training data and better generalization for chess piece detection models.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the YOLOv8 format with the following structure:… See the full description on the dataset page: https://huggingface.co/datasets/dopaul/chess-pieces-merged.","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"livevqa-benchmark","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fmy666/livevqa-benchmark","creator_name":"fmy666","creator_url":"https://huggingface.co/fmy666","description":"\n\t\n\t\t\n\t\tLiveVQA Benchmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLiveVQA is a comprehensive Visual Question Answering benchmark that evaluates multimodal models across three dynamic domains: News, Academic Papers, and Videos. The dataset features both level1 (basic comprehension) and level2 (advanced reasoning) questions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nid: Unique identifier for each question\nimage: Path to the associated image\nquestion: The question text\noptions: List… See the full description on the dataset page: https://huggingface.co/datasets/fmy666/livevqa-benchmark.","first_N":5,"first_N_keywords":["visual-question-answering","multiple-choice","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"human-cornea-snRNAseq","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longevity-db/human-cornea-snRNAseq","creator_name":"2025 Longevity x AI Hackathon","creator_url":"https://huggingface.co/longevity-db","description":"\n\t\n\t\t\n\t\tHuman Cornea Atlas (snRNA-seq) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset comprises single-nucleus RNA sequencing (snRNA-seq) data specifically focusing on the cellular heterogeneity of the human cornea. It provides a high-resolution view of various cell populations and their gene expression profiles across different layers of this critical ocular tissue.\nThe data was sourced from a research paper providing a comprehensive single-cell transcriptome atlas of the human cornea.… See the full description on the dataset page: https://huggingface.co/datasets/longevity-db/human-cornea-snRNAseq.","first_N":5,"first_N_keywords":["found","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"near_duplicate_triple_image_dataset","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hyunlord/near_duplicate_triple_image_dataset","creator_name":"hyunlord","creator_url":"https://huggingface.co/hyunlord","description":"hyunlord/near_duplicate_triple_image_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Korean","mit","1K - 10K","arrow","Image"],"keywords_longer_than_N":true},
	{"name":"Tridis_layout_manuscripts","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/magistermilitum/Tridis_layout_manuscripts","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","description":"\n\t\n\t\t\n\t\tA Unified Dataset for Codicological Document Layout Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains a large-scale, unified dataset for Document Layout Analysis (DLA) in historical manuscripts. It was created by harmonizing three distinct public corpora—e-NDP, CATMuS, and HORAE—which cover a wide range of document types from the 12th to the 17th century (administrative registers, literary manuscripts, printed books, and Books of Hours).\nThe key feature of this… See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis_layout_manuscripts.","first_N":5,"first_N_keywords":["English","French","Latin","German","mit"],"keywords_longer_than_N":true},
	{"name":"chess-board-segmentation","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dopaul/chess-board-segmentation","creator_name":"Dominique Paul","creator_url":"https://huggingface.co/dopaul","description":"\n\t\n\t\t\n\t\tChess Piece Detection Dataset: chess-board-4\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains chess piece detection annotations in YOLOv8 format.\nChess board segmentation dataset with polygon annotations for precise board detection and localization. Optimized for YOLOv8 segmentation training with chess-board class.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the YOLOv8 format with the following structure:\n\ntrain/: Training images and labels\nvalid/: Validation images and… See the full description on the dataset page: https://huggingface.co/datasets/dopaul/chess-board-segmentation.","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"OGC_Geotechnie_Compatible_Negatives","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/noebrndl/OGC_Geotechnie_Compatible_Negatives","creator_name":"Noé BRANDOLINI","creator_url":"https://huggingface.co/noebrndl","description":"\n\t\n\t\t\n\t\tOGC_Geotechnie_Corrected\n\t\n\nCorrected version of racineai/OGC_Geotechnie with proper Image() types and 16 negative image columns for ColPali compatibility.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nid: Unique identifier\nquery: Text query about the document  \nlanguage: Language of the query\nimage: Main document image (corrected Image() type)\nnegative_image_0 to negative_image_15: Negative image columns\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/noebrndl/OGC_Geotechnie_Compatible_Negatives.","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"OGC_Energy_Compatible_Negatives","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/noebrndl/OGC_Energy_Compatible_Negatives","creator_name":"Noé BRANDOLINI","creator_url":"https://huggingface.co/noebrndl","description":"\n\t\n\t\t\n\t\tOGC_Energy_Corrected\n\t\n\nCorrected version of racineai/OGC_Energy with proper Image() types and 16 negative image columns for ColPali compatibility.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nid: Unique identifier\nquery: Text query about the document  \nlanguage: Language of the query\nimage: Main document image (corrected Image() type)\nnegative_image_0 to negative_image_15: Negative image columns\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"Matchone7/OGC_Energy_Corrected\")… See the full description on the dataset page: https://huggingface.co/datasets/noebrndl/OGC_Energy_Compatible_Negatives.","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"french-lot-department-captioned-photos","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NoeFlandre/french-lot-department-captioned-photos","creator_name":"Noé Flandre","creator_url":"https://huggingface.co/NoeFlandre","description":"\n\t\n\t\t\n\t\tLot Department, France Image Dataset\n\t\n\nA collection of high-resolution scenic photographs from the Lot region of France with AI-generated descriptive captions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains scenic photographs from three notable locations in France's Lot department: Rocamadour, Autoire, and Padirac. All images were captured using a Sony A6600 camera and are paired with detailed English captions generated by Mistral AI's Pixtral-Large model.\nKey Features:… See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/french-lot-department-captioned-photos.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-classification","object-detection","English"],"keywords_longer_than_N":true},
	{"name":"Datatest-for-NutriSnap","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abilhzn/Datatest-for-NutriSnap","creator_name":"Muhammad Abil Hasan","creator_url":"https://huggingface.co/abilhzn","description":"abilhzn/Datatest-for-NutriSnap dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","text-ranking","image-classification","Indonesian","English"],"keywords_longer_than_N":true},
	{"name":"albi-captioned-photos","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NoeFlandre/albi-captioned-photos","creator_name":"Noé Flandre","creator_url":"https://huggingface.co/NoeFlandre","description":"\n\t\n\t\t\n\t\tAlbi, France Image Dataset\n\t\n\nA collection of high-resolution scenic photographs from Albi, France with AI-generated descriptive captions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains scenic photographs from Albi, France, including the city center, the Toulouse Lautrec museum, and the Sainte-Cécile Cathedral. All images were captured using a Sony A6600 camera and are paired with detailed English captions generated by Mistral AI's Pixtral-Large model.\nKey Features:\n\nHigh-resolution… See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/albi-captioned-photos.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-classification","object-detection","English"],"keywords_longer_than_N":true},
	{"name":"aim-technical-articles","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhilash88/aim-technical-articles","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","description":"\n\t\n\t\t\n\t\tAnalytics India Magazine Technical Articles Dataset 🚀\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis comprehensive dataset contains 25,685 high-quality technical articles from Analytics India Magazine, one of India's leading publications covering artificial intelligence, machine learning, data science, and emerging technologies.\n\n\t\n\t\t\n\t\t✨ Dataset Highlights\n\t\n\n\n📚 Comprehensive Coverage: Latest AI models, frameworks, and tools\n🔬 Technical Depth: Extracted keywords and complexity scoring\n🏭… See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/aim-technical-articles.","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","summarization","English"],"keywords_longer_than_N":true},
	{"name":"fer2013-enhanced","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhilash88/fer2013-enhanced","creator_name":"Abhilash Sahoo","creator_url":"https://huggingface.co/abhilash88","description":"\n\t\n\t\t\n\t\tFER2013 Enhanced: Advanced Facial Expression Recognition Dataset\n\t\n\nThe most comprehensive and quality-enhanced version of the famous FER2013 dataset for state-of-the-art emotion recognition research and applications.\n\n\t\n\t\t\n\t\t🎯 Dataset Overview\n\t\n\nFER2013 Enhanced is a significantly improved version of the landmark FER2013 facial expression recognition dataset. This enhanced version provides AI-powered quality assessment, balanced data splits, comprehensive metadata, and multi-format… See the full description on the dataset page: https://huggingface.co/datasets/abhilash88/fer2013-enhanced.","first_N":5,"first_N_keywords":["image-classification","visual-question-answering","zero-shot-image-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"bo_or_not","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Voxel51/bo_or_not","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","description":"\n\t\n\t\t\n\t\tDataset Card for bo-dataset\n\t\n\nThis is a FiftyOne dataset with 169 samples designed for binary classification of Bo (Barack Obama's Portuguese Water Dog) versus other pets.\n\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nfrom fiftyone.utils.huggingface import load_from_hub\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = load_from_hub(\"Voxel51/bo_or_not\")\n\n#… See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/bo_or_not.","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Trains_and_Trams","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ROSCOSMOS/Trains_and_Trams","creator_name":"roscosmos","creator_url":"https://huggingface.co/ROSCOSMOS","description":"\n\t\n\t\t\n\t\tTrains and Trams\n\t\n\nHigh resolution image subset from the Aesthetic-Train-V2 dataset containing a mixture of both Trains and Trams. There is some nuanced misalignment with how CLIP perceives the concepts of trains and trams during coarse searches therefor I have included both. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurator: Roscosmos\nVersion: 1.0.0\nTotal Images: 650\nAverage Image Size (on disk): ~5.5 MB compressed\nPrimary Content: Trains and Trams\nStandardization: All images are standardized to… See the full description on the dataset page: https://huggingface.co/datasets/ROSCOSMOS/Trains_and_Trams.","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"M3_VOS","keyword":"computer-vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lijiaxin0111/M3_VOS","creator_name":"Dan","creator_url":"https://huggingface.co/Lijiaxin0111","description":" \n[CVPR 2025]  M3-VOS: Multi-Phase, Multi-Transition, and Multi-Scenery Video Object Segmentation\n\nIf you like our project, please give us a star ⭐ on GitHub for the latest update.  \n\n \n\n\n\t\n\t\t\n\t\t💡 Description\n\t\n\n\nVenue: CVPR2025\nRepository: 🛠️Tool, 🏠Page\nPaper: arxiv.org/html/2412.13803v2\nPoint of Contact: Jiaxin Li , Zixuan Chen\n\n\n\t\n\t\t\n\t\n\t\n\t\t📁 Structure\n\t\n\nThis dataset contains annotated videos and images for object segmentation tasks with phase transition information. The directory… See the full description on the dataset page: https://huggingface.co/datasets/Lijiaxin0111/M3_VOS.","first_N":5,"first_N_keywords":["video-classification","English","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Walking-Tours-Semantic","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentic-learning-ai-lab/Walking-Tours-Semantic","creator_name":"agentic learning ai lab","creator_url":"https://huggingface.co/agentic-learning-ai-lab","description":"\n  Walking Tours Semantic\n\n\n\n\n\nWalking Tours Semantic (WT-Sem), introduced in PooDLe, provides semantic segmentation masks for videos in the Walking Tours dataset, as well as three additional videos for validation.\nFrames are sampled every 2 seconds from each video and a top-of-the-line semantic segmentation model, OpenSeed, is used to generate the masks.\nSpecifically, the Swin-L variant of OpenSeed, pretrained on COCO and Objects365 and finetuned on ADE20K, is used.\nThe 3 new walkaround… See the full description on the dataset page: https://huggingface.co/datasets/agentic-learning-ai-lab/Walking-Tours-Semantic.","first_N":5,"first_N_keywords":["image-segmentation","image-feature-extraction","cc-by-4.0","n<1K","Image"],"keywords_longer_than_N":true},
	{"name":"re-edit-bench","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tarun-menta/re-edit-bench","creator_name":"Tarun Menta","creator_url":"https://huggingface.co/tarun-menta","description":"\n\t\n\t\t\n\t\tReEdit-Bench: Benchmark Dataset for Exemplar-Based Image Editing\n\t\n\nA curated dataset of ~1,500 samples for evaluating exemplar-based image editing methods, as presented in our WACV '25' paper - ReEdit: Multimodal Exemplar-Based Image Editing with Diffusion Models\n    \n\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach sample contains 4 images representing an exemplar edit pair:\n\nx_original: Source image before editingx_edited: Source image after editing (defines the edit operation)  \ny_original:… See the full description on the dataset page: https://huggingface.co/datasets/tarun-menta/re-edit-bench.","first_N":5,"first_N_keywords":["image-to-image","mit","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"DetailVariationsV1","keyword":"computer-vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Scaryplasmon96/DetailVariationsV1","creator_name":"Andrea Cicero","creator_url":"https://huggingface.co/Scaryplasmon96","description":"\n\t\n\t\t\n\t\tImage Detail Manipulation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains sets of images designed for tasks involving controlled manipulation of image details or styles. Each set consists of one input image (representing a baseline detail level, 'f5') and nine corresponding edited versions ('f0' through 'f9'), each representing a different level detail.\nThe Dataset was realized using SDXL Upscaling and Refiner.\nAround 60% of the images used to create this Dataset come from third party… See the full description on the dataset page: https://huggingface.co/datasets/Scaryplasmon96/DetailVariationsV1.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"Year-Guessr-Dataset","keyword":"computer-vision","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Morris0401/Year-Guessr-Dataset","creator_name":"Morris0401","creator_url":"https://huggingface.co/Morris0401","description":"\n\t\n\t\t\n\t\tYearGuessr Dataset\n\t\n\nThis dataset, Morris0401/Year-Guessr-Dataset, is a comprehensive and large-scale collection of architectural images and associated metadata, designed for global building age estimation, specifically treating age as an ordinal variable. It provides an unprecedented benchmark for evaluating building visual recognition, cross-regional generalization, and multi-modal reasoning tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tMotivation and Background\n\t\n\nBuilding age is a critical indicator for… See the full description on the dataset page: https://huggingface.co/datasets/Morris0401/Year-Guessr-Dataset.","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","100K - 1M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"floorplans","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JoaoMigSilva/floorplans","creator_name":"Joao Silva","creator_url":"https://huggingface.co/JoaoMigSilva","description":"\n\t\n\t\t\n\t\t🏠 Floorplan Image Dataset\n\t\n\nThis dataset contains a collection of floorplan images curated as part of a larger research project on architectural retrieval systems.\n\n\t\n\t\t\n\t\t📦 Dataset Summary\n\t\n\nThis repository stores floorplan images that were used primarily for testing and development of image retrieval methods. The dataset includes various floorplan styles, layouts, and formats to support tasks such as:\n\nContent-based image retrieval (CBIR)\nFloorplan similarity matching\nComputer… See the full description on the dataset page: https://huggingface.co/datasets/JoaoMigSilva/floorplans.","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"ai-tool-pool-jewelry-vision","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bzcasper/ai-tool-pool-jewelry-vision","creator_name":"Robert Casper","creator_url":"https://huggingface.co/bzcasper","description":"\n\t\n\t\t\n\t\tAI Tool Pool Jewelry Vision Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 5,130 jewelry images organized into 5 categories for computer vision tasks. The dataset was originally created and hosted on Roboflow Universe.\n\n\t\n\t\t\n\t\tCategories\n\t\n\n\nBracelet: Bracelet jewelry images\nEarrings: Earring jewelry images  \nNecklace: Necklace jewelry images\nPendant: Pendant jewelry images\nRing: Ring jewelry images\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nAI-Tool-Pool-Jewelry-Vision/\n├── train/… See the full description on the dataset page: https://huggingface.co/datasets/bzcasper/ai-tool-pool-jewelry-vision.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"anchor_positive_image_dataset","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hyunlord/anchor_positive_image_dataset","creator_name":"hyunlord","creator_url":"https://huggingface.co/hyunlord","description":"hyunlord/anchor_positive_image_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Korean","mit","10K - 100K","arrow","Image"],"keywords_longer_than_N":true},
	{"name":"skin-lesion-segmentation-classification","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/makhresearch/skin-lesion-segmentation-classification","creator_name":"Majid Khorramgah","creator_url":"https://huggingface.co/makhresearch","description":"\n\t\n\t\t\n\t\t🔗 Usage with 🤗 Datasets Library\n\t\n\n# ==============================================================================\n# Final and reliable method — clean dataset structure, no .cast() required\n# ==============================================================================\n\n# Step 1: Install the Hugging Face datasets library\n!pip install datasets -q\n\n# Step 2: Download and unzip the dataset (recommended method)\nimport requests\nfrom zipfile import ZipFile\nfrom io import BytesIO\nfrom… See the full description on the dataset page: https://huggingface.co/datasets/makhresearch/skin-lesion-segmentation-classification.","first_N":5,"first_N_keywords":["object-detection","image-segmentation","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"central-florida-native-plants","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepearth/central-florida-native-plants","creator_name":"DeepEarth","creator_url":"https://huggingface.co/deepearth","description":"\n\t\n\t\t\n\t\tDeepEarth Central Florida Native Plants Dataset v0.2.0\n\t\n\n\n\t\n\t\t\n\t\t🌿 Dataset Summary\n\t\n\nA comprehensive multimodal dataset featuring 33,665 observations of 232 native plant species from Central Florida. This dataset combines citizen science observations with state-of-the-art vision and language embeddings for advancing multimodal self-supervised ecological intelligence research.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n🌍 Spatiotemporal Coverage: Complete GPS coordinates and timestamps for all… See the full description on the dataset page: https://huggingface.co/datasets/deepearth/central-florida-native-plants.","first_N":5,"first_N_keywords":["image-classification","feature-extraction","zero-shot-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"bharatanatyam-mudra-dataset","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Samarth0710/bharatanatyam-mudra-dataset","creator_name":"Samarth P","creator_url":"https://huggingface.co/Samarth0710","description":"\n\t\n\t\t\n\t\tBharatanatyam Mudra Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Bharatanatyam Mudra Dataset contains 28,431 images of hand gestures (mudras) from Bharatanatyam, a classical Indian dance form. The dataset was collected from 15 volunteers in a studio environment and includes both single-hand and double-hand gestures.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Images: 28,431\nSingle Hand Gestures (Asamyukta Hastas): 15,396 images across 29 classes\nDouble Hand Gestures (Samyukta Hastas): 13,035… See the full description on the dataset page: https://huggingface.co/datasets/Samarth0710/bharatanatyam-mudra-dataset.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CIFAR-10","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KDKCE/CIFAR-10","creator_name":"KDKCE","creator_url":"https://huggingface.co/KDKCE","description":"\n\t\n\t\t\n\t\tCIFAR-10 - Object Recognition in Images\n\t\n\n\nBenchmark dataset for object classification.🖼️ 60,000 32x32 color images🏷️ 10 classes📁 Format: PNG, CSV📦 Files: 4🧪 Subset of the 80 million tiny images dataset\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCIFAR-10 is a widely used computer vision dataset consisting of 60,000 32x32 color images in 10 mutually exclusive classes. It was created by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The dataset is a labeled subset of the 80 million tiny… See the full description on the dataset page: https://huggingface.co/datasets/KDKCE/CIFAR-10.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"gehler-dataset","keyword":"computer-vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/StevenChangWei/gehler-dataset","creator_name":"Chen-Wei Chang","creator_url":"https://huggingface.co/StevenChangWei","description":"StevenChangWei/gehler-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"m-hood-dataset","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HugoHE/m-hood-dataset","creator_name":"WeichengHE","creator_url":"https://huggingface.co/HugoHE","description":"\n\t\n\t\t\n\t\tM-Hood Dataset: Out-of-Distribution Evaluation Collection\n\t\n\nThis dataset collection contains out-of-distribution (OOD) image datasets specifically curated for evaluating the robustness of object detection models, particularly those trained to mitigate hallucination on out-of-distribution data.\n\n\t\n\t\t\n\t\t🎯 Purpose\n\t\n\nThese datasets are designed to test how well object detection models perform when encountering images that differ from their training distribution. They are particularly… See the full description on the dataset page: https://huggingface.co/datasets/HugoHE/m-hood-dataset.","first_N":5,"first_N_keywords":["object-detection","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"nameplate1","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kahua-ml/nameplate1","creator_name":"Kahua","creator_url":"https://huggingface.co/kahua-ml","description":"\n\t\n\t\t\n\t\tNameplate Detection Dataset\n\t\n\nThis dataset contains 1000 images for object detection of nameplates and related warning signs.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nTotal Images: 1000\nClasses: 4 (nameplate, w, warning, yellow)\nTrain: 702 images\nValidation: 149 images  \nTest: 149 images\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"kahua-ml/nameplate1\")\n\n# Access splits\ntrain_data = dataset[\"train\"]\nval_data = dataset[\"valid\"] \ntest_data =… See the full description on the dataset page: https://huggingface.co/datasets/kahua-ml/nameplate1.","first_N":5,"first_N_keywords":["object-detection","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"pompax-classification","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kahua-ml/pompax-classification","creator_name":"Kahua","creator_url":"https://huggingface.co/kahua-ml","description":"\n\t\n\t\t\n\t\tPompax Equipment Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 2,772 images for industrial equipment nameplate classification. The task is to classify whether an image contains an industrial nameplate (\"tabliczka-znamionowa\" in Polish) or not.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Images: 2,772\nTask: Binary classification (nameplate vs non-nameplate)  \nClasses: 3 categories\ntabliczka-znamionowa (nameplate): 2,525 images (91.1%)\ninne (other/non-nameplate):… See the full description on the dataset page: https://huggingface.co/datasets/kahua-ml/pompax-classification.","first_N":5,"first_N_keywords":["image-classification","English","Polish","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MusiXQA","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/puar-playground/MusiXQA","creator_name":"Jian Chen","creator_url":"https://huggingface.co/puar-playground","description":"\n\t\n\t\t\n\t\tMusiXQA 🎵\n\t\n\nMusiXQA is a multimodal dataset for evaluating and training music sheet understanding systems. Each data sample is composed of:\n\nA scanned music sheet image (.png)\nIts corresponding MIDI file (.mid)\nA structured annotation (from metadata.json)\nQuestion–Answer (QA) pairs targeting musical structure, semantics, and optical music recognition (OMR)\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\t📂 Dataset Structure\n\t\n\nMusiXQA/\n├── images.tar             # PNG files of music sheets (e.g., 0000000.png)\n├──… See the full description on the dataset page: https://huggingface.co/datasets/puar-playground/MusiXQA.","first_N":5,"first_N_keywords":["English","mit","arxiv:2506.23009","🇺🇸 Region: US","music"],"keywords_longer_than_N":true},
	{"name":"TEXMET","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hzafar/TEXMET","creator_name":"Hamza Zafar","creator_url":"https://huggingface.co/hzafar","description":"\n\t\n\t\t\n\t\tTeXMET: Curated Textile Dataset from the Metropolitan Museum of Art\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTeXMET is a high-quality, manually curated dataset of textile and tapestry objects from the Metropolitan Museum of Art's Open Access collection. This dataset has been carefully cleaned, validated, and optimized for computer vision and deep learning applications.\n\n\t\n\t\t\n\t\t🎯 TEXMET FINAL - CURATED DATASET\n\t\n\n\nTotal Images: 18,644 high-resolution images\nUnique Objects: 1,697 textile/tapestry objects… See the full description on the dataset page: https://huggingface.co/datasets/hzafar/TEXMET.","first_N":5,"first_N_keywords":["image-classification","other","expert-generated","original","English"],"keywords_longer_than_N":true}
]
;
