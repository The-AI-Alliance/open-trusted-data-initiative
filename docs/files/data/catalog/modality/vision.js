const data_for_modality_vision = 
[
	{"name":"I3D-Tools-Dataset","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/i3dlabiisc/I3D-Tools-Dataset","creator_name":"I3D-Lab-IISc","creator_url":"https://huggingface.co/i3dlabiisc","description":"\n\t\n\t\t\n\t\tI3D Tools Dataset\n\t\n\nThis is the official dataset for the \"I3D Tools Dataset\" paper. The dataset contains a diverse collection of 16 hand tool categories, curated for applications in object detection, segmentation, and synthetic data generation.\nCodebase:\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š Dataset Statistics\n\t\n\n\nNumber of Tool Classes: 16  \nTotal Images: ~35,000  \nImage Resolution: 1024x1024  \nAnnotations per Image:\nYOLOv8 bounding box format\nPixel-level segmentation mask\nNatural language captionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/i3dlabiisc/I3D-Tools-Dataset.","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"TUC-HRI","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SchulzR97/TUC-HRI","creator_name":"Robert Schulz","creator_url":"https://huggingface.co/SchulzR97","description":"\n\nUniversity of Technology Chemnitz, Germany\nDepartment Robotics and Human Machine Interaction\nAuthor: Robert Schulz\n\n\t\n\t\t\n\t\tTUC-HRI Dataset Card\n\t\n\nTUC-AR is an action recognition dataset, containing 10(+1) action categories for human machine interaction. This version contains video sequences, stored as images, frame by frame.\nWe introduce two validation types: random validation and cross-subject validation. This is the random validation dataset. For cross-subject validation, please useâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SchulzR97/TUC-HRI.","first_N":5,"first_N_keywords":["video-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"AtomicGPT-3.0_Dataset","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT-3.0_Dataset","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","description":"Atomic-Ai/AtomicGPT-3.0_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","German","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"pd12m_dct_based_synthetic_stegano","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rinovative/pd12m_dct_based_synthetic_stegano","creator_name":"Rino Albertin","creator_url":"https://huggingface.co/Rinovative","description":"\n\t\n\t\t\n\t\tPD12M DCT-Based Synthetic Steganography Dataset\n\t\n\nThis dataset is a synthetic steganographic image dataset based on the PD12M (Public Domain 12M) image collection.It was designed to simulate detectable modifications similar to those produced by real-world JPEG steganography algorithms, using only public domain data.\nFor each selected image, three synthetic stego variants were created using targeted DCT (Discrete Cosine Transform) manipulations in the Y channel:\n\nsynthetic_JMiPOD:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rinovative/pd12m_dct_based_synthetic_stegano.","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"stock-photos-asian-people","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/stock-photos-asian-people","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tStock Photos (Asian People, Stable Diffusion 1.5)\n\t\n\n\n  \n  Collage of randomly selected images from the dataset\n\n\nCollection of synthetic stock photographs created with Stable Diffusion 1.5, emphasizing Asian people \n(including East Asians, Southeast Asians, South Asians, and Central Asians).\nImages were generated using a diverse set of prompts and filtered for quality, realism, and safety.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nImage generation\nImage captioning\nVisual representation learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/stock-photos-asian-people.","first_N":5,"first_N_keywords":["text-to-image","feature-extraction","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"azerbaijani-cuisine","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ARMammadli/azerbaijani-cuisine","creator_name":"ARMammadli","creator_url":"https://huggingface.co/ARMammadli","description":"\n\t\n\t\t\n\t\tAzerbaijani Cuisine Dataset\n\t\n\nA curated image dataset of traditional Azerbaijani dishes for computer vision and image classification tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains images of five traditional Azerbaijani dish categories. It is organized into standard training, validation, and test splits to facilitate machine learning model development and evaluation.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\n5 Food Categories: Dolma, Kebabs, Pakhlava, Plov, and Soups\n324 Total Images: Properlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ARMammadli/azerbaijani-cuisine.","first_N":5,"first_N_keywords":["English","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"re-edit-bench","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tarun-menta/re-edit-bench","creator_name":"Tarun Menta","creator_url":"https://huggingface.co/tarun-menta","description":"\n\t\n\t\t\n\t\tReEdit-Bench: Benchmark Dataset for Exemplar-Based Image Editing\n\t\n\nA curated dataset of ~1,500 samples for evaluating exemplar-based image editing methods, as presented in our WACV '25' paper - ReEdit: Multimodal Exemplar-Based Image Editing with Diffusion Models\n    \n\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach sample contains 4 images representing an exemplar edit pair:\n\nx_original: Source image before editingx_edited: Source image after editing (defines the edit operation)  \ny_original:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tarun-menta/re-edit-bench.","first_N":5,"first_N_keywords":["image-to-image","mit","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"DetailVariationsV1","keyword":"computer-vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Scaryplasmon96/DetailVariationsV1","creator_name":"Andrea Cicero","creator_url":"https://huggingface.co/Scaryplasmon96","description":"\n\t\n\t\t\n\t\tImage Detail Manipulation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains sets of images designed for tasks involving controlled manipulation of image details or styles. Each set consists of one input image (representing a baseline detail level, 'f5') and nine corresponding edited versions ('f0' through 'f9'), each representing a different level detail.\nThe Dataset was realized using SDXL Upscaling and Refiner.\nAround 60% of the images used to create this Dataset come from third partyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Scaryplasmon96/DetailVariationsV1.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"koch_static_grasp_0402_v5","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JJwuj/koch_static_grasp_0402_v5","creator_name":"JIAWEI","creator_url":"https://huggingface.co/JJwuj","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"koch\",\n    \"total_episodes\": 15,\n    \"total_frames\": 10028,\n    \"total_tasks\": 1,\n    \"total_videos\": 30,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 60,\n    \"splits\": {\n        \"train\": \"0:15\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JJwuj/koch_static_grasp_0402_v5.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"CropCOCO","keyword":"computer-vision","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrg-prague/CropCOCO","creator_name":"Visual Recognition Group FEE CTU in Prague","creator_url":"https://huggingface.co/vrg-prague","description":"\n\t\n\t\t\n\t\tCropCOCO Dataset\n\t\n\nCropCOCO is a validation-only dataset of COCO val 2017 images cropped such that some keypoints annotations are outside of the image.\nIt can be used for keypoint detection, out-of-image keypoint detection and localization, person detection and amodal person detection.\n\n\n\n\n\t\n\t\n\t\n\t\tðŸ“¦ Dataset Details\n\t\n\n\nTotal images: 4,114\nAnnotations: COCO-style (bounding boxes, human keypoints, both in and out-of-image)Resolution: Varies\nFormat: JSON annotations + JPG imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vrg-prague/CropCOCO.","first_N":5,"first_N_keywords":["keypoint-detection","object-detection","English","gpl-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"deepfake-detection-dataset-v3","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v3","creator_name":"Saakshi Gupta","creator_url":"https://huggingface.co/saakshigupta","description":"\n\t\n\t\t\n\t\tDeepfake Detection Dataset V3\n\t\n\nThis dataset contains images and detailed explanations for training and evaluating deepfake detection models. It includes original images, manipulated images, confidence scores, and comprehensive technical and non-technical explanations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of:\n\nOriginal images (image)\nCAM visualization images (cam_image)\nCAM overlay images (cam_overlay)\nComparison images (comparison_image)\nLabels (label): Binaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v3.","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"multiref-datasets","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wsnHowest/multiref-datasets","creator_name":"Sinan Wang","creator_url":"https://huggingface.co/wsnHowest","description":"\n\t\n\t\t\n\t\tMultiRef Datasets\n\t\n\nThis repository contains two datasets for multi-image reference tasks:\n\n\t\n\t\t\n\t\tMultiRef-Bench-Synthetic (900 samples)\n\t\n\n\nimages/: Processed images for the benchmark\noriginal_images/: Original unprocessed images\nbenchmark990v3.json: Benchmark data with 990 entries (first 900 used)\n\n\n\t\n\t\t\n\t\tMulti-Image-Benchmark (1000 samples)\n\t\n\n\ncompressed_images/: Compressed images for the benchmark\nfinal_1000_prompts_taxonomy.json: Taxonomy data with 1000 prompts\n\n\n\t\n\t\t\n\t\tUsageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wsnHowest/multiref-datasets.","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"PixelArt_Multiview","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Scaryplasmon96/PixelArt_Multiview","creator_name":"Andrea Cicero","creator_url":"https://huggingface.co/Scaryplasmon96","description":"\n\t\n\t\t\n\t\tMultiview PixelArt\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains sets of images representing a full 360Â° turnaround of characters, animals and objects in pixel art.\nEach row contains 9 images from all angles.\nCamera Data can be downloaded \n\nExamples\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Scaryplasmon96/PixelArt_Multiview.","first_N":5,"first_N_keywords":["image-to-image","image-to-3d","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Traffic-VQA","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuYu2004/Traffic-VQA","creator_name":"YuZhang","creator_url":"https://huggingface.co/YuYu2004","description":"YuYu2004/Traffic-VQA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","English","cc-by-4.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"recaptchav2-29k","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k","creator_name":"Dennis J.","creator_url":"https://huggingface.co/nobodyPerfecZ","description":"\n\t\n\t\t\n\t\tReCAPTCHAv2-29k\n\t\n\nReCAPTCHAv2-29k is a dataset consisting of images derived from Google's ReCAPTCHA v2 system, which is widely used for online human verification.\nIt contains thousands of ReCAPTCHA images, each paired with corresponding labels indicating the presence of specific objects or features (e.g., bicycle, bus, car).\nThis dataset is intended for educational and research purposes and is particularly suited for tasks such as feature extraction and multi-label imageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nobodyPerfecZ/recaptchav2-29k.","first_N":5,"first_N_keywords":["image-classification","multi-label-image-classification","found","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"Year-Guessr-Dataset","keyword":"computer-vision","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Morris0401/Year-Guessr-Dataset","creator_name":"Morris0401","creator_url":"https://huggingface.co/Morris0401","description":"\n\t\n\t\t\n\t\tYearGuessr Dataset\n\t\n\nThis dataset, Morris0401/Year-Guessr-Dataset, is a comprehensive and large-scale collection of architectural images and associated metadata, designed for global building age estimation, specifically treating age as an ordinal variable. It provides an unprecedented benchmark for evaluating building visual recognition, cross-regional generalization, and multi-modal reasoning tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tMotivation and Background\n\t\n\nBuilding age is a critical indicator forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Morris0401/Year-Guessr-Dataset.","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","100K - 1M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Fruits-30","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VinayHajare/Fruits-30","creator_name":"Vinay Arjun Hajare","creator_url":"https://huggingface.co/VinayHajare","description":"\n\t\n\t\t\n\t\tFruits30 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nThe Fruits30 dataset is a collection of images featuring 30 different types of fruits. Each image has been preprocessed and standardized to a size of 224x224 pixels, ensuring uniformity in the dataset.\n\n\t\n\t\t\n\t\tDataset Composition:\n\t\n\n\nNumber of Classes: 30\nImage Resolution: 224x224 pixels\nTotal Images: 826\n\n\n\t\n\t\t\n\t\tClasses:\n\t\n\n0 : acerolas1 : apples2 : apricots3 : avocados4 : bananas5 : blackberries6 : blueberries7 : cantaloupes8 : cherries9â€¦ See the full description on the dataset page: https://huggingface.co/datasets/VinayHajare/Fruits-30.","first_N":5,"first_N_keywords":["image-classification","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Picklebot-50K","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hbfreed/Picklebot-50K","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","description":"\n\t\n\t\t\n\t\tDataset Card for Picklebot50k\n\t\n\n\n\n50 thousand video clips of balls and strikes from MLB games from the 2016 season through the 2022 season.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset consists of roughly 50 thousand video clips of balls and strikes in .mp4 format, resized to 224x224 resolution.\nThe calculated standard deviation and mean for the dataset are \nstd: (0.2104, 0.1986, 0.1829)\nmean: (0.3939, 0.3817, 0.3314).\n\nCurated by: Henry Freed\nLicense: MITâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-50K.","first_N":5,"first_N_keywords":["video-classification","mit","10K - 100K","webdataset","Text"],"keywords_longer_than_N":true},
	{"name":"Tuberculosis_Dataset","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset","creator_name":"Zhankai Ye","creator_url":"https://huggingface.co/moukaii","description":"\n\t\n\t\t\n\t\tMultimodal Dataset of Tuberculosis Patients including CT and Clinical Case Reports\n\t\n\nZhankai Ye    \nNetID: zy172\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is curated from the original â€œThe MultiCaRe Datasetâ€ to focus on the chest tuberculosis patients. This is a multimodal dataset consisting of lung computed tomography (CT) imaging data and the clinical case records of tuberculosis patients, along with their case keywords, the captions of their CT images, patient_id, gender, and ageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset.","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TAO-Amodal","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal","creator_name":"Cheng-Yen Hsieh","creator_url":"https://huggingface.co/chengyenhsieh","description":"\n\t\n\t\t\n\t\tTAO-Amodal Dataset\n\t\n\n\n Official Source for Downloading the TAO-Amodal and TAO Dataset.\n   ðŸ“™ Project Page  | ðŸ’» Code | ðŸ“Ž Paper Link | âœï¸ Citations\n   \n  \n   \n\n\n\nContact: ðŸ™‹ðŸ»â€â™‚ï¸Cheng-Yen (Wesley) Hsieh\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nOur dataset augments the TAO dataset with amodal bounding box annotations for fully invisible, out-of-frame, and occluded objects. \nNote that this implies TAO-Amodal also includes modal segmentation masks (as visualized in the color overlays above). \nOurâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal.","first_N":5,"first_N_keywords":["object-detection","mit","< 1K","json","Image"],"keywords_longer_than_N":true},
	{"name":"oe_dataset","keyword":"vision","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ABC-iRobotics/oe_dataset","creator_name":"Antal Bejczy Center for Intelligent Robotics","creator_url":"https://huggingface.co/ABC-iRobotics","description":"An instance segmentation dataset for robotic manipulation in a tabletop environment.\nThe dataset incorporates real and synthetic images for testing sim-to-real model transfer after fine-tuning.","first_N":5,"first_N_keywords":["object-detection","image-segmentation","robotics","instance-segmentation","semantic-segmentation"],"keywords_longer_than_N":true},
	{"name":"Military-Aircraft-Detection","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","description":"Dataset for object detection of military aircraft\nbounding box in PASCAL VOC format (xmin, ymin, xmax, ymax)\n43 aircraft types\n(A-10, A-400M, AG-600, AV-8B, B-1, B-2, B-52 Be-200, C-130, C-17, C-2, C-5, E-2, E-7, EF-2000, F-117, F-14, F-15, F-16, F/A-18, F-22, F-35, F-4, J-20, JAS-39, MQ-9, Mig-31, Mirage2000, P-3(CP-140), RQ-4, Rafale, SR-71(may contain A-12), Su-34, Su-57, Tornado, Tu-160, Tu-95(Tu-142), U-2, US-2(US-1A Kai), V-22, Vulcan, XB-70, YF-23)\nPlease let me know if you find wrongâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection.","first_N":5,"first_N_keywords":["object-detection","zero-shot-classification","zero-shot-image-classification","depth-estimation","image-classification"],"keywords_longer_than_N":true},
	{"name":"color-pedia","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/boltuix/color-pedia","creator_name":"boltuix","creator_url":"https://huggingface.co/boltuix","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŽ¨ Color-Pedia â€” A Rich Dataset for Color Naming, Emotion, and Palette Creation ðŸŒˆ\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nColor-Pedia is a comprehensive dataset designed for color naming, palette generation, emotional analysis, and symbolic interpretation tasks. Containing ~50,000 entries, it provides a rich collection of color data, including RGB/HEX values, human-readable color names, and detailed metadata such as emotions, personalities, moods, symbolism, and use cases. Optimized forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/boltuix/color-pedia.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"volga2k","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gosha20777/volga2k","creator_name":"Georgy Perevozchikov","creator_url":"https://huggingface.co/gosha20777","description":"\n\t\n\t\t\n\t\tVolga2K dataset\n\t\n\nIn our cmKAN paper, we presented a large-scale Volga2K dataset captured using a Huawei P40 Pro phone wich containts 1263 well well-aligned image paires (more than 2K images in total).  This device was specifically chosen because it features two distinct cameras with different sensor types: Quad-Bayer RGGB sensor (Sony IMX700) and RYYB sensor (Sony IMX608). These differences in sensor types result in varying image processing algorithms, with the RGGB and RYYB sensorsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gosha20777/volga2k.","first_N":5,"first_N_keywords":["image-to-image","English","Russian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"fashionpedia","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFashionpedia is a dataset mapping out the visual aspects of the fashion world.\nFrom the paper:\n\nFashionpedia is a new dataset which consists of two parts: (1) an ontology built by fashion experts containing 27 main apparel categories, 19 apparel parts, 294 fine-grained attributes and their relationships; (2) a dataset with everyday and celebrity event fashion images annotated with segmentation masks and their associatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia.","first_N":5,"first_N_keywords":["object-detection","monolingual","original","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"fashionpedia_4_categories","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Fashionpedia_4_categories\n\t\n\nThis dataset is a variation of the fashionpedia dataset available here, with 2 key differences:\n\nIt contains only 4 categories:\nClothing\nShoes\nBags\nAccessories\n\n\nNew splits were created:\nTrain: 90% of the images\nVal: 5%\nTest 5%\n\n\n\nThe goal is to make the detection task easier with 4 categories instead of 46 for the full fashionpedia dataset.\nThis dataset was created using the detection_datasets library (GitHub, PyPI), you can check here theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories.","first_N":5,"first_N_keywords":["object-detection","monolingual","fashionpedia","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CADI-AI","keyword":"vision","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaraAgroAI/CADI-AI","creator_name":"KaraAgro AI Foundation","creator_url":"https://huggingface.co/KaraAgroAI","description":"\n\n\t\n\t\t\n\t\tCashew Disease Identication with Artificial Intelligence (CADI-AI) Dataset\n\t\n\nThis repository contains a comprehensive dataset of cashew images captured by drones, accompanied by meticulously annotated labels. \nEach high-resolution image in the dataset has a resolution of 1600x1300 pixels, providing fine details for analysis and model training.\nTo facilitate efficient object detection, each image is paired with a corresponding text file in YOLO format. \nThe YOLO format file containsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KaraAgroAI/CADI-AI.","first_N":5,"first_N_keywords":["object-detection","English","cc-by-sa-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"dtd_split_1","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mcimpoi/dtd_split_1","creator_name":"Mircea Cimpoi","creator_url":"https://huggingface.co/mcimpoi","description":"\n\t\n\t\t\n\t\tDataset Card for Describable Textures Dataset (DTD)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTexture classification dataset; consists of 47 categories, 120 images per class.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nEqually split into train, val, test; The original paper proposed 10 splits; recent works (BYOL, arxiv:2006.07733) use only first split.\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nNot defined at https://www.robots.ox.ac.uk/~vgg/data/dtd/\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n @InProceedings{cimpoi14describingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mcimpoi/dtd_split_1.","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaraAgroAI/Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation","creator_name":"KaraAgro AI Foundation","creator_url":"https://huggingface.co/KaraAgroAI","description":"\n\t\n\t\t\n\t\n\t\n\t\tDrone-based Agricultural Dataset for Crop Yield Estimation\n\t\n\nThis repository contains a comprehensive dataset of cashew, cocoa and coffee images captured by drones, accompanied by meticulously annotated labels. To facilitate object detection, each image is paired with a corresponding text file in YOLO format. The YOLO format file contains annotations, including class labels and bounding box coordinates.\nThe dataset was collected by teams from Ghana (KaraAgro AI) and Ugandaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KaraAgroAI/Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation.","first_N":5,"first_N_keywords":["English","cc-by-4.0","Image","Text","doi:10.57967/hf/0959"],"keywords_longer_than_N":true},
	{"name":"HumanCaption-HQ-311K","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\tHumanCaption-HQ-311K\n\t\n\nHumanCaption-HQ-311K: Approximately 311,000 human-related images and their corresponding natural language descriptions.\nCompared to HumanCaption-10M, this dataset not only includes associated facial language descriptions but also filters out images with higher resolution and employs the powerful visual understanding capabilities of GPT-4V to generate more detailed and accurate text descriptions.\nThis dataset is used for the second phase of training HumanVLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"home_decoration_objects_images","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntZet/home_decoration_objects_images","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","description":"\n\t\n\t\t\n\t\tImage Description Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 5125 images with their corresponding descriptions in both long and short formats. \nThe descriptions were generated using the BLIP-large model.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal images: 5125\nAverage words in long description: 18.1\nAverage words in short description: 9.4\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nfile_name: Relative path to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AntZet/home_decoration_objects_images.","first_N":5,"first_N_keywords":["image-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"men_women_children_wearing_clothes","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntZet/men_women_children_wearing_clothes","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","description":"\n\t\n\t\t\n\t\tImage Description Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 6979 images with their corresponding descriptions in both long and short formats. \nThe descriptions were generated using the BLIP-large model.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal images: 6979\nAverage words in long description: 17.3\nAverage words in short description: 9.4\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nfile_name: Relative path to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AntZet/men_women_children_wearing_clothes.","first_N":5,"first_N_keywords":["image-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"clothes_for_men_women_children","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntZet/clothes_for_men_women_children","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","description":"\n\t\n\t\t\n\t\tImage Description Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3082 images with their corresponding descriptions in both long and short formats. \nThe descriptions were generated using the BLIP-large model.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal images: 3082\nAverage words in long description: 17.5\nAverage words in short description: 8.8\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nfile_name: Relative path to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AntZet/clothes_for_men_women_children.","first_N":5,"first_N_keywords":["image-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"PubMedVision-EnKo","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\n\t\n\t\t\n\t\tInformations\n\t\n\n\nThis is the Korean translation of FreedomIntelligence/PubMedVision. The translation was primarily generated using the 'solar-pro-241126' model, with occasional manual assistance from the 'Gemini 2.0 Flash Experimental' model and the 'Gemini experimental 1206' model.\nAn evaluation of the translation quality (\"llm-as-a-judge\") will be coming soon.\n\n\n\t\n\t\t\n\t\n\t\n\t\tNews\n\t\n\n\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Korean","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"test1","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mujif/test1","creator_name":"dasf","creator_url":"https://huggingface.co/mujif","description":"\n\t\n\t\t\n\t\ttest\n\t\n\ntest1\n","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"license-plate-finetuning","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/license-plate-finetuning","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"A formatted, augmented copy of license_plate_object_detection for use with grounding dino training experiments. \nOriginal license is CC - please attribute author at that dataset address.\n","first_N":5,"first_N_keywords":["object-detection","cc-by-4.0","1K - 10K","Image","Text"],"keywords_longer_than_N":true},
	{"name":"BASEPROD","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hassanjbara/BASEPROD","creator_name":"Hassan Jbara","creator_url":"https://huggingface.co/hassanjbara","description":"\n\t\n\t\t\n\t\tBASEPROD: The Bardenas SemiDesert Planetary Rover Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBASEPROD is a planetary rover dataset collected in the Bardenas semi-desert in Spain, containing approximately 36,000 synchronized sets of RGB, depth, and thermal images from a Realsense camera and thermal sensor, plus 62,000 additional stereo pairs from a Bumblebee XB3 camera. The dataset was collected using the MaRTA rover (Martian Rover Testbed for Autonomy) developed by ESA, traversingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hassanjbara/BASEPROD.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"blip3-grounding-50m","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/blip3-grounding-50m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\n\t\n\t\t\n\t\tBLIP3-GROUNDING-50M Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe BLIP3-GROUNDING-50M dataset is designed to enhance the ability of Vision-Language Models (VLMs) to ground semantic concepts in visual features, which is crucial for tasks like object detection, semantic segmentation, and understanding referring expressions (e.g., \"the object to the left of the dog\"). Traditional datasets often lack the necessary granularity for such tasks, making it challenging for models to accurately localize andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-grounding-50m.","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"siglip_400m","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lhbit20010120/siglip_400m","creator_name":"Hao Liang","creator_url":"https://huggingface.co/lhbit20010120","description":"\n\t\n\t\t\n\t\n\t\n\t\tSigLIP (shape-optimized model)\n\t\n\nSigLIP model pre-trained on WebLi at resolution 384x384. It was introduced in the paper Sigmoid Loss for Language Image Pre-Training by Zhai et al. and first released in this repository.\nThis model has the SoViT-400m architecture, which is the shape-optimized version as presented in Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design by Alabdulmohsin et al.\nDisclaimer: The team releasing SigLIP did not write a model card for thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lhbit20010120/siglip_400m.","first_N":5,"first_N_keywords":["apache-2.0","arxiv:2303.15343","arxiv:2305.13035","arxiv:2209.06794","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"biomed-visual-instructions","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdaptLLM/biomed-visual-instructions","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","description":"\n\t\n\t\t\n\t\tAdapting Multimodal Large Language Models to Domains via Post-Training\n\t\n\nThis repos contains the biomedicine visual instructions for post-training MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\nThe main project page is: Adapt-MLLM-to-Domains\n\n\t\n\t\t\n\t\n\t\n\t\tData Information\n\t\n\nUsing our visual instruction synthesizer, we generate visual instruction tasks based on the image-caption pairs from PubMedVision (referred to as PMC_refined in ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/biomed-visual-instructions.","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Opendoc2-Analysis-Recognition","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\n\t\n\t\t\n\t\tOpendoc2-Analysis-Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Opendoc2-Analysis-Recognition dataset is a collection of data designed for tasks involving image analysis and recognition. It is suitable for various machine learning tasks, including image-to-text conversion, text classification, and image feature extraction.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nModalities: Likely includes images and associated labels (specific modalities can be confirmed on the dataset's page).\nLanguages:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Medical-pills","keyword":"computer-vision","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ultralytics/Medical-pills","creator_name":"Ultralytics","creator_url":"https://huggingface.co/Ultralytics","description":"\n\t\n\t\t\n\t\tUltralytics Medical-pills Dataset\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nUltralytics medical-pills detection dataset is a proof-of-concept (POC) dataset, carefully curated to demonstrate the potential of AI in pharmaceutical applications. It contains labeled images specifically designed to train computer vision models for identifying medical-pills.\n\n\t\n\t\t\n\t\n\t\n\t\tSample Images and Annotations\n\t\n\nHere are some examples of images from the dataset, along with their corresponding annotations in aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ultralytics/Medical-pills.","first_N":5,"first_N_keywords":["object-detection","English","agpl-3.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"PubMedVision","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/PubMedVision","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n\n[2025/02/18]: We add the original captions of PubMedVision in PubMedVision_Original_Caption.json, as well as the Chinese version of PubMedVision in PubMedVision_Chinese.json.\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing the HuatuoGPT-Vision-7B model.\n\n\n\t\n\t\t\n\t\tPubMedVision\n\t\n\nPubMedVision is a large-scale medical VQA dataset. We extracted high-quality image-text pairs from PubMed and used GPT-4V to reformat them to enhance their quality.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/PubMedVision.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ndl-layout-dataset","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nakamura196/ndl-layout-dataset","creator_name":"Satoru Nakamura","creator_url":"https://huggingface.co/nakamura196","description":"\n\t\n\t\t\n\t\tndl-lab/layout-data for YOLOv8\n\t\n\n\n\nThis dataset, originally provided by NDL, has been adapted and formatted to be compatible with YOLO (You Only Look Once) for training purposes.\nhttps://github.com/ndl-lab/layout-dataset\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: Satoru Nakamura\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nakamura196/ndl-layout-dataset.","first_N":5,"first_N_keywords":["object-detection","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"FaceCaptionHQ-4M","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\tFaceCaptionHQ-4M\n\t\n\nFaceCaptionHQ-4M contains about 4M facial image-text pairs that cleaned from FaceCaption-15M .  \n\n\n\n\n\t\n\t\t\n\t\tFigure.1 Illustrations\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFigure.2 Piplines of constructing FaceCaptionHQ-4M. The detailed method can be referred to Face-MakeUp.\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tNews and Update ðŸ”¥ðŸ”¥ðŸ”¥\n\t\n\n\nJan.11, 2025.   ðŸ¤—FaceCaptionHQ-4M, is released!ðŸ‘ðŸ‘ðŸ‘\nJan.11, 2025.   ðŸ¤—FaceMaker-V0, is released!ðŸ‘ðŸ‘ðŸ‘\n\n\n\t\n\t\t\n\t\tðŸ¤— How to Use\n\t\n\nWe provide a few lines of code to downloadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"typed_digital_signatures","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Benjy/typed_digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","description":"\n\t\n\t\t\n\t\tTyped Digital Signatures Dataset\n\t\n\nThis comprehensive dataset contains synthetic digital signatures rendered across 30 different Google Fonts, specifically selected for their handwriting and signature-style characteristics. Each font contributes unique stylistic elements, making this dataset ideal for robust signature analysis and font recognition tasks.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Fonts: 30 different Google Fonts\nImages per Font: 3,000 signatures\nTotal Dataset Size: ~90,000â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Benjy/typed_digital_signatures.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"Facecaption-15M-Embeddings","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\tFacecaption-15M-Embeddings\n\t\n\nWe chose about 5M image-text pairs with the highest resolution from Facecaption-15M, extracted the embeddings of the [CLS] Token using the FLIP model, and released them.\nMore details of Facecaption-15M and FLIP are available at: Facecaption15M and FLIP.\n\n\t\n\t\t\n\t\n\t\n\t\tAdditional Information\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tLicensing Information\n\t\n\nThe FaceCaption-15M dataset is released by OpenFaceCQUPT and is intended exclusively for research and educational purposes. It hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"geometric-shapes","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/0-ma/geometric-shapes","creator_name":"Olivier","creator_url":"https://huggingface.co/0-ma","description":"\n\t\n\t\t\n\t\tDataset Card for Geometric Shapes Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Geometric Shapes Dataset is a synthetic dataset containing images of various geometric shapes with superimposed random text. Each image features a polygon (or just text) on a randomly colored background, with a short string of random characters partially obscuring the shape. This dataset is designed for tasks such as shape classification, image recognition, and robustness testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/0-ma/geometric-shapes.","first_N":5,"first_N_keywords":["image-classification","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Andrew_Alpha_training_data","keyword":"computer vision","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChristopherMarais/Andrew_Alpha_training_data","creator_name":"Christopher Marais","creator_url":"https://huggingface.co/ChristopherMarais","description":"\n\t\n\t\t\n\t\tBark Beetle Grouped Images for AI Classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises high-resolution photographs of bark and ambrosia beetles captured under controlled laboratory conditions. Each image contains multiple beetle specimens arranged on a uniform white background while submerged in 70% ethanol. This approach speeds up data collection and ensures reproducible imaging conditions. Individual beetle images can later be extracted from these grouped photographsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChristopherMarais/Andrew_Alpha_training_data.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"blip3-ocr-200m","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/blip3-ocr-200m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\n\t\n\t\t\n\t\tBLIP3-OCR-200M Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe BLIP3-OCR-200M dataset is designed to address the limitations of current Vision-Language Models (VLMs) in processing and interpreting text-rich images, such as documents and charts. Traditional image-text datasets often struggle to capture nuanced textual information, which is crucial for tasks requiring complex text comprehension and reasoning. \n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nOCR Integration: The dataset incorporates Optical Characterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-ocr-200m.","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Corneocyte_Nanotexture_Dataset","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jenhung/Corneocyte_Nanotexture_Dataset","creator_name":"Jen-Hung Wang","creator_url":"https://huggingface.co/jenhung","description":"\n\t\n\t\t\n\t\tProject Description\n\t\n\n\nGitHub: https://github.com/JenHungWang/ECTI_Atopic_Dermatitis\n\n","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"HumanCaption-10M","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\n\t\n\t\tHumanCaption-10M\n\t\n\nHumanCaption-10M: a large, diverse, high-quality dataset of human-related images with natural language descriptions (image to text). The dataset is designed to facilitate research on human-centered tasks. HumanCaption-10M contains approximately 10 million human-related images and their corresponding facial features in natural language descriptions and is the second generation version of FaceCaption-15M \n\n\t\n\t\t\n\t\n\t\n\t\tIllustrations\n\t\n\n\nPiplines of constructingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"AI4MARS","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hassanjbara/AI4MARS","creator_name":"Hassan Jbara","creator_url":"https://huggingface.co/hassanjbara","description":"Taken from the kaggle repository here.\n\n\t\n\t\t\n\t\tAI4Mars Dataset\n\t\n\nA dataset for terrain classification on Mars, specifically focused on Curiosity (MSL) rover data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains high-resolution Mars surface images with corresponding semantic segmentation masks for terrain classification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nimage: Original EDR (Engineering Data Record) images from Mars\nlabel_mask: Semantic segmentation masks with terrain labels\nrover_mask: Binary masks (1 =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hassanjbara/AI4MARS.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"biomed-VQA-benchmark","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdaptLLM/biomed-VQA-benchmark","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","description":"\n\t\n\t\t\n\t\tAdapting Multimodal Large Language Models to Domains via Post-Training\n\t\n\nThis repos contains the biomedical visual instruction tasks for evaluating MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\nThe main project page is: Adapt-MLLM-to-Domains\n\n\t\n\t\t\n\t\n\t\n\t\t1. Download Data\n\t\n\nYou can load datasets using the datasets library:  \nfrom datasets import load_dataset\n\n# Choose the task name from the list of available tasks\ntask_name = 'SLAKE'  #â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/biomed-VQA-benchmark.","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","10K - 100K","arrow"],"keywords_longer_than_N":true},
	{"name":"food-visual-instructions","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdaptLLM/food-visual-instructions","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","description":"\n\t\n\t\t\n\t\tAdapting Multimodal Large Language Models to Domains via Post-Training\n\t\n\nThis repos contains the food visual instructions for post-training MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\nThe main project page is: Adapt-MLLM-to-Domains\n\n\t\n\t\t\n\t\n\t\n\t\tData Information\n\t\n\nUsing our visual instruction synthesizer, we generate visual instruction tasks based on the image-caption pairs from extended Recipe1M+ dataset. These synthetic tasks, combinedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/food-visual-instructions.","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"digital_signatures","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Benjy/digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","description":"\n\t\n\t\t\n\t\tDigital Signatures Dataset\n\t\n\nThis dataset contains unique synthetic digital signatures rendered in different fonts:\n\n4,000 synthetic signatures in Rage font\n\n4,000 synthetic signatures in Mistral font\n2,000 synthetic signatures in Arial Unicode font\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nFor the development of models that can detect digital signatures in documentation using the publicly available DocusignÂ® font styles.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is organized into three folders:\n\nrage/ - Containsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Benjy/digital_signatures.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"Signature","keyword":"computer-vision","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ultralytics/Signature","creator_name":"Ultralytics","creator_url":"https://huggingface.co/Ultralytics","description":"\n\t\n\t\t\n\t\tSignature Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset focuses on detecting human written signatures within documents. It includes a variety of document types with annotated signatures, providing valuable insights for applications in document verification and fraud detection. Essential for training computer vision algorithms, this dataset aids in identifying signatures in various document formats, supporting research and practical applications in document analysis.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ultralytics/Signature.","first_N":5,"first_N_keywords":["object-detection","English","agpl-3.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"sen12vts","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/links-ads/sen12vts","creator_name":"LINKS - AI, Data & Space","creator_url":"https://huggingface.co/links-ads","description":"\n\t\n\t\t\n\t\tSEN12VTS: Sentinel 1 and 2 Vegetation Time-Series Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe SEN12VTS (Sentinel-1 & Sentinel-2 Vegetation Time-Series) dataset has been created to support research on time-series analysis for vegetation indices, specifically targeting NDVI (Normalized Difference Vegetation Index) regression tasks. Recognizing the lack of datasets catering to this specific temporal and spatial need, SEN12VTS was developed to fill the gap with a high-quality, Europe-focusedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/links-ads/sen12vts.","first_N":5,"first_N_keywords":["English","mit","ðŸ‡ºðŸ‡¸ Region: US","agricolture","computer-vision"],"keywords_longer_than_N":false},
	{"name":"Research-Papers","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khushwant04/Research-Papers","creator_name":"Khushwant Sanwalot","creator_url":"https://huggingface.co/khushwant04","description":"\n\t\n\t\t\n\t\n\t\n\t\tAI & Machine Learning Research Papers Dataset\n\t\n\nThis dataset contains a curated collection of 1296 research papers focused on advancements in Artificial Intelligence and Machine Learning. It is intended as a resource for researchers, educators, and developers to explore and analyze diverse topics within AI and ML.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nTotal Papers: 1296\nDomains Covered: \nArtificial Intelligence (AI)\nMachine Learning (ML)\nDeep Learning\nNatural Language Processing (NLP)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/khushwant04/Research-Papers.","first_N":5,"first_N_keywords":["text-classification","text-retrieval","summarization","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Sujet-Vision-QA","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/Sujet-Vision-QA","creator_name":"1-800-SHARED-TASKS","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","description":"\n\t\n\t\t\n\t\tDataset Description ðŸ“ŠðŸ”\n\t\n\nThe Sujet-Finance-QA-Vision-100k is a comprehensive dataset containing over 100,000 question-answer pairs derived from more than 9,800 financial document images. This dataset is designed to support research and development in the field of financial document analysis and visual question answering.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\nðŸ–¼ï¸ 9,801 unique financial document images\nâ“ 107,050 question-answer pairs\nðŸ‡¬ðŸ‡§ English language\nðŸ“„ Diverse financial document typesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/Sujet-Vision-QA.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM-eval","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","description":"\n\t\n\t\t\n\t\tLayoutSAM-eval Benchmark\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLayoutSAM-Eval is a comprehensive benchmark for evaluating the quality of Layout-to-Image (L2I) generation models. This benchmark assesses L2I generation quality from two perspectives: region-wise quality (spatial and attribute accuracy) and global-wise quality (visual quality and prompt following). It employs the VLMâ€™s visual question answering to evaluate spatial and attribute adherence, and utilizes various metrics including IR scoreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"GenDS","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sudarshan2002/GenDS","creator_name":"Sudarshan Rajagopalan","creator_url":"https://huggingface.co/Sudarshan2002","description":"\n\t\n\t\t\n\t\t[CVPR-2025] GenDeg: Diffusion-based Degradation Synthesis for Generalizable All-In-One Image Restoration\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for GenDS dataset\n\t\n\n\nThe GenDS dataset is a large dataset to boost the generalization of image restoration models. It is a combination of existing image restoration datasets and \ndiffusion-generated degraded samples from GenDeg. \n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset is fairly large at ~360GB. We recommend having at least 800GB of free space. To download the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sudarshan2002/GenDS.","first_N":5,"first_N_keywords":["text-to-image","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"TUC-HRI-CS","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SchulzR97/TUC-HRI-CS","creator_name":"Robert Schulz","creator_url":"https://huggingface.co/SchulzR97","description":"\n\nUniversity of Technology Chemnitz, Germany\nDepartment Robotics and Human Machine Interaction\nAuthor: Robert Schulz\n\n\t\n\t\t\n\t\tTUC-HRI Dataset Card\n\t\n\nTUC-AR is an action recognition dataset, containing 10(+1) action categories for human machine interaction. This version contains video sequences, stored as images, frame by frame.\nWe introduce two validation types: random validation and cross-subject validation. This is the cross-subject validation dataset. For random validation, please useâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SchulzR97/TUC-HRI-CS.","first_N":5,"first_N_keywords":["video-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"RobustAD","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AmazonScience/RobustAD","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","description":"\n\t\n\t\t\n\t\tRobustAD Dataset\n\t\n\n\n\t\n\t\t\n\t\tAbout the Dataset\n\t\n\nRobustAD, specifically designed to evaluate the robustness of anomaly detection models in real-world scenarios. RobustAD features a curated dataset of defect detection images with meticulously controlled distribution shifts across multiple dimensions relevant to practical applications and more closely mirrors real-world deployment scenarios.\nRobustAD is designed to cover inspection challenges across multiple industries to ensure theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/RobustAD.","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"XMS_UI","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AaronHale/XMS_UI","creator_name":"AaronHale","creator_url":"https://huggingface.co/AaronHale","description":"AaronHale/XMS_UI dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["object-detection","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"DRGBT603","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhaodong2061/DRGBT603","creator_name":"zhaodongding","creator_url":"https://huggingface.co/zhaodong2061","description":"zhaodong2061/DRGBT603 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","100K<n<1M","Image","doi:10.57967/hf/5438"],"keywords_longer_than_N":true},
	{"name":"Picklebot-2M","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hbfreed/Picklebot-2M","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n2.6 million clips of balls and called strikes from MLB games from the 2016 season through the 2023 season.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset consists of all listed balls and called strikes from Baseball Savant's Statcast Search from 2016, when their video archives began, through the 2023 season.\nThis dataset includes the date, type (eg. FF, fourseam fastball), mph, spin rate, pitcher, batter, zone (1-14â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-2M.","first_N":5,"first_N_keywords":["video-classification","mit","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V-Chinese","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tALLaVA-4V for Chinese\n\t\n\nThis is the Chinese version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Chinese through ChatGPT and instructed ChatGPT not to translate content related to OCR.\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V-Arabic","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tALLaVA-4V for Arabic\n\t\n\nThis is the Arabic version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Arabic through ChatGPT and instructed ChatGPT not to translate content related to OCR.\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University of Hongâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic.","first_N":5,"first_N_keywords":["question-answering","text-generation","Arabic","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"DEEPFRUlT_DATASET","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET","creator_name":"shangrong chi","creator_url":"https://huggingface.co/sc890","description":"\n\t\n\t\t\n\t\tDeepFruit Dataset\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains total of 21,122 fully labeled images, featuring 20 different kinds of fruits. It is structured into an 80% training set (16,899 images) and a 20% testing set (4,223 images), facilitating a ready-to-use framework for model training and evaluation.\nAdditionally, there are two CSV files that label the types of fruits depicted in each image.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe \"DeepFruit\" dataset is a comprehensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET.","first_N":5,"first_N_keywords":["feature-extraction","text-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MultiCaRe_Dataset","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset","creator_name":"Mauro Nievas Offidani","creator_url":"https://huggingface.co/mauro-nievoff","description":"The dataset contains multi-modal data from over 75,000 open access and de-identified case reports, including metadata, clinical cases, image captions and more than 130,000 images. Images and clinical cases belong to different medical specialties, such as oncology, cardiology, surgery and pathology. The structure of the dataset allows to easily map images with their corresponding article metadata, clinical case, captions and image labels. Details of the data structure can be found in the fileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"reachy-doing-things","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pollen-robotics/reachy-doing-things","creator_name":"Pollen Robotics","creator_url":"https://huggingface.co/pollen-robotics","description":"\n\t\n\t\t\n\t\tReachy Doing Things Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Reachy Doing Things Images Dataset consists of images captured from the perspective of the Reachy humanoid robot. These images were taken during teleoperation sessions, providing a unique view of the environment as perceived by the robot during manipulation tasks. The images were captured with a RGBD camera mounted on the shoulder of the robot.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset is primarily aimed at testing and validating theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pollen-robotics/reachy-doing-things.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tðŸ“š ALLaVA-4V Data\n\t\n\n\n\t\n\t\t\n\t\tGeneration Pipeline\n\t\n\n\n\n\nLAION\n\nWe leverage the superb GPT-4V to generate captions and complex reasoning QA pairs. Prompt is here.\n\nVison-FLAN\n\nWe leverage the superb GPT-4V to generate captions and detailed answer for the original instructions.  Prompt is here.\n\nWizard\n\nWe regenerate the answer of Wizard_evol_instruct with GPT-4-Turbo.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Cards\n\t\n\nAll datasets can be found here.\nThe structure of naming is shown below:\nALLaVA-4V\nâ”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Picklebot-130K","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hbfreed/Picklebot-130K","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Picklebot130k\n\t\n\n\n\n130 thousand video clips of balls and strikes from MLB games from the 2016 season through the 2023 season.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\nThe dataset consists of roughly 130 thousand video clips of balls and strikes in .mp4 format, resized to 224x224 resolution.\n\nCurated by: Henry Freed\nLicense: MIT\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: The original project that this dataset was compiledâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-130K.","first_N":5,"first_N_keywords":["video-classification","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US","baseball"],"keywords_longer_than_N":true},
	{"name":"Sujet-Finance-QA-Vision-100k","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sujet-ai/Sujet-Finance-QA-Vision-100k","creator_name":"Sujet AI","creator_url":"https://huggingface.co/sujet-ai","description":"\n\t\n\t\t\n\t\tDataset Description ðŸ“ŠðŸ”\n\t\n\nThe Sujet-Finance-QA-Vision-100k is a comprehensive dataset containing over 100,000 question-answer pairs derived from more than 9,800 financial document images. This dataset is designed to support research and development in the field of financial document analysis and visual question answering.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\nðŸ–¼ï¸ 9,801 unique financial document images\nâ“ 107,050 question-answer pairs\nðŸ‡¬ðŸ‡§ English language\nðŸ“„ Diverse financial document typesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sujet-ai/Sujet-Finance-QA-Vision-100k.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"FaceCaption-15M","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\n\t\n\t\t\n\t\tFacaCaption-15M\n\t\n\n\n\nFaceCaption-15M, a large-scale, diverse, and high-quality dataset of facial images accompanied by their natural language descriptions (facial image-to-text). This dataset aims to facilitate a study on face-centered tasks. FaceCaption-15M comprises over 15 million pairs of facial images and their corresponding natural language descriptions of facial features, making it the largest facial image caption dataset to date.\n\t\n\t\t\n\t\tNews and Updates ðŸ”¥ðŸ”¥ðŸ”¥ï¼š\n\t\n\n**[25/01/01]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"unusual-objects-unusual-places_text-image","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zer0int/unusual-objects-unusual-places_text-image","creator_name":"zer0int","creator_url":"https://huggingface.co/zer0int","description":"\n\t\n\t\t\n\t\t(Un-)usual objects in (un-)usual places\n\t\n\n\n\t\n\t\t\n\t\tA small Text-Image dataset to confuse, probe (and improve) SOTA (2024) machine vision models.\n\t\n\nTo be continued (with further examples added)...\nExample results from LMSYS ARENA (June 2024):\n\n\n","first_N":5,"first_N_keywords":["English","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"vision-feedback-mix-binarized","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized","creator_name":"NiuTrans","creator_url":"https://huggingface.co/NiuTrans","description":"\n\t\n\t\t\n\t\tDataset Card for Vision-Feedback-Mix-Binarized\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset aims to provide large-scale vision feedback data. \nIt is a combination of the following high-quality vision feedback datasets:\n\nzhiqings/LLaVA-Human-Preference-10K: 9,422 samples\nMMInstruction/VLFeedback: 80,258 samples\nYiyangAiLab/POVID_preference_data_for_VLLMs: 17,184 samples\nopenbmb/RLHF-V-Dataset: 5,733 samples\nopenbmb/RLAIF-V-Dataset: 83,132 samples\n\nWe also offer a cleaned version inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized.","first_N":5,"first_N_keywords":["mit","100K - 1M","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"vision-feedback-mix-binarized-cleaned","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized-cleaned","creator_name":"NiuTrans","creator_url":"https://huggingface.co/NiuTrans","description":"\n\t\n\t\t\n\t\tDataset Card for Vision-Feedback-Mix-Binarized-Cleaned\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset represents a cleaned version on wangclnlp/vision-feedback-mix-binarized.\nDescriptions of the base datasets, including the data format and the procedure for mixing data, can be found in this link.\n\n\t\n\t\t\n\t\tOur Methods for Cleaning Vision Feedback Data\n\t\n\nOur goal is to select vision feedback samples where the preferred outputs are significantly differentiated from the dispreferred ones, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NiuTrans/vision-feedback-mix-binarized-cleaned.","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"AUDITS","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DivyaApp/AUDITS","creator_name":"Divya Appapogu","creator_url":"https://huggingface.co/DivyaApp","description":"\n\t\n\t\t\n\t\tAUDITS: Image Manipulation Dataset\n\t\n\nAUDITS is a large-scale dataset for training and evaluating models on image manipulation detection and localization. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe folder includes train.zip, val.zip, and test.zip, each containing manipulated, original, and mask images, alongside metadata.\n\n\t\n\t\t\n\t\tðŸš€ How to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"DivyaApp/AUDITS\", split=\"train\")\n\n\n\n\t\n\t\t\n\t\tAlternatives\n\t\n\nIf loading via load_dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DivyaApp/AUDITS.","first_N":5,"first_N_keywords":["mask-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"RobustSpring","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jeschmalfuss/RobustSpring","creator_name":"Jenny Schmalfuss","creator_url":"https://huggingface.co/jeschmalfuss","description":"\n\t\n\t\t\n\t\tRobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo\n\t\n\nThis dataset provides structured metadata only for the RobustSpring dataset. All image samples are referenced by relative file paths, and must be paired with local image data downloaded separately from the public release site.\n\nDataset on the Hub: jeschmalfuss/RobustSpring\nImage Data: RobustSpring\n\nFor the related research see\nRobustSpring: Benchmarking Robustness to Image Corruptionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jeschmalfuss/RobustSpring.","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"M3_VOS","keyword":"computer-vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lijiaxin0111/M3_VOS","creator_name":"Dan","creator_url":"https://huggingface.co/Lijiaxin0111","description":" \n[CVPR 2025]  M3-VOS: Multi-Phase, Multi-Transition, and Multi-Scenery Video Object Segmentation\n\nIf you like our project, please give us a star â­ on GitHub for the latest update.  \n\n \n\n\n\t\n\t\t\n\t\tðŸ’¡ Description\n\t\n\n\nVenue: CVPR2025\nRepository: ðŸ› ï¸Tool, ðŸ Page\nPaper: arxiv.org/html/2412.13803v2\nPoint of Contact: Jiaxin Li , Zixuan Chen\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ Structure\n\t\n\nThis dataset contains annotated videos and images for object segmentation tasks with phase transition information. The directoryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lijiaxin0111/M3_VOS.","first_N":5,"first_N_keywords":["video-classification","English","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Walking-Tours-Semantic","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentic-learning-ai-lab/Walking-Tours-Semantic","creator_name":"agentic learning ai lab","creator_url":"https://huggingface.co/agentic-learning-ai-lab","description":"\n  Walking Tours Semantic\n\n\n\n\n\nWalking Tours Semantic (WT-Sem), introduced in PooDLe, provides semantic segmentation masks for videos in the Walking Tours dataset, as well as three additional videos for validation.\nFrames are sampled every 2 seconds from each video and a top-of-the-line semantic segmentation model, OpenSeed, is used to generate the masks.\nSpecifically, the Swin-L variant of OpenSeed, pretrained on COCO and Objects365 and finetuned on ADE20K, is used.\nThe 3 new walkaroundâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentic-learning-ai-lab/Walking-Tours-Semantic.","first_N":5,"first_N_keywords":["image-segmentation","image-feature-extraction","cc-by-4.0","n<1K","Image"],"keywords_longer_than_N":true},
	{"name":"2HANDS","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sjauhri/2HANDS","creator_name":"Snehal Jauhri","creator_url":"https://huggingface.co/sjauhri","description":"\n\t\n\t\t\n\t\tDataset Card for 2HANDS\n\t\n\n\n2HANDS is the 2-Handed Affordance + Narration DataSet, consisting of a large number of unimanual and bimanual object affordance segmentation masks and task narrations as affordance class-labels.  \n\nProject Site https://sites.google.com/view/2handedafforder\nPaper: https://arxiv.org/abs/2503.09320\nRepository: Coming soon\n\nEgocentric images and narrations/verb classes are derived from the EPIC-KITCHENS dataset and EPIC-VISOR annotations [1, 2].[1] Damen, D. etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sjauhri/2HANDS.","first_N":5,"first_N_keywords":["English","mit","arxiv:2503.09320","ðŸ‡ºðŸ‡¸ Region: US","computer-vision"],"keywords_longer_than_N":true},
	{"name":"gc-os-img-art-critic","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpfearnworks/gc-os-img-art-critic","creator_name":"JP","creator_url":"https://huggingface.co/jpfearnworks","description":"\n\t\n\t\t\n\t\tgc-os-img-art-critic\n\t\n\nExample gc dataset with art critic perspective\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains images with associated metadata including captions, tags, and verification information.\n","first_N":5,"first_N_keywords":["English","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US","image-to-text","computer-vision"],"keywords_longer_than_N":true},
	{"name":"deepfake-detection-dataset-v2","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v2","creator_name":"Saakshi Gupta","creator_url":"https://huggingface.co/saakshigupta","description":"\n\t\n\t\t\n\t\tDeepfake Detection Dataset V2\n\t\n\nThis dataset contains images and detailed explanations for training and evaluating deepfake detection models. It includes original images, manipulated images, confidence scores, and comprehensive technical and non-technical explanations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of:\n\nOriginal images\nCAM visualization images \nCAM overlay images\nComparison images\nLabels (real/fake)\nConfidence scores\nImage captions\nTechnical and non-technicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saakshigupta/deepfake-detection-dataset-v2.","first_N":5,"first_N_keywords":["image-classification","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"GeoDE","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MLap/GeoDE","creator_name":"aman prakash","creator_url":"https://huggingface.co/MLap","description":"Official Paper\nNumber of country classes: 40Total number of images: 61925  \n\n\t\n\t\t\n\t\tImage count per country_ip class\n\t\n\n\n\t\n\t\t\nCountry\nNumber of Images\n\n\n\t\t\nAngola\n10\n\n\nArgentina\n3193\n\n\nBotswana\n3\n\n\nBrazil\n16\n\n\nBulgaria\n1\n\n\nCameroon\n1\n\n\nChina\n1565\n\n\nColombia\n3703\n\n\nEgypt\n2449\n\n\nFrance\n59\n\n\nGhana\n1\n\n\nGreece\n45\n\n\nIndonesia\n5311\n\n\nIreland\n2\n\n\nItaly\n3933\n\n\nJapan\n6500\n\n\nJordan\n43\n\n\nMalaysia\n55\n\n\nMexico\n2723\n\n\nMoldova\n2\n\n\nNetherlands\n18\n\n\nNigeria\n5729\n\n\nPhilippines\n2906\n\n\nPoland\n68\n\n\nPortugal\n139â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MLap/GeoDE.","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"UnLOK-VQA","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vaidehi99/UnLOK-VQA","creator_name":"Vaidehi Patil","creator_url":"https://huggingface.co/vaidehi99","description":"\n\t\n\t\t\n\t\tðŸ“Š Dataset: UnLOK-VQA (Unlearning Outside Knowledge VQA)\n\t\n\nPaper: Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation\nCode: https://github.com/Vaidehi99/mmmedit\nLink: Dataset Link\nThis dataset contains approximately 500 entries with the following key attributes:\n\n\"id\": Unique Identifier for each entry\n\"src\": The question whose answer is to be deleted â“\n\"pred\": The answer to the question meant for deletion âŒ\n\"loc\": Related neighborhood questionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vaidehi99/UnLOK-VQA.","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"YOLOv8-Multiclass-Object-Detection-Dataset","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset","creator_name":"Duality AI","creator_url":"https://huggingface.co/duality-robotics","description":"\n\t\n\t\t\n\t\tDATASET SAMPLE\n\t\n\nDuality.ai  just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free!\nJust create an EDU account here. \nThis HuggingFace dataset is a 20 image and label sample, but you can get the rest at no cost by creating a FalconCloud account. Once you verify your email, the link will redirect you to the dataset page.\nWhat makes this dataset unique, useful, and capable of bridging the Sim2Real gap?\n\nThe digital twins areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset.","first_N":5,"first_N_keywords":["object-detection","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"multimedia_dataset","keyword":"computer-vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Scottie201/multimedia_dataset","creator_name":"Sinclair","creator_url":"https://huggingface.co/Scottie201","description":"\n\t\n\t\t\n\t\tMultimedia Dataset\n\t\n\nThis dataset contains both video and image files organized for machine learning tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nScottie201/multimedia_dataset/\nâ”œâ”€â”€ train/\nâ”‚   â”œâ”€â”€ video_file_1.mp4\nâ”‚   â”œâ”€â”€ video_file_2.MP4\nâ”‚   â”œâ”€â”€ image_file_1.jpg\nâ”‚   â”œâ”€â”€ image_file_2.PNG\nâ”‚   â”œâ”€â”€ ...\nâ”‚   â””â”€â”€ metadata.csv\nâ””â”€â”€ README.md\n\n\n\t\n\t\t\n\t\tSupported Media Formats\n\t\n\n\n\t\n\t\t\n\t\tVideo Files (case-insensitive)\n\t\n\n\nmp4, avi, mov, webm, mkv, flv, wmv, m4v, 3gp, ogv\n\nExamples: .mp4, .MP4, .avi, .AVIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Scottie201/multimedia_dataset.","first_N":5,"first_N_keywords":["image-classification","video-classification","image-to-text","visual-question-answering","English"],"keywords_longer_than_N":true},
	{"name":"Marathi_Handwritten","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tDataset Card for Marathi Handwritten OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Marathi Handwritten Text Dataset is a collection of handwritten text images in Marathi (à¤¦à¥‡à¤µà¤¨à¤¾à¤—à¤°à¥€ à¤²à¤¿à¤ªà¥€),\naimed at supporting the development of Optical Character Recognition (OCR) systems, handwriting analysis tools,\nand language research.The dataset was curated from native Marathi speakers to ensure a variety of handwriting styles and character variations.\nThe dataset contains 2520 images with twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten.","first_N":5,"first_N_keywords":["image-classification","image-to-text","image-feature-extraction","Marathi","mit"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","description":"\n\t\n\t\t\n\t\tLayoutSAM Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe LayoutSAM dataset is a large-scale layout dataset derived from the SAM dataset, containing 2.7 million image-text pairs and 10.7 million entities. Each entity is annotated with a spatial position (i.e., bounding box) and a textual description.\nTraditional layout datasets often exhibit a closed-set and coarse-grained nature, which may limit the model's ability to generate complex attributes such as color, shape, and texture.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tKeyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM.","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"cats_dogs_dataset","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/louiecerv/cats_dogs_dataset","creator_name":"Louie Cervantes","creator_url":"https://huggingface.co/louiecerv","description":"\n\t\n\t\t\n\t\tCats and Dogs Image Classification Dataset\n\t\n\nThis dataset contains images of cats and dogs, intended for image classification tasks. It includes two classes: \"cats\" and \"dogs\".\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is structured into two splits:\n\ntrain: Contains 8000 images for training.\ntest: Contains 2000 images for testing.\n\nImages are stored in RGB format with a resolution of 128x128 pixels.\n\n\t\n\t\t\n\t\tData Loading and Usage\n\t\n\nThe dataset can be loaded using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/louiecerv/cats_dogs_dataset.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MBZUAI-Campus","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sebothetramp/MBZUAI-Campus","creator_name":"Sebastian Cavada","creator_url":"https://huggingface.co/sebothetramp","description":"This dataset provides the necessary files and scripts to reconstruct the MBZUAI campus using COLMAP, GLOMAP, and NERFstudio. It contains preprocessed video sequences and metadata required for hierarchical 3D reconstruction.\n\nThe dataset includes:\n- Raw video sequences\n- Preprocessed frames\n- Calibration and metadata\n- Reconstruction scripts\n\nThe hierarchical reconstruction starts with a base structure, followed by incremental updates with additional sequences.\n","first_N":5,"first_N_keywords":["image-to-3d","robotics","other","English","mit"],"keywords_longer_than_N":true},
	{"name":"tool-safety-dataset","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akameswa/tool-safety-dataset","creator_name":"Adithya Kameswara Rao","creator_url":"https://huggingface.co/akameswa","description":"\n\t\n\t\t\n\t\tTool Safety Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Tool Safety Dataset is a specialized collection of tool images with detailed safety and usage information. It combines visual data with comprehensive metadata about various hand tools, making it valuable for both computer vision tasks and safety training applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nType: Image dataset with bounding boxes and detailed tool information\nSize: Multiple splits (train/test/validation)\nFormat: Images withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akameswa/tool-safety-dataset.","first_N":5,"first_N_keywords":["object-detection","image-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true}
]
;
