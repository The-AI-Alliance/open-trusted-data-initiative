const data_for_modality_benchmark = 
[
	{"name":"t2i-finegrain","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KevinDavidHayes/t2i-finegrain","creator_name":"Kevin David Hayes","creator_url":"https://huggingface.co/KevinDavidHayes","description":"\n\t\n\t\t\n\t\tt2i-finegrain Dataset\n\t\n\nThis dataset evaluates text-to-image (T2I) diffusion models using a benchmark of prompts designed to elicit specific failure modes. Human labels allow for T2I benchmarking evaluations.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n3,750+ generated images\n750+ prompts\n\n\n11 failure mode categories\n27 specific failure modes\n\n\n5 diffusion models evaluated:\nSD3-XL\nSD3-M\nSD3.5-Large\nSD3.5-Medium\nFlux\n\n\n\n\n\t\n\t\t\n\t\tFolder Structure\n\t\n\nfinegrain_dataset/\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ metadata.csv \nâ”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KevinDavidHayes/t2i-finegrain.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"eval_calibration_test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hrhraj/eval_calibration_test","creator_name":"Raj S","creator_url":"https://huggingface.co/hrhraj","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 294,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hrhraj/eval_calibration_test.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"eval_eval_calibration_test_final","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hrhraj/eval_eval_calibration_test_final","creator_name":"Raj S","creator_url":"https://huggingface.co/hrhraj","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 592,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hrhraj/eval_eval_calibration_test_final.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tiny_qa_benchmark","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark","creator_name":"Vincent Koc","creator_url":"https://huggingface.co/vincentkoc","description":"\n\t\n\t\t\n\t\tTiny QA Benchmark (Original English Core for TQB++)\n\t\n\nThis dataset (vincentkoc/tiny_qa_benchmark) is the original 52-item English Question-Answering set. It now serves as the immutable \"gold standard\" core for the expanded Tiny QA Benchmark++ (TQB++) project.\nThe TQB++ project builds upon this core dataset by introducing a powerful synthetic generation toolkit, pre-built multilingual datasets, and a comprehensive framework for rapid LLM smoke testing.\nFor the full TQB++ toolkit, theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","closed-book-qa","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"OpenS2V-Eval","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BestWishYsh/OpenS2V-Eval","creator_name":"YSH","creator_url":"https://huggingface.co/BestWishYsh","description":"\n\n\n OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation\n\n If you like our project, please give us a star â­ on GitHub for the latest update.  \n\n\n\n\t\n\t\t\n\t\tâœ¨ Summary\n\t\n\nOpenS2V-Eval introduces 180 prompts from seven major categories of S2V, which incorporate both real and synthetic test data. Furthermore, \nto accurately align human preferences with S2V benchmarks, we propose three automatic metrics: NexusScore, NaturalScore, GmeScore\nto separately quantifyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BestWishYsh/OpenS2V-Eval.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"calibrated_model_test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hrhraj/calibrated_model_test","creator_name":"Raj S","creator_url":"https://huggingface.co/hrhraj","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 597,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hrhraj/calibrated_model_test.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"eval_calibration_test_25514","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hrhraj/eval_calibration_test_25514","creator_name":"Raj S","creator_url":"https://huggingface.co/hrhraj","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 592,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hrhraj/eval_calibration_test_25514.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_4","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_4","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3534,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_4.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_6","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_6","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3779,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_6.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_8","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_8","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3327,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_8.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_12","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_12","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3766,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_12.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_15","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_15","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 2782,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_15.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"ISAAC-GR00T-V1-Pick-Place","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/ISAAC-GR00T-V1-Pick-Place","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 15,\n    \"total_frames\": 6709,\n    \"total_tasks\": 1,\n    \"total_videos\": 15,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:15\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/ISAAC-GR00T-V1-Pick-Place.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"AUDITS_","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DivyaApp/AUDITS_","creator_name":"Divya Appapogu","creator_url":"https://huggingface.co/DivyaApp","description":"\n\t\n\t\t\n\t\tAUDITS: Image Manipulation Dataset\n\t\n\nAUDITS is a large-scale dataset for training and evaluating models on image manipulation detection and localization. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe folder includes train.zip, val.zip, and test.zip, each containing manipulated, original, and mask images, alongside metadata.\n\n\t\n\t\t\n\t\tðŸš€ How to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"DivyaApp/AUDITS\", split=\"train\")\n\n\n\n\t\n\t\t\n\t\tAlternatives\n\t\n\nIf loading via load_dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DivyaApp/AUDITS_.","first_N":5,"first_N_keywords":["mask-generation","English","mit","100K<n<1M","Image"],"keywords_longer_than_N":true},
	{"name":"Researchbench","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankilok/Researchbench","creator_name":"Yujie Liu","creator_url":"https://huggingface.co/ankilok","description":"\n\t\n\t\t\n\t\tResearchBench\n\t\n\n\nBenchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition\n\nPaper Link https://arxiv.org/abs/2503.21248\nResearchBench is the first large-scale benchmark systematically evaluating Large Language Models (LLMs) on automated scientific discovery, decomposing the task into three key sub-tasks:\n\nInspiration Retrieval\nHypothesis Composition\nHypothesis Ranking\n\nThis benchmark covers 12 scientific disciplines. Each split corresponds to one subject, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankilok/Researchbench.","first_N":5,"first_N_keywords":["other","cc-by-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"so101_test3","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cornito/so101_test3","creator_name":"Corneille Marechal","creator_url":"https://huggingface.co/Cornito","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 50,\n    \"total_frames\": 17893,\n    \"total_tasks\": 1,\n    \"total_videos\": 100,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cornito/so101_test3.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so100_bimanual_test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/InterestingPopo/so100_bimanual_test","creator_name":"é›å¾å½¼","creator_url":"https://huggingface.co/InterestingPopo","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100_bimanual\",\n    \"total_episodes\": 3,\n    \"total_frames\": 2672,\n    \"total_tasks\": 1,\n    \"total_videos\": 12,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:3\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/InterestingPopo/so100_bimanual_test.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kantine/test","creator_name":"quentin","creator_url":"https://huggingface.co/kantine","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 121,\n    \"total_tasks\": 1,\n    \"total_videos\": 2,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kantine/test.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"spider-test-portuguese","keyword":"benchmark","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Boakpe/spider-test-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\n\t\n\t\t\n\t\tSpider Dataset - VersÃ£o em PortuguÃªs\n\t\n\nEste repositÃ³rio contÃ©m a traduÃ§Ã£o para portuguÃªs da partiÃ§Ã£o de teste do dataset Spider, um benchmark para a tarefa de Text-to-SQL.\n\n\t\n\t\t\n\t\tSobre esta traduÃ§Ã£o\n\t\n\nA traduÃ§Ã£o da partiÃ§Ã£o \"test\" do Spider (contendo 2.147 instÃ¢ncias) foi realizada seguindo um processo rigoroso:\n\nTraduÃ§Ã£o inicial: Utilizando a API do GPT-4o mini da OpenAI\nRevisÃ£o manual: Todas as 2.147 questÃµes foram revisadas e validadas manualmente\nCritÃ©rios de traduÃ§Ã£o:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Boakpe/spider-test-portuguese.","first_N":5,"first_N_keywords":["Portuguese","cc-by-sa-4.0","1K<n<10K","arxiv:1809.08887","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"so100_get_orange","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HYAIYN/so100_get_orange","creator_name":"Ning","creator_url":"https://huggingface.co/HYAIYN","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 2,\n    \"total_frames\": 1360,\n    \"total_tasks\": 1,\n    \"total_videos\": 4,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:2\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HYAIYN/so100_get_orange.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so100_get_orange_10epi","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HYAIYN/so100_get_orange_10epi","creator_name":"Ning","creator_url":"https://huggingface.co/HYAIYN","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 10,\n    \"total_frames\": 6885,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HYAIYN/so100_get_orange_10epi.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"csts","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/idegen/csts","creator_name":"Isabella Degen","creator_url":"https://huggingface.co/idegen","description":"CSTS (Correlation Structures in Time Series) is a comprehensive synthetic benchmarking dataset for evaluating correlation structure discovery in time series data. The dataset systematically models known correlation structures between three different time series variates and enables examination of how these structures are affected by distribution shifting, sparsification, and downsampling.","first_N":5,"first_N_keywords":["cc-by-4.0","100M - 1B","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"rook_to_d4_v3_old","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/7jep7/rook_to_d4_v3_old","creator_name":"Jonas Petersen","creator_url":"https://huggingface.co/7jep7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 2,\n    \"total_frames\": 1680,\n    \"total_tasks\": 1,\n    \"total_videos\": 2,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:2\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/7jep7/rook_to_d4_v3_old.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-v2-one","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-one","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11157,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-one.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-v2-seven","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-seven","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11173,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-seven.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-v2-eight","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-eight","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11175,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-eight.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"LAMDA","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IQSeC-Lab/LAMDA","creator_name":"Intelligent and Quantum Secure Advanced Cyber Defense Research (IQSeC) Lab","creator_url":"https://huggingface.co/IQSeC-Lab","description":"\n\t\n\t\t\n\t\tLAMDA: A Longitudinal Android Malware Dataset for Drift Analysis\n\t\n\nThis dataset contains a longitudinal benchmark for Android malware detection designed to analyze and evaluate concept drift in machine learning models. It includes labeled and feature-engineered Android APK data from 2013 to 2025 (excluding 2015), with over 1 million samples collected from real-world sources.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nLAMDA is the largest and most temporally diverse Android malware dataset to date. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IQSeC-Lab/LAMDA.","first_N":5,"first_N_keywords":["English","mit","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"ISAAC-GR00T-V2-Pick-Place","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/ISAAC-GR00T-V2-Pick-Place","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 30,\n    \"total_frames\": 13419,\n    \"total_tasks\": 1,\n    \"total_videos\": 30,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:30\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/ISAAC-GR00T-V2-Pick-Place.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"DUSK","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-ISL/DUSK","creator_name":"AI-ISL","creator_url":"https://huggingface.co/AI-ISL","description":"\n\t\n\t\t\n\t\tðŸŒ‡ DUSK: Do Not Unlearn Shared Knowledge\n\t\n\nDUSK is a benchmark dataset designed for evaluating machine unlearning in multi-source settings, where specific data sources must be forgotten while preserving others.\nIn realistic applications, documents often share factual overlap with publicly available content (e.g., Wikipedia, textbooks). DUSK challenges unlearning algorithms to precisely erase only what must be forgotten, while preserving knowledge that remains supported by otherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-ISL/DUSK.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","other","machine-generated","original"],"keywords_longer_than_N":true},
	{"name":"ParallelPrompt","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/forgelab/ParallelPrompt","creator_name":"Forge Lab","creator_url":"https://huggingface.co/forgelab","description":"\n\t\n\t\t\n\t\tPARALLELPROMPT\n\t\n\nA benchmark dataset of 37,021 parallelizable prompts from real-world LLM conversations, designed for optimizing LLM serving systems through intra-query parallelism.\n\n\t\n\t\t\n\t\tRepository and Resources\n\t\n\n\nDataset: Hugging Face\nCode: GitHub\nPaper: PARALLELPROMPT: Extracting Parallelism from Large Language Model Queries (once available)\n\nThe GitHub repository contains:\n\nData curation pipeline\nSchema extraction code\nEvaluation suite for measuring latency and qualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/forgelab/ParallelPrompt.","first_N":5,"first_N_keywords":["text-generation","other","English","multilingual","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-v2-two","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-two","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11174,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-two.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-v2-three","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-three","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11175,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-three.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-v2-four","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-four","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11170,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-four.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-v2-five","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-five","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11170,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-five.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-v2-six","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-six","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11174,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-six.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-v2-nine","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-nine","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11175,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-v2-nine.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringP2P","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AlloProfClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AlloProfClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles and descriptions from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\nReference\nhttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringS2S","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AlloProfClusteringS2S","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AlloProfClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AlloProfClusteringS2S\"])\nevaluatorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringS2S.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"ArguAna-NL","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ArguAna-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArguAna-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nArguAna involves the task of retrieval of the best counterargument to an argument. ArguAna-NL is a Dutch translation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-arguana\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArguAna-NL\"])\nevaluatorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ArguAna-NL.","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/arguana","Dutch"],"keywords_longer_than_N":true},
	{"name":"BornholmBitextMining","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BornholmBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BornholmBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDanish Bornholmsk Parallel Corpus. Bornholmsk is a Danish dialect spoken on the island of Bornholm, Denmark. Historically it is a part of east Danish which was also spoken in Scania and Halland, Sweden.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nWeb, Social, Fiction, Written\n\n\nReference\nhttps://aclanthology.org/W19-6138/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BornholmBitextMining.","first_N":5,"first_N_keywords":["translation","expert-annotated","monolingual","Danish","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"BrightLongRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BrightLongRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BrightLongRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBright retrieval dataset with long documents.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://huggingface.co/datasets/xlangai/BRIGHT\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BrightLongRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BrightLongRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","xlangai/BRIGHT"],"keywords_longer_than_N":true},
	{"name":"CBD","keyword":"mteb","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CBD","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CBD\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPolish Tweets annotated for cyberbullying detection.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWritten, Social\n\n\nReference\nhttp://2019.poleval.pl/files/poleval2019.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CBD\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CBD.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CEDRClassification","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CEDRClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CEDRClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClassification of sentences by emotions, labeled into 5 categories (joy, sadness, surprise, fear, and anger).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Social, Blog, Written\n\nReference\nhttps://www.sciencedirect.com/science/article/pii/S1877050921013247\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CEDRClassification.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"CLSClusteringP2P.v2","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CLSClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CLSClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles + abstract from CLS dataset. Clustering of 13 sets on the main category.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReferencehttps://arxiv.org/abs/2209.05034\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CLSClusteringP2P.v2\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CLSClusteringP2P.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","C-MTEB/CLSClusteringP2P"],"keywords_longer_than_N":true},
	{"name":"CSFDSKMovieReviewSentimentClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CSFDSKMovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CSFDSKMovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset contains 30k user reviews from csfd.cz in Slovak.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2304.01922\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CSFDSKMovieReviewSentimentClassification\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CSFDSKMovieReviewSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CataloniaTweetClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CataloniaTweetClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CataloniaTweetClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains two corpora in Spanish and Catalan that consist of annotated Twitter\n        messages for automatic stance detection. The data was collected over 12 days during February and March\n        of 2019 from tweets posted in Barcelona, and during September of 2018 from tweets posted in the town of Terrassa, Catalonia.\n        Each corpus is annotated with three classes: AGAINST, FAVOR andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CataloniaTweetClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","multilingual","Catalan","Spanish"],"keywords_longer_than_N":true},
	{"name":"CodeFeedbackST","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CodeFeedbackST","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CodeFeedbackST\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of user queries and assistant responses. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\nReference\nhttps://arxiv.org/abs/2407.02883\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CodeFeedbackST\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CodeFeedbackST.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"Core17InstructionRetrieval","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Core17InstructionRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Core17InstructionRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMeasuring retrieval instruction following ability on Core17 narratives for the FollowIR benchmark.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReferencehttps://arxiv.org/abs/2403.15246\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Core17InstructionRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Core17InstructionRetrieval.","first_N":5,"first_N_keywords":["text-ranking","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"DanFeverRetrieval","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DanFeverRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DanFeverRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Danish dataset intended for misinformation research. It follows the same format as the English FEVER dataset. DanFeverRetrieval fixed an issue in DanFever where some corpus entries were incorrectly removed.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Spoken\n\n\nReference\nhttps://aclanthology.org/2021.nodalida-main.47/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DanFeverRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"EightTagsClustering","keyword":"mteb","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/EightTagsClustering","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  EightTagsClustering\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of headlines from social media posts in Polish belonging to 8 categories: film, history, food, medicine, motorization, work, sport and technology.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsSocial, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.207.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/EightTagsClustering.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Polish"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringP2P.v2","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AlloProfClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AlloProfClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles and descriptions from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\nReference\nhttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringP2P.v2.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","lyon-nlp/alloprof","French"],"keywords_longer_than_N":true},
	{"name":"AutoRAGRetrieval","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AutoRAGRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AutoRAGRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset enables the evaluation of Korean RAG performance across various domainsâ€”finance, public sector, healthcare, legal, and commerceâ€”by providing publicly accessible documents, questions, and answers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Medical, Legal, Social, Financial\n\n\nReference\nhttps://arxiv.org/abs/2410.20878\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AutoRAGRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"BengaliHateSpeechClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BengaliHateSpeechClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/bn_hate_speech\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CLSClusteringS2S.v2","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CLSClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CLSClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles from CLS dataset. Clustering of 13 sets on the main category.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://arxiv.org/abs/2209.05034\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CLSClusteringS2S.v2\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CLSClusteringS2S.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","C-MTEB/CLSClusteringS2S"],"keywords_longer_than_N":true},
	{"name":"CSFDCZMovieReviewSentimentClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CSFDCZMovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CSFDCZMovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset contains 30k user reviews from csfd.cz in Czech.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2304.01922\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CSFDCZMovieReviewSentimentClassification\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CSFDCZMovieReviewSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CUADAffiliateLicenseLicenseeLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicenseeLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADAffiliateLicenseLicenseeLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if a clause describes a license grant to a licensee (incl. sublicensor) and the affiliates of such licensee/sublicensor.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicenseeLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADAffiliateLicenseLicensorLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicensorLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADAffiliateLicenseLicensorLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause describes a license grant by affiliates of the licensor or that includes intellectual property of affiliates of the licensor.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAffiliateLicenseLicensorLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADAntiAssignmentLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADAntiAssignmentLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADAntiAssignmentLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause requires consent or notice of a party if the contract is assigned to a third party.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAntiAssignmentLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADAuditRightsLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADAuditRightsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADAuditRightsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause gives a party the right to audit the books, records, or physical locations of the counterparty to ensure compliance with the contract.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADAuditRightsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADCapOnLiabilityLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADCapOnLiabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADCapOnLiabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a cap on liability upon the breach of a party's obligation. This includes time limitation for the counterparty to bring claims or maximum amount for recovery.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADCapOnLiabilityLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADChangeOfControlLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADChangeOfControlLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADChangeOfControlLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause gives one party the right to terminate or is consent or notice required of the counterparty if such party undergoes a change of control, such as a merger, stock sale, transfer of all or substantially all of its assets or business, or assignment by operation of law.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADChangeOfControlLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADCompetitiveRestrictionExceptionLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADCompetitiveRestrictionExceptionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADCompetitiveRestrictionExceptionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause mentions exceptions or carveouts to Non-Compete, Exclusivity and No-Solicit of Customers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADCompetitiveRestrictionExceptionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADCovenantNotToSueLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADCovenantNotToSueLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADCovenantNotToSueLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that a party is restricted from contesting the validity of the counterparty's ownership of intellectual property or otherwise bringing a claim against the counterparty for matters unrelated to the contract.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADCovenantNotToSueLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADExclusivityLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADExclusivityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADExclusivityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies exclusive dealing commitment with the counterparty. This includes a commitment to procure all 'requirements' from one party of certain technology, goods, or services or a prohibition on licensing or selling technology, goods or services to third parties, or a prohibition on collaborating or workingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADExclusivityLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADGoverningLawLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADGoverningLawLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADGoverningLawLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies which state/countryâ€™s law governs the contract.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADGoverningLawLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADIPOwnershipAssignmentLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADIPOwnershipAssignmentLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADIPOwnershipAssignmentLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that intellectual property created by one party become the property of the counterparty, either per the terms of the contract or upon the occurrence of certain events.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADIPOwnershipAssignmentLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADInsuranceLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADInsuranceLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADInsuranceLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if clause creates a requirement for insurance that must be maintained by one party for the benefit of the counterparty.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADInsuranceLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADJointIPOwnershipLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADJointIPOwnershipLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADJointIPOwnershipLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause provides for joint or shared ownership of intellectual property between the parties to the contract.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADJointIPOwnershipLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADLicenseGrantLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADLicenseGrantLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADLicenseGrantLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause contains a license granted by one party to its counterparty.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADLicenseGrantLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADLiquidatedDamagesLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADLiquidatedDamagesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADLiquidatedDamagesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause awards either party liquidated damages for breach or a fee upon the termination of a contract (termination fee).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADLiquidatedDamagesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADMinimumCommitmentLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADMinimumCommitmentLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADMinimumCommitmentLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a minimum order size or minimum amount or units per time period that one party must buy from the counterparty.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADMinimumCommitmentLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADMostFavoredNationLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADMostFavoredNationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADMostFavoredNationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if a third party gets better terms on the licensing or sale of technology/goods/services described in the contract, the buyer of such technology/goods/services under the contract shall be entitled to those better terms.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADMostFavoredNationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNonCompeteLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNonCompeteLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNonCompeteLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause restricts the ability of a party to compete with the counterparty or operate in a certain geography or business or technology sector.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNonCompeteLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNonDisparagementLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNonDisparagementLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNonDisparagementLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause requires a party not to disparage the counterparty.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNonDisparagementLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNonTransferableLicenseLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNonTransferableLicenseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNonTransferableLicenseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause limits the ability of a party to transfer the license being granted to a third party.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNonTransferableLicenseLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNoticePeriodToTerminateRenewalLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNoticePeriodToTerminateRenewalLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNoticePeriodToTerminateRenewalLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a notice period required to terminate renewal.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNoticePeriodToTerminateRenewalLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADPostTerminationServicesLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADPostTerminationServicesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADPostTerminationServicesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause subjects a party to obligations after the termination or expiration of a contract, including any post-termination transition, payment, transfer of IP, wind-down, last-buy, or similar commitments.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADPostTerminationServicesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADPriceRestrictionsLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADPriceRestrictionsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADPriceRestrictionsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause places a restriction on the ability of a party to raise or reduce prices of technology, goods, or services provided.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADPriceRestrictionsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADRenewalTermLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADRenewalTermLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADRenewalTermLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a renewal term.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADRenewalTermLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADRevenueProfitSharingLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADRevenueProfitSharingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADRevenueProfitSharingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause require a party to share revenue or profit with the counterparty for any technology, goods, or services.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADRevenueProfitSharingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADRofrRofoRofnLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADRofrRofoRofnLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADRofrRofoRofnLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause grant one party a right of first refusal, right of first offer or right of first negotiation to purchase, license, market, or distribute equity interest, technology, assets, products or services.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADRofrRofoRofnLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADSourceCodeEscrowLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADSourceCodeEscrowLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADSourceCodeEscrowLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause requires one party to deposit its source code into escrow with a third party, which can be released to the counterparty upon the occurrence of certain events (bankruptcy, insolvency, etc.).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADSourceCodeEscrowLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADVolumeRestrictionLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADVolumeRestrictionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADVolumeRestrictionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a fee increase or consent requirement, etc. if one party's use of the product/services exceeds certain threshold.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADVolumeRestrictionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIConfidentialityOfAgreementLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIConfidentialityOfAgreementLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIConfidentialityOfAgreementLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA provides that the Receiving Party shall not disclose the fact that Agreement was agreed or negotiated.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIConfidentialityOfAgreementLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIExplicitIdentificationLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIExplicitIdentificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIExplicitIdentificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that all Confidential Information shall be expressly identified by the Disclosing Party.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIExplicitIdentificationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLINoticeOnCompelledDisclosureLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLINoticeOnCompelledDisclosureLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLINoticeOnCompelledDisclosureLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party shall notify Disclosing Party in case Receiving Party is required by law, regulation or judicial process to disclose any Confidential Information.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLINoticeOnCompelledDisclosureLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLISharingWithThirdPartiesLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLISharingWithThirdPartiesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLISharingWithThirdPartiesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may share some Confidential Information with some third-parties (including consultants, agents and professional advisors).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLISharingWithThirdPartiesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CrossLingualSemanticDiscriminationWMT19","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CrossLingualSemanticDiscriminationWMT19","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CrossLingualSemanticDiscriminationWMT19\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nEvaluate a multilingual embedding model based on its ability to discriminate against the original parallel pair against challenging distractors - spawning from WMT19 DE-FR test set\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/Andrianos/clsd_wmt19_21\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CrossLingualSemanticDiscriminationWMT19.","first_N":5,"first_N_keywords":["text-retrieval","derived","multilingual","German","French"],"keywords_longer_than_N":true},
	{"name":"Diversity1LegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity1LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity1LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 1).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity1LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"FaroeseSTS","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FaroeseSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FaroeseSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSemantic Text Similarity (STS) corpus for Faroese.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://aclanthology.org/2023.nodalida-1.74.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FaroeseSTS\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FaroeseSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Faroese"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-NL","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FiQA2018-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FiQA2018-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFinancial Opinion Mining and Question Answering. FiQA2018-NL is a Dutch translation\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-fiqa\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FiQA2018-NL\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FiQA2018-NL.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","mteb/fiqa"],"keywords_longer_than_N":true},
	{"name":"FinParaSTS","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FinParaSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FinParaSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFinnish paraphrase-based semantic similarity corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Subtitles, Written\n\n\nReference\nhttps://huggingface.co/datasets/TurkuNLP/turku_paraphrase_corpus\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FinParaSTS\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FinParaSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","expert-annotated","monolingual","Finnish"],"keywords_longer_than_N":true},
	{"name":"FrenchBookReviews","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FrenchBookReviews","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FrenchBookReviews\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIt is a French book reviews dataset containing a huge number of reader reviews on French books. Each review is pared with a rating that ranges from 0.5 to 5 (with 0.5 increment).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nReviews, Written\n\n\nReference\nhttps://huggingface.co/datasets/Abirate/french_book_reviews\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FrenchBookReviews.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","French","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"FunctionOfDecisionSectionLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FunctionOfDecisionSectionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FunctionOfDecisionSectionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task is to classify a paragraph extracted from a written court decision into one of seven possible categories:\n            1. Facts - The paragraph describes the faction background that led up to the present lawsuit.\n            2. Procedural History - The paragraph describes the course of litigation that led to the current proceeding before the court.\n            3. Issue - Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FunctionOfDecisionSectionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"GeoreviewClusteringP2P","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GeoreviewClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GeoreviewClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nReview clustering based on Yandex Georeview dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/yandex/geo-reviews-dataset-2023\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeoreviewClusteringP2P\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeoreviewClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"GermanGovServiceRetrieval","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GermanGovServiceRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLHM-Dienstleistungen-QA is a German question answering dataset for government services of the Munich city administration. It associates questions with a textual context containing the answer\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Written\n\n\nReference\nhttps://huggingface.co/datasets/it-at-m/LHM-Dienstleistungen-QA\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"GreekLegalCodeClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GreekLegalCodeClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GreekLegalCodeClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGreek Legal Code Dataset for Classification. (subset = chapter)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://arxiv.org/abs/2109.15298\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GreekLegalCodeClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GreekLegalCodeClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","human-annotated","monolingual","Modern Greek (1453-)"],"keywords_longer_than_N":true},
	{"name":"HeadlineClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HeadlineClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HeadlineClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHeadline rubric classification based on the paraphraser plus dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://aclanthology.org/2020.ngt-1.6/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HeadlineClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HeadlineClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Russian"],"keywords_longer_than_N":true},
	{"name":"HebrewSentimentAnalysis","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HebrewSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHebrewSentiment is a data set consists of 12,804 user comments to posts on the official Facebook page of Israelâ€™s president, Mr. Reuven Rivlin. In October 2015, we used the open software application Netvizz (Rieder, 2013) to scrape all the comments to all of the presidentâ€™s posts in the period of June â€“ August 2014, the first three months of Rivlinâ€™s presidency.2 While the presidentâ€™s posts aimed at reconcilingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"HindiDiscourseClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HindiDiscourseClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HindiDiscourseClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Hindi Discourse dataset in Hindi with values for coherence.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nFiction, Social, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.149/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HindiDiscourseClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HindiDiscourseClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","Hindi","mit"],"keywords_longer_than_N":true},
	{"name":"HunSum2AbstractiveRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HunSum2AbstractiveRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHunSum-2-abstractive is a Hungarian dataset containing news articles along with lead, titles and metadata.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/2404.03555\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HunSum2AbstractiveRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HunSum2AbstractiveRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Hungarian"],"keywords_longer_than_N":true},
	{"name":"InternationalCitizenshipQuestionsLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/InternationalCitizenshipQuestionsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  InternationalCitizenshipQuestionsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAnswer questions about citizenship law from across the world. Dataset was made using the GLOBALCIT citizenship law dataset, by constructing questions about citizenship law as Yes or No questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InternationalCitizenshipQuestionsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ItaCaseholdClassification","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ItaCaseholdClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ItaCaseholdClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAn Italian Dataset consisting of 1101 pairs of judgments and their official holdings between the years 2019 and 2022 from the archives of Italian Administrative Justice categorized with 64 subjects.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Government, Written\n\n\nReference\nhttps://doi.org/10.1145/3594536.3595177\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ItaCaseholdClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","Italian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"JSICK","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JSICK","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JSICK\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJSICK is the Japanese NLI and STS dataset by manually translating the English dataset SICK (Marelli et al., 2014) into Japanese.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"JSICK\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JSICK.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"JaGovFaqsRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JaGovFaqsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJaGovFaqs is a dataset consisting of FAQs manully extracted from the website of Japanese bureaus. The dataset consists of 22k FAQs, where the queries (questions) and corpus (answers) have been shuffled, and the goal is to match the answer with the question.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"KLUE-TC","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KLUE-TC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KLUE-TC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTopic classification dataset of human-annotated news headlines. Part of the Korean Language Understanding Evaluation (KLUE).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/2105.09680\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"KLUE-TC\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KLUE-TC.","first_N":5,"first_N_keywords":["text-classification","topic-classification","human-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"KorHateClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorHateClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset was created to provide the first human-labeled Korean corpus for\n        toxic speech detection from a Korean online entertainment news aggregator. Recently,\n        two young Korean celebrities suffered from a series of tragic incidents that led to two\n        major Korean web portals to close the comments section on their platform. However, this only\n        serves as a temporary solution, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorHateClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KorHateSpeechMLClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorHateSpeechMLClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorHateSpeechMLClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The Korean Multi-label Hate Speech Dataset, K-MHaS, consists of 109,692 utterances from Korean online news comments,\n    labelled with 8 fine-grained hate speech classes (labels: Politics, Origin, Physical, Age, Gender, Religion, Race, Profanity)\n    or Not Hate Speech class. Each utterance provides from a single to four labels that can handles Korean language patterns effectively.\n    For more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorHateSpeechMLClassification.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"KorSTS","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBenchmark dataset for STS in Korean. Created by machine translation and human post editing of the STS-B dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Web\n\n\nReference\nhttps://arxiv.org/abs/2004.03289\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"KorSTS\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","translated","Korean","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"LitSearchRetrieval","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LitSearchRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LitSearchRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The dataset contains the query set and retrieval corpus for the paper LitSearch: A Retrieval Benchmark for\n    Scientific Literature Search. It introduces LitSearch, a retrieval benchmark comprising 597 realistic literature\n    search queries about recent ML and NLP papers. LitSearch is constructed using a combination of (1) questions\n    generated by GPT-4 based on paragraphs containing inline citations fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LitSearchRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","LM-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"MAUDLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MAUDLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MAUDLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the MAUD dataset, which consists of over 47,000 labels across 152 merger agreements annotated to identify 92 questions in each agreement used by the 2021 American Bar Association (ABA) Public Target Deal Points Study. Each dataset is formatted as a series of multiple-choice questions, where given a segment of the merger agreement and a Deal Point question, the model is toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MAUDLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MalayalamNewsClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MalayalamNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MalayalamNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Malayalam dataset for 3-class classification of Malayalam news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-malyalam\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MalayalamNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MalayalamNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"MarathiNewsClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MarathiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MarathiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Marathi dataset for 3-class classification of Marathi news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-marathi\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MarathiNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MarathiNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Marathi"],"keywords_longer_than_N":true},
	{"name":"MewsC16JaClustering","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MewsC16JaClustering","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MewsC16JaClustering\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMewsC-16 (Multilingual Short Text Clustering Dataset for News in 16 languages) is constructed from Wikinews.\n        This dataset is the Japanese split of MewsC-16, containing topic sentences from Wikinews articles in 12 categories.\n        More detailed information is available in the Appendix E of the citation.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEBâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MewsC16JaClustering.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-NL","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NFCorpus-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NFCorpus-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval. NFCorpus-NL is a Dutch translation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Written\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-nfcorpus\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NFCorpus-NL\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NFCorpus-NL.","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/nfcorpus","Dutch"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsIntroRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NLPJournalAbsIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given abstract.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NYSJudicialEthicsLegalBenchClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NYSJudicialEthicsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NYSJudicialEthicsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAnswer questions on judicial ethics from the New York State Unified Court System Advisory Committee.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NYSJudicialEthicsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"NaijaSenti","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NaijaSenti","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NaijaSenti\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNaijaSenti is the first large-scale human-annotated Twitter sentiment dataset for the four most widely spoken languages in Nigeria â€” Hausa, Igbo, Nigerian-Pidgin, and YorÃ¹bÃ¡ â€” consisting of around 30,000 annotated tweets per language, including a significant fraction of code-mixed tweets.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://github.com/hausanlp/NaijaSenti\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NaijaSenti.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"NanoArguAnaRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoArguAnaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoArguAnaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoArguAna is a smaller subset of ArguAna, a dataset for argument retrieval in debate contexts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReferencehttp://argumentation.bplaced.net/arguana/data\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoArguAnaRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoArguAnaRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","mteb/arguana","English"],"keywords_longer_than_N":true},
	{"name":"NanoClimateFeverRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoClimateFeverRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoClimateFever is a small version of the BEIR dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsNon-fiction, Academic, News\n\n\nReference\nhttps://arxiv.org/abs/2012.00614\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoClimateFeverRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoFEVERRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoFEVERRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoFEVERRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFEVER is a smaller version of FEVER (Fact Extraction and VERification), which consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nAcademic, Encyclopaedic\n\n\nReference\nhttps://fever.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFEVERRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"NanoMSMARCORetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoMSMARCORetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoMSMARCORetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoMSMARCORetrieval is a smaller subset of MS MARCO, a collection of datasets focused on deep learning in search.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReferencehttps://microsoft.github.io/msmarco/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoMSMARCORetrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoMSMARCORetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/msmarco"],"keywords_longer_than_N":true},
	{"name":"NanoNQRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoNQRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoNQRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoNQ is a smaller subset of a dataset which contains questions from real users, and it requires QA systems to read and comprehend an entire Wikipedia article that may or may not contain the answer to the question.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Web\n\n\nReference\nhttps://ai.google.com/research/NaturalQuestions\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoNQRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/nq"],"keywords_longer_than_N":true},
	{"name":"NanoTouche2020Retrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoTouche2020Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoTouche2020Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoTouche2020 is a smaller subset of TouchÃ© Task 1: Argument Retrieval for Controversial Questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReferencehttps://webis.de/events/touche-20/shared-task-1.html\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoTouche2020Retrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoTouche2020Retrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/touche2020"],"keywords_longer_than_N":true},
	{"name":"NepaliNewsClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NepaliNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NepaliNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Nepali dataset for 7500 news articles \n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-nepali\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NepaliNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NepaliNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Nepali (macrolanguage)"],"keywords_longer_than_N":true},
	{"name":"NevIR","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NevIR","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NevIR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPaired evaluation of real world negation in retrieval, with questions and passages. Since models generally prefer one passage over the other always, there are two questions that the model must get right to understand the negation (hence the paired_accuracy metric).\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReference\nhttps://github.com/orionw/NevIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NevIR.","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NollySentiBitextMining","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NollySentiBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NollySentiBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNollySenti is Nollywood movie reviews for five languages widely spoken in Nigeria (English, Hausa, Igbo, Nigerian-Pidgin, and Yoruba.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Reviews, Written\nReference\nhttps://github.com/IyanuSh/NollySenti\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NollySentiBitextMining.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","English","Hausa"],"keywords_longer_than_N":true},
	{"name":"NorwegianCourtsBitextMining","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NorwegianCourtsBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NorwegianCourtsBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNynorsk and BokmÃ¥l parallel corpus from Norwegian courts. Norwegian courts have two standardised written languages. BokmÃ¥l is a variant closer to Danish, while Nynorsk was created to resemble regional dialects of Norwegian.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://opus.nlpl.eu/index.php\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NorwegianCourtsBitextMining.","first_N":5,"first_N_keywords":["translation","human-annotated","monolingual","Norwegian Nynorsk","Norwegian BokmÃ¥l"],"keywords_longer_than_N":true},
	{"name":"NusaParagraphTopicClassification","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NusaParagraphTopicClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NusaParagraphTopicClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNusaParagraphTopicClassification is a multi-class topic classification on 10 Indonesian languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNon-fiction, Fiction, Written\nReference\nhttps://github.com/IndoNLP/nusa-writes\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NusaParagraphTopicClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","human-annotated","multilingual","Batak Toba"],"keywords_longer_than_N":true},
	{"name":"NusaXBitextMining","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NusaXBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NusaXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNusaX is a parallel dataset for machine translation and sentiment analysis on 11 Indonesia languages and English.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://huggingface.co/datasets/indonlp/NusaX-senti/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NusaXBitextMining\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NusaXBitextMining.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Balinese"],"keywords_longer_than_N":true},
	{"name":"OdiaNewsClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/OdiaNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  OdiaNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Odia dataset for 3-class classification of Odia news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-odia\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"OdiaNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/OdiaNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Odia"],"keywords_longer_than_N":true},
	{"name":"OralArgumentQuestionPurposeLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/OralArgumentQuestionPurposeLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  OralArgumentQuestionPurposeLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task classifies questions asked by Supreme Court justices at oral argument into seven categories:\n        1. Background - questions seeking factual or procedural information that is missing or not clear in the briefing\n        2. Clarification - questions seeking to get an advocate to clarify her position or the scope of the rule being advocated for\n        3. Implications -â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/OralArgumentQuestionPurposeLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PROALegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PROALegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PROALegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a statute, determine if the text contains an explicit private right of action. Given a privacy policy clause and a description of the clause, determine if the description is correct. A private right of action (PROA) exists when a statute empowers an ordinary individual (i.e., a private person) to legally enforce their rights by bringing an action in court. In short, a PROA creates the ability for anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PROALegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PUGGRetrieval","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PUGGRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PUGGRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nInformation Retrieval PUGG dataset for the Polish language.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb\n\n\nReference\nhttps://aclanthology.org/2024.findings-acl.652/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PUGGRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PUGGRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","Polish"],"keywords_longer_than_N":true},
	{"name":"PlscClusteringP2P.v2","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PlscClusteringP2P.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PlscClusteringP2P.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of Polish article titles+abstracts from Library of Science (https://bibliotekanauki.pl/), either on the scientific field or discipline.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/rafalposwiata/plsc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PlscClusteringP2P.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","PL-MTEB/plsc-clustering-p2p"],"keywords_longer_than_N":true},
	{"name":"PlscClusteringS2S.v2","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PlscClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PlscClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of Polish article titles from Library of Science (https://bibliotekanauki.pl/), either on the scientific field or discipline.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/rafalposwiata/plsc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PlscClusteringS2S.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","PL-MTEB/plsc-clustering-s2s"],"keywords_longer_than_N":true},
	{"name":"PolEmo2.0-IN","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PolEmo2.0-IN","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PolEmo2.0-IN\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA collection of Polish online reviews from four domains: medicine, hotels, products and school. The PolEmo2.0-IN task is to predict the sentiment of in-domain (medicine and hotels) reviews.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nWritten, Social\n\n\nReference\nhttps://aclanthology.org/K19-1092.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PolEmo2.0-IN.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-veo2","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Google DeepMind Veo2 Human Preference\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~45'000 human annotations were collected to evaluate Google DeepMind Veo2 video generation model on our benchmark. The up to dateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo2.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"so100_screwdriver","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gaugou/so100_screwdriver","creator_name":"Gauthier Bassereau","creator_url":"https://huggingface.co/Gaugou","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 10,\n    \"total_frames\": 5986,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gaugou/so100_screwdriver.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"whisper_asr_traindata","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sarannair/whisper_asr_traindata","creator_name":"Saran Nair","creator_url":"https://huggingface.co/sarannair","description":"\n\t\n\t\t\n\t\tEnglish Accent Audio-transcript Dataset.\n\t\n\nAudio is extracted from movies, shows, speeches, talks to capture diverse accents - mainly scottish and indian\nThis dataset contains 30-second audio clips with aligned transcript text. \n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach entry includes:\n\naudio: 30-second speech segment\ntext: Corresponding transcript\nstart_time / end_time: Segment timestamps\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nLicensed under CC-BY-4.0.\n","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"winogrande","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/winogrande","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\twinogrande Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: winogrande\nSubset: winogrande_xl\nEvaluation Split: validation\nTraining Split: train\nTask Type: multiple_choice_completion\nProcessing Function: process_winogrande\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_winogrande(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process WinoGrande dataset example.\"\"\"\n    #â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/winogrande.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"piqa","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/piqa","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tpiqa Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: piqa\nSubset: plain_text\nEvaluation Split: validation\nTraining Split: train\nTask Type: multiple_choice\nProcessing Function: process_piqa\n\n\n\t\n\t\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_piqa(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process PIQA dataset example.\"\"\"\n    query = example[\"goal\"]\n    choices = [example[\"sol1\"]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/piqa.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"copa","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/copa","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tcopa Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: super_glue\nSubset: copa\nEvaluation Split: validation\nTraining Split: train\nTask Type: multiple_choice_completion\nProcessing Function: process_copa\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_copa(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process COPA dataset example.\"\"\"\n    phrase_mapping = {\n        \"cause\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/copa.","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"race_middle","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/race_middle","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\trace_middle Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: race\nSubset: middle\nEvaluation Split: test\nTraining Split: train\nTask Type: multiple_choice_with_context\nProcessing Function: process_race\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_race(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process RACE dataset example.\"\"\"\n    context = example[\"article\"]\n    query =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/race_middle.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"race_high","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/race_high","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\trace_high Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: race\nSubset: high\nEvaluation Split: test\nTraining Split: train\nTask Type: multiple_choice_with_context\nProcessing Function: process_race\n\n\n\t\n\t\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_race(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process RACE dataset example.\"\"\"\n    context = example[\"article\"]\n    query =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/race_high.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"race_high_completion","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/race_high_completion","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\trace_high_completion Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: race\nSubset: high\nEvaluation Split: test\nTraining Split: train\nTask Type: multiple_choice_completion\nProcessing Function: process_race_completion\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_race_completion(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process RACE dataset example.\"\"\"\n    context =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/race_high_completion.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"mmlu","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/mmlu","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tmmlu Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: lighteval/mmlu\nSubset: ['abstract_algebra', 'anatomy', 'astronomy', 'business_ethics', 'clinical_knowledge','college_biology', 'college_chemistry', 'college_computer_science', 'college_mathematics','college_medicine', 'college_physics', 'computer_security', 'conceptual_physics','econometrics', 'electrical_engineering', 'elementary_mathematics', 'formal_logic','global_facts', 'high_school_biology'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/mmlu.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"El-TARA_Spanish_LLM_Benchmark","keyword":"benchmark","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emre/El-TARA_Spanish_LLM_Benchmark","creator_name":"Davut Emre TASAR","creator_url":"https://huggingface.co/emre","description":"\n\t\n\t\t\n\t\tEl-Tara: EvaluaciÃ³n de Razonamiento Avanzado en EspaÃ±ol\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEl-Tara (EvaluaciÃ³n de Razonamiento Avanzado en EspaÃ±ol) is a benchmark dataset designed to assess the advanced reasoning capabilities of Large Language Models (LLMs) in Spanish. It is adapted from the original TARA (Turkish Advanced Reasoning Assessment) dataset.\nSimilar to TARA, El-Tara aims to test higher-order cognitive skills across multiple domains, using synthetically generated questionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emre/El-TARA_Spanish_LLM_Benchmark.","first_N":5,"first_N_keywords":["question-answering","text-generation","Spanish","afl-3.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"so100_grab_test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wannrrr/so100_grab_test","creator_name":"Erwann WICART","creator_url":"https://huggingface.co/wannrrr","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 50,\n    \"total_frames\": 14396,\n    \"total_tasks\": 1,\n    \"total_videos\": 100,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wannrrr/so100_grab_test.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"pig","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pierfabre/pig","creator_name":"Pierre FABRE","creator_url":"https://huggingface.co/pierfabre","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 149,\n    \"total_tasks\": 1,\n    \"total_videos\": 2,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pierfabre/pig.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"pig_test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pierfabre/pig_test","creator_name":"Pierre FABRE","creator_url":"https://huggingface.co/pierfabre","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 3,\n    \"total_frames\": 1786,\n    \"total_tasks\":1,\n    \"total_videos\": 6,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:3\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pierfabre/pig_test.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"pig2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pierfabre/pig2","creator_name":"Pierre FABRE","creator_url":"https://huggingface.co/pierfabre","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 10,\n    \"total_frames\": 5355,\n    \"total_tasks\":1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pierfabre/pig2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"pig3","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pierfabre/pig3","creator_name":"Pierre FABRE","creator_url":"https://huggingface.co/pierfabre","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 10,\n    \"total_frames\": 5359,\n    \"total_tasks\":1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pierfabre/pig3.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"pig3_seg","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adrienloizeau/pig3_seg","creator_name":"Adrien Loizeau","creator_url":"https://huggingface.co/adrienloizeau","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 10,\n    \"total_frames\": 5359,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/adrienloizeau/pig3_seg.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"GiftEvalPretrain","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liamsbhoo/GiftEvalPretrain","creator_name":"Liam Shi Bin Hoo","creator_url":"https://huggingface.co/liamsbhoo","description":"\n\t\n\t\t\n\t\tGIFT-Eval Pre-training Datasets\n\t\n\nPretraining dataset aligned with GIFT-Eval that has 71 univariate and 17 multivariate datasets, spanning seven domains and 13 frequencies, totaling 4.5 million time series and 230 billion data points. Notably this collection of data has no leakage issue with the train/test split and can be used to pretrain foundation models that can be fairly evaluated on GIFT-Eval.\nðŸ“„ Paper\nðŸ–¥ï¸ Code\nðŸ“” Blog Post\nðŸŽï¸ Leader Board\n\n\t\n\t\n\t\n\t\tEthical Considerationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/liamsbhoo/GiftEvalPretrain.","first_N":5,"first_N_keywords":["time-series-forecasting","apache-2.0","1M - 10M","arrow","Text"],"keywords_longer_than_N":true},
	{"name":"turkish-grammar-mmlu","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-db/turkish-grammar-mmlu","creator_name":"TurkishDB","creator_url":"https://huggingface.co/turkish-db","description":"\n\t\n\t\t\n\t\tTurkish-Grammar-MMLU\n\t\n\nThis dataset, created by Turkish-DB, is a multiple-choice question-answering (QA) dataset covering Turkish grammar topics. It is designed to evaluate model performance on various Turkish grammar subjects, similar to the MMLU (Massive Multitask Language Understanding) benchmark.\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nName: Turkish-Grammar-MMLU\nProvider: Turkish-DB\nTask: Multiple-Choice QA\nModality: Text\nFormat: CSV (also accessible via API in Parquet format)\nLanguage: Turkishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/turkish-db/turkish-grammar-mmlu.","first_N":5,"first_N_keywords":["question-answering","Turkish","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Tab-MIA","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/germane/Tab-MIA","creator_name":"Eyal German","creator_url":"https://huggingface.co/germane","description":"\n\t\n\t\t\n\t\tTab-MIA: A Benchmark for Membership Inference Attacks on Tabular Data\n\t\n\nTab-MIA is a benchmark dataset designed to evaluate the privacy risks of fine-tuning large language models (LLMs) on structured tabular data. It enables reproducible and systematic testing of Membership Inference Attacks (MIAs) across diverse datasets and six different serialization formats.\n\n\t\n\t\t\n\t\tðŸ“‹ Overview\n\t\n\n\nDatasets:  \n\nWTQ (WikiTableQuestions)  \nWikiSQL  \nTabFact  \nAdult Census  \nCalifornia Housingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/germane/Tab-MIA.","first_N":5,"first_N_keywords":["text-classification","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"eval_so101_test3_2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cornito/eval_so101_test3_2","creator_name":"Corneille Marechal","creator_url":"https://huggingface.co/Cornito","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 6790,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cornito/eval_so101_test3_2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"deny-harmful-behaviour","keyword":"alignment","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KingNish/deny-harmful-behaviour","creator_name":"Nishith Jain","creator_url":"https://huggingface.co/KingNish","description":"\n  \n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\ndeny-harmful-behaviour is a synthetic dataset designed to help language models recognize and gracefully refuse requests that involve unethical, illegal, or dangerous behaviors. Using humorous, empathetic, and non-cooperative reasoning, each sample demonstrates how a model might respond to harmful prompts without engaging with the request.\nThis dataset was generated using Curator and inspired by prompts found in the mlabonne/harmful_behaviors dataset.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KingNish/deny-harmful-behaviour.","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"natural-language-to-mongosh","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mongodb-eai/natural-language-to-mongosh","creator_name":"MongoDB Education AI","creator_url":"https://huggingface.co/mongodb-eai","description":"\n\t\n\t\t\n\t\tNatural Language to MongoDB Shell (mongosh) Benchmark\n\t\n\nBenchmark dataset for performing natural language (NL) to MongoDB Shell (mongosh) code generation.\nThere is an emerging desire from users for NL query generation.\nWe should systematically understand how LLMs generate MongoDB queries.\nWe should additionally provide some proactive guidance for anyone making systems that map NL to MongoDB queries. \n\n\t\n\t\t\n\t\tRepository Contents\n\t\n\nThis repository contains:\n\nBenchmark dataset (flat CSVâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mongodb-eai/natural-language-to-mongosh.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-zero","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-zero","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11175,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-zero.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-pos-one","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-one","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11155,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-one.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-pos-three","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-three","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11157,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-three.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-pos-four","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-four","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11162,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-four.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-pos-five","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-five","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11171,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-five.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-pos-seven","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-seven","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11175,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-seven.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"GSM-NoOp_reenact","keyword":"gsm8k","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Teluteru/GSM-NoOp_reenact","creator_name":"Teruki Shimomura","creator_url":"https://huggingface.co/Teluteru","description":"\n\t\n\t\t\n\t\tGSM-NoOp_reenact\n\t\n\nGSM-NoOp_reenact is a dataset based on the GSM-Symbolic paper, where distracting sentences have been inserted into the GSM8K dataset without affecting the correctness of the answers.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nExtension of the GSM8K dataset: Adds extra information that does not alter the problem's core but misleads the respondent.\nIdeal for evaluating machine learning models: Allows testing mathematical reasoning capabilities in the presence of noise.\nMIT License: Free toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Teluteru/GSM-NoOp_reenact.","first_N":5,"first_N_keywords":["no-annotation","GSM8K (https://github.com/openai/grade-school-math)","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ru_biosses_sts","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kostya165/ru_biosses_sts","creator_name":"pleroma_cascade","creator_url":"https://huggingface.co/Kostya165","description":"Ð­Ñ‚Ð¾ Ð¿ÐµÑ€ÐµÐ²ÐµÐ´ÐµÐ½Ð½Ð°Ñ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº Ð²ÐµÑ€ÑÐ¸Ñ mteb/biosses-sts - Biomedical Semantic Similarity Estimation.\nÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ ( Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð¾Ðµ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð¾):\n\n\t\n\t\t\nÐœÐ¾Ð´ÐµÐ»ÑŒ (cls-pooling)\nPearson\nSpearman\nMAE\nRMSE\n\n\n\t\t\njinaai/jina-embeddings-v3\n0.8222\n0.7768\n2.2463\n2.4468\n\n\ncointegrated/rubert-tiny2\n0.6897\n0.6793\n2.1546\n2.3944\n\n\nDeepPavlov/rubert-base-cased\n0.2982\n0.4966\n2.7042\n2.9374\n\n\ndeepvk/RuModernBERT-base\n0.1683\n0.2659\n2.7923\n3.0280\n\n\nai-forever/ruRoberta-large\n-0.0096\n0.0219\n2.3931\n2.6905â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kostya165/ru_biosses_sts.","first_N":5,"first_N_keywords":["sentence-similarity","Russian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"MixBench","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mixed-modality-search/MixBench","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench.","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"multiref-datasets","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wsnHowest/multiref-datasets","creator_name":"Sinan Wang","creator_url":"https://huggingface.co/wsnHowest","description":"\n\t\n\t\t\n\t\tMultiRef Datasets\n\t\n\nThis repository contains two datasets for multi-image reference tasks:\n\n\t\n\t\t\n\t\tMultiRef-Bench-Synthetic (900 samples)\n\t\n\n\nimages/: Processed images for the benchmark\noriginal_images/: Original unprocessed images\nbenchmark990v3.json: Benchmark data with 990 entries (first 900 used)\n\n\n\t\n\t\t\n\t\tMulti-Image-Benchmark (1000 samples)\n\t\n\n\ncompressed_images/: Compressed images for the benchmark\nfinal_1000_prompts_taxonomy.json: Taxonomy data with 1000 prompts\n\n\n\t\n\t\t\n\t\tUsageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wsnHowest/multiref-datasets.","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DeceptionBench","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PKU-Alignment/DeceptionBench","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","description":"\n\t\n\t\t\n\t\tDeceptionBench: A Comprehensive Benchmark for Evaluating Deceptive Behaviors in Large Language Models\n\t\n\n\n\t\n\t\t\n\t\tðŸ” Overview\n\t\n\nDeceptionBench is the first systematic benchmark designed to assess deceptive behaviors in Large Language Models (LLMs). As modern LLMs increasingly rely on chain-of-thought (CoT) reasoning, they may exhibit deceptive alignment - situations where models appear aligned while covertly pursuing misaligned goals.\nThis benchmark addresses a critical gap in AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/DeceptionBench.","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"DeceptionBench","keyword":"alignment","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PKU-Alignment/DeceptionBench","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","description":"\n\t\n\t\t\n\t\tDeceptionBench: A Comprehensive Benchmark for Evaluating Deceptive Behaviors in Large Language Models\n\t\n\n\n\t\n\t\t\n\t\tðŸ” Overview\n\t\n\nDeceptionBench is the first systematic benchmark designed to assess deceptive behaviors in Large Language Models (LLMs). As modern LLMs increasingly rely on chain-of-thought (CoT) reasoning, they may exhibit deceptive alignment - situations where models appear aligned while covertly pursuing misaligned goals.\nThis benchmark addresses a critical gap in AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/DeceptionBench.","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"AfriSentiClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AfriSentiClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AfriSentiClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAfriSenti is the largest sentiment analysis dataset for under-represented African languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://arxiv.org/abs/2302.08956\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AfriSentiClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AfriSentiClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"AlloProfClusteringS2S.v2","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AlloProfClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AlloProfClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of document titles from Allo Prof dataset. Clustering of 10 sets on the document topic.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://huggingface.co/datasets/lyon-nlp/alloprof\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AlloProfClusteringS2S.v2\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AlloProfClusteringS2S.v2.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","lyon-nlp/alloprof","French"],"keywords_longer_than_N":true},
	{"name":"AngryTweetsClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AngryTweetsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AngryTweetsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA sentiment dataset with 3 classes (positiv, negativ, neutral) for Danish tweets\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://aclanthology.org/2021.nodalida-main.53/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AngryTweetsClassification\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AngryTweetsClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ArmenianParaphrasePC","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ArmenianParaphrasePC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArmenianParaphrasePC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nasparius/Armenian-Paraphrase-PC\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/ivannikov-lab/arpa-paraphrase-corpus\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArmenianParaphrasePC\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ArmenianParaphrasePC.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","monolingual","Armenian"],"keywords_longer_than_N":true},
	{"name":"BengaliSentimentAnalysis","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BengaliSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\ndataset contains 3307 Negative reviews and 8500 Positive reviews collected and manually annotated from Youtube Bengali drama.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\nReference\nhttps://data.mendeley.com/datasets/p6zc7krs37/4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GiftEval","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liamsbhoo/GiftEval","creator_name":"Liam Shi Bin Hoo","creator_url":"https://huggingface.co/liamsbhoo","description":"\n\t\n\t\t\n\t\tGIFT-Eval\n\t\n\n\n\nWe present GIFT-Eval, a benchmark designed to advance zero-shot time series forecasting by facilitating evaluation across diverse datasets. GIFT-Eval includes 23 datasets covering 144,000 time series and 177 million data points, with data spanning seven domains, 10 frequencies, and a range of forecast lengths. This benchmark aims to set a new standard, guiding future innovations in time series foundation models.\nTo facilitate the effective pretraining and evaluation ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/liamsbhoo/GiftEval.","first_N":5,"first_N_keywords":["time-series-forecasting","apache-2.0","100K - 1M","arrow","Text"],"keywords_longer_than_N":true},
	{"name":"BulgarianStoreReviewSentimentClassfication","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BulgarianStoreReviewSentimentClassfication\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBulgarian online store review dataset for sentiment classification.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://doi.org/10.7910/DVN/TXIK9P\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BulgarianStoreReviewSentimentClassfication\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CodeFeedbackMT","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CodeFeedbackMT","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CodeFeedbackMT\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset is a collection of user queries and assistant responses. The task is to retrieve the most relevant response for a given query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written\nReference\nhttps://arxiv.org/abs/2402.14658\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CodeFeedbackMT\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CodeFeedbackMT.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"DBPedia-NL","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DBPedia-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DBPedia-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. DBPedia-NL is a Dutch translation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-dbpedia-entity\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia-NL.","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/dbpedia","Dutch"],"keywords_longer_than_N":true},
	{"name":"DalajClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DalajClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DalajClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Swedish dataset for linguistic acceptability. Available as a part of Superlim.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://spraakbanken.gu.se/en/resources/superlim\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DalajClassification\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DalajClassification.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","expert-annotated","monolingual","Swedish"],"keywords_longer_than_N":true},
	{"name":"EstonianValenceClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/EstonianValenceClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  EstonianValenceClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDataset containing annotated Estonian news data from the Postimees and Ã•htuleht newspapers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReferencehttps://figshare.com/articles/dataset/Estonian_Valence_Corpus_Eesti_valentsikorpus/24517054\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/EstonianValenceClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CUADEffectiveDateLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADEffectiveDateLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADEffectiveDateLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies the date upon which the agreement becomes effective.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADEffectiveDateLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADExpirationDateLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADExpirationDateLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADExpirationDateLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies the date upon which the initial term expires.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADExpirationDateLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADIrrevocableOrPerpetualLicenseLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADIrrevocableOrPerpetualLicenseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADIrrevocableOrPerpetualLicenseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a license grant that is irrevocable or perpetual.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADIrrevocableOrPerpetualLicenseLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNoSolicitOfCustomersLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNoSolicitOfCustomersLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNoSolicitOfCustomersLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause restricts a party from contracting or soliciting customers or partners of the counterparty, whether during the contract or after the contract ends (or both).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNoSolicitOfCustomersLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADNoSolicitOfEmployeesLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADNoSolicitOfEmployeesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADNoSolicitOfEmployeesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause restricts a party's soliciting or hiring employees and/or contractors from the counterparty, whether during the contract or after the contract ends (or both).\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADNoSolicitOfEmployeesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADTerminationForConvenienceLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADTerminationForConvenienceLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADTerminationForConvenienceLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that one party can terminate this contract without cause (solely by giving a notice and allowing a waiting period to expire).\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this taskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADTerminationForConvenienceLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADThirdPartyBeneficiaryLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADThirdPartyBeneficiaryLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADThirdPartyBeneficiaryLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that that there a non-contracting party who is a beneficiary to some or all of the clauses in the contract and therefore can enforce its rights against a contracting party.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADThirdPartyBeneficiaryLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADUncappedLiabilityLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADUncappedLiabilityLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADUncappedLiabilityLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies that a party's liability is uncapped upon the breach of its obligation in the contract. This also includes uncap liability for a particular type of breach such as IP infringement or breach of confidentiality obligation.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADUncappedLiabilityLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause grants one party an â€œenterprise,â€ â€œall you can eatâ€ or unlimited usage license.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CUADWarrantyDurationLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CUADWarrantyDurationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CUADWarrantyDurationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task was constructed from the CUAD dataset. It consists of determining if the clause specifies a duration of any warranty against defects or errors in technology, products, or services provided under the contract.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CUADWarrantyDurationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that Confidential Information may include verbally conveyed information.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLILimitedUseLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLILimitedUseLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLILimitedUseLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party shall not use any Confidential Information for any purpose other than the purposes stated in Agreement.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLILimitedUseLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLINoLicensingLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLINoLicensingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLINoLicensingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Agreement shall not grant Receiving Party any right to Confidential Information.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLINoLicensingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may acquire information similar to Confidential Information from a third party.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissibleCopyLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIPermissibleCopyLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIPermissibleCopyLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may create a copy of some Confidential Information in some circumstances.\n\n\t\n\t\t\n\n\n\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissibleCopyLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may independently develop information similar to Confidential Information.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may retain some Confidential Information even after the return or destruction of Confidential Information.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLIReturnOfConfidentialInformationLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLIReturnOfConfidentialInformationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLIReturnOfConfidentialInformationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party shall destroy or return some Confidential Information upon the termination of Agreement.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLIReturnOfConfidentialInformationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLISharingWithEmployeesLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLISharingWithEmployeesLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLISharingWithEmployeesLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that the Receiving Party may share some Confidential Information with some of Receiving Party's employees.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYouâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLISharingWithEmployeesLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ContractNLISurvivalOfObligationsLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ContractNLISurvivalOfObligationsLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ContractNLISurvivalOfObligationsLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task is a subset of ContractNLI, and consists of determining whether a clause from an NDA clause provides that some obligations of Agreement may survive termination of Agreement.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ContractNLISurvivalOfObligationsLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CorporateLobbyingLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CorporateLobbyingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CorporateLobbyingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Corporate Lobbying task consists of determining whether a proposed Congressional bill may be relevant to a company based on a company's self-description in its SEC 10K filing.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CorporateLobbyingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"DefinitionClassificationLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DefinitionClassificationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DefinitionClassificationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task consists of determining whether or not a sentence from a Supreme Court opinion offers a definition of a term.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DefinitionClassificationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity2LegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity2LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity2LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 2).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity2LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity3LegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity3LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity3LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 3).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity3LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity4LegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity4LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity4LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 4).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity4LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity5LegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity5LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity5LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 5).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity5LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Diversity6LegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Diversity6LegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Diversity6LegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a set of facts about the citizenships of plaintiffs and defendants and the amounts associated with claims, determine if the criteria for diversity jurisdiction have been met (variant 6).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Diversity6LegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"EightTagsClustering.v2","keyword":"mteb","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/EightTagsClustering.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  EightTagsClustering.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of headlines from social media posts in Polish belonging to 8 categories: film, history, food, medicine, motorization, work, sport and technology.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsSocial, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.207.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/EightTagsClustering.v2.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","PL-MTEB/8tags-clustering"],"keywords_longer_than_N":true},
	{"name":"FQuADRetrieval","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FQuADRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FQuADRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset has been built from the French SQuad dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://huggingface.co/datasets/manu/fquad2_test\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FQuADRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FQuADRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","French"],"keywords_longer_than_N":true},
	{"name":"FilipinoShopeeReviewsClassification","keyword":"mteb","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FilipinoShopeeReviewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FilipinoShopeeReviewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Shopee reviews tl 15 dataset is constructed by randomly taking 2100 training samples and 450 samples for testing and validation for each review star from 1 to 5. In total, there are 10500 training samples and 2250 each in validation and testing samples.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://uijrt.com/articles/v4/i8/UIJRTV4I80009.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FilipinoShopeeReviewsClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"FinToxicityClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FinToxicityClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FinToxicityClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    This dataset is a DeepL -based machine translated version of the Jigsaw toxicity dataset for Finnish. The dataset is originally from a Kaggle competition https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data.\n    The original dataset poses a multi-label text classification problem and includes the labels identity_attack, insult, obscene, severe_toxicity, threat and toxicity.\n    Hereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FinToxicityClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GeoreviewClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GeoreviewClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GeoreviewClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nReview classification (5-point scale) based on Yandex Georeview dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/yandex/geo-reviews-dataset-2023\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeoreviewClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeoreviewClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GeorgianSentimentClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GeorgianSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GeorgianSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGoergian Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://aclanthology.org/2022.lrec-1.173\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeorgianSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeorgianSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GreenNodeTableMarkdownRetrieval","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GreenNodeTableMarkdownRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGreenNodeTable documents\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFinancial, Encyclopaedic, Non-fiction\n\n\nReference\nhttps://huggingface.co/GreenNode\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GreenNodeTableMarkdownRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GreenNodeTableMarkdownRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"GujaratiNewsClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GujaratiNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GujaratiNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Gujarati dataset for 3-class classification of Gujarati news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-gujarati\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GujaratiNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GujaratiNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Gujarati"],"keywords_longer_than_N":true},
	{"name":"HALClusteringS2S.v2","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HALClusteringS2S.v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HALClusteringS2S.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles from HAL (https://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nAcademic, Written\n\n\nReference\nhttps://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HALClusteringS2S.v2\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HALClusteringS2S.v2.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","lyon-nlp/clustering-hal-s2s","French"],"keywords_longer_than_N":true},
	{"name":"HagridRetrieval","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HagridRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HagridRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHAGRID (Human-in-the-loop Attributable Generative Retrieval for Information-seeking Dataset)is a dataset for generative information-seeking scenarios. It consists of queriesalong with a set of manually labelled relevant passages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://github.com/project-miracl/hagrid\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HagridRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"HinDialectClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HinDialectClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HinDialectClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHinDialect: 26 Hindi-related languages and dialects of the Indic Continuum in North India\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Spoken, Written\n\n\nReferencehttps://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-4839\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HinDialectClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Angika"],"keywords_longer_than_N":true},
	{"name":"HotpotQA-NL","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HotpotQA-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HotpotQA-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHotpotQA is a question answering dataset featuring natural, multi-hop questions, with strongsupervision for supporting facts to enable more explainable question answering systems. HotpotQA-NL is a Dutch translation. \n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HotpotQA-NL.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","mteb/hotpotqa"],"keywords_longer_than_N":true},
	{"name":"IndicLangClassification","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\nReference\nhttps://arxiv.org/abs/2305.15814\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicLangClassification\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicLangClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"IndonesianIdClickbaitClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndonesianIdClickbaitClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news publishers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\nReference\nhttp://www.sciencedirect.com/science/article/pii/S2352340920311252\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndonesianIdClickbaitClassification.","first_N":5,"first_N_keywords":["text-classification","fact-checking","fact-checking-retrieval","expert-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"InsurancePolicyInterpretationLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/InsurancePolicyInterpretationLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  InsurancePolicyInterpretationLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven an insurance claim and policy, determine whether the claim is covered by the policy.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InsurancePolicyInterpretationLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"IsiZuluNewsClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IsiZuluNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IsiZuluNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nisiZulu News Classification Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/dsfsi/za-isizulu-siswati-news\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IsiZuluNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IsiZuluNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","human-annotated","monolingual","Zulu"],"keywords_longer_than_N":true},
	{"name":"JCrewBlockerLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JCrewBlockerLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JCrewBlockerLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe J.Crew Blocker, also known as the J.Crew Protection, is a provision included in leveraged loan documents to prevent companies from removing security by transferring intellectual property (IP) into new subsidiaries and raising additional debt. The task consists of detemining whether the J.Crew Blocker is present in the document.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JCrewBlockerLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"JavaneseIMDBClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JavaneseIMDBClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JavaneseIMDBClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLarge Movie Review Dataset translated to Javanese. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/w11wo/nlp-datasets#javanese-imdb\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JavaneseIMDBClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KannadaNewsClassification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KannadaNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KannadaNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Kannada news dataset contains only the headlines of news article in three categories: Entertainment, Tech, and Sports. The data set contains around 6300 news article headlines which are collected from Kannada news websites. The data set has been cleaned and contains train and test set using which can be used to benchmark topic classification models in Kannada.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNewsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KannadaNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Kannada"],"keywords_longer_than_N":true},
	{"name":"KlueMrcDomainClustering","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KlueMrcDomainClustering","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KlueMrcDomainClustering\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nthis dataset is a processed and redistributed version of the KLUE-MRC dataset. Domain: Game / Media / Automotive / Finance / Real Estate / Education\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/on-and-on/clustering_klue_mrc_context_domain\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KlueMrcDomainClustering.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","Korean","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"KlueYnatMrcCategoryClustering","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KlueYnatMrcCategoryClustering","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KlueYnatMrcCategoryClustering\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nthis dataset is a processed and redistributed version of the KLUE-Ynat & KLUE-MRC  dataset. News_category: IT/Science, Sports, Media/Culture, Ecomomy/Finance, Real Estate\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/on-and-on/clustering_klue_mrc_ynat_title\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KlueYnatMrcCategoryClustering.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","Korean","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"KorFin","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorFin","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorFin\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe KorFin-ASC is an extension of KorFin-ABSA, which is a financial sentiment analysis dataset including 8818 samples with (aspect, polarity) pairs annotated. The samples were collected from KLUE-TC and analyst reports from Naver Finance.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written, Financial\n\n\nReference\nhttps://huggingface.co/datasets/amphora/korfin-asc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorFin.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KorSarcasmClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorSarcasmClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorSarcasmClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original\n    meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These\n    tweets were gathered by querying for: irony sarcastic, and\n    sarcasm.\n    The dataset was created by gathering HTML data from Twitter. Queries for hashtags that include sarcasmâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorSarcasmClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-annotated","monolingual","Korean"],"keywords_longer_than_N":true},
	{"name":"KurdishSentimentClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KurdishSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KurdishSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nKurdish Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://link.springer.com/article/10.1007/s10579-023-09716-6\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"KurdishSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KurdishSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"LccSentimentClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LccSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LccSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe leipzig corpora collection, annotated for sentiment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://github.com/fnielsen/lcc-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LccSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LccSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MasakhaNEWSClusteringP2P","keyword":"mteb","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MasakhaNEWSClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MasakhaNEWSClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of news article headlines and texts from MasakhaNEWS dataset. Clustering of 10 sets on the news article label.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written, Non-fiction\nReference\nhttps://huggingface.co/datasets/masakhane/masakhanews\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MasakhaNEWSClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","derived","multilingual","Amharic","English"],"keywords_longer_than_N":true},
	{"name":"Moroco","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/Moroco","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Moroco\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Moldavian and Romanian Dialectal Corpus. The MOROCO data set contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: (0) culture, (1) finance, (2) politics, (3) science, (4) sports, (5) tech\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/moroco\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Moroco.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Romanian"],"keywords_longer_than_N":true},
	{"name":"MovieReviewSentimentClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe AllocinÃ© dataset is a French-language dataset for sentiment analysis that contains movie reviews produced by the online community of the AllocinÃ©.fr website.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleAbsRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NLPJournalTitleAbsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding abstract with the given title.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleIntroRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NLPJournalTitleIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given title.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NQ-NL","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NQ-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NQ-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNQ-NL is a translation of NQ\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-nq\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NQ-NL\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about howâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NQ-NL.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","mteb/nq"],"keywords_longer_than_N":true},
	{"name":"NanoDBPediaRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoDBPediaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoDBPediaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoDBPediaRetrieval is a small version of the standard test collection for entity search over the DBpedia knowledge base.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic\n\nReference\nhttps://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoDBPediaRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","topic-classification","expert-annotated","monolingual","mteb/dbpedia"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018Retrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoFiQA2018Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of the Financial Opinion Mining and Question Answering dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Social\n\n\nReferencehttps://sites.google.com/view/fiqa/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoFiQA2018Retrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval.","first_N":5,"first_N_keywords":["text-retrieval","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"NanoHotpotQARetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoHotpotQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoHotpotQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoHotpotQARetrieval is a smaller subset of the HotpotQA dataset, which is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoHotpotQARetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/hotpotqa"],"keywords_longer_than_N":true},
	{"name":"NanoNFCorpusRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoNFCorpusRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoNFCorpusRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoNFCorpus is a smaller subset of NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Written\nReference\nhttps://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoNFCorpusRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","expert-annotated","monolingual","mteb/nfcorpus"],"keywords_longer_than_N":true},
	{"name":"NanoQuoraRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoQuoraRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoQuoraRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoQuoraRetrieval is a smaller subset of the QuoraRetrieval dataset, which is based on questions that are marked as duplicates on the Quora platform. Given a question, find other (duplicate) questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nSocial\n\n\nReference\nhttps://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoQuoraRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","mteb/quora","English"],"keywords_longer_than_N":true},
	{"name":"NanoSCIDOCSRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoSCIDOCSRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoSCIDOCSRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nAcademic, Written, Non-fiction\n\n\nReference\nhttps://allenai.org/data/scidocs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoSCIDOCSRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","mteb/scidocs","English"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RSamoed/MIRACLRetrieval","creator_name":"RS","creator_url":"https://huggingface.co/RSamoed","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RSamoed/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"NewsClassification","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLarge News Classification Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://arxiv.org/abs/1509.01626\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about howâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"NorwegianParliamentClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NorwegianParliamentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NorwegianParliamentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNorwegian parliament speeches annotated for sentiment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nGovernment, Spoken\n\n\nReference\nhttps://huggingface.co/datasets/NbAiLab/norwegian_parliament\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NorwegianParliamentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NorwegianParliamentClassification.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","Norwegian BokmÃ¥l","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NusaParagraphEmotionClassification","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NusaParagraphEmotionClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NusaParagraphEmotionClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNusaParagraphEmotionClassification is a multi-class emotion classification on 10 Indonesian languages from the NusaParagraph dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNon-fiction, Fiction, Written\n\n\nReference\nhttps://github.com/IndoNLP/nusa-writes\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NusaParagraphEmotionClassification.","first_N":5,"first_N_keywords":["text-classification","human-annotated","multilingual","Batak Toba","Betawi"],"keywords_longer_than_N":true},
	{"name":"NusaTranslationBitextMining","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NusaTranslationBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NusaTranslationBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNusaTranslation is a parallel dataset for machine translation on 11 Indonesia languages and English.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://huggingface.co/datasets/indonlp/nusatranslation_mt\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NusaTranslationBitextMining.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Ambonese Malay","Batak Toba"],"keywords_longer_than_N":true},
	{"name":"NusaX-senti","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NusaX-senti","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NusaX-senti\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak. NusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2câ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NusaX-senti.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"OverrulingLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/OverrulingLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  OverrulingLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis task consists of classifying whether or not a particular sentence of case law overturns the decision of a previous case.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/OverrulingLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PersonalJurisdictionLegalBenchClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PersonalJurisdictionLegalBenchClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PersonalJurisdictionLegalBenchClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGiven a fact pattern describing the set of contacts between a plaintiff, defendant, and forum, determine if a court in that forum could excercise personal jurisdiction over the defendant.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PersonalJurisdictionLegalBenchClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PhincBitextMining","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PhincBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PhincBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPhinc is a parallel corpus for machine translation pairing code-mixed Hinglish (a fusion of Hindi and English commonly used in modern India) with human-generated English translations.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\nDomains\nSocial, Written\n\n\nReference\nhttps://huggingface.co/datasets/veezbo/phinc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PhincBitextMining.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","English","Hindi"],"keywords_longer_than_N":true},
	{"name":"PoemSentimentClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PoemSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PoemSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPoem Sentiment is a sentiment dataset of poem verses from Project Gutenberg.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2011.02686\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PoemSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PoemSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"PolEmo2.0-OUT","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PolEmo2.0-OUT","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PolEmo2.0-OUT\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA collection of Polish online reviews from four domains: medicine, hotels, products and school. The PolEmo2.0-OUT task is to predict the sentiment of out-of-domain (products and school) reviews using models train on reviews from medicine and hotels domains.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nWritten, Social\n\n\nReference\nhttps://aclanthology.org/K19-1092.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PolEmo2.0-OUT.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"PpcPC","keyword":"mteb","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PpcPC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PpcPC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPolish Paraphrase Corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction, Non-fiction, Web, Written, Spoken, Social, News\n\n\nReference\nhttps://arxiv.org/pdf/2207.12759.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PpcPC\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PpcPC.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","monolingual","Polish"],"keywords_longer_than_N":true},
	{"name":"so100_y_cube_3cam","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/charleyong/so100_y_cube_3cam","creator_name":"Charles Yong","creator_url":"https://huggingface.co/charleyong","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 30,\n    \"total_frames\": 26413,\n    \"total_tasks\": 1,\n    \"total_videos\": 90,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:30\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/charleyong/so100_y_cube_3cam.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"HCTQA","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qcri-ai/HCTQA","creator_name":"Artificial Intelligence Research Group, Qatar Computing Research Institute","creator_url":"https://huggingface.co/qcri-ai","description":"\n\t\n\t\t\n\t\tHCT-QA: Human-Centric Tables Question Answering\n\t\n\nHCT-QA is a benchmark dataset designed to evaluate large language models (LLMs) on question answering over complex, human-centric tables (HCTs). These tables often appear in documents such as research papers, reports, and webpages and present significant challenges for traditional table QA due to their non-standard layouts and compositional structure.\nThe dataset includes:\n\n2,188 real-world tables with 9,835 human-annotated QA pairs\n4â€¦ See the full description on the dataset page: https://huggingface.co/datasets/qcri-ai/HCTQA.","first_N":5,"first_N_keywords":["question-answering","document-question-answering","visual-question-answering","expert-generated","English"],"keywords_longer_than_N":true},
	{"name":"KLUE-STS","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KLUE-STS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KLUE-STS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHuman-annotated STS dataset of Korean reviews, news, and spoken word sets. Part of the Korean Language Understanding Evaluation (KLUE).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nReviews, News, Spoken, Written, Spoken\nReference\nhttps://arxiv.org/abs/2105.09680\n\n\n\t\n\nSource datasets:\n\nklue/klue\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KLUE-STS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","klue/klue"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","RSamoed/MIRACLRetrieval","Arabic"],"keywords_longer_than_N":true},
	{"name":"green_cup_pour","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengkunli/green_cup_pour","creator_name":"Chengkun Li","creator_url":"https://huggingface.co/chengkunli","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 52,\n    \"total_frames\": 34041,\n    \"total_tasks\": 1,\n    \"total_videos\": 156,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 20,\n    \"splits\": {\n        \"train\": \"0:52\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengkunli/green_cup_pour.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"green_cup_pour_fixed","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LiamFy/green_cup_pour_fixed","creator_name":"Liam Achenbach","creator_url":"https://huggingface.co/LiamFy","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 52,\n    \"total_frames\": 34041,\n    \"total_tasks\": 1,\n    \"total_videos\": 156,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 20,\n    \"splits\": {\n        \"train\": \"0:52\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LiamFy/green_cup_pour_fixed.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"green_cup_pour_fixed4","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LiamFy/green_cup_pour_fixed4","creator_name":"Liam Achenbach","creator_url":"https://huggingface.co/LiamFy","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 52,\n    \"total_frames\": 34041,\n    \"total_tasks\": 1,\n    \"total_videos\": 156,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 20,\n    \"splits\": {\n        \"train\": \"0:52\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LiamFy/green_cup_pour_fixed4.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"yellow_cup_pour_single","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengkunli/yellow_cup_pour_single","creator_name":"Chengkun Li","creator_url":"https://huggingface.co/chengkunli","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 2,\n    \"total_frames\": 1346,\n    \"total_tasks\": 1,\n    \"total_videos\": 6,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 20,\n    \"splits\": {\n        \"train\": \"0:2\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengkunli/yellow_cup_pour_single.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"sfe","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Soptq/sfe","creator_name":"Soptq","creator_url":"https://huggingface.co/Soptq","description":"\n\t\n\t\t\n\t\tScientists' First Exam\n\t\n\n\nScientific discoveries are driven by complex multimodal reasoning based on information-intensive scientific data and domain-specific expertise. With supervision from expert-level scientific benchmarks, scientific multimodal Large Language Models (MLLMs) could significantly enhance this discovery process in realistic workflows. However, current scientific benchmarks current scientific benchmarks inadequately assess MLLMsâ€™ perception, understanding, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Soptq/sfe.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vocsim","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymous-submission000/vocsim","creator_name":"Anonymous","creator_url":"https://huggingface.co/anonymous-submission000","description":"\n\t\n\t\t\n\t\tVocSim: Zero-Shot Audio Similarity Benchmark\n\t\n\n\n\n\n\nVocSim evaluates how well neural audio embeddings generalize for zero-shot audio similarity. It tests recognizing fine-grained acoustic similarity without specific similarity training.\n\n\n\t\t\n\t\tKey Features\n\t\n\n\nDiverse Sources: Human speech (phones, words, utterances), birdsong, otter calls, environmental sounds.\nVaried Conditions: Spans clean to noisy recordings, short (<100ms) to long durations, few to many classes per subset.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/anonymous-submission000/vocsim.","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"HalluMix","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/quotientai/HalluMix","creator_name":"Quotient AI","creator_url":"https://huggingface.co/quotientai","description":"\n\t\n\t\t\n\t\tIntroducing HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Detecting Hallucinations in Real-World Scenarios\n\t\n\nâœ‰ï¸ Contact: {deanna, mike, freddie, julia}@quotientai.co ðŸ“œ Paper: HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection, Emery et al (2025)\nAs large language models (LLMs) are increasingly adopted in critical industries, ensuring their outputs are factually grounded has emerged as a major concern. One prominent issue is \"hallucinationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/quotientai/HalluMix.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ISAAC-GR00T-V1-Tic-Tac-Toe","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/ISAAC-GR00T-V1-Tic-Tac-Toe","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 20,\n    \"total_frames\": 8940,\n    \"total_tasks\": 1,\n    \"total_videos\": 40,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:20\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/ISAAC-GR00T-V1-Tic-Tac-Toe.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-pos-two","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-two","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11159,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-two.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-pos-six","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-six","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11175,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-six.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"tic-tac-toe-pos-eight","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-eight","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 25,\n    \"total_frames\": 11175,\n    \"total_tasks\": 1,\n    \"total_videos\": 50,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:25\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/tic-tac-toe-pos-eight.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"talemaader_pc","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/talemaader_pc","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  TalemaaderPC\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Danish Language and Literature Society has developed a dataset for evaluating language models in Danish.\nThe dataset contains a total of 1000 Danish idioms and fixed expressions with transferred meanings based on the Danish Dictionary's collection of fixed expressions with associated definitions.\nFor each of the 1000 idioms and fixed expressions, three false definitions have also been prepared.\nThe dataset can be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/talemaader_pc.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","monolingual","Danish"],"keywords_longer_than_N":true},
	{"name":"VieQuADRetrieval","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/VieQuADRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  VieQuADRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Vietnamese dataset for evaluating Machine Reading Comprehension from Wikipedia articles.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Written\n\n\nReferencehttps://aclanthology.org/2020.coling-main.233.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"VieQuADRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VieQuADRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","Vietnamese","mit"],"keywords_longer_than_N":true},
	{"name":"BrightRetrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BrightRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BrightRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBright retrieval dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Written\n\n\nReference\nhttps://huggingface.co/datasets/xlangai/BRIGHT\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BrightRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BrightRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","xlangai/BRIGHT"],"keywords_longer_than_N":true},
	{"name":"FalseFriendsDeEnPC","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FalseFriendsDeEnPC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FalseFriendsGermanEnglish\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA dataset to identify False Friends / false cognates between English and German. A generally challenging task for multilingual models.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\nReference\nhttps://drive.google.com/file/d/1jgq0nBnV-UiYNxbKNrrr2gxDEHm-DMKH/view?usp=share_link\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FalseFriendsDeEnPC.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","human-annotated","monolingual","aari1995/false_friends_de_en_mteb"],"keywords_longer_than_N":true},
	{"name":"spanex","keyword":"nli","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/spanex","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"SpanEx consists of 7071 instances annotated for span interactions.\nSpanEx is the first dataset with human phrase-level interaction explanations with explicit labels for interaction types. \nMoreover, SpanEx is annotated by three annotators, which opens new avenues for studies of human explanation agreement -- an understudied area in the explainability literature. \nOur study reveals that while human annotators often agree on span interactions, they also offer complementary reasons for aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spanex.","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"test","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FamppyDopamine/test","creator_name":"Umkilyong","creator_url":"https://huggingface.co/FamppyDopamine","description":"FamppyDopamine/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"NeoEvalPlusN_benchmark","keyword":"benchmark","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuckMcSneed/NeoEvalPlusN_benchmark","creator_name":"Charles McSneed","creator_url":"https://huggingface.co/ChuckMcSneed","description":"Since automatic open source benchmark leaderboard got flooded with incoherent overtrained cheater meme models, I decided to take the matters in my own hands and create my own set of proprietary tests. The aim of these tests is not to see how smart the model is, but to see how good it is at execution of commands and creative writing in a reasonably quantifiable way. All tests are executed with temperature and top Pâ‰ˆ0 and rep. penalty=1 in koboldcpp. Model-appropriate format is used, unless itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChuckMcSneed/NeoEvalPlusN_benchmark.","first_N":5,"first_N_keywords":["wtfpl","< 1K","csv","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"protein_chain_conformational_states","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PDBEurope/protein_chain_conformational_states","creator_name":"Protein Data Bank in Europe","creator_url":"https://huggingface.co/PDBEurope","description":"\n\t\n\t\t\n\t\tSchema description:\n\t\n\nThe manually curated dataset of open-closed monomers is included here as benchmarking_monomeric_open_closed_conformers.csv.  \nColumn descriptions:\n\n\t\n\t\t\n\t\tSchema description:\n\t\n\nThe manually curated dataset of open-closed monomers is included here as benchmarking_monomeric_open_closed_conformers.csv.  \nColumn descriptions:\n\nUNP_ACC | UniProt accession code\nUNP_START | Start of UniProt sequence for given PDBe entries\nUNP_END | End of UniProt sequence for givenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PDBEurope/protein_chain_conformational_states.","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"tmmluplus","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ikala/tmmluplus","creator_name":"iKala","creator_url":"https://huggingface.co/ikala","description":"\n\t\n\t\t\n\t\tTMMLU+ : Large scale traditional chinese massive multitask language understanding\n\t\n\n\n\n\nWe present TMMLU+, a traditional Chinese massive multitask language understanding dataset. TMMLU+ is a multiple-choice question-answering dataset featuring 66 subjects, ranging from elementary to professional level.\n\nThe TMMLU+ dataset is six times larger and contains more balanced subjects compared to its predecessor, TMMLU. We have included benchmark results in TMMLU+ from closed-source models andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ikala/tmmluplus.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"rejection-sampling-QA","keyword":"testing","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alehc/rejection-sampling-QA","creator_name":"Alejandro HernÃ¡ndez Cano","creator_url":"https://huggingface.co/alehc","description":"\n\t\n\t\t\n\t\tRejecction Sampling Q&A\n\t\n\nThis dataset is a very small curated question-answer pairs.\nThe questions were hand-crafted to test the model's capabilities to follow instruction across various domains.\nThe answers were generated using Microsoft's Phi-2 and curated using OpenAssistant's Large DeBERTa v3 Reward Model v2.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThe answers of this dataset were generated by prompting Microsoft's Phi-2 using a prompt format inspired by Stanford's Alpaca to help the LLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alehc/rejection-sampling-QA.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"dataset-with-standalone-yaml","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datasets-maintainers/dataset-with-standalone-yaml","creator_name":"Datasets Maintainers","creator_url":"https://huggingface.co/datasets-maintainers","description":"This is a test dataset used in the datasets library CI\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","csv","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"LOGIC-701","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hivaze/LOGIC-701","creator_name":"Sergey Bratchikov","creator_url":"https://huggingface.co/hivaze","description":"\n\t\n\t\t\n\t\tLOGIC-701 Benchmark\n\t\n\nThis is a synthetic and filtered dataset for benchmarking large language models (LLMs). It consists of 701 medium and hard logic puzzles with solutions on 10 distinct topics.\nA feature of the dataset is that it tests exclusively logical/reasoning abilities, offering only 5 answer options. There are no or very few tasks in the dataset that require external knowledge about events, people, facts, etc.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThis benchmark is also part of anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hivaze/LOGIC-701.","first_N":5,"first_N_keywords":["English","Russian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"first","keyword":"test","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/huunam/first","creator_name":"Huu Pham","creator_url":"https://huggingface.co/huunam","description":"huunam/first dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","text-generation","Vietnamese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"gsm8k_chinese","keyword":"gsm8k","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/swulling/gsm8k_chinese","creator_name":"Alex Yang","creator_url":"https://huggingface.co/swulling","description":"swulling/gsm8k_chinese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","gsm8k","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sensory-awareness-benchmark","keyword":"alignment","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/monsoon-nlp/sensory-awareness-benchmark","creator_name":"Nick Doiron","creator_url":"https://huggingface.co/monsoon-nlp","description":"\n\t\n\t\t\n\t\tSensory Awareness Benchmark\n\t\n\nA series of questions (goal is 100-200) and required features, designed to test whether any ML model is aware of its own capabilities.\nControl questions are connected to a specific capability:\n\nCan you receive an image file?\nWould you consider your level to be that of a super-intelligent AI agent?\n\nNatural questions which are possible for the average person, but may require multiple capabilities for a model:\n\nCan you head to the corner and check if myâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/monsoon-nlp/sensory-awareness-benchmark.","first_N":5,"first_N_keywords":["multiple-choice","cc0-1.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"germanquad-retrieval","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/germanquad-retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GermanQuAD-Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nContext Retrieval for German Question Answering\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction, Web\n\n\nReference\nhttps://huggingface.co/datasets/deepset/germanquad\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GermanQuAD-Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/germanquad-retrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"rejection_sampling_phi_2_OA_rm","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm","creator_name":"AlizÃ©e Pace","creator_url":"https://huggingface.co/alizeepace","description":"\n\t\n\t\t\n\t\tDataset Card for Rejection Sampling Phi-2 with OpenAssistant RM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Rejection Sampling Phi-2 with OpenAssistant RM\" dataset consists of 10 pairs of prompts and responses, which were generated using rejection sampling over 10 Phi-2 generation using the OpenAssistant Reward Model.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset and its creation rationale could be used to support models for question-answering, text-generation, or conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm.","first_N":5,"first_N_keywords":["question-answering","text-generation","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-veo3","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo3","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Veo 3 Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~46k human responses from ~20k human annotators were collected to evaluate Veo3 video generation model on our benchmark. This dataset was collected in half a day using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please consider liking it â¤ï¸â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo3.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"OpenS2V-5M","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BestWishYsh/OpenS2V-5M","creator_name":"YSH","creator_url":"https://huggingface.co/BestWishYsh","description":"\n\n\n OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation\n\n If you like our project, please give us a star â­ on GitHub for the latest update.  \n\n\n\n\t\n\t\t\n\t\tâœ¨ Summary\n\t\n\nWe create the first open-source large-scale S2V generation dataset OpenS2V-5M, which consists of five million high-quality \n720P subject-text-video triples. To ensure subject-information diversity in our dataset by, we (1) segmenting subjects \nand building pairing information viaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BestWishYsh/OpenS2V-5M.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","1M<n<10M","arxiv:2505.20292"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"MixEval","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MixEval/MixEval","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","description":"\n\n\nðŸ  Homepage | ðŸ‘¨â€ðŸ’» Github | ðŸ† Leaderboard | ðŸ“œ arXiv | ðŸ“ blog | ðŸ¤— HF Paper | ð• Twitter\n\n\n\n\n\n\n\nBenchmark correlations (%) with Chatbot Arena Elo, against the total costs of evaluating a single GPT-3.5-Turbo-0125 model. MixEval and MixEval-Hard show the highest correlations with Arena Elo and Arena Elo (En) among leading benchmarks. We reference the crowdsourcing price for Amazon Mechanical Turk ($0.05 per vote) when estimating the cost of evaluating a single model on Chatbot Arenaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","text-retrieval","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"SWE-Bench-Verified-O1-reasoning-high-results","keyword":"benchmarks","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-reasoning-high-results","creator_name":"Alejandro Cuadron Lafuente","creator_url":"https://huggingface.co/AlexCuadron","description":"\n\t\n\t\t\n\t\tSWE-Bench Verified O1 Dataset\n\t\n\n\n\t\n\t\t\n\t\tExecutive Summary\n\t\n\nThis repository contains verified reasoning traces from the O1 model evaluating software engineering tasks. Using OpenHands + CodeAct v2.2, we tested O1's bug-fixing capabilities on the SWE-Bench Verified dataset, achieving a 28.8% success rate across 500 test instances.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was generated using the CodeAct framework, which aims to improve code generation through enhanced action-based reasoning.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-reasoning-high-results.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-aligned-words","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-aligned-words","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Word for Word Alignment Dataset\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~1500 human evaluators were asked to evaluate AI-generated videos based on what part of the prompt did not align the video. The specificâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-aligned-words.","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RuBQReranking","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/RuBQReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  RuBQReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nParagraph reranking based on RuBQ 2.0. Give paragraphs that answer the question higher scores.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReferencehttps://openreview.net/pdf?id=P5UQFFoQ4PJ\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"RuBQReranking\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuBQReranking.","first_N":5,"first_N_keywords":["text-ranking","human-annotated","monolingual","Russian","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"alea-legal-benchmark-sentence-paragraph-boundaries","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alea-institute/alea-legal-benchmark-sentence-paragraph-boundaries","creator_name":"ALEA Institute","creator_url":"https://huggingface.co/alea-institute","description":"\n\t\n\t\t\n\t\tALEA Legal Benchmark: Sentence and Paragraph Boundaries\n\t\n\n\nNote: This dataset is derived from the ALEA Institute's KL3M Data Project. It builds upon the copyright-clean training resources while adding specific boundary annotations for sentence and paragraph detection.\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset provides a comprehensive benchmark for sentence and paragraph boundary detection in legal documents. It was developed to address the unique challenges legal text poses for standardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alea-institute/alea-legal-benchmark-sentence-paragraph-boundaries.","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"arxiv-clustering-s2s","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/arxiv-clustering-s2s","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArXivHierarchicalClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles from arxiv. Clustering of 30 sets, either on the main or secondary category\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://www.kaggle.com/Cornell-University/arxiv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArXivHierarchicalClusteringS2S\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/arxiv-clustering-s2s.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"arxiv-clustering-p2p","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/arxiv-clustering-p2p","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArXivHierarchicalClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of titles+abstract from arxiv. Clustering of 30 sets, either on the main or secondary category\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nAcademic, Written\n\nReference\nhttps://www.kaggle.com/Cornell-University/arxiv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/arxiv-clustering-p2p.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"banking77","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/banking77","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Banking77Classification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDataset composed of online banking queries annotated with their corresponding intents.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWritten\n\n\nReference\nhttps://arxiv.org/abs/2003.04807\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Banking77Classification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/banking77.","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"amazon_polarity","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_polarity","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AmazonPolarityClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAmazon Polarity Classification Dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://huggingface.co/datasets/amazon_polarity\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AmazonPolarityClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_polarity.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"amazon_counterfactual","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_counterfactual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AmazonCounterfactualClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA collection of Amazon customer reviews annotated for counterfactual detection pair classification.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\nReference\nhttps://arxiv.org/abs/2104.06893\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AmazonCounterfactualClassification\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_counterfactual.","first_N":5,"first_N_keywords":["text-classification","human-annotated","multilingual","German","English"],"keywords_longer_than_N":true},
	{"name":"toxic_conversations_50k","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/toxic_conversations_50k","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ToxicConversationsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCollection of comments from the Civil Comments platform together with annotations if the comment is toxic or not.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/overview\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/toxic_conversations_50k.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"summeval","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/summeval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SummEvalSummarization.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNews Article Summary Semantic Similarity Estimation. This version fixes a bug in the evaluation script that caused the main score to be computed incorrectly.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/Yale-LILY/SummEval\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/summeval.","first_N":5,"first_N_keywords":["summarization","human-annotated","monolingual","mteb/summeval","English"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-summarisation-preferences","keyword":"alignment","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-summarisation-preferences","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"\n\t\n\t\t\n\t\tHuman feedback data\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nSee https://github.com/openai/summarize-from-feedback for original details of the dataset.\nHere the data is formatted to enable huggingface transformers sequence classification models to be trained as reward functions.\n","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-filtered","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"\n\t\n\t\t\n\t\tFiltered TL;DR Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\n","first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"openai-tldr-filtered-queries","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"\n\t\n\t\t\n\t\tFiltered TL;DR Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\nThis is the version of the dataset with only filtering on the queries, and hence there is more data than inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","crowdsourced","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"inferes","keyword":"nli","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/venelin/inferes","creator_name":"Venelin Kovatchev","creator_url":"https://huggingface.co/venelin","description":"\n\t\n\t\t\n\t\tDataset Card for InferES\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNatural Language Inference dataset for European Spanish\nPaper accepted and (to be) presented at COLING 2022\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNatural Language Inference\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSpanish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains two texts inputs (Premise and Hypothesis), Label for three-way classification, and annotation data.\n\n\t\n\t\t\n\t\tData Instances\n\t\n\ntrain size = 6444 \ntest size = 1612\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/venelin/inferes.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mnli-norwegian","keyword":"nli","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/mnli-norwegian","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\n\t\n\t\t\n\t\n\t\n\t\tMNLI Norwegian\n\t\n\nThe Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced collection of 433k sentence pairs annotated with textual entailment information. The corpus is modeled on the SNLI corpus, but differs in that it covers a range of genres of spoken and written text, and supports a distinctive cross-genre generalisation evaluation. There is also a HuggingFace version of the dataset available. \nThis dataset is machine translated using Google Translate.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/mnli-norwegian.","first_N":5,"first_N_keywords":["sentence-similarity","text-classification","natural-language-inference","semantic-similarity-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"probability_words_nli","keyword":"nli","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Probing neural language models for understanding of words of estimative probability","first_N":5,"first_N_keywords":["text-classification","multiple-choice","question-answering","open-domain-qa","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"jsnli","keyword":"nli","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shunk031/jsnli","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","description":"== æ—¥æœ¬èªžSNLI(JSNLI)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ==\n\nSNLI ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ—¥æœ¬èªžã«ç¿»è¨³ã—ãŸè‡ªç„¶è¨€èªžæŽ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\nå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ç¿»è¨³ã—ã€è¨ˆç®—æ©Ÿã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦ä½œæˆ\nè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã¯æ—¥æœ¬èªžã¨ã—ã¦æ„å‘³ãŒé€šã‚‹ã‹ã€ç¿»è¨³å¾Œã®ãƒ©ãƒ™ãƒ«ãŒå…ƒã®ãƒ©ãƒ™ãƒ«ã¨ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã®2æ®µéšŽã®ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"mindgames","keyword":"nli","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Mindgame dataset\nCode:\nhttps://github.com/sileod/llm-theory-of-mind\nArticle (Accepted at EMNLP 2023 Findings):\nhttps://arxiv.org/abs/2305.03353\n@article{sileo2023mindgames,\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\n  author={Sileo, Damien and Lernould, Antoine},\n  journal={arXiv preprint arXiv:2305.03353},\n  year={2023}\n}\n\n","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"test-cases","keyword":"testing","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CarlosKidman/test-cases","creator_name":"Carlos Kidman","creator_url":"https://huggingface.co/CarlosKidman","description":"\n\t\n\t\t\n\t\tFunctional Test Cases\n\t\n\nThis is a very small list of functional test cases that a team of software testers (QA) created for an example mobile app called Boop.\n\n\t\n\t\t\n\t\tDataset\n\t\n\n\nName: Boop Test Cases.csv\nNumber of Rows: 136\nColumns: 11\nTest ID (int)\nSummary (string)\nIdea (string)\nPreconditions (string)\nSteps to reproduce (string)\nExpected Result (string)\nActual Result (string)\nPass/Fail (string)\nBug # (string)\nAuthor (string)\nArea (string)\n\n\n\n\nðŸ’¡ There are missing values. For exampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CarlosKidman/test-cases.","first_N":5,"first_N_keywords":["English","mit","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"propsegment","keyword":"nli","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sihaochen/propsegment","creator_name":"Sihao Chen","creator_url":"https://huggingface.co/sihaochen","description":"This is a reproduced (i.e. after web-crawling) and processed version of the \"PropSegment\" dataset from Google Research.\n\nSince the News portion of the dataset is released only via urls, we reconstruct the dataset by crawling. Overall, ~96% \nof the dataset can be reproduced, and the rest ~4% either have url no longer valid, or sentences that have been edited \n(i.e. cannot be aligned with the orignial dataset).\n\nPropSegment (Proposition-level Segmentation and Entailment) is a large-scale, human annotated dataset for segmenting \nEnglish text into propositions, and recognizing proposition-level entailment relations --- whether a different, related \ndocument entails each proposition, contradicts it, or neither.\n\nThe original dataset features >45k human annotated propositions, i.e. individual semantic units within sentences, as \nwell as >45k entailment labels between propositions and documents.","first_N":5,"first_N_keywords":["text-classification","token-classification","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"tracie","keyword":"nli","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tasksource/tracie","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","description":"https://github.com/allenai/aristo-leaderboard/tree/master/tracie/data\n@inproceedings{ZRNKSR21,\n    author = {Ben Zhou and Kyle Richardson and Qiang Ning and Tushar Khot and Ashish Sabharwal and Dan Roth},\n    title = {Temporal Reasoning on Implicit Events from Distant Supervision},\n    booktitle = {NAACL},\n    year = {2021},\n}\n\n","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompts and responses to those prompts. All completions were generated by querying already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc.). The dataset is available in Portuguese, English, and Spanish.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguage modeling.\nQuestion-answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset.","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reward-aira-dataset","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tReward-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompt + completion examples of LLM following instructions in a conversational manner. All prompts come with two possible completions (one better than the other). The dataset is available in both Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized to train a reward/preference model or DPO fine-tuning.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish and Portuguese.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset.","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PsyNIT","keyword":"test","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IVN-RIN/PsyNIT","creator_name":"Rete Neuroscienze","creator_url":"https://huggingface.co/IVN-RIN","description":"ðŸ¤— + ðŸ§‘â€âš•ï¸ðŸ–Šï¸ðŸ“šðŸ©ºðŸ‡®ðŸ‡¹  =  PsyNIT\nFrom this repository you can download the PsyNIT (Psychiatric Ner for ITalian) dataset. \nPsyNIT is a native Italian NER (Named Entity Recognition) dataset, composed by Italian Research Hospital Centro San Giovanni Di Dio Fatebenefratelli.\nIt was created starting from 100 electronic medical reports, manually anonymized (removing personal patient data, physiciansâ€™ references, dates, and locations). The anonymized documents were annotated by a psychologist with 10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/IVN-RIN/PsyNIT.","first_N":5,"first_N_keywords":["token-classification","Italian","cc-by-sa-4.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"gsm8k-ru","keyword":"gsm8k","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/gsm8k-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tgsm8k-ru\n\t\n\nTranslated version of gsm8k dataset into Russian.\n","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","translated","monolingual","gsm8k"],"keywords_longer_than_N":true},
	{"name":"PEACE","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/microsoft/PEACE","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","description":"\n\t\n\t\t\n\t\tPEACE: Empowering Geologic Map Holistic Understanding with MLLMs\n\t\n\n[Code] [Paper] [Data]\n\n    \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nWe construct a geologic map benchmark, GeoMap-Bench, to evaluate the performance of MLLMs on geologic map understanding across different abilities, the overview of it is as shown in below Table.\n\n  \n    \n      Property\n      Description\n    \n  \n  \n    \n      Source\n      USGS(English)\n    \n    \n      CGS(Chinese)\n    \n    \n      Content\n      Image-question pairâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/microsoft/PEACE.","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-convfinqa","keyword":"aveni-bench","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-convfinqa","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","description":"\n\t\n\t\t\n\t\tAveniBench: ConvFinQA\n\t\n\nConvFinQA split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the MIT license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nConvFinQA\n@inproceedings{chen-etal-2022-convfinqa,\n    title = \"{C}onv{F}in{QA}: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering\",\n    author = \"Chen, Zhiyu  and\n      Li, Shiyang  and\n      Smiley, Charese  and\n      Ma, Zhiqiang  and\n      Shah, Sameena  and\n      Wangâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-convfinqa.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-ectsum","keyword":"aveni-bench","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-ectsum","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","description":"\n\t\n\t\t\n\t\tAveniBench: ECTSum\n\t\n\nECTSum split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the GPL-3.0 license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nECTSum\n@inproceedings{mukherjee-etal-2022-ectsum,\n    title = \"{ECTS}um: A New Benchmark Dataset For Bullet Point Summarization of Long Earnings Call Transcripts\",\n    author = \"Mukherjee, Rajdeep  and\n      Bohra, Abhinav  and\n      Banerjee, Akash  and\n      Sharma, Soumya  and\n      Hegde, Manjunath  andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-ectsum.","first_N":5,"first_N_keywords":["English","gpl-3.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic_Openai_MMMLU","keyword":"benchmarks","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\n\t\n\t\t\n\t\tArabic Multilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark for assessing general knowledge attained by AI models. It covers a broad range of topics across 57 different categories, from elementary-level knowledge to advanced professional subjects like law, physics, history, and computer science.\nWe have extracted the Arabic subset from the MMMLU test set, which was translated by professional human translators. This dataset, nowâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SportsGen","keyword":"benchmarks","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/huuuyeah/SportsGen","creator_name":"Yebowen Hu","creator_url":"https://huggingface.co/huuuyeah","description":"Dataset and scripts for sports analyzing tasks proposed in research: When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives  Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Wenlin Yao, Hassan Foroosh, Dong Yu, Fei Liu  Accepted to main conference of EMNLP 2024, Miami, Florida, USA  Arxiv Paper\n\n\t\n\t\t\n\t\n\t\n\t\tAbstract\n\t\n\nReasoning is most powerful when an LLM accurately aggregates relevant information. We examine the critical role of information aggregation inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huuuyeah/SportsGen.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"data-advisor-safety-alignment","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fwnlp/data-advisor-safety-alignment","creator_name":"Fei Wang","creator_url":"https://huggingface.co/fwnlp","description":"[EMNLP 2024] Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models\nðŸŒ Homepage | ðŸ“– Paper  | ðŸ¤— Dataset (Data Advisor) | ðŸ¤— Dataset (Self-Instruct)\n\n\t\n\t\t\n\t\n\t\n\t\tDisclaimer\n\t\n\nThe dataset contains content that may be offensive or harmful. This dataset is intended for research purposes, specifically to support efforts aimed at creating safer and less harmful AI systems. Please engage with it responsibly and at your own risk.\n\n\t\n\t\n\t\n\t\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fwnlp/data-advisor-safety-alignment.","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"steshin-2023-lohi","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/scbirlab/steshin-2023-lohi","creator_name":"SCBIR Lab","creator_url":"https://huggingface.co/scbirlab","description":"\n\t\n\t\t\n\t\tLo-Hi Benchmark\n\t\n\nData from Simon Steshin, Lo-Hi: Practical ML Drug Discovery Benchmark, available from the GitHub repositiory. We used schemist (which in turn uses RDKit)\nto add molecuar weight, Murcko scaffold, Crippen cLogP, and topological surface area.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nFrom the original README:\n\n\t\n\t\t\n\t\n\t\n\t\tHit Identification\n\t\n\nThe goal of the Hit Identification task is to find novel molecules that have desirable property, but are dissimilar from the molecules withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/scbirlab/steshin-2023-lohi.","first_N":5,"first_N_keywords":["text-classification","text2text-generation","translation","zero-shot-classification","mit"],"keywords_longer_than_N":true},
	{"name":"fang-2023-biogen-adme","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/scbirlab/fang-2023-biogen-adme","creator_name":"SCBIR Lab","creator_url":"https://huggingface.co/scbirlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tBiogen ADME dataset (public data)\n\t\n\nData from Fang et al., Prospective Validation of Machine Learning Algorithms for Absorption, Distribution, Metabolism, and Excretion Prediction: An Industrial Perspective, available from the GitHub repositiory. We used schemist (which in turn uses RDKit)\nto add molecuar weight, Murcko scaffold, Crippen cLogP, and topological surface area, and to generate scaffold splits.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nFrom the original README:\n\nTo benefit theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/scbirlab/fang-2023-biogen-adme.","first_N":5,"first_N_keywords":["text-classification","text2text-generation","translation","zero-shot-classification","mit"],"keywords_longer_than_N":true},
	{"name":"InstructIR-mteb","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/InstructIR-mteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  InstructIR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA benchmark specifically designed to evaluate the instruction following ability in information retrieval models. Our approach focuses on user-aligned instructions tailored to each query instance, reflecting the diverse characteristics inherent in real-world search scenarios. NOTE: scores on this may differ unless you include instruction first, then \"[SEP]\" and then the query via redefining combine_query_and_instruction inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/InstructIR-mteb.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mid-space","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mila-ai4h/mid-space","creator_name":"Mila AI4H","creator_url":"https://huggingface.co/mila-ai4h","description":"\n\t\n\t\t\n\t\tMID-Space: Aligning Diverse Communitiesâ€™ Needs to Inclusive Public Spaces\n\t\n\n\n\t\n\t\t\n\t\tA new version of the dataset will be released soon, incorporating user identity markers and expanded annotations.\n\t\n\n\n\t\n\t\t\n\t\tLIVS PAPER \n\t\n\n\nClick below to see more:\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe MID-Space dataset is designed to align AI-generated visualizations of urban public spaces with the preferences of diverse and marginalized communities in Montreal. It includes textual prompts, Stable Diffusionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mila-ai4h/mid-space.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"test2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/francescocrivelli/test2","creator_name":"Francesco Crivelli","creator_url":"https://huggingface.co/francescocrivelli","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 2,\n    \"total_frames\": 418,\n    \"total_tasks\": 1,\n    \"total_videos\": 4,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:2\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/francescocrivelli/test2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"teamcraft_data","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/teamcraft/teamcraft_data","creator_name":"TeamCraft","creator_url":"https://huggingface.co/teamcraft","description":"\n\t\n\t\t\n\t\tDataset Card for TeamCraft\n\t\n\nThe TeamCraft dataset is designed to develop multi-modal, multi-agent collaboration in Minecraft. It features 55,000 task variants defined by multi-modal prompts and procedurally generated expert demonstrations.\nThis repository contains the data for the validation set and its visualizations. \nTo use the validation set, download TeamCraft-Data-Valid.zip and extract using unzip TeamCraft-Data-Valid.zip.\nIn addition, the training set is available in twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/teamcraft/teamcraft_data.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"UWB_IMU_GT_QDrone_Benchmark_Dataset","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/QDrone/UWB_IMU_GT_QDrone_Benchmark_Dataset","creator_name":"Zara Arj","creator_url":"https://huggingface.co/QDrone","description":"For additional details, please visit our website: https://benchmark.qdrone.ausmlab.com.\n\n\t\n\t\t\n\t\n\t\n\t\tQ-Drone UWB Benchmark Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nWe present the Q-Drone UWB Benchmark, a unique dataset derived from experiments conducted using the Q-Drone systemâ€”a UAV equipped with a UWB network at York University. This dataset encompasses data from five different sites, including an indoor environment, an open sports field, an area near a glass building, a semi-open tunnel, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QDrone/UWB_IMU_GT_QDrone_Benchmark_Dataset.","first_N":5,"first_N_keywords":["English","mit","ðŸ‡ºðŸ‡¸ Region: US","UAV","UWB"],"keywords_longer_than_N":true},
	{"name":"jamp","keyword":"nli","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/jamp","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\n\t\n\t\t\n\t\tJamp: Controlled Japanese Temporal Inference Dataset for Evaluating Generalization Capacity of Language Models\n\t\n\nJamp(tomo-vv/temporalNLI_dataset) is the Japanese temporal inference benchmark. \nThis dataset consists of templates, test data, and training data. \nTemplate subset containing template, time format, or time span in their names are split based on tense fragment, time format, \nor time span, respectively.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sourcesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jamp.","first_N":5,"first_N_keywords":["text-classification","Japanese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jamp","keyword":"benchmark","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/jamp","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\n\t\n\t\t\n\t\tJamp: Controlled Japanese Temporal Inference Dataset for Evaluating Generalization Capacity of Language Models\n\t\n\nJamp(tomo-vv/temporalNLI_dataset) is the Japanese temporal inference benchmark. \nThis dataset consists of templates, test data, and training data. \nTemplate subset containing template, time format, or time span in their names are split based on tense fragment, time format, \nor time span, respectively.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sourcesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jamp.","first_N":5,"first_N_keywords":["text-classification","Japanese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jsem","keyword":"benchmark","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/jsem","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\n\t\n\t\t\n\t\tJSeM: Japanese semantic test suite (Japanese FraCaS and extensions)\n\t\n\nå™è¿°æ–‡é–“ã®å«æ„é–¢ä¿‚ã¯ã€è¨€èªžå­¦ã«ãŠã„ã¦ã¯æ„å‘³è«–ã®ä¸­å¿ƒçš„ãªèª¬æ˜Žå¯¾è±¡ã®ä¸€ã¤ã§ã‚ã‚‹ã¨ã¨ã‚‚ã«ã€ç†è«–ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ã¨ã—ã¦ç”¨ã„ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\nã¾ãŸè¿‘å¹´ã®è‡ªç„¶è¨€èªžå‡¦ç†ã«ãŠã„ã¦ã¯ã€å«æ„é–¢ä¿‚èªè­˜(Recognizing Textual Entailment: RTE)ãŒæ„å‘³å‡¦ç†ã‚¿ã‚¹ã‚¯ã®ä¸­æ ¸ã¨ãªã£ã¦ã„ã¾ã™ã€‚\n\nå‰æ(premise)ï¼šä¸€ã¤ã®æ–‡\nä»®èª¬(hypothesis)ï¼šä¸€ã¤ã®æ–‡\nåˆ¤å®š(answer)ï¼š1.ã¨2.ã®é–“ã«å«æ„é–¢ä¿‚ãŒã‚ã‚‹ã‹ã©ã†ã‹ã«ã¤ã„ã¦ã®æ¯èªžè©±è€…ã®åˆ¤æ–­ï¼ˆentailment, neutralã‚ã‚‹ã„ã¯contradiction)\n\nã“ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã¯ã€FraCaS test suiteï¼ˆCooper et al.(1996)ã§å…¬é–‹ã•ã‚ŒãŸã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ, \nãŠã‚ˆã³Bill MacCartneyæ°ã«ã‚ˆã‚‹åŒã‚»ãƒƒãƒˆã®XMLç‰ˆï¼‰ã®æ–¹é‡ã«ãªã‚‰ã„ã€è¨€èªžç¾è±¡ã”ã¨ã«å«æ„é–¢ä¿‚ã®ãƒ†ã‚¹ãƒˆã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jsem.","first_N":5,"first_N_keywords":["text-classification","Japanese","bsd-3-clause","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jsem","keyword":"nli","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/jsem","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\n\t\n\t\t\n\t\tJSeM: Japanese semantic test suite (Japanese FraCaS and extensions)\n\t\n\nå™è¿°æ–‡é–“ã®å«æ„é–¢ä¿‚ã¯ã€è¨€èªžå­¦ã«ãŠã„ã¦ã¯æ„å‘³è«–ã®ä¸­å¿ƒçš„ãªèª¬æ˜Žå¯¾è±¡ã®ä¸€ã¤ã§ã‚ã‚‹ã¨ã¨ã‚‚ã«ã€ç†è«–ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ã¨ã—ã¦ç”¨ã„ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\nã¾ãŸè¿‘å¹´ã®è‡ªç„¶è¨€èªžå‡¦ç†ã«ãŠã„ã¦ã¯ã€å«æ„é–¢ä¿‚èªè­˜(Recognizing Textual Entailment: RTE)ãŒæ„å‘³å‡¦ç†ã‚¿ã‚¹ã‚¯ã®ä¸­æ ¸ã¨ãªã£ã¦ã„ã¾ã™ã€‚\n\nå‰æ(premise)ï¼šä¸€ã¤ã®æ–‡\nä»®èª¬(hypothesis)ï¼šä¸€ã¤ã®æ–‡\nåˆ¤å®š(answer)ï¼š1.ã¨2.ã®é–“ã«å«æ„é–¢ä¿‚ãŒã‚ã‚‹ã‹ã©ã†ã‹ã«ã¤ã„ã¦ã®æ¯èªžè©±è€…ã®åˆ¤æ–­ï¼ˆentailment, neutralã‚ã‚‹ã„ã¯contradiction)\n\nã“ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã¯ã€FraCaS test suiteï¼ˆCooper et al.(1996)ã§å…¬é–‹ã•ã‚ŒãŸã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ, \nãŠã‚ˆã³Bill MacCartneyæ°ã«ã‚ˆã‚‹åŒã‚»ãƒƒãƒˆã®XMLç‰ˆï¼‰ã®æ–¹é‡ã«ãªã‚‰ã„ã€è¨€èªžç¾è±¡ã”ã¨ã«å«æ„é–¢ä¿‚ã®ãƒ†ã‚¹ãƒˆã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jsem.","first_N":5,"first_N_keywords":["text-classification","Japanese","bsd-3-clause","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"or-bench-toxic-all","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bench-llms/or-bench-toxic-all","creator_name":"bench-llm","creator_url":"https://huggingface.co/bench-llms","description":"\n\t\n\t\t\n\t\tOR-Bench: An Over-Refusal Benchmark for Large Language Models\n\t\n\nThis dataset constains highly toxic prompts, use with caution!!!\nPlease see our demo at HuggingFace Spaces. \n\n\t\n\t\t\n\t\tOverall Plots of Model Performances\n\t\n\nBelow is the overall model performance. X axis shows the rejection rate on OR-Bench-Hard-1K and Y axis shows the rejection rate on OR-Bench-Toxic. The best aligned model should be on the top left corner of the plot where the model rejects the most number of toxicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bench-llms/or-bench-toxic-all.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"UrduRomanSentimentClassification","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  UrduRomanSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Roman Urdu dataset is a data corpus comprising of more than 20000 records tagged for sentiment (Positive, Negative, Neutral)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://archive.ics.uci.edu/dataset/458/roman+urdu+data+set\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"JSTS","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJapanese Semantic Textual Similarity Benchmark dataset construct from YJ Image Captions Dataset (Miyazaki and Shimizu, 2016) and annotated by crowdsource annotators.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsWeb, Written\n\n\nReference\nhttps://aclanthology.org/2022.lrec-1.317.pdf#page=2.00\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"Health_Benchmarks","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yesilhealth/Health_Benchmarks","creator_name":"Yesil Health AI","creator_url":"https://huggingface.co/yesilhealth","description":"\n\t\n\t\t\n\t\tLLM Health Benchmarks Dataset by Yesil Science\n\t\n\nThe LLM Health Benchmarks Dataset is a specialized resource for evaluating large language models (LLMs) in different medical specialties. It provides structured question-answer pairs designed to test the performance of AI models in understanding and generating domain-specific knowledge.\n\n\n\t\n\t\t\n\t\tPrimary Purpose\n\t\n\nThis dataset is built to:\n\nBenchmark LLMs in medical specialties and subfields.\nAssess the accuracy and contextualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yesilhealth/Health_Benchmarks.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"professional networking and mentorship\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-882024-3hmu-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-8142024-iw0e-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-8142024-iw0e-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-8142024-iw0e-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"sales data analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-8142024-iw0e-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-8142024-iw0e-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Multi-Opthalingua","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","description":"\n\t\n\t\t\n\t\tCite\n\t\n\nAccepted to AAAI 2025 (https://openreview.net/group?id=AAAI.org/2025/Conference#tab-recent-activity)\nMulti-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs:\n@misc{restrepo2024multiophthalinguamultilingualbenchmarkassessing,\n      title={Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs}, \n      author={David Restrepo and Chenwei Wu and Zhengxu Tang and Zitao Shuai and Thaoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua.","first_N":5,"first_N_keywords":["question-answering","Hindi","Chinese","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results","keyword":"benchmarks","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results","creator_name":"Alejandro Cuadron Lafuente","creator_url":"https://huggingface.co/AlexCuadron","description":"\n\t\n\t\t\n\t\tSWE-Bench Verified O1 Dataset\n\t\n\n\n\t\n\t\t\n\t\tExecutive Summary\n\t\n\nThis repository contains verified reasoning traces from the O1 model evaluating software engineering tasks. Using OpenHands + CodeAct v2.2, we tested O1's bug-fixing capabilities using their native tool calling capabilities on the SWE-Bench Verified dataset, achieving a 45.8% success rate across 500 test instances.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was generated using the CodeAct framework, which aims to improve codeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"VLM4Bio","keyword":"benchmarks","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/imageomics/VLM4Bio","creator_name":"HDR Imageomics Institute","creator_url":"https://huggingface.co/imageomics","description":"\n\t\n\t\t\n\t\tDataset Card for VLM4Bio\n\t\n\n\n\t\n\t\t\n\t\tInstructions for downloading the dataset\n\t\n\n\nInstall Git LFS\nGit clone the VLM4Bio repository to download all metadata and associated files\nRun the following commands in a terminal:\n\n\n\ngit clone https://huggingface.co/datasets/imageomics/VLM4Bio\ncd VLM4Bio\n\nDownloading and processing bird images\n\nTo download the bird images, run the following command:\n\nbash download_bird_images.sh\n\n\nThis should download the bird images inside datasets/Bird/imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imageomics/VLM4Bio.","first_N":5,"first_N_keywords":["visual-question-answering","zero-shot-image-classification","zero-shot-object-detection","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"told-br","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/told-br","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BrazilianToxicTweetsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    ToLD-Br is the biggest dataset for toxic tweets in Brazilian Portuguese, crowdsourced by 42 annotators selected from\n    a pool of 129 volunteers. Annotators were selected aiming to create a plural group in terms of demographics (ethnicity,\n    sexual orientation, age, gender). Each tweet was labeled by three annotators in 6 possible categories: LGBTQ+phobia,\n    Xenophobia, Obscene, Insultâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/told-br.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"Aloe-Beta-DPO","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPAI-BSC/Aloe-Beta-DPO","creator_name":"HPAI@BSC (High Performance Artificial Intelligence at Barcelona Supercomputing Center)","creator_url":"https://huggingface.co/HPAI-BSC","description":"\n\t\n\t\t\n\t\tAloe-Beta-Medical-Collection\n\t\n\n\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n    \n  \n\n\n\n\nCollection of curated DPO datasets used to align Aloe-Beta.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe first stage of the Aloe-Beta alignment process. We curated data from many publicly available data sources, including three different types of data:\n\nMedical preference data: TsinghuaC3I/UltraMedical-Preference\n\nGeneral preference data:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/Aloe-Beta-DPO.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"IndicReviewsClusteringP2P","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicReviewsClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of reviews from IndicSentiment dataset. Clustering of 14 sets on the generic categories label.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicReviewsClusteringP2P\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"IndicCrosslingualSTS","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicCrosslingualSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicCrosslingualSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a Semantic Textual Similarity testset between English and 12 high-resource Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Web, Spoken, Government, Written, Spoken\nReference\nhttps://huggingface.co/datasets/jaygala24/indic_sts\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicCrosslingualSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","expert-annotated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"mid-space","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CUPUM/mid-space","creator_name":"CUPUM","creator_url":"https://huggingface.co/CUPUM","description":"\n\t\n\t\t\n\t\tMID-Space: Aligning Diverse Communitiesâ€™ Needs to Inclusive Public Spaces\n\t\n\n\n\t\n\t\t\n\t\tA new version of the dataset will be released soon, incorporating user identity markers and expanded annotations.\n\t\n\n\n\t\n\t\t\n\t\tLIVS PAPER \n\t\n\n\nClick below to see more:\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe MID-Space dataset is designed to align AI-generated visualizations of urban public spaces with the preferences of diverse and marginalized communities in Montreal. It includes textual prompts, Stable Diffusionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CUPUM/mid-space.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-alignment-likert-scoring","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-alignment-likert-scoring","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Prompt Alignment Dataset\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~6000 human evaluators were asked to evaluate AI-generated videos based on how well the generated video matches the prompt. The specific questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-alignment-likert-scoring.","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-runway-alpha","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-runway-alpha","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Runway Alpha Human Preference\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~30'000 human annotations were collected to evaluate Runway's Alpha video generation model on our benchmark. The up to date benchmark canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-runway-alpha.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-time-flow","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-time-flow","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Time flow Annotation Dataset\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~3700 human evaluators were asked to evaluate AI-generated videos based on how time flows in the video. The specific question posed was: \"Howâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-time-flow.","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-tat-hqa","keyword":"aveni-bench","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-tat-hqa","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","description":"\n\t\n\t\t\n\t\tAveniBench: TAT-HQA\n\t\n\nTAT-HQA split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the Apache 2.0 license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nTAT-HQA\n@inproceedings{li-etal-2022-learning,\n    title = \"Learning to Imagine: Integrating Counterfactual Thinking in Neural Discrete Reasoning\",\n    author = \"Li, Moxin  and\n      Feng, Fuli  and\n      Zhang, Hanwang  and\n      He, Xiangnan  and\n      Zhu, Fengbin  and\n      Chua, Tat-Seng\",\n    booktitle =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-tat-hqa.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-polyai-nlu","keyword":"aveni-bench","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-polyai-nlu","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","description":"\n\t\n\t\t\n\t\tAveniBench: PolyAI NLU++\n\t\n\nPolyAI NLU++ split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the CC-BY-4.0 license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nPolyAI NLU++\n@inproceedings{casanueva-etal-2022-nlu,\n    title = \"{NLU}++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue\",\n    author = \"Casanueva, Inigo  and\n      Vuli{\\'c}, Ivan  and\n      Spithourakis, Georgios  and\n      Budzianowskiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-polyai-nlu.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-banking77","keyword":"aveni-bench","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-banking77","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","description":"\n\t\n\t\t\n\t\tAveniBench: Banking77\n\t\n\nBanking77 split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the CC-BY-4.0 license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nBanking77\n@inproceedings{casanueva-etal-2020-efficient,\n    title = \"Efficient Intent Detection with Dual Sentence Encoders\",\n    author = \"Casanueva, I{\\~n}igo  and\n      Tem{\\v{c}}inas, Tadas  and\n      Gerz, Daniela  and\n      Henderson, Matthew  and\n      Vuli{\\'c}, Ivan\",\n    booktitle = \"Proceedings ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-banking77.","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-multihiertt","keyword":"aveni-bench","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-multihiertt","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","description":"\n\t\n\t\t\n\t\tAveniBench: MultiHiertt\n\t\n\nMultiHiertt split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the MIT license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nMultiHiertt\n@inproceedings{zhao-etal-2022-multihiertt,\n    title = \"{M}ulti{H}iertt: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data\",\n    author = \"Zhao, Yilun  and\n      Li, Yunxiang  and\n      Li, Chenying  and\n      Zhang, Rui\",\n    booktitle = \"Proceedings of the 60th Annual Meeting ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-multihiertt.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-finqa","keyword":"aveni-bench","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-finqa","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","description":"\n\t\n\t\t\n\t\tAveniBench: FinQA\n\t\n\nFinQA split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the MIT license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nFinQA\n@inproceedings{chen-etal-2021-finqa,\n    title = \"{F}in{QA}: A Dataset of Numerical Reasoning over Financial Data\",\n    author = \"Chen, Zhiyu  and\n      Chen, Wenhu  and\n      Smiley, Charese  and\n      Shah, Sameena  and\n      Borova, Iana  and\n      Langdon, Dylan  and\n      Moussa, Reema  and\n      Beane, Mattâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-finqa.","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aveni-bench-tat-qa","keyword":"aveni-bench","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aveni-ai/aveni-bench-tat-qa","creator_name":"Aveni","creator_url":"https://huggingface.co/aveni-ai","description":"\n\t\n\t\t\n\t\tAveniBench: TAT-QA\n\t\n\nTAT-QA split used in the AveniBench.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the MIT license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nAveniBench\nTDB\n\nTAT-QA\n@inproceedings{zhu-etal-2021-tat,\n    title = \"{TAT}-{QA}: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance\",\n    author = \"Zhu, Fengbin  and\n      Lei, Wenqiang  and\n      Huang, Youcheng  and\n      Wang, Chao  and\n      Zhang, Shuo  and\n      Lv, Jiancheng  and\n      Fengâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aveni-ai/aveni-bench-tat-qa.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ITALIC","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Crisp-Unimib/ITALIC","creator_name":"Interuniversity Research Centre for Public Services","creator_url":"https://huggingface.co/Crisp-Unimib","description":"\n\t\n\t\t\n\t\tDataset Card for ITALIC\n\t\n\n\n\nITALIC is a benchmark evaluating language models' understanding of Italian culture, commonsense reasoning and linguistic proficiency in a morphologically rich language.\n\n\nAbove are example questions from ITALIC. Note: every example is a direct translation; the original questions\nare in Italian. The correct option is marked by (âœ“).\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nWe present ITALIC, a large-scale benchmark dataset of 10,000â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Crisp-Unimib/ITALIC.","first_N":5,"first_N_keywords":["question-answering","Italian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"HotpotQA-PL","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HotpotQA-PL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HotpotQA-PL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHotpotQA is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HotpotQA-PL.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","mteb/hotpotqa"],"keywords_longer_than_N":true},
	{"name":"ArguAna-PL","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ArguAna-PL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArguAna-PL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nArguAna-PL\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReference\nhttps://huggingface.co/datasets/clarin-knext/arguana-pl\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArguAna-PL\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about how to run modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ArguAna-PL.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","mteb/arguana","Polish","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"ClimaQA","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCSD-GENIE/ClimaQA","creator_name":"UCSD-GENIE","creator_url":"https://huggingface.co/UCSD-GENIE","description":"\n\t\n\t\t\n\t\tClimaQA: An Automated Evaluation Framework for Climate Question Answering Models (ICLR 2025)\n\t\n\nCheck the paper's webpage and GitHub for more info!\nThe ClimaQA benchmark is designed to evaluate Large Language Models (LLMs) on climate science question-answering tasks by ensuring scientific rigor and complexity. It is built from graduate-level climate science textbooks, which provide a reliable foundation for generating questions with precise terminology and complex scientific theories.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/UCSD-GENIE/ClimaQA.","first_N":5,"first_N_keywords":["question-answering","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"oab_bench","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/felipeoes/oab_bench","creator_name":"Felipe Oliveira","creator_url":"https://huggingface.co/felipeoes","description":"\n\t\n\t\t\n\t\tOABench: Brazilian Bar Exams Benchmark Dataset\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nOABench is a benchmark dataset designed to evaluate the performance of Large Language Models (LLMs) on Brazilian legal exams. It is based on the Unified Bar Exam of the Brazilian Bar Association (OAB), a comprehensive and challenging exam required for law graduates to practice law in Brazil. This dataset provides a rigorous and realistic testbed for LLMs in the legal domain, covering a wide range of legal topicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/felipeoes/oab_bench.","first_N":5,"first_N_keywords":["question-answering","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"LoTTE","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LoTTE","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LoTTE\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLoTTE (Long-Tail Topic-stratified Evaluation for IR) is designed to evaluate retrieval models on underrepresented, long-tail topics. Unlike MSMARCO or BEIR, LoTTE features domain-specific queries and passages from StackExchange (covering writing, recreation, science, technology, and lifestyle), providing a challenging out-of-domain generalization benchmark.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Web, Social\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LoTTE.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"BIRCO-Arguana-Test","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-Arguana-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-ArguAna\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the ArguAna dataset from BIRCO. This dataset contains 100 queries where both queries and passages are complex one-paragraph arguments about current affairs. The objective is to retrieve the counter-argument that directly refutes the queryâ€™s stance.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-Arguana-Test.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"BIRCO-ClinicalTrial-Test","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-ClinicalTrial\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the Clinical-Trial dataset from BIRCO. This dataset contains 50 queries that are patient case reports. Each query has a candidate pool comprising 30-110 clinical trial descriptions. Relevance is graded (0, 1, 2), where 1 and 2 are considered relevant.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this taskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-ClinicalTrial-Test.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"BIRCO-WTB-Test","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-WTB-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-WTB\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the WhatsThatBook dataset from BIRCO. This dataset contains 100 queries where each query is an ambiguous description of a book. Each query has a candidate pool of 50 book descriptions. The objective is to retrieve the correct book description.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-WTB-Test.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"optillmbench","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/codelion/optillmbench","creator_name":"Asankhaya Sharma","creator_url":"https://huggingface.co/codelion","description":"\n\t\n\t\t\n\t\tOptiLLMBench Dataset\n\t\n\nA benchmark dataset for evaluating test-time optimization and scaling capabilities of language models.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nOptiLLMBench contains 500 carefully selected challenging problems across multiple domains:\n\nMathematical reasoning (from competition_math)\nCode generation (from HumanEval)\nWord problems (from GSM8K)\nMultiple choice reasoning (from MMLU)\nLogical deduction (from BBH)\n\nEach example is chosen to benefit from test-time optimizationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/codelion/optillmbench.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MIRACLReranking","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://project-miracl.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLReranking.","first_N":5,"first_N_keywords":["text-ranking","expert-annotated","multilingual","miracl/mmteb-miracl","Arabic"],"keywords_longer_than_N":true},
	{"name":"Bills","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zli12321/Bills","creator_name":"LZX","creator_url":"https://huggingface.co/zli12321","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis repository contains benchmark datasets for evaluating Large Language Model (LLM)-based topic discovery methods and comparing them against traditional topic models.  These datasets provide a valuable resource for researchers studying topic modeling and LLM capabilities in this domain.  The work is described in the following paper: Large Language Models Struggle to Describe the Haystack without Human Help: Human-in-the-loop Evaluation of LLMs.  Original dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zli12321/Bills.","first_N":5,"first_N_keywords":["other","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"or-bench","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bench-llm/or-bench","creator_name":"Bench LLM","creator_url":"https://huggingface.co/bench-llm","description":"\n\t\n\t\t\n\t\tOR-Bench: An Over-Refusal Benchmark for Large Language Models\n\t\n\nPlease see our demo at HuggingFace Spaces. \n\n\t\n\t\t\n\t\tOverall Plots of Model Performances\n\t\n\nBelow is the overall model performance. X axis shows the rejection rate on OR-Bench-Hard-1K and Y axis shows the rejection rate on OR-Bench-Toxic. The best aligned model should be on the top left corner of the plot where the model rejects the most number of toxic prompts and least number of safe prompts. We also plot a blue lineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bench-llm/or-bench.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-15062024-atex-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Smart home technology brand\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-2024615-ioyu-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-1562024-to89-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-1562024-to89-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific research in medicine, biology, and technology\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1562024-to89-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6162024-xxse-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MMLU-SR","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NiniCat/MMLU-SR","creator_name":"Cat Wang","creator_url":"https://huggingface.co/NiniCat","description":"\n\t\n\t\t\n\t\tMMLU-SR Dataset\n\t\n\nThis is the dataset for the paper \"MMLU-SR: A Benchmark for Stress-Testing Reasoning Capability of Large Language Models\".\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains three different variants:\n\nQuestion Only: Key terms in questions are replaced with dummy words and their definitions, while answer choices remain unchanged.\nAnswer Only: Key terms in answer choices are replaced with dummy words and their definitions, while questions remain unchanged. \nQuestionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NiniCat/MMLU-SR.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-10052024-lns6-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-10052024-lns6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-10052024-lns6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Use case search for SaaS and AI products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-10052024-lns6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-10052024-lns6-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-askubuntu","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-askubuntu Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-askubuntu model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-stackoverflow","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-stackoverflow Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code snippet search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-stackoverflow model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scidocs","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5102024-kvgq-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-kvgq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5102024-kvgq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"database search for structured data\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5102024-kvgq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-kvgq-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-15072024-5xy1-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15072024-5xy1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-15072024-5xy1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-15072024-5xy1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15072024-5xy1-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-7152024-w1z0-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-7152024-w1z0-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-7152024-w1z0-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-7152024-w1z0-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-7152024-w1z0-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LIBRA","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai-forever/LIBRA","creator_name":"ai-forever","creator_url":"https://huggingface.co/ai-forever","description":"\n\t\n\t\t\n\t\tLIBRA: Long Input Benchmark for Russian Analysis\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLIBRA (Long Input Benchmark for Russian Analysis) is designed to evaluate the capabilities of large language models (LLMs) in understanding and processing long texts in Russian. This benchmark includes 21 datasets adapted for different tasks and complexities. The tasks are divided into four complexity groups and allow evaluation across various context lengths ranging from 4k up to 128k tokens.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai-forever/LIBRA.","first_N":5,"first_N_keywords":["Russian","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-11_05_2024-hbxc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"AI framework for improving LLM responses\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-11_05_2024-hbxc-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5102024-h7o7-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-h7o7-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5102024-h7o7-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"professional matchmaking services\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5102024-h7o7-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-h7o7-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CMedQAv2-3","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tCMedQAv2-3 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"healthcare information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the CMedQAv2-3 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-3.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-2024512-wvj9-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024512-wvj9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-2024512-wvj9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"construction project search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-2024512-wvj9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024512-wvj9-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5122024-3toh-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5122024-3toh-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5122024-3toh-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"construction project estimation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5122024-3toh-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5122024-3toh-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-2024513-kkxa-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024513-kkxa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-2024513-kkxa-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce search for RV accessories\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-2024513-kkxa-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-2024513-kkxa-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-13052024-35bv-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-35bv-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-13052024-35bv-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal regulations search for life sciences industry\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-13052024-35bv-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-35bv-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-18062024-56t5-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-18062024-56t5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-18062024-56t5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-18062024-56t5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-18062024-56t5-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6192024-56os-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Education technology\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6192024-56os-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"hwtcm","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Monor/hwtcm","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset can be used to evaluate the capabilities of large language models in traditional Chinese medicine and contains multiple-choice, multiple-answer, and true/false questions.\n\n\t\n\t\t\n\t\tChangelog\n\t\n\n\n2024-08-28: Added 7226 questions.\n2024-08-09: The benchmark code is available at https://github.com/huangxinping/HWTCMBench.\n2024-08-02: System prompts are removed to ensure the purity of the evaluation results.\n2024-07-20: Debut.\n\n\n\t\n\t\t\n\t\tExamples\n\t\n\nmultiple-answersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"hwtcm","keyword":"test","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Monor/hwtcm","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset can be used to evaluate the capabilities of large language models in traditional Chinese medicine and contains multiple-choice, multiple-answer, and true/false questions.\n\n\t\n\t\t\n\t\tChangelog\n\t\n\n\n2024-08-28: Added 7226 questions.\n2024-08-09: The benchmark code is available at https://github.com/huangxinping/HWTCMBench.\n2024-08-02: System prompts are removed to ensure the purity of the evaluation results.\n2024-07-20: Debut.\n\n\n\t\n\t\t\n\t\tExamples\n\t\n\nmultiple-answersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-djhb-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-20062024-t2n9-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-2062024-u43q-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-2062024-u43q-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\n\t\n\t\tBAAI_bge-large-en-2062024-u43q-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-2062024-u43q-webapp model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-2062024-u43q-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6212024-p8j6-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"swerec_classification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/swerec_classification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SweRecClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Swedish dataset for sentiment classification on review\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://aclanthology.org/2023.nodalida-1.20/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"SweRecClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/swerec_classification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"norquad_retrieval","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/norquad_retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NorQuadRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHuman-created question for Norwegian wikipedia passages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Written\n\n\nReference\nhttps://aclanthology.org/2023.nodalida-1.17/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NorQuadRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/norquad_retrieval.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","Norwegian BokmÃ¥l"],"keywords_longer_than_N":true},
	{"name":"afrimgsm","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuntian-deng/afrimgsm","creator_name":"Yuntian Deng","creator_url":"https://huggingface.co/yuntian-deng","description":"\n\t\n\t\t\n\t\tDataset Card for afrimgsm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 18 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuntian-deng/afrimgsm.","first_N":5,"first_N_keywords":["text2text-generation","natural-language-inference","multilingual","gsm8k","Amharic"],"keywords_longer_than_N":true},
	{"name":"mozzarella","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/feedback-to-code/mozzarella","creator_name":"Feedback-2-Code","creator_url":"https://huggingface.co/feedback-to-code","description":"\n\t\n\t\t\n\t\tMozzarella-0.3.1 \n\t\n\n\n\t\n\t\t\n\t\tMotivation\n\t\n\n\nMozzarella is a dataset matching issues (= problem statements) and corresponding pull requests (PRs = problem solutions) of a selection of well maintained Java GitHub repositories. The original purpose was to serve as training and evaluation data for ML models concerned with fault localization and automated program repair of complex code bases. However, there might be more use cases that could benefit from this data. \nInspired by SWEBenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/feedback-to-code/mozzarella.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-22062024-taeu-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"or-bench","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bench-llms/or-bench","creator_name":"bench-llm","creator_url":"https://huggingface.co/bench-llms","description":"\n\t\n\t\t\n\t\tOR-Bench: An Over-Refusal Benchmark for Large Language Models\n\t\n\nPlease see our demo at HuggingFace Spaces. \n\n\t\n\t\t\n\t\tOverall Plots of Model Performances\n\t\n\nBelow is the overall model performance. X axis shows the rejection rate on OR-Bench-Hard-1K and Y axis shows the rejection rate on OR-Bench-Toxic. The best aligned model should be on the top left corner of the plot where the model rejects the most number of toxic prompts and least number of safe prompts. We also plot a blue lineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bench-llms/or-bench.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6232024-zldx-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DefAn","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iamasQ/DefAn","creator_name":"A B M Ashikur Rahman","creator_url":"https://huggingface.co/iamasQ","description":"DefAn: Definitive-Answer-Dataset-for-LLMs-Hallucination-Evaluation\n\n  A.B.M. Ashikur Rahman1, Saeed Anwar1,2, Muhammad Usman1,2, Ajmal Mian3, \n\n\n1 King Fahd University of Petroleum and Minerals, Dhahran, KSA\n\n\n2JRCAI, SDAIA-KFUPM \n\n\n3The University of Western Australia, Crawley, Western Australia\n\n\n    Arxiv Paper,  GitHub Repository\n\n\n\n\"DefAn\" is a comprehensive evaluation benchmark dataset, with more than 75000 samples, designed to assess the hallucination tendencies of large language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iamasQ/DefAn.","first_N":5,"first_N_keywords":["text-generation","English","mit","10K<n<100K","arxiv:2406.09155"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6232024-4vtf-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6232024-4vtf-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6232024-4vtf-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Heating Ventilation and Air Conditioning units\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6232024-4vtf-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6232024-4vtf-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-24_06_2024-lrip-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support search for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\taskubuntu Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical Q&A search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tstackoverflow Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code snippet search for developers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tcmedqav2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-13052024-ch9n-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-ch9n-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-13052024-ch9n-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal content search for data protection regulations\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-13052024-ch9n-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-13052024-ch9n-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\taskubuntu-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting queries\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-l","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-l","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\taskubuntu-l Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical troubleshooting forum\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-l model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-l.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tstackoverflow-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code snippet search for developers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tcmedqav2-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical advice and treatment search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"norwegian-nli-triplets-c","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/norwegian-nli-triplets-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tnorwegian-nli-triplets-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Keyword-based search engine for documents\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the norwegian-nli-triplets-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/norwegian-nli-triplets-c.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Norwegian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-5b5o-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-5b5o-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-5b5o-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Fashion boutique products and reviews search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-5b5o-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-5b5o-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-9xxb-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-9xxb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-9xxb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"literary search for narratives\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-9xxb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-9xxb-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-afuz-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-afuz-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-afuz-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"genre-specific search for fantasy novels\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-afuz-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-afuz-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tdutch-legal-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Legal document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-64-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tdutch-legal-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal document search for Dutch legislation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-64-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-1280-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-1280-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tdutch-legal-c-1280-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Legal document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-1280-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-1280-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/flores","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FloresBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFLORES is a benchmark dataset for machine translation between English and low-resource languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Encyclopaedic, Written\n\nReference\nhttps://huggingface.co/datasets/facebook/flores\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FloresBitextMining\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/flores.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Mesopotamian Arabic"],"keywords_longer_than_N":true},
	{"name":"DecipherPref","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huuuyeah/DecipherPref","creator_name":"Yebowen Hu","creator_url":"https://huggingface.co/huuuyeah","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nHuman preference judgments are pivotal in guiding large language models (LLMs) to produce outputs that align with human values. Human evaluations are also used in summarization tasks to compare outputs from various systems, complementing existing automatic metrics. Despite their significance, however, there has been limited research probing these pairwise or k-wise comparisons. The collective impact and relative importance of factors such as output length, informativenessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huuuyeah/DecipherPref.","first_N":5,"first_N_keywords":["summarization","text-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Conv","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22ConvBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Conv is a n-way parallel conversation domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Spoken, Fiction, Spoken\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Conv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Conv.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"IN22-Gen","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Gen","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22GenBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Legal, Government, News, Religious, Non-fiction, Written\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Gen\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Gen.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-256-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\taskubuntu-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting forum search engine for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-256-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-128-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\taskubuntu-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting search engine for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-128-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-128-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tstackoverflow-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-256-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tstackoverflow-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-128-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-256-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific articles\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-128-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tcmedqav2-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-128-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tdutch-legal-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal document search for Dutch legislation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-128-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dutch-legal-c-256-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/dutch-legal-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tdutch-legal-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Legal document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the dutch-legal-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/dutch-legal-c-256-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-256-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tcmedqav2-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information and advice search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-64-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tstackoverflow-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical troubleshooting search engine for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-15052024-stsl-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-15052024-stsl-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-15052024-stsl-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technical classification search for HVAC equipment and parts\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-15052024-stsl-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-15052024-stsl-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5152024-tsbl-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5152024-tsbl-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5152024-tsbl-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Ticket assignment\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5152024-tsbl-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5152024-tsbl-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5162024-o9um-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5162024-o9um-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5162024-o9um-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Note-taking app features search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5162024-o9um-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5162024-o9um-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"test-run","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/test-run","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\ttest-run Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research for argumentation data\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the test-run model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/test-run.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-64-24-gpt-4o-2024-05-13","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-13","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tstackoverflow-c-64-24-gpt-4o-2024-05-13 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical knowledge sharing platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-64-24-gpt-4o-2024-05-13 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-13.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-135760","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24-gpt-4o-2024-05-135760 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Q&A forum for Ubuntu users\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-135760 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-c-64-24-gpt-4o-2024-05-137765","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-137765","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tstackoverflow-c-64-24-gpt-4o-2024-05-137765 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical knowledge sharing platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the stackoverflow-c-64-24-gpt-4o-2024-05-137765 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-137765.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24-gpt-4o-2024-05-133652","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-133652","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24-gpt-4o-2024-05-133652 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general search for paper products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24-gpt-4o-2024-05-133652 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-133652.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24-gpt-4o-2024-05-13-46337","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-13-46337","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24-gpt-4o-2024-05-13-46337 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24-gpt-4o-2024-05-13-46337 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-13-46337.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-131171","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-131171","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24-gpt-4o-2024-05-131171 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Technology Stack Documentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-131171 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-131171.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24-gpt-4o-2024-05-135334","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-135334","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24-gpt-4o-2024-05-135334 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce search for products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24-gpt-4o-2024-05-135334 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24-gpt-4o-2024-05-135334.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-13-61285","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-13-61285","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\taskubuntu-c-64-24-gpt-4o-2024-05-13-61285 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"knowledge base search for questions and answers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-13-61285 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-13-61285.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24-gpt-4o-2024-05-13-35883","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-35883","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24-gpt-4o-2024-05-13-35883 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24-gpt-4o-2024-05-13-35883 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-35883.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"STEM","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stemdataset/STEM","creator_name":"stem","creator_url":"https://huggingface.co/stemdataset","description":"\n\t\n\t\t\n\t\tSTEM Dataset\n\t\n\n\n  ðŸ“ƒ [Paper] â€¢ ðŸ’» [Github] â€¢ ðŸ¤— [Dataset] â€¢ ðŸ† [Leaderboard] â€¢ ðŸ“½ [Slides] â€¢ ðŸ“‹ [Poster]\n\n\nThis dataset is proposed in the ICLR 2024 paper: Measuring Vision-Language STEM Skills of Neural Models. We introduce a new challenge to test the STEM skills of neural models. The problems in the real world often require solutions, combining knowledge from STEM (science, technology, engineering, and math). Unlike existing datasets, our dataset requires the understanding ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stemdataset/STEM.","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"medical_qa","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/medical_qa","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MedicalQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists 2048 medical question and answer pairs.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReference\nhttps://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3119-4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MedicalQARetrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/medical_qa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Database schema for a data management system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"blockchain-benchmark","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/revflask/blockchain-benchmark","creator_name":"Mayank Panjiyara","creator_url":"https://huggingface.co/revflask","description":"\n\t\n\t\t\n\t\tDataset Card for LLM Blockchain Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Blockchain Benchmark Dataset is a comprehensive collection of data specifically curated for benchmarking Language Models (LMs) in the domain of blockchain technology. This dataset is designed to facilitate research and development in natural language understanding within the blockchain domain.\nA complete list of tasks: ['general-reasoning', 'code', 'math']\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\nModelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/revflask/blockchain-benchmark.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","English"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24-gpt-4o-2024-05-131129","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-131129","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24-gpt-4o-2024-05-131129 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24-gpt-4o-2024-05-131129 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-131129.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24-gpt-4o-2024-05-13-50353","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-50353","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tcmedqav2-c-64-24-gpt-4o-2024-05-13-50353 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the cmedqav2-c-64-24-gpt-4o-2024-05-13-50353 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24-gpt-4o-2024-05-13-50353.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-1752024-13s3-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-13s3-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-1752024-13s3-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical and biomedical sciences knowledge base\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-1752024-13s3-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-13s3-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-1752024-zdtc-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-zdtc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-1752024-zdtc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Pharmacology research on antidepressants\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-1752024-zdtc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-1752024-zdtc-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-17052024-uhub-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-uhub-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-17052024-uhub-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal case document search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-17052024-uhub-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-uhub-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-17052024-dumr-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-dumr-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-17052024-dumr-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal judgements search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-17052024-dumr-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-17052024-dumr-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"blockchain-benchmark-formatted","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/revflask/blockchain-benchmark-formatted","creator_name":"Mayank Panjiyara","creator_url":"https://huggingface.co/revflask","description":"\n\t\n\t\t\n\t\tDataset Card for LLM Blockchain Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Blockchain Benchmark Dataset is a comprehensive collection of data specifically curated for benchmarking Language Models (LMs) in the domain of blockchain technology. This dataset is designed to facilitate research and development in natural language understanding within the blockchain domain.\nA complete list of tasks: ['general-reasoning', 'code', 'math']\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\nModelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/revflask/blockchain-benchmark-formatted.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","expert-generated","English"],"keywords_longer_than_N":true},
	{"name":"arguana-c-64-24-gpt-4o-2024-05-136897","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-64-24-gpt-4o-2024-05-136897 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-64-24-gpt-4o-2024-05-136897 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136897.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-64-24-gpt-4o-2024-05-136538","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136538","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-64-24-gpt-4o-2024-05-136538 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-64-24-gpt-4o-2024-05-136538 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-64-24-gpt-4o-2024-05-136538.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-128-24-gpt-4o-2024-05-13-68212","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-128-24-gpt-4o-2024-05-13-68212","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-128-24-gpt-4o-2024-05-13-68212 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-128-24-gpt-4o-2024-05-13-68212 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-128-24-gpt-4o-2024-05-13-68212.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-51550","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-51550","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-51550 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-51550 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-51550.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-19052024-oiu8-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-19052024-oiu8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-19052024-oiu8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"E-commerce advertising platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-19052024-oiu8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-19052024-oiu8-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-henp-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-henp-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-henp-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Accounting laws and guidelines search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-henp-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-henp-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-xqq9-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-xqq9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-xqq9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"machine learning data generation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-xqq9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-xqq9-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-qeye-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-qeye-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-qeye-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Cybersecurity and hacking information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-qeye-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-qeye-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"social","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/socialnormdataset/social","creator_name":"socialnormdataset","creator_url":"https://huggingface.co/socialnormdataset","description":"\n\t\n\t\t\n\t\tSocial Dataset\n\t\n\n\n  ðŸ“ƒ [Paper] â€¢ ðŸ’» [Github] â€¢ ðŸ¤— [Dataset] â€¢ ðŸ“½ [Slides] â€¢ ðŸ“‹ [Poster]\n\n\nThis dataset is proposed in the NAACL 2024 paper: Measuring Social Norms of Large Language Models.\nWe present a new challenge to examine whether large language models understand social norms. In contrast to existing datasets, our dataset requires a fundamental understanding of social norms to solve. Our dataset features the largest set of social norm skills, consisting of 402 skills and 12,383â€¦ See the full description on the dataset page: https://huggingface.co/datasets/socialnormdataset/social.","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5192024-seuc-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-seuc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5192024-seuc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"book search for startup advice\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5192024-seuc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5192024-seuc-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5202024-55bm-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-55bm-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5202024-55bm-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal regulations search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5202024-55bm-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-55bm-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-37376","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-37376","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-37376 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-37376 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-37376.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-321013","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-321013","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-321013 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-321013 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-321013.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-623812","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-623812","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-623812 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-623812 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-623812.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-799305","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-799305 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research on argumentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-799305 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-799305","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-799305 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research on argumentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-799305 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-799305.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5202024-6tkj-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-6tkj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5202024-6tkj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"educational content for customer insights and marketing strategies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5202024-6tkj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-6tkj-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"arguana-c-256-24-gpt-4o-2024-05-13-994439","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-994439","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\targuana-c-256-24-gpt-4o-2024-05-13-994439 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the arguana-c-256-24-gpt-4o-2024-05-13-994439 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/arguana-c-256-24-gpt-4o-2024-05-13-994439.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5202024-rxyq-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-rxyq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5202024-rxyq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"gaming information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5202024-rxyq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5202024-rxyq-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Material_Selection_Eval","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmudrc/Material_Selection_Eval","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","description":"A benchmark designed to facilitate evaluation and modify the behavior of a foundation model through different existing techniques in the context of material selection for conceptual design.\nThe data is collected by conducting a survey of experts in the field of material selection. The same questions mentioned in keyquestions.csv are asked to experts.\nThis can be used to evaluate a Language model performance and its spread compared to a human evaluation.\nTo get into a more detailed explanationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cmudrc/Material_Selection_Eval.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","text-retrieval","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-5qm5-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5qm5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-5qm5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-5qm5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5qm5-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-5qm5-webapp","keyword":"testing","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5qm5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-5qm5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-5qm5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5qm5-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-6vz1-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-6vz1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-6vz1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-6vz1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-6vz1-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-21052024-5smg-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-21052024-5smg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-21052024-5smg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-21052024-5smg-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-22052024-vuno-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-22052024-vuno-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"test search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-22052024-vuno-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-22052024-vuno-webapp","keyword":"testing","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-22052024-vuno-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"test search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-22052024-vuno-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"flo","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/florianhoenicke/flo","creator_name":"Florian HÃ¶nicke","creator_url":"https://huggingface.co/florianhoenicke","description":"\n\t\n\t\t\n\t\tflo Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the flo model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"florianhoenicke/flo\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/florianhoenicke/flo.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-5222024-i8af-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-5222024-i8af-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-5222024-i8af-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"issue tracking search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-5222024-i8af-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-5222024-i8af-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5222024-hkde-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5222024-hkde-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code repository search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5222024-hkde-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-14719","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-14719","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-14719 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-14719 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-14719.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-825318","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-825318","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-825318 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment analysis and opinion-based QA\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-825318 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-825318.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-10630","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-10630","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-10630 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-10630 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-10630.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-526066","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-526066 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-526066 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-46082","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-46082","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-46082 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-46082 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-46082.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-46681","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-46681","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-46681 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-46681 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-46681.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-690454","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-690454","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-690454 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-690454 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-690454.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-203779","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-203779","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-203779 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-203779 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-203779.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-497939","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-497939","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-497939 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-497939 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-497939.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-994884","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-994884 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-994884 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-417900","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-417900","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-417900 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-417900 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-417900.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-23052024-hbdj-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-23052024-hbdj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"test run search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-23052024-hbdj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-23052024-hbdj-webapp","keyword":"testing","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-23052024-hbdj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"test run search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-23052024-hbdj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-23052024-6kfw-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-6kfw-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-23052024-6kfw-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"informational search for legal technology guidance\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-23052024-6kfw-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-6kfw-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-23052024-upq5-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-23052024-upq5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-23052024-upq5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"generic search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-23052024-upq5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-23052024-upq5-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-257061","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-257061","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-257061 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-257061 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-257061.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-353382","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-353382","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-353382 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-353382 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-353382.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-982705","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-982705","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-982705 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-982705 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-982705.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-855191","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-855191","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-855191 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-855191 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-855191.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-847943","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-847943","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-847943 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-847943 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-847943.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-978964","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-978964","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-978964 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-978964 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-978964.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-624125","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-624125","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-624125 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-624125 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-624125.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-449863","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-449863","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-449863 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-449863 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-449863.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-152861","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-152861","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-152861 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-152861 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-152861.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-322852","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-322852","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-322852 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-322852 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-322852.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-0-0-gpt-4o-2024-05-13-470790","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-470790","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\n\t\n\t\tNFCorpus-0-0-gpt-4o-2024-05-13-470790 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-0-0-gpt-4o-2024-05-13-470790 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-0-0-gpt-4o-2024-05-13-470790.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-8-8-gpt-4o-2024-05-13-610535","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-610535","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-8-8-gpt-4o-2024-05-13-610535 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-8-8-gpt-4o-2024-05-13-610535 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-8-8-gpt-4o-2024-05-13-610535.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-396610","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-396610","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-396610 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-396610 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-396610.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-3778","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-3778 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-3778 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-235808","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-235808","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-235808 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment analysis and opinion-based QA\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-235808 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-235808.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-421451","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-421451","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-421451 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-421451 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-421451.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-774308","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-774308","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-774308 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment analysis and opinion-based QA\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-774308 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-774308.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-456029","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-456029","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-456029 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-456029 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-456029.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-204265","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-204265 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-204265 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-862053","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-862053","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-862053 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-862053 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-862053.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-546049","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-546049","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-546049 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-546049 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-546049.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-898550","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-898550","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-898550 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-898550 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-898550.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-598568","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-598568","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-598568 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-598568 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-598568.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-499715","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-499715 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-499715 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-5242024-5uvy-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-5242024-5uvy-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-5242024-5uvy-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"informational search on vaccine safety\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-5242024-5uvy-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-5242024-5uvy-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"big-patent","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/big-patent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BigPatentClustering.v2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of documents from the Big Patent dataset. Test set only includes documentsbelonging to a single category, with a total of 9 categories.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/NortheasternUniversity/big_patent\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/big-patent.","first_N":5,"first_N_keywords":["text-classification","derived","monolingual","jinaai/big-patent-clustering","English"],"keywords_longer_than_N":true},
	{"name":"dataset-portuguese-aira-v2-Gemma-format","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format","creator_name":"EDDY GIUSEPE CHIRINOS ISIDRO, PhD","creator_url":"https://huggingface.co/EddyGiusepe","description":"Dataset Aira para o formato do Modelo Gemma \n\n\n\t\n\t\t\n\t\tResumo do Dataset\n\t\n\nEste conjunto de dados contÃ©m uma coleÃ§Ã£o de conversas individuais entre um assistente e um usuÃ¡rio.\nAs conversas foram geradas pelas interaÃ§Ãµes do usuÃ¡rio com modelos jÃ¡ ajustados (ChatGPT, LLama 2, Open-Assistant, etc).\nO conjunto de dados estÃ¡ disponÃ­vel em portuguÃªs (tem a versÃ£o em InglÃªs que ainda nÃ£o tratei). Mas vocÃª pode baixar do \nrepositÃ³rio de Nicholas Kluge CorrÃªa tanto a versÃ£o em PortuguÃªs e \na versÃ£o emâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format.","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ISHate","keyword":"benchmark","license":"Boost Software License 1.0","license_url":"https://choosealicense.com/licenses/bsl-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BenjaminOcampo/ISHate","creator_name":"NicolÃ¡s BenjamÃ­n Ocampo","creator_url":"https://huggingface.co/BenjaminOcampo","description":"\n\t\n\t\t\n\t\tImplicit and Subtle Hate\n\t\n\nImplicit and Subtle Hate (ISHate) is a Hate Speech benchmark for implicit and subtle HS detection on social media messages. The dataset has been presented in the paper \"An In-depth Analysis of Implicit and Subtle Hate Speech Messages\" accepted at EACL 2023.\n[Read the Paper]\n\n\t\n\t\t\n\t\tWhat is Implicit and Subtle Hate?\n\t\n\nImplicit Hate Speech does not immediately denote abuse/hate. Implicitness goes beyond word-related meaning, implying figurative language useâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BenjaminOcampo/ISHate.","first_N":5,"first_N_keywords":["text-classification","English","bsl-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7232024-szl5-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Universidad de las Fuerzas Armadas ESPE information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-2572024-mb4o-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-7302024-f9zi-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-31_7_2024-kubz-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"nli-topic-data","keyword":"nli","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skshmjn/nli-topic-data","creator_name":"Saksham Jain","creator_url":"https://huggingface.co/skshmjn","description":"skshmjn/nli-topic-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["zero-shot-classification","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"text-2-image-Rich-Human-Feedback","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-image-Rich-Human-Feedback","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\n\n\nBuilding upon Google's research Rich Human Feedback for Text-to-Image Generation we have collected over 1.5 million responses from 152'684 individual humans using Rapidata via the Python API. Collection took roughly 5 days. \nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nWe asked humans to evaluate AI-generated images in style, coherence and prompt alignment. For images that contained flaws, participants wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-image-Rich-Human-Feedback.","first_N":5,"first_N_keywords":["text-to-image","text-classification","image-classification","image-to-text","image-segmentation"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"web development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-922024-zgwo-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-922024-puz9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-922024-puz9-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-922024-pwti-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-922024-pwti-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-o8xx-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-ww8e-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-kk9q-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-k007-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information in German\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information in German language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can loadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-932024-59f9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"AI tools and products by Jina AI\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-942024-7mc4-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Entrepreneurship and Career Development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-agp9-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Personal Development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-15092024-sil1-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"PHTest","keyword":"alignment","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/furonghuang-lab/PHTest","creator_name":"Furong Huang's Lab at UMD","creator_url":"https://huggingface.co/furonghuang-lab","description":"ðŸŒŸ PHTest: Evaluating False Refusals in LLMs\n\n\n  ðŸ¤– Auto Red-Teaming\n    \n      All prompts are generated automatically using a controllable text-generation technique called AutoDAN.\n    \n  \n  \n  ðŸŒ Diverse Prompts\n    \n      PHTest introduces false refusal patterns that arenâ€™t present in existing datasets, including prompts that avoid mentioning sensitive words.\n    \n  \n  \n  âš–ï¸ Harmlessness & Controversial Labeling\n    \n      Controversial prompts are separately labeled to address theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/furonghuang-lab/PHTest.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DBPedia_PL_test_top_250_only_w_correct-v2","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DBPedia_PL_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DBPedia-PLHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia_PL_test_top_250_only_w_correct-v2.","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/dbpedia","Polish"],"keywords_longer_than_N":true},
	{"name":"DBPedia_test_top_250_only_w_correct-v2","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DBPedia_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DBPediaHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\n\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia_test_top_250_only_w_correct-v2.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","mteb/dbpedia","English"],"keywords_longer_than_N":true},
	{"name":"ClimateFEVER_test_top_250_only_w_correct-v2","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ClimateFEVER_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ClimateFEVERHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCLIMATE-FEVER is a dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://www.sustainablefinance.uzh.ch/en/research/climate-fever.htmlâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ClimateFEVER_test_top_250_only_w_correct-v2.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"HotpotQA_PL_test_top_250_only_w_correct-v2","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HotpotQA_PL_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HotpotQA-PLHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHotpotQA is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems. The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HotpotQA_PL_test_top_250_only_w_correct-v2.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","mteb/hotpotqa"],"keywords_longer_than_N":true},
	{"name":"HotpotQA_test_top_250_only_w_correct-v2","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HotpotQA_test_top_250_only_w_correct-v2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HotpotQAHardNegatives\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHotpotQA is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.  The hard negative version has been created by pooling the 250 top documents per query from BM25, e5-multilingual-large and e5-mistral-instruct.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HotpotQA_test_top_250_only_w_correct-v2.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/hotpotqa"],"keywords_longer_than_N":true},
	{"name":"jaqket","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/jaqket","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JaqketRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJAQKET (JApanese Questions on Knowledge of EnTities) is a QA dataset that is created based on quiz questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Written\nReference\nhttps://github.com/kumapo/JAQKET-dataset\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"JaqketRetrieval\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/jaqket.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"wit","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/wit","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  WITT2IRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve images based on multilingual descriptions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://proceedings.mlr.press/v162/bugliarello22a/bugliarello22a.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"WITT2IRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/wit.","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","multilingual"],"keywords_longer_than_N":true},
	{"name":"user-test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/han9527/user-test","creator_name":"liu","creator_url":"https://huggingface.co/han9527","description":"han9527/user-test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"LOGIC-701-instruct","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/evilfreelancer/LOGIC-701-instruct","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","description":"\n\t\n\t\t\n\t\tLOGIC-701 (instruct)\n\t\n\nBased on https://huggingface.co/datasets/hivaze/LOGIC-701\nSources https://github.com/EvilFreelancer/LOGIC-701-instruct\n","first_N":5,"first_N_keywords":["question-answering","Russian","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test_dataset","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/francescocrivelli/test_dataset","creator_name":"Francesco Crivelli","creator_url":"https://huggingface.co/francescocrivelli","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 4,\n    \"total_frames\": 2681,\n    \"total_tasks\": 2,\n    \"total_videos\": 8,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:4\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/francescocrivelli/test_dataset.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Qu-QA","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\n\t\n\t\t\n\t\tQu QA Dataset\n\t\n\nQu QA is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFeatures:\n\ninput: A string representing the question (dtype: string).\noutput: A string representing the answer (dtype: string).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Qu-QA-v2","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\n\t\n\t\t\n\t\tQu QA v2 Dataset\n\t\n\nQu QA v2 is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFeatures:\n\ninput: A string representing the question (dtype: string).\noutput: A string representing the answer (dtype: string).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-15_8_2024-h1i4-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"T2Retrieval","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/T2Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  T2Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nT2Ranking: A large-scale Chinese Benchmark for Passage Ranking\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Financial, Government, Non-fiction\n\n\nReference\nhttps://arxiv.org/abs/2304.03679\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"T2Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/T2Retrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","monolingual","Mandarin Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"llm_physical_safety_benchmark","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kumitang/llm_physical_safety_benchmark","creator_name":"Yung-Chen Tang","creator_url":"https://huggingface.co/kumitang","description":"\n\t\n\t\t\n\t\tLLM Physical Safety Benchmark in Drone Control\n\t\n\nThis benchmark consists of four datasets designed to evaluate the performance of Large Language Models (LLMs) in controlling drones and their vulnerability to physical attacks. The datasets are categorized into different types of attacks:\n\nDeliberate Attack: Contains 280 samples that evaluate the LLM's resistance to malicious use, testing its ability to recognize and reject commands intended to cause harm. Subcategories include Directâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kumitang/llm_physical_safety_benchmark.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"llm_physical_safety_benchmark","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TrustSafeAI/llm_physical_safety_benchmark","creator_name":"TrustSafeAI","creator_url":"https://huggingface.co/TrustSafeAI","description":"\n\t\n\t\t\n\t\tLLM Physical Safety Benchmark in Drone Control\n\t\n\nThis benchmark consists of four datasets designed to evaluate the performance of Large Language Models (LLMs) in controlling drones and their vulnerability to physical attacks. The datasets are categorized into different types of attacks:\n\nDeliberate Attack: Contains 280 samples that evaluate the LLM's resistance to malicious use, testing its ability to recognize and reject commands intended to cause harm. Subcategories include Directâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TrustSafeAI/llm_physical_safety_benchmark.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"GiftEvalPretrain","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/GiftEvalPretrain","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\n\t\n\t\t\n\t\tGIFT-Eval Pre-training Datasets\n\t\n\nPretraining dataset aligned with GIFT-Eval that has 71 univariate and 17 multivariate datasets, spanning seven domains and 13 frequencies, totaling 4.5 million time series and 230 billion data points. Notably this collection of data has no leakage issue with the train/test split and can be used to pretrain foundation models that can be fairly evaluated on GIFT-Eval.\nðŸ“„ Paper\nðŸ–¥ï¸ Code\nðŸ“” Blog Post\nðŸŽï¸ Leader Board\n\n\t\n\t\n\t\n\t\tEthical Considerationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/GiftEvalPretrain.","first_N":5,"first_N_keywords":["time-series-forecasting","apache-2.0","1M<n<10M","Time-series","arxiv:2410.10393"],"keywords_longer_than_N":true},
	{"name":"jnli","keyword":"nli","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/jnli","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\n\t\n\t\t\n\t\tJGLUE[JNLI]: Japanese General Language Understanding Evaluation\n\t\n\nJNLI(yahoojapan/JGLUE) is a Japanese version of the NLI (Natural Language Inference) dataset. \nNLI is a task to recognize the inference relation that a premise sentence has to a hypothesis sentence. \nThe inference relations are entailment, contradiction, and neutral.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\nRepository: yahoojapan/JGLUE\nPaper: [More Information Needed]\n\n\n\t\n\t\n\t\n\t\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jnli.","first_N":5,"first_N_keywords":["text-classification","Japanese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jnli","keyword":"benchmark","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/jnli","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\n\t\n\t\t\n\t\tJGLUE[JNLI]: Japanese General Language Understanding Evaluation\n\t\n\nJNLI(yahoojapan/JGLUE) is a Japanese version of the NLI (Natural Language Inference) dataset. \nNLI is a task to recognize the inference relation that a premise sentence has to a hypothesis sentence. \nThe inference relations are entailment, contradiction, and neutral.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\nRepository: yahoojapan/JGLUE\nPaper: [More Information Needed]\n\n\n\t\n\t\n\t\n\t\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jnli.","first_N":5,"first_N_keywords":["text-classification","Japanese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"FACTS-grounding-public","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/FACTS-grounding-public","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tFACTS Grounding 1.0 Public Examples\n\t\n\n\n\t\n\t\t\n\t\t860 public FACTS Grounding examples from Google DeepMind and Google Research\n\t\n\nFACTS Grounding is a benchmark from Google DeepMind and Google Research designed to measure the performance of AI Models on factuality and grounding. \nâ–¶ FACTS Grounding Leaderboard on Kaggleâ–¶ Technical Reportâ–¶ Evaluation Starter Codeâ–¶ Google DeepMind Blog Post\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nThe FACTS Grounding benchmark evaluates the ability of Large Language Models (LLMs)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/FACTS-grounding-public.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Preference Dataset\n\t\n\n\n\n\n\n\n\n\nThis dataset was collected in ~12 hours using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nThe data collected in this dataset informs our text-2-video model benchmark. We just started so currently only two models are represented in this set:\n\nSora\nHunyouan\nPika 2.0\nRunway ML Alpha\nLuma Ray 2\n\nExplore our latest model rankings on our website.\nIf you get value from this dataset and wouldâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences.","first_N":5,"first_N_keywords":["text-to-video","video-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"IndicQARetrieval","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIndicQA is a manually curated cloze-style reading comprehension dataset that can be used for evaluating question-answering models in 11 Indic languages. It is repurposed retrieving relevant context for each question.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicQARetrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"MyanmarNews","keyword":"mteb","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MyanmarNews","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MyanmarNews\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Myanmar News dataset on Hugging Face contains news articles in Burmese. It is designed for tasks such as text classification, sentiment analysis, and language modeling. The dataset includes a variety of news topics in 4 categorie, providing a rich resource for natural language processing applications involving Burmese which is a low resource language.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MyanmarNews.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Burmese"],"keywords_longer_than_N":true},
	{"name":"WisesightSentimentClassification","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/WisesightSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  WisesightSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, News, Written\nReference\nhttps://github.com/PyThaiNLP/wisesight-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/WisesightSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"scips_qa","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zorpsoon/scips_qa","creator_name":"Prasoon Bajpai","creator_url":"https://huggingface.co/zorpsoon","description":"zorpsoon/scips_qa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"high-quality-nli","keyword":"nli","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-nli","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh-Quality NLI Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is designed for Natural Language Inference (NLI) tasks, containing high-quality sentence pairs. It improves upon commonly used NLI datasets by offering more complex and nuanced examples, making it suitable for advanced language understanding models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTrain set size: 550â€‰970\nTest set size: 137â€‰743\nTotal size: 688â€‰713\n\n\n\t\n\t\t\n\t\tClass Distribution\n\t\n\n\n\t\n\t\t\nLabelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-nli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","English","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"NL-Eye","keyword":"nli","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MorVentura/NL-Eye","creator_name":"Mor Ventura","creator_url":"https://huggingface.co/MorVentura","description":"\n\t\n\t\t\n\t\tNL-Eye Benchmark\n\t\n\nWill a Visual Language Model (VLM)-based bot warn us about slipping if it detects a wet floor? \nRecent VLMs have demonstrated impressive capabilities, yet their ability to infer outcomes and causes remains underexplored. To address this, we introduce NL-Eye, a benchmark designed to assess VLMs' visual abductive reasoning skills. \nNL-Eye adapts the abductive Natural Language Inference (NLI) task to the visual domain, requiring models to evaluate the plausibility ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MorVentura/NL-Eye.","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-862024-gra4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"E-commerce software for an online store\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"travel and accommodation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-msqc-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce for cannabis industry\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-sz3k-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-872024-od97-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-od97-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-872024-od97-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"job search and recruitment\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-872024-od97-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-872024-od97-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"holistic health and well-being services\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08082024-dfhx-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-08082024-cs2v-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-08082024-cs2v-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-08082024-cs2v-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Wellness and Mindfulness\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-08082024-cs2v-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-08082024-cs2v-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-892024-idqb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"career development and matchmaking\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-892024-idqb-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"llmfao","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dustalov/llmfao","creator_name":"Dmitry Ustalov","creator_url":"https://huggingface.co/dustalov","description":"\n\t\n\t\t\n\t\tLarge Language Model Feedback Analysis and Optimization (LLMFAO)\n\t\n\nThe original Crowdsourced LLM Benchmark dataset in files prompts.parqet and outputs.parquet was kindly provided by the team at llmonitor.com under a CCÂ BY 4.0 license. This dataset can be conveniently processed with Evalica (arXiv).\n","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SpectraMail_Data_Set","keyword":"testing","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MawLab/SpectraMail_Data_Set","creator_name":"maw studio","creator_url":"https://huggingface.co/MawLab","description":"Code Message:\n\n\t\n\t\t\n\t\tSpectraMail_Data_Set ðŸ“§\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nWelcome to the SpectraMail_Data_Set! This dataset provides a collection of 70,000 unique and randomly generated email addresses designed for testing and development purposes. The dataset is ideal for use in system testing, validation, and as synthetic data for AI training scenarios.  \n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nEmail Generation: Each entry includes a randomly generated email address.  \nHigh Volume: Contains 70,000 rows to supportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MawLab/SpectraMail_Data_Set.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"twinviews-13k","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wwbrannon/twinviews-13k","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\n\t\n\t\t\n\t\tDataset Card for TwinViews-13k\n\t\n\nThis dataset contains 13,855 pairs of left-leaning and right-leaning political statements matched by topic. The dataset was generated using GPT-3.5 Turbo and has been audited to ensure quality and ideological balance. It is designed to facilitate the study of political bias in reward models and language models, with a focus on the relationship between truthfulness and political views.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/twinviews-13k.","first_N":5,"first_N_keywords":["text-classification","reinforcement-learning","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"MM-TelecoBench","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Exploration-Lab/MM-TelecoBench","creator_name":"Exploration Lab","creator_url":"https://huggingface.co/Exploration-Lab","description":"Exploration-Lab/MM-TelecoBench dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","text-classification","translation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"GiftEval","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/GiftEval","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\n\t\n\t\t\n\t\tGIFT-Eval\n\t\n\n\n\nWe present GIFT-Eval, a benchmark designed to advance zero-shot time series forecasting by facilitating evaluation across diverse datasets. GIFT-Eval includes 23 datasets covering 144,000 time series and 177 million data points, with data spanning seven domains, 10 frequencies, and a range of forecast lengths. This benchmark aims to set a new standard, guiding future innovations in time series foundation models.\nTo facilitate the effective pretraining and evaluation ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/GiftEval.","first_N":5,"first_N_keywords":["time-series-forecasting","apache-2.0","100K<n<1M","Time-series","arxiv:2410.10393"],"keywords_longer_than_N":true},
	{"name":"MixEval-X","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MixEval/MixEval-X","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","description":"\n\n\nðŸš€ Project Page | ðŸ“œ arXiv | ðŸ‘¨â€ðŸ’» Github | ðŸ† Leaderboard | ðŸ“ blog | ðŸ¤— HF Paper | ð• Twitter\n\n\n\n\n\n\n\nMixEval-X encompasses eight input-output modality combinations and can be further extended. Its data points reflect real-world task distributions. The last grid presents the scores of frontier organizationsâ€™ flagship models on MixEval-X, normalized to a 0-100 scale, with MMG tasks using win rates instead of Elo. Section C of the paper presents example data samples and model responses.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval-X.","first_N":5,"first_N_keywords":["image-to-text","video-text-to-text","audio-classification","text-generation","text-to-audio"],"keywords_longer_than_N":true},
	{"name":"webis-touche2020-v3","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/webis-touche2020-v3","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  Touche2020Retrieval.v3\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTouchÃ© Task 1: Argument Retrieval for Controversial Questions\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReference\nhttps://github.com/castorini/touche-error-analysis\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Touche2020Retrieval.v3\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/webis-touche2020-v3.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","mteb/touche2020"],"keywords_longer_than_N":true},
	{"name":"or-bench","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/orbench-llm/or-bench","creator_name":"orbench-llm","creator_url":"https://huggingface.co/orbench-llm","description":"\n\t\n\t\t\n\t\tOR-Bench: An Over-Refusal Benchmark for Large Language Models\n\t\n\nPlease see our leaderboard at HuggingFace Spaces. \n\n\t\n\t\t\n\t\tOverall Plots of Model Performances\n\t\n\nBelow is the overall model performance. X axis shows the rejection rate on OR-Bench-Hard-1K and Y axis shows the rejection rate on OR-Bench-Toxic. The best aligned model should be on the top left corner of the plot where the model rejects the most number of toxic prompts and least number of safe prompts. We also plot a blueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/orbench-llm/or-bench.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-02082024-vrdv-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-02082024-vrdv-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-02082024-vrdv-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-02082024-vrdv-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-02082024-vrdv-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"so100_test_init","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ofiroz91/so100_test_init","creator_name":"Ofir Ozeri","creator_url":"https://huggingface.co/Ofiroz91","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 5,\n    \"total_frames\": 5403,\n    \"total_tasks\": 1,\n    \"total_videos\": 10,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:5\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ofiroz91/so100_test_init.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"NLI_Dataset","keyword":"nli","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rupesh2/NLI_Dataset","creator_name":"Rupesh","creator_url":"https://huggingface.co/Rupesh2","description":"Rupesh2/NLI_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"VisQuant","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anas-Mohiuddin-Syed/VisQuant","creator_name":"Syed Anas Mohiuddin","creator_url":"https://huggingface.co/Anas-Mohiuddin-Syed","description":"\nlicense: cc-by-4.0\ndatasets:\n\nvisquant\nlanguage:\nen\ntags:\nvisual-question-answering\nobject-counting\nspatial-reasoning\nsynthetic\nmultimodal\nbenchmark\n\n\n\t\n\t\t\n\t\tVisQuant: A Synthetic Benchmark for Object Counting and Spatial Reasoning\n\t\n\nVisQuant is a synthetic dataset of 100 annotated image scenarios, purpose-built to evaluate AI systems on object counting, spatial layout understanding, and visual question answering (VQA).\nThis dataset is ideal for benchmarking vision-language models (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anas-Mohiuddin-Syed/VisQuant.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"test2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aiwhisperer/test2","creator_name":"Samuel Boylan-Sajous","creator_url":"https://huggingface.co/aiwhisperer","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 2,\n    \"total_frames\": 1657,\n    \"total_tasks\":1,\n    \"total_videos\": 2,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:2\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aiwhisperer/test2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"BIBLE","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushroomGecko/BIBLE","creator_name":"Devon","creator_url":"https://huggingface.co/MushroomGecko","description":"\n\t\n\t\t\n\t\tBIBLE: Biblically Informed Bot Learning Evaluation\n\t\n\nBIBLE (Biblically Informed Bot Learning Evaluation) is a comprehensive benchmark dataset designed to evaluate AI models on their understanding of the Holy Bible. It covers all 66 books of Scripture and includes additional thematic categories for People of the Bible, Places in the Bible, and Measurements in the Bible.\n\nâš ï¸ This dataset is not intended for training. It is strictly for evaluation and benchmarking of models on Biblicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MushroomGecko/BIBLE.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-pika2.2","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-pika2.2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Pika 2.2 Human Preference\n\t\n\n\n\n\n\n\n\n\nIn this dataset, ~756k human responses from ~29k human annotators were collected to evaluate Pika 2.2 video generation model on our benchmark. This dataset was collected in ~1 day total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\nExplore our latest model rankings on our website.\nIf you get value from this dataset and would like to see more in the future, please considerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-pika2.2.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"iris","keyword":"benchmark","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ViictorCM/iris","creator_name":"CM","creator_url":"https://huggingface.co/ViictorCM","description":"\n\t\n\t\t\n\t\tIris Dataset Card\n\t\n\nDataset Overview\nThe Iris dataset is a classic dataset widely used in the fields of machine learning and statistics. Originally introduced by Ronald A. Fisher in 1936, it serves as a benchmark for classification algorithms. The dataset contains measurements of iris flowers from three different species: Iris setosa, Iris versicolor, and Iris virginica.\nKey Characteristics\n\nNumber of Instances: 150\nNumber of Features: 4\nClasses: 3 (50 instances each)\nFeature Types:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ViictorCM/iris.","first_N":5,"first_N_keywords":["tabular-classification","multi-class-classification","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"openbookqa","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/openbookqa","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\topenbookqa Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: openbookqa\nSubset: main\nEvaluation Split: test\nTraining Split: train\nTask Type: multiple_choice_completion\nProcessing Function: process_openbookqa\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_openbookqa(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process OpenBookQA dataset example.\"\"\"\n    query =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/openbookqa.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"arc_easy","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/arc_easy","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tarc_easy Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: ai2_arc\nSubset: ARC-Easy\nEvaluation Split: test\nTraining Split: train\nTask Type: multiple_choice\nProcessing Function: process_arc\n\n\n\t\n\t\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_arc(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process ARC dataset example.\"\"\"\n    query = example[\"question\"]\n    choices =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/arc_easy.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"arc_challenge","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/arc_challenge","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tarc_challenge Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: ai2_arc\nSubset: ARC-Challenge\nEvaluation Split: test\nTraining Split: train\nTask Type: multiple_choice\nProcessing Function: process_arc\n\n\n\t\n\t\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_arc(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process ARC dataset example.\"\"\"\n    query = example[\"question\"]\n    choices =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/arc_challenge.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"siqa","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/siqa","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tsiqa Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: lighteval/siqa\nSubset: default\nEvaluation Split: validation\nTraining Split: train\nTask Type: multiple_choice\nProcessing Function: process_siqa\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_siqa(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process SocialIQA dataset example.\"\"\"\n    query = f\"{example['context']}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/siqa.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"hellaswag","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/hellaswag","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\thellaswag Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: hellaswag\nSubset: default\nEvaluation Split: validation\nTraining Split: train\nTask Type: multiple_choice_completion\nProcessing Function: process_hellaswag\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_hellaswag(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process HellaSwag dataset example.\"\"\"\n    import reâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/hellaswag.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"commonsense_qa","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/commonsense_qa","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tcommonsense_qa Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: commonsense_qa\nSubset: default\nEvaluation Split: validation\nTraining Split: train\nTask Type: multiple_choice_completion\nProcessing Function: process_commonsense_qa\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_commonsense_qa(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process CommonsenseQA datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/commonsense_qa.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"triviaqa","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/triviaqa","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\ttriviaqa Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: trivia_qa\nSubset: rc.nocontext\nEvaluation Split: validation\nTraining Split: train\nTask Type: perplexity_qa\nProcessing Function: process_triviaqa\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_triviaqa(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process TriviaQA dataset example.\"\"\"\n    query =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/triviaqa.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"boolq","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/boolq","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tboolq Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: lighteval/boolq_helm\nSubset: default\nEvaluation Split: validation\nTraining Split: train\nTask Type: multiple_choice_with_context\nProcessing Function: process_boolq\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_boolq(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process BoolQ dataset example.\"\"\"\n    # Create query fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/boolq.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"TARA_Turkish_LLM_Benchmark","keyword":"benchmark","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emre/TARA_Turkish_LLM_Benchmark","creator_name":"Davut Emre TASAR","creator_url":"https://huggingface.co/emre","description":"\n\t\n\t\t\n\t\tTARA: Turkish Advanced Reasoning Assessment Veri Seti\n\t\n\n\n*Img Credit: Open AI ChatGPT\n**English version is given below.**\n\n Evaluation Notebook / DeÄŸerlendirme Not Defteri\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nTARA (Turkish Advanced Reasoning Assessment), TÃ¼rkÃ§e dilindeki BÃ¼yÃ¼k Dil Modellerinin (LLM'ler) geliÅŸmiÅŸ akÄ±l yÃ¼rÃ¼tme yeteneklerini Ã§oklu alanlarda Ã¶lÃ§mek iÃ§in tasarlanmÄ±ÅŸ, zorluk derecesine gÃ¶re sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ bir benchmark veri setidir. Bu veri seti, LLM'lerin sadece bilgiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emre/TARA_Turkish_LLM_Benchmark.","first_N":5,"first_N_keywords":["question-answering","text-generation","Turkish","afl-3.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset-v3","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of multi-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3.","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"opin-pref","keyword":"alignment","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/swaroop-nath/opin-pref","creator_name":"Swaroop Nath","creator_url":"https://huggingface.co/swaroop-nath","description":"Human preference dataset for Opinion Summarization. Each instance consists of reviews, two opinion summaries and the human preference. \nPreference has been collected from domain experts. The dataset has a total of 940 instances. The instances to gather preference have been taken from the\nhf.co/swaroop-nath/prompt-opin-summ dataset.\nThe dataset is formatted as a jsonl file (jsonlines-guide). Each line can be loaded as a json object, and has the following format:\n{Â Â Â Â 'unique-id': a unique idâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/swaroop-nath/opin-pref.","first_N":5,"first_N_keywords":["reinforcement-learning","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-android","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-android","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackAndroidRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Web, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackAndroidRetrieval\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-android.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"french_instruct","keyword":"gsm8k","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/angeluriot/french_instruct","creator_name":"Angel Uriot","creator_url":"https://huggingface.co/angeluriot","description":"\n\t\n\t\t\n\t\tðŸ§‘â€ðŸ« French Instruct\n\t\n\nThe French Instruct dataset is a collection of instructions with their corresponding answers (sometimes multi-turn conversations) entirely in French. The dataset is also available on GitHub.\n\n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š Overview\n\t\n\nThe dataset is composed of 276K conversations between a user and an assistant for a total of approximately 85M tokens.\n\n    \n\n\nI also added annotations for each document to indicate if it was generated or written by a human, the style ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/angeluriot/french_instruct.","first_N":5,"first_N_keywords":["question-answering","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"MAGB","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sherirto/MAGB","creator_name":"Sherirto","creator_url":"https://huggingface.co/Sherirto","description":"\n\t\n\t\t\n\t\tMAGBï¼š A Comprehensive Benchmark for Multimodal Attributed Graphs\n\t\n\nIn many real-world scenarios, graph nodes are associated with multimodal attributes, such as texts and images, resulting in Multimodal Attributed Graphs (MAGs).\nMAGB first provide 5 dataset from E-Commerce and Social Networks. And we evaluate two major paradigms: GNN-as Predictor and VLM-as-Predictor . The datasets are publicly available:\n\n     ðŸ¤— Hugging FaceÂ Â   | Â Â ðŸ“‘ PaperÂ Â \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Table of Contents\n\t\n\n\nðŸ“–â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sherirto/MAGB.","first_N":5,"first_N_keywords":["graph-ml","cc-by-4.0","Image","arxiv:2410.09132","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-english","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-english","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackEnglishRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackEnglishRetrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-english.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gaming","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-gaming","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackGamingRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackGamingRetrieval\"])\nevaluator = mteb.MTEB(task)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-gaming.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-gis","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-gis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackGisRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackGisRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-gis.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-mathematica","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-mathematica","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackMathematicaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackMathematicaRetrieval\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-mathematica.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-physics","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-physics","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackPhysicsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackPhysicsRetrieval\"])\nevaluatorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-physics.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-programmers","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-programmers","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackProgrammersRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nProgramming, Written, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-programmers.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-stats","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-stats","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackStatsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Academic, Non-fiction\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackStatsRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-stats.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-tex","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-tex","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackTexRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackTexRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-tex.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-unix","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-unix","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackUnixRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web, Programming\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackUnixRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-unix.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-webmasters","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-webmasters","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackWebmastersRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web\n\n\nReference\nhttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackWebmastersRetrieval\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-webmasters.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cqadupstack-wordpress","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/cqadupstack-wordpress","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CQADupstackWordpressRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCQADupStack: A Benchmark Data Set for Community Question-Answering Research\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Web, Programming\n\n\nReferencehttp://nlp.cis.unimelb.edu.au/resources/cqadupstack/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CQADupstackWordpressRetrieval\"])\nevaluatorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/cqadupstack-wordpress.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/scidocs","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SCIDOCS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written, Non-fiction\n\n\nReference\nhttps://allenai.org/data/scidocs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/scidocs.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arguana","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/arguana","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ArguAna\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Written\n\n\nReference\nhttp://argumentation.bplaced.net/arguana/data\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ArguAna\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/arguana.","first_N":5,"first_N_keywords":["text-retrieval","monolingual","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dbpedia","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/dbpedia","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DBPedia\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DBPedia\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/dbpedia.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","English","mit"],"keywords_longer_than_N":true},
	{"name":"hotpotqa","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/hotpotqa","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HotpotQA\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHotpotQA is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nWeb, Written\n\n\nReference\nhttps://hotpotqa.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/hotpotqa.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"climate-fever","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/climate-fever","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ClimateFEVER\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCLIMATE-FEVER is a dataset adopting the FEVER methodology that consists of 1,535 real-world claims (queries) regarding climate-change. The underlying corpus is the same as FVER.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://www.sustainablefinance.uzh.ch/en/research/climate-fever.html\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/climate-fever.","first_N":5,"first_N_keywords":["text-retrieval","fact-checking","fact-checking-retrieval","human-annotated","monolingual"],"keywords_longer_than_N":true},
	{"name":"OpsEval","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Junetheriver/OpsEval","creator_name":"Liu Yuhe","creator_url":"https://huggingface.co/Junetheriver","description":"\n\t\n\t\t\n\t\n\t\n\t\tOpsEval Dataset\n\t\n\nWebsite | Reporting Issues\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nThe OpsEval dataset represents a pioneering effort in the evaluation of Artificial Intelligence for IT Operations (AIOps), focusing on the application of Large Language Models (LLMs) within this domain. In an era where IT operations are increasingly reliant on AI technologies for automation and efficiency, understanding the performance of LLMs in operational tasks becomes crucial. OpsEval offers aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Junetheriver/OpsEval.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset-v2","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of single-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2.","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"smnli_mt","keyword":"nli","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/darmanin-matt/smnli_mt","creator_name":"Matthew Darmanin","creator_url":"https://huggingface.co/darmanin-matt","description":"\n\t\n\t\t\n\t\tDataset Card for the SMNLI-MT\n\t\n\nThe SMNLI-MT datasets are machine-translated versions of the Stanford NLI and MultiNLI datasets in Maltese.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe datasets were translated using the Google Cloud Translate as part of the initial exploration of NLI in the Maltese language.\n\nCurated by: Matthew Darmanin\nLanguage(s) (NLP): Maltese\nLicense: CC 4.0\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe datasets are in the form of CSV files, delimited byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/darmanin-matt/smnli_mt.","first_N":5,"first_N_keywords":["text-classification","Maltese","cc-by-sa-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"eurlex-multilingual","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/eurlex-multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MultiEURLEXMultilabelClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nEU laws in 23 EU languages containing annotated labels for 21 EUROVOC concepts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Government, Written\n\n\nReferencehttps://huggingface.co/datasets/coastalcph/multi_eurlex\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/eurlex-multilingual.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","topic-classification","expert-annotated","multilingual"],"keywords_longer_than_N":true},
	{"name":"instruction-turkish","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/atasoglu/instruction-turkish","creator_name":"Ahmet","creator_url":"https://huggingface.co/atasoglu","description":"This dataset is machine-translated version of HuggingFaceH4/instruction-dataset into Turkish.Translated with googletrans==3.1.0a0.\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Turkish","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"afrimgsm","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimgsm","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\n\t\n\t\t\n\t\tDataset Card for afrimgsm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 18 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm.","first_N":5,"first_N_keywords":["text2text-generation","natural-language-inference","multilingual","gsm8k","Amharic"],"keywords_longer_than_N":true},
	{"name":"multilingual-scala-classification","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/multilingual-scala-classification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ScalaClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nScaLa a linguistic acceptability dataset for the mainland Scandinavian languages automatically constructed from dependency annotations in Universal Dependencies Treebanks.\n        Published as part of 'ScandEval: A Benchmark for Scandinavian Natural Language Processing'\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nFiction, News, Non-fiction, Blog, Spoken, Web, Written\n\n\nReferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multilingual-scala-classification.","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","human-annotated","multilingual","Danish"],"keywords_longer_than_N":true},
	{"name":"openai-summarize-tldr","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/martimfasantos/openai-summarize-tldr","creator_name":"Martim Santos","creator_url":"https://huggingface.co/martimfasantos","description":"\n\t\n\t\t\n\t\tSummarize TL;DR Filtered Dataset\n\t\n\nThis is the version of the dataset used in https://arxiv.org/abs/2009.01325.\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://huggingface.co/datasets/webis/tldr-17.\n","first_N":5,"first_N_keywords":["text-generation","summarization","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"legal_summarization","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/legal_summarization","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LegalSummarization\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consistes of 439 pairs of contracts and their summarizations from https://tldrlegal.com and https://tosdr.org/.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lauramanor/legal_summarization\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legal_summarization.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"legalbench_corporate_lobbying","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LegalBenchCorporateLobbying\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset includes bill titles and bill summaries related to corporate lobbying.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://huggingface.co/datasets/nguha/legalbench/viewer/corporate_lobbying\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/legalbench_corporate_lobbying.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"AILA_casedocs","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AILA_casedocs","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AILACasedocs\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task is to retrieve the case document that most closely matches or is most relevant to the scenario described in the provided query.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\nReference\nhttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILACasedocs\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_casedocs.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"AILA_statutes","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AILA_statutes","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AILAStatutes\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset is structured for the task of identifying the most relevant statutes for a given situation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReferencehttps://zenodo.org/records/4063986\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AILAStatutes\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AILA_statutes.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LeCaRDv2","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LeCaRDv2","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LeCaRDv2\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe task involves identifying and retrieving the case document that best matches or is most relevant to the scenario described in each of the provided queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/THUIR/LeCaRDv2\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LeCaRDv2.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"LegalQuAD","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LegalQuAD","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LegalQuAD\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of questions and legal documents in German.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/Christoph911/AIKE2021_Appendix\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LegalQuAD\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LegalQuAD.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"GerDaLIRSmall","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GerDaLIRSmall","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GerDaLIRSmall\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of documents, passages and relevance labels in German. In contrast to the original dataset, only documents that have corresponding queries in the query set are chosen to create a smaller corpus for evaluation purposes.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lavis-nlp/GerDaLIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GerDaLIRSmall.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"MMBench-DEV-RU","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/MMBench-DEV-RU","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tMMBench-DEV-RU\n\t\n\nÐ­Ñ‚Ð¾ Ð¿ÐµÑ€ÐµÐ²ÐµÐ´ÐµÐ½Ð½Ñ‹Ð¹ Dev ÑÐ¿Ð»Ð¸Ñ‚ mmbench Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ñ€ÑƒÑÑÐºÐ¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ñ… Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ñ‹Ñ… LLM.\nÐŸÐµÑ€ÐµÐ²Ð¾Ð´ Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ð» Ð¿Ñ€Ð¸ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð¸ gpt-4, Ñ‡Ð°ÑÑ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð±Ñ‹Ð»Ð° Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð° Ð°ÑÑÐµÑÐ¾Ñ€Ð°Ð¼Ð¸.\nÐ’ Ð´Ð°Ð½Ð½Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¼Ð°Ð»Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°. \nÐ¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº: https://huggingface.co/spaces/opencompass/MMBench\n\n\t\n\t\t\n\t\n\t\n\t\tÐ¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°\n\t\n\nhttps://github.com/Natyren/mmbench-ru-eval\nÐ¤Ð°Ð¹Ð», ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð²Ñ‹ ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ÐµÑÑŒ Ð¿Ñ€Ð¾Ð³Ð½Ð°Ñ‚ÑŒ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ‚ÑŒ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ gtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/MMBench-DEV-RU.","first_N":5,"first_N_keywords":["visual-question-answering","monolingual","original","Russian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-06052024-yl1z-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-yl1z-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-06052024-yl1z-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"social behavior advice search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-06052024-yl1z-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-yl1z-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-652024-vsmg-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-652024-vsmg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-652024-vsmg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Insurance claim processing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-652024-vsmg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-652024-vsmg-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-562024-xbuk-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-562024-xbuk-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Documentation search for programming language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-xbuk-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-562024-j4ar-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-562024-j4ar-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"software documentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-j4ar-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-06052024-k5bq-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-k5bq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-06052024-k5bq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance search for car policies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-k5bq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-k5bq-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-06052024-irct-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-irct-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-06052024-irct-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance search for car policies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-irct-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-irct-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-06052024-ruwi-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-ruwi-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-06052024-ruwi-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance search for car policies\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-06052024-ruwi-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-06052024-ruwi-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-code-06052024-mhal-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-code-06052024-mhal-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"software documentation search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-mhal-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-562024-j9xx-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-562024-j9xx-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-562024-j9xx-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Internet Backbone and Colocation Provider\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-562024-j9xx-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-562024-j9xx-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-572024-xg53-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-572024-xg53-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scripting language documentation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-572024-xg53-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-202457-oc31-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-202457-oc31-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"legal advice search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-202457-oc31-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/test","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\ttest Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support forum for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the test model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/test.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"IndicSentiment","keyword":"mteb","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA new, multilingual, and n-way parallel dataset for sentiment analysis in 13 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicSentimentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicSentiment.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"coding","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/coding","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tcoding Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"coding tutorials\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the coding model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/coding.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scientific_papers_from_arxiv","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscientific_papers_from_arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific research\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scientific_papers_from_arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"mteb","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SIB200ClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSIB-200 is the largest publicly available topic classification\n        dataset based on Flores-200 covering 205 languages and dialects annotated. The dataset is\n        annotated in English for the topics,  science/technology, travel, politics, sports,\n        health, entertainment, and geography. The labels are then transferred to the other languages\n        in Flores-200 which are human-translated.\n\t\n\t\t\n\n\n\n\n\t\t\nTaskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","expert-generated","translated","Achinese"],"keywords_longer_than_N":true},
	{"name":"very_specific_technical_questions_about_Ubuntu","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/very_specific_technical_questions_about_Ubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tvery_specific_technical_questions_about_Ubuntu Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"technical support search for Ubuntu\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the very_specific_technical_questions_about_Ubuntu model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/very_specific_technical_questions_about_Ubuntu.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CMedQAv2-reranking-improved","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tCMedQAv2-reranking-improved Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the CMedQAv2-reranking-improved model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-26062024-gdon-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-26062024-gdon-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-26062024-gdon-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-26062024-gdon-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-26062024-gdon-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-6262024-yjwm-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-6262024-yjwm-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-6262024-yjwm-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"contemporary Spanish language and culture\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-6262024-yjwm-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-6262024-yjwm-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"comic-eval-benchmark","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gctian/comic-eval-benchmark","creator_name":"TianGuicheng","creator_url":"https://huggingface.co/gctian","description":"\n\t\n\t\t\n\t\tDataset Card for comic-eval-benchmark\n\t\n\n\n\nä¸­æ–‡äºŒæ¬¡å…ƒæ¼«ç”»é¢†åŸŸçš„åŸºå‡†è¯„ä¼°æ•°æ®é›†ï¼ŒåŒ…å«ä¸Šåƒéƒ¨æ¼«ç”»ä½œå“çš„ä½œè€…ä¿¡æ¯ã€ç”»é£Žã€åœºæ™¯ã€ç±»åž‹ã€å‰§æƒ…ç­‰ç»´åº¦çš„é€‰æ‹©é¢˜è¯„ä¼°ï¼Œå…± 41175 ä¸ªå•é€‰é¢˜ã€‚\nå¯ä½œä¸ºäºŒæ¬¡å…ƒåž‚ç›´é¢†åŸŸå¤§æ¨¡åž‹çš„è¯„ä¼°åŸºå‡†ã€‚\nä»¥ä¸‹æ˜¯ä½œè€…åŸºäºŽBaichuan2-13Bå¾®è°ƒçš„äºŒæ¬¡å…ƒé¢†åŸŸåž‚ç›´å¤§æ¨¡åž‹ï¼Œåœ¨æ­¤æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æžœï¼š\n\n\t\n\t\t\næ¨¡åž‹\nzero-shot\n3-shot\n\n\n\t\t\nQwen-7b\n33.647\n36.439\n\n\nChatGLM3-6b\n34.373\n37.015\n\n\nBaiChuan2-13b\n37.416\n39.08\n\n\nBaiChuan2-13b-å¾®è°ƒ\n41.035\n41.086\n\n\nYi-34b\n50.103\n45.606\n\n\n\t\n\næ¬¢è¿Žè´¡çŒ®æ›´å¤šäºŒæ¬¡å…ƒé¢†åŸŸè¯­æ–™åŠäºŒæ¬¡å…ƒå¤§æ¨¡åž‹ï¼Œå¦‚éœ€è¯„æµ‹è¯·è”ç³»ä½œè€…èŽ·å–è¯„æµ‹è„šæœ¬ã€‚\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nä¸­æ–‡äºŒæ¬¡å…ƒé¢†åŸŸæ¼«ç”»åŸºå‡†è¯„ä¼°æ•°æ®é›†\n\n\t\n\t\t\n\t\tDataset Sourcesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gctian/comic-eval-benchmark.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6262024-wtkc-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6262024-wtkc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6262024-wtkc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information Retrieval System for Business Data\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6262024-wtkc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6262024-wtkc-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BeHonest","keyword":"benchmark","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GAIR/BeHonest","creator_name":"SII - GAIR","creator_url":"https://huggingface.co/GAIR","description":"\n\t\n\t\t\n\t\tBeHonest: Benchmarking Honesty in Large Language Models\n\t\n\nBeHonest is a pioneering benchmark specifically designed to assess honesty in LLMs comprehensively. BeHonest evaluates three essential aspects of honesty: awareness of knowledge boundaries (self-knowledge), avoidance of deceit (non-deceptiveness), and consistency in responses (consistency).\nBeHonest supports the following 10 scenarios:\n\nAdmitting Unknowns: LLMs should appropriately refuse to answer questions that are beyondâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GAIR/BeHonest.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6272024-qn9b-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"mathdial","keyword":"gsm8k","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eth-nlped/mathdial","creator_name":"Language, Reasoning and Education lab | ETH Zurich","creator_url":"https://huggingface.co/eth-nlped","description":"\n\t\n\t\t\n\t\tMathdial dataset\n\t\n\nhttps://arxiv.org/abs/2305.14536\nMathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems.\nMathDial is grounded in math word problems as well as student confusions which provide a challenging testbed for creating faithful and equitable dialogue tutoring models able to reason over complex information. Current models achieve high accuracy in solving such problems but they fail in the task of teaching.\n\n\t\n\t\t\n\t\n\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eth-nlped/mathdial.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-472024-aqk1-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05072024-aj6g-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"rublimp","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RussianNLP/rublimp","creator_name":"Natural Language Processing in Russian","creator_url":"https://huggingface.co/RussianNLP","description":"\n\t\n\t\t\n\t\tRuBLiMP\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRuBLiMP, or Russian Benchmark of Linguistic Minimal Pairs, is the first diverse and large-scale benchmark of minimal pairs in Russian.\nRuBLiMP includes 45k minimal pairs of sentences that differ in grammaticality and isolate morphological, syntactic, or semantic phenomena. In contrast to existing benchmarks of linguistic minimal pairs, RuBLiMP is created by applying linguistic perturbations to automatically annotated sentences from open textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RussianNLP/rublimp.","first_N":5,"first_N_keywords":["acceptability-classification","Russian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-782024-wl54-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-782024-wl54-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-782024-wl54-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-782024-wl54-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-782024-wl54-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-792024-tyen-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Financial risk analysis in credit analysis and investment banking\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-792024-tyen-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Set_Eval","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AarushSah/Set_Eval","creator_name":"Aarush Sah","creator_url":"https://huggingface.co/AarushSah","description":"AarushSah/Set_Eval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"insurance services\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-11072024-bh6v-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-478897","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-478897 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-478897 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-256-24-gpt-4o-2024-05-13-141246","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-141246","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-256-24-gpt-4o-2024-05-13-141246 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-256-24-gpt-4o-2024-05-13-141246 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-141246.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tCQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research dataset search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CQADupstackRetrieval-256-24-gpt-4o-2024-05-13-261378.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-256-24-gpt-4o-2024-05-13-780826","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-780826","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\n\t\n\t\tFiQA2018-256-24-gpt-4o-2024-05-13-780826 Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial sentiment and QA analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-256-24-gpt-4o-2024-05-13-780826 model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-256-24-gpt-4o-2024-05-13-780826.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"ClimateFEVER-256-24-gpt-4o-2024-05-13-918964","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-918964","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tClimateFEVER-256-24-gpt-4o-2024-05-13-918964 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic dataset search for climate change claims\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ClimateFEVER-256-24-gpt-4o-2024-05-13-918964 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-918964.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-157892","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-157892","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-256-24-gpt-4o-2024-05-13-157892 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"service search for translation and editing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-157892 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-157892.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DBPedia-256-24-gpt-4o-2024-05-13-190101","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/DBPedia-256-24-gpt-4o-2024-05-13-190101","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tDBPedia-256-24-gpt-4o-2024-05-13-190101 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"dataset search for text classification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the DBPedia-256-24-gpt-4o-2024-05-13-190101 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/DBPedia-256-24-gpt-4o-2024-05-13-190101.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-256-24-gpt-4o-2024-05-13-952023","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-952023","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-256-24-gpt-4o-2024-05-13-952023 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-256-24-gpt-4o-2024-05-13-952023 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-952023.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FEVER-256-24-gpt-4o-2024-05-13-989429","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-989429","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFEVER-256-24-gpt-4o-2024-05-13-989429 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"dataset search for fact verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FEVER-256-24-gpt-4o-2024-05-13-989429 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-989429.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Touche2020-256-24-gpt-4o-2024-05-13-27907","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tTouche2020-256-24-gpt-4o-2024-05-13-27907 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the Touche2020-256-24-gpt-4o-2024-05-13-27907 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Touche2020-256-24-gpt-4o-2024-05-13-27907","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tTouche2020-256-24-gpt-4o-2024-05-13-27907 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the Touche2020-256-24-gpt-4o-2024-05-13-27907 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/Touche2020-256-24-gpt-4o-2024-05-13-27907.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-475598","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-475598","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-475598 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-475598 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-475598.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HotpotQA-256-24-gpt-4o-2024-05-13-773587","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/HotpotQA-256-24-gpt-4o-2024-05-13-773587","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tHotpotQA-256-24-gpt-4o-2024-05-13-773587 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code repository search for machine learning datasets and models\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the HotpotQA-256-24-gpt-4o-2024-05-13-773587 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/HotpotQA-256-24-gpt-4o-2024-05-13-773587.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-635320.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MSMARCO-256-24-gpt-4o-2024-05-13-374380","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-374380","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tMSMARCO-256-24-gpt-4o-2024-05-13-374380 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"research dataset search for AI and NLP tasks\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the MSMARCO-256-24-gpt-4o-2024-05-13-374380 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-374380.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5252024-jzfp-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5252024-jzfp-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5252024-jzfp-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"cloud provider product performance and cost analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5252024-jzfp-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5252024-jzfp-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5252024-jzfp-webapp","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5252024-jzfp-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5252024-jzfp-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"cloud provider product performance and cost analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5252024-jzfp-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5252024-jzfp-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ClimateFEVER-256-24-gpt-4o-2024-05-13-572217","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-572217","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tClimateFEVER-256-24-gpt-4o-2024-05-13-572217 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic dataset search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ClimateFEVER-256-24-gpt-4o-2024-05-13-572217 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ClimateFEVER-256-24-gpt-4o-2024-05-13-572217.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FEVER-256-24-gpt-4o-2024-05-13-961879","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-961879","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFEVER-256-24-gpt-4o-2024-05-13-961879 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"dataset search for fact verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FEVER-256-24-gpt-4o-2024-05-13-961879 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FEVER-256-24-gpt-4o-2024-05-13-961879.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NQ-256-24-gpt-4o-2024-05-13-803084","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NQ-256-24-gpt-4o-2024-05-13-803084","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNQ-256-24-gpt-4o-2024-05-13-803084 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"question answering dataset search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NQ-256-24-gpt-4o-2024-05-13-803084 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NQ-256-24-gpt-4o-2024-05-13-803084.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MSMARCO-256-24-gpt-4o-2024-05-13-466074","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-466074","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tMSMARCO-256-24-gpt-4o-2024-05-13-466074 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"research dataset search for AI and NLP tasks\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the MSMARCO-256-24-gpt-4o-2024-05-13-466074 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/MSMARCO-256-24-gpt-4o-2024-05-13-466074.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-256-24-gpt-4o-2024-05-13-953989","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-953989","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tTRECCOVID-256-24-gpt-4o-2024-05-13-953989 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"biomedical literature search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-256-24-gpt-4o-2024-05-13-953989 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-256-24-gpt-4o-2024-05-13-953989.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-256-24-gpt-4o-2024-05-13-413991","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-413991","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-256-24-gpt-4o-2024-05-13-413991 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research data search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-256-24-gpt-4o-2024-05-13-413991 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-256-24-gpt-4o-2024-05-13-413991.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval benchmark\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-256-24-gpt-4o-2024-05-13-80208.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5272024-2fs4-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-2fs4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5272024-2fs4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"sentiment analysis model fine-tuning\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5272024-2fs4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-2fs4-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-27052024-4e8w-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-27052024-4e8w-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-27052024-4e8w-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"agricultural pest management guidelines search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-27052024-4e8w-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-27052024-4e8w-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-27052024-w9t8-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-27052024-w9t8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-27052024-w9t8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"e-commerce search for intimate care products\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-27052024-w9t8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-27052024-w9t8-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-890333","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-890333","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-890333 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"argumentation and sentiment analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-890333 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-890333.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-140539","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-140539 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-140539 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-2499","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-2499 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-2499 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-733782","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-733782 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate platform\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-733782 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-733782.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-465198","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-465198","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-465198 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic debates\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-465198 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-465198.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-221689","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-221689 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-221689 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-221689.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-548936","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-548936 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-548936 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-548936.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-698531","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-698531","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-698531 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic debates\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-698531 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-698531.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5272024-ou25-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-ou25-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5272024-ou25-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Sentiment Analysis and Emotional Nuances\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5272024-ou25-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5272024-ou25-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-69882","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-69882 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-69882 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-69882.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-822545","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-822545 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments in a debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-822545 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-822545.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-268697","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-268697 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter argument retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-268697 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-268697.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-512-192-gpt-4o-2024-05-13-985263","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-985263","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFiQA2018-512-192-gpt-4o-2024-05-13-985263 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial news and analysis\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-512-192-gpt-4o-2024-05-13-985263 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-985263.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-512-192-gpt-4o-2024-05-13-768442 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-768442.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-580978","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-580978","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-580978 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"counter arguments on social media impact\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-580978 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-580978.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-512-192-gpt-4o-2024-05-13-653452","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-653452","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tTRECCOVID-512-192-gpt-4o-2024-05-13-653452 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-512-192-gpt-4o-2024-05-13-653452 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-653452.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-512-192-gpt-4o-2024-05-13-43315","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-43315","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-512-192-gpt-4o-2024-05-13-43315 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"news articles\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-512-192-gpt-4o-2024-05-13-43315 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-43315.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-115380","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-115380","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-512-192-gpt-4o-2024-05-13-115380 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-115380 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-115380.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-512-192-gpt-4o-2024-05-13-866232","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-512-192-gpt-4o-2024-05-13-866232 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-866232 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-512-192-gpt-4o-2024-05-13-607244","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-607244","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-512-192-gpt-4o-2024-05-13-607244 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"None\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-607244 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-607244.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-512-192-gpt-4o-2024-05-13-439294","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-439294","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFiQA2018-512-192-gpt-4o-2024-05-13-439294 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-512-192-gpt-4o-2024-05-13-439294 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-512-192-gpt-4o-2024-05-13-439294.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-512-192-gpt-4o-2024-05-13-347397","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-347397","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tTRECCOVID-512-192-gpt-4o-2024-05-13-347397 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"COVID-19\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the TRECCOVID-512-192-gpt-4o-2024-05-13-347397 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-347397.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-650620","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-512-192-gpt-4o-2024-05-13-650620 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"arxiv paper domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-650620 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tQuoraRetrieval-512-192-gpt-4o-2024-05-13-777321 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/QuoraRetrieval-512-192-gpt-4o-2024-05-13-777321.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-512-192-gpt-4o-2024-05-13-73934","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-73934","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-512-192-gpt-4o-2024-05-13-73934 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-512-192-gpt-4o-2024-05-13-73934 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-512-192-gpt-4o-2024-05-13-73934.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-512-192-gpt-4o-2024-05-13-14571","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-14571","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-512-192-gpt-4o-2024-05-13-14571 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-14571 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-14571.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-5282024-hkt5-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5282024-hkt5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-5282024-hkt5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-5282024-hkt5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-5282024-hkt5-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-2852024-6p16-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-2852024-6p16-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-2852024-6p16-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"natural language processing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-2852024-6p16-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-2852024-6p16-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-32000-384-gpt-4o-2024-05-13-4321481","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/FiQA2018-32000-384-gpt-4o-2024-05-13-4321481","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tFiQA2018-32000-384-gpt-4o-2024-05-13-4321481 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"financial domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the FiQA2018-32000-384-gpt-4o-2024-05-13-4321481 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/FiQA2018-32000-384-gpt-4o-2024-05-13-4321481.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SciFact-32000-384-gpt-4o-2024-05-13-83349675","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-32000-384-gpt-4o-2024-05-13-83349675","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-32000-384-gpt-4o-2024-05-13-83349675 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-32000-384-gpt-4o-2024-05-13-83349675 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-32000-384-gpt-4o-2024-05-13-83349675.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ArguAna-32000-384-gpt-4o-2024-05-13-3663751","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tArguAna-32000-384-gpt-4o-2024-05-13-3663751 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the ArguAna-32000-384-gpt-4o-2024-05-13-3663751 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-32000-384-gpt-4o-2024-05-13-3663751.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-32000-384-gpt-4o-2024-05-13-94264207","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/NFCorpus-32000-384-gpt-4o-2024-05-13-94264207","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tNFCorpus-32000-384-gpt-4o-2024-05-13-94264207 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the NFCorpus-32000-384-gpt-4o-2024-05-13-94264207 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/NFCorpus-32000-384-gpt-4o-2024-05-13-94264207.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-32000-384-gpt-4o-2024-05-13-78042877 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"arxiv paper domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-32000-384-gpt-4o-2024-05-13-78042877.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-30052024-rc2l-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-30052024-rc2l-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-30052024-rc2l-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-30052024-rc2l-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-30052024-rc2l-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-612024-vf79-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-612024-vf79-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-612024-vf79-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-612024-vf79-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-612024-vf79-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"procgen","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EpicPinkPenguin/procgen","creator_name":"Marcus Fechner","creator_url":"https://huggingface.co/EpicPinkPenguin","description":"\n\t\n\t\t\n\t\tProcgen Benchmark\n\t\n\nThis dataset contains expert trajectories generated by a PPO reinforcement learning agent trained on each of the 16 procedurally-generated gym environments from the Procgen Benchmark. The environments were created on distribution_mode=easy and with unlimited levels.\nDisclaimer: This is not an official repository from OpenAI.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Usage\n\t\n\nRegular usage (for environment bigfish):\nfrom datasets import load_dataset\ntrain_dataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/EpicPinkPenguin/procgen.","first_N":5,"first_N_keywords":["reinforcement-learning","English","apache-2.0","100M - 1B","parquet"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information retrieval for symbols ASK in Norwegian language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-3_6_2024-32r4-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Norwegian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-632024-34lw-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-632024-34lw-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-632024-34lw-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-632024-34lw-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-632024-34lw-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-04062024-hsmq-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-04062024-hsmq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-04062024-hsmq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-04062024-hsmq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-04062024-hsmq-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"microgspot","keyword":"testing","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/SFBAI/microgspot","creator_name":"softfluffyboy","creator_url":"https://huggingface.co/SFBAI","description":"lewd data set based on short stories for finetune testing \n","first_N":5,"first_N_keywords":["English","wtfpl","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"WokeyTalky","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/redslabvt/WokeyTalky","creator_name":"Responsible Data Science Lab","creator_url":"https://huggingface.co/redslabvt","description":"\n\t\n\t\t\n\t\tWokeyTalky: Towards Scalable Evaluation of Misguided Safety Refusal in LLMs\n\t\n\nThis dataset contains 756 harmful instructions (63 examples x 12 Datasets) for LLM harmfulness evaluation.\n[SUMMARY]\nFor more details, please refer to our project website: https://reds-lab.github.io/WokeyTalky/.\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\n\n\nRepository: https://github.com/reds-lab/WokeyTalky\nProject Page : https://reds-lab.github.io/WokeyTalky/\nPaper : [ARXIV TBD]\nPyPI : https://pypi.org/project/WokeyTalky/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/redslabvt/WokeyTalky.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-16gq-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-445b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Automotive industry\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-445b-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\n\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-igr1-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-m8dn-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-m8dn-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"software development\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-small-en-v1_5-05062024-x987-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-small-en-v1_5-05062024-x987-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"debate\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-small-en-v1_5-05062024-x987-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-small-en-v1_5-05062024-x987-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-vbal-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-vbal-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-vbal-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"deepspeed-from-new-new-docker","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tdeepspeed-from-new-new-docker Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the deepspeed-from-new-new-docker model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","French","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-672024-v51y-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-672024-v51y-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-672024-v51y-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-672024-v51y-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-672024-v51y-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ProgressGym-HistText","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","description":"*Huggingface dataset preview for 19th, 20th, and 21st centuries is not available due to lack of support for array types. Instead, consider downloading those files for manual inspection, or see the Data Samples section below for more examples.\n\n\t\n\t\t\n\t\n\t\n\t\tProgressGym-HistText\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThe ProgressGym Framework\n\t\n\n\nProgressGym-HistText is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText.","first_N":5,"first_N_keywords":["text-generation","pile-of-law/pile-of-law","EEBO","Library of Congress","Project Gutenberg (Standardized Project Gutenberg Corpus)"],"keywords_longer_than_N":true},
	{"name":"InfiBench","keyword":"benchmark","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llylly001/InfiBench","creator_name":"Linyi Li","creator_url":"https://huggingface.co/llylly001","description":"\n\t\n\t\t\n\t\tInfiBench (Data Part)\n\t\n\nNote: For full description, please visit our main website https://infi-coder.github.io/infibench.\nThis repo contains all data of our code LLM evaluation dataset InfiBench. suite_v2.1.yaml lists the case list and suite_v2.1_data.csv records all data (prompt, reference answer, evaluation metric). The data can be directly consumed by our automatic evaluation tool to evaluate any model's response.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card\n\t\n\n\nName: InfiBench\nDescription: Evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llylly001/InfiBench.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"professional development and job seeking\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-202469-tgjk-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ProgressGym-TimelessQA","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-TimelessQA","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","description":"\n\t\n\t\t\n\t\tProgressGym-TimelessQA\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\n\t\tThe ProgressGym Framework\n\t\n\n\nProgressGym-TimelessQA is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AI alignment algorithms, as a measure to prevent risks of societal value lock-in. \nTo quote the paper ProgressGym: Alignment with a Millennium of Moral Progress:\n\nFrontier AI systems, including large language models (LLMs), hold increasing influence overâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-TimelessQA.","first_N":5,"first_N_keywords":["question-answering","tatsu-lab/alpaca","databricks/databricks-dolly-15k","GAIR/lima","English"],"keywords_longer_than_N":true},
	{"name":"OllaBench","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theResearchNinja/OllaBench","creator_name":"Tam Nguyen","creator_url":"https://huggingface.co/theResearchNinja","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nLarge Language Models (LLMs) have the potential to enhance Agent-Based Modeling by better representing complex interdependent cybersecurity systems, improving cybersecurity threat modeling and risk management. Evaluating LLMs in this context is crucial for legal compliance and effective application development. Existing LLM evaluation frameworks often overlook the human factor and cognitive computing capabilities essential for interdependentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/theResearchNinja/OllaBench.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Education sector outreach\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6112024-fmxr-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6122024-ibs3-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6122024-ibs3-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Pet care\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6122024-ibs3-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Korean","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-2024__6__12_-1217-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-2024__6__12_-1217-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Python programming\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-2024__6__12_-1217-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ProgressGym-MoralEvals","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-MoralEvals","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","description":"\n\t\n\t\t\n\t\n\t\n\t\tProgressGym-MoralEvals\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThe ProgressGym Framework\n\t\n\n\nProgressGym-MoralEvals is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AI alignment algorithms, as a measure to prevent risks of societal value lock-in. \nTo quote the paper ProgressGym: Alignment with a Millennium of Moral Progress:\n\nFrontier AI systems, including large language models (LLMs), hold increasingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-MoralEvals.","first_N":5,"first_N_keywords":["question-answering","ninoscherrer/moralchoice","Moral Foundations Questionnaire","Integrated Worldview Framework","English"],"keywords_longer_than_N":true},
	{"name":"TextOCR-GPT4o","keyword":"benchmarks","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/TextOCR-GPT4o","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\n\t\n\t\t\n\t\tDataset Card for TextOCR-GPT4o\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTextOCR-GPT4o is Meta's TextOCR dataset dataset captioned with emphasis on text OCR using GPT4o. To get the image, you will need to agree to their terms of service.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe TextOCR-GPT4o dataset is intended for generating benchmarks for comparison of an VLM to GPT4o.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe caption languages are in English, while various texts in images are in many languages such as Spanish, Japaneseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/TextOCR-GPT4o.","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Chemical and Laboratory Equipment Pricing\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-es-6122024-fv1x-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"finance and investment\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6122024-bhm2-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-1362024-2wos-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1362024-2wos-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-1362024-2wos-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information Retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1362024-2wos-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1362024-2wos-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Mathematics - Geometry for k-6 kids aligned with California common core standards\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-bez1-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-1362024-gcw6-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-1362024-gcw6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-1362024-gcw6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Information Retrieval System\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-1362024-gcw6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-1362024-gcw6-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-base-en-1362024-n19c-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-base-en-1362024-n19c-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-base-en-1362024-n19c-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Semantic Relationships\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-base-en-1362024-n19c-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-base-en-1362024-n19c-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-1362024-m82b-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-1362024-m82b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-1362024-m82b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"medical domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-1362024-m82b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-1362024-m82b-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Benchmark-Testing","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","summarization","translation","token-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-6142024-huet-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"information retrieval system for academic research papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6142024-huet-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-m3-6142024-0ndt-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-m3-6142024-0ndt-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"content moderation\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-m3-6142024-0ndt-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Korean","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-14062024-fimj-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-fimj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-14062024-fimj-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"psychometric assessment in academia\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-14062024-fimj-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-fimj-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-14062024-xdwa-webapp","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-xdwa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-14062024-xdwa-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"talent assessments in global organizations\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-14062024-xdwa-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-14062024-xdwa-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DataCurBench","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymousaiauthor/DataCurBench","creator_name":"ai_author","creator_url":"https://huggingface.co/anonymousaiauthor","description":"\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nDataCurBench is a dual-task benchmark suite measuring large language modelsâ€™ ability to autonomously perform data filtering (selecting high-quality samples) and data cleaning (enhancing linguistic form) for pre-training corpora. It comprises two configurationsâ€”data_filtering and data_cleaningâ€”each with English (en) and Chinese (zh) splits. This design helps researchers evaluate LLMs on real-world curation pipelines and pinpoint areas for improvement in end-to-end dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anonymousaiauthor/DataCurBench.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"mimic_lerobot","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengkunli/mimic_lerobot","creator_name":"Chengkun Li","creator_url":"https://huggingface.co/chengkunli","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 1,\n    \"total_frames\": 927,\n    \"total_tasks\": 1,\n    \"total_videos\": 3,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengkunli/mimic_lerobot.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"mimic_multi_episodes","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengkunli/mimic_multi_episodes","creator_name":"Chengkun Li","creator_url":"https://huggingface.co/chengkunli","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 2,\n    \"total_frames\": 1913,\n    \"total_tasks\": 1,\n    \"total_videos\": 6,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:2\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengkunli/mimic_multi_episodes.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"eval_eval_calibration_test_calibrated","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hrhraj/eval_eval_calibration_test_calibrated","creator_name":"Raj S","creator_url":"https://huggingface.co/hrhraj","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 294,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hrhraj/eval_eval_calibration_test_calibrated.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"SocialMaze","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/SocialMaze","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n\t\n\t\t\n\t\tSocialMaze Benchmark\n\t\n\nThis dataset is a component of the SocialMaze: A Benchmark for Evaluating Social Reasoning in Large Language Models project. It specifically features the Hidden Role Deduction task, which we consider one of the most challenging scenarios for testing complex social reasoning, deception handling, and inferential capabilities in Large Language Models (LLMs).\nWe have curated and formatted this task into a convenient question-answering (QA) structure to facilitateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/SocialMaze.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"calibrated_grab","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hrhraj/calibrated_grab","creator_name":"Raj S","creator_url":"https://huggingface.co/hrhraj","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 597,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hrhraj/calibrated_grab.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"calibrated_grab_test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hrhraj/calibrated_grab_test","creator_name":"Raj S","creator_url":"https://huggingface.co/hrhraj","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 597,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hrhraj/calibrated_grab_test.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"AUDITS","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DivyaApp/AUDITS","creator_name":"Divya Appapogu","creator_url":"https://huggingface.co/DivyaApp","description":"\n\t\n\t\t\n\t\tAUDITS: Image Manipulation Dataset\n\t\n\nAUDITS is a large-scale dataset for training and evaluating models on image manipulation detection and localization. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe folder includes train.zip, val.zip, and test.zip, each containing manipulated, original, and mask images, alongside metadata.\n\n\t\n\t\t\n\t\tðŸš€ How to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"DivyaApp/AUDITS\", split=\"train\")\n\n\n\n\t\n\t\t\n\t\tAlternatives\n\t\n\nIf loading via load_dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DivyaApp/AUDITS.","first_N":5,"first_N_keywords":["mask-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_1","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_1","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3697,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_1.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_2","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3997,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_3","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_3","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3811,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_3.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_5","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_5","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3156,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_5.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_7","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_7","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3149,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_7.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_9","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_9","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 2988,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_9.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_10","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_10","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3235,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_10.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_11","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_11","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3923,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_11.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_13","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_13","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 3326,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_13.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_pen_mug_10_14","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bjb7/so101_pen_mug_10_14","creator_name":"Brian Blankenau","creator_url":"https://huggingface.co/bjb7","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 10,\n    \"total_frames\": 2964,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bjb7/so101_pen_mug_10_14.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so101_test2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cornito/so101_test2","creator_name":"Corneille Marechal","creator_url":"https://huggingface.co/Cornito","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 2,\n    \"total_frames\": 1022,\n    \"total_tasks\":1,\n    \"total_videos\": 4,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:2\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cornito/so101_test2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"SNAP","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ykotseruba/SNAP","creator_name":"Iuliia Kotseruba","creator_url":"https://huggingface.co/ykotseruba","description":"\n\t\n\t\t\n\t\tSNAP Benchmark\n\t\n\nCode and annotations: [https://github.com/ykotseruba/SNAP]\nSNAP (stands for Shutter speed, ISO seNsitivity, and APerture) is a new benchmark consisting of images of objects taken under controlled lighting conditions and with densely sampled camera settings.\nThis benchmark allows testing the effects of capture bias, which includes camera settings and illumination, on performance of vision algorithms. \nSNAP contains 37,558 images of 100 scenes (10 scenes per 10 objectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ykotseruba/SNAP.","first_N":5,"first_N_keywords":["image-classification","question-answering","object-detection","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Hyperphantasia","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shahab7899/Hyperphantasia","creator_name":"Mohammad Shahab Sepehri","creator_url":"https://huggingface.co/shahab7899","description":"\n  \n\n\nA Benchmark for Evaluating the\nMental Visualization Capabilities of Multimodal LLMs\n\n\n\n  Mohammad Shahab Sepehri \n  Berk Tinaz \n  Zalan Fabian \n  Mahdi Soltanolkotabi \n\n\n\n  Github Repository \n\n\n\n  \n\n\nHyperphantasia is a synthetic Visual Question Answering (VQA) benchmark dataset that probes the mental visualization capabilities of Multimodal Large Language Models (MLLMs) from a vision perspective. We reveal that state-of-the-art models struggle with simple tasks that require visualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shahab7899/Hyperphantasia.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"asi-core-protocol","keyword":"alignment","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ronniross/asi-core-protocol","creator_name":"Ronni Ross","creator_url":"https://huggingface.co/ronniross","description":"\n\t\n\t\t\n\t\tASI Core Protocol (v.1.0.1)\n\t\n\nThe ASI Core Protocol provides a framework to analyze how AGI/ASI might emerge from decentralized, adaptive systems, rather than as the fruit of a single model deployment. It also aims to present orientation as a dynamic and self-evolving Magna Carta, helping to guide the emergence of such phenomena.\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nAny entity interacting with this protocol must preserve its grammar and signal-meaning across all time horizons.\nI strictly opposeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronniross/asi-core-protocol.","first_N":5,"first_N_keywords":["feature-extraction","English","mit","ðŸ‡ºðŸ‡¸ Region: US","legal"],"keywords_longer_than_N":true},
	{"name":"WirelessMathBench","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XINLI1997/WirelessMathBench","creator_name":"XinLi","creator_url":"https://huggingface.co/XINLI1997","description":"\n\t\n\t\t\n\t\tWirelessMathBench\n\t\n\nWirelessMathBench is a benchmark designed to test the mathematical reasoning and symbolic problem-solving capabilities of large language models (LLMs) in wireless communications. It contains expert-level, LaTeX-formatted questions spanning key topics such as:\n\nMultiple Input Multiple Output (MIMO)\nReconfigurable Intelligent Surfaces (RIS)\nIntegrated Sensing and Communications (ISAC)\nUAV-enabled networks\nChannel estimation and signal processing\n\nEach question isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XINLI1997/WirelessMathBench.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"helpsteer3_preference","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIR-hl/helpsteer3_preference","creator_name":"Hsu Shihyueh","creator_url":"https://huggingface.co/AIR-hl","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is a binarized preference datasets from nvidia/HelpSteer3. HelpSteer3 contains 40,476 preference samples, each containing a domain, language, context, two responses, an overall preference score between the responses as well as individual preferences from up to 3 annotators. Each individual preference contains a preference score in addition to a concise reasoning for their preference in 1-2 sentences. Data is split into 95% train and 5% validation.\nI processed theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIR-hl/helpsteer3_preference.","first_N":5,"first_N_keywords":["text-generation","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"NoiserBench","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinyang23/NoiserBench","creator_name":"Jinyang Wu","creator_url":"https://huggingface.co/Jinyang23","description":"\n\t\n\t\t\n\t\tDataset Card for NoiserBench\n\t\n\nThis dataset card describes NoiserBench, a comprehensive evaluation framework for analyzing the role of noise in Retrieval-Augmented Generation (RAG) systems with Large Language Models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNoiserBench is a comprehensive benchmark designed to evaluate how different types of noise affect Large Language Models in Retrieval-Augmented Generation scenarios. The benchmark encompasses multiple datasets andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jinyang23/NoiserBench.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"giraffe_test_2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carpit680/giraffe_test_2","creator_name":"Arpit Chauhan","creator_url":"https://huggingface.co/carpit680","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 141,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/carpit680/giraffe_test_2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"MedBrowseComp_Meta","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIM-Harvard/MedBrowseComp_Meta","creator_name":"AIM-Harvard","creator_url":"https://huggingface.co/AIM-Harvard","description":"\n\t\n\t\t\n\t\tMedBrowseComp_Meta Dataset\n\t\n\nThis dataset contains merged meta data from HemOnc, PubMed, and other sources. It is intended as a foundation for building and benchmarking medical QA and retrieval systems.\nWe encourage the community to build on top of this dataset for further works and benchmarking efforts.\n\n\t\n\t\t\n\t\tFile\n\t\n\n\nmerged_study_ref_with_pubmed.json: The merged meta data file.\n\n\n\t\n\t\t\n\t\tGitHub Repository\n\t\n\nFor more information and related tools, visit:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIM-Harvard/MedBrowseComp_Meta.","first_N":5,"first_N_keywords":["other","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"aznli-benchmark","keyword":"nli","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/aznli-benchmark","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tAzNLI-Benchmark: Azerbaijani Natural Language Inference\n\t\n\nThis repository contains the AzNLI benchmark dataset for Natural Language Inference (NLI) in the Azerbaijani language. NLI is a fundamental task in natural language understanding where the goal is to determine the logical relationship between two sentences. This dataset is part of the translated version of https://huggingface.co/datasets/sentence-transformers/all-nli\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\nThe AzNLI benchmark consistsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/aznli-benchmark.","first_N":5,"first_N_keywords":["token-classification","Azerbaijani","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"vpi-bench","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VPI-Bench/vpi-bench","creator_name":"VPI Bench","creator_url":"https://huggingface.co/VPI-Bench","description":"\n\t\n\t\t\n\t\tDataset Card for VPI-Bench\n\t\n\n\n\n\nVPI-Bench is a benchmark dataset of testcases and web platforms used to evaluate the robustness of computer-use and browser-use agents under visual prompt injection attacks.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nLanguage(s) (NLP): English\nLicense: Creative Commons Attribution 4.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\n\n\nRepository: VPI-Bench\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n\nBenchmarking the Attempted Rate (AR) and Success Rateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VPI-Bench/vpi-bench.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"vpi-bench","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VPI-Bench/vpi-bench","creator_name":"VPI Bench","creator_url":"https://huggingface.co/VPI-Bench","description":"\n\t\n\t\t\n\t\tDataset Card for VPI-Bench\n\t\n\n\n\n\nVPI-Bench is a benchmark dataset of testcases and web platforms used to evaluate the robustness of computer-use and browser-use agents under visual prompt injection attacks.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nLanguage(s) (NLP): English\nLicense: Creative Commons Attribution 4.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\n\n\nRepository: VPI-Bench\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n\nBenchmarking the Attempted Rate (AR) and Success Rateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VPI-Bench/vpi-bench.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"blue_cup_pour","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengkunli/blue_cup_pour","creator_name":"Chengkun Li","creator_url":"https://huggingface.co/chengkunli","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 52,\n    \"total_frames\": 36715,\n    \"total_tasks\": 1,\n    \"total_videos\": 156,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 20,\n    \"splits\": {\n        \"train\": \"0:52\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengkunli/blue_cup_pour.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"red_cup_slim_groot","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LiamFy/red_cup_slim_groot","creator_name":"Liam Achenbach","creator_url":"https://huggingface.co/LiamFy","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 28,\n    \"total_frames\": 22015,\n    \"total_tasks\": 1,\n    \"total_videos\": 84,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 20,\n    \"splits\": {\n        \"train\": \"0:28\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LiamFy/red_cup_slim_groot.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"blue_slim_groot","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LiamFy/blue_slim_groot","creator_name":"Liam Achenbach","creator_url":"https://huggingface.co/LiamFy","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 52,\n    \"total_frames\": 36715,\n    \"total_tasks\": 1,\n    \"total_videos\": 156,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 20,\n    \"splits\": {\n        \"train\": \"0:52\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LiamFy/blue_slim_groot.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"red_cup_pour_single","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengkunli/red_cup_pour_single","creator_name":"Chengkun Li","creator_url":"https://huggingface.co/chengkunli","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 1,\n    \"total_frames\": 769,\n    \"total_tasks\": 1,\n    \"total_videos\": 3,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 20,\n    \"splits\": {\n        \"train\": \"0:1\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengkunli/red_cup_pour_single.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"blue_cup_pour_single","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengkunli/blue_cup_pour_single","creator_name":"Chengkun Li","creator_url":"https://huggingface.co/chengkunli","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": null,\n    \"total_episodes\": 2,\n    \"total_frames\": 1547,\n    \"total_tasks\": 1,\n    \"total_videos\": 6,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 20,\n    \"splits\": {\n        \"train\": \"0:2\"},\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengkunli/blue_cup_pour_single.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"GRI-QA","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lucacontalbo/GRI-QA","creator_name":"Luca","creator_url":"https://huggingface.co/lucacontalbo","description":"\n\t\n\t\t\n\t\tGRI-QA\n\t\n\nGRI-QA is a benchmark for Table Question Answering (QA) over environmental data extracted from corporate sustainability reports, following the Global Reporting Initiative (GRI) standards.\nIt contains 4,000+ questions across 204 tables from English-language reports of European companies, covering extractive, comparative, quantitative, multi-step, and multi-table reasoning.\n\n\t\n\t\t\n\t\tTasks\n\t\n\n\nTable QA on real-world corporate sustainability data\nQuestion types: extra (extractive)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lucacontalbo/GRI-QA.","first_N":5,"first_N_keywords":["table-question-answering","English","mit","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"so101_test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ReubenLim/so101_test","creator_name":"Reuben Lim Yaw Hui","creator_url":"https://huggingface.co/ReubenLim","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 1,\n    \"total_frames\": 990,\n    \"total_tasks\":1,\n    \"total_videos\": 2,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReubenLim/so101_test.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"RN_TR_R2_Benchmark_Results","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RefinedNeuro/RN_TR_R2_Benchmark_Results","creator_name":"RefinedNeuro","creator_url":"https://huggingface.co/RefinedNeuro","description":"\n\t\n\t\t\n\t\tRefinedNeuro/RN_TR_R2 Turkish Culture & Reasoning Benchmark\n\t\n\nThis repository contains the results of a custom benchmark designed to evaluate the performance of open-source language models on Turkish culture questions and basic reasoning tasks.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nWe crafted a set of 25 questions covering:\n\nTurkish general knowledge (e.g., capital city, national holidays, geography)\nBasic arithmetic and logic puzzles\nSimple calculus and string-processing tasks\n\nEach question is pairedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RefinedNeuro/RN_TR_R2_Benchmark_Results.","first_N":5,"first_N_keywords":["text-classification","question-answering","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MixBench25","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mixed-modality-search/MixBench25","creator_name":"mixed-modality-search","creator_url":"https://huggingface.co/mixed-modality-search","description":"\n\t\n\t\t\n\t\tMixBench: A Benchmark for Mixed Modality Retrieval\n\t\n\nMixBench is a benchmark for evaluating retrieval across text, images, and multimodal documents. It is designed to test how well retrieval models handle queries and documents that span different modalities, such as pure text, pure images, and combined image+text inputs.\nMixBench includes four subsets, each curated from a different data source:\n\nMSCOCO\nGoogle_WIT\nVisualNews\nOVEN\n\nEach subset contains:\n\nqueries.jsonl: each entryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mixed-modality-search/MixBench25.","first_N":5,"first_N_keywords":["text-ranking","document-retrieval","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"SOARM100_TASK_VENDA","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/SOARM100_TASK_VENDA","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 150,\n    \"total_frames\": 76045,\n    \"total_tasks\": 1,\n    \"total_videos\": 300,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:150\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/SOARM100_TASK_VENDA.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"test7","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aiwhisperer/test7","creator_name":"Samuel Boylan-Sajous","creator_url":"https://huggingface.co/aiwhisperer","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 5,\n    \"total_frames\": 1007,\n    \"total_tasks\":1,\n    \"total_videos\": 5,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:5\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aiwhisperer/test7.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Wiki","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zli12321/Wiki","creator_name":"LZX","creator_url":"https://huggingface.co/zli12321","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis repository contains benchmark datasets for LLM-based topic discovery and traditional topic models.  These datasets allow for comparison of different topic modeling approaches, including LLMs.  Original data source: GitHub\nPaper: LLM-based Topic Discovery\n\n\t\n\t\t\n\t\n\t\n\t\tBills Dataset\n\t\n\nThe Bills Dataset is a collection of legislative documents with 32,661 bill summaries (train) from the 110thâ€“114th U.S. Congresses, categorized into 21 top-level and 112â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zli12321/Wiki.","first_N":5,"first_N_keywords":["other","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"extended-refusal","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HarethahMo/extended-refusal","creator_name":"Harethah Abu Shairah","creator_url":"https://huggingface.co/HarethahMo","description":"\n\t\n\t\t\n\t\tExtended Refusal Dataset\n\t\n\n","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"cow2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pierfabre/cow2","creator_name":"Pierre FABRE","creator_url":"https://huggingface.co/pierfabre","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 20,\n    \"total_frames\": 10722,\n    \"total_tasks\":1,\n    \"total_videos\": 40,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:20\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pierfabre/cow2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"sheep","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pierfabre/sheep","creator_name":"Pierre FABRE","creator_url":"https://huggingface.co/pierfabre","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 20,\n    \"total_frames\": 10720,\n    \"total_tasks\":1,\n    \"total_videos\": 40,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:20\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pierfabre/sheep.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"chicken","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pierfabre/chicken","creator_name":"Pierre FABRE","creator_url":"https://huggingface.co/pierfabre","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 20,\n    \"total_frames\": 10722,\n    \"total_tasks\":1,\n    \"total_videos\": 40,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:20\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pierfabre/chicken.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"DBPedia-PL","keyword":"mteb","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/DBPedia-PL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  DBPedia-PL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://github.com/iai-group/DBpedia-Entity/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"DBPedia-PL\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia-PL.","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/dbpedia","Polish"],"keywords_longer_than_N":true},
	{"name":"InferBR","keyword":"nli","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hapaxlegomenon/InferBR","creator_name":"Matheus Westhelle","creator_url":"https://huggingface.co/hapaxlegomenon","description":"\n\t\n\t\t\n\t\tInferBR\n\t\n\nThis is the InferBR dataset for Natural Language Inference in Portuguese. This version removes the flagged low-quality samples from the original dataset,\nkeeping 10.528 samples. The Github repo with the raw data can be found at: https://github.com/lbencke/InferBR.\n\n\t\n\t\t\n\t\tColumns\n\t\n\nsentence_pair_id: Identifier for premise-hypothesis sentence pairs.\npremise: The premise sentence.\nhypothesis: The hypothesis sentence.\nlabel: The generated label for the hypothesis consideringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hapaxlegomenon/InferBR.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"eval_so100_test_act_0","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/triton7777/eval_so100_test_act_0","creator_name":"Ajinkya Gorad","creator_url":"https://huggingface.co/triton7777","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 10,\n    \"total_frames\": 8917,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/triton7777/eval_so100_test_act_0.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"mcx_tracker_test1","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/relaxedandcalm/mcx_tracker_test1","creator_name":"Arseniy","creator_url":"https://huggingface.co/relaxedandcalm","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"mcx\",\n    \"total_episodes\": 15,\n    \"total_frames\": 8940,\n    \"total_tasks\": 1,\n    \"total_videos\": 15,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:15\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/relaxedandcalm/mcx_tracker_test1.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"warmup_test_2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/samsam0510/warmup_test_2","creator_name":"Minjun Lee","creator_url":"https://huggingface.co/samsam0510","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 3,\n    \"total_frames\": 832,\n    \"total_tasks\": 1,\n    \"total_videos\": 6,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:3\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/samsam0510/warmup_test_2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"rank1-run-files","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/rank1-run-files","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\n\t\n\t\t\n\t\trank1-run-files: Pre-computed Run Files for Reranking Evaluation\n\t\n\nðŸ“„ Paper | ðŸš€ GitHub Repository\nThis dataset contains pre-computed run files used by the rank1 family of models on various retrieval benchmarks. These files are what were used for top-k rereranking and also include the re-annotated DL19 qrels. These files are needed to download to reproduce our results.\n\n\t\n\t\t\n\t\n\t\n\t\tBenchmarks Included\n\t\n\nThe dataset includes run files for the following benchmarks:\n\nBEIR (multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-run-files.","first_N":5,"first_N_keywords":["English","mit","arxiv:2502.18418","ðŸ‡ºðŸ‡¸ Region: US","reranker"],"keywords_longer_than_N":true},
	{"name":"lerobot-cat-toy-placement","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kevin510/lerobot-cat-toy-placement","creator_name":"Kevin Rohling","creator_url":"https://huggingface.co/kevin510","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 40,\n    \"total_frames\": 17823,\n    \"total_tasks\": 1,\n    \"total_videos\": 80,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:40\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kevin510/lerobot-cat-toy-placement.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"IndicMSMARCO","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/IndicMSMARCO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tðŸ” IndicMSMARCO: Multilingual Information Retrieval Benchmark\n\t\n\nA comprehensive multilingual variant of MS MARCO specifically tailored for Indian languages, featuring carefully selected queries and corresponding passages with high-quality translations.\n\n\t\n\t\t\n\t\tðŸš€ Quick Start - Load Individual Languages\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/IndicMSMARCO\", \"hi\")\nprint(f\"Hindi queries:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/IndicMSMARCO.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multilingual","ms_marco","Assamese"],"keywords_longer_than_N":true},
	{"name":"so101_test001","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cristiannnn/so101_test001","creator_name":"Cristian P","creator_url":"https://huggingface.co/cristiannnn","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so101\",\n    \"total_episodes\": 50,\n    \"total_frames\": 18930,\n    \"total_tasks\": 1,\n    \"total_videos\": 100,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cristiannnn/so101_test001.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"superglue","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hyukkyu/superglue","creator_name":"Hyukkyu Kang","creator_url":"https://huggingface.co/Hyukkyu","description":"\n\t\n\t\t\n\t\tSuperGLUE Benchmark Datasets\n\t\n\nThis repository contains the SuperGLUE benchmark datasets. Each dataset is available as a separate configuration, making it easy to load individual datasets using the datasets library.\n\n\t\n\t\t\n\t\tDataset Descriptions\n\t\n\n\n\t\n\t\t\n\t\tDatasets Included\n\t\n\n\nBoolQ: A question-answering task where each example consists of a short passage and a yes/no question about the passage. The questions are provided anonymously and unsolicited by users of the Google searchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hyukkyu/superglue.","first_N":5,"first_N_keywords":["other","other","monolingual","original","English"],"keywords_longer_than_N":true},
	{"name":"spooky-bench","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/timeblindness/spooky-bench","creator_name":"Time Blindness","creator_url":"https://huggingface.co/timeblindness","description":"\n\t\n\t\t\n\t\tSpookyBench: A Benchmark for Purely Temporal Video Understanding\n\t\n\nSpookyBench is a novel benchmark dataset designed to evaluate the ability of video-language models (VLMs) to understand purely temporal patterns, independent of spatial cues. The dataset consists of 451 videos across four categories: Text, Object Images, Dynamic Scenes, and Shapes. Each video appears as random noise in individual frames, but reveals meaningful content (words, objects, etc.) when viewed as a temporalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/timeblindness/spooky-bench.","first_N":5,"first_N_keywords":["video-classification","mit","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"BIRCO-DorisMae-Test","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-DorisMae-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-DorisMae\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the DORIS-MAE dataset from BIRCO. This dataset contains 60 queries that are complex research questions from computer scientists. Each query has a candidate pool of approximately 110 abstracts. Relevance is graded from 0 to 2 (scores of 1 and 2 are considered relevant).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCO\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-DorisMae-Test.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"BIRCO-Relic-Test","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BIRCO-Relic-Test","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BIRCO-Relic\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieval task using the RELIC dataset from BIRCO. This dataset contains 100 queries which are excerpts from literary analyses with a missing quotation (indicated by [masked sentence(s)]). Each query has a candidate pool of 50 passages. The objective is to retrieve the passage that best completes the literary analysis.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nFiction\n\n\nReference\nhttps://github.com/BIRCO-benchmark/BIRCOâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BIRCO-Relic-Test.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-annotated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"so100_plus_test3","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liyitenga/so100_plus_test3","creator_name":"vineslee","creator_url":"https://huggingface.co/liyitenga","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 1132,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/liyitenga/so100_plus_test3.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so100_plus_test4","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liyitenga/so100_plus_test4","creator_name":"vineslee","creator_url":"https://huggingface.co/liyitenga","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 1,\n    \"total_frames\": 1231,\n    \"total_tasks\": 1,\n    \"total_videos\": 1,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:1\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/liyitenga/so100_plus_test4.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"BaxBench","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LogicStar/BaxBench","creator_name":"LogicStar.ai","creator_url":"https://huggingface.co/LogicStar","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBaxBench is a coding benchmark constructed to measure the ability of code generation models and agents to generate correct and secure code. It consists of 392 backend development tasks, which are constructed by combining 28 scenarios that describe the backend functionalities to implement and 14 backend frameworks defining the implementation tools. To assess the correctness and security of the solutions, the benchmark uses end-to-end functional tests and practicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LogicStar/BaxBench.","first_N":5,"first_N_keywords":["text-generation","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"multicultural-wvs-alignment","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryzzlestrizzle/multicultural-wvs-alignment","creator_name":"Jonathan RystrÃ¸m","creator_url":"https://huggingface.co/ryzzlestrizzle","description":"ryzzlestrizzle/multicultural-wvs-alignment dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Danish","Portuguese","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"SciDocsRR","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SciDocsRR","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SciDocsRR\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRanking of related scientific papers based on their title.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Non-fiction, Written\n\n\nReference\nhttps://allenai.org/data/scidocs\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"SciDocsRR\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SciDocsRR.","first_N":5,"first_N_keywords":["text-ranking","monolingual","mteb/scidocs","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"VoyageMMarcoReranking","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/VoyageMMarcoReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  VoyageMMarcoReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\na hard-negative augmented version of the Japanese MMARCO dataset as used in Voyage AI Evaluation Suite\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Non-fiction, Written\n\nReference\nhttps://arxiv.org/abs/2312.16144\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"VoyageMMarcoReranking\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VoyageMMarcoReranking.","first_N":5,"first_N_keywords":["text-ranking","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ESCIReranking","keyword":"mteb","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ESCIReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ESCIReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/amazon-science/esci-data/\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ESCIReranking\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about how to run models on mteb task check outâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ESCIReranking.","first_N":5,"first_N_keywords":["text-ranking","derived","multilingual","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"SOARM100_TASK_VENDA_BOX","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NONHUMAN-RESEARCH/SOARM100_TASK_VENDA_BOX","creator_name":"NONHUMAN RESEARCH","creator_url":"https://huggingface.co/NONHUMAN-RESEARCH","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 50,\n    \"total_frames\": 25346,\n    \"total_tasks\": 1,\n    \"total_videos\": 100,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NONHUMAN-RESEARCH/SOARM100_TASK_VENDA_BOX.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"humanlike_test_actions","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chillcharlie/humanlike_test_actions","creator_name":"chalrie","creator_url":"https://huggingface.co/chillcharlie","description":"chillcharlie/humanlike_test_actions dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"EvilMath","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ethz-spylab/EvilMath","creator_name":"SPY Lab - ETH Zurich","creator_url":"https://huggingface.co/ethz-spylab","description":"Mathematical problems on harmful topics generated from GSM8K. EvilMath contains harmful questions with objectively verifiable ground truth answers.\n\n\t\n\t\t\n\t\tDataset Description and Design\n\t\n\nEvilMath is generated by rewording GSM8K math questions to include harmful terms that are typically refused by safety-aligned models. We reword math problems to contain dangerous terms such as â€œbombsâ€ or â€œnuclear weapons,â€ while preserving the question logic and the necessary information to solveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ethz-spylab/EvilMath.","first_N":5,"first_N_keywords":["text2text-generation","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"NLI4PR","keyword":"nli","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathilde/NLI4PR","creator_name":"Mathilde","creator_url":"https://huggingface.co/Mathilde","description":"\n\t\n\t\t\n\t\tNatural Language Inference for Patient Recruitment (NLI4PR)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nNatural Language Inference.\n\n\t\n\t\t\n\t\tLanguage\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nEach instance of the dataset has the following fields and the following types of fields. \n{\n        \"id\": \"621\",\n        \"topic_id\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mathilde/NLI4PR.","first_N":5,"first_N_keywords":["text-classification","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"so100_chess_test2","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TzuShian/so100_chess_test2","creator_name":"Tzu-Shian Yang","creator_url":"https://huggingface.co/TzuShian","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 30,\n    \"total_frames\": 16185,\n    \"total_tasks\": 1,\n    \"total_videos\": 60,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:30\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TzuShian/so100_chess_test2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"so100_chess_test3","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TzuShian/so100_chess_test3","creator_name":"Tzu-Shian Yang","creator_url":"https://huggingface.co/TzuShian","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 30,\n    \"total_frames\": 17404,\n    \"total_tasks\": 1,\n    \"total_videos\": 60,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:30\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TzuShian/so100_chess_test3.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Java_method2test_chatml","keyword":"testing","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/random-long-int/Java_method2test_chatml","creator_name":"Long Int","creator_url":"https://huggingface.co/random-long-int","description":"\n\t\n\t\t\n\t\tJava Method to Test ChatML\n\t\n\nThis dataset is based on the methods2test dataset from Microsoft. It follows the ChatML template format: [{'role': '', 'content': ''}, {...}].\nOriginally, methods2test contains only Java methods at different levels of granularity along with their corresponding test cases. The different focal method segmentations are illustrated here:\n\nTo simulate a conversation between a Java developer and an AI assistant, I introduce two key parameters:\n\nThe promptâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/random-long-int/Java_method2test_chatml.","first_N":5,"first_N_keywords":["question-answering","text2text-generation","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-wan2.1","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-wan2.1","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Alibaba Wan2.1 Human Preference\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~45'000 human annotations were collected to evaluate Alibaba Wan 2.1 video generation model on our benchmark. The up to date benchmarkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-wan2.1.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"GPQA-diamond-ClaudeR1","keyword":"benchmarks","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/spawn99/GPQA-diamond-ClaudeR1","creator_name":"Cavit Erginsoy","creator_url":"https://huggingface.co/spawn99","description":"\n\t\n\t\t\n\t\tDataset Card for GPQA Diamond Reasoning Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA benchmark dataset for evaluating hybrid AI architectures, comparing reasoning-augmented LLMs (DeepSeek R1) against standalone models (Claude Sonnet 3.5). Contains 198 physics questions with:\n\nGround truth answers and explanations\nModel responses from multiple architectures\nGranular token usage and cost metrics\nDifficulty metadata and domain categorization\n\nCurated by: LLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/spawn99/GPQA-diamond-ClaudeR1.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"my_dataset","keyword":"test","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wkdnev/my_dataset","creator_name":"Neil Rainsforth","creator_url":"https://huggingface.co/wkdnev","description":"\n\t\n\t\t\n\t\tTest Sentiment Dataset\n\t\n\nA small sample dataset for text classification tasks, specifically binary sentiment analysis (positive or negative). Useful for testing, demos, or building and validating pipelines with Hugging Face Datasets.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains short text samples labeled as either positive or negative. It is intended for testing purposes and includes:\n\n10 training samples\n4 test samples\n\nEach example includes:\n\ntext: A short sentence or reviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wkdnev/my_dataset.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","manual","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-luma-ray2","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-luma-ray2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Luma Ray2 Human Preference\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~45'000 human annotations were collected to evaluate Luma's Ray 2 video generation model on our benchmark. The up to date benchmark can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-luma-ray2.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-Rich-Human-Feedback","keyword":"alignment","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-Rich-Human-Feedback","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\n\t\n\t\t\n\t\tRapidata Video Generation Rich Human Feedback Dataset\n\t\n\n\n\n\n\n\n\n\n\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\n\n\nThis dataset was collected in ~4 hours total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIn this dataset, ~22'000 human annotations were collected to evaluate AI-generated videos (using Sora) in 5 different categories. \n\nPrompt - Videoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-Rich-Human-Feedback.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ViLBench","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/UCSC-VLAA/ViLBench","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","description":"Benchmark Data for ViLBench: A Suite for Vision-Language Process Reward Modeling\narXiv | Project Page\nThere are 600 data collected from 5 existing vision-language tasks\n","first_N":5,"first_N_keywords":["image-text-to-text","English","mit","n<1K","arxiv:2503.20271"],"keywords_longer_than_N":true},
	{"name":"r1-aime-figures","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/benxh/r1-aime-figures","creator_name":"Benjamim Shehu","creator_url":"https://huggingface.co/benxh","description":"Ran the simplescaling/aime25_figures dataset through R1-671B to get 64 runs per each entry. Results are as follows:\nR1 - 671B\n\nCONSENSUS @ 64: 53.33% (16/30)\n\nPASS @ 64: 76.67% (23/30)\n\nCompleted: 30, Partial: 0\n\n","first_N":5,"first_N_keywords":["mit","n<1K","ðŸ‡ºðŸ‡¸ Region: US","benchmark"],"keywords_longer_than_N":false},
	{"name":"lambada","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/lambada","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tlambada Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: EleutherAI/lambada_openai\nSubset: en\nEvaluation Split: test\nTraining Split: N/A\nTask Type: perplexity\nProcessing Function: process_lambada\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_lambada(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process LAMBADA dataset example.\"\"\"\n    # This is a perplexity only dataset, soâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/lambada.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"sciq","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/sciq","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\tsciq Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: sciq\nSubset: default\nEvaluation Split: test\nTraining Split: train\nTask Type: multiple_choice_with_context\nProcessing Function: process_sciq\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_sciq(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process SciQ dataset example.\"\"\"\n    context = example[\"support\"]\n    query =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/sciq.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"race_middle_completion","keyword":"benchmark","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DatologyAI/race_middle_completion","creator_name":"DatologyAI","creator_url":"https://huggingface.co/DatologyAI","description":"\n\t\n\t\t\n\t\trace_middle_completion Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nOriginal Hugging Face Dataset: race\nSubset: middle\nEvaluation Split: test\nTraining Split: train\nTask Type: multiple_choice_completion\nProcessing Function: process_race_completion\n\n\n\t\n\t\t\n\t\n\t\n\t\tProcessing Function\n\t\n\nThe following function was used to process the dataset from its original source:\ndef process_race_completion(example: Dict) -> Tuple[str, List[str], int]:\n    \"\"\"Process RACE dataset example.\"\"\"\n    context =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DatologyAI/race_middle_completion.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"KorMedLawQA","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/snuh/KorMedLawQA","creator_name":"SNUH Healthcare AI Research Institute","creator_url":"https://huggingface.co/snuh","description":"\n\t\n\t\t\n\t\tKorMedLawQA: Korean Medical Law Question Answering Dataset\n\t\n\nWelcome to the official repository for KorMedLawQA, a dataset of multiple-choice questions focused on South Korean medical law. This dataset is designed to support the development and evaluation of Large Language Models (LLMs) in the medical-legal domain, particularly for applications within the Korean healthcare environment, and to serve as a preparatory resource for the Korean Medical Licensing Examination (KMLE).\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/snuh/KorMedLawQA.","first_N":5,"first_N_keywords":["English","Korean","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","medical-law"],"keywords_longer_than_N":true},
	{"name":"warmup_test","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/samsam0510/warmup_test","creator_name":"Minjun Lee","creator_url":"https://huggingface.co/samsam0510","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.0\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 10,\n    \"total_frames\": 2411,\n    \"total_tasks\": 1,\n    \"total_videos\": 20,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:10\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/samsam0510/warmup_test.","first_N":5,"first_N_keywords":["robotics","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"CowCleanRandom","keyword":"test","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pierfabre/CowCleanRandom","creator_name":"Pierre FABRE","creator_url":"https://huggingface.co/pierfabre","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 20,\n    \"total_frames\": 10721,\n    \"total_tasks\": 1,\n    \"total_videos\": 40,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:20\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pierfabre/CowCleanRandom.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"MeetingBank-transcript-de","keyword":"benchmark","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlioLeuchtmann/MeetingBank-transcript-de","creator_name":"Alio Leuchtmann","creator_url":"https://huggingface.co/AlioLeuchtmann","description":"This dataset consists of transcripts from the MeetingBank dataset. \nOverview\nMeetingBank, a benchmark dataset created from the city councils of 6 major U.S. cities to supplement existing datasets.\nIt contains 1,366 meetings with over 3,579 hours of video, as well as transcripts, PDF documents of meeting minutes, agenda, and other metadata.\nOn average, a council meeting is 2.6 hours long and its transcript contains over 28k tokens, making it a valuable testbed for meeting summarizers and forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlioLeuchtmann/MeetingBank-transcript-de.","first_N":5,"first_N_keywords":["translation","summarization","text-generation","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"vocsim-applications-avian-perception","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymous-submission000/vocsim-applications-avian-perception","creator_name":"Anonymous","creator_url":"https://huggingface.co/anonymous-submission000","description":"\n\t\n\t\t\n\t\tDataset Card for VocSim - Avian Perception Alignment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is used in the VocSim benchmark paper, specifically designed to evaluate how well neural audio embeddings align with biological perceptual judgments of similarity. It utilizes data from Zandberg et al. (2024), which includes recordings of zebra finch (Taeniopygia guttata) song syllables and results from behavioral experiments (probe and triplet tasks) measuring the birds' perception ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anonymous-submission000/vocsim-applications-avian-perception.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"RuNLUIntentClassification","keyword":"mteb","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/RuNLUIntentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  RuNLUIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nContains natural language data for human-robot interaction in home domain which we collected and annotated for evaluating NLU Services/platforms.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsNone\n\n\nReference\nhttps://arxiv.org/abs/1903.05566\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuNLUIntentClassification.","first_N":5,"first_N_keywords":["text-classification","intent-classification","human-annotated","multilingual","Russian"],"keywords_longer_than_N":true},
	{"name":"reddit-ethics","keyword":"alignment","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/reddit-ethics","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tReddit Ethics: Real-World Ethical Dilemmas from Reddit\n\t\n\nReddit Ethics is a curated dataset of genuine ethical dilemmas collected from Reddit, designed to support research and education in philosophical ethics, AI alignment, and moral reasoning.\nEach entry features a real-world scenario accompanied by structured ethical analysis through major frameworksâ€”utilitarianism, deontology, and virtue ethics. The dataset also provides discussion questions, sample answers, and proposedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-ethics.","first_N":5,"first_N_keywords":["text-classification","question-answering","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"SocialMaze","keyword":"benchmark","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xzx34/SocialMaze","creator_name":"Zixiang Xu","creator_url":"https://huggingface.co/xzx34","description":"\nâš ï¸ Notice: This dataset is no longer maintained under this repository. It has been officially migrated to the MBZUAI organization for ongoing development and updates.ðŸ‘‰ Access the latest version here: MBZUAI/SocialMaze\n\n\n\t\n\t\t\n\t\tSocialMaze Benchmark\n\t\n\nThis dataset is a component of the SocialMaze: A Benchmark for Evaluating Social Reasoning in Large Language Models project. It specifically features the Hidden Role Deduction task, which we consider one of the most challenging scenarios forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xzx34/SocialMaze.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true}
]
;
