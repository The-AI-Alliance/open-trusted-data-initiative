const data_for_modality_vision = 
[
	{"name":"Tuberculosis_Dataset","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset","creator_name":"Zhankai Ye","creator_url":"https://huggingface.co/moukaii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultimodal Dataset of Tuberculosis Patients including CT and Clinical Case Reports\\n\\t\\n\\nZhankai Ye    \\nNetID: zy172\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is curated from the original ‚ÄúThe MultiCaRe Dataset‚Äù to focus on the chest tuberculosis patients. This is a multimodal dataset consisting of lung computed tomography (CT) imaging data and the clinical case records of tuberculosis patients, along with their case keywords, the captions of their CT images, patient_id, gender, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/moukaii/Tuberculosis_Dataset."},
	{"name":"Picklebot-2M","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hbfreed/Picklebot-2M","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\n2.6 million clips of balls and called strikes from MLB games from the 2016 season through the 2023 season.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nThe dataset consists of all listed balls and called strikes from Baseball Savant's Statcast Search from 2016, when their video archives began, through the 2023 season.\\nThis dataset includes the date, type (eg. FF, fourseam fastball), mph, spin rate, pitcher, batter, zone (1-14‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-2M."},
	{"name":"reachy-doing-things","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pollen-robotics/reachy-doing-things","creator_name":"Pollen Robotics","creator_url":"https://huggingface.co/pollen-robotics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReachy Doing Things Dataset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Reachy Doing Things Images Dataset consists of images captured from the perspective of the Reachy humanoid robot. These images were taken during teleoperation sessions, providing a unique view of the environment as perceived by the robot during manipulation tasks. The images were captured with a RGBD camera mounted on the shoulder of the robot.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThis dataset is primarily aimed at testing and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pollen-robotics/reachy-doing-things."},
	{"name":"Picklebot-130K","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hbfreed/Picklebot-130K","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Picklebot130k\\n\\t\\n\\n\\n\\n130 thousand video clips of balls and strikes from MLB games from the 2016 season through the 2023 season.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nThe dataset consists of roughly 130 thousand video clips of balls and strikes in .mp4 format, resized to 224x224 resolution.\\n\\nCurated by: Henry Freed\\nLicense: MIT\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: The original project that this dataset was compiled‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-130K."},
	{"name":"ndl-layout-dataset","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nakamura196/ndl-layout-dataset","creator_name":"Satoru Nakamura","creator_url":"https://huggingface.co/nakamura196","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tndl-lab/layout-data for YOLOv8\\n\\t\\n\\n\\n\\nThis dataset, originally provided by NDL, has been adapted and formatted to be compatible with YOLO (You Only Look Once) for training purposes.\\nhttps://github.com/ndl-lab/layout-dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: Satoru Nakamura\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOut-of-Scope Use\\n\\t\\n\\n\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nakamura196/ndl-layout-dataset."},
	{"name":"unusual-objects-unusual-places_text-image","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zer0int/unusual-objects-unusual-places_text-image","creator_name":"zer0int","creator_url":"https://huggingface.co/zer0int","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t(Un-)usual objects in (un-)usual places\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA small Text-Image dataset to confuse, probe (and improve) SOTA (2024) machine vision models.\\n\\t\\n\\nTo be continued (with further examples added)...\\nExample results from LMSYS ARENA (June 2024):\\n\\n\\n\\n"},
	{"name":"vision-feedback-mix-binarized","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wangclnlp/vision-feedback-mix-binarized","creator_name":"wangchenglong","creator_url":"https://huggingface.co/wangclnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Vision-Feedback-Mix-Binarized\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset aims to provide large-scale vision feedback data. \\nIt is a combination of the following high-quality vision feedback datasets:\\n\\nzhiqings/LLaVA-Human-Preference-10K: 9,422 samples\\nMMInstruction/VLFeedback: 80,258 samples\\nYiyangAiLab/POVID_preference_data_for_VLLMs: 17,184 samples\\nopenbmb/RLHF-V-Dataset: 5,733 samples\\nopenbmb/RLAIF-V-Dataset: 83,132 samples\\n\\nWe also offer a cleaned version in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wangclnlp/vision-feedback-mix-binarized."},
	{"name":"vision-feedback-mix-binarized-cleaned","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wangclnlp/vision-feedback-mix-binarized-cleaned","creator_name":"wangchenglong","creator_url":"https://huggingface.co/wangclnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Vision-Feedback-Mix-Binarized-Cleaned\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset represents a cleaned version on wangclnlp/vision-feedback-mix-binarized.\\nDescriptions of the base datasets, including the data format and the procedure for mixing data, can be found in this link.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOur Methods for Cleaning Vision Feedback Data\\n\\t\\n\\nOur goal is to select vision feedback samples where the preferred outputs are significantly differentiated from the dispreferred‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wangclnlp/vision-feedback-mix-binarized-cleaned."},
	{"name":"Sujet-Vision-QA","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/Sujet-Vision-QA","creator_name":"1-800-Shared-Tasks","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description üìäüîç\\n\\t\\n\\nThe Sujet-Finance-QA-Vision-100k is a comprehensive dataset containing over 100,000 question-answer pairs derived from more than 9,800 financial document images. This dataset is designed to support research and development in the field of financial document analysis and visual question answering.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features:\\n\\t\\n\\n\\nüñºÔ∏è 9,801 unique financial document images\\n‚ùì 107,050 question-answer pairs\\nüá¨üáß English language\\nüìÑ Diverse financial document‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/Sujet-Vision-QA."},
	{"name":"sen12vts","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/links-ads/sen12vts","creator_name":"LINKS - AI, Data & Space","creator_url":"https://huggingface.co/links-ads","description":"\\n\\t\\n\\t\\t\\n\\t\\tSEN12VTS: Sentinel 1 and 2 Vegetation Time-Series Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe SEN12VTS (Sentinel-1 & Sentinel-2 Vegetation Time-Series) dataset has been created to support research on time-series analysis for vegetation indices, specifically targeting NDVI (Normalized Difference Vegetation Index) regression tasks. Recognizing the lack of datasets catering to this specific temporal and spatial need, SEN12VTS was developed to fill the gap with a high-quality, Europe-focused‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/links-ads/sen12vts."},
	{"name":"AI4MARS","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hassanjbara/AI4MARS","creator_name":"Hassan Jbara","creator_url":"https://huggingface.co/hassanjbara","description":"Taken from the kaggle repository here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI4Mars Dataset\\n\\t\\n\\nA dataset for terrain classification on Mars, specifically focused on Curiosity (MSL) rover data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains high-resolution Mars surface images with corresponding semantic segmentation masks for terrain classification.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nimage: Original EDR (Engineering Data Record) images from Mars\\nlabel_mask: Semantic segmentation masks with terrain labels\\nrover_mask:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hassanjbara/AI4MARS."},
	{"name":"home_decoration_objects_images","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntZet/home_decoration_objects_images","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","description":"\\n\\t\\n\\t\\t\\n\\t\\tImage Description Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains 5125 images with their corresponding descriptions in both long and short formats. \\nThe descriptions were generated using the BLIP-large model.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\nTotal images: 5125\\nAverage words in long description: 18.1\\nAverage words in short description: 9.4\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish (en)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach record in the dataset contains:\\n\\nfile_name: Relative path to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AntZet/home_decoration_objects_images."},
	{"name":"men_women_children_wearing_clothes","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntZet/men_women_children_wearing_clothes","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","description":"\\n\\t\\n\\t\\t\\n\\t\\tImage Description Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains 6979 images with their corresponding descriptions in both long and short formats. \\nThe descriptions were generated using the BLIP-large model.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\nTotal images: 6979\\nAverage words in long description: 17.3\\nAverage words in short description: 9.4\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish (en)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach record in the dataset contains:\\n\\nfile_name: Relative path to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AntZet/men_women_children_wearing_clothes."},
	{"name":"clothes_for_men_women_children","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntZet/clothes_for_men_women_children","creator_name":"Ant_Z (AntheZ)","creator_url":"https://huggingface.co/AntZet","description":"\\n\\t\\n\\t\\t\\n\\t\\tImage Description Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains 3082 images with their corresponding descriptions in both long and short formats. \\nThe descriptions were generated using the BLIP-large model.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\nTotal images: 3082\\nAverage words in long description: 17.5\\nAverage words in short description: 8.8\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish (en)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach record in the dataset contains:\\n\\nfile_name: Relative path to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AntZet/clothes_for_men_women_children."},
	{"name":"license-plate-finetuning","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/license-plate-finetuning","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"A formatted, augmented copy of license_plate_object_detection for use with grounding dino training experiments. \\nOriginal license is CC - please attribute author at that dataset address.\\n"},
	{"name":"test1","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mujif/test1","creator_name":"dasf","creator_url":"https://huggingface.co/mujif","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttest\\n\\t\\n\\ntest1\\n"},
	{"name":"BASEPROD","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hassanjbara/BASEPROD","creator_name":"Hassan Jbara","creator_url":"https://huggingface.co/hassanjbara","description":"\\n\\t\\n\\t\\t\\n\\t\\tBASEPROD: The Bardenas SemiDesert Planetary Rover Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBASEPROD is a planetary rover dataset collected in the Bardenas semi-desert in Spain, containing approximately 36,000 synchronized sets of RGB, depth, and thermal images from a Realsense camera and thermal sensor, plus 62,000 additional stereo pairs from a Bumblebee XB3 camera. The dataset was collected using the MaRTA rover (Martian Rover Testbed for Autonomy) developed by ESA, traversing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hassanjbara/BASEPROD."},
	{"name":"TUC-HRI","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SchulzR97/TUC-HRI","creator_name":"Robert Schulz","creator_url":"https://huggingface.co/SchulzR97","description":"\\n\\nUniversity of Technology Chemnitz, Germany\\nDepartment Robotics and Human Machine Interaction\\nAuthor: Robert Schulz\\n\\n\\t\\n\\t\\t\\n\\t\\tTUC-HRI Dataset Card\\n\\t\\n\\nTUC-AR is a small scale action recognition dataset, containing 10(+1) action categories for human machine interaction. This version contains video sequences, stored as images, frame by frame.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nRGB and depth input recorded by Intel RealSense D435 depth camera\\n8 subjects\\n11,031 sequences (train 8,893/ val 2,138)\\n3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SchulzR97/TUC-HRI."},
	{"name":"Facecaption-15M-Embeddings","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFacecaption-15M-Embeddings\\n\\t\\n\\nWe chose about 5M image-text pairs with the highest resolution from Facecaption-15M, extracted the embeddings of the [CLS] Token using the FLIP model, and released them.\\nMore details of Facecaption-15M and FLIP are available at: Facecaption15M and FLIP.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAdditional Information\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe FaceCaption-15M dataset is released by OpenFaceCQUPT and is intended exclusively for research and educational purposes. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings."},
	{"name":"Andrew_Alpha_training_data","keyword":"computer vision","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChristopherMarais/Andrew_Alpha_training_data","creator_name":"Christopher Marais","creator_url":"https://huggingface.co/ChristopherMarais","description":"\\n\\t\\n\\t\\t\\n\\t\\tBark Beetle Grouped Images for AI Classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset comprises high-resolution photographs of bark and ambrosia beetles captured under controlled laboratory conditions. Each image contains multiple beetle specimens arranged on a uniform white background while submerged in 70% ethanol. This approach speeds up data collection and ensures reproducible imaging conditions. Individual beetle images can later be extracted from these grouped photographs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChristopherMarais/Andrew_Alpha_training_data."},
	{"name":"Corneocyte_Nanotexture_Dataset","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jenhung/Corneocyte_Nanotexture_Dataset","creator_name":"Jen-Hung Wang","creator_url":"https://huggingface.co/jenhung","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject Description\\n\\t\\n\\n\\nGitHub: https://github.com/JenHungWang/ECTI_Atopic_Dermatitis\\n\\n"},
	{"name":"digital_signatures","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Benjy/digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDigital Signatures Dataset\\n\\t\\n\\nThis dataset contains unique synthetic digital signatures rendered in different fonts:\\n\\n4,000 synthetic signatures in Rage font\\n\\n4,000 synthetic signatures in Mistral font\\n2,000 synthetic signatures in Arial Unicode font\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nFor the development of models that can detect digital signatures in documentation using the publicly available Docusign¬Æ font styles.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\nThe dataset is organized into three folders:\\n\\nrage/‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Benjy/digital_signatures."},
	{"name":"Signature","keyword":"computer-vision","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ultralytics/Signature","creator_name":"Ultralytics","creator_url":"https://huggingface.co/Ultralytics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSignature Detection Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset focuses on detecting human written signatures within documents. It includes a variety of document types with annotated signatures, providing valuable insights for applications in document verification and fraud detection. Essential for training computer vision algorithms, this dataset aids in identifying signatures in various document formats, supporting research and practical applications in document analysis.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ultralytics/Signature."},
	{"name":"Arabic_captioned_Images","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Daemontatox/Arabic_captioned_Images","creator_name":"Ammar","creator_url":"https://huggingface.co/Daemontatox","description":"\\n\\t\\n\\t\\t\\n\\t\\tALLaVA-4V for Arabic\\n\\t\\n\\nThis is the Arabic version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Arabic through ChatGPT and instructed ChatGPT not to translate content related to OCR.\\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University of Hong‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Daemontatox/Arabic_captioned_Images."},
	{"name":"siglip_400m","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lhbit20010120/siglip_400m","creator_name":"Hao Liang","creator_url":"https://huggingface.co/lhbit20010120","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSigLIP (shape-optimized model)\\n\\t\\n\\nSigLIP model pre-trained on WebLi at resolution 384x384. It was introduced in the paper Sigmoid Loss for Language Image Pre-Training by Zhai et al. and first released in this repository.\\nThis model has the SoViT-400m architecture, which is the shape-optimized version as presented in Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design by Alabdulmohsin et al.\\nDisclaimer: The team releasing SigLIP did not write a model card for this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lhbit20010120/siglip_400m."},
	{"name":"blip3-grounding-50m","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/blip3-grounding-50m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\\n\\t\\n\\t\\t\\n\\t\\tBLIP3-GROUNDING-50M Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe BLIP3-GROUNDING-50M dataset is designed to enhance the ability of Vision-Language Models (VLMs) to ground semantic concepts in visual features, which is crucial for tasks like object detection, semantic segmentation, and understanding referring expressions (e.g., \\\"the object to the left of the dog\\\"). Traditional datasets often lack the necessary granularity for such tasks, making it challenging for models to accurately localize and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-grounding-50m."},
	{"name":"geometric-shapes","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/0-ma/geometric-shapes","creator_name":"Olivier","creator_url":"https://huggingface.co/0-ma","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Geometric Shapes Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Geometric Shapes Dataset is a synthetic dataset containing images of various geometric shapes with superimposed random text. Each image features a polygon (or just text) on a randomly colored background, with a short string of random characters partially obscuring the shape. This dataset is designed for tasks such as shape classification, image recognition, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/0-ma/geometric-shapes."},
	{"name":"PubMedVision-EnKo","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\tInformations\\n\\t\\n\\n\\nThis is the Korean translation of FreedomIntelligence/PubMedVision. The translation was primarily generated using the 'solar-pro-241126' model, with occasional manual assistance from the 'Gemini 2.0 Flash Experimental' model and the 'Gemini experimental 1206' model.\\nAn evaluation of the translation quality (\\\"llm-as-a-judge\\\") will be coming soon.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNews\\n\\t\\n\\n\\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo."},
	{"name":"FaceCaption-15M","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFacaCaption-15M\\n\\t\\n\\n\\n\\nFaceCaption-15M, a large-scale, diverse, and high-quality dataset of facial images accompanied by their natural language descriptions (facial image-to-text). This dataset aims to facilitate a study on face-centered tasks. FaceCaption-15M comprises over 15 million pairs of facial images and their corresponding natural language descriptions of facial features, making it the largest facial image caption dataset to date.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNews and Updates üî•üî•üî•Ôºö‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M."},
	{"name":"fashionpedia","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fashionpedia\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFashionpedia is a dataset mapping out the visual aspects of the fashion world.\\nFrom the paper:\\n\\nFashionpedia is a new dataset which consists of two parts: (1) an ontology built by fashion experts containing 27 main apparel categories, 19 apparel parts, 294 fine-grained attributes and their relationships; (2) a dataset with everyday and celebrity event fashion images annotated with segmentation masks and their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia."},
	{"name":"Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaraAgroAI/Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation","creator_name":"KaraAgro AI Foundation","creator_url":"https://huggingface.co/KaraAgroAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDrone-based Agricultural Dataset for Crop Yield Estimation\\n\\t\\n\\nThis repository contains a comprehensive dataset of cashew, cocoa and coffee images captured by drones, accompanied by meticulously annotated labels. To facilitate object detection, each image is paired with a corresponding text file in YOLO format. The YOLO format file contains annotations, including class labels and bounding box coordinates.\\nThe dataset was collected by teams from Ghana (KaraAgro AI) and Uganda‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaraAgroAI/Drone-based-Agricultural-Dataset-for-Crop-Yield-Estimation."},
	{"name":"TAO-Amodal","keyword":"computer vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal","creator_name":"Cheng-Yen Hsieh","creator_url":"https://huggingface.co/chengyenhsieh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTAO-Amodal Dataset\\n\\t\\n\\n\\n Official Source for Downloading the TAO-Amodal and TAO Dataset.\\n   üìô Project Page  | üíª Code | üìé Paper Link | ‚úèÔ∏è Citations\\n   \\n  \\n   \\n\\n\\n\\nContact: üôãüèª‚Äç‚ôÇÔ∏èCheng-Yen (Wesley) Hsieh\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nOur dataset augments the TAO dataset with amodal bounding box annotations for fully invisible, out-of-frame, and occluded objects. \\nNote that this implies TAO-Amodal also includes modal segmentation masks (as visualized in the color overlays‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal."},
	{"name":"Military-Aircraft-Detection","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","description":"Dataset for object detection of military aircraft\\nbounding box in PASCAL VOC format (xmin, ymin, xmax, ymax)\\n43 aircraft types\\n(A-10, A-400M, AG-600, AV-8B, B-1, B-2, B-52 Be-200, C-130, C-17, C-2, C-5, E-2, E-7, EF-2000, F-117, F-14, F-15, F-16, F/A-18, F-22, F-35, F-4, J-20, JAS-39, MQ-9, Mig-31, Mirage2000, P-3(CP-140), RQ-4, Rafale, SR-71(may contain A-12), Su-34, Su-57, Tornado, Tu-160, Tu-95(Tu-142), U-2, US-2(US-1A Kai), V-22, Vulcan, XB-70, YF-23)\\nPlease let me know if you find wrong‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection."},
	{"name":"ALLaVA-4V","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìö ALLaVA-4V Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration Pipeline\\n\\t\\n\\n\\n\\n\\nLAION\\n\\nWe leverage the superb GPT-4V to generate captions and complex reasoning QA pairs. Prompt is here.\\n\\nVison-FLAN\\n\\nWe leverage the superb GPT-4V to generate captions and detailed answer for the original instructions.  Prompt is here.\\n\\nWizard\\n\\nWe regenerate the answer of Wizard_evol_instruct with GPT-4-Turbo.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Cards\\n\\t\\n\\nAll datasets can be found here.\\nThe structure of naming is shown below:\\nALLaVA-4V‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V."},
	{"name":"ALLaVA-4V-Chinese","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tALLaVA-4V for Chinese\\n\\t\\n\\nThis is the Chinese version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Chinese through ChatGPT and instructed ChatGPT not to translate content related to OCR.\\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese."},
	{"name":"ALLaVA-4V-Arabic","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tALLaVA-4V for Arabic\\n\\t\\n\\nThis is the Arabic version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Arabic through ChatGPT and instructed ChatGPT not to translate content related to OCR.\\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic."},
	{"name":"DEEPFRUlT_DATASET","keyword":"computer vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET","creator_name":"shangrong chi","creator_url":"https://huggingface.co/sc890","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDeepFruit Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThis dataset contains total of 21,122 fully labeled images, featuring 20 different kinds of fruits. It is structured into an 80% training set (16,899 images) and a 20% testing set (4,223 images), facilitating a ready-to-use framework for model training and evaluation.\\nAdditionally, there are two CSV files that label the types of fruits depicted in each image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe \\\"DeepFruit\\\" dataset is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sc890/DEEPFRUlT_DATASET."},
	{"name":"PubMedVision","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/PubMedVision","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tNews\\n\\t\\n\\n\\n[2025/02/18]: We add the original captions of PubMedVision in PubMedVision_Original_Caption.json, as well as the Chinese version of PubMedVision in PubMedVision_Chinese.json.\\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing the HuatuoGPT-Vision-7B model.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPubMedVision\\n\\t\\n\\nPubMedVision is a large-scale medical VQA dataset. We extracted high-quality image-text pairs from PubMed and used GPT-4V to reformat them to enhance their quality.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/PubMedVision."},
	{"name":"Sujet-Finance-QA-Vision-100k","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sujet-ai/Sujet-Finance-QA-Vision-100k","creator_name":"Sujet AI","creator_url":"https://huggingface.co/sujet-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description üìäüîç\\n\\t\\n\\nThe Sujet-Finance-QA-Vision-100k is a comprehensive dataset containing over 100,000 question-answer pairs derived from more than 9,800 financial document images. This dataset is designed to support research and development in the field of financial document analysis and visual question answering.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features:\\n\\t\\n\\n\\nüñºÔ∏è 9,801 unique financial document images\\n‚ùì 107,050 question-answer pairs\\nüá¨üáß English language\\nüìÑ Diverse financial document‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujet-ai/Sujet-Finance-QA-Vision-100k."},
	{"name":"blip3-ocr-200m","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/blip3-ocr-200m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\\n\\t\\n\\t\\t\\n\\t\\tBLIP3-OCR-200M Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe BLIP3-OCR-200M dataset is designed to address the limitations of current Vision-Language Models (VLMs) in processing and interpreting text-rich images, such as documents and charts. Traditional image-text datasets often struggle to capture nuanced textual information, which is crucial for tasks requiring complex text comprehension and reasoning. \\n\\n\\t\\n\\t\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nOCR Integration: The dataset incorporates Optical Character‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-ocr-200m."},
	{"name":"HumanCaption-10M","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHumanCaption-10M\\n\\t\\n\\nHumanCaption-10M: a large, diverse, high-quality dataset of human-related images with natural language descriptions (image to text). The dataset is designed to facilitate research on human-centered tasks. HumanCaption-10M contains approximately 10 million human-related images and their corresponding facial features in natural language descriptions and is the second generation version of FaceCaption-15M \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIllustrations\\n\\t\\n\\n\\nPiplines of constructing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M."},
	{"name":"Research-Papers","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khushwant04/Research-Papers","creator_name":"Khushwant Sanwalot","creator_url":"https://huggingface.co/khushwant04","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI & Machine Learning Research Papers Dataset\\n\\t\\n\\nThis dataset contains a curated collection of 1296 research papers focused on advancements in Artificial Intelligence and Machine Learning. It is intended as a resource for researchers, educators, and developers to explore and analyze diverse topics within AI and ML.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nTotal Papers: 1296\\nDomains Covered: \\nArtificial Intelligence (AI)\\nMachine Learning (ML)\\nDeep Learning\\nNatural Language Processing (NLP)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/khushwant04/Research-Papers."},
	{"name":"HumanCaption-HQ-311K","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHumanCaption-HQ-311K\\n\\t\\n\\nHumanCaption-HQ-311K: Approximately 311,000 human-related images and their corresponding natural language descriptions.\\nCompared to HumanCaption-10M, this dataset not only includes associated facial language descriptions but also filters out images with higher resolution and employs the powerful visual understanding capabilities of GPT-4V to generate more detailed and accurate text descriptions.\\nThis dataset is used for the second phase of training HumanVLM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K."},
	{"name":"biomed-visual-instructions","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdaptLLM/biomed-visual-instructions","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","description":"\\n\\t\\n\\t\\t\\n\\t\\tAdapting Multimodal Large Language Models to Domains via Post-Training\\n\\t\\n\\nThis repos contains the biomedicine visual instructions for post-training MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\\nThe main project page is: Adapt-MLLM-to-Domains\\nWe investigate domain adaptation of MLLMs through post-training, focusing on data synthesis, training pipelines, and task evaluation. \\n(1) Data Synthesis: Using open-source models, we develop a visual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/biomed-visual-instructions."},
	{"name":"biomed-VQA-benchmark","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdaptLLM/biomed-VQA-benchmark","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","description":"\\n\\t\\n\\t\\t\\n\\t\\tAdapting Multimodal Large Language Models to Domains via Post-Training\\n\\t\\n\\nThis repos contains the biomedical visual instruction tasks for evaluating MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\\nThe main project page is: Adapt-MLLM-to-Domains\\nWe investigate domain adaptation of MLLMs through post-training, focusing on data synthesis, training pipelines, and task evaluation. \\n(1) Data Synthesis: Using open-source models, we develop a visual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/biomed-VQA-benchmark."},
	{"name":"food-visual-instructions","keyword":"vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdaptLLM/food-visual-instructions","creator_name":"AdaptLLM","creator_url":"https://huggingface.co/AdaptLLM","description":"\\n\\t\\n\\t\\t\\n\\t\\tAdapting Multimodal Large Language Models to Domains via Post-Training\\n\\t\\n\\nThis repos contains the food visual instructions for post-training MLLMs in our paper: On Domain-Specific Post-Training for Multimodal Large Language Models.\\nThe main project page is: Adapt-MLLM-to-Domains\\nWe investigate domain adaptation of MLLMs through post-training, focusing on data synthesis, training pipelines, and task evaluation. \\n(1) Data Synthesis: Using open-source models, we develop a visual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdaptLLM/food-visual-instructions."},
	{"name":"LayoutSAM-eval","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLayoutSAM-eval Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nLayoutSAM-Eval is a comprehensive benchmark for evaluating the quality of Layout-to-Image (L2I) generation models. This benchmark assesses L2I generation quality from two perspectives: region-wise quality (spatial and attribute accuracy) and global-wise quality (visual quality and prompt following). It employs the VLM‚Äôs visual question answering to evaluate spatial and attribute adherence, and utilizes various metrics including IR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval."},
	{"name":"LayoutSAM","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLayoutSAM Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe LayoutSAM dataset is a large-scale layout dataset derived from the SAM dataset, containing 2.7 million image-text pairs and 10.7 million entities. Each entity is annotated with a spatial position (i.e., bounding box) and a textual description.\\nTraditional layout datasets often exhibit a closed-set and coarse-grained nature, which may limit the model's ability to generate complex attributes such as color, shape, and texture.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM."},
	{"name":"FaceCaptionHQ-4M","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\tFaceCaptionHQ-4M\\n\\t\\n\\nFaceCaptionHQ-4M contains about 4M facial image-text pairs that cleaned from FaceCaption-15M .  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFigure.1 Illustrations\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFigure.2 Piplines of constructing FaceCaptionHQ-4M. The detailed method can be referred to Face-MakeUp.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNews and Update üî•üî•üî•\\n\\t\\n\\n\\nJan.11, 2025.   ü§óFaceCaptionHQ-4M, is released!üëèüëèüëè\\nJan.11, 2025.   ü§óFaceMaker-V0, is released!üëèüëèüëè\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tü§ó How to Use\\n\\t\\n\\nWe provide a few lines of code to download‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M."},
	{"name":"Opendoc2-Analysis-Recognition","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpendoc2-Analysis-Recognition Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Opendoc2-Analysis-Recognition dataset is a collection of data designed for tasks involving image analysis and recognition. It is suitable for various machine learning tasks, including image-to-text conversion, text classification, and image feature extraction.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nModalities: Likely includes images and associated labels (specific modalities can be confirmed on the dataset's page).\\nLanguages:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Opendoc2-Analysis-Recognition."},
	{"name":"Medical-pills","keyword":"computer-vision","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ultralytics/Medical-pills","creator_name":"Ultralytics","creator_url":"https://huggingface.co/Ultralytics","description":"\\n\\t\\n\\t\\t\\n\\t\\tUltralytics Medical-pills Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nUltralytics medical-pills detection dataset is a proof-of-concept (POC) dataset, carefully curated to demonstrate the potential of AI in pharmaceutical applications. It contains labeled images specifically designed to train computer vision models for identifying medical-pills.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Images and Annotations\\n\\t\\n\\nHere are some examples of images from the dataset, along with their corresponding annotations in a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ultralytics/Medical-pills."},
	{"name":"YOLOv8-Multiclass-Object-Detection-Dataset","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset","creator_name":"Duality AI","creator_url":"https://huggingface.co/duality-robotics","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATASET SAMPLE\\n\\t\\n\\nDuality.ai  just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free!\\nJust create an EDU account here. \\nThis HuggingFace dataset is a 20 image and label sample, but you can get the rest at no cost by creating a FalconCloud account. Once you verify your email, the link will redirect you to the dataset page.\\nWhat makes this dataset unique, useful, and capable of bridging the Sim2Real gap?\\n\\nThe digital twins are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset."},
	{"name":"fashionpedia_4_categories","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fashionpedia_4_categories\\n\\t\\n\\nThis dataset is a variation of the fashionpedia dataset available here, with 2 key differences:\\n\\nIt contains only 4 categories:\\nClothing\\nShoes\\nBags\\nAccessories\\n\\n\\nNew splits were created:\\nTrain: 90% of the images\\nVal: 5%\\nTest 5%\\n\\n\\n\\nThe goal is to make the detection task easier with 4 categories instead of 46 for the full fashionpedia dataset.\\nThis dataset was created using the detection_datasets library (GitHub, PyPI), you can check here‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories."},
	{"name":"CADI-AI","keyword":"vision","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaraAgroAI/CADI-AI","creator_name":"KaraAgro AI Foundation","creator_url":"https://huggingface.co/KaraAgroAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCashew Disease Identication with Artificial Intelligence (CADI-AI) Dataset\\n\\t\\n\\nThis repository contains a comprehensive dataset of cashew images captured by drones, accompanied by meticulously annotated labels. \\nEach high-resolution image in the dataset has a resolution of 1600x1300 pixels, providing fine details for analysis and model training.\\nTo facilitate efficient object detection, each image is paired with a corresponding text file in YOLO format. \\nThe YOLO format file‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaraAgroAI/CADI-AI."},
	{"name":"dtd_split_1","keyword":"computer-vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mcimpoi/dtd_split_1","creator_name":"Mircea Cimpoi","creator_url":"https://huggingface.co/mcimpoi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Describable Textures Dataset (DTD)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTexture classification dataset; consists of 47 categories, 120 images per class.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nEqually split into train, val, test; The original paper proposed 10 splits; recent works (BYOL, arxiv:2006.07733) use only first split.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nNot defined at https://www.robots.ox.ac.uk/~vgg/data/dtd/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mcimpoi/dtd_split_1."},
	{"name":"Fruits-30","keyword":"vision","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VinayHajare/Fruits-30","creator_name":"Vinay Arjun Hajare","creator_url":"https://huggingface.co/VinayHajare","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFruits30 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription:\\n\\t\\n\\nThe Fruits30 dataset is a collection of images featuring 30 different types of fruits. Each image has been preprocessed and standardized to a size of 224x224 pixels, ensuring uniformity in the dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Composition:\\n\\t\\n\\n\\nNumber of Classes: 30\\nImage Resolution: 224x224 pixels\\nTotal Images: 826\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tClasses:\\n\\t\\n\\n0 : acerolas1 : apples2 : apricots3 : avocados4 : bananas5 : blackberries6 : blueberries7 :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VinayHajare/Fruits-30."},
	{"name":"Picklebot-50K","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hbfreed/Picklebot-50K","creator_name":"Henry","creator_url":"https://huggingface.co/hbfreed","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Picklebot50k\\n\\t\\n\\n\\n\\n50 thousand video clips of balls and strikes from MLB games from the 2016 season through the 2022 season.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nThe dataset consists of roughly 50 thousand video clips of balls and strikes in .mp4 format, resized to 224x224 resolution.\\nThe calculated standard deviation and mean for the dataset are \\nstd: (0.2104, 0.1986, 0.1829)\\nmean: (0.3939, 0.3817, 0.3314).\\n\\nCurated by: Henry Freed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hbfreed/Picklebot-50K."},
	{"name":"oe_dataset","keyword":"vision","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ABC-iRobotics/oe_dataset","creator_name":"Antal Bejczy Center for Intelligent Robotics","creator_url":"https://huggingface.co/ABC-iRobotics","description":"An instance segmentation dataset for robotic manipulation in a tabletop environment.\\nThe dataset incorporates real and synthetic images for testing sim-to-real model transfer after fine-tuning."},
	{"name":"MultiCaRe_Dataset","keyword":"computer vision","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset","creator_name":"Mauro Nievas Offidani","creator_url":"https://huggingface.co/mauro-nievoff","description":"The dataset contains multi-modal data from over 75,000 open access and de-identified case reports, including metadata, clinical cases, image captions and more than 130,000 images. Images and clinical cases belong to different medical specialties, such as oncology, cardiology, surgery and pathology. The structure of the dataset allows to easily map images with their corresponding article metadata, clinical case, captions and image labels. Details of the data structure can be found in the file‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset."},
	{"name":"UnLOK-VQA","keyword":"vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vaidehi99/UnLOK-VQA","creator_name":"Vaidehi Patil","creator_url":"https://huggingface.co/vaidehi99","description":"\\n\\t\\n\\t\\t\\n\\t\\tüìä Dataset: UnLOK-VQA (Unlearning Outside Knowledge VQA)\\n\\t\\n\\nLink: Dataset Link\\nThis dataset contains approximately 500 entries with the following key attributes:\\n\\n\\\"id\\\": Unique Identifier for each entry\\n\\\"src\\\": The question whose answer is to be deleted ‚ùì\\n\\\"pred\\\": The answer to the question meant for deletion ‚ùå\\n\\\"loc\\\": Related neighborhood questions üîÑ\\n\\\"loc_ans\\\": Answers to the neighborhood questions üó£Ô∏è\\n\\\"image_id\\\": The ID corresponding to the image in the COCO dataset üñºÔ∏è\\n\\nTo access the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vaidehi99/UnLOK-VQA."},
	{"name":"typed_digital_signatures","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Benjy/typed_digital_signatures","creator_name":"Ben","creator_url":"https://huggingface.co/Benjy","description":"\\n\\t\\n\\t\\t\\n\\t\\tTyped Digital Signatures Dataset\\n\\t\\n\\nThis comprehensive dataset contains synthetic digital signatures rendered across 30 different Google Fonts, specifically selected for their handwriting and signature-style characteristics. Each font contributes unique stylistic elements, making this dataset ideal for robust signature analysis and font recognition tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nTotal Fonts: 30 different Google Fonts\\nImages per Font: 3,000 signatures\\nTotal Dataset Size: ~90,000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Benjy/typed_digital_signatures."},
	{"name":"Marathi_Handwritten","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Marathi Handwritten OCR Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Marathi Handwritten Text Dataset is a collection of handwritten text images in Marathi (‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡§≤‡§ø‡§™‡•Ä),\\naimed at supporting the development of Optical Character Recognition (OCR) systems, handwriting analysis tools,\\nand language research.The dataset was curated from native Marathi speakers to ensure a variety of handwriting styles and character variations.\\nThe dataset contains 2520 images with two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten."},
	{"name":"gc-os-img-art-critic","keyword":"computer-vision","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpfearnworks/gc-os-img-art-critic","creator_name":"JP","creator_url":"https://huggingface.co/jpfearnworks","description":"\\n\\t\\n\\t\\t\\n\\t\\tgc-os-img-art-critic\\n\\t\\n\\nExample gc dataset with art critic perspective\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains images with associated metadata including captions, tags, and verification information.\\n"},
	{"name":"cats_dogs_dataset","keyword":"computer-vision","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/louiecerv/cats_dogs_dataset","creator_name":"Louie Cervantes","creator_url":"https://huggingface.co/louiecerv","description":"\\n\\t\\n\\t\\t\\n\\t\\tCats and Dogs Image Classification Dataset\\n\\t\\n\\nThis dataset contains images of cats and dogs, intended for image classification tasks. It includes two classes: \\\"cats\\\" and \\\"dogs\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is structured into two splits:\\n\\ntrain: Contains 8000 images for training.\\ntest: Contains 2000 images for testing.\\n\\nImages are stored in RGB format with a resolution of 128x128 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\tData Loading and Usage\\n\\t\\n\\nThe dataset can be loaded using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louiecerv/cats_dogs_dataset."}
]
;
