const data_for_modality_audio = 
[
	{"name":"emova-sft-4m","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-4m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-4M\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-4M is a comprehensive dataset curated for omni-modal instruction tuning, including textual, visual, and audio interactions. This dataset is created by gathering open-sourced multi-modal instruction datasets and synthesizing high-quality omni-modal conversation data to enhance user experience. This dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-4m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amogh7777/MANGO","creator_name":"Amogh Gulati","creator_url":"https://huggingface.co/amogh7777","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n47,100 human ratings of TTS-generated and ground-truth human speech.\nCovers two major Indian languages:\nHindi\nTamil\n\n\nBased on the MUSHRA (Multiple Stimuli with Hidden Reference and Anchor) test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amogh7777/MANGO.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"AV_Odyssey_Bench","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AV-Odyssey/AV_Odyssey_Bench","creator_name":"AV-Odyssey Bench","creator_url":"https://huggingface.co/AV-Odyssey","description":"Official dataset for the paper \"AV-Odyssey: Can Your Multimodal LLMs Really Understand Audio-Visual Information?\".\nüåü For more details, please refer to the project page with data examples: https://av-odyssey.github.io/.\n[üåê Webpage] [üìñ Paper] [ü§ó Huggingface AV-Odyssey Dataset] [ü§ó Huggingface Deaftest Dataset] [üèÜ Leaderboard]\n\n\n\t\n\t\n\t\n\t\tüî• News\n\t\n\n\n2024.11.24 üåü We release AV-Odyssey, the first-ever comprehensive evaluation benchmark to explore whether MLLMs really understand audio-visual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AV-Odyssey/AV_Odyssey_Bench.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_eu_v2.1","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/composite_corpus_eu_v2.1","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tComposite dataset for Basque made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/eu: \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\ngttsehu/basque_parliament_1/eu: \"train_clean\" split removing some of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_eu_v2.1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ar-quran-hadith14books-MSA","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DrAliGomaa/ar-quran-hadith14books-MSA","creator_name":"arabic_speech","creator_url":"https://huggingface.co/DrAliGomaa","description":"\n\t\n\t\t\n\t\tDataset Card for quran and hadith dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nArabic specialized dataset to make sure that AI is not changing our sacred scriptures in speech recognition by training and evaluating upon quran and hadith.\n\nCombining quran + magma'a el zawa'ed book of sidi Nour eldin elhaithamy author including 14 book of hadith of approximately 10,000 hadith without repititions + other existing datasets like common voice, fleurs, media speech\n\nFirst dataset to have full‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DrAliGomaa/ar-quran-hadith14books-MSA.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"galaxy","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fivetech/galaxy","creator_name":"Antonio Linares","creator_url":"https://huggingface.co/fivetech","description":"fivetech/galaxy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Aerith","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Aerith","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Aerith dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"masri_audio_transcription","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexstokes/masri_audio_transcription","creator_name":"Alex Yosef","creator_url":"https://huggingface.co/alexstokes","description":"alexstokes/masri_audio_transcription dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Rosmontis","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Chinese","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"Rosmontis","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Chinese","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"cretan-speech-corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ilsp/cretan-speech-corpus","creator_name":"Institute for Language and Speech Processing","creator_url":"https://huggingface.co/ilsp","description":"Cretan is a variety of Modern Greek predominantly used by\nspeakers who reside on the island of Crete or belong to the Cretan\ndiaspora. This includes communities of Cretan origin that were\nrelocated to the village of Hamidieh in Syria and to Western\nAsia Minor, following the population exchange between Greece\nand Turkey in 1923. The historical and geographical factors\nthat have shaped the development and preservation of the dialect\ninclude the long-term isolation of Crete from the mainland, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilsp/cretan-speech-corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"alphanumeric-audio-dataset","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset","creator_name":"Sakshee Patil","creator_url":"https://huggingface.co/sakshee05","description":"\n\t\n\t\t\n\t\tSpeech Recognition Bias Reduction Project\n\t\n\n\n\t\n\t\t\n\t\tExecutive Summary\n\t\n\nWelcome to the Speech Recognition Bias Reduction Project. It aims to create a more inclusive and representative dataset for improving automated speech recognition systems. This project addresses the challenges faced by speakers with non-native English accents, particularly when interacting with automated voice systems that struggle to interpret alphanumeric information such as names, phone numbers, and addresses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"alphanumeric-audio-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset","creator_name":"Sakshee Patil","creator_url":"https://huggingface.co/sakshee05","description":"\n\t\n\t\t\n\t\tSpeech Recognition Bias Reduction Project\n\t\n\n\n\t\n\t\t\n\t\tExecutive Summary\n\t\n\nWelcome to the Speech Recognition Bias Reduction Project. It aims to create a more inclusive and representative dataset for improving automated speech recognition systems. This project addresses the challenges faced by speakers with non-native English accents, particularly when interacting with automated voice systems that struggle to interpret alphanumeric information such as names, phone numbers, and addresses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"alphanumeric-audio-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset","creator_name":"Sakshee Patil","creator_url":"https://huggingface.co/sakshee05","description":"\n\t\n\t\t\n\t\tSpeech Recognition Bias Reduction Project\n\t\n\n\n\t\n\t\t\n\t\tExecutive Summary\n\t\n\nWelcome to the Speech Recognition Bias Reduction Project. It aims to create a more inclusive and representative dataset for improving automated speech recognition systems. This project addresses the challenges faced by speakers with non-native English accents, particularly when interacting with automated voice systems that struggle to interpret alphanumeric information such as names, phone numbers, and addresses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"audio_benchmarks","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gtysssp/audio_benchmarks","creator_name":"gtysssp","creator_url":"https://huggingface.co/gtysssp","description":"gtysssp/audio_benchmarks dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"UrbanSoundsNew","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanSounds/UrbanSoundsNew","creator_name":"Sensemakers Amsterdam UrbanSounds repo","creator_url":"https://huggingface.co/UrbanSounds","description":"New version of the UrbanSounds (small) dataset. Containing +/- 25 samples of each of the nine classes. See https://github.com/Sensemakersamsterdam/OpenEars for more info.\n","first_N":5,"first_N_keywords":["audio-classification","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"UrbanSoundsNew","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanSounds/UrbanSoundsNew","creator_name":"Sensemakers Amsterdam UrbanSounds repo","creator_url":"https://huggingface.co/UrbanSounds","description":"New version of the UrbanSounds (small) dataset. Containing +/- 25 samples of each of the nine classes. See https://github.com/Sensemakersamsterdam/OpenEars for more info.\n","first_N":5,"first_N_keywords":["audio-classification","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Arabic_audio_recordings","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/a1anas1a/Arabic_audio_recordings","creator_name":"anas moussa","creator_url":"https://huggingface.co/a1anas1a","description":"a1anas1a/Arabic_audio_recordings dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Hope","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Hope","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Hope dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"common-voice-corpus-20","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hataphu/common-voice-corpus-20","creator_name":"Ha Van Tan","creator_url":"https://huggingface.co/hataphu","description":"hataphu/common-voice-corpus-20 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"audio6","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlenJoy47/audio6","creator_name":"Alen Joy","creator_url":"https://huggingface.co/AlenJoy47","description":"AlenJoy47/audio6 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Vietnamese-streamer-voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/some1oe/Vietnamese-streamer-voice","creator_name":"one some","creator_url":"https://huggingface.co/some1oe","description":"some1oe/Vietnamese-streamer-voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","text","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"full_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biancataz/full_dataset","creator_name":"Bianca Tazlauanu","creator_url":"https://huggingface.co/biancataz","description":"biancataz/full_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"PARADE_audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/UCSC-VLAA/PARADE_audio","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","description":"UCSC-VLAA/PARADE_audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Elise","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Elise","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Elise dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"work7","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlenJoy47/work7","creator_name":"Alen Joy","creator_url":"https://huggingface.co/AlenJoy47","description":"AlenJoy47/work7 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hoanghiepv77/tts","creator_name":"VuHoangHiep","creator_url":"https://huggingface.co/hoanghiepv77","description":"hoanghiepv77/tts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Mridingham-Tonic","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silky1708/Mridingham-Tonic","creator_name":"Silky Singh","creator_url":"https://huggingface.co/silky1708","description":"silky1708/Mridingham-Tonic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Mridingham-Stroke","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silky1708/Mridingham-Stroke","creator_name":"Silky Singh","creator_url":"https://huggingface.co/silky1708","description":"silky1708/Mridingham-Stroke dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"twi_multispeaker_audio_transcribed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Twi Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Asante Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"twi_multispeaker_audio_transcribed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Twi Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Asante Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"akuapem_multispeaker_audio_transcribed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tAkuapem Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Akuapem Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Akuapem Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"akuapem_multispeaker_audio_transcribed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tAkuapem Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Akuapem Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Akuapem Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"fante_multispeaker_audio_transcribed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tFante Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Fante Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Fante, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Fanti","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"fante_multispeaker_audio_transcribed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tFante Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Fante Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Fante, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Fanti","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Babillage","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kyutai/Babillage","creator_name":"Kyutai","creator_url":"https://huggingface.co/kyutai","description":"\n\t\n\t\t\n\t\tBabillage\n\t\n\nBabillage is a multimodal benchmark dataset introduced along with MoshiVis (Project Page | arXiv), containing three common vision-language benchmarks converted in spoken form, for the evaluation of Vision Speech Models. \nFor each benchmark (COCO-Captions, OCR-VQA, VQAv2), we first reformat the text question-answer pairs into a more conversational dialogue, and then convert them using a text-to-speech pipeline, using a \nconsistent synthetic voice for the answer (assistant)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kyutai/Babillage.","first_N":5,"first_N_keywords":["visual-question-answering","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"fpt-open-audio-noised","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/huytran98/fpt-open-audio-noised","creator_name":"Tran Quoc Huy","creator_url":"https://huggingface.co/huytran98","description":"huytran98/fpt-open-audio-noised dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Vietnamese","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"MiscSpeech-ja","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rakuto/MiscSpeech-ja","creator_name":"rakuto","creator_url":"https://huggingface.co/Rakuto","description":"\n\t\n\t\t\n\t\tMiscSpeech-ja\n\t\n\nThis dataset comprises audio and corresponding transcripts collected from a diverse range of YouTube videos and Podcasts. \n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"parallel-recordings","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lescidium/parallel-recordings","creator_name":"Kenny Haak","creator_url":"https://huggingface.co/lescidium","description":"\n\t\n\t\t\n\t\tParallel Recordings\n\t\n\nThis dataset is a small corpus of audio recorded in parallel.\nThis data can be used to quantify the difference in recording quality between different audio devices.\nAn example of this quantification using WER is shown below.\n\n\t\n\t\t\n\t\tOrganization\n\t\n\nThere are two separate experiments.\n\nPersonal Microphone\nSpeakerphone\n\nThe original data for both experiments are located in thefull_length_audio directory.\nEach experiment was performed by recording simultaneously on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lescidium/parallel-recordings.","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"parallel-recordings","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lescidium/parallel-recordings","creator_name":"Kenny Haak","creator_url":"https://huggingface.co/lescidium","description":"\n\t\n\t\t\n\t\tParallel Recordings\n\t\n\nThis dataset is a small corpus of audio recorded in parallel.\nThis data can be used to quantify the difference in recording quality between different audio devices.\nAn example of this quantification using WER is shown below.\n\n\t\n\t\t\n\t\tOrganization\n\t\n\nThere are two separate experiments.\n\nPersonal Microphone\nSpeakerphone\n\nThe original data for both experiments are located in thefull_length_audio directory.\nEach experiment was performed by recording simultaneously on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lescidium/parallel-recordings.","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"medical-segmentation-dataset_v2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abar-uwc/medical-segmentation-dataset_v2","creator_name":"Ayush","creator_url":"https://huggingface.co/abar-uwc","description":"abar-uwc/medical-segmentation-dataset_v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"mtg_jamendo_autotagging","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vtsouval/mtg_jamendo_autotagging","creator_name":"Vasileios Tsouvalas","creator_url":"https://huggingface.co/vtsouval","description":"\n\t\n\t\t\n\t\tüéµ MTG-Jamendo Autotagging (30s, 16kHz, Multi-Label)\n\t\n\nThis dataset is a curated subset of the MTG-Jamendo Autotagging Dataset, containing only tracks that include instrument, genre, and mood/theme annotations. Each audio file is preprocessed to ensure consistent formatting for music auto-tagging tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüßæ Dataset Description\n\t\n\n\nSource: MTG-Jamendo Autotagging benchmark\nSelection: Tracks that include all three tag types:\ngenre\ninstrument\nmood/theme\n\n\nPreprocessing:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vtsouval/mtg_jamendo_autotagging.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"mtg_jamendo_autotagging","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vtsouval/mtg_jamendo_autotagging","creator_name":"Vasileios Tsouvalas","creator_url":"https://huggingface.co/vtsouval","description":"\n\t\n\t\t\n\t\tüéµ MTG-Jamendo Autotagging (30s, 16kHz, Multi-Label)\n\t\n\nThis dataset is a curated subset of the MTG-Jamendo Autotagging Dataset, containing only tracks that include instrument, genre, and mood/theme annotations. Each audio file is preprocessed to ensure consistent formatting for music auto-tagging tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüßæ Dataset Description\n\t\n\n\nSource: MTG-Jamendo Autotagging benchmark\nSelection: Tracks that include all three tag types:\ngenre\ninstrument\nmood/theme\n\n\nPreprocessing:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vtsouval/mtg_jamendo_autotagging.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"TTA-Bench","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hui519/TTA-Bench","creator_name":"hui wang","creator_url":"https://huggingface.co/Hui519","description":"\n\t\n\t\t\n\t\tTTA-Bench Dataset\n\t\n\n\n\t\n\t\t\n\t\tüéØ Overview\n\t\n\nWelcome to TTA-Bench! This repository contains our comprehensive evaluation framework for text-to-audio (TTA) systems. We've carefully curated 2,999 prompts across six different evaluation dimensions, creating a standardized benchmark for assessing text-to-audio generation capabilities.\n\n\t\n\t\t\n\t\tüìö Dataset Structure\n\t\n\nEach prompt in our dataset contains these essential fields:\n\nid: Unique identifier for each prompt (format: prompt_XXXX)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hui519/TTA-Bench.","first_N":5,"first_N_keywords":["text-to-audio","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Pseudolabels_Whisper_Large_CSALT_FLEUR","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mscs23021/Pseudolabels_Whisper_Large_CSALT_FLEUR","creator_name":"mustafiz ur Rehman","creator_url":"https://huggingface.co/mscs23021","description":"mscs23021/Pseudolabels_Whisper_Large_CSALT_FLEUR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"MusicSem","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Rsalga/MusicSem","creator_name":"Rebecca Salganik","creator_url":"https://huggingface.co/Rsalga","description":"\n\t\n\t\t\n\t\tDataset Card for MusicSem\n\t\n\n\n\n\nThis dataset contains 35977 entries of text-audio pairs. There is an accompanying test set of size 480 which is withheld for leaderboard purposes. Please reach out to authors for further access.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Rebecca Salganik, Teng Tu, Fei-Yueh Chen, Xiaohao Liu, Kaifeng Lu, Ethan Luvisia, Zhiyao Duan, Guillaume Salha-Galvan, Anson Kahng, Yunshan Ma, Jian Kang\nLanguage(s) : English\nLicense: MIT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rsalga/MusicSem.","first_N":5,"first_N_keywords":["text-to-audio","summarization","feature-extraction","audio-text-to-text","English"],"keywords_longer_than_N":true},
	{"name":"in_the_wild","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AdnanKhan2003/in_the_wild","creator_name":"Adnan Khan","creator_url":"https://huggingface.co/AdnanKhan2003","description":"AdnanKhan2003/in_the_wild dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"VATT","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FF2416/VATT","creator_name":"Frank Fang","creator_url":"https://huggingface.co/FF2416","description":"FF2416/VATT dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","soundfolder","Audio","Datasets","Croissant"],"keywords_longer_than_N":true},
	{"name":"sova_test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NikiPshg/sova_test","creator_name":"Nikita","creator_url":"https://huggingface.co/NikiPshg","description":"NikiPshg/sova_test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"english_accents","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexnasa/english_accents","creator_name":"Alex Nasa","creator_url":"https://huggingface.co/alexnasa","description":"alexnasa/english_accents dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Voila-Benchmark","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/maitrix-org/Voila-Benchmark","creator_name":"Maitrix.org","creator_url":"https://huggingface.co/maitrix-org","description":"\n    \n    Voila: Voice-Language Foundation Models\n    üíú Project Page ¬†¬† ÔΩú ¬†¬† üñ•Ô∏è GitHub ¬†¬†  | ¬†¬†ü§ó Hugging Face¬†¬† | ¬†¬† üìë Paper ¬†¬† | ¬†¬† üåê Online Demo ¬†¬†| ¬†¬† üè†Maitrix.org\n\n\nVoila is a new family of large voice-language foundation models aiming to lift human-AI interaction experiences to the next level. Breaking away from the constraints of traditional voice AI systems‚Äîhigh latency, loss of vocal nuances, and mechanical responses‚ÄîVoila employs an innovative end-to-end model design and a novel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maitrix-org/Voila-Benchmark.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"final_final","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Finalprojectfour/final_final","creator_name":"bleeehh ","creator_url":"https://huggingface.co/Finalprojectfour","description":"Finalprojectfour/final_final dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"somali_speech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HusseinBashir/somali_speech","creator_name":"Hussein Bashir","creator_url":"https://huggingface.co/HusseinBashir","description":"HusseinBashir/somali_speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vin-bigdata-vi-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/huytran98/vin-bigdata-vi-audio","creator_name":"Tran Quoc Huy","creator_url":"https://huggingface.co/huytran98","description":"huytran98/vin-bigdata-vi-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"evals-btb-whisper-large-v3-ft-btb-cv-ca-cy-2503","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DewiBrynJones/evals-btb-whisper-large-v3-ft-btb-cv-ca-cy-2503","creator_name":"Dewi Bryn Jones","creator_url":"https://huggingface.co/DewiBrynJones","description":"Model: DewiBrynJones/whisper-large-v3-ft-btb-cv-ca-cy-2503\nTest Set: DewiBrynJones/banc-trawsgrifiadau-bangor\nSplit: test\n\nWER: 29.537816\nCER: 10.727831\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"pyannote-hindi-diarization","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Venkatesh4342/pyannote-hindi-diarization","creator_name":"venkatesh R","creator_url":"https://huggingface.co/Venkatesh4342","description":"Venkatesh4342/pyannote-hindi-diarization dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"InsectSet459","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/academic-datasets/InsectSet459","creator_name":"academic-datasets","creator_url":"https://huggingface.co/academic-datasets","description":"\n\t\n\t\t\n\t\tInsectSet459: An Open Dataset of Insect Sounds for Bioacoustic Machine Learning\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nInsectSet459 is a comprehensive dataset of insect sounds designed for developing and testing machine learning algorithms for automatic insect identification. It contains 26,399 audio files from 459 species of Orthoptera (crickets, grasshoppers, katydids) and Cicadidae (cicadas), providing 9.5 days of audio material.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n459 unique insect species (310 Orthopteran‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/academic-datasets/InsectSet459.","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","10K - 100K","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"InsectSet459","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/academic-datasets/InsectSet459","creator_name":"academic-datasets","creator_url":"https://huggingface.co/academic-datasets","description":"\n\t\n\t\t\n\t\tInsectSet459: An Open Dataset of Insect Sounds for Bioacoustic Machine Learning\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nInsectSet459 is a comprehensive dataset of insect sounds designed for developing and testing machine learning algorithms for automatic insect identification. It contains 26,399 audio files from 459 species of Orthoptera (crickets, grasshoppers, katydids) and Cicadidae (cicadas), providing 9.5 days of audio material.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n459 unique insect species (310 Orthopteran‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/academic-datasets/InsectSet459.","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","10K - 100K","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"thumania-2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mohaddz/thumania-2","creator_name":"MohammedNamri","creator_url":"https://huggingface.co/Mohaddz","description":"Mohaddz/thumania-2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"spc_r","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/i4ds/spc_r","creator_name":"Institute for Data Science","creator_url":"https://huggingface.co/i4ds","description":"\n\t\n\t\t\n\t\tDataset Card: Swiss‚ÄØParliaments‚ÄØCorpus ‚Äî SPC_R‚ÄØv1.0\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nSPC_R pairs Swiss‚ÄØGerman parliamentary speech with Standard‚ÄØGerman transcriptions, yielding ‚âà‚ÄØ751‚ÄØhours of high‚Äëquality speech‚Äìtext data for training and evaluating automatic speech‚Äërecognition (ASR) and speech‚Äëtranslation models.  The corpus extends the original Swiss‚ÄØParliaments‚ÄØCorpus by processing full‚Äëlength sessions (~28‚ÄØ‚Äì‚ÄØ242‚ÄØmin each) from the Grosser‚ÄØRat Kanton‚ÄØBern with a modern, LLM‚Äëenhanced pipeline‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/i4ds/spc_r.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"evals-btb-whisper-large-v3-ft-btb-cv-cvad-ca-cy-2503","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DewiBrynJones/evals-btb-whisper-large-v3-ft-btb-cv-cvad-ca-cy-2503","creator_name":"Dewi Bryn Jones","creator_url":"https://huggingface.co/DewiBrynJones","description":"Model: DewiBrynJones/whisper-large-v3-ft-btb-cv-cvad-ca-cy-2503\nTest Set: DewiBrynJones/banc-trawsgrifiadau-bangor\nSplit: test\n\nWER: 28.996734\nCER: 10.270132\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"leaderboard_data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ttsds/leaderboard_data","creator_name":"TTS Distribution Score","creator_url":"https://huggingface.co/ttsds","description":"ttsds/leaderboard_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"CMM","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xing0047/CMM","creator_name":"Xing Yun","creator_url":"https://huggingface.co/xing0047","description":"\n\t\n\t\t\n\t\tThe Curse of Multi-Modalities (CMM) Dataset Card\n\t\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nDataset type:\nCMM is a curated benchmark designed to evaluate hallucination vulnerabilities in Large Multi-Modal Models (LMMs). It is constructed to rigorously test LMMs‚Äô capabilities across visual, audio, and language modalities, focusing on hallucinations arising from inter-modality spurious correlations and uni-modal over-reliance.\nDataset detail:\nCMM introduces 2,400 probing questions across 1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xing0047/CMM.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","audio-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"electricboogaloo","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hardlyworking/electricboogaloo","creator_name":"workinghardly","creator_url":"https://huggingface.co/hardlyworking","description":"hardlyworking/electricboogaloo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Motahare-FA_EN_AR-Public-Phone-Audio-Dataset","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mah92/Motahare-FA_EN_AR-Public-Phone-Audio-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","description":"mah92/Motahare-FA_EN_AR-Public-Phone-Audio-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","10K - 100K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Motahare-AR_EN-Public-Phone-Audio-Dataset","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mah92/Motahare-AR_EN-Public-Phone-Audio-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","description":"mah92/Motahare-AR_EN-Public-Phone-Audio-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"YouTube-Cantonese","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OrcinusOrca/YouTube-Cantonese","creator_name":"Orca","creator_url":"https://huggingface.co/OrcinusOrca","description":"\n\t\n\t\t\n\t\tCantonese Audio Dataset from YouTube\n\t\n\nThis dataset contains Cantonese audio segments extracted from various YouTube channels, along with corresponding transcription metadata. The data is intended for training automatic speech recognition (ASR) models.\n\n\t\n\t\t\n\t\tData Source and Processing\n\t\n\nThe data was obtained through the following process:\n\nDownload: Audio (.m4a) and available Cantonese subtitles (.srt for zh-TW, zh-HK, zh-Hant) were downloaded from selected YouTube channels. This‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OrcinusOrca/YouTube-Cantonese.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","Yue Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"voice_sample","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zayawofeso/voice_sample","creator_name":"Zaynab Awofeso","creator_url":"https://huggingface.co/zayawofeso","description":"zayawofeso/voice_sample dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"animespeech-orpheus-prep-800","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/taresh18/animespeech-orpheus-prep-800","creator_name":"Taresh Rajput","creator_url":"https://huggingface.co/taresh18","description":"Preprocessed dataset in Orpheus TTS FT format corresponding to voices [\"107\", \"125\", \"145\", \"16\", \"163\", \"179\", \"180\", \"183\", \"185\", \"187\"] from ShoukanLabs/AniSpeech\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"animespeech-orpheus-prep-800","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/taresh18/animespeech-orpheus-prep-800","creator_name":"Taresh Rajput","creator_url":"https://huggingface.co/taresh18","description":"Preprocessed dataset in Orpheus TTS FT format corresponding to voices [\"107\", \"125\", \"145\", \"16\", \"163\", \"179\", \"180\", \"183\", \"185\", \"187\"] from ShoukanLabs/AniSpeech\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"plug_socket_moved","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_moved","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 44,\n    \"total_frames\": 15772,\n    \"total_tasks\": 1,\n    \"total_videos\": 132,\n    \"total_audio\": 132,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:44\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_moved.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"plug_socket_moved","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_moved","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 44,\n    \"total_frames\": 15772,\n    \"total_tasks\": 1,\n    \"total_videos\": 132,\n    \"total_audio\": 132,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:44\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_moved.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"behavior-sd","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yhytoto12/behavior-sd","creator_name":"Sehun Lee","creator_url":"https://huggingface.co/yhytoto12","description":"\n\t\n\t\t\n\t\tüéôÔ∏è Behavior-SD\n\t\n\nOfficial repository for our NAACL 2025 paper:Behavior-SD: Behaviorally Aware Spoken Dialogue Generation with Large Language ModelsSehun Lee*, Kang-wook Kim*, Gunhee Kim  (* Equal contribution)\n\nüèÜ SAC Award Winner in Speech Processing and Spoken Language Understanding\n\n\n\t\n\t\t\n\t\n\t\n\t\tüîó Links\n\t\n\n\nProject Page\nCode\n\n\n\t\n\t\n\t\n\t\tüìñ Overview\n\t\n\nWe explores how to generate natural, behaviorally-rich full-duplex spoken dialogues using large language models (LLMs).\nWe introduce:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yhytoto12/behavior-sd.","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"YouTube-English","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OrcinusOrca/YouTube-English","creator_name":"Orca","creator_url":"https://huggingface.co/OrcinusOrca","description":"\n\t\n\t\t\n\t\tEnglish Audio Dataset from YouTube\n\t\n\nThis dataset contains English audio segments extracted from various YouTube channels, along with corresponding transcription metadata. The data is intended for training automatic speech recognition (ASR) models.\n\n\t\n\t\t\n\t\tData Source and Processing\n\t\n\nThe data was obtained through the following process:\n\nDownload: Audio (.m4a) and available English subtitles (.srt for en, en.j3PyPqV-e1s) were downloaded from selected YouTube channels. This raw data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OrcinusOrca/YouTube-English.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"acoustic-PUUM","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Logistikon/acoustic-PUUM","creator_name":"Fedor Zolotarev","creator_url":"https://huggingface.co/Logistikon","description":"\n\t\n\t\t\n\t\tDataset Card for PUUM_passive_recordings\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a dataset containing unlabelled, unprocessed passive acoustic recordings of Hawaiian birds in the Pu'u Maka'ala Natural Area Reserve (PUUM) in Hawaii. This dataset is intended for use in unsupervised audio analysis methods, classification using existing models, and other machine learning and ecology research purposes. Additionally, this dataset contains dataframes with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Logistikon/acoustic-PUUM.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"acoustic-PUUM","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Logistikon/acoustic-PUUM","creator_name":"Fedor Zolotarev","creator_url":"https://huggingface.co/Logistikon","description":"\n\t\n\t\t\n\t\tDataset Card for PUUM_passive_recordings\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a dataset containing unlabelled, unprocessed passive acoustic recordings of Hawaiian birds in the Pu'u Maka'ala Natural Area Reserve (PUUM) in Hawaii. This dataset is intended for use in unsupervised audio analysis methods, classification using existing models, and other machine learning and ecology research purposes. Additionally, this dataset contains dataframes with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Logistikon/acoustic-PUUM.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"acoustic-PUUM","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Logistikon/acoustic-PUUM","creator_name":"Fedor Zolotarev","creator_url":"https://huggingface.co/Logistikon","description":"\n\t\n\t\t\n\t\tDataset Card for PUUM_passive_recordings\n\t\n\n \n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a dataset containing unlabelled, unprocessed passive acoustic recordings of Hawaiian birds in the Pu'u Maka'ala Natural Area Reserve (PUUM) in Hawaii. This dataset is intended for use in unsupervised audio analysis methods, classification using existing models, and other machine learning and ecology research purposes. Additionally, this dataset contains dataframes with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Logistikon/acoustic-PUUM.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"TatSC_ASR","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/TatSC_ASR","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\n\t\n\t\t\n\t\tTatar Speech Corpus ASR\n\t\n\n[Original repository] [Original site]\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTatar Speech Corpus ASR is a speech dataset sourced from this GitHub repository. TatSC contains 269.1 hours of transcribed speech with 271,914 utterances. It is the first open-source Tatar speech corpus covering both crowdsourced and audiobooks data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains a single set of recordings, though they come from two different sources:\n\nCrowdsourced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yasalma/TatSC_ASR.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"TatSC_ASR","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/TatSC_ASR","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\n\t\n\t\t\n\t\tTatar Speech Corpus ASR\n\t\n\n[Original repository] [Original site]\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTatar Speech Corpus ASR is a speech dataset sourced from this GitHub repository. TatSC contains 269.1 hours of transcribed speech with 271,914 utterances. It is the first open-source Tatar speech corpus covering both crowdsourced and audiobooks data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains a single set of recordings, though they come from two different sources:\n\nCrowdsourced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yasalma/TatSC_ASR.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"lomwe-speech-text","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/lomwe-speech-text","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tLomwe Speech-Text Parallel Dataset\n\t\n\nThis dataset is a collection of aligned audio-text pairs in Lomwe, extracted from the CMU Wilderness dataset. It is useful for tasks such as:\n\nSpeech recognition (ASR)\nText-to-speech (TTS)\nLanguage modeling for low-resource languages\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry in the dataset contains:\n\naudio: A .wav file sampled at 16kHz\ntext: A transcription of the spoken audio in Lomwe (digits removed)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\t\n\t\t\naudio\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/lomwe-speech-text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","audio-intent-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"tat_hackathon_asr","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/tat_hackathon_asr","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\n\t\n\t\t\n\t\tHackathon Tatar ASR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHackathon Tatar ASR is a speech dataset distributed during the \"–¢–∞—Ç–∞—Ä.–ë—É –•–∞–∫–∞—Ç–æ–Ω\" (Tatar.Bu Hackathon) held in Tatarstan in May 2024. This dataset likely consists of newly collected crowdsourced recordings created after the last release of TatSC (Tatar Speech Corpus), although some intersections with TatSC might be present. While TatSC contains 269.1 hours of transcribed speech with 271,914 utterances, this hackathon dataset comprises‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yasalma/tat_hackathon_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"tat_hackathon_asr","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/tat_hackathon_asr","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\n\t\n\t\t\n\t\tHackathon Tatar ASR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHackathon Tatar ASR is a speech dataset distributed during the \"–¢–∞—Ç–∞—Ä.–ë—É –•–∞–∫–∞—Ç–æ–Ω\" (Tatar.Bu Hackathon) held in Tatarstan in May 2024. This dataset likely consists of newly collected crowdsourced recordings created after the last release of TatSC (Tatar Speech Corpus), although some intersections with TatSC might be present. While TatSC contains 269.1 hours of transcribed speech with 271,914 utterances, this hackathon dataset comprises‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yasalma/tat_hackathon_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Hin_Fem_Orpheus","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sk1382/Hin_Fem_Orpheus","creator_name":"Srivathsava","creator_url":"https://huggingface.co/Sk1382","description":"Sk1382/Hin_Fem_Orpheus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TheNOexistenceNofyouANDme-Lilith-Chinese","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TraceAI/TheNOexistenceNofyouANDme-Lilith-Chinese","creator_name":"daiaiwei","creator_url":"https://huggingface.co/TraceAI","description":"\n„Ää‰∏ç/Â≠òÂú®ÁöÑ‰Ω†ÔºåÂíåÊàë„Äã/ (The NOexistenceN of you AND me)\nÂ∑≤Â∞ÜËæÉÈïøÁöÑÈü≥È¢ëÂàáÊàê10Áßí‰ª•ÂÜÖÁöÑÁâáÊÆµÔºåÊñπ‰æøËÆ≠ÁªÉ„ÄÇTranscriptÊñá‰ª∂‰∏≠ÁöÑËØ≠Èü≥ÊñáÊú¨ÊØèÊù°ÂùáÂ∑≤Ê†°ÂØπ„ÄÇ\nI have split the longer audio into segments of less than 10 seconds for easier training. The speech texts in the Transcript file have been proofread for each entry.\n\n\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"warrungu-dictionary","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/warrungu/warrungu-dictionary","creator_name":"Christopher morganson","creator_url":"https://huggingface.co/warrungu","description":"This dataset contains cleaned dictionary and grammar resources for the Warrungu language, compiled from structured CSV files for use in language revitalisation apps and AI tutors.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nCleaned_Warrungu_Dictionary.csv\nwarrungu_flashcards.csv\nwarrungu_suffix_table.csv\n/images/ (Warrungu flashcard images)\n/audio/ (Warrungu flashcard audio)\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCreative Commons Attribution 4.0 International (CC BY 4.0)\n\n\t\n\t\t\n\t\tContact\n\t\n\nMaintained by the Warrungu project team.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/warrungu/warrungu-dictionary.","first_N":5,"first_N_keywords":["translation","human-annotated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"gigaspeech2_vie","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/gigaspeech2_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tVietnamse subset of the Gigaspeech2 dataset\n\t\n\nextracted from: https://huggingface.co/datasets/speechcolab/gigaspeech2\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-4.0","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-4.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution 4.0 International (CC-BY-4.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-4.0","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-4.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution 4.0 International (CC-BY-4.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-GPL-2.0","keyword":"audio","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-2.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-GPL-2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the GNU General Public License version 2.0 (GPL-2.0). The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): All asset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-2.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-GPL-2.0","keyword":"audio","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-2.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-GPL-2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the GNU General Public License version 2.0 (GPL-2.0). The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): All asset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-2.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-GPL-3.0","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-3.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-GPL-3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the GNU General Public License version 3.0 (GPL-3.0). The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, and textures along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): All asset descriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-3.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-GPL-3.0","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-3.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-GPL-3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the GNU General Public License version 3.0 (GPL-3.0). The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, and textures along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): All asset descriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-GPL-3.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Hindi-Train","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maverick1713/Hindi-Train","creator_name":"Pratyush","creator_url":"https://huggingface.co/Maverick1713","description":"Maverick1713/Hindi-Train dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"no-filter-raw-NepaliParliamentDSv2","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kiranpantha/no-filter-raw-NepaliParliamentDSv2","creator_name":"Kiran Pantha","creator_url":"https://huggingface.co/kiranpantha","description":"kiranpantha/no-filter-raw-NepaliParliamentDSv2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"audiotest","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Andy2505/audiotest","creator_name":"Andy2505","creator_url":"https://huggingface.co/Andy2505","description":"An audio dataset for test.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"audiotest","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Andy2505/audiotest","creator_name":"Andy2505","creator_url":"https://huggingface.co/Andy2505","description":"An audio dataset for test.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"PersonalHub","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/PersonalHub","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tPersonal Hub: Exploring High-Expressiveness Speech Data through Spatio-Temporal Feature Integration and Model Fine-Tuning\n\t\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nIn this work, we present Personal Hub, a novel framework for mining and utilizing high-expressivity speech data by integrating spatio-temporal context with combinatorial attribute control. At the core of our approach lies a Speech Attribute Matrix, which enables annotators to systematically combine speaker-related features such as age‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/PersonalHub.","first_N":5,"first_N_keywords":["English","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Audio-Txt-LiuTao","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/Audio-Txt-LiuTao","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"REILX/Audio-Txt-LiuTao dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"JavisData-audios","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JavisDiT/JavisData-audios","creator_name":"JavisDiT","creator_url":"https://huggingface.co/JavisDiT","description":"JavisDiT/JavisData-audios dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","100K - 1M","csv","Audio","Tabular"],"keywords_longer_than_N":true},
	{"name":"Iserverdownload","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FASTER123456/Iserverdownload","creator_name":"FASTER","creator_url":"https://huggingface.co/FASTER123456","description":"FASTER123456/Iserverdownload dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ArVoice","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ArVoice","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n  ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis\n\n Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki \n {hawau.toyin, hanan.aldarmaki}@mbzuai.ac.ae \n\n\n    ArVoice is a multi-speaker Modern Standard Arabic (MSA) speech corpus with fully diacritized transcriptions, intended  for multi-speaker speech synthesis, and can be useful for other tasks such as speech-based diacritic restoration, voice conversion, and deepfake detection.  \n      ArVoice‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ArVoice.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ArVoice","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ArVoice","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n  ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis\n\n Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki \n {hawau.toyin, hanan.aldarmaki}@mbzuai.ac.ae \n\n\n    ArVoice is a multi-speaker Modern Standard Arabic (MSA) speech corpus with fully diacritized transcriptions, intended  for multi-speaker speech synthesis, and can be useful for other tasks such as speech-based diacritic restoration, voice conversion, and deepfake detection.  \n      ArVoice‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ArVoice.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"inat_sounds","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/taozi555/inat_sounds","creator_name":"Taojiang","creator_url":"https://huggingface.co/taozi555","description":"taozi555/inat_sounds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"panas-music","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DRDELATV/panas-music","creator_name":"IGNACIO TAPIA","creator_url":"https://huggingface.co/DRDELATV","description":"DRDELATV/panas-music dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Video"],"keywords_longer_than_N":true},
	{"name":"kasem-speech-text-parallel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tKasem Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 75990 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 75990 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"wenetspeech-subset-S","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pengyizhou/wenetspeech-subset-S","creator_name":"pengyizhou","creator_url":"https://huggingface.co/pengyizhou","description":"pengyizhou/wenetspeech-subset-S dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"vai-speech-text-parallel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tVai Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 23286 parallel speech-text pairs for Vai, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vai - vai\nTask: Speech Recognition, Text-to-Speech\nSize: 23286 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vai"],"keywords_longer_than_N":true},
	{"name":"hsb_audio_corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zalozbadev/hsb_audio_corpus","creator_name":"Za≈Ço≈æba za serbski lud","creator_url":"https://huggingface.co/zalozbadev","description":"This is a collection of speech recordings in Upper Sorbian. Several speakers have contributed their voice to this dataset.\nAudio files are stored in subfolders of the sig folder. The corresponding written text can be found at the same path in the trl folder.\nSubfolders are constructed as follows:\nsig/ID_of_resource/ID_of_speaker/recording_session/files.wav\n\nresp.\ntrl/ID_of_resource/ID_of_speaker/recording_session/files.trl\n\nMatching speaker IDs inside different resources indicate the same‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zalozbadev/hsb_audio_corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Upper Sorbian","cc-by-4.0","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"hsb_audio_corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zalozbadev/hsb_audio_corpus","creator_name":"Za≈Ço≈æba za serbski lud","creator_url":"https://huggingface.co/zalozbadev","description":"This is a collection of speech recordings in Upper Sorbian. Several speakers have contributed their voice to this dataset.\nAudio files are stored in subfolders of the sig folder. The corresponding written text can be found at the same path in the trl folder.\nSubfolders are constructed as follows:\nsig/ID_of_resource/ID_of_speaker/recording_session/files.wav\n\nresp.\ntrl/ID_of_resource/ID_of_speaker/recording_session/files.trl\n\nMatching speaker IDs inside different resources indicate the same‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zalozbadev/hsb_audio_corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Upper Sorbian","cc-by-4.0","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"real_music_albums_fs","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NHLOCAL/real_music_albums_fs","creator_name":"NH Local","creator_url":"https://huggingface.co/NHLOCAL","description":"\n\t\n\t\t\n\t\tReal Music Albums FS\n\t\n\nReal Music Albums FS is a structured dataset representing metadata extracted from real-world music album directories in Hebrew. The dataset was created by scanning existing folder structures from personal or archival music collections, typically stored on hard drives or local systems.\nThe data is organized by artist and album, and contains information on individual audio files including file names, sizes, formats, and file hashes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NHLOCAL/real_music_albums_fs.","first_N":5,"first_N_keywords":["feature-extraction","Hebrew","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"real_music_albums_fs","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NHLOCAL/real_music_albums_fs","creator_name":"NH Local","creator_url":"https://huggingface.co/NHLOCAL","description":"\n\t\n\t\t\n\t\tReal Music Albums FS\n\t\n\nReal Music Albums FS is a structured dataset representing metadata extracted from real-world music album directories in Hebrew. The dataset was created by scanning existing folder structures from personal or archival music collections, typically stored on hard drives or local systems.\nThe data is organized by artist and album, and contains information on individual audio files including file names, sizes, formats, and file hashes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NHLOCAL/real_music_albums_fs.","first_N":5,"first_N_keywords":["feature-extraction","Hebrew","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"nug_myanmar_asr","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/nug_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t366 Hours NUG Myanmar ASR Dataset\n\t\n\nThe NUG Myanmar ASR Dataset is the first large-scale open Burmese speech dataset ‚Äî now expanded to over 521,476 audio-text pairs, totaling ~366 hours of clean, segmented audio. All data was collected from public-service educational broadcasts by the National Unity Government (NUG) of Myanmar and the FOEIM Academy.\nThis dataset is released under a CC0 1.0 Universal license ‚Äî fully open and public domain. No attribution required.\n\n\t\n\t\t\n\t\n\t\n\t\tüïäÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/nug_myanmar_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"nug_myanmar_asr","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/nug_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t366 Hours NUG Myanmar ASR Dataset\n\t\n\nThe NUG Myanmar ASR Dataset is the first large-scale open Burmese speech dataset ‚Äî now expanded to over 521,476 audio-text pairs, totaling ~366 hours of clean, segmented audio. All data was collected from public-service educational broadcasts by the National Unity Government (NUG) of Myanmar and the FOEIM Academy.\nThis dataset is released under a CC0 1.0 Universal license ‚Äî fully open and public domain. No attribution required.\n\n\t\n\t\t\n\t\n\t\n\t\tüïäÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/nug_myanmar_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"nug_myanmar_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/nug_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t366 Hours NUG Myanmar ASR Dataset\n\t\n\nThe NUG Myanmar ASR Dataset is the first large-scale open Burmese speech dataset ‚Äî now expanded to over 521,476 audio-text pairs, totaling ~366 hours of clean, segmented audio. All data was collected from public-service educational broadcasts by the National Unity Government (NUG) of Myanmar and the FOEIM Academy.\nThis dataset is released under a CC0 1.0 Universal license ‚Äî fully open and public domain. No attribution required.\n\n\t\n\t\t\n\t\n\t\n\t\tüïäÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/nug_myanmar_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"nug_myanmar_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/nug_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t366 Hours NUG Myanmar ASR Dataset\n\t\n\nThe NUG Myanmar ASR Dataset is the first large-scale open Burmese speech dataset ‚Äî now expanded to over 521,476 audio-text pairs, totaling ~366 hours of clean, segmented audio. All data was collected from public-service educational broadcasts by the National Unity Government (NUG) of Myanmar and the FOEIM Academy.\nThis dataset is released under a CC0 1.0 Universal license ‚Äî fully open and public domain. No attribution required.\n\n\t\n\t\t\n\t\n\t\n\t\tüïäÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/nug_myanmar_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"common_voices_21_mn","keyword":"audio","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/btsee/common_voices_21_mn","creator_name":"Battseren Badral","creator_url":"https://huggingface.co/btsee","description":"btsee/common_voices_21_mn dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Mongolian","mpl-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"zia-mohiuyo-din","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ReySajju742/zia-mohiuyo-din","creator_name":"Muhammad Sajjad Rasool","creator_url":"https://huggingface.co/ReySajju742","description":"\n\t\n\t\t\n\t\tZia Mohiuddin Speech Corpus\n\t\n\nThis dataset contains audio clips and transcriptions of speeches by Zia Mohiuddin. Each audio file is paired with transcriptions in Urdu script, English, and Roman Urdu. The dataset is suitable for tasks such as automatic speech recognition (ASR), machine translation, and multilingual speech processing.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudio_data/: Contains audio clips in MP3 format (e.g., clip_0001.mp3).\nall_transcriptions_summary.csv: CSV file with the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReySajju742/zia-mohiuyo-din.","first_N":5,"first_N_keywords":["text-classification","Urdu","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"ToneWebinars","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/ToneWebinars","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tToneWebinars\n\t\n\nToneWebinars ‚Äî —ç—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è ZeroAgency/shkolkovo-bobr.video-webinars-audio.\n–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –±—ã–ª–∏ –ø–µ—Ä–µ–ø–∞–∫–æ–≤—ã–Ω—ã –≤ parquet —Ñ–æ—Ä–º–∞—Ç —Å –Ω–∞—Ä–µ–∑–∫–æ–π –ø–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–Ω—ã–º —Ç–∞–∫–º–∫–æ–¥–∞–º. –í –¥–∞—Ç–∞—Å–µ—Ç–µ 2053.55 —á–∞—Å–∞ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 154.34 –¥–ª—è validation.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –ø—Ä–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ MP3-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (sample_rate)\n\n\n\n\t\n\t\t\n\t\t–§–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–∏ (JSON)\n\t\n\n{\n  \"audio\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneWebinars.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ahead_ds_unmixed","keyword":"audio-classification","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hzhongresearch/ahead_ds_unmixed","creator_name":"Henry Zhong","creator_url":"https://huggingface.co/hzhongresearch","description":"\n\t\n\t\t\n\t\tAnother HEaring AiD DataSet (AHEAD-DS) unmixed\n\t\n\nAnother HEaring AiD DataSet (AHEAD-DS) unmixed is an audio dataset labelled with audiologically relevant scene categories for hearing aids. This dataset contains the environment and speech sounds before they were mixed. The file ahead_ds_unmixed.csv documents the details of every file.\n\n\t\n\t\t\n\t\tDescription of data\n\t\n\nAll files are encoded as single channel WAV, 16 bit signed, sampled at 16 kHz with 10 seconds per recording.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hzhongresearch/ahead_ds_unmixed.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-sa-4.0","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ahead_ds_unmixed","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hzhongresearch/ahead_ds_unmixed","creator_name":"Henry Zhong","creator_url":"https://huggingface.co/hzhongresearch","description":"\n\t\n\t\t\n\t\tAnother HEaring AiD DataSet (AHEAD-DS) unmixed\n\t\n\nAnother HEaring AiD DataSet (AHEAD-DS) unmixed is an audio dataset labelled with audiologically relevant scene categories for hearing aids. This dataset contains the environment and speech sounds before they were mixed. The file ahead_ds_unmixed.csv documents the details of every file.\n\n\t\n\t\t\n\t\tDescription of data\n\t\n\nAll files are encoded as single channel WAV, 16 bit signed, sampled at 16 kHz with 10 seconds per recording.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hzhongresearch/ahead_ds_unmixed.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-sa-4.0","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ahead_ds_unmixed","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hzhongresearch/ahead_ds_unmixed","creator_name":"Henry Zhong","creator_url":"https://huggingface.co/hzhongresearch","description":"\n\t\n\t\t\n\t\tAnother HEaring AiD DataSet (AHEAD-DS) unmixed\n\t\n\nAnother HEaring AiD DataSet (AHEAD-DS) unmixed is an audio dataset labelled with audiologically relevant scene categories for hearing aids. This dataset contains the environment and speech sounds before they were mixed. The file ahead_ds_unmixed.csv documents the details of every file.\n\n\t\n\t\t\n\t\tDescription of data\n\t\n\nAll files are encoded as single channel WAV, 16 bit signed, sampled at 16 kHz with 10 seconds per recording.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hzhongresearch/ahead_ds_unmixed.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-sa-4.0","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"deg-speech-text-parallel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tDeg Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 125958 parallel speech-text pairs for Deg, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Deg - mzw\nTask: Speech Recognition, Text-to-Speech\nSize: 125958 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Deg"],"keywords_longer_than_N":true},
	{"name":"sage-voice-pt-br","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/srxz/sage-voice-pt-br","creator_name":"RC","creator_url":"https://huggingface.co/srxz","description":"Dataset usado para treinar a voz da Sage (Valorant)\nGera√ß√£o do metadata.csv:\nRodar: whisper.sh em seguida transcrib.sh, isso produzira um txt com todas falas pronto para ser utilizado no treinamento com piper\n\n\n\t\n\t\t\n\t\tlicense: mit\n\t\n\n","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"vyse-voice-pt-br","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/srxz/vyse-voice-pt-br","creator_name":"RC","creator_url":"https://huggingface.co/srxz","description":"Dataset usado para treinar a voz da Vyse (Valorant)\nGera√ß√£o do metadata.csv:\nRodar: whisper.sh em seguida transcrib.sh, isso produzira um txt com todas falas pronto para ser utilizado no treinamento com piper\n","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Islandboys1","keyword":"audio-to-audio","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Mi6paulino/Islandboys1","creator_name":"Michael Paulino","creator_url":"https://huggingface.co/Mi6paulino","description":"{init}Hexo.js\nNodes= [XKrazyaces602x] -convert\n~hp\nCOMPILE=#michaelpaulino\nconfig// \nimply [format1-10]\n1=<articleS/24+b20>/h1>\n2=<section25+c300>/3Querty/>\n3=h2<eventsource=820=/nquery<center/h3>\n4=x<progress=1\nx=wbr\n\nvscode -june 2 2025 {section b /2 \n   *).append(offset);\n\n\n","first_N":5,"first_N_keywords":["token-classification","fill-mask","table-question-answering","text-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"persian-voice-v1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vhdm/persian-voice-v1","creator_name":"Vahid Mahmoudian","creator_url":"https://huggingface.co/vhdm","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Common Voice 17 ‚Äî Persian (Spelling-Corrected Edition)\n\t\n\nThis is a refined version of the Persian subset of Mozilla's Common Voice 17 dataset, specially curated to enhance the performance of ASR (Automatic Speech Recognition) systems in Persian.\n\n\t\n\t\t\n\t\tüõ†Ô∏è Why this matters\n\t\n\nThe original dataset contained a significant number of spelling inconsistencies and typographical errors, which negatively impacted transcription accuracy and model alignment.\n\n\t\n\t\t\n\t\t‚ú® What‚Äôs improved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vhdm/persian-voice-v1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"persian-voice-v1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vhdm/persian-voice-v1","creator_name":"Vahid Mahmoudian","creator_url":"https://huggingface.co/vhdm","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Common Voice 17 ‚Äî Persian (Spelling-Corrected Edition)\n\t\n\nThis is a refined version of the Persian subset of Mozilla's Common Voice 17 dataset, specially curated to enhance the performance of ASR (Automatic Speech Recognition) systems in Persian.\n\n\t\n\t\t\n\t\tüõ†Ô∏è Why this matters\n\t\n\nThe original dataset contained a significant number of spelling inconsistencies and typographical errors, which negatively impacted transcription accuracy and model alignment.\n\n\t\n\t\t\n\t\t‚ú® What‚Äôs improved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vhdm/persian-voice-v1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"mbspeech_mn","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/btsee/mbspeech_mn","creator_name":"Battseren Badral","creator_url":"https://huggingface.co/btsee","description":"\n\t\n\t\t\n\t\tMBSpeech MN: Mongolian Biblical Speech Dataset\n\t\n\nMBSpeech MN is a Mongolian text-to-speech (TTS) dataset derived from biblical texts. It consists of aligned audio recordings and corresponding sentences in Mongolian. The dataset is suitable for training TTS models and other speech processing applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n  Language: Mongolian (mn)\n  Task: Text-to-Speech (TTS)\n  License: MIT\n  Size:\n  Download size: ~721 MB\n\n  Dataset size: ~822 MB\n\n  Examples: 3,846‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/btsee/mbspeech_mn.","first_N":5,"first_N_keywords":["text-to-speech","Mongolian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mbspeech_mn","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/btsee/mbspeech_mn","creator_name":"Battseren Badral","creator_url":"https://huggingface.co/btsee","description":"\n\t\n\t\t\n\t\tMBSpeech MN: Mongolian Biblical Speech Dataset\n\t\n\nMBSpeech MN is a Mongolian text-to-speech (TTS) dataset derived from biblical texts. It consists of aligned audio recordings and corresponding sentences in Mongolian. The dataset is suitable for training TTS models and other speech processing applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n  Language: Mongolian (mn)\n  Task: Text-to-Speech (TTS)\n  License: MIT\n  Size:\n  Download size: ~721 MB\n\n  Dataset size: ~822 MB\n\n  Examples: 3,846‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/btsee/mbspeech_mn.","first_N":5,"first_N_keywords":["text-to-speech","Mongolian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"myanmar-english-accent-speech","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/myanmar-english-accent-speech","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tMyanmar English Accent Speech (PVTV & FOEIM)\n\t\n\nThis dataset contains English speech by Myanmar speakers, collected from public videos published by PVTV and FOEIM ‚Äî two media channels operating under the National Unity Government (NUG).\nThe clips reflect a wide range of spoken English contexts: interviews, announcements, sermons, and educational content. The speakers vary in tone, pace, and emotion ‚Äî but all share the characteristic sound of Burmese-accented English.\nThis dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/myanmar-english-accent-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc0-1.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"myanmar-english-accent-speech","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/myanmar-english-accent-speech","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tMyanmar English Accent Speech (PVTV & FOEIM)\n\t\n\nThis dataset contains English speech by Myanmar speakers, collected from public videos published by PVTV and FOEIM ‚Äî two media channels operating under the National Unity Government (NUG).\nThe clips reflect a wide range of spoken English contexts: interviews, announcements, sermons, and educational content. The speakers vary in tone, pace, and emotion ‚Äî but all share the characteristic sound of Burmese-accented English.\nThis dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/myanmar-english-accent-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc0-1.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"gigademan_denoise","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duyynh/gigademan_denoise","creator_name":"Do Phu Duy","creator_url":"https://huggingface.co/Duyynh","description":"Duyynh/gigademan_denoise dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"rohini-orpheus-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Rohini076/rohini-orpheus-dataset","creator_name":"Rohini Koli","creator_url":"https://huggingface.co/Rohini076","description":"Rohini076/rohini-orpheus-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Chinese-Dialogue-180k-Instruct-Audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CJY/Chinese-Dialogue-180k-Instruct-Audio","creator_name":"‰øäÊ¥ã Èôà","creator_url":"https://huggingface.co/CJY","description":"CJY/Chinese-Dialogue-180k-Instruct-Audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"listening_test","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ttsds/listening_test","creator_name":"TTS Distribution Score","creator_url":"https://huggingface.co/ttsds","description":"\n\t\n\t\t\n\t\tListening Test Results for TTSDS2\n\t\n\nThis dataset contains all 11,000+ ratings collected for 20 synthetic speech systems for the TTSDS2 study (link coming soon).\nThe scores are MOS (Mean Opinion Score), CMOS (Comparative Mean Opinion Score) and SMOS (Speaker Similarity Mean Opinion Score).\nAll annotators included passed three attention checks throughout the survey.\n","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"listening_test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ttsds/listening_test","creator_name":"TTS Distribution Score","creator_url":"https://huggingface.co/ttsds","description":"\n\t\n\t\t\n\t\tListening Test Results for TTSDS2\n\t\n\nThis dataset contains all 11,000+ ratings collected for 20 synthetic speech systems for the TTSDS2 study (link coming soon).\nThe scores are MOS (Mean Opinion Score), CMOS (Comparative Mean Opinion Score) and SMOS (Speaker Similarity Mean Opinion Score).\nAll annotators included passed three attention checks throughout the survey.\n","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"listening_test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ttsds/listening_test","creator_name":"TTS Distribution Score","creator_url":"https://huggingface.co/ttsds","description":"\n\t\n\t\t\n\t\tListening Test Results for TTSDS2\n\t\n\nThis dataset contains all 11,000+ ratings collected for 20 synthetic speech systems for the TTSDS2 study (link coming soon).\nThe scores are MOS (Mean Opinion Score), CMOS (Comparative Mean Opinion Score) and SMOS (Speaker Similarity Mean Opinion Score).\nAll annotators included passed three attention checks throughout the survey.\n","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AVQA-R1-6K","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/harryhsing/AVQA-R1-6K","creator_name":"Zhenghao Xing","creator_url":"https://huggingface.co/harryhsing","description":"This repository contains data presented in EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning.\nFor training and inference, please refer to the Code: https://github.com/HarryHsing/EchoInk\nData Format in AVQA-R1-6K:\n  {\n      \"problem_id\": 0,\n      \"problem\": \"What is the source of the sound in the video?\",\n      \"data_type\": \"image_audio\",\n      \"problem_type\": \"multiple choice\",\n      \"options\": [\n        \"A. motorcycle\",\n        \"B. automobile\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/harryhsing/AVQA-R1-6K.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"Multi-Frequency_Sine_Wave_Audio_Dataset","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ismielabir/Multi-Frequency_Sine_Wave_Audio_Dataset","creator_name":"Md. Ismiel Hossen Abir","creator_url":"https://huggingface.co/ismielabir","description":"\n\t\n\t\t\n\t\tMulti-Frequency Sine Wave Audio Dataset\n\t\n\nThis dataset contains 43,000 synthetic sine wave audio samples across 43 frequencies (20Hz to 10kHz), with 1,000 unique 5-second WAV samples per frequency.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Samples: 43,000\nDuration: 5 seconds per file\nSample Rate: 44.1 kHz (CD quality)\nBit Depth: 16-bit PCM\nAmplitude: 0.5 (-6 dBFS)\nFrequencies: 20Hz to 10,000Hz\n\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nAudio signal processing\nMachine learning model training\nFrequency detection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ismielabir/Multi-Frequency_Sine_Wave_Audio_Dataset.","first_N":5,"first_N_keywords":["audio-classification","mit","10K<n<100K","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Multi-Frequency_Sine_Wave_Audio_Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ismielabir/Multi-Frequency_Sine_Wave_Audio_Dataset","creator_name":"Md. Ismiel Hossen Abir","creator_url":"https://huggingface.co/ismielabir","description":"\n\t\n\t\t\n\t\tMulti-Frequency Sine Wave Audio Dataset\n\t\n\nThis dataset contains 43,000 synthetic sine wave audio samples across 43 frequencies (20Hz to 10kHz), with 1,000 unique 5-second WAV samples per frequency.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Samples: 43,000\nDuration: 5 seconds per file\nSample Rate: 44.1 kHz (CD quality)\nBit Depth: 16-bit PCM\nAmplitude: 0.5 (-6 dBFS)\nFrequencies: 20Hz to 10,000Hz\n\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nAudio signal processing\nMachine learning model training\nFrequency detection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ismielabir/Multi-Frequency_Sine_Wave_Audio_Dataset.","first_N":5,"first_N_keywords":["audio-classification","mit","10K<n<100K","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Multi-Frequency_Sine_Wave_Audio_Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ismielabir/Multi-Frequency_Sine_Wave_Audio_Dataset","creator_name":"Md. Ismiel Hossen Abir","creator_url":"https://huggingface.co/ismielabir","description":"\n\t\n\t\t\n\t\tMulti-Frequency Sine Wave Audio Dataset\n\t\n\nThis dataset contains 43,000 synthetic sine wave audio samples across 43 frequencies (20Hz to 10kHz), with 1,000 unique 5-second WAV samples per frequency.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Samples: 43,000\nDuration: 5 seconds per file\nSample Rate: 44.1 kHz (CD quality)\nBit Depth: 16-bit PCM\nAmplitude: 0.5 (-6 dBFS)\nFrequencies: 20Hz to 10,000Hz\n\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nAudio signal processing\nMachine learning model training\nFrequency detection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ismielabir/Multi-Frequency_Sine_Wave_Audio_Dataset.","first_N":5,"first_N_keywords":["audio-classification","mit","10K<n<100K","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"clone","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emmylahot12/clone","creator_name":"Aneleemmanuel0","creator_url":"https://huggingface.co/Emmylahot12","description":"Emmylahot12/clone dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"audio_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sandhya2002/audio_dataset","creator_name":"Sandhya S","creator_url":"https://huggingface.co/Sandhya2002","description":"Sandhya2002/audio_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"NPTL_Filtered_Datasets","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FariqF/NPTL_Filtered_Datasets","creator_name":"Fariq Rahman","creator_url":"https://huggingface.co/FariqF","description":"FariqF/NPTL_Filtered_Datasets dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TTS-Multilingual-Test-Set","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MiniMaxAI/TTS-Multilingual-Test-Set","creator_name":"MiniMax","creator_url":"https://huggingface.co/MiniMaxAI","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nTo assess the multilingual zero-shot voice cloning capabilities of TTS models, we have constructed a test set encompassing 24 languages. This dataset provides both audio samples for voice cloning and corresponding test texts.\nSpecifically, the test set for each language includes:\n100 distinct test sentences.\nAudio samples from two speakers (one male and one female) carefully selected from the Mozilla Common Voice (MCV) dataset, intended for voice cloning.\nResearchers can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MiniMaxAI/TTS-Multilingual-Test-Set.","first_N":5,"first_N_keywords":["text-to-speech","cc-by-sa-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"msd_dmelodies_wav","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TalBarami/msd_dmelodies_wav","creator_name":"Tal Barami","creator_url":"https://huggingface.co/TalBarami","description":"\n\t\n\t\t\n\t\tMSD dMelodies-WAV Dataset Attribution\n\t\n\nThe Multi-factor Sequential Disentanglement benchmark includes the dMelodies-WAV dataset, a synthetically generated collection of 48,000-sample audio waveforms labeled with one static factor (instrument) and five dynamic musical attributes.\nExtending the symbolic dMelodies benchmark into the raw audio domain, dMelodies-WAV was created by synthesizing a subset of dMelodies using the MIDI-DDSP neural audio synthesis model, producing realistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TalBarami/msd_dmelodies_wav.","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"carlos_french_10_may","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/carlos_french_10_may","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/carlos_french_10_may dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts_english_may_10","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/tts_english_may_10","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/tts_english_may_10 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian\n\t\n\nThis is a dataset with Russian audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian\", split=\"train\")\nprint(dataset[0])\n\n","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian\n\t\n\nThis is a dataset with Russian audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian\", split=\"train\")\nprint(dataset[0])\n\n","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"AudioJailbreak","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/AudioJailbreak","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n\t\n\t\t\n\t\tAudio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models\n\t\n\n\n\n\nAudioJailbreak is a benchmark framework specifically designed for evaluating the security of Audio Language Models (Audio LLMs). This project tests model defenses against malicious requests through various audio perturbation techniques.Note: This project aims to improve the security of audio language models. Researchers should use this tool responsibly.\n\t\n\t\t\n\t\tüìã Table of Contents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/AudioJailbreak.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"mls-eng-128kb","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ntt123/mls-eng-128kb","creator_name":"Th√¥ng Nguy·ªÖn","creator_url":"https://huggingface.co/ntt123","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ntt123/mls-eng-128kb.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-128kb","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ntt123/mls-eng-128kb","creator_name":"Th√¥ng Nguy·ªÖn","creator_url":"https://huggingface.co/ntt123","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ntt123/mls-eng-128kb.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ASA2_dataset","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AnonymousAuthor1/ASA2_dataset","creator_name":"AnonymousAuthor1","creator_url":"https://huggingface.co/AnonymousAuthor1","description":"üéß Auditory Scene Analysis 2 (ASA2) Dataset \n\nWe constructed a new dataset for multichannel USS and polyphonic audio classification tasks. The proposed dataset is designed to reflect various conditions, including moving sources with temporal onsets and offsets. For foreground sound sources, signals from 13 audio classes were selected from open-source databases (Pixabay¬π, FSD50K, Librispeech, MUSDB18, Vocalsound). These signals were resampled to 16 kHz and pre-processed by either padding zeros‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AnonymousAuthor1/ASA2_dataset.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"ASA2_dataset","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AnonymousAuthor1/ASA2_dataset","creator_name":"AnonymousAuthor1","creator_url":"https://huggingface.co/AnonymousAuthor1","description":"üéß Auditory Scene Analysis 2 (ASA2) Dataset \n\nWe constructed a new dataset for multichannel USS and polyphonic audio classification tasks. The proposed dataset is designed to reflect various conditions, including moving sources with temporal onsets and offsets. For foreground sound sources, signals from 13 audio classes were selected from open-source databases (Pixabay¬π, FSD50K, Librispeech, MUSDB18, Vocalsound). These signals were resampled to 16 kHz and pre-processed by either padding zeros‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AnonymousAuthor1/ASA2_dataset.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"common_voice_21.0_br","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/common_voice_21.0_br","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nPartie en breton du jeu de donn√©es Common Voice 21.0.  \n\n\t\n\t\t\n\t\tChamps\n\t\n\n\naudio (dict) : Un dictionnaire contenant le chemin vers le fichier audio t√©l√©charg√©, l'audio d√©cod√© et la fr√©quence d'√©chantillonnage.Notez que lors de l'acc√®s √† la colonne audio : dataset[0][\"audio\"], le fichier audio est automatiquement d√©cod√© et r√©√©chantillonn√© √† dataset.features[\"audio\"].sampling_rate. Le d√©codage et le r√©√©chantillonnage d'un grand nombre de fichiers audio peuvent prendre‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/common_voice_21.0_br.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Breton","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_test_vad","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/guynich/librispeech_asr_test_vad","creator_name":"Guy Nicholson","creator_url":"https://huggingface.co/guynich","description":"Voice Activity Detection (VAD) Test Dataset\nThis dataset is based on the test.clean and test.other splits from the\nlibrispeech_asr\ncorpus. It includes two binary labels:\n\nspeech: Indicates presence of speech ([0, 1]), computed using a dynamic threshold method with background noise estimation and smoothing.\n\nconfidence: A post-processing flag to optionally correct transient dropouts in speech. It is set to 1 by default, but switches to 0 for up to ~0.1 seconds (3 chunks of audio) following a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guynich/librispeech_asr_test_vad.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MMMG","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UW-FMRL2/MMMG","creator_name":"Foundation Model and RL Research Lab @ UW","creator_url":"https://huggingface.co/UW-FMRL2","description":"\n\t\n\t\t\n\t\tDataset Card for MMMG\n\t\n\n\nWe present MMMG, a comprehensive and human-aligned benchmark for multimodal generation across 4 modality combinations (image, audio, interleaved text and image, interleaved text and audio), with a focus on tasks that present significant challenges for generation models, while still enabling reliable automatic evaluation. \nThis huggingface page only contains the raw dataset of MMMG, for full evaluation suite, please refer to our github page:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UW-FMRL2/MMMG.","first_N":5,"first_N_keywords":["text-to-audio","text-to-image","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"MMMG","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UW-FMRL2/MMMG","creator_name":"Foundation Model and RL Research Lab @ UW","creator_url":"https://huggingface.co/UW-FMRL2","description":"\n\t\n\t\t\n\t\tDataset Card for MMMG\n\t\n\n\nWe present MMMG, a comprehensive and human-aligned benchmark for multimodal generation across 4 modality combinations (image, audio, interleaved text and image, interleaved text and audio), with a focus on tasks that present significant challenges for generation models, while still enabling reliable automatic evaluation. \nThis huggingface page only contains the raw dataset of MMMG, for full evaluation suite, please refer to our github page:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UW-FMRL2/MMMG.","first_N":5,"first_N_keywords":["text-to-audio","text-to-image","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"diarizations","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pushthetempo/diarizations","creator_name":"Name","creator_url":"https://huggingface.co/pushthetempo","description":"\n\t\n\t\t\n\t\tDiarizations Dataset\n\t\n\nAggregated speaker segmentation outputs.\n\n\t\n\t\t\n\t\tVideos\n\t\n\n\n\t\n\t\t\n\t\tecx7ywj89m4\n\t\n\n\nSegments: 54\nSpeakers: SPEAKER_00, SPEAKER_01\nDuration: 2369.59s\n\n\n\t\n\t\t\n\t\tConfig\n\t\n\n\nTrimmed: none\nDiarize model: pyannote/speaker-diarization\nASR model: akuzdeuov/whisper-base.kk chunk 30s, lang kk\nBatch: 16\n\n\n\t\n\t\t\n\t\tFWmr-zrGK_w\n\t\n\n\nSegments: 206\nSpeakers: SPEAKER_00, SPEAKER_01, SPEAKER_02\nDuration: 3071.74s\n\n\n\t\n\t\t\n\t\tConfig\n\t\n\n\nTrimmed: none\nDiarize model:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pushthetempo/diarizations.","first_N":5,"first_N_keywords":["Kazakh","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"flusense","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vtsouval/flusense","creator_name":"Vasileios Tsouvalas","creator_url":"https://huggingface.co/vtsouval","description":"\n\t\n\t\t\n\t\tFluSense\n\t\n\nFluSense is a dataset of segmented audio events derived from the FluSense platform, a contactless influenza-like illness surveillance system.\nThis dataset is intended for use in flu symptom detection.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample includes:\n\naudio: audio segment (waveform and sampling rate)\nlabel: string label (e.g., \"cough\", \"speech\", etc.)\n\n\n\t\n\t\t\n\t\tLabels\n\t\n\nThe dataset includes the following sound event classes:\n\ncough\nsneeze\nsniffle\nspeech\nsilence‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vtsouval/flusense.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","expert-generated","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"flusense","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vtsouval/flusense","creator_name":"Vasileios Tsouvalas","creator_url":"https://huggingface.co/vtsouval","description":"\n\t\n\t\t\n\t\tFluSense\n\t\n\nFluSense is a dataset of segmented audio events derived from the FluSense platform, a contactless influenza-like illness surveillance system.\nThis dataset is intended for use in flu symptom detection.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample includes:\n\naudio: audio segment (waveform and sampling rate)\nlabel: string label (e.g., \"cough\", \"speech\", etc.)\n\n\n\t\n\t\t\n\t\tLabels\n\t\n\nThe dataset includes the following sound event classes:\n\ncough\nsneeze\nsniffle\nspeech\nsilence‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vtsouval/flusense.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","expert-generated","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Chinese-Dialogue-180k","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CJY/Chinese-Dialogue-180k","creator_name":"‰øäÊ¥ã Èôà","creator_url":"https://huggingface.co/CJY","description":"CJY/Chinese-Dialogue-180k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Chinese-Dialogue-180k-Sample","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CJY/Chinese-Dialogue-180k-Sample","creator_name":"‰øäÊ¥ã Èôà","creator_url":"https://huggingface.co/CJY","description":"CJY/Chinese-Dialogue-180k-Sample dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"evals-wav2vec2-xlsr-53-ft-cv99-cy","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DewiBrynJones/evals-wav2vec2-xlsr-53-ft-cv99-cy","creator_name":"Dewi Bryn Jones","creator_url":"https://huggingface.co/DewiBrynJones","description":"Model: DewiBrynJones/wav2vec2-xlsr-53-ft-cv99-cy\nTest Set: techiaith/commonvoice_18_0_cy\nSplit: test\n\nWER: 10.511980\nCER: 2.808515\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ASR_fa_v1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nezamisafa/ASR_fa_v1","creator_name":"safa","creator_url":"https://huggingface.co/nezamisafa","description":"nezamisafa/ASR_fa_v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"lleisiau-arfor","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cymen-arfor/lleisiau-arfor","creator_name":"Prosiect Arfor Cymen","creator_url":"https://huggingface.co/cymen-arfor","description":"See below for English\n\n\t\n\t\t\n\t\tLleisiau ARFOR\n\t\n\nCafodd y set ddata hon ei chreu gan Cymen fel rhan o brosiect a ariannwyd gan ARFOR ar y cyd √¢‚Äôr Uned Technolegau Iaith ym Mhrifysgol Bangor.‚ÄØ‚ÄØ \nNod y prosiect oedd casglu llawer iawn o ddata llafar Cymraeg o ansawdd uchel, ynghyd √¢‚Äôu trawsgrifiadau cyfatebol, gan ganolbwyntio‚Äôn benodol ar iaith anffurfiol, sgyrsiol a digymell o ardal Arfor. Bydd y set ddata sy‚Äôn deillio ohoni wedyn yn cael ei defnyddio i wella technoleg adnabod llais yng Nghymru‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cymen-arfor/lleisiau-arfor.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Welsh","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"wav2vec2-vd-bird-sound-classification-dataset","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/greenarcade/wav2vec2-vd-bird-sound-classification-dataset","creator_name":"Suvan Gowri Shanker","creator_url":"https://huggingface.co/greenarcade","description":"greenarcade/wav2vec2-vd-bird-sound-classification-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"wav2vec2-vd-bird-sound-classification-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/greenarcade/wav2vec2-vd-bird-sound-classification-dataset","creator_name":"Suvan Gowri Shanker","creator_url":"https://huggingface.co/greenarcade","description":"greenarcade/wav2vec2-vd-bird-sound-classification-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Sonidos","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Eldongarrizon/Sonidos","creator_name":"garrizon","creator_url":"https://huggingface.co/Eldongarrizon","description":"Eldongarrizon/Sonidos dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to download‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to download‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"tg-voices-uk","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/tg-voices-uk","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\n\t\n\t\t\n\t\tAn ASR Corpus created using a Telegram bot for Ukrainian\n\t\n\nThis repository contains the corpus of human recordings they made using a Telegram bot - https://t.me/asr_corpus_bot - for the task of Automatic Speech Recognition for Ukrainian.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\nSee other Ukrainian models: https://github.com/egorsmkv/speech-recognition-uk‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/tg-voices-uk.","first_N":5,"first_N_keywords":["Ukrainian","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"CSEU-Bench","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smart9/CSEU-Bench","creator_name":"Qiuchi Li","creator_url":"https://huggingface.co/smart9","description":"\n\t\n\t\t\n\t\tChinese Speech Emotional Understanding Benchmark (CSEU-Bench)\n\t\n\n\nThe benchmark aims to evaluate the ability of understanding psycho-linguistic emotion labels in Chinese speech. It contains Chinese speech audios with diverse syntactic structures, and 83 psycho-linguistic emotion entities as classification labels.\n\nGithub: https://github.com/qiuchili/CSEU-Bench\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tCSEU-Bench Components:\n\t\n\n\nCSEU-Bench.csv: all speech samples\nCSEU-monosyllabic.csv: speech samples with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smart9/CSEU-Bench.","first_N":5,"first_N_keywords":["audio-classification","Chinese","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"CSEU-Bench","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smart9/CSEU-Bench","creator_name":"Qiuchi Li","creator_url":"https://huggingface.co/smart9","description":"\n\t\n\t\t\n\t\tChinese Speech Emotional Understanding Benchmark (CSEU-Bench)\n\t\n\n\nThe benchmark aims to evaluate the ability of understanding psycho-linguistic emotion labels in Chinese speech. It contains Chinese speech audios with diverse syntactic structures, and 83 psycho-linguistic emotion entities as classification labels.\n\nGithub: https://github.com/qiuchili/CSEU-Bench\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tCSEU-Bench Components:\n\t\n\n\nCSEU-Bench.csv: all speech samples\nCSEU-monosyllabic.csv: speech samples with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smart9/CSEU-Bench.","first_N":5,"first_N_keywords":["audio-classification","Chinese","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Sphere360","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omniaudio/Sphere360","creator_name":"omniaudio-360v2sa","creator_url":"https://huggingface.co/omniaudio","description":"\n\t\n\t\t\n\t\tSphere360\n\t\n\nSphere360 is a comprehensive dataset of paired 360-degree videos and spatial audio content sourced from YouTube. The collection contains over 103,000 matched 360-degree video and audio clips, representing a total of 288 hours of immersive content. This repository includes both the curated dataset and the essential web crawling and data processing tools used for its compilation.\n\nSphere360\nCopyright\nDataset Split\nToolset Environment\nPython Environment\nYouTube API\nFFmpeg‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omniaudio/Sphere360.","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","text","Text","Audio"],"keywords_longer_than_N":true},
	{"name":"Sphere360","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omniaudio/Sphere360","creator_name":"omniaudio-360v2sa","creator_url":"https://huggingface.co/omniaudio","description":"\n\t\n\t\t\n\t\tSphere360\n\t\n\nSphere360 is a comprehensive dataset of paired 360-degree videos and spatial audio content sourced from YouTube. The collection contains over 103,000 matched 360-degree video and audio clips, representing a total of 288 hours of immersive content. This repository includes both the curated dataset and the essential web crawling and data processing tools used for its compilation.\n\nSphere360\nCopyright\nDataset Split\nToolset Environment\nPython Environment\nYouTube API\nFFmpeg‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omniaudio/Sphere360.","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","text","Text","Audio"],"keywords_longer_than_N":true},
	{"name":"WanJuanSiLu-Multimodal-5Languages","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opendatalab/WanJuanSiLu-Multimodal-5Languages","creator_name":"OpenDataLab","creator_url":"https://huggingface.co/opendatalab","description":"\n\t\n\t\t\n\t\tWanJuan¬∑SiLu Multimodal Multilingual Corpus\n\t\n\n\n\t\n\t\t\n\t\tüåèDataset Introduction\n\t\n\nThe newly upgraded \"Wanjuan¬∑Silk Road Multimodal Corpus\" brings the following three core improvements:\n\nThe number of languages has been significantly expanded: Based on the five open-source languages ‚Äã‚Äãof \"Wanjuan¬∑Silk Road\", namely Arabic, Russian, Korean, Vietnamese, and Thai, \"Wanjuan¬∑Silk Road Multimodal\" has added three scarce corpus data of Serbian, Hungarian, and Czech, and uses the above eight key‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opendatalab/WanJuanSiLu-Multimodal-5Languages.","first_N":5,"first_N_keywords":["cc-by-4.0","Audio","arxiv:2407.13773","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"emonet-voice-bench","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/t1a5anu-anon/emonet-voice-bench","creator_name":"t1a5anu-anon","creator_url":"https://huggingface.co/t1a5anu-anon","description":"t1a5anu-anon/emonet-voice-bench dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"denes","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Denhotech/denes","creator_name":"Denes Mbezi","creator_url":"https://huggingface.co/Denhotech","description":"\n\t\n\t\t\n\t\tAudio-Text Dataset\n\t\n\nThis dataset contains 1 audio segments with their corresponding text.\n\n\t\n\t\t\n\t\tFormat\n\t\n\n\naudio: Audio files in WAV format\ntext: Corresponding text transcription\n\n\n\t\n\t\t\n\t\tCreated on\n\t\n\n2025-05-16 16:23:37\n","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"mswaha","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Denhotech/mswaha","creator_name":"Denes Mbezi","creator_url":"https://huggingface.co/Denhotech","description":"\n\t\n\t\t\n\t\tAudio-Text Dataset\n\t\n\nThis dataset contains 1 audio segments with their corresponding text.\n\n\t\n\t\t\n\t\tFormat\n\t\n\n\naudio: Audio files in WAV format\ntext: Corresponding text transcription\n\n\n\t\n\t\t\n\t\tCreated on\n\t\n\n2025-05-16 17:14:28\n","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"voxceleb","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alphaqmoi/voxceleb","creator_name":"Victor Kwemoi","creator_url":"https://huggingface.co/alphaqmoi","description":"This dataset includes both VoxCeleb and VoxCeleb2\n\n\t\n\t\t\n\t\tMultipart Zips\n\t\n\nAlready joined zips for convenience but these specified files are NOT part of the original datasets\nvox2_mp4_1.zip - vox2_mp4_6.zip \nvox2_aac_1.zip - vox2_aac_2.zip \n\n\t\n\t\t\n\t\tJoining Zip\n\t\n\ncat vox1_dev* > vox1_dev_wav.zip\n\ncat vox2_dev_aac* > vox2_aac.zip\n\ncat vox2_dev_mp4* > vox2_mp4.zip\n\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@article{Nagrani19,\n    author = \"Arsha Nagrani and Joon~Son Chung and Weidi Xie and Andrew‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alphaqmoi/voxceleb.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","image-classification","video-classification","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V3","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V3","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V3 version and two previous versions (V1|V2):\n\nThis version is built base on Common Voice 21.0 English Subset.\n   This version only includes utterance that are an exact match with the transcription from Whisper V3 LARGE (CER == 0).\n   This version includes the original Common Voice metadata (age, gender, accent, and ID).\n   All audio files in this version are at 24kHz sampling rate.\n   All audio files in this version are unenhanced. (We‚Äôd greatly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V3.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V3","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V3","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V3 version and two previous versions (V1|V2):\n\nThis version is built base on Common Voice 21.0 English Subset.\n   This version only includes utterance that are an exact match with the transcription from Whisper V3 LARGE (CER == 0).\n   This version includes the original Common Voice metadata (age, gender, accent, and ID).\n   All audio files in this version are at 24kHz sampling rate.\n   All audio files in this version are unenhanced. (We‚Äôd greatly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V3.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V3","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V3","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V3 version and two previous versions (V1|V2):\n\nThis version is built base on Common Voice 21.0 English Subset.\n   This version only includes utterance that are an exact match with the transcription from Whisper V3 LARGE (CER == 0).\n   This version includes the original Common Voice metadata (age, gender, accent, and ID).\n   All audio files in this version are at 24kHz sampling rate.\n   All audio files in this version are unenhanced. (We‚Äôd greatly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V3.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V3","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V3","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V3 version and two previous versions (V1|V2):\n\nThis version is built base on Common Voice 21.0 English Subset.\n   This version only includes utterance that are an exact match with the transcription from Whisper V3 LARGE (CER == 0).\n   This version includes the original Common Voice metadata (age, gender, accent, and ID).\n   All audio files in this version are at 24kHz sampling rate.\n   All audio files in this version are unenhanced. (We‚Äôd greatly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V3.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech_test_vad","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/guynich/multilingual_librispeech_test_vad","creator_name":"Guy Nicholson","creator_url":"https://huggingface.co/guynich","description":"Voice Activity Detection (VAD) Test Dataset\nThis dataset is based on the test splits found in\nmultilingual_librispeech\ndataset.  It includes two binary labels:\n\nspeech: Indicates presence of speech ([0, 1]), computed using a dynamic threshold method with background noise estimation and smoothing.\n\nconfidence: A post-processing flag to optionally correct transient dropouts in speech. It is set to 1 by default, but switches to 0 for up to ~0.1 seconds (3 chunks of audio) following a transition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guynich/multilingual_librispeech_test_vad.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Clotho-Moment","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lighthouse-emnlp2024/Clotho-Moment","creator_name":"lighthouse","creator_url":"https://huggingface.co/lighthouse-emnlp2024","description":"\n\t\n\t\t\n\t\tClotho-Moment\n\t\n\nThis repository provides wav files used in Language-based audio moment retrieval.\nEach sample includes long audio containing some audio events with the temporal and textual annotation.\n\n\t\n\t\t\n\t\tSplit\n\t\n\n\nTrain\ntrain/train-{000..715}.tar\n37930 audio samples\n\n\nValid\nvalid/valid-{000..108}.tar\n5741 audio samples\n\n\nTest\ntest/test-{000..142}.tar\n7569 audio samples\n\n\n\n\n\t\n\t\t\n\t\tUsing Webdataset\n\t\n\nimport torch\nimport webdataset as wds\nfrom huggingface_hub import get_token\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lighthouse-emnlp2024/Clotho-Moment.","first_N":5,"first_N_keywords":["text-to-audio","English","apache-2.0","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"Clotho-Moment","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lighthouse-emnlp2024/Clotho-Moment","creator_name":"lighthouse","creator_url":"https://huggingface.co/lighthouse-emnlp2024","description":"\n\t\n\t\t\n\t\tClotho-Moment\n\t\n\nThis repository provides wav files used in Language-based audio moment retrieval.\nEach sample includes long audio containing some audio events with the temporal and textual annotation.\n\n\t\n\t\t\n\t\tSplit\n\t\n\n\nTrain\ntrain/train-{000..715}.tar\n37930 audio samples\n\n\nValid\nvalid/valid-{000..108}.tar\n5741 audio samples\n\n\nTest\ntest/test-{000..142}.tar\n7569 audio samples\n\n\n\n\n\t\n\t\t\n\t\tUsing Webdataset\n\t\n\nimport torch\nimport webdataset as wds\nfrom huggingface_hub import get_token\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lighthouse-emnlp2024/Clotho-Moment.","first_N":5,"first_N_keywords":["text-to-audio","English","apache-2.0","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"PlanetofMusic","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/planetvol/PlanetofMusic","creator_name":"gr","creator_url":"https://huggingface.co/planetvol","description":"planetvol/PlanetofMusic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"aus_voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dst19/aus_voice","creator_name":"Sow Behl","creator_url":"https://huggingface.co/dst19","description":"dst19/aus_voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"quranic-audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prabowomurti/quranic-audio","creator_name":"Prab","creator_url":"https://huggingface.co/prabowomurti","description":"prabowomurti/quranic-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"AAT_Deekfake_and_real_Audio","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ArshTandon/AAT_Deekfake_and_real_Audio","creator_name":"Arsh Tandon","creator_url":"https://huggingface.co/ArshTandon","description":"\n\t\n\t\t\n\t\tAudio Deepfake Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset provides one of the most comprehensive audio deepfake detection resources available, consisting of real and synthetic audio samples standardized for machine learning research. It is designed to support development and benchmarking of deepfake detection algorithms.\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\n\nTotal audio files: 189,221\n\nReal: 101,172 (53.5%)\nFake: 88,049 (46.5%)\nClass ratio (Real:Fake): 1.15:1\n\n\nTotal duration:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArshTandon/AAT_Deekfake_and_real_Audio.","first_N":5,"first_N_keywords":["audio-classification","apache-2.0","100K - 1M","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"Eyaa-Tom","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Umbaji/Eyaa-Tom","creator_name":"Umbaji","creator_url":"https://huggingface.co/Umbaji","description":"\n\t\n\t\t\n\t\tEyaa-Tom Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nEyaa-Tom is a dataset designed to support Natural Language Processing (NLP) research for Togolese languages. It originates from the Eyaa-Tom dataset, meaning \"People's Words\" in Kaby√®, which was collected through fieldwork by the Umbaji community of linguists, researchers, and annotators. The dataset focuses on speech and text data for various applications, including name identification and service queries in healthcare and finance, among other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Umbaji/Eyaa-Tom.","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"nanospeech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/manojkmk/nanospeech","creator_name":"Manojkumar Karpurapu","creator_url":"https://huggingface.co/manojkmk","description":"manojkmk/nanospeech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_ru","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/common_voice_21_ru","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö validated.tsv –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ down_votes = 0\n\n\t\n\t\t\n\t\tüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n\n\t\n\t\t\n\t\t–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–ø–ª–∏—Ç–∞–º\n\t\n\n\n\t\n\t\t\n\t\tüîπ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä (train)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n93,531\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n132.25 —á–∞—Å–æ–≤ (476,089.70 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n5.09 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\tüîπ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (validate)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n38,836\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n55.21‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/common_voice_21_ru.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","Russian","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_ru","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/common_voice_21_ru","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö validated.tsv –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ down_votes = 0\n\n\t\n\t\t\n\t\tüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n\n\t\n\t\t\n\t\t–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–ø–ª–∏—Ç–∞–º\n\t\n\n\n\t\n\t\t\n\t\tüîπ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä (train)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n93,531\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n132.25 —á–∞—Å–æ–≤ (476,089.70 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n5.09 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\tüîπ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (validate)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n38,836\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n55.21‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/common_voice_21_ru.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","Russian","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_ru","keyword":"voice","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/common_voice_21_ru","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö validated.tsv –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ down_votes = 0\n\n\t\n\t\t\n\t\tüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n\n\t\n\t\t\n\t\t–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–ø–ª–∏—Ç–∞–º\n\t\n\n\n\t\n\t\t\n\t\tüîπ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä (train)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n93,531\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n132.25 —á–∞—Å–æ–≤ (476,089.70 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n5.09 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\tüîπ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (validate)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n38,836\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n55.21‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/common_voice_21_ru.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","Russian","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"HAL-9000-Speech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/campwill/HAL-9000-Speech","creator_name":"William Campbell","creator_url":"https://huggingface.co/campwill","description":"\n\t\n\t\t\n\t\tHAL 9000 Speech Dataset\n\t\n\nThis repository contains audio recordings of dialogue from HAL 9000, the AI character from 2001: A Space Odyssey. The full dataset contains most, but not all audio recordings of HAL 9000 from the film. The dataset is not cleaned, as background noise and variations in his voice are prevalent.  \nThe dataset can be formatted into the LJSpeech structure to ensure compatibility with most text-to-speech (TTS) models and training pipelines, such as Piper.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/campwill/HAL-9000-Speech.","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"speech_podcast","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anhhhhhhhhhhhhhh/speech_podcast","creator_name":"anh","creator_url":"https://huggingface.co/anhhhhhhhhhhhhhh","description":"anhhhhhhhhhhhhhh/speech_podcast dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"crf-metrics-board","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liyc5929/crf-metrics-board","creator_name":"Yanchen Li","creator_url":"https://huggingface.co/liyc5929","description":"liyc5929/crf-metrics-board dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"jadson","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NandinhoVinicius/jadson","creator_name":"Fernando Vinicius da Silva Bandeca","creator_url":"https://huggingface.co/NandinhoVinicius","description":"NandinhoVinicius/jadson dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"rudevices","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/rudevices","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tüìä –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞—É–¥–∏–æ-–¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n\t\n\n\n\t\n\t\t\n\t\tüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–í—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤/—Å–∞–±—Å–µ—Ç–æ–≤\n2\n\n\n–í—Å–µ–≥–æ —Å–µ–º–ø–ª–æ–≤\n296,394\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n369.14 —á–∞—Å–æ–≤ (1328901.86 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n4.48 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–∞—Ç–∞—Å–µ—Ç–∞–º\n\t\n\nru_audiobooks_devices ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 68.5%\nrudevices_audio_records ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 31.5%\n\n\n\n\t\n\t\t\n\t\n\t\n\t\t–î–∞—Ç–∞—Å–µ—Ç: rudevices_audio_records‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rudevices.","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","100K - 1M","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"rudevices","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/rudevices","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tüìä –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞—É–¥–∏–æ-–¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n\t\n\n\n\t\n\t\t\n\t\tüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–í—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤/—Å–∞–±—Å–µ—Ç–æ–≤\n2\n\n\n–í—Å–µ–≥–æ —Å–µ–º–ø–ª–æ–≤\n296,394\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n369.14 —á–∞—Å–æ–≤ (1328901.86 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n4.48 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–∞—Ç–∞—Å–µ—Ç–∞–º\n\t\n\nru_audiobooks_devices ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 68.5%\nrudevices_audio_records ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 31.5%\n\n\n\n\t\n\t\t\n\t\n\t\n\t\t–î–∞—Ç–∞—Å–µ—Ç: rudevices_audio_records‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rudevices.","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","100K - 1M","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"rudevices","keyword":"voice","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/rudevices","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tüìä –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞—É–¥–∏–æ-–¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n\t\n\n\n\t\n\t\t\n\t\tüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–í—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤/—Å–∞–±—Å–µ—Ç–æ–≤\n2\n\n\n–í—Å–µ–≥–æ —Å–µ–º–ø–ª–æ–≤\n296,394\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n369.14 —á–∞—Å–æ–≤ (1328901.86 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n4.48 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–∞—Ç–∞—Å–µ—Ç–∞–º\n\t\n\nru_audiobooks_devices ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 68.5%\nrudevices_audio_records ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 31.5%\n\n\n\n\t\n\t\t\n\t\n\t\n\t\t–î–∞—Ç–∞—Å–µ—Ç: rudevices_audio_records‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rudevices.","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","100K - 1M","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"DE_Emilia_Yodas_680h","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MrDragonFox/DE_Emilia_Yodas_680h","creator_name":"MrDragonFox","creator_url":"https://huggingface.co/MrDragonFox","description":"the dataset is 680h out of the german part from \nhttps://huggingface.co/datasets/amphion/Emilia-Dataset ( Emilia Yodas - cc by 4.0)\naudio event classified via scribe v1 (elevenlabs stt/asr)\n\nfacebook audio aestetics to be used as prefilter\n\nthe dataset is very much at a v1 - \nif you want to help - lets talk\nhttps://discord.gg/RUs3uzBdW3 (nsfw is fully opt in only - as sfw)\nif you want full transaction timestamps as they come from scribe v1 - they are cc by 4.0 NC\nand can be found here‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrDragonFox/DE_Emilia_Yodas_680h.","first_N":5,"first_N_keywords":["German","cc-by-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"testtest","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/azerconnect/testtest","creator_name":"llc","creator_url":"https://huggingface.co/azerconnect","description":"azerconnect/testtest dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["afl-3.0","< 1K","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"KinyaWhisperDataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/benax-rw/KinyaWhisperDataset","creator_name":"Benax Labs","creator_url":"https://huggingface.co/benax-rw","description":"\n\t\n\t\t\n\t\tKinyarwanda Spoken Words Dataset\n\t\n\nThis dataset contains 102 short audio samples of spoken Kinyarwanda words, each labeled with its corresponding transcription. It is designed for training, evaluating, and experimenting with Automatic Speech Recognition (ASR) models in low-resource settings.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudio/: Contains 102 .wav files (mono, 16kHz)\ntranscripts.txt: Tab-separated transcription file (e.g., 001.wav\\tmuraho)\nmanifest.jsonl: JSONL file with audio paths and text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benax-rw/KinyaWhisperDataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kinyarwanda","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"dong_nam_bo_raw","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hongquoc/dong_nam_bo_raw","creator_name":"Le Hong Quoc","creator_url":"https://huggingface.co/hongquoc","description":"hongquoc/dong_nam_bo_raw dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"AvaMERG","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZhangHanXD/AvaMERG","creator_name":"ZhangHan","creator_url":"https://huggingface.co/ZhangHanXD","description":"ZhangHanXD/AvaMERG dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Video","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Barkopedia_Dog_Sex_Classification_Dataset","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_Dog_Sex_Classification_Dataset","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\tüì¶ Dataset Description\n\t\n\nThis dataset is part of the Barkopedia Challenge: https://uta-acl2.github.io/barkopedia.html\nCheck training data on Hugging Face:\nüëâ ArlingtonCL2/Barkopedia_Dog_Sex_Classification_Dataset\nThis challenge provides a dataset of labeled dog bark audio clips:\n29,345 total clips of vocalizations from 156 individual dogs across 5 breeds:\n\nShiba Inu\n\nHusky\n\nChihuahua\n\nGerman Shepherd\n\nPitbull\n\nTraining set: 26,895 clips\n\n13,567 female13,328 male\n\n\nTest set: 2,450‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_Dog_Sex_Classification_Dataset.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Barkopedia_Dog_Sex_Classification_Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_Dog_Sex_Classification_Dataset","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\tüì¶ Dataset Description\n\t\n\nThis dataset is part of the Barkopedia Challenge: https://uta-acl2.github.io/barkopedia.html\nCheck training data on Hugging Face:\nüëâ ArlingtonCL2/Barkopedia_Dog_Sex_Classification_Dataset\nThis challenge provides a dataset of labeled dog bark audio clips:\n29,345 total clips of vocalizations from 156 individual dogs across 5 breeds:\n\nShiba Inu\n\nHusky\n\nChihuahua\n\nGerman Shepherd\n\nPitbull\n\nTraining set: 26,895 clips\n\n13,567 female13,328 male\n\n\nTest set: 2,450‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_Dog_Sex_Classification_Dataset.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Barkopedia_Individual_Dog_Recognition_Dataset","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_Individual_Dog_Recognition_Dataset","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"This dataset is for Barkopedia Challenge https://uta-acl2.github.io/barkopedia.html\n\n\t\n\t\t\n\t\tüì¶ Dataset Description\n\t\n\nCheck Training Data here: ArlingtonCL2/Barkopedia_Individual_Dog_Recognition_Dataset\nThis challenge provides a dataset of labeled dog bark audio clips:\n8924\n\nTraining set: 7137 clips (~120 clips per 60 dog IDs).\nTest set: 1787 clips (~30 clips per 60 dog IDs) with hidden labels:\n709 public (~40%) for live leaderboard updates.\n1078 private (~60%) for final evaluation.\nYou will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_Individual_Dog_Recognition_Dataset.","first_N":5,"first_N_keywords":["audio-classification","English","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Barkopedia_Individual_Dog_Recognition_Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_Individual_Dog_Recognition_Dataset","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"This dataset is for Barkopedia Challenge https://uta-acl2.github.io/barkopedia.html\n\n\t\n\t\t\n\t\tüì¶ Dataset Description\n\t\n\nCheck Training Data here: ArlingtonCL2/Barkopedia_Individual_Dog_Recognition_Dataset\nThis challenge provides a dataset of labeled dog bark audio clips:\n8924\n\nTraining set: 7137 clips (~120 clips per 60 dog IDs).\nTest set: 1787 clips (~30 clips per 60 dog IDs) with hidden labels:\n709 public (~40%) for live leaderboard updates.\n1078 private (~60%) for final evaluation.\nYou will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_Individual_Dog_Recognition_Dataset.","first_N":5,"first_N_keywords":["audio-classification","English","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Barkopedia_DOG_AGE_GROUP_CLASSIFICATION_DATASET","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_DOG_AGE_GROUP_CLASSIFICATION_DATASET","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nCheck Training Data here: ArlingtonCL2/Barkopedia_DOG_AGE_GROUP_CLASSIFICATION_DATASET\nDataset Description\nThis dataset is for Dog Age Group Classification and contains dog bark audio clips. The data is split into training, public test, and private test sets.\n\nTraining set: 17888 audio clips.\nTest set: 4920 audio clips, further divided into:\nTest Public (~40%): 1966 audio clips for live leaderboard updates.\nTest Private (~60%): 2954 audio clips for final evaluation.\nYou will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_DOG_AGE_GROUP_CLASSIFICATION_DATASET.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Barkopedia_DOG_AGE_GROUP_CLASSIFICATION_DATASET","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_DOG_AGE_GROUP_CLASSIFICATION_DATASET","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nCheck Training Data here: ArlingtonCL2/Barkopedia_DOG_AGE_GROUP_CLASSIFICATION_DATASET\nDataset Description\nThis dataset is for Dog Age Group Classification and contains dog bark audio clips. The data is split into training, public test, and private test sets.\n\nTraining set: 17888 audio clips.\nTest set: 4920 audio clips, further divided into:\nTest Public (~40%): 1966 audio clips for live leaderboard updates.\nTest Private (~60%): 2954 audio clips for final evaluation.\nYou will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_DOG_AGE_GROUP_CLASSIFICATION_DATASET.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"BarkopediaDogEmotionClassification_Data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/BarkopediaDogEmotionClassification_Data","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\tüê∂ Barkopedia Challenge Dataset\n\t\n\nüîó Barkopedia Website\n\n\t\n\t\t\n\t\tüì¶ Dataset Description\n\t\n\nThis challenge provides a labeled dataset of dog bark audio clips for understanding the arousal and valence of emotional state from sound.\n\n\t\n\t\t\n\t\tüìÅ Current Release\n\t\n\n\nTraining Set\n\nIncludes:\ntrain/husky and train/shiba contain all training audio clips for each of the two breeds\nhusky_train_labels.csv and shiba_train_labels.csv contain labels for all training audio clips\n\n\nTotal: 1000 training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/BarkopediaDogEmotionClassification_Data.","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Barkopedia_DOG_BREED_CLASSIFICATION_DATASET","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_DOG_BREED_CLASSIFICATION_DATASET","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\tüì¶ Dataset Description\n\t\n\nThis dataset is part of the Barkopedia Challenge\nüîó https://uta-acl2.github.io/barkopedia.html\nCheck Training Data here:üëâ ArlingtonCL2/Barkopedia_DOG_BREED_CLASSIFICATION_DATASET\nThis dataset contains 29,347 audio clips of dog barks labeled by dog breed.\nThe audio samples come from 156 individual dogs across 5 dog breeds:\n\nshiba inu\nhusky\nchihuahua\ngerman shepherd\npitbull\n\n\n\n\t\n\t\n\t\n\t\tüìä Per-Breed Summary\n\t\n\n\n\t\n\t\t\nBreed\nTrain\nPublic TestPrivate Test\nTest‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_DOG_BREED_CLASSIFICATION_DATASET.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Barkopedia_DOG_BREED_CLASSIFICATION_DATASET","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_DOG_BREED_CLASSIFICATION_DATASET","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\tüì¶ Dataset Description\n\t\n\nThis dataset is part of the Barkopedia Challenge\nüîó https://uta-acl2.github.io/barkopedia.html\nCheck Training Data here:üëâ ArlingtonCL2/Barkopedia_DOG_BREED_CLASSIFICATION_DATASET\nThis dataset contains 29,347 audio clips of dog barks labeled by dog breed.\nThe audio samples come from 156 individual dogs across 5 dog breeds:\n\nshiba inu\nhusky\nchihuahua\ngerman shepherd\npitbull\n\n\n\n\t\n\t\n\t\n\t\tüìä Per-Breed Summary\n\t\n\n\n\t\n\t\t\nBreed\nTrain\nPublic TestPrivate Test\nTest‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Barkopedia_DOG_BREED_CLASSIFICATION_DATASET.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"CAFA-VGGSound-Test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichaelFinkelson/CAFA-VGGSound-Test","creator_name":"Michael Finkelson","creator_url":"https://huggingface.co/MichaelFinkelson","description":"Code\nPaper\nGenerated results for VGGSound test set of our CAFA model. The results are trimmed down to 8s and generated with the default configuration described in the paper.\n","first_N":5,"first_N_keywords":["mit","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_5k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_5k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (5k)\n\t\n\nThis dataset contains 10000 synthetic speech recordings in the Pashto language,\nwith 5000 male voice recordings and 5000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 5000 sentences\nTotal Recordings: 10000 audio files (5000 male + 5000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz (24000 Hz)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_5k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_5k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_5k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (5k)\n\t\n\nThis dataset contains 10000 synthetic speech recordings in the Pashto language,\nwith 5000 male voice recordings and 5000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 5000 sentences\nTotal Recordings: 10000 audio files (5000 male + 5000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz (24000 Hz)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_5k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"vocsim","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymous-submission000/vocsim","creator_name":"Anonymous","creator_url":"https://huggingface.co/anonymous-submission000","description":"\n\t\n\t\t\n\t\tVocSim: Zero-Shot Audio Similarity Benchmark\n\t\n\n\n\n\n\nVocSim evaluates how well neural audio embeddings generalize for zero-shot audio similarity. It tests recognizing fine-grained acoustic similarity without specific similarity training.\n\n\n\t\t\n\t\tKey Features\n\t\n\n\nDiverse Sources: Human speech (phones, words, utterances), birdsong, otter calls, environmental sounds.\nVaried Conditions: Spans clean to noisy recordings, short (<100ms) to long durations, few to many classes per subset.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anonymous-submission000/vocsim.","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"vocsim","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymous-submission000/vocsim","creator_name":"Anonymous","creator_url":"https://huggingface.co/anonymous-submission000","description":"\n\t\n\t\t\n\t\tVocSim: Zero-Shot Audio Similarity Benchmark\n\t\n\n\n\n\n\nVocSim evaluates how well neural audio embeddings generalize for zero-shot audio similarity. It tests recognizing fine-grained acoustic similarity without specific similarity training.\n\n\n\t\t\n\t\tKey Features\n\t\n\n\nDiverse Sources: Human speech (phones, words, utterances), birdsong, otter calls, environmental sounds.\nVaried Conditions: Spans clean to noisy recordings, short (<100ms) to long durations, few to many classes per subset.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anonymous-submission000/vocsim.","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"GodSaveTheQueen","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eduhk-lin3046/GodSaveTheQueen","creator_name":"EdUHK LIN3046 Language Information Management","creator_url":"https://huggingface.co/eduhk-lin3046","description":"Received pronunciation (RP) was an accent of high prestige in British society as it is associated with the high classes and well-educated. However, nowadays, RP is spoken by 2-3% of the British population. This project aims to preserve RP by analyzing its features through the late Queen Elizabeth II, whose accent was seen as a hallmark of RP. For the purpose of this study, we have divided our data into three different decades: the 1950s, the 1990s and the 2010s. This is to examine Her‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eduhk-lin3046/GodSaveTheQueen.","first_N":5,"first_N_keywords":["text-classification","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"synthetic-newsroom-assets","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ninou21/synthetic-newsroom-assets","creator_name":"Khaliel","creator_url":"https://huggingface.co/Ninou21","description":"Ninou21/synthetic-newsroom-assets dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","Audio","Image","Video"],"keywords_longer_than_N":true},
	{"name":"EmoTransCap","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shuhao-Xu/EmoTransCap","creator_name":"Shuhao Xu","creator_url":"https://huggingface.co/Shuhao-Xu","description":"Shuhao-Xu/EmoTransCap dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Defeasible","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Neuripscc/Defeasible","creator_name":"Neurips","creator_url":"https://huggingface.co/Neuripscc","description":"Neuripscc/Defeasible dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","1K - 10K","Audio","Video"],"keywords_longer_than_N":true},
	{"name":"ToneSpeak","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/ToneSpeak","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tToneSpeak\n\t\n\nToneSpeak ‚Äî –±–æ–ª—å—à–æ–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—É–¥–∏–æ–¥–∞—Ç–∞—Å–µ—Ç —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º –∏–Ω—Ç–æ–Ω–∞—Ü–∏–π, —Ç–µ–º–±—Ä–∞ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞. –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ 26.33 —á–∞—Å–∞ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 2.91 —á–∞—Å–∞ –¥–ª—è valitation.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –∞—É–¥–∏–æ —Å–æ–±—Ä–∞–Ω—ã:\n\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ –∏ —ç–º–æ—Ü–∏–π (text_description), —Ä–∞–∑–±–∏—Ç–æ–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:\nAccent/Affect  \nVoice Affect  \nTone  \nPhrasing  \nPunctuation  \nEmotion  \nEmphasis  \nPronunciation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneSpeak.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"CodecBench_collected_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RayYuki/CodecBench_collected_dataset","creator_name":"Deng RF","creator_url":"https://huggingface.co/RayYuki","description":"RayYuki/CodecBench_collected_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Hy-Generated-audio-data-with-cv20.0","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ErikMkrtchyan/Hy-Generated-audio-data-with-cv20.0","creator_name":"Erik Mkrtchyan","creator_url":"https://huggingface.co/ErikMkrtchyan","description":"\n\t\n\t\t\n\t\tHy-Generated Audio Data with CV20.0\n\t\n\nThis dataset provides Armenian speech data consisting of both real and generated audio clips.\n\nThe train, test, and eval splits are derived from the Common Voice 20.0 Armenian dataset.\nThe generated split contains 100,000 high-quality clips synthesized using a fine-tuned F5-TTS model, covering 404 equal distribution of synthetic voices.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Statistics\n\t\n\n\n\t\n\t\t\nSplit\n# Clips\nDuration (hours)\n\n\n\t\t\ntrain\n9,300\n13.53\n\n\ntest\n5,818‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ErikMkrtchyan/Hy-Generated-audio-data-with-cv20.0.","first_N":5,"first_N_keywords":["Armenian","cc0-1.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","creator_name":"MAdel","creator_url":"https://huggingface.co/MAdel121","description":"\n\t\n\t\t\n\t\tCurated Arabic Speech Dataset for Seasme (from MCV17)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a curated and preprocessed version of the Arabic (ar) subset from Mozilla Common Voice (MCV) 17.0. It has been specifically prepared for fine-tuning conversational speech models, with a primary focus on the Seasme-CSM model architecture. The dataset consists of audio clips in WAV format (24kHz, mono) and their corresponding transcripts, along with integer speaker IDs.\nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning.","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","creator_name":"MAdel","creator_url":"https://huggingface.co/MAdel121","description":"\n\t\n\t\t\n\t\tCurated Arabic Speech Dataset for Seasme (from MCV17)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a curated and preprocessed version of the Arabic (ar) subset from Mozilla Common Voice (MCV) 17.0. It has been specifically prepared for fine-tuning conversational speech models, with a primary focus on the Seasme-CSM model architecture. The dataset consists of audio clips in WAV format (24kHz, mono) and their corresponding transcripts, along with integer speaker IDs.\nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning.","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"VocalBench","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VocalNet/VocalBench","creator_name":"VocalNet","creator_url":"https://huggingface.co/VocalNet","description":"\n\t\n\t\t\n\t\tVocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models\n\t\n\nThis is the official release of VocalBench\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you find our work helpful, please cite our paper:\n@article{liu2025vocalbench,\n  title={VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models},\n  author={Liu, Heyang and Wang, Yuhao and Cheng, Ziyang and Wu, Ronghua and Gu, Qunshan and Wang, Yanfeng and Wang, Yu},\n  journal={arXiv preprint‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VocalNet/VocalBench.","first_N":5,"first_N_keywords":["question-answering","audio-to-audio","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"VocalBench","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VocalNet/VocalBench","creator_name":"VocalNet","creator_url":"https://huggingface.co/VocalNet","description":"\n\t\n\t\t\n\t\tVocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models\n\t\n\nThis is the official release of VocalBench\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you find our work helpful, please cite our paper:\n@article{liu2025vocalbench,\n  title={VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models},\n  author={Liu, Heyang and Wang, Yuhao and Cheng, Ziyang and Wu, Ronghua and Gu, Qunshan and Wang, Yanfeng and Wang, Yu},\n  journal={arXiv preprint‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VocalNet/VocalBench.","first_N":5,"first_N_keywords":["question-answering","audio-to-audio","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"small_i","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/s61511484894/small_i","creator_name":"132456","creator_url":"https://huggingface.co/s61511484894","description":"s61511484894/small_i dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Jailbreak-AudioBench-Plus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/researchtopic/Jailbreak-AudioBench-Plus","creator_name":"research","creator_url":"https://huggingface.co/researchtopic","description":"researchtopic/Jailbreak-AudioBench-Plus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Indic-r","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dvyomkesh/Indic-r","creator_name":"Dundigalla Vyomakesh","creator_url":"https://huggingface.co/dvyomkesh","description":"dvyomkesh/Indic-r dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"gaming","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hyhz/gaming","creator_name":"Hoon Yao Hui","creator_url":"https://huggingface.co/hyhz","description":"hyhz/gaming dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ToneBooks","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/ToneBooks","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tToneBooks\n\t\n\nToneBooks ‚Äî –±–æ–ª—å—à–æ–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∞—É–¥–∏–æ–∫–Ω–∏–≥ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –∏–Ω—Ç–æ–Ω–∞—Ü–∏–π, —Ç–µ–º–±—Ä–∞ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞. –í –¥–∞—Ç–∞—Å–µ—Ç–µ 179.16 —á–∞—Å–æ–≤ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 9.42 —á–∞—Å–∞ –¥–ª—è validation.\n–ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ its5Q –∑–∞ –ø–æ–º–æ—â—å –≤ —Å–±–æ—Ä–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Å–æ–±—Ä–∞–Ω—ã:\n\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ –∏ —ç–º–æ—Ü–∏–π (text_description), —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:\nAccent/Affect  \nVoice Affect‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneBooks.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"aimeghamuse","keyword":"voice","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/siyadsiya/aimeghamuse","creator_name":"K","creator_url":"https://huggingface.co/siyadsiya","description":"siyadsiya/aimeghamuse dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-classification","text-to-image","Malayalam","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/harris88/test","creator_name":"yu","creator_url":"https://huggingface.co/harris88","description":"test\n","first_N":5,"first_N_keywords":["text-classification","apache-2.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-3lang-raw","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-3lang-raw","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (3 Languages, Raw)\n\t\n\nThis dataset is a curated subset of previously published speech command datasets in Kazakh, Tatar, and Russian. It is intended for use in multilingual speech command recognition and keyword spotting tasks. No data augmentation has been applied.\nAll files are included in their original form as released in the cited works below. This repository simply reorganizes them for convenience and accessibility.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-3lang-raw.","first_N":5,"first_N_keywords":["Kazakh","Tatar","Russian","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-3lang-raw","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-3lang-raw","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (3 Languages, Raw)\n\t\n\nThis dataset is a curated subset of previously published speech command datasets in Kazakh, Tatar, and Russian. It is intended for use in multilingual speech command recognition and keyword spotting tasks. No data augmentation has been applied.\nAll files are included in their original form as released in the cited works below. This repository simply reorganizes them for convenience and accessibility.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-3lang-raw.","first_N":5,"first_N_keywords":["Kazakh","Tatar","Russian","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"rssdb","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/devfed/rssdb","creator_name":"Fedot Sereoja","creator_url":"https://huggingface.co/devfed","description":"\n***  RSS (Romanian Speech Synthesis) DATABASE v.0.8.1  ***\n\nhttps://romaniantts.com/rssdb/\nThis directory contains recordings of Romanian sentences, recorded by ADR, a native Romanian speaker.\nThe phoneme set used is described in PHONEMES.txt\nThe folder is divided into trainining and testing data. The training data contains two sets of sentences chosen for diphone coverage (diph1 and diph2), three sets of randomly selected newspaper sentences (rnd1, rnd2 and rnd3) and two short stories by Ion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devfed/rssdb.","first_N":5,"first_N_keywords":["Romanian","mit","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"rssdb","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/devfed/rssdb","creator_name":"Fedot Sereoja","creator_url":"https://huggingface.co/devfed","description":"\n***  RSS (Romanian Speech Synthesis) DATABASE v.0.8.1  ***\n\nhttps://romaniantts.com/rssdb/\nThis directory contains recordings of Romanian sentences, recorded by ADR, a native Romanian speaker.\nThe phoneme set used is described in PHONEMES.txt\nThe folder is divided into trainining and testing data. The training data contains two sets of sentences chosen for diphone coverage (diph1 and diph2), three sets of randomly selected newspaper sentences (rnd1, rnd2 and rnd3) and two short stories by Ion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devfed/rssdb.","first_N":5,"first_N_keywords":["Romanian","mit","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"aus_voice_4","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dst19/aus_voice_4","creator_name":"Sow Behl","creator_url":"https://huggingface.co/dst19","description":"\n\t\n\t\t\n\t\tOrpheus TTS Dataset\n\t\n\nThis dataset is prepared for training Orpheus TTS models.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal samples: 429\nAudio sampling rate: 44100 Hz\nFormat: Single-speaker TTS dataset with 'text' and 'audio' columns\n\nThis dataset is specifically formatted for Orpheus TTS single-speaker models. It includes:\n\nText content in the 'text' column\nAudio files properly structured for training\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided in multiple formats:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dst19/aus_voice_4.","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang.","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang.","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"AudioLDM-with-LoRA-Hiphop-subgenre","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rofla/AudioLDM-with-LoRA-Hiphop-subgenre","creator_name":"KIMSEONPYO","creator_url":"https://huggingface.co/Rofla","description":"Rofla/AudioLDM-with-LoRA-Hiphop-subgenre dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Odia-data-collection","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minutor/Odia-data-collection","creator_name":"Anshuman Mishra","creator_url":"https://huggingface.co/Minutor","description":"This is a repo created for training purpose for the language \"Odia\".\ndataset's collection, that exists:\n\nLink\n\n","first_N":5,"first_N_keywords":["Oriya","apache-2.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"AI-Belha","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NOSInovacao/AI-Belha","creator_name":"NOS Inova√ß√£o, SA","creator_url":"https://huggingface.co/NOSInovacao","description":"\n\t\n\t\t\n\t\tDataset Card for AI-Belha\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAI-Belha is a dataset comprising audio recordings from beehives, collected to determine the presence and status of the queen bee. The dataset includes 86 mono WAV files, each approximately 60 seconds long and sampled at 16 kHz, totaling about 1 hour and 26 minutes of audio. Each recording is annotated with beekeeper observations and model predictions regarding the queen bee's status.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NOSInovacao/AI-Belha.","first_N":5,"first_N_keywords":["feature-extraction","audio-classification","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"AI-Belha","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NOSInovacao/AI-Belha","creator_name":"NOS Inova√ß√£o, SA","creator_url":"https://huggingface.co/NOSInovacao","description":"\n\t\n\t\t\n\t\tDataset Card for AI-Belha\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAI-Belha is a dataset comprising audio recordings from beehives, collected to determine the presence and status of the queen bee. The dataset includes 86 mono WAV files, each approximately 60 seconds long and sampled at 16 kHz, totaling about 1 hour and 26 minutes of audio. Each recording is annotated with beekeeper observations and model predictions regarding the queen bee's status.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NOSInovacao/AI-Belha.","first_N":5,"first_N_keywords":["feature-extraction","audio-classification","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"AI-Belha","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NOSInovacao/AI-Belha","creator_name":"NOS Inova√ß√£o, SA","creator_url":"https://huggingface.co/NOSInovacao","description":"\n\t\n\t\t\n\t\tDataset Card for AI-Belha\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAI-Belha is a dataset comprising audio recordings from beehives, collected to determine the presence and status of the queen bee. The dataset includes 86 mono WAV files, each approximately 60 seconds long and sampled at 16 kHz, totaling about 1 hour and 26 minutes of audio. Each recording is annotated with beekeeper observations and model predictions regarding the queen bee's status.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NOSInovacao/AI-Belha.","first_N":5,"first_N_keywords":["feature-extraction","audio-classification","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"AudioQA-1M","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shenyunhang/AudioQA-1M","creator_name":"Ê≤à‰∫ëËà™ Yunhang Shen","creator_url":"https://huggingface.co/shenyunhang","description":"shenyunhang/AudioQA-1M dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"hausa_voice_dataset","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mide7x/hausa_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Voice Dataset\nDescription: This dataset contains Hausa language audio samples from Common Voice. The dataset includes audio files and their corresponding transcriptions, designed for text-to-speech (TTS) and automatic speech recognition (ASR) research and applications.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train\n\nDataset Info:\n\nFeatures:\naudio: Audio file (mono‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","keyword-spotting","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"hausa_voice_dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mide7x/hausa_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Voice Dataset\nDescription: This dataset contains Hausa language audio samples from Common Voice. The dataset includes audio files and their corresponding transcriptions, designed for text-to-speech (TTS) and automatic speech recognition (ASR) research and applications.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train\n\nDataset Info:\n\nFeatures:\naudio: Audio file (mono‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","keyword-spotting","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"small_private_db","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArtemRost/small_private_db","creator_name":"ARTEM ROSTOVTSEV","creator_url":"https://huggingface.co/ArtemRost","description":"ArtemRost/small_private_db dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"italian_clean_5th_may_v1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/italian_clean_5th_may_v1","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/italian_clean_5th_may_v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"urdu-language-speech-dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ReySajju742/urdu-language-speech-dataset","creator_name":"Muhammad Sajjad Rasool","creator_url":"https://huggingface.co/ReySajju742","description":"\n\t\n\t\t\n\t\tURDU-Dataset\n\t\n\nURDU dataset contains emotional utterances of Urdu speech gathered from Urdu talk shows. It contains 400 utterances of four basic emotions: Angry, Happy, Neutral, and Emotion. There are 38 speakers (27 male and 11 female).\nThis data is created from Youtube. Speakers are selected randomly. Anyone can use this data only for research purposes. \nNomenclature followed while naming the files in the dataset is to provide information about the speaker, gender, number of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReySajju742/urdu-language-speech-dataset.","first_N":5,"first_N_keywords":["translation","Urdu","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"plug_socket_single_slow","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_single_slow","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 50,\n    \"total_frames\": 24939,\n    \"total_tasks\": 1,\n    \"total_videos\": 150,\n    \"total_audio\": 150,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_single_slow.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"plug_socket_single_slow","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_single_slow","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 50,\n    \"total_frames\": 24939,\n    \"total_tasks\": 1,\n    \"total_videos\": 150,\n    \"total_audio\": 150,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_single_slow.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"XCDC-tiny","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wuao652/XCDC-tiny","creator_name":"Wuao Liu","creator_url":"https://huggingface.co/Wuao652","description":"Wuao652/XCDC-tiny dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"carlos_all_italian","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/carlos_all_italian","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/carlos_all_italian dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"MoChaBench","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CongWei1230/MoChaBench","creator_name":"Cong Wei","creator_url":"https://huggingface.co/CongWei1230","description":"\n\t\n\t\t\n\t\tMoChaBench\n\t\n\nMoCha is a pioneering model for Dialogue-driven Movie Shot Generation.\n| üåêProject Page | üìñPaper | üîóGithub | ü§óDemo|\nWe introduce our evaluation benchmark \"MoChaBench\", as described in Section 4.3 of the MoCha Paper.\nMoChaBench is tailored for Dialogue-driven Movie Shot Generation ‚Äî generating movie shots from a combination of speech and text(speech + text ‚Üí video).\nIt complements existing narration-style, non-dialogue scene generation benchmarks (text ‚Üí video), such as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CongWei1230/MoChaBench.","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"MoChaBench","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CongWei1230/MoChaBench","creator_name":"Cong Wei","creator_url":"https://huggingface.co/CongWei1230","description":"\n\t\n\t\t\n\t\tMoChaBench\n\t\n\nMoCha is a pioneering model for Dialogue-driven Movie Shot Generation.\n| üåêProject Page | üìñPaper | üîóGithub | ü§óDemo|\nWe introduce our evaluation benchmark \"MoChaBench\", as described in Section 4.3 of the MoCha Paper.\nMoChaBench is tailored for Dialogue-driven Movie Shot Generation ‚Äî generating movie shots from a combination of speech and text(speech + text ‚Üí video).\nIt complements existing narration-style, non-dialogue scene generation benchmarks (text ‚Üí video), such as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CongWei1230/MoChaBench.","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"commonaudio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Bolorjin/commonaudio","creator_name":"Bolorjin Batbaatar","creator_url":"https://huggingface.co/Bolorjin","description":"Bolorjin/commonaudio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"test_hf_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/guynich/test_hf_dataset","creator_name":"Guy Nicholson","creator_url":"https://huggingface.co/guynich","description":"\n\t\n\t\t\n\t\ttest_hf_dataset\n\t\n\nThis dataset was created to document how to create an audio dataset and upload\nit to HuggingFace see GitHub repo.\nNext step: add more documentation.\ne.g.:\n\ncontents of the dataset\ncontext for how the dataset should be used, e.g.: datasets package\nexisting dataset cards, such as the ELI5 dataset card, show common conventions\n\n\n\t\n\t\t\n\t\n\t\n\t\tExample usage of dataset\n\t\n\nExample of transcription.\nFirst install extra dependencies, typically within virtual environment.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guynich/test_hf_dataset.","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"skn","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/okuparinen/skn","creator_name":"Olli Kuparinen","creator_url":"https://huggingface.co/okuparinen","description":"An utterance-level version of the Samples of Spoken Finnish corpus detailed here: https://www.kielipankki.fi/corpora/skn/\nIf you use this dataset, refer to the original data providers: Institute for the Languages of Finland (2021). Samples of Spoken Finnish, Downloadable Version [data set]. Kielipankki. http://urn.fi/urn:nbn:fi:lb-2020112937","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"hi_luna_synthetic_audio_v1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ThomasTheMaker/hi_luna_synthetic_audio_v1","creator_name":"Thomas Nguyen","creator_url":"https://huggingface.co/ThomasTheMaker","description":"300k audio files synthetically generated by VITS using https://github.com/dscripka/synthetic_speech_dataset_generation?tab=readme-ov-file\n\nCommand used\npython generate_clips.py \\\n    --model VITS \\\n    --enable_gpu \\\n    --text \"Hey, Luna\" \\\n    --N 300000 \\\n    --max_per_speaker 1 \\\n    --output_dir /luna_audio\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","apache-2.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Hebrew-talk","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/Hebrew-talk","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"sleeping-ai/Hebrew-talk dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"hausa_long_voice_dataset","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_long_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Long Voice Dataset\nDescription: This dataset contains merged Hausa language audio samples from Common Voice. Audio files from the same speaker have been concatenated to create longer audio samples with their corresponding transcriptions, designed for text-to-speech (TTS) training where longer sequences are beneficial.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"hausa_long_voice_dataset","keyword":"speaker-identification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_long_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Long Voice Dataset\nDescription: This dataset contains merged Hausa language audio samples from Common Voice. Audio files from the same speaker have been concatenated to create longer audio samples with their corresponding transcriptions, designed for text-to-speech (TTS) training where longer sequences are beneficial.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"hausa_long_voice_dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_long_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Long Voice Dataset\nDescription: This dataset contains merged Hausa language audio samples from Common Voice. Audio files from the same speaker have been concatenated to create longer audio samples with their corresponding transcriptions, designed for text-to-speech (TTS) training where longer sequences are beneficial.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"tts","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FINGU-AI/tts","creator_name":"GRINDA AI","creator_url":"https://huggingface.co/FINGU-AI","description":"FINGU-AI/tts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"ChineseNumberEnglishMixer","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Cheemer/ChineseNumberEnglishMixer","creator_name":"Ming","creator_url":"https://huggingface.co/Cheemer","description":"Cheemer/ChineseNumberEnglishMixer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"animal-sounds","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cgeorgiaw/animal-sounds","creator_name":"Georgia Channing","creator_url":"https://huggingface.co/cgeorgiaw","description":"A collection of audio recordings for various animal vocalizations, including birds, dogs, Egyptian fruit bats, giant otters, macaques, orcas, and zebra finches. Useful for training and evaluating models in bioacoustics, species classification, and sound event detection.\n","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"zuhri","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/humair025/zuhri","creator_name":"Humair M","creator_url":"https://huggingface.co/humair025","description":"\n\t\n\t\t\n\t\tZuhri ‚Äî Urdu G2P Dataset\n\t\n\nZuhri is a comprehensive and manually verified Urdu Grapheme-to-Phoneme (G2P) dataset. It is designed to aid research and development in areas such as speech synthesis, pronunciation modeling, and computational linguistics, specifically for the Urdu language.\nThis dataset provides accurate phoneme transcriptions and IPA representations, making it ideal for use in building high-quality TTS (Text-to-Speech), ASR (Automatic Speech Recognition), and other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/humair025/zuhri.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","Urdu","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"plug_socket_single_padding","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_single_padding","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 50,\n    \"total_frames\": 22752,\n    \"total_tasks\": 1,\n    \"total_videos\": 150,\n    \"total_audio\": 150,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_single_padding.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"plug_socket_single_padding","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_single_padding","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 50,\n    \"total_frames\": 22752,\n    \"total_tasks\": 1,\n    \"total_videos\": 150,\n    \"total_audio\": 150,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_single_padding.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"alternative_christian_text2music","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeardingFace/alternative_christian_text2music","creator_name":"Benjamin","creator_url":"https://huggingface.co/BeardingFace","description":"MP3s created with a Pro Subscription to a proprietary text2music provider. While under a Pro Subscription, outputs are licensed permissively.\nDesigned to be LORA training for the below model:\nhttps://huggingface.co/ACE-Step/ACE-Step-v1-3.5B\nI may update the _Prompts in the dataset for other models in the future.\nPlease support the official ACE-Step team:\n@misc{gong2025acestep,\n  title={ACE-Step: A Step Towards Music Generation Foundation Model},\n  author={Junmin Gong, Wenxiao Zhao, Sen Wang‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeardingFace/alternative_christian_text2music.","first_N":5,"first_N_keywords":["text-to-audio","English","apache-2.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"alternative_christian_text2music","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeardingFace/alternative_christian_text2music","creator_name":"Benjamin","creator_url":"https://huggingface.co/BeardingFace","description":"MP3s created with a Pro Subscription to a proprietary text2music provider. While under a Pro Subscription, outputs are licensed permissively.\nDesigned to be LORA training for the below model:\nhttps://huggingface.co/ACE-Step/ACE-Step-v1-3.5B\nI may update the _Prompts in the dataset for other models in the future.\nPlease support the official ACE-Step team:\n@misc{gong2025acestep,\n  title={ACE-Step: A Step Towards Music Generation Foundation Model},\n  author={Junmin Gong, Wenxiao Zhao, Sen Wang‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeardingFace/alternative_christian_text2music.","first_N":5,"first_N_keywords":["text-to-audio","English","apache-2.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"TesterData","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Naveed-SNR/TesterData","creator_name":"Naveed SNR","creator_url":"https://huggingface.co/Naveed-SNR","description":"Naveed-SNR/TesterData dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ChiSER5","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChiSER5/ChiSER5","creator_name":"ChiSER5","creator_url":"https://huggingface.co/ChiSER5","description":"\n\t\n\t\t\n\t\tChiSER-5: ‰∏≠ÊñáËØ≠Èü≥ÊÉÖÊÑüËØÜÂà´Êï∞ÊçÆÈõÜ\n\t\n\n\n\t\n\t\t\n\t\tÁÆÄ‰ªã (Introduction)\n\t\n\nChiSER-5 ÊòØ‰∏Ä‰∏™Áî®‰∫é‰∏≠ÊñáËØ≠Èü≥ÊÉÖÊÑüËØÜÂà´‰ªªÂä°ÁöÑÂ∞èÂûãÊï∞ÊçÆÈõÜ„ÄÇÂÆÉÊó®Âú®‰∏∫Á†îÁ©∂ËÄÖÂíåÂºÄÂèëËÄÖÊèê‰æõ‰∏Ä‰∏™Âü∫Á°ÄÁöÑ„ÄÅÊòì‰∫é‰∏äÊâãÁöÑËµÑÊ∫êÔºåÁî®‰∫éÂàùÊ≠•Êé¢Á¥¢ÂíåÊµãËØï‰∏≠ÊñáËØ≠Èü≥ÊÉÖÊÑüÂàÜÁ±ªÊ®°Âûã„ÄÇ\nËØ•Êï∞ÊçÆÈõÜÂåÖÂê´‰∫Ü‰∫î‰∏™Âü∫Êú¨ÁöÑÊÉÖÊÑüÁ±ªÂà´ÔºåÊØè‰∏™Á±ªÂà´ÂåÖÂê´100Êù°‰∏≠ÊñáËØ≠Èü≥Ê†∑Êú¨„ÄÇ\nÊÄªÊó∂Èïø35ÂàÜÈíüÔºåÂπ≥Â±Ä4ÁßíÔºåÈááÊ†∑Áéá16kHZÔºå‰ΩçÊ∑±Â∫¶16bit\nÊÉÖÊÑüÁ±ªÂà´ (Emotion Categories):\n*   È´òÂÖ¥ (Happy)\n*   ‰º§ÂøÉ (Sad)\n*   ÁîüÊ∞î (Angry)\n*   ‰∏≠ÊÄß (Neutral)\n*   ÊÉäÂñú (Surprise)\n\nÊ†∑Êú¨Êï∞Èáè (Number of Samples):\n\nÊØè‰∏™ÊÉÖÊÑüÁ±ªÂà´: 100 Êù°ËØ≠Èü≥Ê†∑Êú¨\nÊÄªËÆ°: 500 Êù°ËØ≠Èü≥Ê†∑Êú¨\n\n\n\t\n\t\t\n\t\tËÆ∏ÂèØËØÅ (License)\n\t\n\nÊú¨Êï∞ÊçÆÈõÜÈááÁî® Creative Commons Attribution 4.0 International License (CC BY 4.0) ËøõË°åËÆ∏ÂèØ„ÄÇ\n\nËøôÊÑèÂë≥ÁùÄÊÇ®ÂèØ‰ª•Ëá™Áî±Âú∞Ôºö\n\nÂÖ±‰∫´‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChiSER5/ChiSER5.","first_N":5,"first_N_keywords":["audio-classification","Chinese","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ChiSER5","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChiSER5/ChiSER5","creator_name":"ChiSER5","creator_url":"https://huggingface.co/ChiSER5","description":"\n\t\n\t\t\n\t\tChiSER-5: ‰∏≠ÊñáËØ≠Èü≥ÊÉÖÊÑüËØÜÂà´Êï∞ÊçÆÈõÜ\n\t\n\n\n\t\n\t\t\n\t\tÁÆÄ‰ªã (Introduction)\n\t\n\nChiSER-5 ÊòØ‰∏Ä‰∏™Áî®‰∫é‰∏≠ÊñáËØ≠Èü≥ÊÉÖÊÑüËØÜÂà´‰ªªÂä°ÁöÑÂ∞èÂûãÊï∞ÊçÆÈõÜ„ÄÇÂÆÉÊó®Âú®‰∏∫Á†îÁ©∂ËÄÖÂíåÂºÄÂèëËÄÖÊèê‰æõ‰∏Ä‰∏™Âü∫Á°ÄÁöÑ„ÄÅÊòì‰∫é‰∏äÊâãÁöÑËµÑÊ∫êÔºåÁî®‰∫éÂàùÊ≠•Êé¢Á¥¢ÂíåÊµãËØï‰∏≠ÊñáËØ≠Èü≥ÊÉÖÊÑüÂàÜÁ±ªÊ®°Âûã„ÄÇ\nËØ•Êï∞ÊçÆÈõÜÂåÖÂê´‰∫Ü‰∫î‰∏™Âü∫Êú¨ÁöÑÊÉÖÊÑüÁ±ªÂà´ÔºåÊØè‰∏™Á±ªÂà´ÂåÖÂê´100Êù°‰∏≠ÊñáËØ≠Èü≥Ê†∑Êú¨„ÄÇ\nÊÄªÊó∂Èïø35ÂàÜÈíüÔºåÂπ≥Â±Ä4ÁßíÔºåÈááÊ†∑Áéá16kHZÔºå‰ΩçÊ∑±Â∫¶16bit\nÊÉÖÊÑüÁ±ªÂà´ (Emotion Categories):\n*   È´òÂÖ¥ (Happy)\n*   ‰º§ÂøÉ (Sad)\n*   ÁîüÊ∞î (Angry)\n*   ‰∏≠ÊÄß (Neutral)\n*   ÊÉäÂñú (Surprise)\n\nÊ†∑Êú¨Êï∞Èáè (Number of Samples):\n\nÊØè‰∏™ÊÉÖÊÑüÁ±ªÂà´: 100 Êù°ËØ≠Èü≥Ê†∑Êú¨\nÊÄªËÆ°: 500 Êù°ËØ≠Èü≥Ê†∑Êú¨\n\n\n\t\n\t\t\n\t\tËÆ∏ÂèØËØÅ (License)\n\t\n\nÊú¨Êï∞ÊçÆÈõÜÈááÁî® Creative Commons Attribution 4.0 International License (CC BY 4.0) ËøõË°åËÆ∏ÂèØ„ÄÇ\n\nËøôÊÑèÂë≥ÁùÄÊÇ®ÂèØ‰ª•Ëá™Áî±Âú∞Ôºö\n\nÂÖ±‰∫´‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChiSER5/ChiSER5.","first_N":5,"first_N_keywords":["audio-classification","Chinese","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ITCL-ES-TTS-5voices-143ksamples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ejbejaranos/ITCL-ES-TTS-5voices-143ksamples","creator_name":"Edison Bejarano Sepulveda","creator_url":"https://huggingface.co/ejbejaranos","description":"\n\t\n\t\t\n\t\tüó£Ô∏è ITCL-ES-TTS-5voices-143ksamples\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tüì¶ Descripci√≥n del Dataset\n\t\n\nEste dataset contiene 143,390 muestras en espa√±ol compuestas por consultas y respuestas generadas por motores TTS (Text-to-Speech). Se generaron utilizando los modelos:\n\nüó£Ô∏è Kokoro TTS (kokoro-82m)\nüó£Ô∏è Coqui TTS (coqui)\n\nLas consultas y respuestas est√°n basadas en el dataset ms-marco-es, y se generaron audios sint√©ticos para ambas partes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß¨ Estructura del Dataset\n\t\n\nCada muestra incluye‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ejbejaranos/ITCL-ES-TTS-5voices-143ksamples.","first_N":5,"first_N_keywords":["question-answering","Spanish","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ITCL-ES-TTS-5voices-143ksamples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ejbejaranos/ITCL-ES-TTS-5voices-143ksamples","creator_name":"Edison Bejarano Sepulveda","creator_url":"https://huggingface.co/ejbejaranos","description":"\n\t\n\t\t\n\t\tüó£Ô∏è ITCL-ES-TTS-5voices-143ksamples\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tüì¶ Descripci√≥n del Dataset\n\t\n\nEste dataset contiene 143,390 muestras en espa√±ol compuestas por consultas y respuestas generadas por motores TTS (Text-to-Speech). Se generaron utilizando los modelos:\n\nüó£Ô∏è Kokoro TTS (kokoro-82m)\nüó£Ô∏è Coqui TTS (coqui)\n\nLas consultas y respuestas est√°n basadas en el dataset ms-marco-es, y se generaron audios sint√©ticos para ambas partes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß¨ Estructura del Dataset\n\t\n\nCada muestra incluye‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ejbejaranos/ITCL-ES-TTS-5voices-143ksamples.","first_N":5,"first_N_keywords":["question-answering","Spanish","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"hindi-1-chunk","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pareek123/hindi-1-chunk","creator_name":"Aaditya Pareek","creator_url":"https://huggingface.co/pareek123","description":"pareek123/hindi-1-chunk dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"v2s","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jlking/v2s","creator_name":"Jialong Zuo","creator_url":"https://huggingface.co/jlking","description":"jlking/v2s dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","text","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"sxfx_USTC","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lixiang9527/sxfx_USTC","creator_name":"Li puhe","creator_url":"https://huggingface.co/lixiang9527","description":"lixiang9527/sxfx_USTC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"sxfx_USTC","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lixiang9527/sxfx_USTC","creator_name":"Li puhe","creator_url":"https://huggingface.co/lixiang9527","description":"lixiang9527/sxfx_USTC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"onomatopeia","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/contatosmartcomprasonline/onomatopeia","creator_name":"Di√™go R√™go","creator_url":"https://huggingface.co/contatosmartcomprasonline","description":"contatosmartcomprasonline/onomatopeia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"GTZAN","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/GTZAN","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"m-a-p/GTZAN dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","Audio","Image","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"sxfx2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lixiang9527/sxfx2","creator_name":"Li puhe","creator_url":"https://huggingface.co/lixiang9527","description":"lixiang9527/sxfx2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"sxfx2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lixiang9527/sxfx2","creator_name":"Li puhe","creator_url":"https://huggingface.co/lixiang9527","description":"lixiang9527/sxfx2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"speech-to-text","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaishah2808/speech-to-text","creator_name":"jai","creator_url":"https://huggingface.co/jaishah2808","description":"\n\t\n\t\t\n\t\tMy Audio Dataset\n\t\n\nThis dataset contains audio recordings with corresponding transcriptions and metadata.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\naudio: Audio files (WAV format).\ntext: Transcription of the audio.\ncategory: Category of the audio (if applicable).\nduration: Duration of the audio in seconds.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset using the datasets library:\nfrom datasets import load_dataset\ndataset = load_dataset(\"jaishah2808/speech-to-text\")\n\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"may_30_french","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/may_30_french","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/may_30_french dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"may_30_es","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/may_30_es","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/may_30_es dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"NS-Vox-Complex","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dozingofff/NS-Vox-Complex","creator_name":"Dozingofff","creator_url":"https://huggingface.co/Dozingofff","description":"Dozingofff/NS-Vox-Complex dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"whisper-dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omkars20/whisper-dataset","creator_name":"Omkar Singh","creator_url":"https://huggingface.co/omkars20","description":"omkars20/whisper-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ContextASR-Bench","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrSupW/ContextASR-Bench","creator_name":"He Wang","creator_url":"https://huggingface.co/MrSupW","description":"\n\t\n\t\t\n\t\tContextASR-Bench: A Massive Contextual Speech Recognition Benchmark\n\t\n\n\n\n\n\nAutomatic Speech Recognition (ASR) has been extensively investigated, yet prior evaluative efforts have largely been restricted to contextless paradigms. This constraint stems from the limited proficiency of conventional ASR models in context modeling and their deficiency in memory and reasoning based on world knowledge. Recent breakthroughs in the development of Large Language Models (LLMs) and corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrSupW/ContextASR-Bench.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ContextASR-Bench","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrSupW/ContextASR-Bench","creator_name":"He Wang","creator_url":"https://huggingface.co/MrSupW","description":"\n\t\n\t\t\n\t\tContextASR-Bench: A Massive Contextual Speech Recognition Benchmark\n\t\n\n\n\n\n\nAutomatic Speech Recognition (ASR) has been extensively investigated, yet prior evaluative efforts have largely been restricted to contextless paradigms. This constraint stems from the limited proficiency of conventional ASR models in context modeling and their deficiency in memory and reasoning based on world knowledge. Recent breakthroughs in the development of Large Language Models (LLMs) and corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrSupW/ContextASR-Bench.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"testnew","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/setfunctionenvironment/testnew","creator_name":"setfunctionenvironment","creator_url":"https://huggingface.co/setfunctionenvironment","description":"\n\t\n\t\t\n\t\tAudio Dataset Statistics\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal audio files\n556,667\n\n\nTotal duration\n1,024.71 hours (3,688,949 seconds)\n\n\nAverage duration\n6.63 seconds\n\n\nShortest clip\n0.41 seconds\n\n\nLongest clip\n44.97 seconds\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSpeaker Breakdown\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tTop 10 Speakers by Clip Count\n\t\n\n\n\t\n\t\t\nSpeaker\nClips\nDuration\n% of Total\n\n\n\t\t\nDespina\n60,150\n118.07 hours\n11.5%\n\n\nSulafat\n31,593\n58.15 hours\n5.7%\n\n\nAchernar29,889\n54.53 hours\n5.3%\n\n\nAutonoe\n27,897‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/setfunctionenvironment/testnew.","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Elise","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrDragonFox/Elise","creator_name":"MrDragonFox","creator_url":"https://huggingface.co/MrDragonFox","description":"this is very much a clone of \nhttps://huggingface.co/datasets/Jinsaryko/Elise\nbut with classified emotions like laughs and giggles\nnot ment to be comprehenive - its about 3h in total and will be enough to for a finetuned voice and some basic emotional tags \nshort but sweet - acts as demo test set\n\"giggles - 76\",\n\"laughs - 336\",\n\"long pause - 2\",\n\"chuckles - 20\",\n\"whispers - 2\",\n\"normal volume - 2\",\n\"sighs - 156\",\n\"clicks tongue - 2\",\n\"gasps - 4\",\n\"moans - 8\",\n\"sonora - 2\",\n\"habla en ingl√©s -‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrDragonFox/Elise.","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"NonverbalTTS","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepvk/NonverbalTTS","creator_name":"deep vk","creator_url":"https://huggingface.co/deepvk","description":"\n\t\n\t\t\n\t\tNonverbalTTS Dataset üéµüó£Ô∏è\n\t\n\n\n\nNonverbalTTS is a 17-hour open-access English speech corpus with aligned text annotations for nonverbal vocalizations (NVs) and emotional categories, designed to advance expressive text-to-speech (TTS) research.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features ‚ú®\n\t\n\n\n17 hours of high-quality speech data\n10 NV types: Breathing, laughter, sighing, sneezing, coughing, throat clearing, groaning, grunting, snoring, sniffing\n8 emotion categories: Angry, disgusted, fearful, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepvk/NonverbalTTS.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"NonverbalTTS","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepvk/NonverbalTTS","creator_name":"deep vk","creator_url":"https://huggingface.co/deepvk","description":"\n\t\n\t\t\n\t\tNonverbalTTS Dataset üéµüó£Ô∏è\n\t\n\n\n\nNonverbalTTS is a 17-hour open-access English speech corpus with aligned text annotations for nonverbal vocalizations (NVs) and emotional categories, designed to advance expressive text-to-speech (TTS) research.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features ‚ú®\n\t\n\n\n17 hours of high-quality speech data\n10 NV types: Breathing, laughter, sighing, sneezing, coughing, throat clearing, groaning, grunting, snoring, sniffing\n8 emotion categories: Angry, disgusted, fearful, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepvk/NonverbalTTS.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ami","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edinburghcstr/ami","creator_name":"University of Edingburgh - Centre For Speech Technology Research","creator_url":"https://huggingface.co/edinburghcstr","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_ASR_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Japanese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_ASR_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Japanese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"voice","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_ASR_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Japanese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"RFUAV","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kitofrank/RFUAV","creator_name":"Rui Shi","creator_url":"https://huggingface.co/kitofrank","description":" The RFUAV DATASET \n\nThis repository contains the RFUAV dataset, presented in the paper \"RFUAV: A Benchmark Dataset for Unmanned Aerial Vehicle Detection and Identification\". RFUAV provides approximately 1.3 TB of raw frequency data collected from 37 distinct UAVs, offering a comprehensive benchmark for radio-frequency-based drone detection and identification.  The dataset addresses limitations of existing datasets by providing a diverse range of drone types, sufficient data volume, coverage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kitofrank/RFUAV.","first_N":5,"first_N_keywords":["audio-classification","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ASCEND","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/ASCEND","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"\n\t\n\t\t\n\t\tDataset Card for ASCEND\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CAiRE/ASCEND.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"alvenir_asr_da_eval","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Alvenir/alvenir_asr_da_eval","creator_name":"Alvenir","creator_url":"https://huggingface.co/Alvenir","description":"\n\t\n\t\t\n\t\tDataset Card alvenir_asr_da_eval\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created by Alvenir in order to evaluate ASR models in Danish. It can also be used for training but the amount is very limited.\nThe dataset consists of .wav files with corresponding reference text. The amount of data is just above 5 hours spread across 50 speakers with age in the interval 20-60 years old. The data was collected by a third party vendor through their software and people. All recordings have‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alvenir/alvenir_asr_da_eval.","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"cmu-arctic","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MikhailT/cmu-arctic","creator_name":"Mikhail Tsimashkou","creator_url":"https://huggingface.co/MikhailT","description":"\n\t\n\t\t\n\t\tCMU Arctic Dataset\n\t\n\n","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"the-mc-speech-dataset","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset","creator_name":"Mateusz Czy≈ºnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This is public domain speech dataset consisting of 24018 short audio clips of a single speaker reading sentences in Polish. A transcription is provided for each clip. Clips have total length of more than 22 hours.\nTexts are in public domain. The audio was recorded in 2021-22 as a part of my master's thesis and is in public domain.\nIf you use this dataset, please cite:\n@masterthesis{mcspeech,\n  title={Analiza por√≥wnawcza korpus√≥w nagra≈Ñ mowy dla cel√≥w syntezy mowy w jƒôzyku polskim}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Polish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"AzurLane-voice-transcription","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TLME/AzurLane-voice-transcription","creator_name":"Lethe_End","creator_url":"https://huggingface.co/TLME","description":"\n\t\n\t\t\n\t\n\t\n\t\tAzurLane-voice-transcription\n\t\n\nTotal charcters: 617\nComes with transcription and has undergone dataset cleaning, removing data containing English.\n","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"hifi-tts","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MikhailT/hifi-tts","creator_name":"Mikhail Tsimashkou","creator_url":"https://huggingface.co/MikhailT","description":"Hi-Fi Multi-Speaker English TTS Dataset (Hi-Fi TTS) is based on LibriVox's public domain audio books and Gutenberg Project texts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"hifi-tts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MikhailT/hifi-tts","creator_name":"Mikhail Tsimashkou","creator_url":"https://huggingface.co/MikhailT","description":"Hi-Fi Multi-Speaker English TTS Dataset (Hi-Fi TTS) is based on LibriVox's public domain audio books and Gutenberg Project texts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"nst-da","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nst-da","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is an upload of the NST Danish ASR Database (16 kHz) ‚Äì reorganized.\nThe training and test splits are the original ones.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTraining automatic speech recognition is the intended task for this dataset. No leaderboard is active at this point.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is available in Danish (da).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\nSize of downloaded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nst-da.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"librispeech-alignments","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gilkeyio/librispeech-alignments","creator_name":"Kim Gilkey","creator_url":"https://huggingface.co/gilkeyio","description":"\n\t\n\t\t\n\t\tDataset Card for Librispeech Alignments\n\t\n\nLibrispeech with alignments generated by the Montreal Forced Aligner. The original alignments in TextGrid format can be found here\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLibrispeech is a corpus of read English speech, designed for training and evaluating automatic speech recognition (ASR) systems. The dataset contains 1000 hours of 16kHz read English speech derived from audiobooks.\nThe Montreal Forced Aligner (MFA) was used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gilkeyio/librispeech-alignments.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"google-tamil","keyword":"text-to-audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-tamil","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for Tamil Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 7 hours of transcribed high-quality audio of Tamil sentences recorded by 50 volunteers. The dataset is intended for speech technologies. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).\nautomatic-speech-recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-tamil.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Tamil","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"google-tamil","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-tamil","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for Tamil Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 7 hours of transcribed high-quality audio of Tamil sentences recorded by 50 volunteers. The dataset is intended for speech technologies. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).\nautomatic-speech-recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-tamil.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Tamil","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multilingual-tts","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\n\t\n\t\t\n\t\tBefore Anything and Everything ‚ö±\n\t\n\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) üáµüá∏\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","description":"\n\t\n\t\t\n\t\tAniSpeech Dataset\n\t\n\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\n\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\n\n\n\n\t\n\t\t\n\t\tANNOUNCMENTS:\n\t\n\n\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"voice","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","description":"\n\t\n\t\t\n\t\tAniSpeech Dataset\n\t\n\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\n\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\n\n\n\n\t\n\t\t\n\t\tANNOUNCMENTS:\n\t\n\n\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"libritts_r","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/libritts_r","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\n\t\n\t\t\n\t\tDataset Card for LibriTTS-R\n\t\n\n\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus \n(http://www.openslr.org/60/) which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate, published in 2019.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the LibriTTS-R dataset, adapted for the datasets library.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThere are 7 splits (dots replace dashes from the original dataset, to comply with hf naming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/libritts_r.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"BEAT2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-Liu1997/BEAT2","creator_name":"Haiyang Liu","creator_url":"https://huggingface.co/H-Liu1997","description":"H-Liu1997/BEAT2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"mls_eng","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls_eng","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton. The corpus was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mls-eng-speaker-descriptions","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of English MLS\n\t\n\nThis dataset consists in annotations of the English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Shanghai_Dialect_TTS_openai","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TingChen-ppmc/Shanghai_Dialect_TTS_openai","creator_name":"Ting Chen","creator_url":"https://huggingface.co/TingChen-ppmc","description":"\n\t\n\t\t\n\t\tNotes\n\t\n\n\nSame format as authentic dataset here\nAdded train split (70%) and test split (30%)\nauthentic data of the same split could be found on authentic dataset with split\nsynthesized using Openai tts (self-funded)\nbased on transcription of the anthentic dataset\nsynthesized using TTS for mandarin, with no external prompt\n\n\n\nFor non-comercial use only\n","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"Á≤µË™ûË®àÁÆóË™ûË®ÄÂ≠∏Âü∫Á§éÂª∫Ë®≠ÁµÑ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑Ë¨õÂè§Ë™ûÈü≥Êï∏ÊìöÈõÜ\n\t\n\nEnglish\nÂë¢ÂÄã‰øÇÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„Äã„ÄÅ„ÄäÊ∞¥Êª∏ÂÇ≥„Äã„ÄÅ„ÄäËµ∞ÈÄ≤ÊØõÊæ§Êù±ÁöÑÊúÄÂæåÊ≠≤Êúà„Äã„ÄÅ„ÄäÈπøÈºéË®ò„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ„ÄÇÂºµÊÇ¶Ê•∑‰øÇÂª£Â∑ûÊúÄÂá∫ÂêçÂòÖË¨õÂè§‰Ω¨ / Á≤µË™ûË™¨Êõ∏Ëóù‰∫∫„ÄÇ‰Ω¢Âæû‰∏ä‰∏ñÁ¥Ä‰∏ÉÂçÅÂπ¥‰ª£ÈñãÂßãÂ∞±Âñ∫Âª£Êù±ÂêÑÂÄãÊî∂Èü≥ÈõªÂè∞Â∫¶Ë¨õÂè§Ôºå‰Ω¢ÊääËÅ≤‰øÇÂ•ΩÂ§öÂª£Â∑û‰∫∫ÂòÖÂÖ±ÂêåÂõûÊÜ∂„ÄÇÊú¨Êï∏ÊìöÈõÜÊî∂ÈõÜÂòÖ‰øÇ‰Ω¢ÊúÄÁü•ÂêçÂòÖ‰∏âÈÉ®‰ΩúÂìÅ„ÄÇ\nÊï∏ÊìöÈõÜÁî®ÈÄîÔºö\n\nTTSÔºàË™ûÈü≥ÂêàÊàêÔºâË®ìÁ∑¥ÈõÜ\nASRÔºàË™ûÈü≥Ë≠òÂà•ÔºâË®ìÁ∑¥ÈõÜÊàñÊ∏¨Ë©¶ÈõÜ\nÂêÑÁ®ÆË™ûË®ÄÂ≠∏„ÄÅÊñáÂ≠∏Á†îÁ©∂\nÁõ¥Êé•ËÅΩÂöüÊ¨£Ë≥ûËóùË°ìÔºÅ\n\nTTS ÊïàÊûúÊºîÁ§∫Ôºöhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\tË™¨Êòé\n\t\n\n\nÊâÄÊúâÊñáÊú¨ÈÉΩÊ†πÊìö https://jyutping.org/blog/typo/ Âêå https://jyutping.org/blog/particles/ Ë¶èÁØÑÁî®Â≠ó„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩ‰ΩøÁî®ÂÖ®ËßíÊ®ôÈªûÔºåÂÜáÂçäËßíÊ®ôÈªû„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩÁî®Êº¢Â≠óËΩâÂØ´ÔºåÁÑ°ÈòøÊãâ‰ºØÊï∏Â≠óÁÑ°Ëã±ÊñáÂ≠óÊØç\nÊâÄÊúâÈü≥È†ªÊ∫êÈÉΩÂ≠òÊîæÂñ∫/sourceÔºåÁÇ∫Êñπ‰æøÁõ¥Êé•Áî®‰ΩúË®ìÁ∑¥Êï∏ÊìöÔºåÂàáÂàÜÂæåÂòÖÈü≥È†ªÈÉΩÊîæÂñ∫ opus/\nÊâÄÊúâ opus Èü≥È†ªÁöÜÁÇ∫ 48000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"Á≤µË™ûË®àÁÆóË™ûË®ÄÂ≠∏Âü∫Á§éÂª∫Ë®≠ÁµÑ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑Ë¨õÂè§Ë™ûÈü≥Êï∏ÊìöÈõÜ\n\t\n\nEnglish\nÂë¢ÂÄã‰øÇÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„Äã„ÄÅ„ÄäÊ∞¥Êª∏ÂÇ≥„Äã„ÄÅ„ÄäËµ∞ÈÄ≤ÊØõÊæ§Êù±ÁöÑÊúÄÂæåÊ≠≤Êúà„Äã„ÄÅ„ÄäÈπøÈºéË®ò„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ„ÄÇÂºµÊÇ¶Ê•∑‰øÇÂª£Â∑ûÊúÄÂá∫ÂêçÂòÖË¨õÂè§‰Ω¨ / Á≤µË™ûË™¨Êõ∏Ëóù‰∫∫„ÄÇ‰Ω¢Âæû‰∏ä‰∏ñÁ¥Ä‰∏ÉÂçÅÂπ¥‰ª£ÈñãÂßãÂ∞±Âñ∫Âª£Êù±ÂêÑÂÄãÊî∂Èü≥ÈõªÂè∞Â∫¶Ë¨õÂè§Ôºå‰Ω¢ÊääËÅ≤‰øÇÂ•ΩÂ§öÂª£Â∑û‰∫∫ÂòÖÂÖ±ÂêåÂõûÊÜ∂„ÄÇÊú¨Êï∏ÊìöÈõÜÊî∂ÈõÜÂòÖ‰øÇ‰Ω¢ÊúÄÁü•ÂêçÂòÖ‰∏âÈÉ®‰ΩúÂìÅ„ÄÇ\nÊï∏ÊìöÈõÜÁî®ÈÄîÔºö\n\nTTSÔºàË™ûÈü≥ÂêàÊàêÔºâË®ìÁ∑¥ÈõÜ\nASRÔºàË™ûÈü≥Ë≠òÂà•ÔºâË®ìÁ∑¥ÈõÜÊàñÊ∏¨Ë©¶ÈõÜ\nÂêÑÁ®ÆË™ûË®ÄÂ≠∏„ÄÅÊñáÂ≠∏Á†îÁ©∂\nÁõ¥Êé•ËÅΩÂöüÊ¨£Ë≥ûËóùË°ìÔºÅ\n\nTTS ÊïàÊûúÊºîÁ§∫Ôºöhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\tË™¨Êòé\n\t\n\n\nÊâÄÊúâÊñáÊú¨ÈÉΩÊ†πÊìö https://jyutping.org/blog/typo/ Âêå https://jyutping.org/blog/particles/ Ë¶èÁØÑÁî®Â≠ó„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩ‰ΩøÁî®ÂÖ®ËßíÊ®ôÈªûÔºåÂÜáÂçäËßíÊ®ôÈªû„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩÁî®Êº¢Â≠óËΩâÂØ´ÔºåÁÑ°ÈòøÊãâ‰ºØÊï∏Â≠óÁÑ°Ëã±ÊñáÂ≠óÊØç\nÊâÄÊúâÈü≥È†ªÊ∫êÈÉΩÂ≠òÊîæÂñ∫/sourceÔºåÁÇ∫Êñπ‰æøÁõ¥Êé•Áî®‰ΩúË®ìÁ∑¥Êï∏ÊìöÔºåÂàáÂàÜÂæåÂòÖÈü≥È†ªÈÉΩÊîæÂñ∫ opus/\nÊâÄÊúâ opus Èü≥È†ªÁöÜÁÇ∫ 48000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"Á≤µË™ûË®àÁÆóË™ûË®ÄÂ≠∏Âü∫Á§éÂª∫Ë®≠ÁµÑ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑Ë¨õÂè§Ë™ûÈü≥Êï∏ÊìöÈõÜ\n\t\n\nEnglish\nÂë¢ÂÄã‰øÇÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„Äã„ÄÅ„ÄäÊ∞¥Êª∏ÂÇ≥„Äã„ÄÅ„ÄäËµ∞ÈÄ≤ÊØõÊæ§Êù±ÁöÑÊúÄÂæåÊ≠≤Êúà„Äã„ÄÅ„ÄäÈπøÈºéË®ò„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ„ÄÇÂºµÊÇ¶Ê•∑‰øÇÂª£Â∑ûÊúÄÂá∫ÂêçÂòÖË¨õÂè§‰Ω¨ / Á≤µË™ûË™¨Êõ∏Ëóù‰∫∫„ÄÇ‰Ω¢Âæû‰∏ä‰∏ñÁ¥Ä‰∏ÉÂçÅÂπ¥‰ª£ÈñãÂßãÂ∞±Âñ∫Âª£Êù±ÂêÑÂÄãÊî∂Èü≥ÈõªÂè∞Â∫¶Ë¨õÂè§Ôºå‰Ω¢ÊääËÅ≤‰øÇÂ•ΩÂ§öÂª£Â∑û‰∫∫ÂòÖÂÖ±ÂêåÂõûÊÜ∂„ÄÇÊú¨Êï∏ÊìöÈõÜÊî∂ÈõÜÂòÖ‰øÇ‰Ω¢ÊúÄÁü•ÂêçÂòÖ‰∏âÈÉ®‰ΩúÂìÅ„ÄÇ\nÊï∏ÊìöÈõÜÁî®ÈÄîÔºö\n\nTTSÔºàË™ûÈü≥ÂêàÊàêÔºâË®ìÁ∑¥ÈõÜ\nASRÔºàË™ûÈü≥Ë≠òÂà•ÔºâË®ìÁ∑¥ÈõÜÊàñÊ∏¨Ë©¶ÈõÜ\nÂêÑÁ®ÆË™ûË®ÄÂ≠∏„ÄÅÊñáÂ≠∏Á†îÁ©∂\nÁõ¥Êé•ËÅΩÂöüÊ¨£Ë≥ûËóùË°ìÔºÅ\n\nTTS ÊïàÊûúÊºîÁ§∫Ôºöhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\tË™¨Êòé\n\t\n\n\nÊâÄÊúâÊñáÊú¨ÈÉΩÊ†πÊìö https://jyutping.org/blog/typo/ Âêå https://jyutping.org/blog/particles/ Ë¶èÁØÑÁî®Â≠ó„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩ‰ΩøÁî®ÂÖ®ËßíÊ®ôÈªûÔºåÂÜáÂçäËßíÊ®ôÈªû„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩÁî®Êº¢Â≠óËΩâÂØ´ÔºåÁÑ°ÈòøÊãâ‰ºØÊï∏Â≠óÁÑ°Ëã±ÊñáÂ≠óÊØç\nÊâÄÊúâÈü≥È†ªÊ∫êÈÉΩÂ≠òÊîæÂñ∫/sourceÔºåÁÇ∫Êñπ‰æøÁõ¥Êé•Áî®‰ΩúË®ìÁ∑¥Êï∏ÊìöÔºåÂàáÂàÜÂæåÂòÖÈü≥È†ªÈÉΩÊîæÂñ∫ opus/\nÊâÄÊúâ opus Èü≥È†ªÁöÜÁÇ∫ 48000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"Á≤µË™ûË®àÁÆóË™ûË®ÄÂ≠∏Âü∫Á§éÂª∫Ë®≠ÁµÑ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑Ë¨õÂè§Ë™ûÈü≥Êï∏ÊìöÈõÜ\n\t\n\nEnglish\nÂë¢ÂÄã‰øÇÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„Äã„ÄÅ„ÄäÊ∞¥Êª∏ÂÇ≥„Äã„ÄÅ„ÄäËµ∞ÈÄ≤ÊØõÊæ§Êù±ÁöÑÊúÄÂæåÊ≠≤Êúà„Äã„ÄÅ„ÄäÈπøÈºéË®ò„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ„ÄÇÂºµÊÇ¶Ê•∑‰øÇÂª£Â∑ûÊúÄÂá∫ÂêçÂòÖË¨õÂè§‰Ω¨ / Á≤µË™ûË™¨Êõ∏Ëóù‰∫∫„ÄÇ‰Ω¢Âæû‰∏ä‰∏ñÁ¥Ä‰∏ÉÂçÅÂπ¥‰ª£ÈñãÂßãÂ∞±Âñ∫Âª£Êù±ÂêÑÂÄãÊî∂Èü≥ÈõªÂè∞Â∫¶Ë¨õÂè§Ôºå‰Ω¢ÊääËÅ≤‰øÇÂ•ΩÂ§öÂª£Â∑û‰∫∫ÂòÖÂÖ±ÂêåÂõûÊÜ∂„ÄÇÊú¨Êï∏ÊìöÈõÜÊî∂ÈõÜÂòÖ‰øÇ‰Ω¢ÊúÄÁü•ÂêçÂòÖ‰∏âÈÉ®‰ΩúÂìÅ„ÄÇ\nÊï∏ÊìöÈõÜÁî®ÈÄîÔºö\n\nTTSÔºàË™ûÈü≥ÂêàÊàêÔºâË®ìÁ∑¥ÈõÜ\nASRÔºàË™ûÈü≥Ë≠òÂà•ÔºâË®ìÁ∑¥ÈõÜÊàñÊ∏¨Ë©¶ÈõÜ\nÂêÑÁ®ÆË™ûË®ÄÂ≠∏„ÄÅÊñáÂ≠∏Á†îÁ©∂\nÁõ¥Êé•ËÅΩÂöüÊ¨£Ë≥ûËóùË°ìÔºÅ\n\nTTS ÊïàÊûúÊºîÁ§∫Ôºöhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\tË™¨Êòé\n\t\n\n\nÊâÄÊúâÊñáÊú¨ÈÉΩÊ†πÊìö https://jyutping.org/blog/typo/ Âêå https://jyutping.org/blog/particles/ Ë¶èÁØÑÁî®Â≠ó„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩ‰ΩøÁî®ÂÖ®ËßíÊ®ôÈªûÔºåÂÜáÂçäËßíÊ®ôÈªû„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩÁî®Êº¢Â≠óËΩâÂØ´ÔºåÁÑ°ÈòøÊãâ‰ºØÊï∏Â≠óÁÑ°Ëã±ÊñáÂ≠óÊØç\nÊâÄÊúâÈü≥È†ªÊ∫êÈÉΩÂ≠òÊîæÂñ∫/sourceÔºåÁÇ∫Êñπ‰æøÁõ¥Êé•Áî®‰ΩúË®ìÁ∑¥Êï∏ÊìöÔºåÂàáÂàÜÂæåÂòÖÈü≥È†ªÈÉΩÊîæÂñ∫ opus/\nÊâÄÊúâ opus Èü≥È†ªÁöÜÁÇ∫ 48000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"Á≤µË™ûË®àÁÆóË™ûË®ÄÂ≠∏Âü∫Á§éÂª∫Ë®≠ÁµÑ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑Ë¨õÂè§Ë™ûÈü≥Êï∏ÊìöÈõÜ\n\t\n\nEnglish\nÂë¢ÂÄã‰øÇÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„Äã„ÄÅ„ÄäÊ∞¥Êª∏ÂÇ≥„Äã„ÄÅ„ÄäËµ∞ÈÄ≤ÊØõÊæ§Êù±ÁöÑÊúÄÂæåÊ≠≤Êúà„Äã„ÄÅ„ÄäÈπøÈºéË®ò„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ„ÄÇÂºµÊÇ¶Ê•∑‰øÇÂª£Â∑ûÊúÄÂá∫ÂêçÂòÖË¨õÂè§‰Ω¨ / Á≤µË™ûË™¨Êõ∏Ëóù‰∫∫„ÄÇ‰Ω¢Âæû‰∏ä‰∏ñÁ¥Ä‰∏ÉÂçÅÂπ¥‰ª£ÈñãÂßãÂ∞±Âñ∫Âª£Êù±ÂêÑÂÄãÊî∂Èü≥ÈõªÂè∞Â∫¶Ë¨õÂè§Ôºå‰Ω¢ÊääËÅ≤‰øÇÂ•ΩÂ§öÂª£Â∑û‰∫∫ÂòÖÂÖ±ÂêåÂõûÊÜ∂„ÄÇÊú¨Êï∏ÊìöÈõÜÊî∂ÈõÜÂòÖ‰øÇ‰Ω¢ÊúÄÁü•ÂêçÂòÖ‰∏âÈÉ®‰ΩúÂìÅ„ÄÇ\nÊï∏ÊìöÈõÜÁî®ÈÄîÔºö\n\nTTSÔºàË™ûÈü≥ÂêàÊàêÔºâË®ìÁ∑¥ÈõÜ\nASRÔºàË™ûÈü≥Ë≠òÂà•ÔºâË®ìÁ∑¥ÈõÜÊàñÊ∏¨Ë©¶ÈõÜ\nÂêÑÁ®ÆË™ûË®ÄÂ≠∏„ÄÅÊñáÂ≠∏Á†îÁ©∂\nÁõ¥Êé•ËÅΩÂöüÊ¨£Ë≥ûËóùË°ìÔºÅ\n\nTTS ÊïàÊûúÊºîÁ§∫Ôºöhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\tË™¨Êòé\n\t\n\n\nÊâÄÊúâÊñáÊú¨ÈÉΩÊ†πÊìö https://jyutping.org/blog/typo/ Âêå https://jyutping.org/blog/particles/ Ë¶èÁØÑÁî®Â≠ó„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩ‰ΩøÁî®ÂÖ®ËßíÊ®ôÈªûÔºåÂÜáÂçäËßíÊ®ôÈªû„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩÁî®Êº¢Â≠óËΩâÂØ´ÔºåÁÑ°ÈòøÊãâ‰ºØÊï∏Â≠óÁÑ°Ëã±ÊñáÂ≠óÊØç\nÊâÄÊúâÈü≥È†ªÊ∫êÈÉΩÂ≠òÊîæÂñ∫/sourceÔºåÁÇ∫Êñπ‰æøÁõ¥Êé•Áî®‰ΩúË®ìÁ∑¥Êï∏ÊìöÔºåÂàáÂàÜÂæåÂòÖÈü≥È†ªÈÉΩÊîæÂñ∫ opus/\nÊâÄÊúâ opus Èü≥È†ªÁöÜÁÇ∫ 48000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"VoiceAssistant-400K","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gpt-omni/VoiceAssistant-400K","creator_name":"Changqiao Wu","creator_url":"https://huggingface.co/gpt-omni","description":"gpt-omni/VoiceAssistant-400K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Ceylia","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Ceylia","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Ceylia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V2","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V2","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V2 version and the version described in paper:\n\nThe V2 version provide audio in 44.1kHz sample rate. (Supersampling)\nThe V2 versionn removed some samples (~5%) due to the volumn and text aligment issues.\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to address the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V2.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V2","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V2","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V2 version and the version described in paper:\n\nThe V2 version provide audio in 44.1kHz sample rate. (Supersampling)\nThe V2 versionn removed some samples (~5%) due to the volumn and text aligment issues.\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to address the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V2.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V2","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V2","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V2 version and the version described in paper:\n\nThe V2 version provide audio in 44.1kHz sample rate. (Supersampling)\nThe V2 versionn removed some samples (~5%) due to the volumn and text aligment issues.\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to address the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V2.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V2","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V2","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V2 version and the version described in paper:\n\nThe V2 version provide audio in 44.1kHz sample rate. (Supersampling)\nThe V2 versionn removed some samples (~5%) due to the volumn and text aligment issues.\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to address the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V2.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"LAION-Audio-300M","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/LAION-Audio-300M","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"laion/LAION-Audio-300M dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100M - 1B","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tarjoman-persian-asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PerSets/tarjoman-persian-asr","creator_name":"Persian Datasets","creator_url":"https://huggingface.co/PerSets","description":"\n\t\n\t\t\n\t\tTarjoman Podcast 2023 ASR Dataset\n\t\n\nThis datasets consists of a collection of 507 articles from the Tarjoman website until the end of 2023, each accompanied by corresponding audio recordings.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes complete articles along with their audio counterparts. Each article is presented in its entirety, without sentence segmentation. Every entry contains the following metadata fields:\n\nTitle: The main title of the article.\nSubtitle: A secondary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PerSets/tarjoman-persian-asr.","first_N":5,"first_N_keywords":["Persian","cc0-1.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"gemini-flash-2.0-speech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"\n\t\n\t\t\n\t\tüéôÔ∏è Gemini Flash 2.0 Speech Dataset\n\t\n\n\nThis is a high quality synthetic speech dataset generated by Gemini Flash 2.0 via the Multimodal Live API. It contains speech from 2 speakers - Puck (Male) and Kore (Female) in English.\nüèÖ #1 Trending Audio Dataset in Feb 2025\nüèÖ Used in training of Kokoro TTS and LLaSA 1B\n\n\t\n\t\n\t\n\t\t„ÄΩÔ∏è Stats\n\t\n\nTotal number of audio files: 47,256*2 = 94512Total duration: 1023527.20seconds (284.31 hours)   \nAverage duration: 10.83 seconds   \nShortest file: 0.6‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"gemini-flash-2.0-speech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"\n\t\n\t\t\n\t\tüéôÔ∏è Gemini Flash 2.0 Speech Dataset\n\t\n\n\nThis is a high quality synthetic speech dataset generated by Gemini Flash 2.0 via the Multimodal Live API. It contains speech from 2 speakers - Puck (Male) and Kore (Female) in English.\nüèÖ #1 Trending Audio Dataset in Feb 2025\nüèÖ Used in training of Kokoro TTS and LLaSA 1B\n\n\t\n\t\n\t\n\t\t„ÄΩÔ∏è Stats\n\t\n\nTotal number of audio files: 47,256*2 = 94512Total duration: 1023527.20seconds (284.31 hours)   \nAverage duration: 10.83 seconds   \nShortest file: 0.6‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Punjabi","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Punjabi","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tPunjabi Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Punjabi monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Punjabi\nTotal Duration: ~20 hours (Male: 10 hours, Female: 10 hours)\nAudio Format: WAV\nSampling Rate: 48000Hz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Punjabi.","first_N":5,"first_N_keywords":["text-to-speech","pb","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MLAAD","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mueller91/MLAAD","creator_name":"Nicolas M√ºller","creator_url":"https://huggingface.co/mueller91","description":"\n  \n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWelcome to MLAAD: The Multi-Language Audio Anti-Spoofing Dataset -- a dataset to train, test and evaluate audio deepfake detection. See\nthe paper for more information.\n\n\t\n\t\t\n\t\tDownload the dataset\n\t\n\n# if needed, install git-lfs\nsudo apt-get install git-lfs\ngit lfs install\n# clone the repository\ngit clone https://huggingface.co/datasets/mueller91/MLAAD\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is based on the M-AILABS dataset.\nMLAAD is structured as follows:\nfake‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mueller91/MLAAD.","first_N":5,"first_N_keywords":["audio-classification","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"MLAAD","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mueller91/MLAAD","creator_name":"Nicolas M√ºller","creator_url":"https://huggingface.co/mueller91","description":"\n  \n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWelcome to MLAAD: The Multi-Language Audio Anti-Spoofing Dataset -- a dataset to train, test and evaluate audio deepfake detection. See\nthe paper for more information.\n\n\t\n\t\t\n\t\tDownload the dataset\n\t\n\n# if needed, install git-lfs\nsudo apt-get install git-lfs\ngit lfs install\n# clone the repository\ngit clone https://huggingface.co/datasets/mueller91/MLAAD\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is based on the M-AILABS dataset.\nMLAAD is structured as follows:\nfake‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mueller91/MLAAD.","first_N":5,"first_N_keywords":["audio-classification","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"MLAAD","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mueller91/MLAAD","creator_name":"Nicolas M√ºller","creator_url":"https://huggingface.co/mueller91","description":"\n  \n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWelcome to MLAAD: The Multi-Language Audio Anti-Spoofing Dataset -- a dataset to train, test and evaluate audio deepfake detection. See\nthe paper for more information.\n\n\t\n\t\t\n\t\tDownload the dataset\n\t\n\n# if needed, install git-lfs\nsudo apt-get install git-lfs\ngit lfs install\n# clone the repository\ngit clone https://huggingface.co/datasets/mueller91/MLAAD\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is based on the M-AILABS dataset.\nMLAAD is structured as follows:\nfake‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mueller91/MLAAD.","first_N":5,"first_N_keywords":["audio-classification","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"MLAAD","keyword":"voice","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mueller91/MLAAD","creator_name":"Nicolas M√ºller","creator_url":"https://huggingface.co/mueller91","description":"\n  \n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWelcome to MLAAD: The Multi-Language Audio Anti-Spoofing Dataset -- a dataset to train, test and evaluate audio deepfake detection. See\nthe paper for more information.\n\n\t\n\t\t\n\t\tDownload the dataset\n\t\n\n# if needed, install git-lfs\nsudo apt-get install git-lfs\ngit lfs install\n# clone the repository\ngit clone https://huggingface.co/datasets/mueller91/MLAAD\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is based on the M-AILABS dataset.\nMLAAD is structured as follows:\nfake‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mueller91/MLAAD.","first_N":5,"first_N_keywords":["audio-classification","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"nigerian_accented_english_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Accent English Speech Data 1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Accent Speech Data is a comprehensive dataset of about 8 hours of audio recordings featuring speakers from various regions of Nigeria, \ncapturing the rich diversity of Nigerian accents. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for researchers and developers working on Automatic Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","English"],"keywords_longer_than_N":true},
	{"name":"DailyTalkContiguous","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kyutai/DailyTalkContiguous","creator_name":"Kyutai","creator_url":"https://huggingface.co/kyutai","description":"\n\t\n\t\t\n\t\tDailyTalkContiguous\n\t\n\nThis repo contains a concatenated version of the DailyTalk dataset (official repo).\nRather than having separate files for each speaker's turn, this uses a stereo file for each conversation. The two speakers in a conversation\nare put separately on the left and right channels.\nThe dataset is annotated with word level timestamps.\nThe original DailyTalk dataset and baseline code are freely available for academic use with CC-BY-SA 4.0 license, this dataset\nuses the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kyutai/DailyTalkContiguous.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Sentiment-Reasoning","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","description":"\n\t\n\t\t\n\t\tSentiment Reasoning for Healthcare\n\t\n\nACL 2025 (Oral)\nKhai-Nguyen Nguyen*, Khai Le-Duc*, Bach Phan Tat, Duy Le, Long Vo-Dang, Truong-Son Hy\n\n*Equal contribution\n\n\nPlease press ‚≠ê button and/or cite papers if you feel helpful.\n\n\n  \n\nSentiment Reasoning pipeline\n\n\nAbstract:\nTransparency in AI healthcare decision-making is crucial. By incorporating rationales to explain reason for each predicted label, users could understand Large Language Models (LLMs)‚Äôs reasoning to make better decision.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning.","first_N":5,"first_N_keywords":["text-generation","text-classification","audio-classification","automatic-speech-recognition","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"Sentiment-Reasoning","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","description":"\n\t\n\t\t\n\t\tSentiment Reasoning for Healthcare\n\t\n\nACL 2025 (Oral)\nKhai-Nguyen Nguyen*, Khai Le-Duc*, Bach Phan Tat, Duy Le, Long Vo-Dang, Truong-Son Hy\n\n*Equal contribution\n\n\nPlease press ‚≠ê button and/or cite papers if you feel helpful.\n\n\n  \n\nSentiment Reasoning pipeline\n\n\nAbstract:\nTransparency in AI healthcare decision-making is crucial. By incorporating rationales to explain reason for each predicted label, users could understand Large Language Models (LLMs)‚Äôs reasoning to make better decision.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning.","first_N":5,"first_N_keywords":["text-generation","text-classification","audio-classification","automatic-speech-recognition","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"AudioTrust","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JusperLee/AudioTrust","creator_name":"Kai Li","creator_url":"https://huggingface.co/JusperLee","description":"üéß AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models\n\n  üìú Paper | üé∂ Demo | üíª Code | ü§ó Dataset\n\n\nAudioTrust is a large-scale benchmark designed to evaluate the multifaceted trustworthiness of Multimodal Audio Language Models (ALLMs). It examines model behavior across six critical dimensions:\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Benchmark Tasks\n\t\n\n\n\t\n\t\t\nTask\nMetric\nDescription\n\n\n\t\t\nHallucination Detection\nAccuracy / Recall\nGroundedness of response in audio\n\n\nRobustness‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JusperLee/AudioTrust.","first_N":5,"first_N_keywords":["audio-text-to-text","English","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MMSU","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ddwang2000/MMSU","creator_name":"ElaineWang","creator_url":"https://huggingface.co/ddwang2000","description":"\n\t\n\t\t\n\t\tMMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark\n\t\n\n\n\t\n\t\t\n\t\tOverview of MMSU:\n\t\n\nMMSU, a comprehensive benchmark designed specifically for understanding and reasoning in spoken language. \nMMSU comprises 5,000 meticulously curated audio-question-answer triplets across 47 distinct tasks. \nTo ground our benchmark in linguistic theory, we systematically incorporate a wide range of linguistic phenomena, including phonetics, prosody, syntax, syntactics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ddwang2000/MMSU.","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"tts-indo","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agufsamudra/tts-indo","creator_name":"Gufranaka Samudra","creator_url":"https://huggingface.co/agufsamudra","description":"\n\t\n\t\t\n\t\tagufsamudra/tts-indo\n\t\n\nagufsamudra/tts-indo is a preprocessed Indonesian speech dataset designed for training Text-to-Speech (TTS) models. This dataset is derived from the original Dataset TTS Indo available on Kaggle.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nNumber of Examples: 114,036\nDataset Size: ~4GB\nAudio Sampling Rate: 16,000 Hz\nFeatures:\naudio: WAV audio recordings\ntext: Transcription of the audio\n\n\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach sample in the dataset contains:\n\naudio: A dictionary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agufsamudra/tts-indo.","first_N":5,"first_N_keywords":["text-to-speech","Indonesian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"SynStard-1000","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cksqs/SynStard-1000","creator_name":"Pu Yu","creator_url":"https://huggingface.co/cksqs","description":"\n\t\n\t\t\n\t\tSynStard-1000\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSynStard-1000 is a 1,000-hour synthetic dataset for training and evaluating end-to-end speech-to-speech translation (S2ST) models. It is built from English-Chinese parallel texts in the WMT News Commentary v18 corpus and contains approximately 390,000 sentence pairs with paired synthetic speech.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n.\n‚îú‚îÄ‚îÄ map/\n‚îÇ   ‚îî‚îÄ‚îÄ all.tsv\n‚îÇ‚îÄ‚îÄ text/\n‚îÇ   ‚îú‚îÄ‚îÄ en/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ en.txt\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ en_1.txt\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cksqs/SynStard-1000.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"SynStard-1000","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cksqs/SynStard-1000","creator_name":"Pu Yu","creator_url":"https://huggingface.co/cksqs","description":"\n\t\n\t\t\n\t\tSynStard-1000\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSynStard-1000 is a 1,000-hour synthetic dataset for training and evaluating end-to-end speech-to-speech translation (S2ST) models. It is built from English-Chinese parallel texts in the WMT News Commentary v18 corpus and contains approximately 390,000 sentence pairs with paired synthetic speech.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n.\n‚îú‚îÄ‚îÄ map/\n‚îÇ   ‚îî‚îÄ‚îÄ all.tsv\n‚îÇ‚îÄ‚îÄ text/\n‚îÇ   ‚îú‚îÄ‚îÄ en/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ en.txt\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ en_1.txt\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cksqs/SynStard-1000.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"KAI-indian-emotional-speech-corpus","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kratos-AI/KAI-indian-emotional-speech-corpus","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","description":"\n\t\n\t\t\n\t\tIndian Emotional Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset comprises high-quality audio recordings of Indian speakers reading a standardized 50-word paragraph in four distinct emotional tones ‚Äî happy, sad, surprised, and angry.\nEach recording is approximately 20‚Äì25 seconds long and includes the full paragraph with tone shifts at specific points.\nText spoken by all participants:\n\n(happy tone) Last Monday was perfect‚ÄîI got the job I‚Äôd been dreaming of! I screamed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/KAI-indian-emotional-speech-corpus.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"KAI-indian-emotional-speech-corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kratos-AI/KAI-indian-emotional-speech-corpus","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","description":"\n\t\n\t\t\n\t\tIndian Emotional Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset comprises high-quality audio recordings of Indian speakers reading a standardized 50-word paragraph in four distinct emotional tones ‚Äî happy, sad, surprised, and angry.\nEach recording is approximately 20‚Äì25 seconds long and includes the full paragraph with tone shifts at specific points.\nText spoken by all participants:\n\n(happy tone) Last Monday was perfect‚ÄîI got the job I‚Äôd been dreaming of! I screamed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/KAI-indian-emotional-speech-corpus.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"wav2phone-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WariHima/wav2phone-dataset","creator_name":"‰ºëÊöá‰∫≠„ÄÄÂêëÊó•Ëëµ","creator_url":"https://huggingface.co/WariHima","description":"jvnv-nonv„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË©±ËÄÖf2„ÅßÂ≠¶Áøí„Åó„ÅüVoiceSpeechMaker„ÅÆ„É¢„Éá„É´„Åß„ÄÅjsut„Ç≥„Éº„Éë„Çπ„ÅÆÊõ∏„Åç‰∏ã„ÅóÂàÜ„ÇíÊé®Ë´ñ„Åó„ÄÅÊé®Ë´ñÊôÇ„ÅÆ„Éï„É´„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„É©„Éô„É´„Å®„Éö„Ç¢„Å´„Åó„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô\n„Éï„É´„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„É©„Éô„É´„ÅØÊ¨°„ÅÆ„Çà„ÅÜ„Å™ÂΩ¢Âºè„Åß„Åô(hf„ÅÆ„Éó„É¨„Éì„É•„Éº„ÅØÂ£ä„Çå„Å¶„ÅÑ„Åæ„Åô)\nxx^xx-sil+m=i/A:xx+xx+xx/B:xx-xx_xx/C:xx_xx+xx/D:02+xx_xx/E:xx_xx!xx_xx-xx/F:xx_xx#xx_xx@xx_xx|xx_xx/G:3_3%0_0_xx/H:xx_xx/I:xx-xx@xx+xx&xx-xx|xx+xx/J:3_23/K:1+3-23\nxx^sil-m+i=z/A:-2+1+3/B:xx-xx_xx/C:02_xx+xx/D:13+xx_xx/E:xx_xx!xx_xx-xx/F:3_3#0_0@1_3|1_23/G:7_2%0_0_1/H:xx_xx/I:3-23@1+1&1-3|1+23/J:xx_xx/K:1+3-23‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WariHima/wav2phone-dataset.","first_N":5,"first_N_keywords":["mit","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"StreamUni","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ICTNLP/StreamUni","creator_name":"Natural Language Processing Group, Institute of Computing Technology, Chinese Academy of Science","creator_url":"https://huggingface.co/ICTNLP","description":"\n\t\n\t\t\n\t\tThe training dataset for the paper 'StreamUni: Achieving Streaming Speech Translation with a Unified Large Speech-Language Model'\n\t\n\n\n\t\n\t\t\n\t\tModel\n\t\n\n\nhttps://huggingface.co/ICTNLP/StreamUni-Phi4\n\n\n\t\n\t\t\n\t\tGithub\n\t\n\n\nhttps://github.com/ictnlp/StreamUni\n\n","first_N":5,"first_N_keywords":["translation","Chinese","English","French","German"],"keywords_longer_than_N":true},
	{"name":"audioset-nonspeech","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bond005/audioset-nonspeech","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","description":"\n\t\n\t\t\n\t\tAudioset-Nonspeech\n\t\n\nAudioset-Nonspeech is a processed version of the well-known agkphysics/AudioSet dataset. The processing was performed to remove all audio recordings that may contain clearly distinguishable human speech, leaving only non-speech audio recordings. The resulting Audioset-Nonspeech dataset can be used not only for audio event classification but also for augmentation (mixing with a specified signal-to-noise ratio) of speech recordings when training speech recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bond005/audioset-nonspeech.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"audioset-nonspeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bond005/audioset-nonspeech","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","description":"\n\t\n\t\t\n\t\tAudioset-Nonspeech\n\t\n\nAudioset-Nonspeech is a processed version of the well-known agkphysics/AudioSet dataset. The processing was performed to remove all audio recordings that may contain clearly distinguishable human speech, leaving only non-speech audio recordings. The resulting Audioset-Nonspeech dataset can be used not only for audio event classification but also for augmentation (mixing with a specified signal-to-noise ratio) of speech recordings when training speech recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bond005/audioset-nonspeech.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"taudio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wjiaqi/taudio","creator_name":"Jiaqi Wang","creator_url":"https://huggingface.co/wjiaqi","description":"wjiaqi/taudio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tropical-gunshot-wda-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aazmaine25/tropical-gunshot-wda-dataset","creator_name":"Aazmaine Alif Abrar","creator_url":"https://huggingface.co/aazmaine25","description":"aazmaine25/tropical-gunshot-wda-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"TikTok_Most_Shared_Video_Transcription_Example","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MasaFoundation/TikTok_Most_Shared_Video_Transcription_Example","creator_name":"MasaAI","creator_url":"https://huggingface.co/MasaFoundation","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MasaFoundation/TikTok_Most_Shared_Video_Transcription_Example.","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"NPSC_test","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/NPSC_test","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\n\t\n\t\t\n\t\tDataset Card for NBAiLab/NPSC\n\t\n\nThe Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Spr√•kbanken at the National Library in Norway. \nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokm√•l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/NPSC_test.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"NPSC_test","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/NPSC_test","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\n\t\n\t\t\n\t\tDataset Card for NBAiLab/NPSC\n\t\n\nThe Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Spr√•kbanken at the National Library in Norway. \nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokm√•l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/NPSC_test.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"FSD50k","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Fhrozen/FSD50k","creator_name":"Nelson Yalta","creator_url":"https://huggingface.co/Fhrozen","description":"\n\t\n\t\t\n\t\tFreesound Dataset 50k (FSD50K)\n\t\n\n\n\t\n\t\t\n\t\tImportant\n\t\n\nThis data set is a copy from the original one located at Zenodo.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use the FSD50K dataset, or part of it, please cite our paper:\n\nEduardo Fonseca, Xavier Favory, Jordi Pons, Frederic Font, Xavier Serra. \"FSD50K: an Open Dataset of Human-Labeled Sound Events\", arXiv 2020.\n\n\n\t\n\t\t\n\t\tData curators\n\t\n\nEduardo Fonseca, Xavier Favory, Jordi Pons, Mercedes Collado, Ceren Can, Rachit Gupta, Javier Arredondo, Gary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fhrozen/FSD50k.","first_N":5,"first_N_keywords":["audio-classification","unknown","unknown","unknown","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"FSD50k","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Fhrozen/FSD50k","creator_name":"Nelson Yalta","creator_url":"https://huggingface.co/Fhrozen","description":"\n\t\n\t\t\n\t\tFreesound Dataset 50k (FSD50K)\n\t\n\n\n\t\n\t\t\n\t\tImportant\n\t\n\nThis data set is a copy from the original one located at Zenodo.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use the FSD50K dataset, or part of it, please cite our paper:\n\nEduardo Fonseca, Xavier Favory, Jordi Pons, Frederic Font, Xavier Serra. \"FSD50K: an Open Dataset of Human-Labeled Sound Events\", arXiv 2020.\n\n\n\t\n\t\t\n\t\tData curators\n\t\n\nEduardo Fonseca, Xavier Favory, Jordi Pons, Mercedes Collado, Ceren Can, Rachit Gupta, Javier Arredondo, Gary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fhrozen/FSD50k.","first_N":5,"first_N_keywords":["audio-classification","unknown","unknown","unknown","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ascend","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/filwsyl/ascend","creator_name":"jianyuan.zengjy","creator_url":"https://huggingface.co/filwsyl","description":"\n\t\n\t\t\n\t\tDataset Card for ASCEND\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/filwsyl/ascend.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"resd","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/resd","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tDataset Card for resd\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRussian dataset of emotional speech dialogues. This dataset was assembled from ~3.5 hours of live speech by actors who voiced pre-distributed emotions in the dialogue for ~3 minutes each.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniemore/resd.","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","expert-generated","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"resd","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/resd","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tDataset Card for resd\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRussian dataset of emotional speech dialogues. This dataset was assembled from ~3.5 hours of live speech by actors who voiced pre-distributed emotions in the dialogue for ~3 minutes each.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniemore/resd.","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","expert-generated","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"REPV","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/REPV","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tCitations\n\t\n\n@misc{Aniemore,\n  author = {–ê—Ä—Ç–µ–º –ê–º–µ–Ω—Ç–µ—Å, –ò–ª—å—è –õ—É–±–µ–Ω–µ—Ü, –ù–∏–∫–∏—Ç–∞ –î–∞–≤–∏–¥—á—É–∫},\n  title = {–û—Ç–∫—Ä—ã—Ç–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤ —Ä–µ—á–∏ —á–µ–ª–æ–≤–µ–∫–∞},\n  year = {2022},\n  publisher = {Hugging Face},\n  journal = {Hugging Face Hub},\n  howpublished = {\\url{https://huggingface.com/aniemore/Aniemore}},\n  email = {hello@socialcode.ru}\n}\n\n","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"REPV-S","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/REPV-S","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tCitations\n\t\n\n@misc{Aniemore,\n  author = {–ê—Ä—Ç–µ–º –ê–º–µ–Ω—Ç–µ—Å, –ò–ª—å—è –õ—É–±–µ–Ω–µ—Ü, –ù–∏–∫–∏—Ç–∞ –î–∞–≤–∏–¥—á—É–∫},\n  title = {–û—Ç–∫—Ä—ã—Ç–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤ —Ä–µ—á–∏ —á–µ–ª–æ–≤–µ–∫–∞},\n  year = {2022},\n  publisher = {Hugging Face},\n  journal = {Hugging Face Hub},\n  howpublished = {\\url{https://huggingface.com/aniemore/Aniemore}},\n  email = {hello@socialcode.ru}\n}\n\n","first_N":5,"first_N_keywords":["audio-classification","audio-emotion-recognition","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"dani-voice","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/daniel-dona/dani-voice","creator_name":"Daniel Do√±a","creator_url":"https://huggingface.co/daniel-dona","description":"daniel-dona/dani-voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"EmiratiDialictShowsAudioTranscription","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eabayed/EmiratiDialictShowsAudioTranscription","creator_name":"Ahmed Abdulla Eabayed AlDhanhani","creator_url":"https://huggingface.co/eabayed","description":"This dataset contains two files: a zipped file with segmented audio files from Emirati TV shows, podcasts, or YouTube channels, and a tsv file containing the transcription of the zipped audio files.\nThe purpose of the dataset is to act as a benchmark for Automatic Speech Recognition models that work with the Emirati dialect. \nThe dataset is made so that it covers different categories: traditions, cars, health, games, sports, and police.\nAlthough the dataset is for the emirati dialect‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eabayed/EmiratiDialictShowsAudioTranscription.","first_N":5,"first_N_keywords":["afl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"infore25","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/awghuku/infore25","creator_name":"Anh","creator_url":"https://huggingface.co/awghuku","description":"awghuku/infore25 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"earnings22","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anton-l/earnings22","creator_name":"Anton Lozhkov","creator_url":"https://huggingface.co/anton-l","description":"The Earnings 22 dataset ( also referred to as earnings22 ) is a 119-hour corpus of English-language earnings calls collected from global companies. \nThe primary purpose is to serve as a benchmark for industrial and academic automatic speech recognition (ASR) models on real-world accented speech.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","Audio","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"SNIPS","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/s3prl/SNIPS","creator_name":"s3prl","creator_url":"https://huggingface.co/s3prl","description":"s3prl/SNIPS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","text","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"earnings22_robust","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anton-l/earnings22_robust","creator_name":"Anton Lozhkov","creator_url":"https://huggingface.co/anton-l","description":"\\nThe Earnings 22 dataset ( also referred to as earnings22 ) is a 119-hour corpus of English-language earnings calls collected from global companies. \nThe primary purpose is to serve as a benchmark for industrial and academic automatic speech recognition (ASR) models on real-world accented speech.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","Audio","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"zeroth-korean","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/zeroth-korean","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\n\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\nZeroth project introduces free Korean speech corpus and aims to make Korean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/zeroth-korean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","monolingual","extended|kresnik/zeroth_korean","Korean"],"keywords_longer_than_N":true},
	{"name":"ami-6h","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pokameswaran/ami-6h","creator_name":"Ponniah Kameswaran","creator_url":"https://huggingface.co/pokameswaran","description":"pokameswaran/ami-6h dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"earn","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/polinaeterna/earn","creator_name":"Polina Kazakova","creator_url":"https://huggingface.co/polinaeterna","description":"polinaeterna/earn dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"waxal-wolof","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/perrynelson/waxal-wolof","creator_name":"Perry Nelson","creator_url":"https://huggingface.co/perrynelson","description":"perrynelson/waxal-wolof dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"youtube-transcriptions","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jamescalam/youtube-transcriptions","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","description":"The YouTube transcriptions dataset contains technical tutorials (currently from James Briggs, Daniel Bourke, and AI Coffee Break) transcribed using OpenAI's Whisper (large). Each row represents roughly a sentence-length chunk of text alongside the video URL and timestamp.\nNote that each item in the dataset contains just a short chunk of text. For most use cases you will likely need to merge multiple rows to create more substantial chunks of text, if you need to do that, this code snippet will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jamescalam/youtube-transcriptions.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","visual-question-answering","open-domain-qa","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"youtube-transcriptions","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jamescalam/youtube-transcriptions","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","description":"The YouTube transcriptions dataset contains technical tutorials (currently from James Briggs, Daniel Bourke, and AI Coffee Break) transcribed using OpenAI's Whisper (large). Each row represents roughly a sentence-length chunk of text alongside the video URL and timestamp.\nNote that each item in the dataset contains just a short chunk of text. For most use cases you will likely need to merge multiple rows to create more substantial chunks of text, if you need to do that, this code snippet will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jamescalam/youtube-transcriptions.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","visual-question-answering","open-domain-qa","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"misc","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nateraw/misc","creator_name":"Nate Raw","creator_url":"https://huggingface.co/nateraw","description":"nateraw/misc dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"sova_rudevices","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bond005/sova_rudevices","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","description":"\n\t\n\t\t\n\t\tDataset Card for sova_rudevices\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSOVA Dataset is free public STT/ASR dataset. It consists of several parts, one of them is SOVA RuDevices. This part is an acoustic corpus of approximately 100 hours of 16kHz Russian live speech with manual annotating, prepared by SOVA.ai team.\nAuthors do not divide the dataset into train, validation and test subsets. Therefore, I was compelled to prepare this splitting. The training subset includes more than 82 hours, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bond005/sova_rudevices.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"sova_rudevices","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bond005/sova_rudevices","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","description":"\n\t\n\t\t\n\t\tDataset Card for sova_rudevices\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSOVA Dataset is free public STT/ASR dataset. It consists of several parts, one of them is SOVA RuDevices. This part is an acoustic corpus of approximately 100 hours of 16kHz Russian live speech with manual annotating, prepared by SOVA.ai team.\nAuthors do not divide the dataset into train, validation and test subsets. Therefore, I was compelled to prepare this splitting. The training subset includes more than 82 hours, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bond005/sova_rudevices.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"caes","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmvasque/caes","creator_name":"Laura V√°squez-Rodr√≠guez","creator_url":"https://huggingface.co/lmvasque","description":"\n\t\n\t\t\n\t\tAbout this dataset\n\t\n\nThe CAES (Parodi, 2015) dataset, also referred as the ‚ÄúCorpus de Aprendices del Espa√±ol‚Äù (CAES), is a collection of texts created by Spanish L2 learners from Spanish learning centres and universities. These students had different learning levels, different backgrounds (11 native languages) and various levels of experience with the language. We used web scraping techniques to download a portion of the full dataset since its current website only provides content‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lmvasque/caes.","first_N":5,"first_N_keywords":["cc-by-4.0","soundfolder","Audio","Datasets","Croissant"],"keywords_longer_than_N":true},
	{"name":"libri","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bgstud/libri","creator_name":"bc","creator_url":"https://huggingface.co/bgstud","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bgstud/libri.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"libri-whisper-raw","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bgstud/libri-whisper-raw","creator_name":"bc","creator_url":"https://huggingface.co/bgstud","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bgstud/libri-whisper-raw.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"IMaSC","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/IMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tIMaSC: ICFOSS Malayalam Speech Corpus\n\t\n\nIMaSC is a Malayalam text and speech corpus made available by ICFOSS for the purpose of developing speech technology for Malayalam, particularly text-to-speech. The corpus contains 34,473 text-audio pairs of Malayalam sentences spoken by 8 speakers, totalling in approximately 50 hours of audio.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 34,473 instances with fields text, speaker, and audio. The audio is mono, sampled at 16kH. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/IMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"dummy_corpus_asr_es","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/dummy_corpus_asr_es","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository where the audio files are not compressed in tar files.\n","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_dummy","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy","creator_name":"Sanchit Gandhi","creator_url":"https://huggingface.co/sanchit-gandhi","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr_dummy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a truncated version of the LibriSpeech dataset. It contains 20 samples from each of the splits. To view the full dataset, visit: https://huggingface.co/datasets/librispeech_asr\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_dummy","keyword":"speaker-identification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy","creator_name":"Sanchit Gandhi","creator_url":"https://huggingface.co/sanchit-gandhi","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr_dummy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a truncated version of the LibriSpeech dataset. It contains 20 samples from each of the splits. To view the full dataset, visit: https://huggingface.co/datasets/librispeech_asr\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_dummy","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy","creator_name":"Sanchit Gandhi","creator_url":"https://huggingface.co/sanchit-gandhi","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr_dummy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a truncated version of the LibriSpeech dataset. It contains 20 samples from each of the splits. To view the full dataset, visit: https://huggingface.co/datasets/librispeech_asr\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_es","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_es","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ravnursson_asr","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"\n\t\n\t\t\n\t\tDataset Card for ravnursson_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus \"RAVNURSSON FAROESE SPEECH AND TRANSCRIPTS\" (or RAVNURSSON Corpus for short) is a collection of speech recordings with transcriptions intended for Automatic Speech Recognition (ASR) applications in the language that is spoken at the Faroe Islands (Faroese). It was curated at the Reykjav√≠k University (RU) in 2022.\nThe RAVNURSSON Corpus is an extract of the \"Basic Language Resource Kit 1.0\" (BLARK 1.0) [1] developed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"nujdiki","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/4eJIoBek/nujdiki","creator_name":"katyshek","creator_url":"https://huggingface.co/4eJIoBek","description":"–¥–≤–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: –æ–¥–∏–Ω —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –Ω—É–∂–¥–∏–∫–∞–º–∏ –∏ –æ–¥–∏–Ω –ø–æ–º–µ–Ω—å—à–µ —Å –ø—É–ø–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω—É–∂–¥–∏–∫–æ–≤. –æ–±–∞ –≤ –∞—É–¥–∏–æ –∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.\n","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"common-voice-test16k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-voice-test16k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice-test16k.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-voice-test3k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-voice-test3k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice-test3k.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-voice","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ciempiess_test","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_test","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"The CIEMPIESS TEST Corpus is a gender balanced corpus destined to test acoustic models for the speech recognition task. The corpus was manually transcribed and it contains audio recordings from 10 male and 10 female speakers. The CIEMPIESS TEST is one of the three corpora included at the LDC's \\\"CIEMPIESS Experimentation\\\" (LDC2019S07).","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"telugu_asr","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bnriiitb/telugu_asr","creator_name":"Naga Budigam","creator_url":"https://huggingface.co/bnriiitb","description":"bnriiitb/telugu_asr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"dmeo","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/dmeo","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/dmeo.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"samromur_children","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_children","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"The Samr√≥mur Children corpus contains more than 137000 validated speech-recordings uttered by Icelandic children.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"raddromur_asr","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"\n\t\n\t\t\n\t\tDataset Card for raddromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Raddr√≥mur Icelandic Speech 22.09\" (\"Raddr√≥mur Corpus\" for short) is an Icelandic corpus created by the Language and Voice Laboratory (LVL) at Reykjav√≠k University (RU) in 2022. It is made out of radio podcasts mostly taken from R√öV (ruv.is).\n\n\t\n\t\t\n\t\tExample Usage\n\t\n\nThe Raddr√≥mur Corpus counts with the train split only. To load the training split pass its name as a config name:\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"speaker-recognition-american-rhetoric","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/owahltinez/speaker-recognition-american-rhetoric","creator_name":"Oscar W","creator_url":"https://huggingface.co/owahltinez","description":"owahltinez/speaker-recognition-american-rhetoric dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"commonvoice_accent_test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/commonvoice_accent_test","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/commonvoice_accent_test.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"quran-data","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ashraf-ali/quran-data","creator_name":"Ashraf Ali","creator_url":"https://huggingface.co/ashraf-ali","description":"\n\t\n\t\t\n\t\tDataset Card for Quran audio\n\t\n\nContent \n\n7 Imam Full Quran Recitation: 7*6236 wav file\ncsv contains the Text info for 11k subset short wav file\n\n\nTarteel.io user dataset ~25k wav\ncsv contains the Text info for 18k subset of the accepted user quality\n\n\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tarteel.io","cc0-1.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"common-native","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-native","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-native.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"spectrogram-captions","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vucinatim/spectrogram-captions","creator_name":"Tim Vuƒçina","creator_url":"https://huggingface.co/vucinatim","description":"Dataset of captioned spectrograms (text describing the sound).\n","first_N":5,"first_N_keywords":["text-to-image","machine-generated","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"common-accent","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common-accent-proc","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-proc.","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech_test_noise","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joefox/LibriSpeech_test_noise","creator_name":"joefox","creator_url":"https://huggingface.co/joefox","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nAugmented part of the test data of the LibriSpeech dataset.\nAs a basis, the original part of the test was taken, and augmentation was carried out to add extraneous noise.\n","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Mozilla_Common_Voice_ru_test_noise","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joefox/Mozilla_Common_Voice_ru_test_noise","creator_name":"joefox","creator_url":"https://huggingface.co/joefox","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nAugmented part of the test data of the Mozilla Common Voice (part 10, ru, test)  dataset.\nAs a basis, the original part of the test was taken, and augmentation was carried out to add extraneous noise.\nPart dataset: test\n","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Russian_LibriSpeech_RuLS_test_noise","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joefox/Russian_LibriSpeech_RuLS_test_noise","creator_name":"joefox","creator_url":"https://huggingface.co/joefox","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nAugmented part of the test data of the Russian LibriSpeech (RuLS) test part dataset.\nAs a basis, the original part of the test was taken, and augmentation was carried out to add extraneous noise.\nPart dataset: test\n","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"libris_clean_100","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automatic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"libris_clean_100","keyword":"speaker-identification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automatic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"libris_clean_100","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automatic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"TongaASR_Space_Examples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kalisia/TongaASR_Space_Examples","creator_name":"Kalinda Siaminwe","creator_url":"https://huggingface.co/kalisia","description":"kalisia/TongaASR_Space_Examples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"everyayah","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tarteel-ai/everyayah","creator_name":"Tarteel AI","creator_url":"https://huggingface.co/tarteel-ai","description":"Ô∑Ω\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Arabic.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA typical data point comprises the audio file audio, and its transcription called text.\nThe duration is in seconds, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarteel-ai/everyayah.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"msc","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/msc","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tSMC Malayalam Speech Corpus\n\t\n\nMalayalam Speech Corpus (MSC) is a repository of curated speech samples collected using MSC web application, released by Swathanthra Malayalam Computing. \nThe official blog post and source data can be found at https://blog.smc.org.in/malayalam-speech-corpus/.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe first version of Malayalam Speech Corpus contains 1541 speech samples from 75 contributors amounting to 1:38:16 hours of speech. It has 482 unique sentences, 1400‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/msc.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"ulca_ml","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/ulca_ml","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tULCA ASR Dataset Malayalam Speech Corpus\n\t\n\nThe labelled Malayalam speech subcorpus from the larger ULCA ASR Corpus.\nThe speech is taken from news broadcasts, and is largely composed of short soundbites with some longer outliers.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","found","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"mm_speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aungmyatv8/mm_speech","creator_name":"Aung Myint Mytat","creator_url":"https://huggingface.co/aungmyatv8","description":"This dataset contains speech(wave files) from a single woman and the tsv file contain transcript of the speech files\n","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Donate_a_cry","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nooon/Donate_a_cry","creator_name":"Nouran Ahmed Ibrahim","creator_url":"https://huggingface.co/Nooon","description":"Nooon/Donate_a_cry dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"muc","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/syzym/muc","creator_name":"Senyan Li","creator_url":"https://huggingface.co/syzym","description":"syzym/muc dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"EngASRwithCVWav","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kabir5297/EngASRwithCVWav","creator_name":"A F M MAHFUZUL KABIR","creator_url":"https://huggingface.co/kabir5297","description":"kabir5297/EngASRwithCVWav dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Umamusume-voice-text-pairs","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Plachta/Umamusume-voice-text-pairs","creator_name":"ElderFrog","creator_url":"https://huggingface.co/Plachta","description":"Plachta/Umamusume-voice-text-pairs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"bn_emotion_speech_corpus","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sustcsenlp/bn_emotion_speech_corpus","creator_name":"SUST CSE NLP Research","creator_url":"https://huggingface.co/sustcsenlp","description":"SUST Bangla Emotional Speech Coropus Dataset","first_N":5,"first_N_keywords":["audio-classification","Bengali","cc-by-4.0","1K - 10K","Audio"],"keywords_longer_than_N":true},
	{"name":"bn_emotion_speech_corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sustcsenlp/bn_emotion_speech_corpus","creator_name":"SUST CSE NLP Research","creator_url":"https://huggingface.co/sustcsenlp","description":"SUST Bangla Emotional Speech Coropus Dataset","first_N":5,"first_N_keywords":["audio-classification","Bengali","cc-by-4.0","1K - 10K","Audio"],"keywords_longer_than_N":true},
	{"name":"whisper-sun-system-dataset","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/suwitlam/whisper-sun-system-dataset","creator_name":"Suwit Arnmanee","creator_url":"https://huggingface.co/suwitlam","description":"suwitlam/whisper-sun-system-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"simple_tamil","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Achitha/simple_tamil","creator_name":"M","creator_url":"https://huggingface.co/Achitha","description":"The data contains roughly one and half hours of audio and transcripts in Tamil language.","first_N":5,"first_N_keywords":["translation","Tamil","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"hungarian-single-speaker-tts","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts","creator_name":"KTH","creator_url":"https://huggingface.co/KTH","description":"\n\t\n\t\t\n\t\tDataset Card for CSS10 Hungarian: Single Speaker Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus consists of a single speaker, with 4515 segments extracted\nfrom a single LibriVox audiobook.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Hungarian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts.","first_N":5,"first_N_keywords":["text-to-speech","other","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"voxforge-ru-dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dangrebenkin/voxforge-ru-dataset","creator_name":"Daniel Grebenkin","creator_url":"https://huggingface.co/dangrebenkin","description":"\n\t\n\t\t\n\t\tDataset audio info\n\t\n\n\n16000 Hz 16 bit\nwav\nmono\nRussian speech\n\n\n\t\n\t\t\n\t\tDataset instance structure\n\t\n\n{'audio': {'path': '/path/to/wav.wav',\n  'array': array([wav numpy array]), dtype=float32),\n  'sampling_rate': 16000},\n 'transcription': '—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è'}\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@Misc{Voxforge.org,\n  author = {Voxforge.org},\n  title = {Free Speech... Recognition (Linux, Windows and Mac) - voxforge.org},\n  howpublished = {\\url{[http://www.voxforge.org/]}},\n  note = {accessed 01/21/2023}\n}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dangrebenkin/voxforge-ru-dataset.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"gos-demo","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bartelds/gos-demo","creator_name":"Martijn Bartelds","creator_url":"https://huggingface.co/bartelds","description":"\n\t\n\t\t\n\t\tGronings transcribed speech\n\t\n\nDemonstration dataset with Gronings transcribed speech based on the dataset released by San et al. (2021).\nFor more information see the corresponding ASRU 2021 paper.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Gronings","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"spoken_words_en_ml_commons_filtered_split","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TheSeriousProgrammer/spoken_words_en_ml_commons_filtered_split","creator_name":"Chidhambararajan","creator_url":"https://huggingface.co/TheSeriousProgrammer","description":"TheSeriousProgrammer/spoken_words_en_ml_commons_filtered_split dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"spoken_words_en_ml_commons_filtered_split","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TheSeriousProgrammer/spoken_words_en_ml_commons_filtered_split","creator_name":"Chidhambararajan","creator_url":"https://huggingface.co/TheSeriousProgrammer","description":"TheSeriousProgrammer/spoken_words_en_ml_commons_filtered_split dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"spoken_words_en_ml_commons_filtered_split","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TheSeriousProgrammer/spoken_words_en_ml_commons_filtered_split","creator_name":"Chidhambararajan","creator_url":"https://huggingface.co/TheSeriousProgrammer","description":"TheSeriousProgrammer/spoken_words_en_ml_commons_filtered_split dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"venv-me","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GlowingBrick/venv-me","creator_name":"GlowingBrick","creator_url":"https://huggingface.co/GlowingBrick","description":"GlowingBrick/venv-me dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","text","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"sova_rudevices_audiobooks","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dangrebenkin/sova_rudevices_audiobooks","creator_name":"Daniel Grebenkin","creator_url":"https://huggingface.co/dangrebenkin","description":"\n\t\n\t\t\n\t\tDataset instance structure\n\t\n\n{'audio': {'path': '/path/to/wav.wav',\n  'array': array([wav numpy array]), dtype=float32),\n  'sampling_rate': 16000},\n 'transcription': '—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è'}\n\n\t\n\t\t\n\t\tDataset audio info\n\t\n\n\n16000 Hz\nwav\nmono\nRussian speech from audiobooks\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{sova2021rudevices,\n  author = {Zubarev, Egor and Moskalets, Timofey and SOVA.ai},\n  title = {SOVA RuDevices Dataset: free public STT/ASR dataset with manually annotated live speech},\n  publisher =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dangrebenkin/sova_rudevices_audiobooks.","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"atco2_only_augmented","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/luigisaetta/atco2_only_augmented","creator_name":"LuigiSaetta","creator_url":"https://huggingface.co/luigisaetta","description":"luigisaetta/atco2_only_augmented dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"cmu-arctic-xvectors","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors","creator_name":"Matthijs Hollemans","creator_url":"https://huggingface.co/Matthijs","description":"\n\t\n\t\t\n\t\tSpeaker embeddings extracted from CMU ARCTIC\n\t\n\nThere is one .npy file for each utterance in the dataset, 7931 files in total. The speaker embeddings are 512-element X-vectors.\nThe CMU ARCTIC dataset divides the utterances among the following speakers:\n\nbdl (US male)\nslt (US female)\njmk (Canadian male)\nawb (Scottish male)\nrms (US male)\nclb (US female)\nksp (Indian male)\n\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\nUsage:\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors.","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","mit","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/j-krzywdziak/test","creator_name":"Justyna Krzywdziak","creator_url":"https://huggingface.co/j-krzywdziak","description":"Lorem ipsum","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"sampled_audio4ft","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Plachta/sampled_audio4ft","creator_name":"ElderFrog","creator_url":"https://huggingface.co/Plachta","description":"Plachta/sampled_audio4ft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"test2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/j-krzywdziak/test2","creator_name":"Justyna Krzywdziak","creator_url":"https://huggingface.co/j-krzywdziak","description":"Lorem ipsum","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","Audio"],"keywords_longer_than_N":true},
	{"name":"resd_annotated","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/resd_annotated","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tDataset Card for \"resd_annotated\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["audio-classification","Russian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"resd_annotated","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/resd_annotated","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tDataset Card for \"resd_annotated\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["audio-classification","Russian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"resd_annotated","keyword":"voice","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/resd_annotated","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\n\t\n\t\t\n\t\tDataset Card for \"resd_annotated\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["audio-classification","Russian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mr_trial","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bhatvineet/mr_trial","creator_name":"Vineet Bhat","creator_url":"https://huggingface.co/bhatvineet","description":"bhatvineet/mr_trial dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["afl-3.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"zydxn77","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zydxn77/zydxn77","creator_name":"yinzhang","creator_url":"https://huggingface.co/zydxn77","description":"zydxn77/zydxn77 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"zydxn","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zydxn77/zydxn","creator_name":"yinzhang","creator_url":"https://huggingface.co/zydxn77","description":"zydxn77/zydxn dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"N_Nazarbayev_Speech_corpus","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shirali/N_Nazarbayev_Speech_corpus","creator_name":"Kadyrov","creator_url":"https://huggingface.co/Shirali","description":"About Dataset\nThis dataset is taken from https://www.kaggle.com/datasets/bolattleubayev/nursultan-nazarbayev-speech-dataset\nThe dataset consists of manually labelled 9341 wav files (around 14.8 hours) taken from speeches of The First President of the Republic of Kazakhstan Nursultan Nazarbayev published online. 7919 files (12.1 hours) are in Russian and 1422 files (2.7 hours) in Kazakh. Minimum duration: 0.42 sec, maximum: 13.00 sec, mean: 5.71 sec.\nThe dataset was collected as a part of a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Shirali/N_Nazarbayev_Speech_corpus.","first_N":5,"first_N_keywords":["cc0-1.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"nursultan_nazarbayev_speech","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shirali/nursultan_nazarbayev_speech","creator_name":"Kadyrov","creator_url":"https://huggingface.co/Shirali","description":"Shirali/nursultan_nazarbayev_speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"synthetic_compassion","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/birgermoell/synthetic_compassion","creator_name":"Birger Moell","creator_url":"https://huggingface.co/birgermoell","description":"\n\t\n\t\t\n\t\tDataset Card for \"synthetic_compassion\"\n\t\n\nSynthetic compassion is a dataset consisting of generated compassionate speech for meditation and psychology advice. \nThe dataset consists of unique voices as each audio file has its own synthetic voice.\nThe speech is generated with Tortoise TTS\n\n\t\n\t\t\n\t\tHow to use\n\t\n\nHere is how you can load the dataset\nfrom datasets import load_dataset\ndataset = load_dataset(\"birgermoell/synthetic_compassion\")\n\n","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"test-user","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/polinaeterna/test-user","creator_name":"Polina Kazakova","creator_url":"https://huggingface.co/polinaeterna","description":"Lorem ipsum","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"sbtal_riksdag_asr","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jimregan/sbtal_riksdag_asr","creator_name":"Jim O'Regan","creator_url":"https://huggingface.co/jimregan","description":"jimregan/sbtal_riksdag_asr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"NINJAL-Ainu-Folklore","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wav2gloss/NINJAL-Ainu-Folklore","creator_name":"CMU LTI Wav2Gloss Project","creator_url":"https://huggingface.co/wav2gloss","description":"\n\t\n\t\t\n\t\tDataset Card for NINJAL Ainu Folklore\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAinu is an endangered (nearly extinct) language spoken in Hokkaido, Japan. This dataset contains recordings of 38 traditional Ainu folktales by two Ainu speakers (Mrs. Kimi Kimura and Mrs. Ito Oda), along with their transcriptions (in Latin script), English translations, and underlying and surface gloss forms in English. (For transcriptions in Katakana and translation/gloss in Japanese, please see the original corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wav2gloss/NINJAL-Ainu-Folklore.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","Audio","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"prezident_ru","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/spdenisov/prezident_ru","creator_name":"Sviatoslav Denisov","creator_url":"https://huggingface.co/spdenisov","description":"These recording and transcripts have been copied from the Russian President's website at kremlin.ru. All content on this site is licensed under Creative Commons Attribution 4.0 International.\nhttp://en.kremlin.ru/about/copyrights\n","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","Audio","Video","Datasets"],"keywords_longer_than_N":true},
	{"name":"Ver0_voice_dataset","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ThePioneer/Ver0_voice_dataset","creator_name":"The Pioneer","creator_url":"https://huggingface.co/ThePioneer","description":"ThePioneer/Ver0_voice_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Ald_Mexican_Spanish_speech_dataset","keyword":"audio","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/rmcpantoja/Ald_Mexican_Spanish_speech_dataset","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"This dataset can be used to fine-tune Speech To Text models as Text To Speech.\n\n\t\n\t\t\n\t\tdataset information\n\t\n\n\nSpeaker: Aldo\nDataset size: 535 audio files\naudio duration of 4-15 seconds (1:33:15)\n\n\n\t\n\t\t\n\t\tDataset structure\n\t\n\nThis dataset has been structured in the LJSpeech format:\n\nwavs/\n1.wav\n2.wav\n3.wav\n\n\n535.wav\n\n\ntranscript.csv\n\n","first_N":5,"first_N_keywords":["token-classification","Spanish","unlicense","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"dingzhen-voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/acdzh/dingzhen-voice","creator_name":"z","creator_url":"https://huggingface.co/acdzh","description":"Â∫îËØ•Ê≤°Â§ñÂõΩ‰∫∫Áî®ÔºåÁõ¥Êé•Áî®‰∏≠ÊñáÂêß\ndingzhen.zip ÊòØÂ£∞Ê∫êÂéãÁº©Êñá‰ª∂ÔºåÂ£∞Ê∫êÊù•Ëá™‰∏§ÈÉ®ÂàÜ\n\nÊüêÊ¨°ÂΩïÊí≠(qh_0_*.wav)Ôºö220725‰∏ÅÁúüÁõ¥Êí≠ÂΩïÂ±èÂÆåÊï¥Áâà_ÂìîÂì©ÂìîÂì©_bilibili\nÁ≤òÂêàÂõΩÊºîËÆ≤(qh_1_*.wav)Ôºö‰∏ÅÁúü Âá∫Â∏≠ËÅîÂêàÂõΩÊºîËÆ≤(ÂÆåÊï¥Áâà)ÊØ´‰∏çÊÄØÂú∫ ‰ªéÂÆπËá™Ëã• Â•ΩÊúâÈ≠ÖÂäõ_ÂìîÂì©ÂìîÂì©_bilibili\n\ncuts.txt ÊòØÂØπÂ∫îÊñá‰ª∂Â≠óÂπï„ÄÇ\n","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tadokoro-voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/acdzh/tadokoro-voice","creator_name":"z","creator_url":"https://huggingface.co/acdzh","description":"ÈáéÂÖΩÂÖàËæàÈü≥Â£∞Á¥†Êùê\nÊù•Ê∫êÔºöhttps://www.nicovideo.jp/watch/sm31721928\n","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"banc-trawsgrifiadau-bangor","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prvInSpace/banc-trawsgrifiadau-bangor","creator_name":"Preben Vangberg","creator_url":"https://huggingface.co/prvInSpace","description":"Huggingface Dataset version of Banc Trawsgrifiadau Bangor","first_N":5,"first_N_keywords":["automatic-speech-recognition","Welsh","cc0-1.0","10K - 100K","Audio"],"keywords_longer_than_N":true},
	{"name":"Cylonix_ASR_CV","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Haodon/Cylonix_ASR_CV","creator_name":"Cylonix","creator_url":"https://huggingface.co/Haodon","description":"Haodon/Cylonix_ASR_CV dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"or_in_dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ranjit/or_in_dataset","creator_name":"Ranjit Patro","creator_url":"https://huggingface.co/Ranjit","description":"Ranjit/or_in_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Oriya","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"testdataset","keyword":"audio","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/KevinGeng/testdataset","creator_name":"Kevin Geng","creator_url":"https://huggingface.co/KevinGeng","description":"KevinGeng/testdataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["bsd-2-clause","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"BirdCLEF-Challenge2023-Kaggle","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bernardocecchetto/BirdCLEF-Challenge2023-Kaggle","creator_name":"Bernardo Cecchetto","creator_url":"https://huggingface.co/bernardocecchetto","description":"This dataset contains audios of 264 species of birds singing that were all processed. It was processed as follows:\n\nStereo to Mono\nResampled 16kHz\nHigh Pass Filter (1500Hz and filter order of 16)\nNormalized\n\nThe raw dataset was provided by the BirdCLEF 2023 challenge from Kaggle. You can access it in https://www.kaggle.com/competitions/birdclef-2023/data\n","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"pop2piano_ci","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sweetcocoa/pop2piano_ci","creator_name":"Jongho Choi","creator_url":"https://huggingface.co/sweetcocoa","description":"sweetcocoa/pop2piano_ci dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"spinetta","keyword":"audio-to-audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/santifiorino/spinetta","creator_name":"Santiago Fiorino","creator_url":"https://huggingface.co/santifiorino","description":"Samples de ~10-15 segundos de Luis Alberto Spinetta cantando.\nLimpio, sin instrumentos y sin silencios.\nCanciones de Pescado Rabioso, Almendra, Invisible y como solista.\n","first_N":5,"first_N_keywords":["audio-to-audio","Spanish","artistic-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"spinetta","keyword":"audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/santifiorino/spinetta","creator_name":"Santiago Fiorino","creator_url":"https://huggingface.co/santifiorino","description":"Samples de ~10-15 segundos de Luis Alberto Spinetta cantando.\nLimpio, sin instrumentos y sin silencios.\nCanciones de Pescado Rabioso, Almendra, Invisible y como solista.\n","first_N":5,"first_N_keywords":["audio-to-audio","Spanish","artistic-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"AESDD","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EdwardLin2023/AESDD","creator_name":"EdwardLin","creator_url":"https://huggingface.co/EdwardLin2023","description":"AESDD v1.0 was created on October 2017 in the Laboratory of Electronic Media, \nSchool of Journalism and Mass Communications, Aristotle University of Thessaloniki, \nfor the needs of Speech Emotion Recognition research of the Multidisciplinary Media & \nMediated Communication Research Group (M3C, http://m3c.web.auth.gr/).\n\nFor the creation of v.1 of the database, 5 (3 female and 2 male) professional actors were recorded. \n19 utterances of ambiguous out of context emotional content were chosen. \nThe actors acted these 19 utterances in every one of the 5 chosen emotions. \nOne extra improvised utterance was added for every actor and emotion. \nThe guidance of the actors and the choice of the final recordings were supervised by \na scientific expert in dramatology. For some of the utterances, more that one takes were qualified. \nConsequently, around 500 utterances occured in the final database.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","Audio","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"snips_slu_v1.0","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MWilinski/snips_slu_v1.0","creator_name":"Micha≈Ç Wili≈Ñski","creator_url":"https://huggingface.co/MWilinski","description":"\n\t\n\t\t\n\t\tDataset Card for SNIPS SLU v1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains SNIPS SLU Speech Recognition Dataset, available here.\nIt contains recordings of commands for smart home appliances in English, with info about demographics of the speaker.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ASVP_ESD","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EdwardLin2023/ASVP_ESD","creator_name":"EdwardLin","creator_url":"https://huggingface.co/EdwardLin2023","description":"ASVP-ESD","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","Audio","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Kasugano-Sora","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PorYoung/Kasugano-Sora","creator_name":"PorYoung","creator_url":"https://huggingface.co/PorYoung","description":"\n\t\n\t\t\n\t\tÊò•Êó•ÈáéÁ©π(Kasugano Sora) Èü≥Â£∞Êï∞ÊçÆÈõÜ\n\t\n\nÊï∞ÊçÆÈõÜÊèêÂèñËá™„ÄäÁºò‰πãÁ©∫„ÄãÂíå„ÄäÊÇ†‰πãÁ©∫„ÄãÔºåÂâîÈô§ÈÉ®ÂàÜ‰∏çÂíåË∞êÁöÑÈü≥Â£∞\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜËØ¥Êòé\n\t\n\n\n\t\n\t\t\n\t\tÁºò‰πãÁ©∫\n\t\n\n\n\t\n\t\t\n\t\tÊÇ†‰πãÁ©∫\n\t\n\n\n\t\n\t\t\n\t\tÁî∞Âè£ÂÆèÂ≠ê(ÂÆ´ÊùëÂÆ´Â≠ê)Ê≠åÂ£∞\n\t\n\n\n\t\n\t\t\n\t\tÂÖçË¥£Â£∞Êòé\n\t\n\nÊú¨È°πÁõÆÂÜÖÂÆπ‰ªÖ‰æõÂ≠¶‰π†‰∫§ÊµÅÔºå‰∏•Á¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÂíå‰ªé‰∫ãÂÖ∂‰ªñÈùûÊ≥ïÂíåÊúâËøùÂÖ¨Â∫èËâØ‰øóÁöÑÊ¥ªÂä®ÔºåËØ∑‰∫é24Â∞èÊó∂ÂÜÖÂà†Èô§ÔºÅ\n","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enriched","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enriched","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"This is a set of one-second .wav audio files, each containing a single spoken\nEnglish word or background noise. These words are from a small set of commands, and are spoken by a\nvariety of different speakers. This data set is designed to help train simple\nmachine learning models. This dataset is covered in more detail at\n[https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\n\nVersion 0.01 of the data set (configuration `\"v0.01\"`) was released on August 3rd 2017 and contains\n64,727 audio files.\n\nIn version 0.01 thirty different words were recoded: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n\"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", \"Wow\".\n\n\nIn version 0.02 more words were added: \"Backward\", \"Forward\", \"Follow\", \"Learn\", \"Visual\".\n\nIn both versions, ten of them are used as commands by convention: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\". Other words are considered to be auxiliary (in current implementation\nit is marked by `True` value of `\"is_unknown\"` feature). Their function is to teach a model to distinguish core words\nfrom unrecognized ones.\nThis version is not yet supported.\n\nThe `_silence_` class contains a set of longer audio clips that are either recordings or\na mathematical simulation of noise.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enriched","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enriched","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"This is a set of one-second .wav audio files, each containing a single spoken\nEnglish word or background noise. These words are from a small set of commands, and are spoken by a\nvariety of different speakers. This data set is designed to help train simple\nmachine learning models. This dataset is covered in more detail at\n[https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\n\nVersion 0.01 of the data set (configuration `\"v0.01\"`) was released on August 3rd 2017 and contains\n64,727 audio files.\n\nIn version 0.01 thirty different words were recoded: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n\"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", \"Wow\".\n\n\nIn version 0.02 more words were added: \"Backward\", \"Forward\", \"Follow\", \"Learn\", \"Visual\".\n\nIn both versions, ten of them are used as commands by convention: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\". Other words are considered to be auxiliary (in current implementation\nit is marked by `True` value of `\"is_unknown\"` feature). Their function is to teach a model to distinguish core words\nfrom unrecognized ones.\nThis version is not yet supported.\n\nThe `_silence_` class contains a set of longer audio clips that are either recordings or\na mathematical simulation of noise.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enriched","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enriched","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"This is a set of one-second .wav audio files, each containing a single spoken\nEnglish word or background noise. These words are from a small set of commands, and are spoken by a\nvariety of different speakers. This data set is designed to help train simple\nmachine learning models. This dataset is covered in more detail at\n[https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\n\nVersion 0.01 of the data set (configuration `\"v0.01\"`) was released on August 3rd 2017 and contains\n64,727 audio files.\n\nIn version 0.01 thirty different words were recoded: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n\"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", \"Wow\".\n\n\nIn version 0.02 more words were added: \"Backward\", \"Forward\", \"Follow\", \"Learn\", \"Visual\".\n\nIn both versions, ten of them are used as commands by convention: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\". Other words are considered to be auxiliary (in current implementation\nit is marked by `True` value of `\"is_unknown\"` feature). Their function is to teach a model to distinguish core words\nfrom unrecognized ones.\nThis version is not yet supported.\n\nThe `_silence_` class contains a set of longer audio clips that are either recordings or\na mathematical simulation of noise.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"xecanto_birds","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Saads/xecanto_birds","creator_name":"Saad Ashraf","creator_url":"https://huggingface.co/Saads","description":"Saads/xecanto_birds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tttttttt","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zomehwh/tttttttt","creator_name":"zome","creator_url":"https://huggingface.co/zomehwh","description":"zomehwh/tttttttt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"birdsounds","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Saads/birdsounds","creator_name":"Saad Ashraf","creator_url":"https://huggingface.co/Saads","description":"Saads/birdsounds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"MELD_Audio_3Labels","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EdwardLin2023/MELD_Audio_3Labels","creator_name":"EdwardLin","creator_url":"https://huggingface.co/EdwardLin2023","description":"Multimodal EmotionLines Dataset (MELD) has been created by enhancing and extending EmotionLines dataset. \nMELD contains the same dialogue instances available in EmotionLines, but it also encompasses audio and \nvisual modality along with text. MELD has more than 1400 dialogues and 13000 utterances from Friends TV series. \nMultiple speakers participated in the dialogues. Each utterance in a dialogue has been labeled by any of these \nseven emotions -- Anger, Disgust, Sadness, Joy, Neutral, Surprise and Fear. MELD also has sentiment (positive, \nnegative and neutral) annotation for each utterance.\n\nThis dataset is slightly modified, so that it concentrates on Emotion recognition in audio input only.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","Audio","Datasets","Croissant"],"keywords_longer_than_N":true},
	{"name":"french-conversation","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Snit/french-conversation","creator_name":"Vincent","creator_url":"https://huggingface.co/Snit","description":"+15 hours of speech data from TTS and text file recording.\n+9k utterances from various sources, novels, parliamentary debates, professional language.\n","first_N":5,"first_N_keywords":["French","cc-by-4.0","10K - 100K","text","Audio"],"keywords_longer_than_N":true},
	{"name":"km-speech-corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seanghay/km-speech-corpus","creator_name":"seanghay","creator_url":"https://huggingface.co/seanghay","description":"\n\t\n\t\t\n\t\tDataset Card for \"km-speech-corpus\"\n\t\n\nsampling_rate: 16000\nmean_seconds: 2.5068187111021882\nmax_seconds: 19.392\nmin_seconds: 0.448\ntotal_seconds: 37459.392\ntotal_hrs: 10.405386666666667\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Khmer","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"GreendamOpencpop","keyword":"audio","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/255doesnotexist/GreendamOpencpop","creator_name":"ezra","creator_url":"https://huggingface.co/255doesnotexist","description":"\n\t\n\t\t\n\t\tWarning\n\t\n\nThis is a specialized dataset for greendam. YOU CANNOT USE IT if you have no original dataset access permisson from Opencpop team.\nYou could requst access permission for original dataset via Google Forms or email.\n\n\t\n\t\t\n\t\tWhat is opencpop?\n\t\n\nOpencpop, a publicly available high-quality Mandarin singing corpus, is designed for singing voice synthesis (SVS) systems. This corpus consists of 100 unique Mandarin songs, which were recorded by a professional female singer. All‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/255doesnotexist/GreendamOpencpop.","first_N":5,"first_N_keywords":["gpl-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"audio_test_dataset","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/audio_test_dataset","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\n\t\n\t\t\n\t\tDataset Card for \"audio_test_dataset\"\n\t\n\nThis dataset consists of the first 5 samples of mozilla-foundation/common_voice_13_0 and is only used for unit testing.\n","first_N":5,"first_N_keywords":["Danish","cc0-1.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"m4singer","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/umoubuton/m4singer","creator_name":"Umoubuton","creator_url":"https://huggingface.co/umoubuton","description":"umoubuton/m4singer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"paimon","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/umoubuton/paimon","creator_name":"Umoubuton","creator_url":"https://huggingface.co/umoubuton","description":"umoubuton/paimon dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"GMaSC","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/GMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tGMaSC: GEC Barton Hill Malayalam Speech Corpus\n\t\n\nGMaSC is a Malayalam text and speech corpus created by the Government Engineering College Barton Hill with an emphasis on Malayalam-accented English. The corpus contains 2,000 text-audio pairs of Malayalam sentences spoken by 2 speakers, totalling in approximately 139 minutes of audio. Each sentences has at least one English word common in Malayalam speech.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 2,000 instances with fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/GMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"3.0","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lin-df4g/3.0","creator_name":"lin-df4g","creator_url":"https://huggingface.co/lin-df4g","description":"lin-df4g/3.0 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"kafuu_chino_voice_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/umoubuton/kafuu_chino_voice_dataset","creator_name":"Umoubuton","creator_url":"https://huggingface.co/umoubuton","description":"umoubuton/kafuu_chino_voice_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"art_sr_vc1_mini1","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nyaa97/art_sr_vc1_mini1","creator_name":"Micha≈Ç Zawieja","creator_url":"https://huggingface.co/Nyaa97","description":"Nyaa97/art_sr_vc1_mini1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"art_sr_vc1_test","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nyaa97/art_sr_vc1_test","creator_name":"Micha≈Ç Zawieja","creator_url":"https://huggingface.co/Nyaa97","description":"Nyaa97/art_sr_vc1_test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"carl_johnson_voice_pack","keyword":"audio","license":"BSD 3-Clause Clear License","license_url":"https://choosealicense.com/licenses/bsd-3-clause-clear/","language":"en","dataset_url":"https://huggingface.co/datasets/Katock/carl_johnson_voice_pack","creator_name":"Katock Guo","creator_url":"https://huggingface.co/Katock","description":"\n\t\n\t\t\n\t\tCarl Johnson Voice Pack/Dataset\n\t\n\n","first_N":5,"first_N_keywords":["bsd-3-clause-clear","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"audio_es","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/joelespinozaro/audio_es","creator_name":"Joel Espinoza Rojas","creator_url":"https://huggingface.co/joelespinozaro","description":"joelespinozaro/audio_es dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"latin_music","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ramonpzg/latin_music","creator_name":"Ramon Perez","creator_url":"https://huggingface.co/ramonpzg","description":"ramonpzg/latin_music dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"audio_letters_eo","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xekri/audio_letters_eo","creator_name":"Xekri Dragon","creator_url":"https://huggingface.co/xekri","description":"Audio files sampled at 48000Hz of an American male pronouncing the names of the Esperanto letters in three ways. Retroflex-r and trilled-r are included.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Esperanto","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"genshin_ch_10npc","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmj2002/genshin_ch_10npc","creator_name":"xmj","creator_url":"https://huggingface.co/xmj2002","description":"\n\t\n\t\t\n\t\tDataset Card for \"genshin_ch_10npc\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Ainu","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ananyaayasi/Ainu","creator_name":"Ananya Ayasi","creator_url":"https://huggingface.co/ananyaayasi","description":"ananyaayasi/Ainu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"NINJAL-Ainu-Folklore","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/junyinc/NINJAL-Ainu-Folklore","creator_name":"Junyin Chen","creator_url":"https://huggingface.co/junyinc","description":"\n\t\n\t\t\n\t\tDataset Card for NINJAL Ainu Folklore\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAinu is an endangered (nearly extinct) language spoken in Hokkaido, Japan. This dataset contains recordings of 38 traditional Ainu folktales by two Ainu speakers (Mrs. Kimi Kimura and Mrs. Ito Oda), along with their transcriptions (in Latin script), English translations, and underlying and surface gloss forms in English. (For transcriptions in Katakana and translation/gloss in Japanese, please see the original corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/junyinc/NINJAL-Ainu-Folklore.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","Audio","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"arxiv_audio_archived","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/taesiri/arxiv_audio_archived","creator_name":"taesiri","creator_url":"https://huggingface.co/taesiri","description":"taesiri/arxiv_audio_archived dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"TangoPromptBank","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/declare-lab/TangoPromptBank","creator_name":"Deep Cognition and Language Research (DeCLaRe) Lab","creator_url":"https://huggingface.co/declare-lab","description":"\n\t\n\t\t\n\t\tProject Links\n\t\n\nGithub\nWeb\nHuggingface Space\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was used to Pre-train Tango-Full-FT-Audiocaps. TangoPromptBank is a diverse corpus consisting of textual prompts and audio samples sourced from WavCaps [1], AudioCaps [9], ESC [2], UrbanSound [3], MusicCaps [4], GTZAN [5], and Musical Instruments [6] dataset. The dataset statistics are reported in Table 1. All audio clips longer than 10 seconds were segmented into partitions of successive 10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/declare-lab/TangoPromptBank.","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ainu-processed-v2","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ananyaayasi/ainu-processed-v2","creator_name":"Ananya Ayasi","creator_url":"https://huggingface.co/ananyaayasi","description":"ananyaayasi/ainu-processed-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ParsiGoo","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kamtera/ParsiGoo","creator_name":"Flincer","creator_url":"https://huggingface.co/Kamtera","description":"A Persian multispeaker dataset for text-to-speech purposes.","first_N":5,"first_N_keywords":["text-to-speech","other","monolingual","original","Persian"],"keywords_longer_than_N":true},
	{"name":"timbre_range","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ccmusic-database/timbre_range","creator_name":"CCMUSIC Database","creator_url":"https://huggingface.co/ccmusic-database","description":"\n\t\n\t\t\n\t\tDataset Card for Timbre and Range Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe timbre dataset contains acapella singing audio of 9 singers, as well as cut single-note audio, totaling 775 clips (.wav format)\nThe vocal range dataset includes several up and down chromatic scales audio clips of several vocals, as well as the cut single-note audio clips (.wav format).\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nAudio classification\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nChinese, English\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ccmusic-database/timbre_range.","first_N":5,"first_N_keywords":["audio-classification","Chinese","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"timbre_range","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ccmusic-database/timbre_range","creator_name":"CCMUSIC Database","creator_url":"https://huggingface.co/ccmusic-database","description":"\n\t\n\t\t\n\t\tDataset Card for Timbre and Range Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe timbre dataset contains acapella singing audio of 9 singers, as well as cut single-note audio, totaling 775 clips (.wav format)\nThe vocal range dataset includes several up and down chromatic scales audio clips of several vocals, as well as the cut single-note audio clips (.wav format).\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nAudio classification\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nChinese, English\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ccmusic-database/timbre_range.","first_N":5,"first_N_keywords":["audio-classification","Chinese","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"VTTFPBS","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BenShermaister/VTTFPBS","creator_name":"Ben Shermaister","creator_url":"https://huggingface.co/BenShermaister","description":"BenShermaister/VTTFPBS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","Audio","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"tarteel-ai-everyayah-Quran","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran","creator_name":"Mohamed Salama","creator_url":"https://huggingface.co/Salama1429","description":"Ô∑Ω\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tHow to download\n\t\n\n!pip install -q datasets\n\nfrom datasets import load_dataset\ndataset =load_dataset(\"Salama1429/tarteel-ai-everyayah-Quran\", verification_mode=\"no_checks\")\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ahmetkayavocals","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/turkmen/ahmetkayavocals","creator_name":"Enes","creator_url":"https://huggingface.co/turkmen","description":"\n\t\n\t\t\n\t\n\t\n\t\tAhmet Kaya Vokal\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset A√ßƒ±klamasƒ±\n\t\n\nAhmet Kaya'nƒ±n ≈üarkƒ±larƒ±ndaki vokaller UVR ile √ßƒ±karƒ±lmƒ±≈ütƒ±r. Toplam 103 adet veri vardƒ±r.\nahmetv3.zip i√ßinde ise Ahmet Kayanƒ±n en pop√ºler 3-4 r√∂portajƒ±nƒ±n kesilerek sadece onun konu≈ütuƒüu kƒ±sƒ±mlar ayrƒ±ca UVR ile tekrar g√∂zden ge√ßirilerek olu≈üturulmu≈ü hali vardƒ±r.\nak320kbps.zip'in i√ßinde ise Ahmet Kaya'nƒ±n 320kbps olarak indirilmi≈ü y√ºksek kalite olduƒüu iddia edilen 4 par√ßasƒ±nƒ±n UVR windows size 1024 agression 15 1_HP_UVR modeli‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkmen/ahmetkayavocals.","first_N":5,"first_N_keywords":["Turkish","mit","Audio","üá∫üá∏ Region: US","ahmetkaya"],"keywords_longer_than_N":true},
	{"name":"lj-speech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MikhailT/lj-speech","creator_name":"Mikhail Tsimashkou","creator_url":"https://huggingface.co/MikhailT","description":"\n\t\n\t\t\n\t\tLJ Speech Dataset\n\t\n\n","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_individual","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Splend1dchan/librispeech_asr_individual","creator_name":"Ë®±ÊπõÁÑ∂","creator_url":"https://huggingface.co/Splend1dchan","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_individual","keyword":"speaker-identification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Splend1dchan/librispeech_asr_individual","creator_name":"Ë®±ÊπõÁÑ∂","creator_url":"https://huggingface.co/Splend1dchan","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_individual","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Splend1dchan/librispeech_asr_individual","creator_name":"Ë®±ÊπõÁÑ∂","creator_url":"https://huggingface.co/Splend1dchan","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"YueMotion","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/YueMotion","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"YueMotion is a Cantonese speech emotion dataset.","first_N":5,"first_N_keywords":["Yue Chinese","cc-by-sa-4.0","1K - 10K","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"SUBESCO-audio-dataset","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sajid73/SUBESCO-audio-dataset","creator_name":"Md Sajidul Mowla","creator_url":"https://huggingface.co/sajid73","description":"\n\t\n\t\t\n\t\tSUST BANGLA EMOTIONAL SPEECH CORPUS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBESCO is an audio-only emotional speech corpus of 7000 sentence-level utterances of the Bangla language. 20 professional actors (10 males and 10 females) participated in the recordings of 10 sentences for 7 target emotions. The emotions are Anger, Disgust, Fear, Happiness, Neutral, Sadness and Surprise. Total duration of the corpus is 7 hours 40 min 40 sec.  Total size of the dataset is 2.03 GB. The dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sajid73/SUBESCO-audio-dataset.","first_N":5,"first_N_keywords":["audio-classification","Bengali","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"SUBESCO-audio-dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sajid73/SUBESCO-audio-dataset","creator_name":"Md Sajidul Mowla","creator_url":"https://huggingface.co/sajid73","description":"\n\t\n\t\t\n\t\tSUST BANGLA EMOTIONAL SPEECH CORPUS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBESCO is an audio-only emotional speech corpus of 7000 sentence-level utterances of the Bangla language. 20 professional actors (10 males and 10 females) participated in the recordings of 10 sentences for 7 target emotions. The emotions are Anger, Disgust, Fear, Happiness, Neutral, Sadness and Surprise. Total duration of the corpus is 7 hours 40 min 40 sec.  Total size of the dataset is 2.03 GB. The dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sajid73/SUBESCO-audio-dataset.","first_N":5,"first_N_keywords":["audio-classification","Bengali","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"amis_voice","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caasih/amis_voice","creator_name":"Isaac Huang","creator_url":"https://huggingface.co/caasih","description":"\n\t\n\t\t\n\t\tamis_voice\n\t\n\n\n\t\n\t\t\n\t\ttest data\n\t\n\n\nDr. Safulo Kacaw Lalanges introduces himself in Amis (Pangcah) Language: YouTube, WAV\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Amis","cc-by-sa-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"arxiv_audio","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/taesiri/arxiv_audio","creator_name":"taesiri","creator_url":"https://huggingface.co/taesiri","description":"taesiri/arxiv_audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","text","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"samromur_synthetic","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_synthetic","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"Samr√≥mur Synthetic consists of 72 hours of synthetized speech in Icelandic.","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"edited_common_voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lunarlist/edited_common_voice","creator_name":"taetiya taechamatavorn","creator_url":"https://huggingface.co/lunarlist","description":"\n\t\n\t\t\n\t\tDataset Card for \"edited_common_voice\"\n\t\n\nMore Information needed\nThis dataset is a Thai TTS dataset that use the voice from Common Voice dataset and modify the voice to not to sound like the original.\nMedium: Text-To-Speech ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Tacotron2\n","first_N":5,"first_N_keywords":["text-to-speech","Thai","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"vertin_train_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lowo/vertin_train_dataset","creator_name":"ll","creator_url":"https://huggingface.co/lowo","description":"lowo/vertin_train_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"youtube_results","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lazyboy450/youtube_results","creator_name":"LazyBoy","creator_url":"https://huggingface.co/lazyboy450","description":"lazyboy450/youtube_results dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"scream_detection_heavy_metal","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jpdiazpardo/scream_detection_heavy_metal","creator_name":"Juan Pablo D√≠az","creator_url":"https://huggingface.co/jpdiazpardo","description":"\n\t\n\t\t\n\t\tDataset card for Scream Detection in Heavy Metal Music\n\t\n\nThis dataset contains the processed dataset used in the paper \"Scream Detection in Heavy Metal Music\" (Kalbag & Lerch, 2022) from the Georgia Institute of Technology.\nThis dataset contains annotations of 57 songs, distributed over 34 bands and 47 albums. The vocal events are labelled into 5 classes:\n\nClean (or sung vocal)\nLow Fry Scream\nMid Fry Scream\nHigh Fry Scream\nLayered Vocals\n\nThe label \"Layered Vocals\" has been applied to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpdiazpardo/scream_detection_heavy_metal.","first_N":5,"first_N_keywords":["audio-classification","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"scream_detection_heavy_metal","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jpdiazpardo/scream_detection_heavy_metal","creator_name":"Juan Pablo D√≠az","creator_url":"https://huggingface.co/jpdiazpardo","description":"\n\t\n\t\t\n\t\tDataset card for Scream Detection in Heavy Metal Music\n\t\n\nThis dataset contains the processed dataset used in the paper \"Scream Detection in Heavy Metal Music\" (Kalbag & Lerch, 2022) from the Georgia Institute of Technology.\nThis dataset contains annotations of 57 songs, distributed over 34 bands and 47 albums. The vocal events are labelled into 5 classes:\n\nClean (or sung vocal)\nLow Fry Scream\nMid Fry Scream\nHigh Fry Scream\nLayered Vocals\n\nThe label \"Layered Vocals\" has been applied to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpdiazpardo/scream_detection_heavy_metal.","first_N":5,"first_N_keywords":["audio-classification","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"BuboGPT","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/magicr/BuboGPT","creator_name":"MagIC Research","creator_url":"https://huggingface.co/magicr","description":"magicr/BuboGPT dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"MKB_Hindi_2023","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rashmi035/MKB_Hindi_2023","creator_name":"Rashmi Singh","creator_url":"https://huggingface.co/rashmi035","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rashmi035/MKB_Hindi_2023.","first_N":5,"first_N_keywords":["expert-generated","monolingual","Polish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"cantone","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/cantone","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"\n\t\n\t\t\n\t\n\t\n\t\tCantone\n\t\n\nA dataset of 34,489 recordings of Cantonese syllables by 10 speakers.\nThose syllables are generated through the Cantonese speech synthesis engines of Amazon, Apple, Google, and Microsoft.\nAll recordings are stored as WAV files with the following format\n\nChannel: mono\nSample rate: 16 kHz\nBits per sample: 16\n\nHere's a breakdown of the number of recordings under each speaker:\n\n\t\n\t\t\nCompany\nSpeaker\n# Syllables\n\n\n\t\t\nAmazon\nHiujin\n3,885\n\n\nApple\nAasing\n2,977\n\n\nApple\nSinji\n2,977‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlienKevin/cantone.","first_N":5,"first_N_keywords":["audio-classification","Yue Chinese","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"cantone","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/cantone","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"\n\t\n\t\t\n\t\n\t\n\t\tCantone\n\t\n\nA dataset of 34,489 recordings of Cantonese syllables by 10 speakers.\nThose syllables are generated through the Cantonese speech synthesis engines of Amazon, Apple, Google, and Microsoft.\nAll recordings are stored as WAV files with the following format\n\nChannel: mono\nSample rate: 16 kHz\nBits per sample: 16\n\nHere's a breakdown of the number of recordings under each speaker:\n\n\t\n\t\t\nCompany\nSpeaker\n# Syllables\n\n\n\t\t\nAmazon\nHiujin\n3,885\n\n\nApple\nAasing\n2,977\n\n\nApple\nSinji\n2,977‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlienKevin/cantone.","first_N":5,"first_N_keywords":["audio-classification","Yue Chinese","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"Green-Elephant-Remixes","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/4eJIoBek/Green-Elephant-Remixes","creator_name":"katyshek","creator_url":"https://huggingface.co/4eJIoBek","description":"–º–Ω–æ–≥–æ —Ä–µ–º–∏–∫—Å–æ–≤ —Å –∑–µ–ª—ë–Ω—ã–º —Å–ª–æ–Ω–∏–∫–æ–º, –≤—Å–µ–≥–æ 290 —à—Ç—É–∫\n","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"rvcTrainData","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xiaodoushi1234/rvcTrainData","creator_name":"xiaodoushi1234","creator_url":"https://huggingface.co/xiaodoushi1234","description":"Â≠òÂÇ®‰∏≠ËΩ¨\n","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"malay-speech","keyword":"audio","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pavan331999/malay-speech","creator_name":"Pavan Kumar S","creator_url":"https://huggingface.co/pavan331999","description":"pavan331999/malay-speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mpl-2.0","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"diet-members-voice-embeddings","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yutakobayashi/diet-members-voice-embeddings","creator_name":"Yuta Kobayashi","creator_url":"https://huggingface.co/yutakobayashi","description":"\n\t\n\t\t\n\t\n\t\n\t\tdiet-members-voice-embeddings\n\t\n\nÊó•Êú¨„ÅÆÂõΩ‰ºöË≠∞Âì°„ÅÆÂ£∞„Çí speechbrain/spkrec-ecapa-voxceleb„Åß embedding „Åó„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇË©±ËÄÖÂàÜÈõ¢„Å™„Å©„ÅÆ„Çø„Çπ„ÇØ„Åß‰ΩøÁî®„Åß„Åç„Åæ„Åô„ÄÇ\nÂõΩ‰ºö‰∏≠Á∂ô„ÇÑÊºîË™¨Á≠â„ÅÆÂàÜÊûê„Å™„Å©„ÄÅ„ÅîËá™Áî±„Å´„Åä‰Ωø„ÅÑ„Åè„Å†„Åï„ÅÑ„ÄÇ\n\n\t\n\t\t\n\t\n\t\n\t\t‰ΩøÁî®‰æã\n\t\n\n‰ª•‰∏ã„ÅØ„Éà„É©„É≥„Çπ„ÇØ„É™„Éó„Éà„Å®Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÇíÂÖÉ„Å´„ÄÅË©±ËÄÖÂàÜÊûê„ÇíË°å„ÅÜ‰æã„Åß„Åô„ÄÇ\npip install pandas numpy wave ast scipy pyannote.audio\n\nimport pandas as pd\nimport numpy as np\nimport contextlib\nimport wave\nimport ast\nfrom typing import List, Tuple\nfrom scipy.spatial.distance import cosine\nfrom pyannote.audio import Audio\nfrom pyannote.core import Segment\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yutakobayashi/diet-members-voice-embeddings.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"zindi_swahili","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lyimo/zindi_swahili","creator_name":"Tumaini Lyimo","creator_url":"https://huggingface.co/lyimo","description":"lyimo/zindi_swahili dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech-Synthesizer-TTS","keyword":"voice","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","Spanish Sign Language","unlicense","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"indic-superb-whisper","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/makaveli10/indic-superb-whisper","creator_name":"Vineet Suryan","creator_url":"https://huggingface.co/makaveli10","description":"makaveli10/indic-superb-whisper dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"OE-DCT-Movie-clips","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/knoriy/OE-DCT-Movie-clips","creator_name":"Kari","creator_url":"https://huggingface.co/knoriy","description":"knoriy/OE-DCT-Movie-clips dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"OE-DCT-Movie-clips","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/knoriy/OE-DCT-Movie-clips","creator_name":"Kari","creator_url":"https://huggingface.co/knoriy","description":"knoriy/OE-DCT-Movie-clips dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"ciempiess_light","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_light","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_light\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIEMPIESS LIGHT is a Radio Corpus designed to create acoustic models for automatic speech recognition and it is made up by recordings of spontaneous conversations in Mexican Spanish between a radio moderator and his guests. It is an enhanced version of the CIEMPIESS Corpus (LDC item LDC2015S07).\nCIEMPIESS LIGHT is \"light\" because it doesn't include much of the files of the first version of CIEMPIESS and it is \"enhanced\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_light.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"messaih","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirix/messaih","creator_name":"Ed Moman","creator_url":"https://huggingface.co/mirix","description":"DATASET DESCRIPTION\nThe messAIh dataset is a fork of CMU MOSEI.\nUnlike its parent, MESSAIH is indended for unimodal model development and focusses exclusively on audio classification, more specifically, Speech Emotion Recognition (SER).\nOf course, it can be used for bimodal classification by transcribing each audio track.\nMESSAIH currently contains 13,234 speech samples annotated according to the CMU MOSEI scheme:\n\nEach sentence is annotated for sentiment on a [-3,3] Likert scale of:\n[‚àí3:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mirix/messaih.","first_N":5,"first_N_keywords":["audio-classification","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"messaih","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirix/messaih","creator_name":"Ed Moman","creator_url":"https://huggingface.co/mirix","description":"DATASET DESCRIPTION\nThe messAIh dataset is a fork of CMU MOSEI.\nUnlike its parent, MESSAIH is indended for unimodal model development and focusses exclusively on audio classification, more specifically, Speech Emotion Recognition (SER).\nOf course, it can be used for bimodal classification by transcribing each audio track.\nMESSAIH currently contains 13,234 speech samples annotated according to the CMU MOSEI scheme:\n\nEach sentence is annotated for sentiment on a [-3,3] Likert scale of:\n[‚àí3:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mirix/messaih.","first_N":5,"first_N_keywords":["audio-classification","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Ten2Zero","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gfbati/Ten2Zero","creator_name":"Ghassan F. Bati","creator_url":"https://huggingface.co/gfbati","description":"This dataset contains the following:\n1- A balanced audio dataset of spoken Arabic digits from ten to zero in wav form (located at the \"Dataset\" folder);\n2- A balanced image dataset of spoken Arabic digits from ten to zero in png form (located at the \"Dataset\" folder);\n3- Tabular data generated using deep learning (SqueezeNet and Inception v3) from the spectrograms of the audio files; \n4- Orange Data Mining workflows (\".ows\" files) used in processing this dataset.\nPlease cite the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfbati/Ten2Zero.","first_N":5,"first_N_keywords":["audio-classification","image-classification","tabular-classification","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"Ten2Zero","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gfbati/Ten2Zero","creator_name":"Ghassan F. Bati","creator_url":"https://huggingface.co/gfbati","description":"This dataset contains the following:\n1- A balanced audio dataset of spoken Arabic digits from ten to zero in wav form (located at the \"Dataset\" folder);\n2- A balanced image dataset of spoken Arabic digits from ten to zero in png form (located at the \"Dataset\" folder);\n3- Tabular data generated using deep learning (SqueezeNet and Inception v3) from the spectrograms of the audio files; \n4- Orange Data Mining workflows (\".ows\" files) used in processing this dataset.\nPlease cite the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfbati/Ten2Zero.","first_N":5,"first_N_keywords":["audio-classification","image-classification","tabular-classification","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"ciempiess_balance","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_balance","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_balance\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIEMPIESS BALANCE Corpus is designed to match with the CIEMPIESS LIGHT Corpus (LDC2017S23). So, \"Balance\" means that if the CIEMPIESS BALANCE is combined with the CIEMPIESS LIGHT, one will get a gender balanced corpus. To appreciate this, one need to know that the CIEMPIESS LIGHT is by itself, a gender unbalanced corpus of approximately 25% of female speakers and 75% of male speakers. So, the CIEMPIESS BALANCE is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_balance.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ciempiess_fem","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_fem","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_fem\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSince the publication of the CIEMPIESS Corpus (LDC2015S07) in 2015 we have noticed that there is a lack of female speakers in the sources where we traditionally take audio to create new CIEMPIESS datasets. That is why we decided to create a corpus that helps to balance future gender unbalanced datasets.\nThe CIEMPIESS FEM Corpus was created by recordings and human transcripts of 21 different women. 16 of these women are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_fem.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ciempiess_complementary","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_complementary","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_complementary\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIEMPIESS COMPLEMENTARY is a phonetically balanced corpus of isolated Spanish words spoken by people of Central Mexico. It was designed to solve one particular issue when training automatic speech recognition (ASR) systems in the Spanish of Central Mexico. This problem appears when someone collects some training data, but the system complains because it does not find enough instances of one or more particular‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_complementary.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"asr-arg-spanish","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/storresbusquets/asr-arg-spanish","creator_name":"Santiago Torres Busquets","creator_url":"https://huggingface.co/storresbusquets","description":"storresbusquets/asr-arg-spanish dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"GTZAN_audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deetsadi/GTZAN_audio","creator_name":"Aditya Sridhar","creator_url":"https://huggingface.co/deetsadi","description":"deetsadi/GTZAN_audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"sayoko-tts-corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bandad/sayoko-tts-corpus","creator_name":"kai washizaki","creator_url":"https://huggingface.co/bandad","description":"\n\t\n\t\t\n\t\t„Çµ„É®Â≠ê Èü≥Â£∞„Ç≥„Éº„Éë„Çπ\n\t\n\n\n\t\n\t\t\n\t\t„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊñπÊ≥ï\n\t\n\n„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÂúßÁ∏Æ„Åó„Åüzip„Éï„Ç°„Ç§„É´„Çí„ÄÅgdrive„Å´ÁΩÆ„ÅÑ„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n„Åæ„Åü„ÄÅ‰ª•‰∏ã„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„Åß„ÄÅhuggingface hub„Åã„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇÇÂèØËÉΩ„Åß„Åô„ÄÇ\n# pip install --upgrade huggingface_hub\nfrom huggingface_hub import snapshot_download\n\nsnapshot_download(repo_id=\"bandad/sayoko-tts-corpus\", repo_type=\"dataset\", revision=\"main\", local_dir=\"./sayoko-tts-corpus\")\n\n\n\t\n\t\t\n\t\tÊ¶ÇË¶Å\n\t\n\n81Ê≠≥„ÅÆÂ•≥ÊÄß„ÅÆÈü≥Â£∞„Ç≥„Éº„Éë„Çπ„Åß„Åô„ÄÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bandad/sayoko-tts-corpus.","first_N":5,"first_N_keywords":["text-to-speech","Japanese","cc-by-4.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"music-audio-pseudo-captions","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/seungheondoh/music-audio-pseudo-captions","creator_name":"seungheon.doh","creator_url":"https://huggingface.co/seungheondoh","description":"\n\t\n\t\t\n\t\tDataset Card for Music-Audio-Pseudo Captions\n\t\n\nPseudo Music and Audio Captions from LP-MusicCaps, Music Negation/Temporal Ordering WavCaps\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nCompared to other domains, music and audio domains cannot obtain well-written web caption data, and caption annotation is expensive. \nTherefore, we use the Music (LP-MusicCaps), (Music Negation/Temporal Ordering) and Audio (Wavcaps) datasets created with ChatGPT to re-organize them in the form of instructions, input‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seungheondoh/music-audio-pseudo-captions.","first_N":5,"first_N_keywords":["English","mit","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"music-audio-pseudo-captions","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/seungheondoh/music-audio-pseudo-captions","creator_name":"seungheon.doh","creator_url":"https://huggingface.co/seungheondoh","description":"\n\t\n\t\t\n\t\tDataset Card for Music-Audio-Pseudo Captions\n\t\n\nPseudo Music and Audio Captions from LP-MusicCaps, Music Negation/Temporal Ordering WavCaps\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nCompared to other domains, music and audio domains cannot obtain well-written web caption data, and caption annotation is expensive. \nTherefore, we use the Music (LP-MusicCaps), (Music Negation/Temporal Ordering) and Audio (Wavcaps) datasets created with ChatGPT to re-organize them in the form of instructions, input‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seungheondoh/music-audio-pseudo-captions.","first_N":5,"first_N_keywords":["English","mit","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"TALI","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Antreas/TALI","creator_name":"Antreas Antoniou","creator_url":"https://huggingface.co/Antreas","description":"\n\t\n\t\t\n\t\tDataset Card for \"TALI\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nTALI is a large-scale, tetramodal dataset designed to facilitate a shift from unimodal and duomodal to tetramodal research in deep learning. It aligns text, video, images, and audio, providing a rich resource for innovative self-supervised learning tasks and multimodal research. TALI enables exploration of how different modalities and data/model scaling affect downstream performance, with the aim of inspiring‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Antreas/TALI.","first_N":5,"first_N_keywords":["zero-shot-classification","cc-by-4.0","1M - 10M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"TALI","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Antreas/TALI","creator_name":"Antreas Antoniou","creator_url":"https://huggingface.co/Antreas","description":"\n\t\n\t\t\n\t\tDataset Card for \"TALI\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nTALI is a large-scale, tetramodal dataset designed to facilitate a shift from unimodal and duomodal to tetramodal research in deep learning. It aligns text, video, images, and audio, providing a rich resource for innovative self-supervised learning tasks and multimodal research. TALI enables exploration of how different modalities and data/model scaling affect downstream performance, with the aim of inspiring‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Antreas/TALI.","first_N":5,"first_N_keywords":["zero-shot-classification","cc-by-4.0","1M - 10M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"uzbekvoice-filtered","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered","creator_name":"Dovron Sherbaev","creator_url":"https://huggingface.co/DavronSherbaev","description":"This is heavy filtered version of the dataset with additional information.\nThis dataset does not contain original Mozilla Common Voice audios or texts\nWe filtered the dataset using number approaches:\n\nVAD + Noise detection. Audios which lacked voice activity and produced no sound after denoiser were removed\nReading Speed. Audios with outlier speeds (approximately 5-10%), as they didnt match natural speed or were too noisy\nAutomatic STT validation. We trained the model using subset of valid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"laoruiya","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/laoruiya","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/laoruiya dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"VietBibleVox","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ntt123/VietBibleVox","creator_name":"Th√¥ng Nguy·ªÖn","creator_url":"https://huggingface.co/ntt123","description":"\n\t\n\t\t\n\t\n\t\n\t\tVietBibleVox Dataset\n\t\n\nThe VietBibleVox Dataset is based on the data extracted from open.bible specifically for the Vietnamese language. As the original data is provided under the cc-by-sa-4.0 license, this derived dataset is also licensed under cc-by-sa-4.0.\nThe dataset comprises 29,185 pairs of (verse, audio clip), with each verse from the Bible read in Vietnamese by a male voice.\n\nThe verses are the original texts and may not be directly usable for training text-to-speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ntt123/VietBibleVox.","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","cc-by-sa-4.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"TUT-urban-acoustic-scenes-2018-development","keyword":"audio-classification","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wetdog/TUT-urban-acoustic-scenes-2018-development","creator_name":"jose Giraldo","creator_url":"https://huggingface.co/wetdog","description":"\n\t\n\t\t\n\t\tDataset Card for \"TUT-urban-acoustic-scenes-2018-development\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTUT Urban Acoustic Scenes 2018 development dataset consists of 10-seconds audio segments from 10 acoustic scenes:\nAirport - airport\nIndoor shopping mall - shopping_mall\nMetro station - metro_station\nPedestrian street - street_pedestrian\nPublic square - public_square\nStreet with medium level of traffic - street_traffic\nTravelling by a tram - tram\nTravelling by a bus - bus\nTravelling by an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wetdog/TUT-urban-acoustic-scenes-2018-development.","first_N":5,"first_N_keywords":["audio-classification","afl-3.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"TUT-urban-acoustic-scenes-2018-development","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wetdog/TUT-urban-acoustic-scenes-2018-development","creator_name":"jose Giraldo","creator_url":"https://huggingface.co/wetdog","description":"\n\t\n\t\t\n\t\tDataset Card for \"TUT-urban-acoustic-scenes-2018-development\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTUT Urban Acoustic Scenes 2018 development dataset consists of 10-seconds audio segments from 10 acoustic scenes:\nAirport - airport\nIndoor shopping mall - shopping_mall\nMetro station - metro_station\nPedestrian street - street_pedestrian\nPublic square - public_square\nStreet with medium level of traffic - street_traffic\nTravelling by a tram - tram\nTravelling by a bus - bus\nTravelling by an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wetdog/TUT-urban-acoustic-scenes-2018-development.","first_N":5,"first_N_keywords":["audio-classification","afl-3.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ZEZE","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Servicospf/ZEZE","creator_name":"Servi√ßos Digitais","creator_url":"https://huggingface.co/Servicospf","description":"Servicospf/ZEZE dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"cszs_es_en","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ky552/cszs_es_en","creator_name":"speech552_ky","creator_url":"https://huggingface.co/ky552","description":"This dataset contains the Spanish-English track of the benchmark from ICASSP 2024: Zero Resource Code-Switched Speech Benchmark Using Speech Utterance Pairs for Multiple Spoken Languages.Though the benchmark is originally designed to assess the semantic and syntactic abilities of the speech foundation models, you can also use this dataset for code-switching ASR.\nIf you find this dataset helpful, please consider to cite the following paper:\n@INPROCEEDINGS{10446737,\n  author={Huang, Kuan-Po and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ky552/cszs_es_en.","first_N":5,"first_N_keywords":["English","Spanish","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Yae_Miko","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/Yae_Miko","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/Yae_Miko dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"examples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MariaK/examples","creator_name":"Maria Khalusova","creator_url":"https://huggingface.co/MariaK","description":"MariaK/examples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"icaroGC3","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/icaro23/icaroGC3","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/icaro23","description":"icaro23/icaroGC3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"nb_samtale","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sprakbanken/nb_samtale","creator_name":"Nasjonalbiblioteket Spr√•kbanken","creator_url":"https://huggingface.co/Sprakbanken","description":"NB Samtale is a speech corpus made by the Language Bank at the National Library of Norway.\nThe corpus contains orthographically transcribed speech from podcasts and recordings of live events at the National Library.\nThe corpus is intended as an open source dataset for Automatic Speech Recognition (ASR) development,\nand is specifically aimed at improving ASR systems‚Äô handle on conversational speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Norwegian Bokm√•l","Norwegian Nynorsk","Norwegian","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"hifi-tts-light","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MikhailT/hifi-tts-light","creator_name":"Mikhail Tsimashkou","creator_url":"https://huggingface.co/MikhailT","description":"Hi-Fi Multi-Speaker English TTS Dataset (Hi-Fi TTS) is based on LibriVox's public domain audio books and Gutenberg Project texts.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"AnuraSet_v2.0.0","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AnuraSet/AnuraSet_v2.0.0","creator_name":"AnuraSet","creator_url":"https://huggingface.co/AnuraSet","description":"AnuraSet/AnuraSet_v2.0.0 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"AnuraSet_v1.0.0","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AnuraSet/AnuraSet_v1.0.0","creator_name":"AnuraSet","creator_url":"https://huggingface.co/AnuraSet","description":"AnuraSet/AnuraSet_v1.0.0 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"AnuraSet_v2.0.0_raw","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AnuraSet/AnuraSet_v2.0.0_raw","creator_name":"AnuraSet","creator_url":"https://huggingface.co/AnuraSet","description":"AnuraSet/AnuraSet_v2.0.0_raw dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"AnuraSet_v1.0.0_raw","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AnuraSet/AnuraSet_v1.0.0_raw","creator_name":"AnuraSet","creator_url":"https://huggingface.co/AnuraSet","description":"AnuraSet/AnuraSet_v1.0.0_raw dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"BibleTTS_Ewe-Bible","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abiyo27/BibleTTS_Ewe-Bible","creator_name":"Mawaba Botossi","creator_url":"https://huggingface.co/abiyo27","description":"abiyo27/BibleTTS_Ewe-Bible dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"test_lections","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/an1rud/test_lections","creator_name":"Alexander","creator_url":"https://huggingface.co/an1rud","description":"an1rud/test_lections dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"asr_med_ru_tuberculosis","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bene-ges/asr_med_ru_tuberculosis","creator_name":"Alexandra Antonova","creator_url":"https://huggingface.co/bene-ges","description":"This is a small 30-minute dataset for testing ASR on medical domain, based on this video lecture.\nThe manifest file is in NeMo format, \"text\" is the reference text.\n","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"mrmocci","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mrmocciai/mrmocci","creator_name":"Mocci lutha","creator_url":"https://huggingface.co/mrmocciai","description":"\n\n VOICE CONVERSATION BACKUP\nOriginal Repo\n","first_N":5,"first_N_keywords":["English","mit","< 1K","text","Audio"],"keywords_longer_than_N":true},
	{"name":"tunes","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brivapor/tunes","creator_name":"CaptnBriVaps","creator_url":"https://huggingface.co/brivapor","description":"brivapor/tunes dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"BOGDANKOZLOV1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leoarias12/BOGDANKOZLOV1","creator_name":"Leo Arias","creator_url":"https://huggingface.co/leoarias12","description":"leoarias12/BOGDANKOZLOV1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Spanish","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"juzne_vesti","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/5roop/juzne_vesti","creator_name":"Peter Rupnik","creator_url":"https://huggingface.co/5roop","description":"\n\t\n\t\t\n\t\tASR training dataset for Serbian JuzneVesti-SR v1.0\n\t\n\nhdl: http://hdl.handle.net/11356/1679\nThe JuzneVesti-SR dataset consists of audio recordings and manual transcripts from the Ju≈æne Vesti website and its host show called '15 minuta' (https://www.juznevesti.com/Tagovi/Intervju-15-minuta.sr.html). \nThe processing of the audio and its alignment to the manual transcripts followed the pipeline of the ParlaSpeech-HR dataset (http://hdl.handle.net/11356/1494) as closely as possible.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/5roop/juzne_vesti.","first_N":5,"first_N_keywords":["Serbian","cc-by-sa-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"speechocean762","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seba3y/speechocean762","creator_name":"Elsebaiy mohamed","creator_url":"https://huggingface.co/seba3y","description":"\n\t\n\t\t\n\t\tspeechocean762: A non-native English corpus for pronunciation scoring task\n\t\n\n\n\t\n\t\t\n\t\tHow to use?\n\t\n\nyou can load data using\nspeechocean762_dataset = load_dataset('seba3y/speechocean762')\n\n>> speechocean762_dataset\nDatasetDict({\n    train: Dataset({\n        features: ['spk', 'age', 'gender', 'utt_name', 'audio', 'utt_text', 'utt_accuracy', 'utt_completeness', 'utt_fluency', 'utt_prosodic', 'utt_total', 'words', 'words_accuracy', 'words_stress', 'words_total', 'phones'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seba3y/speechocean762.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"speechocean762","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seba3y/speechocean762","creator_name":"Elsebaiy mohamed","creator_url":"https://huggingface.co/seba3y","description":"\n\t\n\t\t\n\t\tspeechocean762: A non-native English corpus for pronunciation scoring task\n\t\n\n\n\t\n\t\t\n\t\tHow to use?\n\t\n\nyou can load data using\nspeechocean762_dataset = load_dataset('seba3y/speechocean762')\n\n>> speechocean762_dataset\nDatasetDict({\n    train: Dataset({\n        features: ['spk', 'age', 'gender', 'utt_name', 'audio', 'utt_text', 'utt_accuracy', 'utt_completeness', 'utt_fluency', 'utt_prosodic', 'utt_total', 'words', 'words_accuracy', 'words_stress', 'words_total', 'phones'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seba3y/speechocean762.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"openslr-slr69-ca-trimmed-denoised","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for openslr-slr69-ca-denoised\n\t\n\nThis is a post-processed version of the Catalan subset belonging to the Open Speech and Language Resources (OpenSLR) speech dataset. \nSpecifically the subset OpenSLR-69. \nThe original HFü§ó SLR-69 dataset is located here.\nSame license is maintained: Attribution-ShareAlike 4.0 International.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe processed the data of the Catalan OpenSLR with the following recipe:\n\nTrimming: Long‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised.","first_N":5,"first_N_keywords":["text-to-speech","no-annotation","crowdsourced","monolingual","openslr"],"keywords_longer_than_N":true},
	{"name":"VozPowerMan","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DenisVousin/VozPowerMan","creator_name":"Sim√µes Souza","creator_url":"https://huggingface.co/DenisVousin","description":"DenisVousin/VozPowerMan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"tocadovale","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kevem/tocadovale","creator_name":"lucas","creator_url":"https://huggingface.co/kevem","description":"kevem/tocadovale dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"devidi","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ediudo/devidi","creator_name":"Pinto","creator_url":"https://huggingface.co/Ediudo","description":"Ediudo/devidi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"poderdodirect","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosfuy/poderdodirect","creator_name":"carlos","creator_url":"https://huggingface.co/carlosfuy","description":"carlosfuy/poderdodirect dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"messi3","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoSolares/messi3","creator_name":"RicSolares","creator_url":"https://huggingface.co/RicardoSolares","description":"RicardoSolares/messi3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"sgdhfdde","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosfuy/sgdhfdde","creator_name":"carlos","creator_url":"https://huggingface.co/carlosfuy","description":"carlosfuy/sgdhfdde dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["afl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"papi_asr_test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ctam8736/papi_asr_test","creator_name":"Chris Tam","creator_url":"https://huggingface.co/ctam8736","description":"ctam8736/papi_asr_test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"duda","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/n3gflash/duda","creator_name":"anderson rocha leal","creator_url":"https://huggingface.co/n3gflash","description":"n3gflash/duda dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"blacko","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ledoc/blacko","creator_name":"le doc","creator_url":"https://huggingface.co/ledoc","description":"ledoc/blacko dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"papi_asr_mini","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ctam8736/papi_asr_mini","creator_name":"Chris Tam","creator_url":"https://huggingface.co/ctam8736","description":"ctam8736/papi_asr_mini dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Cod_MW2019_Precision_Airstrike_Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SouBryan/Cod_MW2019_Precision_Airstrike_Dataset","creator_name":"Lorenzo Cristianini de Oliveira","creator_url":"https://huggingface.co/SouBryan","description":"SouBryan/Cod_MW2019_Precision_Airstrike_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"poncho","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/naiviv1000/poncho","creator_name":"Naiviv","creator_url":"https://huggingface.co/naiviv1000","description":"naiviv1000/poncho dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"speech-mendeley-pa","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aipanjab/speech-mendeley-pa","creator_name":"AI Panjab","creator_url":"https://huggingface.co/aipanjab","description":"\n\t\n\t\t\n\t\tCredit - https://data.mendeley.com/datasets/sdbc8f5b77/2\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Panjabi","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"DATASETVOZ","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MASTERREDE/DATASETVOZ","creator_name":"Jose Santos","creator_url":"https://huggingface.co/MASTERREDE","description":"MASTERREDE/DATASETVOZ dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"nst-da-norm","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da Normalized\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): da\nLicense: cc0-1.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"cszs_zh_en","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ky552/cszs_zh_en","creator_name":"speech552_ky","creator_url":"https://huggingface.co/ky552","description":"This dataset contains the Mandarin-English track of the benchmark from ICASSP 2024: Zero Resource Code-Switched Speech Benchmark Using Speech Utterance Pairs for Multiple Spoken Languages.Though the benchmark is originally designed to assess the semantic and syntactic abilities of the speech foundation models, you can also use this dataset for code-switching ASR.\nIf you find this dataset helpful, please consider to cite the following paper:\n@INPROCEEDINGS{10446737,\n  author={Huang, Kuan-Po and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ky552/cszs_zh_en.","first_N":5,"first_N_keywords":["Chinese","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"papi_asr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ctam8736/papi_asr","creator_name":"Chris Tam","creator_url":"https://huggingface.co/ctam8736","description":"ctam8736/papi_asr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"problems_youtuber","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Caioba123flamengo/problems_youtuber","creator_name":"Caio de Ara√∫jo Cunha","creator_url":"https://huggingface.co/Caioba123flamengo","description":"Caioba123flamengo/problems_youtuber dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"test_audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pmaslak/test_audio","creator_name":"Petr Maslak","creator_url":"https://huggingface.co/pmaslak","description":"pmaslak/test_audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Russian","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"voices","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/claudiotarbe/voices","creator_name":"Claudio Torres Arbe","creator_url":"https://huggingface.co/claudiotarbe","description":"claudiotarbe/voices dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Dustin_Siu","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ttabo/Dustin_Siu","creator_name":"ttabo","creator_url":"https://huggingface.co/ttabo","description":"ttabo/Dustin_Siu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Pessoas","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VenonSabio/Pessoas","creator_name":"Caio Nazareth","creator_url":"https://huggingface.co/VenonSabio","description":"VenonSabio/Pessoas dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"katievoic","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Miniex/katievoic","creator_name":"Xml ","creator_url":"https://huggingface.co/Miniex","description":"Miniex/katievoic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"katievoiceactor2.0","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Miniex/katievoiceactor2.0","creator_name":"Xml ","creator_url":"https://huggingface.co/Miniex","description":"Miniex/katievoiceactor2.0 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Meauzin","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YAGO1818/Meauzin","creator_name":"Yago Luiz Cotrin","creator_url":"https://huggingface.co/YAGO1818","description":"YAGO1818/Meauzin dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"LilRato","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YAGO1818/LilRato","creator_name":"Yago Luiz Cotrin","creator_url":"https://huggingface.co/YAGO1818","description":"YAGO1818/LilRato dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"clonevoz","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xDidoZombiex/clonevoz","creator_name":"Zombie","creator_url":"https://huggingface.co/xDidoZombiex","description":"xDidoZombiex/clonevoz dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Cuzinho","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/diguinn17/Cuzinho","creator_name":"rodrigo neves","creator_url":"https://huggingface.co/diguinn17","description":"diguinn17/Cuzinho dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"HisaSoft","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hisasartori/HisaSoft","creator_name":"Hisa Sartori ","creator_url":"https://huggingface.co/Hisasartori","description":"Hisasartori/HisaSoft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"eu","keyword":"audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carterzin/eu","creator_name":"Carter","creator_url":"https://huggingface.co/carterzin","description":"carterzin/eu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["artistic-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"dataseths","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yukiamenta/dataseths","creator_name":"yuki a menta","creator_url":"https://huggingface.co/yukiamenta","description":"yukiamenta/dataseths dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"chicobento","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yukiamenta/chicobento","creator_name":"yuki a menta","creator_url":"https://huggingface.co/yukiamenta","description":"yukiamenta/chicobento dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"CommonVoiceAz","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RashadGarazadeh/CommonVoiceAz","creator_name":"Garayev","creator_url":"https://huggingface.co/RashadGarazadeh","description":"RashadGarazadeh/CommonVoiceAz dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"LunaVB","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YAGO1818/LunaVB","creator_name":"Yago Luiz Cotrin","creator_url":"https://huggingface.co/YAGO1818","description":"YAGO1818/LunaVB dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"saudi_arabic_accent","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nasser2023/saudi_arabic_accent","creator_name":"Nasser","creator_url":"https://huggingface.co/Nasser2023","description":"Nasser2023/saudi_arabic_accent dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"poh-samples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengdujin/poh-samples","creator_name":"Yuan Jin","creator_url":"https://huggingface.co/chengdujin","description":"chengdujin/poh-samples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"poppyhigh","keyword":"audio","license":"Boost Software License 1.0","license_url":"https://choosealicense.com/licenses/bsl-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wessmetal/poppyhigh","creator_name":"Wesley Nascimeto","creator_url":"https://huggingface.co/wessmetal","description":"wessmetal/poppyhigh dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["bsl-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"nasslafolie","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ledoc/nasslafolie","creator_name":"le doc","creator_url":"https://huggingface.co/ledoc","description":"ledoc/nasslafolie dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Indian-Accent-Dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Santhosh-kumar/Indian-Accent-Dataset","creator_name":"Santhanam","creator_url":"https://huggingface.co/Santhosh-kumar","description":"Santhosh-kumar/Indian-Accent-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"LatinYoutube","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thiagolira/LatinYoutube","creator_name":"Thiago Ildeu Albuquerque Lira","creator_url":"https://huggingface.co/thiagolira","description":"This is a dataset with text/audio pairs of Classical Latin extracted from youtube videos from the channels Scorpio Martianus, LATINITIUS and Musa Pedestris\n","first_N":5,"first_N_keywords":["Latin","afl-3.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"DigPilot","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AntonioPinaIA/DigPilot","creator_name":"Antonio Pina","creator_url":"https://huggingface.co/AntonioPinaIA","description":"AntonioPinaIA/DigPilot dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Voice-KusanagiNene","keyword":"audio-to-audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MomoyamaSawa/Voice-KusanagiNene","creator_name":"„ÅÜ„Åï„Åé","creator_url":"https://huggingface.co/MomoyamaSawa","description":"\n  \n\n ü•ï \n Â¶ÇÊûúÂÖîÂÖîÁöÑ‰ªìÂ∫ìÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÁöÑËØùÁÇπ‰∏™‚≠êÂñµ~ \n If Tutu's repository is helpful to you, please give it a ‚≠ê meow~ \n „ÇÇ„Åó„ÅÜ„Åï„Åé„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅåÂΩπ„Å´Á´ã„Å£„ÅüÂ†¥Âêà„ÅØ„ÄÅ‚≠ê„Çí„ÅΩ„Å°„Å£„Å®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„Å´„ÇÉ„Çì~  \n\n üçâ \n ‰ªª‰Ωï ‚ùìÈóÆÈ¢ò / üí≠ÊÄùËÄÉ /üí°ÊÉ≥Ê≥ï ÈÉΩÊ¨¢ËøéÊèêÂá∫ÔºÅ\n Any ‚ùìquestion / üí≠thought /üí°idea  is welcome! \n „Å©„Çì„Å™ ‚ùìË≥™Âïè / üí≠ËÄÉ„Åà /üí°„Ç¢„Ç§„Éá„Ç¢ „Åß„ÇÇÊ≠ìËøé„Åß„ÅôÔºÅ \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tÁÆÄ‰ªã\n\t\n\n\nËçâËñôÂØß„ÄÖ Âπ≤Â£∞Â∏¶Ê†áÁ≠æÊï∞ÊçÆÈõÜ\n\nÊú¨Êï∞ÊçÆÈõÜÂè™Êî∂ÈõÜ‰∫ÜÊ∏∏ÊàèÂÜÖÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂπ∂‰∏çÊòØÂÖ®ÈÉ®ÁöÑÂÆÅÂÆÅÂπ≤Â£∞ËØ≠Èü≥ÔºåÂÖ∂‰∏≠ nene_org.txt ÊòØÊ†áÁ≠æÊñá‰ª∂\npjsk ÂÖ®ÈÉ®ËßíËâ≤Âπ≤Â£∞Â∏¶Ê†áÁ≠æÊï∞ÊçÆÈõÜÁöÑËØùÂèØ‰ª•Âä†QQÁæ§Ôºö691795641ÔºåÁæ§ÂÖ¨ÂëäÈáåÊúâÁΩëÁõòÂú∞ÂùÄ\n\n\t\n\t\n\t\n\t\tÂèÇËÄÉ\n\t\n\n\nÂ£∞Ê∫êÂΩíÂ±ûÔºöËçâËñôÂØß„ÄÖ(CV:Machico)-„Äå„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çª„Ç´„Ç§ „Ç´„É©„Éï„É´„Çπ„ÉÜ„Éº„Ç∏ÔºÅ feat. ÂàùÈü≥„Éü„ÇØ„Äç\n\t\n\t\t\n\t\tTODO\n\t\n\n\nÔºàÈïøÊúüÔºâË°•ÂÖ®ÂÆÅÂÆÅËØ≠Èü≥ÔºåËßÑËåÉÊï∞ÊçÆÈõÜÊ†ºÂºè„ÄÇ\n\n","first_N":5,"first_N_keywords":["other","text-to-speech","audio-to-audio","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"Voice-KusanagiNene","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MomoyamaSawa/Voice-KusanagiNene","creator_name":"„ÅÜ„Åï„Åé","creator_url":"https://huggingface.co/MomoyamaSawa","description":"\n  \n\n ü•ï \n Â¶ÇÊûúÂÖîÂÖîÁöÑ‰ªìÂ∫ìÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÁöÑËØùÁÇπ‰∏™‚≠êÂñµ~ \n If Tutu's repository is helpful to you, please give it a ‚≠ê meow~ \n „ÇÇ„Åó„ÅÜ„Åï„Åé„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅåÂΩπ„Å´Á´ã„Å£„ÅüÂ†¥Âêà„ÅØ„ÄÅ‚≠ê„Çí„ÅΩ„Å°„Å£„Å®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„Å´„ÇÉ„Çì~  \n\n üçâ \n ‰ªª‰Ωï ‚ùìÈóÆÈ¢ò / üí≠ÊÄùËÄÉ /üí°ÊÉ≥Ê≥ï ÈÉΩÊ¨¢ËøéÊèêÂá∫ÔºÅ\n Any ‚ùìquestion / üí≠thought /üí°idea  is welcome! \n „Å©„Çì„Å™ ‚ùìË≥™Âïè / üí≠ËÄÉ„Åà /üí°„Ç¢„Ç§„Éá„Ç¢ „Åß„ÇÇÊ≠ìËøé„Åß„ÅôÔºÅ \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tÁÆÄ‰ªã\n\t\n\n\nËçâËñôÂØß„ÄÖ Âπ≤Â£∞Â∏¶Ê†áÁ≠æÊï∞ÊçÆÈõÜ\n\nÊú¨Êï∞ÊçÆÈõÜÂè™Êî∂ÈõÜ‰∫ÜÊ∏∏ÊàèÂÜÖÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂπ∂‰∏çÊòØÂÖ®ÈÉ®ÁöÑÂÆÅÂÆÅÂπ≤Â£∞ËØ≠Èü≥ÔºåÂÖ∂‰∏≠ nene_org.txt ÊòØÊ†áÁ≠æÊñá‰ª∂\npjsk ÂÖ®ÈÉ®ËßíËâ≤Âπ≤Â£∞Â∏¶Ê†áÁ≠æÊï∞ÊçÆÈõÜÁöÑËØùÂèØ‰ª•Âä†QQÁæ§Ôºö691795641ÔºåÁæ§ÂÖ¨ÂëäÈáåÊúâÁΩëÁõòÂú∞ÂùÄ\n\n\t\n\t\n\t\n\t\tÂèÇËÄÉ\n\t\n\n\nÂ£∞Ê∫êÂΩíÂ±ûÔºöËçâËñôÂØß„ÄÖ(CV:Machico)-„Äå„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çª„Ç´„Ç§ „Ç´„É©„Éï„É´„Çπ„ÉÜ„Éº„Ç∏ÔºÅ feat. ÂàùÈü≥„Éü„ÇØ„Äç\n\t\n\t\t\n\t\tTODO\n\t\n\n\nÔºàÈïøÊúüÔºâË°•ÂÖ®ÂÆÅÂÆÅËØ≠Èü≥ÔºåËßÑËåÉÊï∞ÊçÆÈõÜÊ†ºÂºè„ÄÇ\n\n","first_N":5,"first_N_keywords":["other","text-to-speech","audio-to-audio","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"VoxCelebSpoof","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MattyB95/VoxCelebSpoof","creator_name":"Matthew Boakes","creator_url":"https://huggingface.co/MattyB95","description":"\n\t\n\t\t\n\t\n\t\n\t\tVoxCelebSpoof\n\t\n\nVoxCelebSpoof is a dataset related to detecting spoofing attacks on automatic speaker verification systems. This dataset is part of a broader effort to improve the security of voice biometric systems against various types of spoofing attacks, such as replay attacks, voice synthesis, and voice conversion.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe VoxCelebSpoof dataset includes a range of audio samples from different types of synthesis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MattyB95/VoxCelebSpoof.","first_N":5,"first_N_keywords":["audio-classification","text-to-speech","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"sixuxar_yijiri_mak7","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anzorq/sixuxar_yijiri_mak7","creator_name":"AQ","creator_url":"https://huggingface.co/anzorq","description":"\n\t\n\t\t\n\t\tDataset Info\n\t\n\nThis dataset consists of paired audio and text data sourced from the following book:\n\nTitle: –ö—ä—ç—Ä–º–æ–∫—ä—É—ç –ú. –©–∏—Ö—É—Ö—ç—Ä –∏–¥–∂—ã—Ä–∏ –º—ç–∫I. –Ø–ø—ç —Ç—Ö—ã–ª—ä.\nPublication: –ù–∞–ª—å—á–∏–∫: –≠–ª—å–±—Ä—É—Å, 1999\n\n\n\t\n\t\t\n\t\tAudio Specifications\n\t\n\n\nSample Rate: 16,000 Hz\nTotal Length: 10:36:40\nSource: adigabook.ru\n\n\n\t\n\t\t\n\t\tProcessing Information\n\t\n\nAudio-text pairs for this dataset were extracted and aligned using META AI's forced alignment algorithm.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kabardian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"khmer-try","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ken0997/khmer-try","creator_name":"lee","creator_url":"https://huggingface.co/ken0997","description":"ken0997/khmer-try dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Khmer","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Synthetic_Voice_Detection_Resources","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MattyB95/Synthetic_Voice_Detection_Resources","creator_name":"Matthew Boakes","creator_url":"https://huggingface.co/MattyB95","description":"MattyB95/Synthetic_Voice_Detection_Resources dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","mit","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"rule1_embeddings","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dthomas84/rule1_embeddings","creator_name":"David Thomas","creator_url":"https://huggingface.co/dthomas84","description":"dthomas84/rule1_embeddings dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Barone","keyword":"audio","license":"GNU Lesser General Public License v2.1","license_url":"https://choosealicense.com/licenses/lgpl-2.1/","language":"en","dataset_url":"https://huggingface.co/datasets/jinnclf/Barone","creator_name":"FLAVIO CANDIDO DE LIMA FILHO","creator_url":"https://huggingface.co/jinnclf","description":"jinnclf/Barone dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["lgpl-2.1","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"swahili_common_voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Adeptschneider/swahili_common_voice","creator_name":"Ronnie Leon Ochieng","creator_url":"https://huggingface.co/Adeptschneider","description":"Adeptschneider/swahili_common_voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"lbls","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbls888/lbls","creator_name":"RICK","creator_url":"https://huggingface.co/lbls888","description":"lbls888/lbls dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Video"],"keywords_longer_than_N":true},
	{"name":"spoken-arabic-digits","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mohnasgbr/spoken-arabic-digits","creator_name":"Mohammed Nasser Gaber","creator_url":"https://huggingface.co/mohnasgbr","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains spoken Arabic digits from 40 speakers from multiple Arab communities and local dialects. It is augmented using various techniques to increase the size of the dataset and improve its diversity. The recordings went through a number of pre-processors to evaluate and process the sound quality using Audacity app.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThe dataset was created by collecting recordings of the digits 0-9 from 40 speakers from different Arab communities‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mohnasgbr/spoken-arabic-digits.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"audio-aus-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/napnel/audio-aus-dataset","creator_name":"Yoshiaki Nejime","creator_url":"https://huggingface.co/napnel","description":"napnel/audio-aus-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dzq","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/dzq","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/dzq dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"vibravox","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"speaker-identification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"opendsbinary","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/opendsbinary","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/opendsbinary dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"DRAL","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jonavila/DRAL","creator_name":"Jonathan Avila","creator_url":"https://huggingface.co/jonavila","description":"\n\t\n\t\t\n\t\n\t\n\t\tDialogs Re-enacted Across Languages (DRAL) corpus\n\t\n\nDRAL is a bilingual speech corpus of parallel utterances, using recorded conversations and fragments re-enacted in a different language. It is intended as a resource for research, especially for training and evaluating speech-to-speech translation models and systems. We dedicate this corpus to the public domain; there is no copyright (CC 0).\nDRAL is described in a new technical report: Dialogs Re-enacted Across Languages, Version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jonavila/DRAL.","first_N":5,"first_N_keywords":["translation","English","Spanish","cc0-1.0","Audio"],"keywords_longer_than_N":true},
	{"name":"youtube-data-various-domain","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yongchanskii/youtube-data-various-domain","creator_name":"yong chan chun","creator_url":"https://huggingface.co/yongchanskii","description":"\n\t\n\t\t\n\t\tDataset Card for \"youtube-data-various-domain\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"poesia","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/adleme94/poesia","creator_name":"Alberto L√≥pez","creator_url":"https://huggingface.co/adleme94","description":"adleme94/poesia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"rampage","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/curry99/rampage","creator_name":"Manu Srimat","creator_url":"https://huggingface.co/curry99","description":"curry99/rampage dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"irish-traditional-tunes","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hdparmar/irish-traditional-tunes","creator_name":"Harshdeep Parmar","creator_url":"https://huggingface.co/hdparmar","description":"\n\t\n\t\t\n\t\tDataset Card for \"irish-traditional-tunes\"\n\t\n\nMore Information needed\n\n\t\n\t\t\n\t\tDataset Card for \"irish-tunes-spectrograms\"\n\t\n\n\n\t\n\t\t\n\t\t1. Dataset Description\n\t\n\n  Dataset is used for the following project\n\nHomepage: Trad-fusion\n\n\n\t\n\t\t\n\t\t1.1 Dataset Summary\n\t\n\nThis dataset contains 9604 Mel spectrograms that represent Traditional Irish Music. \nThis dataset is smaller compared to hdparmar/irish-tunes-spectrogram, to reduce the training time and increase the possibilty to train for longer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hdparmar/irish-traditional-tunes.","first_N":5,"first_N_keywords":["text-to-image","text-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"control_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tuanmanh28/control_dataset","creator_name":"Tr∆∞∆°ng M·∫°nh Tu·∫•n","creator_url":"https://huggingface.co/tuanmanh28","description":"tuanmanh28/control_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"12","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JohnDiaz14/12","creator_name":"diaz","creator_url":"https://huggingface.co/JohnDiaz14","description":"JohnDiaz14/12 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"sebut-perkataan","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mesolitica/sebut-perkataan","creator_name":"Mesolitica","creator_url":"https://huggingface.co/mesolitica","description":"\n\t\n\t\t\n\t\tSebut Perkataan\n\t\n\n\nsebut-perkataan-man voice by Husein Zolkepli\ntolong-sebut voice by Khalil Nooh\nsebut-perkataan-woman voice by Mas Aisyah Ahmad\nRecorded using low-end tech microphones.\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malay","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"drod","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/metredo085/drod","creator_name":"Caique Mitri","creator_url":"https://huggingface.co/metredo085","description":"metredo085/drod dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"voztaniamae","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/metredo085/voztaniamae","creator_name":"Caique Mitri","creator_url":"https://huggingface.co/metredo085","description":"metredo085/voztaniamae dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"dweqjkHGRFEWF","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/metredo085/dweqjkHGRFEWF","creator_name":"Caique Mitri","creator_url":"https://huggingface.co/metredo085","description":"metredo085/dweqjkHGRFEWF dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"dsafthsdhbgchnb","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/metredo085/dsafthsdhbgchnb","creator_name":"Caique Mitri","creator_url":"https://huggingface.co/metredo085","description":"metredo085/dsafthsdhbgchnb dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vozmarina","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/metredo085/vozmarina","creator_name":"Caique Mitri","creator_url":"https://huggingface.co/metredo085","description":"metredo085/vozmarina dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"BRVozes","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PatoDonaldo/BRVozes","creator_name":"Patinho Donaldo","creator_url":"https://huggingface.co/PatoDonaldo","description":"PatoDonaldo/BRVozes dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Eumesmo","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Erickbarbosa/Eumesmo","creator_name":"Erickzin","creator_url":"https://huggingface.co/Erickbarbosa","description":"Erickbarbosa/Eumesmo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"NevioZanette","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ivomaioli/NevioZanette","creator_name":"Ivo Andr√© Maioli","creator_url":"https://huggingface.co/ivomaioli","description":"ivomaioli/NevioZanette dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"RyotaSakurabaAI","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MaxYuki/RyotaSakurabaAI","creator_name":"Max Yuki","creator_url":"https://huggingface.co/MaxYuki","description":"MaxYuki/RyotaSakurabaAI dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"common-voice-filtered","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/common-voice-filtered","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"\n\t\n\t\t\n\t\tCommon Voice Filtered\n\t\n\nA filtered subset of the Common Voice dataset. Currently, this dataset only includes a small subset of English speech.\nWe only include speech ranked above 3.75 (75%) on the MOS metric, as calculated by the UTMOS system. Approximately 7% of audio qualified for inclusion in this filtered dataset.\nThis data is not final. Processing the whole Common Voice dataset would require a significant amount of compute, this is just a small sample/MVP of the project.\nThe code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/styletts2-community/common-voice-filtered.","first_N":5,"first_N_keywords":["text-to-speech","cc-by-sa-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"khan1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MobeenHameed/khan1","creator_name":"Mobeen Hameed","creator_url":"https://huggingface.co/MobeenHameed","description":"MobeenHameed/khan1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"khan2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MobeenHameed/khan2","creator_name":"Mobeen Hameed","creator_url":"https://huggingface.co/MobeenHameed","description":"MobeenHameed/khan2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"khan_final","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MobeenHameed/khan_final","creator_name":"Mobeen Hameed","creator_url":"https://huggingface.co/MobeenHameed","description":"MobeenHameed/khan_final dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"musicians","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MHunnter/musicians","creator_name":"marmota hunter","creator_url":"https://huggingface.co/MHunnter","description":"MHunnter/musicians dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"RyotaSakuraba","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MaxYuki/RyotaSakuraba","creator_name":"Max Yuki","creator_url":"https://huggingface.co/MaxYuki","description":"MaxYuki/RyotaSakuraba dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Lily-Angel","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MaxYuki/Lily-Angel","creator_name":"Max Yuki","creator_url":"https://huggingface.co/MaxYuki","description":"MaxYuki/Lily-Angel dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Leonardo_Legends.VoiceLines","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/LeonardoTiger/Leonardo_Legends.VoiceLines","creator_name":"Leonardo Monthay","creator_url":"https://huggingface.co/LeonardoTiger","description":"LeonardoTiger/Leonardo_Legends.VoiceLines dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Samples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hungarians/Samples","creator_name":"Hungarian","creator_url":"https://huggingface.co/Hungarians","description":"Hungarians/Samples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"jvnv_corpus_v1_no_nv","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/jvnv_corpus_v1_no_nv","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"JVNV„Ç≥„Éº„Éë„Çπ(Ë®ÄË™ûÈü≥Â£∞„Å®ÈùûË®ÄË™ûÈü≥Â£∞„ÇíÊåÅ„Å§Êó•Êú¨Ë™ûÊÑüÊÉÖÈü≥Â£∞„Ç≥„Éº„Éë„Çπ)„ÅÆ„ÄÅÈùûË®ÄË™ûÈü≥Â£∞ÈÉ®ÂàÜ„ÇíÂâäÈô§„Åó„ÅüÈü≥Â£∞„Éï„Ç°„Ç§„É´„Å®„ÄÅÈùûË®ÄË™ûÈü≥Â£∞ÈÉ®ÂàÜ„ÇíÂâäÈô§„Åó„ÅüÊõ∏„ÅçËµ∑„Åì„Åó„Éï„Ç°„Ç§„É´„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\nÂÖÉ„ÅÆJVNV„Ç≥„Éº„Éë„Çπ„Å´Â≠òÂú®„Åô„ÇãÈùûË®ÄË™ûÈü≥Â£∞„ÅÆÂå∫ÈñìÊÉÖÂ†±„ÇíÂà©Áî®„Åó„ÄÅ„Åù„ÅÆÈÉ®ÂàÜ„ÇíÂçòÁ¥î„Å´„Ç´„ÉÉ„Éà„Åó„Åü„Å†„Åë„Å´„Å™„Çä„Åæ„Åô„ÄÇ\n„Åæ„ÅüÊõ∏„ÅçËµ∑„Åì„Åó„Éï„Ç°„Ç§„É´„ÅØ„ÄÅÂÖÉ„ÅÆÊõ∏„ÅçËµ∑„Åì„Åó„Éï„Ç°„Ç§„É´„Åã„ÇâÈùûË®ÄË™ûÈü≥Â£∞„Å´ÂØæÂøú„Åô„ÇãÈÉ®ÂàÜ„ÇíÂçòÁ¥î„Å´Ââä„Å£„Åü„Å†„Åë„Å´„Å™„Çä„Åæ„Åô„ÄÇ\nÂÖ®„Å¶„Çí„ÉÅ„Çß„ÉÉ„ÇØ„ÅØ„Åó„Å¶„ÅÑ„Å™„ÅÑ„ÅÆ„Åß„ÄÅÊõ∏„ÅçËµ∑„Åì„ÅóÁ≠â„ÅÆ„Å©„Åì„Åã„Å´„Åä„Åã„Åó„ÅÑ„Å®„Åì„Çç„Åå„ÅÇ„Çã„Åã„ÇÇ„Åó„Çå„Åæ„Åõ„Çì„ÄÅ„Åî‰∫ÜÊâø„Åè„Å†„Åï„ÅÑ„ÄÇ\n„É©„Ç§„Çª„É≥„Çπ„ÅØ„ÇÇ„Å®„ÅÆ„É©„Ç§„Çª„É≥„Çπ„ÇíÁ∂ôÊâø„Åó„Å¶CC BY-SA-4.0„Åß„Åô„ÄÇ\n","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Portelinha","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lucianoportela/Portelinha","creator_name":"Luciano Portela","creator_url":"https://huggingface.co/lucianoportela","description":"lucianoportela/Portelinha dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Bird_audio_in_China","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sakei/Bird_audio_in_China","creator_name":"rr","creator_url":"https://huggingface.co/sakei","description":"\n\t\n\t\t\n\t\tDataset Card for Bird_audio_in_China\n\t\n\n\nÊú¨Êï∞ÊçÆÈõÜÊî∂ÈõÜ‰∫ÜÂú®‰∏≠ÂõΩÂ¢ÉÂÜÖÁöÑ401ÁßçÈ∏üÁßçÁöÑÂè´Â£∞Ôºå‰ΩúËÄÖÂ∞ÜÂÖ∂Áî®‰∫é‰∏Ä‰∏™ÁÆÄÊòìÁöÑTinyMLÈ°πÁõÆÔºö„ÄäÂü∫‰∫éSTM32F746ÂÆûÁé∞ÂÆûÊó∂È∏üÁßçËØÜÂà´„Äã\nÈ∏üÂè´Â£∞Èü≥ÂàÜÁ±ª‰Ωú‰∏∫‰∏ÄÁßçÂ∏∏ËßÅÁöÑÁéØÂ¢ÉÈü≥ÂàÜÁ±ª‰ªªÂä°Ôºå‰πüÈùûÂ∏∏ÈÄÇÂêàÁî®‰∫éÂµåÂÖ•ÂºèAIÂ∫îÁî®ÁöÑÊé¢Á¥¢ÔºåÂπ∂‰∏îÂú®ÁîüÊÄÅÁ†îÁ©∂„ÄÅÈ∏üÁ±ª‰øùÊä§„ÄÅÁîüÁâ©Â§öÊ†∑ÊÄßÁõëÊµãÈÉΩÂÖ∑ÊúâÈáçË¶ÅÁöÑÁé∞ÂÆûÊÑè‰πâ„ÄÇÈÄöËøáÂ∞ÜÈ∏üÂè´Â£∞Èü≥ÂàÜÁ±ªÁÆóÊ≥ïÂíåÊ®°ÂûãÂéãÁº©Âà∞Â∞èÂûãËÆæÂ§á‰∏≠ÔºåÂèØ‰ª•Â∞ÜËøô‰∫õÂäüËÉΩÂ∏¶Âà∞Êõ¥Â§öÁöÑÂú∫ÊôØÂíåÂ∫îÁî®‰∏≠Ôºå‰æãÂ¶ÇÂ∞ÜÈ∏üÂè´Â£∞Èü≥ÂàÜÁ±ªÊäÄÊúØÂ∫îÁî®‰∫éÊô∫ËÉΩÈ∏üÁ™ùÁõëÊéßÁ≥ªÁªü„ÄÅÊó†‰∫∫Êú∫Â∑°Ëà™ÁõëÊµãÁ≥ªÁªüÁ≠âÈ¢ÜÂüüÔºåÁî®‰∫éËØÑ‰º∞ÁîüÊÄÅÁ≥ªÁªüÁöÑÂÅ•Â∫∑Áä∂ÊÄÅ‰ª•ÂèäÁõëÊµãÊ∞îÂÄôÂèòÂåñÔºå‰πüÂèØ‰ª•ÂèØ‰ª•ÂØπÈ∏üÁ±ªÁöÑÂàÜÂ∏ÉÊÉÖÂÜµ„ÄÅËøÅÂæôË∑ØÂæÑ„ÄÅÊ†ñÊÅØÂú∞Âà©Áî®Á≠âËøõË°åÁõëÊµãÂíåÁ†îÁ©∂„ÄÇ\nÁî≥ÊòéÔºöÂ£∞Èü≥Ê∫êÊù•Ëá™https://xeno-canto.orgÔºåËøôÊòØ‰∏Ä‰∏™Ëá¥Âäõ‰∫éÂàÜ‰∫´Êù•Ëá™‰∏ñÁïåÂêÑÂú∞ÁöÑÈ∏üÂ£∞ÁöÑÁΩëÁ´ô\n\n\n\t\n\t\t\n\t\n\t\n\t\tÊï∞ÊçÆÈõÜÊèèËø∞\n\t\n\nÊú¨Êï∞ÊçÆÈõÜÊî∂ÈõÜ‰∫ÜÂú®‰∏≠ÂõΩÂ¢ÉÂÜÖÁöÑ401ÁßçÈ∏üÁßçÁöÑÂè´Â£∞ÔºåËØ¶ÁªÜÈ∏üÁßçÁöÑÂàóË°®ÁÇπÂáªËøôÈáåÔºåÊ†ºÂºèÂ¶Ç‰∏ãÔºö\n{\n   \"Áâ©ÁßçÁöÑÈÄöÁî®ÂêçÁß∞\": {\n        \"sp\": \"Áâ©ÁßçÁöÑÂÖ∑‰ΩìÂêçÁß∞ÔºàÁª∞Âè∑Ôºâ\",\n        \"ssp\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sakei/Bird_audio_in_China.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"cszs_fr_en","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ky552/cszs_fr_en","creator_name":"speech552_ky","creator_url":"https://huggingface.co/ky552","description":"This dataset contains the French-English track of the benchmark from ICASSP 2024: Zero Resource Code-Switched Speech Benchmark Using Speech Utterance Pairs for Multiple Spoken Languages.Though the benchmark is originally designed to assess the semantic and syntactic abilities of the speech foundation models, you can also use this dataset for code-switching ASR.\nIf you find this dataset helpful, please consider to cite the following paper:\n@INPROCEEDINGS{10446737,\n  author={Huang, Kuan-Po and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ky552/cszs_fr_en.","first_N":5,"first_N_keywords":["French","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"voice-ai","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yash-412/voice-ai","creator_name":"Yashwanth Kumar K","creator_url":"https://huggingface.co/yash-412","description":"yash-412/voice-ai dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"caveira","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caveira-memes/caveira","creator_name":"caveira memes","creator_url":"https://huggingface.co/caveira-memes","description":"caveira-memes/caveira dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Fmanew","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omolayo/Fmanew","creator_name":"Ipinsanmi","creator_url":"https://huggingface.co/Omolayo","description":"Omolayo/Fmanew dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"openslr63","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/openslr63","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\n\t\n\t\t\n\t\tSLR63: Crowdsourced high-quality Malayalam multi-speaker speech data set\n\t\n\nThis data set contains transcribed high-quality audio of Malayalam sentences recorded by volunteers. The data set consists of wave files, and a TSV file (line_index.tsv). The file line_index.tsv contains a anonymized FileID and the transcription of audio in the file.\nThe data set has been manually quality checked, but there might still be errors.\nPlease report any issues in the following issue tracker on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vrclc/openslr63.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Malayalam","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"bts","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/bts","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/bts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"albion","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mateus7/albion","creator_name":"mateus pego berty","creator_url":"https://huggingface.co/mateus7","description":"mateus7/albion dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Hoshikuzu-Telepashi-Character-Audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ADKhugging/Hoshikuzu-Telepashi-Character-Audio","creator_name":"ADKhuging","creator_url":"https://huggingface.co/ADKhugging","description":"ADKhugging/Hoshikuzu-Telepashi-Character-Audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"TTS-test-wavs","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AaronLi/TTS-test-wavs","creator_name":"aaron li","creator_url":"https://huggingface.co/AaronLi","description":"\n\t\n\t\t\n\t\tTTS-test-wavs\n\t\n\nFor test.\n","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"asr-alignment","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nguyenvulebinh/asr-alignment","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","description":"\n\t\n\t\t\n\t\tSpeech Recognition Alignment Dataset\n\t\n\nThis dataset is a variation of several widely-used ASR datasets, encompassing Librispeech, MuST-C, TED-LIUM, VoxPopuli, Common Voice, and GigaSpeech. The difference is this dataset includes:\n\nPrecise alignment between audio and text. \nText that has been punctuated and made case-sensitive.\nIdentification of named entities in the text.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nFirst, install the latest version of the ü§ó Datasets package:\npip install --upgrade pip\npip‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/asr-alignment.","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"hyvoxpopuli","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Edmon02/hyvoxpopuli","creator_name":"Edmon Sahakyan","creator_url":"https://huggingface.co/Edmon02","description":"\n\t\n\t\t\n\t\tHyVoxPopuli Dataset\n\t\n\nThe HyVoxPopuli dataset is the Armenian language subset of the Facebook VoxPopuli dataset. The name \"HyVoxPopuli\" comes from combining \"hy\" (the ISO 639-1 language code for Armenian) with \"VoxPopuli\" (the original dataset name). It is a high-quality collection of Armenian speech recordings with expert-validated transcriptions, carefully extracted and processed from the original VoxPopuli dataset (https://github.com/facebookresearch/voxpopuli).\nThis dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Edmon02/hyvoxpopuli.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Armenian","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"hyvoxpopuli","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Edmon02/hyvoxpopuli","creator_name":"Edmon Sahakyan","creator_url":"https://huggingface.co/Edmon02","description":"\n\t\n\t\t\n\t\tHyVoxPopuli Dataset\n\t\n\nThe HyVoxPopuli dataset is the Armenian language subset of the Facebook VoxPopuli dataset. The name \"HyVoxPopuli\" comes from combining \"hy\" (the ISO 639-1 language code for Armenian) with \"VoxPopuli\" (the original dataset name). It is a high-quality collection of Armenian speech recordings with expert-validated transcriptions, carefully extracted and processed from the original VoxPopuli dataset (https://github.com/facebookresearch/voxpopuli).\nThis dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Edmon02/hyvoxpopuli.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Armenian","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"SUBAK.KO","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO","creator_name":"SUST CSE Speech Processing Lab","creator_url":"https://huggingface.co/SUST-CSE-Speech","description":"\n\t\n\t\t\n\t\tDataset Card for SUBAK.KO\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBAK.KO (‡¶∏‡ßÅ‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø), a publicly available annotated Bangladeshi standard Bangla speech corpus, is compiled for automatic speech recognition research. \nThis corpus contains 241 hours of high-quality speech data, including 229 hours of read speech data and 12 hours of broadcast speech data. \nThe read speech segment is recorded in a noise-proof studio environment from 33 male and 28 female native Bangladeshi Bangla speakers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"kittech_shona_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kittech/kittech_shona_dataset","creator_name":"Bright Chirindo","creator_url":"https://huggingface.co/Kittech","description":"Kittech/kittech_shona_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","token-classification","text-generation","Shona","English"],"keywords_longer_than_N":true},
	{"name":"sounds","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mozi1924/sounds","creator_name":"Mozi","creator_url":"https://huggingface.co/mozi1924","description":"mozi1924/sounds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"tetsos","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tailsaro/tetsos","creator_name":"tailsaro","creator_url":"https://huggingface.co/Tailsaro","description":"Tailsaro/tetsos dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ziggy1/dataset","creator_name":"Ofc","creator_url":"https://huggingface.co/Ziggy1","description":"Ziggy1/dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mcnguyenkhang","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minhhieu2512/mcnguyenkhang","creator_name":"hieu","creator_url":"https://huggingface.co/minhhieu2512","description":"minhhieu2512/mcnguyenkhang dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"alcace_speech_choice_en","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/denysdios/alcace_speech_choice_en","creator_name":"Den","creator_url":"https://huggingface.co/denysdios","description":"denysdios/alcace_speech_choice_en dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Franja","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yukiamenta/Franja","creator_name":"yuki a menta","creator_url":"https://huggingface.co/yukiamenta","description":"yukiamenta/Franja dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"tts_audio_samples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bilgedogan/tts_audio_samples","creator_name":"Nadide Bilge Doƒüan","creator_url":"https://huggingface.co/bilgedogan","description":"bilgedogan/tts_audio_samples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"vits2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lrxzytime/vits2","creator_name":"zhaoyang","creator_url":"https://huggingface.co/lrxzytime","description":"lrxzytime/vits2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Ryota","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MaxYuki/Ryota","creator_name":"Max Yuki","creator_url":"https://huggingface.co/MaxYuki","description":"MaxYuki/Ryota dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"demo","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/altkl/demo","creator_name":"Alexander Tallund Klungerbo","creator_url":"https://huggingface.co/altkl","description":"altkl/demo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"SakumaRitsuEnStars","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MaxYuki/SakumaRitsuEnStars","creator_name":"Max Yuki","creator_url":"https://huggingface.co/MaxYuki","description":"MaxYuki/SakumaRitsuEnStars dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"test_cs","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xbilek25/test_cs","creator_name":"Stepan Bilek","creator_url":"https://huggingface.co/xbilek25","description":"xbilek25/test_cs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"music_caps_4sec_wave_type","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mb23/music_caps_4sec_wave_type","creator_name":"make brain project 2023","creator_url":"https://huggingface.co/mb23","description":"mb23/music_caps_4sec_wave_type dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ultimatevoice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ledoc/ultimatevoice","creator_name":"le doc","creator_url":"https://huggingface.co/ledoc","description":"ledoc/ultimatevoice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"whisper-sample","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hacoro/whisper-sample","creator_name":"Hyeonjun Yoo","creator_url":"https://huggingface.co/hacoro","description":"hacoro/whisper-sample dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Mark-Rober-Voice","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/elapt1c/Mark-Rober-Voice","creator_name":"elapt1c","creator_url":"https://huggingface.co/elapt1c","description":"This is a dataset of all the clean voice clips of mark rober I could find.\n","first_N":5,"first_N_keywords":["English","wtfpl","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"simsamu","keyword":"voice-activity-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/medkit/simsamu","creator_name":"medkit","creator_url":"https://huggingface.co/medkit","description":"\n\t\n\t\t\n\t\tSimsamu dataset\n\t\n\nThis repository contains recordings of simulated medical dispatch dialogs in the\nfrench language, annotated for diarization and transcription. It is published\nunder the MIT license.\nThese dialogs were recorded as part of the training of emergency medicine\ninterns, which consisted in simulating a medical dispatch call where the interns\ntook turns playing the caller and the regulating doctor. \nEach situation was decided randomly in advance, blind to who was playing the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/medkit/simsamu.","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"simsamu","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/medkit/simsamu","creator_name":"medkit","creator_url":"https://huggingface.co/medkit","description":"\n\t\n\t\t\n\t\tSimsamu dataset\n\t\n\nThis repository contains recordings of simulated medical dispatch dialogs in the\nfrench language, annotated for diarization and transcription. It is published\nunder the MIT license.\nThese dialogs were recorded as part of the training of emergency medicine\ninterns, which consisted in simulating a medical dispatch call where the interns\ntook turns playing the caller and the regulating doctor. \nEach situation was decided randomly in advance, blind to who was playing the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/medkit/simsamu.","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"gatodebotas","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gafoeda/gatodebotas","creator_name":"Oliveira","creator_url":"https://huggingface.co/Gafoeda","description":"Gafoeda/gatodebotas dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"VietMed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leduckhai/VietMed","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","description":"\n\t\n\t\t\n\t\tVietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain (LREC-COLING 2024, Oral)\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nWe introduced a Vietnamese speech recognition dataset in the medical domain comprising 16h of labeled medical speech, 1000h of unlabeled medical speech and 1200h of unlabeled general-domain speech. \nTo our best knowledge, VietMed is by far the world‚Äôs largest public medical speech recognition dataset in 7 aspects:\ntotal duration‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/VietMed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"desa","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theuop/desa","creator_name":"wawdwdw","creator_url":"https://huggingface.co/theuop","description":"theuop/desa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"konkani-speech-text-collection","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thak123/konkani-speech-text-collection","creator_name":"Gaurish Thakkar","creator_url":"https://huggingface.co/thak123","description":"thak123/konkani-speech-text-collection dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"beb","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NandinhoVinicius/beb","creator_name":"Fernando Vinicius da Silva Bandeca","creator_url":"https://huggingface.co/NandinhoVinicius","description":"NandinhoVinicius/beb dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"modelo","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NandinhoVinicius/modelo","creator_name":"Fernando Vinicius da Silva Bandeca","creator_url":"https://huggingface.co/NandinhoVinicius","description":"NandinhoVinicius/modelo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"auto-pale","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeio/auto-pale","creator_name":"zeionara","creator_url":"https://huggingface.co/zeio","description":"\n\t\n\t\t\n\t\tDataset card for pale\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nThis dataset contains league of legends champions' quotes parsed from fandom.\nSee dataset usage example at google colab.\nThe dataset is available in the following configurations:\n\nvanilla - all data pulled from the website without significant modifications apart from the web page structure parsing;\nquotes - truncated version of the corpus, which does't contain sound effects;\nannotated - an extended version of the full configuration‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zeio/auto-pale.","first_N":5,"first_N_keywords":["text-generation","text-classification","automatic-speech-recognition","crowdsourced","English"],"keywords_longer_than_N":true},
	{"name":"isaaa","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lz0kzs/isaaa","creator_name":"luiz","creator_url":"https://huggingface.co/lz0kzs","description":"lz0kzs/isaaa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"modelo","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TurcoLoko/modelo","creator_name":"Emanuel Zanutto Ferreira ","creator_url":"https://huggingface.co/TurcoLoko","description":"TurcoLoko/modelo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"lady","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kelvinloh/lady","creator_name":"Kelvin Loh","creator_url":"https://huggingface.co/Kelvinloh","description":"Kelvinloh/lady dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Common_Voice","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/avinashrajavarapu/Common_Voice","creator_name":"Rajavarapu Avinash","creator_url":"https://huggingface.co/avinashrajavarapu","description":"avinashrajavarapu/Common_Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"modelorr","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TurcoLoko/modelorr","creator_name":"Emanuel Zanutto Ferreira ","creator_url":"https://huggingface.co/TurcoLoko","description":"TurcoLoko/modelorr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Chora","keyword":"audio","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/RogelioRobles/Chora","creator_name":"Rogelio Robles","creator_url":"https://huggingface.co/RogelioRobles","description":"RogelioRobles/Chora dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["unlicense","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"FNaF_Movie_William_Afton_in_Springbonnie_Suit","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SouBryan/FNaF_Movie_William_Afton_in_Springbonnie_Suit","creator_name":"Lorenzo Cristianini de Oliveira","creator_url":"https://huggingface.co/SouBryan","description":"SouBryan/FNaF_Movie_William_Afton_in_Springbonnie_Suit dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"anacastela","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NandinhoVinicius/anacastela","creator_name":"Fernando Vinicius da Silva Bandeca","creator_url":"https://huggingface.co/NandinhoVinicius","description":"NandinhoVinicius/anacastela dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Medradooriginal","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Medradome/Medradooriginal","creator_name":"santos","creator_url":"https://huggingface.co/Medradome","description":"Medradome/Medradooriginal dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Masha","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Medradome/Masha","creator_name":"santos","creator_url":"https://huggingface.co/Medradome","description":"Medradome/Masha dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"jorge","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NandinhoVinicius/jorge","creator_name":"Fernando Vinicius da Silva Bandeca","creator_url":"https://huggingface.co/NandinhoVinicius","description":"NandinhoVinicius/jorge dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"TainaCosta","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Medradome/TainaCosta","creator_name":"santos","creator_url":"https://huggingface.co/Medradome","description":"Medradome/TainaCosta dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Taina","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Medradome/Taina","creator_name":"santos","creator_url":"https://huggingface.co/Medradome","description":"Medradome/Taina dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"GokuBlack","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LyanDJF/GokuBlack","creator_name":"DJF","creator_url":"https://huggingface.co/LyanDJF","description":"LyanDJF/GokuBlack dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"donate_a_cry","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jstoone/donate_a_cry","creator_name":"Jakob Steinn","creator_url":"https://huggingface.co/jstoone","description":"jstoone/donate_a_cry dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"donate_a_cry","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jstoone/donate_a_cry","creator_name":"Jakob Steinn","creator_url":"https://huggingface.co/jstoone","description":"jstoone/donate_a_cry dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"FernandaMedrado","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Medradome/FernandaMedrado","creator_name":"santos","creator_url":"https://huggingface.co/Medradome","description":"Medradome/FernandaMedrado dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"streaming_options_xtts_v2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bilgedogan/streaming_options_xtts_v2","creator_name":"Nadide Bilge Doƒüan","creator_url":"https://huggingface.co/bilgedogan","description":"bilgedogan/streaming_options_xtts_v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts-rj-hi-karya","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/tts-rj-hi-karya","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. They had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426872 recordings in this dataset. They had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1rsh/tts-rj-hi-karya.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"libritts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/libritts","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\n\t\n\t\t\n\t\tDataset Card for LibriTTS\n\t\n\n\n\nLibriTTS is a multi-speaker English corpus of approximately 585 hours of read English speech at 24kHz sampling rate, \nprepared by Heiga Zen with the assistance of Google Speech and Google Brain team members. The LibriTTS corpus is \ndesigned for TTS research. It is derived from the original materials (mp3 audio files from LibriVox and text files \nfrom Project Gutenberg) of the LibriSpeech corpus.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the LibriTTS dataset, adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/libritts.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"speech-rj-hi","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/speech-rj-hi","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. We had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426873 recordings in this dataset. We had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/severo/speech-rj-hi.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"cc","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chaejinki/cc","creator_name":"jinki chae","creator_url":"https://huggingface.co/chaejinki","description":"chaejinki/cc dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Goularte","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ziggy1/Goularte","creator_name":"Ofc","creator_url":"https://huggingface.co/Ziggy1","description":"Ziggy1/Goularte dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"librispeech-200","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/argmaxinc/librispeech-200","creator_name":"Argmax","creator_url":"https://huggingface.co/argmaxinc","description":"argmaxinc/librispeech-200 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"facebook_mms-tts-eng_GPU-CPU","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bilgedogan/facebook_mms-tts-eng_GPU-CPU","creator_name":"Nadide Bilge Doƒüan","creator_url":"https://huggingface.co/bilgedogan","description":"bilgedogan/facebook_mms-tts-eng_GPU-CPU dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ratchet-util","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FL33TW00D-HF/ratchet-util","creator_name":"Christopher Fleetwood","creator_url":"https://huggingface.co/FL33TW00D-HF","description":"FL33TW00D-HF/ratchet-util dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vlsp2020_vinai_100h","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VLSP 2020 - VinAI - ASR challenge dataset\n\t\n\nofficial announcement:\n\nti·∫øng vi·ªát: https://institute.vinbigdata.org/events/vinbigdata-chia-se-100-gio-du-lieu-tieng-noi-cho-cong-dong/\nin eglish: https://institute.vinbigdata.org/en/events/vinbigdata-shares-100-hour-data-for-the-community/\nVLSP 2020 workshop: https://vlsp.org.vn/vlsp2020\n\nofficial download: https://drive.google.com/file/d/1vUSxdORDxk-ePUt-bUVDahpoXiqKchMx/view?usp=sharing\ncontact: info@vinbigdata.org‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Vicent_Price","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/italobovier/Vicent_Price","creator_name":"italo pablo","creator_url":"https://huggingface.co/italobovier","description":"italobovier/Vicent_Price dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"fpt_fosd","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/fpt_fosd","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of FPT Open Speech Dataset (FOSD)\n\t\n\nreleased publicly in 2018 by FPT Corporation\n100h, 25.9k samples\nofficial link (dead): https://fpt.ai/fpt-open-speech-data/\nmirror: https://data.mendeley.com/datasets/k9sxg2twv4/4\nDOI: 10.17632/k9sxg2twv4.4\npre-process:\n\nremove non-sense strings: -N \\r\\n\nremove 4 files because missing transcription:\nSet001_V0.1_008210.mp3\nSet001_V0.1_010753.mp3\nSet001_V0.1_011477.mp3\nSet001_V0.1_011841.mp3\n\n\n\nneed to do: check misspelling\nusage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/fpt_fosd.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SaCa","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ReicDiro/SaCa","creator_name":"Auxmiliano Auxiliares","creator_url":"https://huggingface.co/ReicDiro","description":"ReicDiro/SaCa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"jv14","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rogeriosss/jv14","creator_name":"mario","creator_url":"https://huggingface.co/rogeriosss","description":"rogeriosss/jv14 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"infore1_25hours","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore1_25hours","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset ‚Ññ1\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n25h, 14.9k samples, InfoRe paid a contractor to read text\nofficial download: magnet:?xt=urn:btih:1cbe13fb14a390c852c016a924b4a5e879d85f41&dn=25hours.zip&tr=http%3A%2F%2Foffice.socials.vn%3A8725%2Fannounce\nmirror: https://files.huylenguyen.com/datasets/infore/25hours.zip\nunzip password: BroughtToYouByInfoRe\npre-process: see‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore1_25hours.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"alyx-vance-audio-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Atopona-Organization/alyx-vance-audio-dataset","creator_name":"Atopona-Organization","creator_url":"https://huggingface.co/Atopona-Organization","description":"\n\t\n\t\t\n\t\talyx-vance-audio-dataset\n\t\n\n\n\t\n\t\t\n\t\tAlyx VanceÔºàÂçäÊù°ÂëΩ2ÔºâÈü≥È¢ëÊï∞ÊçÆÈõÜ\n\t\n\n\n\t\n\t\t\n\t\tÂà∂‰ΩúÔºöAtopona\n\t\n\n\n\t\n\t\t\n\t\tÊ≥®ÊÑè\n\t\n\n1„ÄÅÊï∞ÊçÆÈõÜÂùáÂèñËá™ÂØπÂ∫î‰∫∫Áâ©ËßÜÈ¢ëÂàáÁâáÔºåÂ£∞Èü≥ÁâàÊùÉÂΩíÂ±û‰∫éÂØπÂ∫î‰∫∫Áâ©ÔºåÊó©ÊúüË¥®Èáè‰∏ÄÂù®ÁöÑÂ∞±Ê≤°‰∏ä‰º†Ôºõ\n2„ÄÅÈü≥È¢ë‰ªÖËøõË°åÂàÜÁ¶ª‰∫∫Â£∞ÂèäËá™Âä®ÂàáÁâáÔºåÊú™ËøõË°åÁ≤æÈÄâÔºåËØ∑‰∏ãËΩΩËøõË°åÊäΩÈÄâËØïÂê¨ÂêéÂÜçËÄÉËôëÊòØÂê¶‰ΩøÁî®ÔºàÂºÉÁî®Èü≥È¢ëÂú®ÊâãÂ∑•Ê†áÊ≥®Êó∂ËøõË°å‰∫ÜË∑≥ËøáÔºâÔºõ\n3„ÄÅÊâãÂ∑•Ê†áÊ≥®Êñá‰ª∂ÈöèÊú∫ÊéâËêΩÔºàÊâãÂ∑•Ê†áÊ≥®Êó†Ê≥ï‰øùËØÅÊØè‰∏ÄÂè•ÈÉΩÊ†áÁöÑÂæàÊ†áÂáÜÔºåÂèØ‰ª•Ëá™Ë°åÊ£ÄÊü•ÔºâÔºõ\n4„ÄÅËØ∑Âú®Ê≥ïÂæãÂÖÅËÆ∏ËåÉÂõ¥ÂÜÖËøõË°åÊµãËØï‰ΩøÁî®ÔºÅ‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜ‰∫ßÁîüÈóÆÈ¢òËØ∑Ëá™Ë°åÊâøÊãÖÔºÅ\n5„ÄÅgithub‰ªìÂ∫ìÁöÑËØùÊï∞ÊçÆÈõÜÂú® Releases ‰∏≠\n","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"infore2_audiobooks","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore2_audiobooks","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset ‚Ññ2\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n415h, 315k samples, vietnamese audiobooks of chinese w«îxi√° Ê≠¶‰ø† & xiƒÅnxi√° ‰ªô‰ø†\nb·ªô d·ªØ li·ªáu b√≥c ra t·ª´ YouTube ƒë·ªçc truy·ªán v√µ hi·ªáp & ti√™n hi·ªáp, √°p d·ª•ng kƒ© thu·∫≠t ƒë·ªëi chi·∫øu vƒÉn b·∫£n ƒë·ªÉ d√°n nh√£n t·ª± ƒë·ªông\nofficial download:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore2_audiobooks.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"schaeffer_thesis_corrected","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dbschaeffer/schaeffer_thesis_corrected","creator_name":"SCHAEFFER Database","creator_url":"https://huggingface.co/dbschaeffer","description":"The SCHAEFFER dataset (Spectro-morphogical Corpus of Human-annotated Audio with Electroacoustic Features for Experimental Research), is a compilation of 788 raw audio data accompanied by human annotations and morphological acoustic features. \nThe audio files adhere to the concept of Sound Objects introduced by Pierre Scaheffer, a framework for the analysis and creation of sound that focuses on its typological and morphological characteristics.\nInside the dataset, the annotation are provided in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dbschaeffer/schaeffer_thesis_corrected.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"schaeffer_thesis_corrected","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dbschaeffer/schaeffer_thesis_corrected","creator_name":"SCHAEFFER Database","creator_url":"https://huggingface.co/dbschaeffer","description":"The SCHAEFFER dataset (Spectro-morphogical Corpus of Human-annotated Audio with Electroacoustic Features for Experimental Research), is a compilation of 788 raw audio data accompanied by human annotations and morphological acoustic features. \nThe audio files adhere to the concept of Sound Objects introduced by Pierre Scaheffer, a framework for the analysis and creation of sound that focuses on its typological and morphological characteristics.\nInside the dataset, the annotation are provided in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dbschaeffer/schaeffer_thesis_corrected.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"schaeffer_thesis_corrected","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dbschaeffer/schaeffer_thesis_corrected","creator_name":"SCHAEFFER Database","creator_url":"https://huggingface.co/dbschaeffer","description":"The SCHAEFFER dataset (Spectro-morphogical Corpus of Human-annotated Audio with Electroacoustic Features for Experimental Research), is a compilation of 788 raw audio data accompanied by human annotations and morphological acoustic features. \nThe audio files adhere to the concept of Sound Objects introduced by Pierre Scaheffer, a framework for the analysis and creation of sound that focuses on its typological and morphological characteristics.\nInside the dataset, the annotation are provided in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dbschaeffer/schaeffer_thesis_corrected.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jequevoice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tidesmoz/jequevoice","creator_name":"Aristides Banda","creator_url":"https://huggingface.co/tidesmoz","description":"tidesmoz/jequevoice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mariadefatima","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/erikrose93/mariadefatima","creator_name":"Erik Rose","creator_url":"https://huggingface.co/erikrose93","description":"erikrose93/mariadefatima dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"elevenlabs_dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skypro1111/elevenlabs_dataset","creator_name":"Serhii Kravchenko","creator_url":"https://huggingface.co/skypro1111","description":"\n\t\n\t\t\n\t\tSynthetic TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was created with the aim of exploring the concept of using synthetic datasets for training Text-to-Speech (TTS) models. It consists of 1,388 audio files with a total duration of 2 hours and 20 minutes and their corresponding textual transcripts. The dataset leverages the capabilities of advanced AI services, utilizing paid subscriptions to ChatGPT-4 for text generation and ElevenLabs.io for audio generation.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skypro1111/elevenlabs_dataset.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"poppy","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Selever/poppy","creator_name":"Selever selever selver","creator_url":"https://huggingface.co/Selever","description":"Selever/poppy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"liniker","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kkkkpojjhh/liniker","creator_name":"kkkkk","creator_url":"https://huggingface.co/kkkkpojjhh","description":"kkkkpojjhh/liniker dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"krut","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/karshrecords/krut","creator_name":"karshrecords","creator_url":"https://huggingface.co/karshrecords","description":"karshrecords/krut dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"RENNY","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/moralesid/RENNY","creator_name":"jo√£o marcos ","creator_url":"https://huggingface.co/moralesid","description":"moralesid/RENNY dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Afar","afl-3.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"yousa_data_0","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yousaforever/yousa_data_0","creator_name":"Algacez","creator_url":"https://huggingface.co/yousaforever","description":"Êú¨Êï∞ÊçÆÈõÜÂÖ±138minÔºåÂ§ßÊ¶ÇÂåÖÂê´yousaÁöÑ50È¶ñÊ≠åÔºàÂ§ßÈÉ®ÂàÜÂú®2016-2022Âπ¥ÔºâÔºåÂ∑≤ÁªèËøáÂàáÁâáÂ§ÑÁêÜÂπ∂Á≠õÈÄâÔºåÊó∂ÈïøÂú®4-15sÔºåÂÖ±796Êù°wavÈü≥È¢ëÊï∞ÊçÆ„ÄÇ‰∏≠ÊñáÂç†ÁªùÂ§ßÈÉ®ÂàÜÔºåÊúâÂ∞ëÈáèÊó•ÊñáÂèäÊûÅÂ∞ëËã±Êñá„ÄÇ\nThis dataset consists of 138 minutes in total and approximately includes 50 songs by yousa (most of them released between 2016 and 2022). The dataset has been sliced and filtered, with durations ranging from 4 to 15 seconds, resulting in a total of 796 WAV audio files. The majority of the content is in Chinese, with a small amount in Japanese and very little in English.\n","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"yousa_data_1","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yousaforever/yousa_data_1","creator_name":"Algacez","creator_url":"https://huggingface.co/yousaforever","description":"Â§ßÁ∫¶9minÁöÑÊ≠£Â∏∏ËØ¥ËØùÂ£∞Èü≥ÔºåÂàíÂàÜ‰∏∫70‰∏™ÂàáÁâáÔºåÂèØÁî®‰∫éËÆ≠ÁªÉttsÊ®°Âûã„ÄÇ\nA 9-minute normal speaking voice divided into 70 slices for training a TTS model.\n","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ProcedimentosSUS","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lucasjca/ProcedimentosSUS","creator_name":"Lucas Justino Costa Assis","creator_url":"https://huggingface.co/lucasjca","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nYour dataset description goes here. Describe what the dataset contains, its purpose, and any relevant information about its creation and usage.\n\n\t\n\t\t\n\t\tData Format\n\t\n\nEach entry in the dataset consists of two fields:\n\naudio_path: The path to the audio file.\ndescription: The written description corresponding to the audio file.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nHere's an example entry from the dataset:\n{\n    \"audio_path\": \"/path/to/audio/file.mp3\",\n    \"description\": \"A written‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lucasjca/ProcedimentosSUS.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vad-multi-species","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nccratliri/vad-multi-species","creator_name":"TTF Datascience, NCCR@LiRI, UZH","creator_url":"https://huggingface.co/nccratliri","description":"\n\t\n\t\t\n\t\n\t\n\t\tPositive Transfer Of The Whisper Speech Transformer To Human And Animal Voice Activity Detection\n\t\n\nWe proposed WhisperSeg, utilizing the Whisper Transformer pre-trained for Automatic Speech Recognition (ASR) for both human and animal Voice Activity Detection (VAD). For more details, please refer to our paper\n\nPositive Transfer of the Whisper Speech Transformer to Human and Animal Voice Activity Detection\nNianlong Gu, Kanghwi Lee, Maris Basha, Sumit Kumar Ram, Guanghao You, Richard‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nccratliri/vad-multi-species.","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"vad-zebra-finch","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nccratliri/vad-zebra-finch","creator_name":"TTF Datascience, NCCR@LiRI, UZH","creator_url":"https://huggingface.co/nccratliri","description":"\n\t\n\t\t\n\t\tPositive Transfer Of The Whisper Speech Transformer To Human And Animal Voice Activity Detection\n\t\n\nWe proposed WhisperSeg, utilizing the Whisper Transformer pre-trained for Automatic Speech Recognition (ASR) for both human and animal Voice Activity Detection (VAD). For more details, please refer to our paper\n\nPositive Transfer of the Whisper Speech Transformer to Human and Animal Voice Activity Detection\nNianlong Gu, Kanghwi Lee, Maris Basha, Sumit Kumar Ram, Guanghao You, Richard H.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nccratliri/vad-zebra-finch.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vad-bengalese-finch","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nccratliri/vad-bengalese-finch","creator_name":"TTF Datascience, NCCR@LiRI, UZH","creator_url":"https://huggingface.co/nccratliri","description":"\n\t\n\t\t\n\t\tPositive Transfer Of The Whisper Speech Transformer To Human And Animal Voice Activity Detection\n\t\n\nWe proposed WhisperSeg, utilizing the Whisper Transformer pre-trained for Automatic Speech Recognition (ASR) for both human and animal Voice Activity Detection (VAD). For more details, please refer to our paper\n\nPositive Transfer of the Whisper Speech Transformer to Human and Animal Voice Activity Detection\nNianlong Gu, Kanghwi Lee, Maris Basha, Sumit Kumar Ram, Guanghao You, Richard H.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nccratliri/vad-bengalese-finch.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vad-marmoset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nccratliri/vad-marmoset","creator_name":"TTF Datascience, NCCR@LiRI, UZH","creator_url":"https://huggingface.co/nccratliri","description":"\n\t\n\t\t\n\t\tPositive Transfer Of The Whisper Speech Transformer To Human And Animal Voice Activity Detection\n\t\n\nWe proposed WhisperSeg, utilizing the Whisper Transformer pre-trained for Automatic Speech Recognition (ASR) for both human and animal Voice Activity Detection (VAD). For more details, please refer to our paper\n\nPositive Transfer of the Whisper Speech Transformer to Human and Animal Voice Activity Detection\nNianlong Gu, Kanghwi Lee, Maris Basha, Sumit Kumar Ram, Guanghao You, Richard H.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nccratliri/vad-marmoset.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vad-mouse","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nccratliri/vad-mouse","creator_name":"TTF Datascience, NCCR@LiRI, UZH","creator_url":"https://huggingface.co/nccratliri","description":"\n\t\n\t\t\n\t\tPositive Transfer Of The Whisper Speech Transformer To Human And Animal Voice Activity Detection\n\t\n\nWe proposed WhisperSeg, utilizing the Whisper Transformer pre-trained for Automatic Speech Recognition (ASR) for both human and animal Voice Activity Detection (VAD). For more details, please refer to our paper\n\nPositive Transfer of the Whisper Speech Transformer to Human and Animal Voice Activity Detection\nNianlong Gu, Kanghwi Lee, Maris Basha, Sumit Kumar Ram, Guanghao You, Richard H.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nccratliri/vad-mouse.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vad-human-ava-speech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nccratliri/vad-human-ava-speech","creator_name":"TTF Datascience, NCCR@LiRI, UZH","creator_url":"https://huggingface.co/nccratliri","description":"\n\t\n\t\t\n\t\n\t\n\t\tPositive Transfer Of The Whisper Speech Transformer To Human And Animal Voice Activity Detection\n\t\n\nWe proposed WhisperSeg, utilizing the Whisper Transformer pre-trained for Automatic Speech Recognition (ASR) for both human and animal Voice Activity Detection (VAD). For more details, please refer to our paper\n\nPositive Transfer of the Whisper Speech Transformer to Human and Animal Voice Activity Detection\nNianlong Gu, Kanghwi Lee, Maris Basha, Sumit Kumar Ram, Guanghao You, Richard‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nccratliri/vad-human-ava-speech.","first_N":5,"first_N_keywords":["apache-2.0","Audio","arxiv:1808.00606","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"NoisyLibriSpeechDataset-MUSAN","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhaoyang9425/NoisyLibriSpeechDataset-MUSAN","creator_name":"Zhao Yang","creator_url":"https://huggingface.co/zhaoyang9425","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for the Noisy LibriSpeech dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe noisy speech corpus is  constructed by randomly sampling noise clips from the MUSAN noise dataset and adding them to LibriSpeech dataset.\nThe Signal-to-Noise Ratio (SNR) levels are sampled from a uniform  distribution in 0 dB, 5 dB, 10 dB, 15 dB, and 20 dB.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nsame structure with LibriSpeech dataset\n","first_N":5,"first_N_keywords":["English","afl-3.0","Audio","üá∫üá∏ Region: US","read book"],"keywords_longer_than_N":false},
	{"name":"AlbanianSpeech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Yakidev/AlbanianSpeech","creator_name":"Trust Oriakhi","creator_url":"https://huggingface.co/Yakidev","description":"Yakidev/AlbanianSpeech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Albanian","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Persian-Speech-Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SeyedAli/Persian-Speech-Dataset","creator_name":"Seyed Ali Mir Mohammad Hosseini","creator_url":"https://huggingface.co/SeyedAli","description":"SeyedAli/Persian-Speech-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"open-music-practice-demo","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/realfolkcode/open-music-practice-demo","creator_name":"Dmitry","creator_url":"https://huggingface.co/realfolkcode","description":"realfolkcode/open-music-practice-demo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enrichment_only","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enrichment_only","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"\n\t\n\t\t\n\t\tDataset Card for SpeechCommands\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nüìä Data-centric AI principles have become increasingly important for real-world use cases.At Renumics we believe that classical benchmark datasets and competitions should be extended to reflect this development. \nüîç This is why we are publishing benchmark datasets with application-specific enrichments (e.g. embeddings, baseline results, uncertainties, label error scores). We hope this helps the ML community in the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renumics/speech_commands_enrichment_only.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enrichment_only","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enrichment_only","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"\n\t\n\t\t\n\t\tDataset Card for SpeechCommands\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nüìä Data-centric AI principles have become increasingly important for real-world use cases.At Renumics we believe that classical benchmark datasets and competitions should be extended to reflect this development. \nüîç This is why we are publishing benchmark datasets with application-specific enrichments (e.g. embeddings, baseline results, uncertainties, label error scores). We hope this helps the ML community in the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renumics/speech_commands_enrichment_only.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"speech_commands_enrichment_only","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enrichment_only","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"\n\t\n\t\t\n\t\tDataset Card for SpeechCommands\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nüìä Data-centric AI principles have become increasingly important for real-world use cases.At Renumics we believe that classical benchmark datasets and competitions should be extended to reflect this development. \nüîç This is why we are publishing benchmark datasets with application-specific enrichments (e.g. embeddings, baseline results, uncertainties, label error scores). We hope this helps the ML community in the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renumics/speech_commands_enrichment_only.","first_N":5,"first_N_keywords":["audio-classification","keyword-spotting","other","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"CommonVoiceCorpusHindi15","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusHindi15","creator_name":"Yagnik Poshiya","creator_url":"https://huggingface.co/yagnikposhiya","description":"\n\t\n\t\t\n\t\n\t\n\t\tCommonVoiceCorpusHindi15\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDirectory structure:\n\t\n\n\nassets \n a. Download whole compressed dataset by clicking on the cv-corpus-15.0-2023-09-08-hi.tar.gz file. \n b. splitdata.py, python script contains code to split \"clips\" direcrtory in the original dataset. Because HuggingFace supports 10,000 files per directory but in the original dataset \"clips\" directory contains 14,000 files almost. So, \"clips\" directory is splitted into two directories \"clips0\" and \"clips1\".‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusHindi15.","first_N":5,"first_N_keywords":["Hindi","apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"CommonVoiceCorpusPunjabi15","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusPunjabi15","creator_name":"Yagnik Poshiya","creator_url":"https://huggingface.co/yagnikposhiya","description":"\n\t\n\t\t\n\t\n\t\n\t\tComonVoiceCorpusPunjabi15\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDirectory structure:\n\t\n\n\nassets\n a. Download whole compressed dataset by clicking on the cv-corpus-15.0-2023-09-08-pa-IN.tar.gz file.\n\ndata\n a. All audio files are stored into \"clips\" directory\n b. All metadata are also stored into \"data\" directory\n\nCredit: Common Voice moz://a\n\n\n","first_N":5,"first_N_keywords":["Panjabi","apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"CommonVoiceCorpusTamil15","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusTamil15","creator_name":"Yagnik Poshiya","creator_url":"https://huggingface.co/yagnikposhiya","description":"yagnikposhiya/CommonVoiceCorpusTamil15 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Tamil","apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"nota","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nota","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\n\t\n\t\t\n\t\tDataset Card for Nota\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis data was created by the public institution Nota, which is part of the Danish Ministry of Culture. Nota has a library audiobooks and audiomagazines for people with reading or sight disabilities. Nota also produces a number of audiobooks and audiomagazines themselves.  \nThe dataset consists of audio and associated transcriptions from Nota's audiomagazines \"Inspiration\" and \"Radio/TV\". All files related to one reading of one edition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nota.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"faith-connors","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iwillreturnbatman/faith-connors","creator_name":"peter crane","creator_url":"https://huggingface.co/iwillreturnbatman","description":"iwillreturnbatman/faith-connors dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"CommonVoiceCorpusUrdu15","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusUrdu15","creator_name":"Yagnik Poshiya","creator_url":"https://huggingface.co/yagnikposhiya","description":"yagnikposhiya/CommonVoiceCorpusUrdu15 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"silasbr","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XisDraki3142/silasbr","creator_name":"Draki Xis","creator_url":"https://huggingface.co/XisDraki3142","description":"XisDraki3142/silasbr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Jennie","keyword":"audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rmx-stay/Jennie","creator_name":"RMX","creator_url":"https://huggingface.co/rmx-stay","description":"rmx-stay/Jennie dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["artistic-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"azspeech_voices","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/interneuronai/azspeech_voices","creator_name":"interneuron","creator_url":"https://huggingface.co/interneuronai","description":"interneuronai/azspeech_voices dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mls_eng_10k","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng_10k","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls_eng_10k","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng_10k","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"My-Mister-K-Dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Prayuk/My-Mister-K-Dataset","creator_name":"Kaewsanit","creator_url":"https://huggingface.co/Prayuk","description":"Prayuk/My-Mister-K-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"blaze","keyword":"audio","license":"GNU Lesser General Public License v3.0","license_url":"https://choosealicense.com/licenses/lgpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oviniciusc/blaze","creator_name":"Vinicius Cesar de Oliveira","creator_url":"https://huggingface.co/oviniciusc","description":"oviniciusc/blaze dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["lgpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"alexg","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KHome/alexg","creator_name":"Lab","creator_url":"https://huggingface.co/KHome","description":"KHome/alexg dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"colab","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gtar69/colab","creator_name":"Chris Chang","creator_url":"https://huggingface.co/gtar69","description":"gtar69/colab dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"noiseVehicle","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anderloh/noiseVehicle","creator_name":"Anders L√∏hr","creator_url":"https://huggingface.co/anderloh","description":"anderloh/noiseVehicle dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"prueba","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/prueba","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository where the audio files are in another Hugging Face repository.\n","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"iSparrow_test_data","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MaHaWo/iSparrow_test_data","creator_name":"HaMa","creator_url":"https://huggingface.co/MaHaWo","description":"MaHaWo/iSparrow_test_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ROAA-SHORT2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khaledrabie1979/ROAA-SHORT2","creator_name":"Khaled Rabie","creator_url":"https://huggingface.co/khaledrabie1979","description":"khaledrabie1979/ROAA-SHORT2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Hokchia","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yjhuang01/Hokchia","creator_name":"Yijun Huang","creator_url":"https://huggingface.co/yjhuang01","description":"\n\t\n\t\t\n\t\tHokchia Audio Dataset\n\t\n\nHokchia, or the Fuqing dialect, is a branch of Eastern Min Chinese spoken mainly in the Fuqing City of Fujian province, China. Unlike Hokkien, which is more widely recognized and spoken in various parts of Southeast Asia, Hokchia maintains its unique linguistic characteristics and is primarily used within the Fuqing community and its diaspora. This dialect is known for its distinct pronunciation, vocabulary, and grammatical structures compared to other Min‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yjhuang01/Hokchia.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","original","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"Wilbur-Robinson","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Bluebomber182/Wilbur-Robinson","creator_name":"Bluebomber182","creator_url":"https://huggingface.co/Bluebomber182","description":"Bluebomber182/Wilbur-Robinson dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"emotion_dataset_from_STEVEN_R._LIVINGSTONE","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cychristophercyc/emotion_dataset_from_STEVEN_R._LIVINGSTONE","creator_name":"Yang Cao","creator_url":"https://huggingface.co/cychristophercyc","description":"cychristophercyc/emotion_dataset_from_STEVEN_R._LIVINGSTONE dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"luna-speech-dataset","keyword":"audio","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/luna-speech-dataset","creator_name":"Mateusz Czy≈ºnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This speech dataset consists of 10385 short audio clips of multiple speakers conversing in Polish. A transcription is provided for each clip, also gender of speaker is provided for part of the dataset. Clips have total length of almost 10 hours.\nThis dataset was created from LUNA dataset of human-human and human-computer dialogues on the topic of public transport. The postprocessing consisted of extracting segments with human speech together with their transcripts. If you are interested in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/luna-speech-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Polish","bsd-2-clause","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MenoSet","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rmndrnts/MenoSet","creator_name":"Roman Derunets","creator_url":"https://huggingface.co/rmndrnts","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nA dataset invented for Meno multimodal LLM. Contains questions related to three modalities - audio, visual and text.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nYou can load images and audios from here\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nA dataset of intellectual questions chained together was collected based on open\ndata from the game ‚ÄùWhat? Where? When?‚Äù and questions on arbitrary topics.\nFor each question in the dataset, there are from one to several possible answers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rmndrnts/MenoSet.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"Multi_Language_Audio2Text","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/UdyanSachdev/Multi_Language_Audio2Text","creator_name":"Udyan Sachdev","creator_url":"https://huggingface.co/UdyanSachdev","description":"This dataset by Mozilla Common Voice (https://commonvoice.mozilla.org/en/datasets) is crafted by Udyan Sachdev\nVoice datasets play a pivotal role in training and evaluating speech-to-text models, influencing advancements in natural language processing. This dataset outlines the creation of a comprehensive text dataset from 40,571 MP3 audio files sourced from the Common Voice project. The dataset aims to serve as a benchmark for training and evaluating speech-to-text models in English, French‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UdyanSachdev/Multi_Language_Audio2Text.","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"MediaSpeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tMediaSpeech\n\t\n\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\nBaseline models and WAV version of the dataset can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"test_NextAudioGen_uvr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mohannad/test_NextAudioGen_uvr","creator_name":"Mohannad Ehab Barakat","creator_url":"https://huggingface.co/Mohannad","description":"Mohannad/test_NextAudioGen_uvr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"hindustani-raag-small","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neerajaabhyankar/hindustani-raag-small","creator_name":"Neeraja Abhyankar","creator_url":"https://huggingface.co/neerajaabhyankar","description":"neerajaabhyankar/hindustani-raag-small dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"hindustani-raag-small","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neerajaabhyankar/hindustani-raag-small","creator_name":"Neeraja Abhyankar","creator_url":"https://huggingface.co/neerajaabhyankar","description":"neerajaabhyankar/hindustani-raag-small dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"dummy-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bezzam/dummy-dataset","creator_name":"Eric Bezzam","creator_url":"https://huggingface.co/bezzam","description":"bezzam/dummy-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"Test_DataSet1","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SatishFaction/Test_DataSet1","creator_name":"Satish","creator_url":"https://huggingface.co/SatishFaction","description":"This is a test for creating a dataset\n","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Hades","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rogerio8369/Hades","creator_name":"santos","creator_url":"https://huggingface.co/rogerio8369","description":"rogerio8369/Hades dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"jalandhary_asr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirfan899/jalandhary_asr","creator_name":"Muhammad Irfan","creator_url":"https://huggingface.co/mirfan899","description":"Jalandhary dataset is created using whisper model for STT and TTS. Some audios are ommited due to issues while trimming them. If there are some isues \nin the dataset or audio not matching the text you can start a discussion or ping me to correcting it. \n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Urdu","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_test_clean_word_timestamp","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/olympusmons/librispeech_asr_test_clean_word_timestamp","creator_name":"ML","creator_url":"https://huggingface.co/olympusmons","description":"\n\t\n\t\t\n\t\tWord-level timestamp annotated Librispeech ASR test set\n\t\n\nThis dataset contains word-level timestamp information for the Librispeech ASR test (clean) dataset.\nIt contains 2620 short files that have been force-aligned with its text to get reasonably accurate word-level timestamp information.\nSuitable for use in timestamp benchmarking of ASR models or audio dataset preprocessing.\nTo request access to more datasets like this, please fill out this form:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/olympusmons/librispeech_asr_test_clean_word_timestamp.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MJ2009era","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/camilomj/MJ2009era","creator_name":"Apple Head","creator_url":"https://huggingface.co/camilomj","description":"camilomj/MJ2009era dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Khinalug_ASR","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4LT/Khinalug_ASR","creator_name":"AI4LT","creator_url":"https://huggingface.co/AI4LT","description":"AI4LT/Khinalug_ASR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"pwr-azon-speech-dataset","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/pwr-azon-speech-dataset","creator_name":"Mateusz Czy≈ºnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This speech dataset consists of 15332 short audio clips of multiple speakers speaking in Polish. Transcription is provided for 14491 audio clips (train split), and it is missing for 841 audio clips (unsup split). Gender of speaker is provided for the whole dataset. Clips have total length of almost 31 hours.\nThis dataset was created from Korpus nagra≈Ñ pr√≥bek mowy do cel√≥w budowy modeli akustycznych dla automatycznego rozpoznawania mowy w jƒôzyku polskim. The dataset was repackaged into easier‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/pwr-azon-speech-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Polish","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"px-corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bastiendechamps/px-corpus","creator_name":"Bastien Dechamps","creator_url":"https://huggingface.co/bastiendechamps","description":"\n\t\n\t\t\n\t\tPxCorpus : A Spoken Drug Prescription Dataset in French\n\t\n\nPxCorpus is to the best of our knowledge, the first spoken medical drug prescriptions corpus to be distributed. \nIt contains 4 hours of transcribed and annotated dialogues of drug prescriptions in \nFrench acquired through an experiment with 55 participants experts and non-experts  in drug prescriptions.\nThe automatic transcriptions were verified by human effort and aligned with \nsemantic labels to allow training of NLP models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bastiendechamps/px-corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","French","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"slmix","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jstackhouse/slmix","creator_name":"Jamie Stackhouse","creator_url":"https://huggingface.co/jstackhouse","description":"A generated dataset constructed from LibriSpeech and code from the SparseLibriMix project.\nThis is licensed as CC-BY-4.0.\n","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts_hindi","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudarsa/tts_hindi","creator_name":"Parida","creator_url":"https://huggingface.co/sudarsa","description":"sudarsa/tts_hindi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"shn-tts-datasets","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NorHsangPha/shn-tts-datasets","creator_name":"NoerNova","creator_url":"https://huggingface.co/NorHsangPha","description":"NorHsangPha/shn-tts-datasets dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"modi_tts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudarsa/modi_tts","creator_name":"Parida","creator_url":"https://huggingface.co/sudarsa","description":"sudarsa/modi_tts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts_m_ds","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudarsa/tts_m_ds","creator_name":"Parida","creator_url":"https://huggingface.co/sudarsa","description":"sudarsa/tts_m_ds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"auto_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudarsa/auto_dataset","creator_name":"Parida","creator_url":"https://huggingface.co/sudarsa","description":"sudarsa/auto_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Vozes","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexMine/Vozes","creator_name":"8080","creator_url":"https://huggingface.co/AlexMine","description":"AlexMine/Vozes dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"librispeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argmaxinc/librispeech","creator_name":"Argmax","creator_url":"https://huggingface.co/argmaxinc","description":"argmaxinc/librispeech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"AISHELL-3","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISHELL/AISHELL-3","creator_name":"aishelltech","creator_url":"https://huggingface.co/AISHELL","description":"AISHELL-3 is a large-scale and high-fidelity multi-speaker Mandarin speech corpus published by Beijing Shell Shell Technology Co.,Ltd. It can be used to train multi-speaker Text-to-Speech (TTS) systems.The corpus contains roughly 85 hours of emotion-neutral recordings spoken by 218 native Chinese mandarin speakers and total 88035 utterances. Their auxiliary attributes such as gender, age group and native accents are explicitly marked and provided in the corpus. Accordingly, transcripts in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AISHELL/AISHELL-3.","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"OUltimate","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ORVC/OUltimate","creator_name":"Open RVC","creator_url":"https://huggingface.co/ORVC","description":"ORVC/OUltimate dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"lil","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yeslirrr/lil","creator_name":"ye junir","creator_url":"https://huggingface.co/yeslirrr","description":"yeslirrr/lil dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"AISHELL-4","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISHELL/AISHELL-4","creator_name":"aishelltech","creator_url":"https://huggingface.co/AISHELL","description":"AISHELL/AISHELL-4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"TCC","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kashmir96/TCC","creator_name":"Thierry Braga","creator_url":"https://huggingface.co/Kashmir96","description":"Kashmir96/TCC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","afl-3.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"tfex_set50","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kasamajin/tfex_set50","creator_name":"Kasama Jin","creator_url":"https://huggingface.co/kasamajin","description":"kasamajin/tfex_set50 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"work","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gustav114514/work","creator_name":"Ryohei Kasai","creator_url":"https://huggingface.co/Gustav114514","description":"\n\t\n\t\t\n\t\n\t\n\t\tFine-tuned XLSR-53 large model for speech recognition in Japanese\n\t\n\nFine-tuned facebook/wav2vec2-large-xlsr-53 on Japanese using the train and validation splits of Common Voice 6.1, CSS10 and JSUT.\nWhen using this model, make sure that your speech input is sampled at 16kHz.\nThis model has been fine-tuned thanks to the GPU credits generously given by the OVHcloud :)\nThe script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint\n\n\t\n\t\t\n\t\n\t\n\t\tUsage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gustav114514/work.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"work","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gustav114514/work","creator_name":"Ryohei Kasai","creator_url":"https://huggingface.co/Gustav114514","description":"\n\t\n\t\t\n\t\n\t\n\t\tFine-tuned XLSR-53 large model for speech recognition in Japanese\n\t\n\nFine-tuned facebook/wav2vec2-large-xlsr-53 on Japanese using the train and validation splits of Common Voice 6.1, CSS10 and JSUT.\nWhen using this model, make sure that your speech input is sampled at 16kHz.\nThis model has been fine-tuned thanks to the GPU credits generously given by the OVHcloud :)\nThe script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint\n\n\t\n\t\t\n\t\n\t\n\t\tUsage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gustav114514/work.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"HI-MIA","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISHELL/HI-MIA","creator_name":"aishelltech","creator_url":"https://huggingface.co/AISHELL","description":"AISHELL/HI-MIA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"tamil-bible-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Bhoomika1109/tamil-bible-audio","creator_name":"demonalive","creator_url":"https://huggingface.co/Bhoomika1109","description":"Bhoomika1109/tamil-bible-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"nsynth-test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RaulZBergamo/nsynth-test","creator_name":"Raul Zinezi Bergamo","creator_url":"https://huggingface.co/RaulZBergamo","description":"RaulZBergamo/nsynth-test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"chinese_accent","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kennethzhang/chinese_accent","creator_name":"Kenneth Chandra","creator_url":"https://huggingface.co/kennethzhang","description":"kennethzhang/chinese_accent dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"VoxEval","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qqjz/VoxEval","creator_name":"Wenqian Cui","creator_url":"https://huggingface.co/qqjz","description":"\n\t\n\t\t\n\t\tVoxEval\n\t\n\n\n\nGithub repository for paper: VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models\nAlso check out our survey paper at Recent Advances in Speech Language Models: A Survey!\nVoxEval is a novel speech question-answering benchmark specifically designed to assess SLMs' knowledge understanding through purely speech-based interactions.\nBelow are the three highlights of our VoxEval benchmark:\n\nEnd-to-end speech-based evaluation: Both‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qqjz/VoxEval.","first_N":5,"first_N_keywords":["cc-by-4.0","Audio","arxiv:2501.04962","arxiv:2410.03751","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"SIWIS_French_Speech_Synthesis_Database","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database","creator_name":"Anthonny Olime","creator_url":"https://huggingface.co/Aviv-anthonnyolime","description":"\n\t\n\t\t\n\t\tSIWIS French Speech Synthesis Database\n\t\n\nThis README provides a concise description of the dataset, including its structure, file naming conventions, and known labeling issues. Additionally, suggestions for potential improvements are outlined in the TODO section.  \nThe dataset is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting its use for any purpose.  \nFor more details about the database design and recording process, please refer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","French","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"originalHindiVoice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mikhil-jivus/originalHindiVoice","creator_name":"Shetty","creator_url":"https://huggingface.co/Mikhil-jivus","description":"Mikhil-jivus/originalHindiVoice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dataset1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlenJoy47/dataset1","creator_name":"Alen Joy","creator_url":"https://huggingface.co/AlenJoy47","description":"AlenJoy47/dataset1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"voice-gender-clustering","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mmn3690/voice-gender-clustering","creator_name":"Marc","creator_url":"https://huggingface.co/mmn3690","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nVoxCelebs Dataset separated by gender (https://dagshub.com/DagsHub/audio-datasets/src/main/voice_gender_detection)\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCelebrities voice recordings separated by their gender.\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\nVoxCeleb dataset (https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html)\n\\Separation (https://dagshub.com/DagsHub/audio-datasets/src/main/voice_gender_detection)\n","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"MODELSTESTE2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Abcdefghijklmnopqrstuvwxyz12/MODELSTESTE2","creator_name":"Samuel da Cruz Bastos ","creator_url":"https://huggingface.co/Abcdefghijklmnopqrstuvwxyz12","description":"Abcdefghijklmnopqrstuvwxyz12/MODELSTESTE2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"dataset2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlenJoy47/dataset2","creator_name":"Alen Joy","creator_url":"https://huggingface.co/AlenJoy47","description":"AlenJoy47/dataset2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"multiprovider-voice-mix","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/multiprovider-voice-mix","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"unlimitedbytes/multiprovider-voice-mix dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"opentts-lada","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-lada","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-lada.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-oleksa","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-oleksa","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-oleksa.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"HANAVoice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wanlau/HANAVoice","creator_name":"Wan Lau","creator_url":"https://huggingface.co/Wanlau","description":"Wanlau/HANAVoice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"AMVD_AS","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AnodHuang/AMVD_AS","creator_name":"KUNYANG HUANG","creator_url":"https://huggingface.co/AnodHuang","description":"\n\t\n\t\t\n\t\tAI_Mixed_Voice_Dataset_for_Anti_Spoofing (AMVD_AS)\n\t\n\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\n\t\n\t\t\n\t\tAuthor\n\t\n\n\nKunyang Huang (huangku@kean.edu)\nBin Hu (binhu.philip@gmail.com)\n\n\n\t\n\t\t\n\t\tBasic Information\n\t\n\n\nFile Type: flac\nSampling Rate: 16000\nKey:\n\n\n\t\n\t\t\nvalue\nlabel\n\n\n\t\t\n0\nbonafide\n\n\n1\nspoof\n\n\n\t\n\n\nArxiv Link: Hybrid Audio Detection Using Fine-Tuned Audio Spectrogram Transformers: A Dataset-Driven Evaluation of Mixed AI-Human Speech\n\nNotice: \n\nSince the models employed in our experiment were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AnodHuang/AMVD_AS.","first_N":5,"first_N_keywords":["mit","Audio","arxiv:2505.15136","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"pashto_speech_parquet_10k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (10k)\n\t\n\nThis dataset contains 20000 synthetic speech recordings in the Pashto language,\nwith 10000 male voice recordings and 10000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 10000 sentences\nTotal Recordings: 20000 audio files (10000 male + 10000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_parquet_10k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (10k)\n\t\n\nThis dataset contains 20000 synthetic speech recordings in the Pashto language,\nwith 10000 male voice recordings and 10000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 10000 sentences\nTotal Recordings: 20000 audio files (10000 male + 10000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SCHAEFFER","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dbschaeffer/SCHAEFFER","creator_name":"SCHAEFFER Database","creator_url":"https://huggingface.co/dbschaeffer","description":"\n\t\n\t\t\n\t\tSCHAEFFER\n\t\n\n\n\t\n\t\t\n\t\tBy Maurizio Berta & Daniele Ghisi\n\t\n\nThe SCHAEFFER dataset (Spectro-morphogical Corpus of Human-annotated Audio with Electroacoustic Features for Experimental Research), is a compilation of 1000 raw audio files accompanied by human annotations and morphological acoustic features. The audio files adhere to the concept of Sound Objects introduced by Pierre Schaeffer, a framework for the analysis and creation of sound that focuses on its typological and morphological‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dbschaeffer/SCHAEFFER.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SCHAEFFER","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dbschaeffer/SCHAEFFER","creator_name":"SCHAEFFER Database","creator_url":"https://huggingface.co/dbschaeffer","description":"\n\t\n\t\t\n\t\tSCHAEFFER\n\t\n\n\n\t\n\t\t\n\t\tBy Maurizio Berta & Daniele Ghisi\n\t\n\nThe SCHAEFFER dataset (Spectro-morphogical Corpus of Human-annotated Audio with Electroacoustic Features for Experimental Research), is a compilation of 1000 raw audio files accompanied by human annotations and morphological acoustic features. The audio files adhere to the concept of Sound Objects introduced by Pierre Schaeffer, a framework for the analysis and creation of sound that focuses on its typological and morphological‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dbschaeffer/SCHAEFFER.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SCHAEFFER","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dbschaeffer/SCHAEFFER","creator_name":"SCHAEFFER Database","creator_url":"https://huggingface.co/dbschaeffer","description":"\n\t\n\t\t\n\t\tSCHAEFFER\n\t\n\n\n\t\n\t\t\n\t\tBy Maurizio Berta & Daniele Ghisi\n\t\n\nThe SCHAEFFER dataset (Spectro-morphogical Corpus of Human-annotated Audio with Electroacoustic Features for Experimental Research), is a compilation of 1000 raw audio files accompanied by human annotations and morphological acoustic features. The audio files adhere to the concept of Sound Objects introduced by Pierre Schaeffer, a framework for the analysis and creation of sound that focuses on its typological and morphological‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dbschaeffer/SCHAEFFER.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"updated_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlenJoy47/updated_dataset","creator_name":"Alen Joy","creator_url":"https://huggingface.co/AlenJoy47","description":"AlenJoy47/updated_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"nigerian_common_voice_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Common Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Common Voice Dataset is a comprehensive dataset consisting of 158 hours of audio recordings and corresponding transcription (sentence). \nThis dataset includes metadata like accent, locale that can help improve the accuracy of speech recognition engines. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"0046","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zh-liu799/0046","creator_name":"Zihang Liu","creator_url":"https://huggingface.co/zh-liu799","description":"zh-liu799/0046 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Image","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"tanarav2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mike22g/tanarav2","creator_name":"Mi","creator_url":"https://huggingface.co/Mike22g","description":"Mike22g/tanarav2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"en_and_de_reference_voice_files_for_emotion_cloning","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/en_and_de_reference_voice_files_for_emotion_cloning","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"laion/en_and_de_reference_voice_files_for_emotion_cloning dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"cleaned_music_vocals","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Akxe/cleaned_music_vocals","creator_name":"Akxe","creator_url":"https://huggingface.co/Akxe","description":"Akxe/cleaned_music_vocals dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"korean_tts_ds","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigdefence/korean_tts_ds","creator_name":"bigdefence","creator_url":"https://huggingface.co/bigdefence","description":"bigdefence/korean_tts_ds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Mon3tr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Mon3tr","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Mon3tr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Video_Speech_Actor_24","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ajv101/Video_Speech_Actor_24","creator_name":"Angzehua Feng","creator_url":"https://huggingface.co/Ajv101","description":"Ajv101/Video_Speech_Actor_24 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","Audio","Video","Datasets"],"keywords_longer_than_N":true},
	{"name":"example_webdataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/example_webdataset","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"Sh1man/example_webdataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"rulibrispeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/rulibrispeech","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nwav 16kHz\n\n\t\n\t\t\n\t\tüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n\n\t\n\t\t\n\t\t–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–ø–ª–∏—Ç–∞–º\n\t\n\n\n\t\n\t\t\n\t\tüîπ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä (train)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n54,472\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n92.79 —á–∞—Å–æ–≤ (334028.33 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n6.13 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\tüîπ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (validate)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n1,400\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n2.81 —á–∞—Å–æ–≤ (10105.46 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n7.22‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rulibrispeech.","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","10K - 100K","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"rulibrispeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/rulibrispeech","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nwav 16kHz\n\n\t\n\t\t\n\t\tüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n\n\t\n\t\t\n\t\t–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–ø–ª–∏—Ç–∞–º\n\t\n\n\n\t\n\t\t\n\t\tüîπ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä (train)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n54,472\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n92.79 —á–∞—Å–æ–≤ (334028.33 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n6.13 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\tüîπ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (validate)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n1,400\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n2.81 —á–∞—Å–æ–≤ (10105.46 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n7.22‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rulibrispeech.","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","10K - 100K","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"rulibrispeech","keyword":"voice","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/rulibrispeech","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nwav 16kHz\n\n\t\n\t\t\n\t\tüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n\n\t\n\t\t\n\t\t–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–ø–ª–∏—Ç–∞–º\n\t\n\n\n\t\n\t\t\n\t\tüîπ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä (train)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n54,472\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n92.79 —á–∞—Å–æ–≤ (334028.33 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n6.13 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\tüîπ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (validate)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n1,400\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n2.81 —á–∞—Å–æ–≤ (10105.46 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n7.22‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rulibrispeech.","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","10K - 100K","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"Audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tjochen3/Audio","creator_name":"john chen","creator_url":"https://huggingface.co/tjochen3","description":"tjochen3/Audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"common-voice-english-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freddyaboulton/common-voice-english-audio","creator_name":"Freddy Boulton","creator_url":"https://huggingface.co/freddyaboulton","description":"freddyaboulton/common-voice-english-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Polachek","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/astvito/Polachek","creator_name":"vito vito","creator_url":"https://huggingface.co/astvito","description":"astvito/Polachek dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"japanese-anime-speech","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joujiboi/japanese-anime-speech","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","description":"\n\t\n\t\t\n\t\tJapanese Anime Speech Dataset\n\t\n\nÊó•Êú¨Ë™û„ÅØ„Åì„Å°„Çâ\njapanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.\nThe goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"japanese-anime-speech","keyword":"voice","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joujiboi/japanese-anime-speech","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","description":"\n\t\n\t\t\n\t\tJapanese Anime Speech Dataset\n\t\n\nÊó•Êú¨Ë™û„ÅØ„Åì„Å°„Çâ\njapanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.\nThe goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"yyds","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/yyds","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/yyds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Club57","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joaofreitas/Club57","creator_name":"Jo√£o Gabriel Freeitas","creator_url":"https://huggingface.co/joaofreitas","description":"joaofreitas/Club57 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"crey","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NandinhoVinicius/crey","creator_name":"Fernando Vinicius da Silva Bandeca","creator_url":"https://huggingface.co/NandinhoVinicius","description":"NandinhoVinicius/crey dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"hypnosis_dataset","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/hypnosis_dataset","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\n\t\n\t\t\n\t\tdataset card for \"hypnosis_dataset\"\n\t\n\n\n\t\n\t\t\n\t\thypnosis scripts based on Erickson progressions\n\t\n\nThis is a small dataset containing hypnosis scripts that were both obtained from legitimate (manual) sources, and also generated using the following closed and open models:\nlarge llm:\n\nopenai api\ncohere\npalm\nopen models:\nmistral-7b\ntrismegistus-mistral-7b\nzephyr-7b\nmistral-anima-phi-7b\nmistral-instruct\n\nThe data has been cleaned but not altered save for formatting. \nSome entries include a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jtatman/hypnosis_dataset.","first_N":5,"first_N_keywords":["text-generation","text-to-audio","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"reinomc","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/djemerson7k/reinomc","creator_name":"Santos","creator_url":"https://huggingface.co/djemerson7k","description":"djemerson7k/reinomc dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"minhavoz","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/betotdai/minhavoz","creator_name":"beto streher","creator_url":"https://huggingface.co/betotdai","description":"betotdai/minhavoz dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"escagleu-64k","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/escagleu-64k","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for escagleu-64K corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nescagleu-64k is a parallel corpus comprising 64091 sentences translated among Spanish, Catalan, Valencian Catalan, Galician, and Basque.\nThe original sentences are in Spanish and come from the Spanish Common Voice Corpus.\nWe prepared this corpus with the aim of creating a parallel speech dataset among these languages using the Common Voice platform between the frame of the project Ilenia.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/escagleu-64k.","first_N":5,"first_N_keywords":["translation","audio-to-audio","automatic-speech-recognition","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"speechcorpus","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/domebacsi/speechcorpus","creator_name":"dome","creator_url":"https://huggingface.co/domebacsi","description":"domebacsi/speechcorpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dis-cyril-male","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/do-2021/dis-cyril-male","creator_name":"Polytech DO - promotion 2021-2024","creator_url":"https://huggingface.co/do-2021","description":"This contains training data for the do-2021/activator-keyword-detector with male voices, with a sample rate of 32000HZ, in a split format.\nAudio samples in the \"yes\" subdirectory would activate the assistant, and those in \"no\" should not.\n","first_N":5,"first_N_keywords":["French","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Indic-subtitler-audio_evals","keyword":"audio","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals","creator_name":"Kurian Benoy","creator_url":"https://huggingface.co/kurianbenoy","description":"\n\t\n\t\t\n\t\tIndic_audio_evals\n\t\n\nAs part of this project. We are evaluating our performance of various ASR models as well\nin a benchmarking dataset, we have created in various languages. This benchmarking dataset\nis more alligned to real-world use-cases rather than having any academic datasets.\n\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\n\nDataset Link in HuggingFace: kurianbenoy/Indic-subtitler-audio_evals\n\nThis dataset contains audio file in .wav format and video file in .mp4. The respective groundtruth will be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","Hindi","English","Bengali"],"keywords_longer_than_N":true},
	{"name":"Indic-subtitler-audio_evals","keyword":"audio","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals","creator_name":"Kurian Benoy","creator_url":"https://huggingface.co/kurianbenoy","description":"\n\t\n\t\t\n\t\tIndic_audio_evals\n\t\n\nAs part of this project. We are evaluating our performance of various ASR models as well\nin a benchmarking dataset, we have created in various languages. This benchmarking dataset\nis more alligned to real-world use-cases rather than having any academic datasets.\n\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\n\nDataset Link in HuggingFace: kurianbenoy/Indic-subtitler-audio_evals\n\nThis dataset contains audio file in .wav format and video file in .mp4. The respective groundtruth will be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","Hindi","English","Bengali"],"keywords_longer_than_N":true},
	{"name":"20242","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/20242","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/20242 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"audio_record","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisuko/audio_record","creator_name":"Bowen Li","creator_url":"https://huggingface.co/aisuko","description":"aisuko/audio_record dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"GeneratedMusic","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nonstopio/GeneratedMusic","creator_name":"NonStop IO Technologies","creator_url":"https://huggingface.co/nonstopio","description":"nonstopio/GeneratedMusic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"henrique","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NandinhoVinicius/henrique","creator_name":"Fernando Vinicius da Silva Bandeca","creator_url":"https://huggingface.co/NandinhoVinicius","description":"NandinhoVinicius/henrique dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"henriqueju","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NandinhoVinicius/henriqueju","creator_name":"Fernando Vinicius da Silva Bandeca","creator_url":"https://huggingface.co/NandinhoVinicius","description":"NandinhoVinicius/henriqueju dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"bulgarian_tts","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Opit/bulgarian_tts","creator_name":"Opit Opit","creator_url":"https://huggingface.co/Opit","description":"Source: https://github.com/vislupus/Bulgarian-TTS-dataset/\n","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tue","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dovakauhm/tue","creator_name":"Kauhm Dova","creator_url":"https://huggingface.co/Dovakauhm","description":"Dovakauhm/tue dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"icaroGCO2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/icaro23/icaroGCO2","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/icaro23","description":"icaro23/icaroGCO2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"dscxczxc","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fsdfdsffd/dscxczxc","creator_name":"sdfsdf","creator_url":"https://huggingface.co/fsdfdsffd","description":"fsdfdsffd/dscxczxc dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"simsamu","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/diarizers-community/simsamu","creator_name":"diarizers-community","creator_url":"https://huggingface.co/diarizers-community","description":"\n\t\n\t\t\n\t\tDataset Card for the Simsamu dataset\n\t\n\nThis repository contains recordings of simulated medical dispatch dialogs in the french language, annotated for diarization and transcription. It is published under the MIT license.\nThese dialogs were recorded as part of the training of emergency medicine interns, which consisted in simulating a medical dispatch call where the interns took turns playing the caller and the regulating doctor.\nEach situation was decided randomly in advance, blind to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/diarizers-community/simsamu.","first_N":5,"first_N_keywords":["French","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"simsamu","keyword":"voice-activity-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/diarizers-community/simsamu","creator_name":"diarizers-community","creator_url":"https://huggingface.co/diarizers-community","description":"\n\t\n\t\t\n\t\tDataset Card for the Simsamu dataset\n\t\n\nThis repository contains recordings of simulated medical dispatch dialogs in the french language, annotated for diarization and transcription. It is published under the MIT license.\nThese dialogs were recorded as part of the training of emergency medicine interns, which consisted in simulating a medical dispatch call where the interns took turns playing the caller and the regulating doctor.\nEach situation was decided randomly in advance, blind to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/diarizers-community/simsamu.","first_N":5,"first_N_keywords":["French","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"FLEURS-GA-EN","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the Irish-to-English portion of the FLEURS dataset.\nFleurs is the speech version of the FLoRes machine translation benchmark.\nThe Irish portion consists of 3991 utterances, which correspond to approximately 16 hours and 45 minutes (16:45:17) of audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'audio', 'text_ga', 'text_en'],\n        num_rows: 3991\n    })\n})\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{fleurs2022arxiv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"aud_tts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudarsa/aud_tts","creator_name":"Parida","creator_url":"https://huggingface.co/sudarsa","description":"sudarsa/aud_tts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"AudioMNIST","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gilkeyio/AudioMNIST","creator_name":"Kim Gilkey","creator_url":"https://huggingface.co/gilkeyio","description":"\n\t\n\t\t\n\t\tDataset Card for \"AudioMNIST\"\n\t\n\nThe audioMNIST dataset has 50 English recordings per digit (0-9) of 60 speakers.\nThere are 60 participants in total, with 12 being women and 48 being men, all featuring a diverse range of accents and country of origin. Their ages vary from 22 to 61 years old. This is a great dataset to explore a simple audio classification problem: either the digit or the gender.\n\n\t\n\t\t\n\t\n\t\n\t\tBias, Risks, and Limitations\n\t\n\n\nThe genders represented in the dataset are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gilkeyio/AudioMNIST.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AudioMNIST","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gilkeyio/AudioMNIST","creator_name":"Kim Gilkey","creator_url":"https://huggingface.co/gilkeyio","description":"\n\t\n\t\t\n\t\tDataset Card for \"AudioMNIST\"\n\t\n\nThe audioMNIST dataset has 50 English recordings per digit (0-9) of 60 speakers.\nThere are 60 participants in total, with 12 being women and 48 being men, all featuring a diverse range of accents and country of origin. Their ages vary from 22 to 61 years old. This is a great dataset to explore a simple audio classification problem: either the digit or the gender.\n\n\t\n\t\t\n\t\n\t\n\t\tBias, Risks, and Limitations\n\t\n\n\nThe genders represented in the dataset are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gilkeyio/AudioMNIST.","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"vad-animals","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nccratliri/vad-animals","creator_name":"TTF Datascience, NCCR@LiRI, UZH","creator_url":"https://huggingface.co/nccratliri","description":"\n\t\n\t\t\n\t\tPositive Transfer Of The Whisper Speech Transformer To Human And Animal Voice Activity Detection\n\t\n\nWe proposed WhisperSeg, utilizing the Whisper Transformer pre-trained for Automatic Speech Recognition (ASR) for both human and animal Voice Activity Detection (VAD). For more details, please refer to our paper\n\nPositive Transfer of the Whisper Speech Transformer to Human and Animal Voice Activity Detection\nNianlong Gu, Kanghwi Lee, Maris Basha, Sumit Kumar Ram, Guanghao You, Richard H.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nccratliri/vad-animals.","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"arabic_xvector_embeddings","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings","creator_name":"Hawau Olamide Toyin","creator_url":"https://huggingface.co/herwoww","description":"\n\t\n\t\t\n\t\tArabic Speaker Embeddings extracted from ASC and ClArTTS\n\t\n\nThere is one speaker embedding for each utterance in the validation set of both datasets. The speaker embeddings are 512-element X-vectors.\nArabic Speech Corpus has 100 files for a single male speaker and ClArTTS has 205 files for a single male speaker.\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\nUsage:\nfrom datasets import load_dataset\n\nembeddings_dataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings.","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RaviNaik/Fleurs-Kn","creator_name":"Ravi Naik","creator_url":"https://huggingface.co/RaviNaik","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RaviNaik/Fleurs-Kn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn","creator_name":"Kannada LLM Labs","creator_url":"https://huggingface.co/Kannada-LLM-Labs","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn","creator_name":"Indic-LLM-Labs","creator_url":"https://huggingface.co/Indic-LLM-Labs","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"geneSYS","keyword":"audio","license":"GNU Lesser General Public License v2.1","license_url":"https://choosealicense.com/licenses/lgpl-2.1/","language":"en","dataset_url":"https://huggingface.co/datasets/Ecranium/geneSYS","creator_name":"Miller","creator_url":"https://huggingface.co/Ecranium","description":"Ecranium/geneSYS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["lgpl-2.1","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"seamless-align-expressive","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align-Expressive (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined expressive Speech-to-Speech(S2S) released by Meta AI.  The S2S contains data for 5 language pairs. The S2S dataset is ~228GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soon\n\n\nClone the git repo\n\ngit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive.","first_N":5,"first_N_keywords":["translation","audio-to-audio","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"audioset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jovillios/audioset","creator_name":"Jules Decaestecker","creator_url":"https://huggingface.co/Jovillios","description":"Jovillios/audioset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"DATN_20191956_Train","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/manhvh2601/DATN_20191956_Train","creator_name":"vu hoang manh","creator_url":"https://huggingface.co/manhvh2601","description":"manhvh2601/DATN_20191956_Train dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"comondv","keyword":"audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Arbi-Houssem/comondv","creator_name":"houssem arbi","creator_url":"https://huggingface.co/Arbi-Houssem","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Arbi-Houssem/comondv.","first_N":5,"first_N_keywords":["artistic-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"static-pink-trombone-1s","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mcamara/static-pink-trombone-1s","creator_name":"Mateo C√°mara","creator_url":"https://huggingface.co/mcamara","description":"mcamara/static-pink-trombone-1s dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Jarvis_samples","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/crazyup37/Jarvis_samples","creator_name":"suyash krishan garg","creator_url":"https://huggingface.co/crazyup37","description":"crazyup37/Jarvis_samples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"wikitext-103","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/segyges/wikitext-103","creator_name":"SE Gyges","creator_url":"https://huggingface.co/segyges","description":"segyges/wikitext-103 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"BiaLanutti","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Medradome/BiaLanutti","creator_name":"santos","creator_url":"https://huggingface.co/Medradome","description":"Medradome/BiaLanutti dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"SpokenWords-GA-EN-MTed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis is the Irish portion of the Spoken Words dataset (available at MLCommons/ml_spoken_words),\nwith merged splits ‚Äútrain‚Äù, ‚Äúvalidation‚Äù, and ‚Äútest‚Äù, augmented with machine translation.\nThe Irish sentences are automatically translated into English using Google Translation API.\nThe dataset includes approximately 3 hours and 2 minutes of audio (03:02:02), spoken by multiple narrators.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['keyword'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"efficient-speech-codec","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tracygu/efficient-speech-codec","creator_name":"Yuzhe Gu","creator_url":"https://huggingface.co/Tracygu","description":"\n\t\n\t\t\n\t\tEfficient Speech Codec\n\t\n\n\nPaper\nCode\nDemo Page\n\n","first_N":5,"first_N_keywords":["mit","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"memes_models","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/disouz4/memes_models","creator_name":"Diego di Souza","creator_url":"https://huggingface.co/disouz4","description":"disouz4/memes_models dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Ryota","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Luizagrod23/Ryota","creator_name":"LUIZA GABRON RODRIGUES","creator_url":"https://huggingface.co/Luizagrod23","description":"Luizagrod23/Ryota dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"music_caps_4sec_wave_type_classical","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mb23/music_caps_4sec_wave_type_classical","creator_name":"make brain project 2023","creator_url":"https://huggingface.co/mb23","description":"\n\t\n\t\t\n\t\tDataset Card for \"music_caps_4sec_wave_type_classical\"\n\t\n\nThis is MusicCaps Dataset classified as \"classical\" using distilhubert fintuned for GTZAN datasets.\nMore Information needed\n","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"myDataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KHM-hf/myDataset","creator_name":"Hamad","creator_url":"https://huggingface.co/KHM-hf","description":"KHM-hf/myDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"leagan","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sanspop/leagan","creator_name":"MOttcost","creator_url":"https://huggingface.co/Sanspop","description":"Sanspop/leagan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"imasc_slr","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/imasc_slr","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"Clone of : thennal/IMaSC\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Rhulk_pt-br","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/satierf/Rhulk_pt-br","creator_name":"thiago freitas pimenta","creator_url":"https://huggingface.co/satierf","description":"satierf/Rhulk_pt-br dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"HeySQuAD_machine","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yijingwu/HeySQuAD_machine","creator_name":"Yijing","creator_url":"https://huggingface.co/yijingwu","description":"citation:\n@misc{wu2023heysquad,\n      title={HeySQuAD: A Spoken Question Answering Dataset}, \n      author={Yijing Wu and SaiKrishna Rallabandi and Ravisutha Srinivasamurthy and Parag Pravin Dakle and Alolika Gon and Preethi Raghavan},\n      year={2023},\n      eprint={2304.13689},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"HeySQuAD_human","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yijingwu/HeySQuAD_human","creator_name":"Yijing","creator_url":"https://huggingface.co/yijingwu","description":"citation: @misc{wu2023heysquad, title={HeySQuAD: A Spoken Question Answering Dataset}, author={Yijing Wu and SaiKrishna Rallabandi and Ravisutha Srinivasamurthy and Parag Pravin Dakle and Alolika Gon and Preethi Raghavan}, year={2023}, eprint={2304.13689}, archivePrefix={arXiv}, primaryClass={cs.CL} }\n","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"cassidy","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pjuk/cassidy","creator_name":"pedro juk","creator_url":"https://huggingface.co/pjuk","description":"pjuk/cassidy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"assamese_speech_corpus","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/madhabpaul/assamese_speech_corpus","creator_name":"Madhab Paul","creator_url":"https://huggingface.co/madhabpaul","description":"madhabpaul/assamese_speech_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Assamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"assamese_speech_corpus","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/madhabpaul/assamese_speech_corpus","creator_name":"Madhab Paul","creator_url":"https://huggingface.co/madhabpaul","description":"madhabpaul/assamese_speech_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Assamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Skilo","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/djemerson7k/Skilo","creator_name":"Santos","creator_url":"https://huggingface.co/djemerson7k","description":"djemerson7k/Skilo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Skilo2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/djemerson7k/Skilo2","creator_name":"Santos","creator_url":"https://huggingface.co/djemerson7k","description":"djemerson7k/Skilo2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"common-voice13","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mohammadnpak/common-voice13","creator_name":"Mohammad Nozari Pak","creator_url":"https://huggingface.co/mohammadnpak","description":"mohammadnpak/common-voice13 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Molly","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Voice-man-76/Molly","creator_name":"John Paul Bristoe","creator_url":"https://huggingface.co/Voice-man-76","description":".gitattributes\n2.31 kB\ninitial commit\n10 minutes ago\nOh gee, no party.mp3\n31.7 kB\nLFS\nUpload Oh gee, no party.mp3\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Kanami_Dataset","keyword":"audio","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holmuium97/Kanami_Dataset","creator_name":"Holmuium97","creator_url":"https://huggingface.co/Holmuium97","description":"È¶ôÂ•àÁæéËÆ≠ÁªÉËØ≠Èü≥Êï∞ÊçÆÈõÜÔºà‰ªÖÂÖ¨ÊµãÂâçÁöÑËØ≠Èü≥Ôºâ\nP.S\n  1„ÄÅÊï∞ÊçÆÈõÜËØ≠Èü≥‰ªÖÈÄöËøáÊ∏∏ÊàèÂÜÖËé∑ÂèñÔºå‰∏ÄÂàáÁâàÊùÉÂΩíÊ∑±Âú≥Â∏ÇÂàõÊ¢¶Â§©Âú∞ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏ÊâÄÊúâ\n  2„ÄÅÈü≥È¢ë‰ªÖËøõË°åÁÆÄÂçïÁöÑËá™Âä®ÂàáÁâáÔºåÂèØËÉΩÂ≠òÂú®Êñ≠Âè•‰∏çÂêàÁêÜÁöÑÊÉÖÂÜµÔºåÂª∫ËÆÆËØïÂê¨ÂÅö‰∏ãÁ≠õÈÄâ\n  3„ÄÅÁ¶ÅÊ≠¢‰ΩøÁî®ËØ•Êï∞ÊçÆÈõÜËøõË°å‰∏ÄÂàá‰ª•ËøùÊ≥ï‰∏∫ÁõÆÁöÑÁöÑÊ¥ªÂä®\n","first_N":5,"first_N_keywords":["Chinese","agpl-3.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"vaiNeymar","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexpanick/vaiNeymar","creator_name":"Alexsander","creator_url":"https://huggingface.co/alexpanick","description":"alexpanick/vaiNeymar dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"doreco_southengland","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bob80333/doreco_southengland","creator_name":"Eric Engelhart","creator_url":"https://huggingface.co/bob80333","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\nThis dataset is the aligned phoneme subset of the DoReCo South England dataset, split into utterances + phonetic transcriptions based on pause lengths / total length,\nwith the goal of creating utterances < 30s for fine-tuning speech recognition models on phoneme recognition, not one phoneme at a time, but rather for entire utterances.\nIt is already randomly pre-split into train/dev/test sets, with 80% in train, 10% in dev, and the final 10% in test.\n\nLink to original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bob80333/doreco_southengland.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Penny","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Voice-man-76/Penny","creator_name":"John Paul Bristoe","creator_url":"https://huggingface.co/Voice-man-76","description":"Voice-man-76/Penny dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"54","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wewewewe1/54","creator_name":"Irving","creator_url":"https://huggingface.co/wewewewe1","description":"wewewewe1/54 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Fievel","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Voice-man-76/Fievel","creator_name":"John Paul Bristoe","creator_url":"https://huggingface.co/Voice-man-76","description":"Voice-man-76/Fievel dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Tuguim","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/InkFozy/Tuguim","creator_name":"Bruno Souza Osmundo","creator_url":"https://huggingface.co/InkFozy","description":"InkFozy/Tuguim dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"qu","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/qu","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/qu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Nepali","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SunilC/Nepali","creator_name":"Sunil Chaudhary","creator_url":"https://huggingface.co/SunilC","description":"SunilC/Nepali dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Nepali","mit","Audio","üá∫üá∏ Region: US","code"],"keywords_longer_than_N":false},
	{"name":"TestingDataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BadBoy17G/TestingDataset","creator_name":"G","creator_url":"https://huggingface.co/BadBoy17G","description":"BadBoy17G/TestingDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"huhhg","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/heiderkkkk/huhhg","creator_name":"heider kkkkkk","creator_url":"https://huggingface.co/heiderkkkk","description":"heiderkkkk/huhhg dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"bolinha","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/coelhobrbr/bolinha","creator_name":"antonio coelho","creator_url":"https://huggingface.co/coelhobrbr","description":"coelhobrbr/bolinha dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Living-Audio-Irish","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Living-Audio-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nLiving Audio Irish speech corpus. This version is based on the Irish dataset on Kaggle.\nThe original dataset with audio in more languages is available on GitHub as part of the Idlak project.\nThe details of the Irish portion of the Living Audio dataset are as follows:\n\n\t\n\t\t\nSpeaker\nLanguage\nAccent\nGender\nTotal duration(mm:ss)\nSample rate (Hz)\n\n\n\t\t\nCLL\nIrish (ga)\nNon-native (ie)\nMan\n61:56\n48,000\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['sentence'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Living-Audio-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Irish","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"AudioLabelingTestDataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/XTer123/AudioLabelingTestDataset","creator_name":"XTer","creator_url":"https://huggingface.co/XTer123","description":"XTer123/AudioLabelingTestDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Felipaera","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Medradome/Felipaera","creator_name":"santos","creator_url":"https://huggingface.co/Medradome","description":"Medradome/Felipaera dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"tele_con_ciencia","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/tele_con_ciencia","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for tele_con_ciencia\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAccording to the Facebook page of Tele con Ciencia:\n\"Nuestra misi√≥n es la comunicaci√≥n p√∫blica de la ciencia y la tecnolog√≠a mexicana. El objetivo, \nla participaci√≥n activa de todos los mexicanos en las √°reas del descubrimiento cient√≠fico y el \ndesarrollo tecnol√≥gico.\"\n\"Our mission is to spread the achievements of the Mexican Science and Technology. The main goal\nis to promote the active participation of mexican people in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/tele_con_ciencia.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"librivox_spanish","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/librivox_spanish","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for librivox_spanish\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibrivox is a non-commercial, non-profit and ad-free project that is dedicated to make all books in the public domain available, for free, in audio format on the internet. According to this, we downloaded 300 titles in Spanish to create the LIBRIVOX SPANISH CORPUS.\nThe LIBRIVOX SPANISH CORPUS has a duration of 73 hours and it is constituted by audio files between 3 and 10 seconds long, manually segmented. Transcription are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/librivox_spanish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"voxforge_spanish","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/voxforge_spanish","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for voxforge_spanish\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVoxForge was set up to collect transcribed speech for use with Free and Open Source Speech Recognition Engines (on Linux, Windows and Mac). They promise they will make available all submitted audio files under the GPL license, and then 'compile' them into acoustic models for use with Open Source speech recognition engines such as CMU Sphinx, ISIP, Julius and HTK. According to this, we downloaded the Spanish recordings of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/voxforge_spanish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","gpl-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ikk_bible_JHNandMRK_chapter1_to_10","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ogbi/ikk_bible_JHNandMRK_chapter1_to_10","creator_name":"Daniel Ogbuigwe","creator_url":"https://huggingface.co/ogbi","description":"\n\t\n\t\t\n\t\tikk_bible_JHNandMRK_chapter1_to_10 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThis dataset is not fully setup, you will encounter errors while trying to load the data.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ikaaudio dataset comprises segments from the first 10 chapters of the Ika translation of the New Testament. It contains verse-level audio segments, manually verified to include only high-quality segments were the transcription sufficiently matches the audio. The MMS_FA MMS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ogbi/ikk_bible_JHNandMRK_chapter1_to_10.","first_N":5,"first_N_keywords":["Ika","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"ikk_bible_JHNandMRK_chapter1_to_10","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ogbi/ikk_bible_JHNandMRK_chapter1_to_10","creator_name":"Daniel Ogbuigwe","creator_url":"https://huggingface.co/ogbi","description":"\n\t\n\t\t\n\t\tikk_bible_JHNandMRK_chapter1_to_10 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThis dataset is not fully setup, you will encounter errors while trying to load the data.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ikaaudio dataset comprises segments from the first 10 chapters of the Ika translation of the New Testament. It contains verse-level audio segments, manually verified to include only high-quality segments were the transcription sufficiently matches the audio. The MMS_FA MMS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ogbi/ikk_bible_JHNandMRK_chapter1_to_10.","first_N":5,"first_N_keywords":["Ika","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"chm150_asr","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/chm150_asr","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"\n\t\n\t\t\n\t\tDataset Card for chm150_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CHM150 is a corpus of microphone speech of mexican Spanish taken from 75 male speakers and 75 female speakers in a noise environment of a \"quiet office\" with a total duration of 1.63 hours.\nSpeakers were encouraged to respond between some pre selected open questions or they could also describe a particular painting showed to them in a computer monitor. By so, the speech is completely spontaneous and one can see it in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlosdanielhernandezmena/chm150_asr.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DORI-ONC","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DORI-SRKW/DORI-ONC","creator_name":"Dataset for Orca Resident Interpretation","creator_url":"https://huggingface.co/DORI-SRKW","description":"Warning: This is a pre-release version. Labels in this dataset are subject to change without notice.\nThis is a marine mammal vocalisation dataset primarily focused on the southern resident killer whale habitat.\nThe portion of this data comes from Ocean Networks Canada, and is shared under a CC-BY License.\nAlternatively, the data can be downloaded from Ocean Networks Canada Directly:\nhttps://data.oceannetworks.ca/SearchHydrophoneData\nMarine mammal detections are conducted by an amature labeller‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DORI-SRKW/DORI-ONC.","first_N":5,"first_N_keywords":["cc-by-4.0","10K<n<100K","Audio","üá∫üá∏ Region: US","biology"],"keywords_longer_than_N":false},
	{"name":"BIOMON","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cmammides/BIOMON","creator_name":"Christos Mammides","creator_url":"https://huggingface.co/cmammides","description":"\"BIOMON: Using passive acoustic monitoring methods to survey bird communities in biodiverse agricultural farmlands in the EU\"\nhttps://cordis.europa.eu/project/id/101090273\n1/6/2022 - 31/5/2024\nBIOMON is funded by the European Union's Horizon Europe programme, ERA Talents, under grant agreement 101090273\nA complete description of the dataset can be found in the following article: \nMammides, C., Ieronymidou, C. & Papadopoulos, H. (2025). An ecoacoustic dataset collected on the island of Cyprus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmammides/BIOMON.","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"2ClassProblem","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anderloh/2ClassProblem","creator_name":"Anders L√∏hr","creator_url":"https://huggingface.co/anderloh","description":"anderloh/2ClassProblem dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"spotify_music","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Prarabdha/spotify_music","creator_name":"Prarabdha Srivastava","creator_url":"https://huggingface.co/Prarabdha","description":"Prarabdha/spotify_music dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"libritts_r","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/libritts_r","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\n\t\n\t\t\n\t\tDataset Card for LibriTTS-R\n\t\n\n\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus \n(http://www.openslr.org/60/) which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate, published in 2019.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the LibriTTS-R dataset, adapted for the datasets library.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThere are 7 splits (dots replace dashes from the original dataset, to comply with hf naming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/libritts_r.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Parkinsons_Disease_Speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hahad14/Parkinsons_Disease_Speech","creator_name":"Hassan Duffaydar","creator_url":"https://huggingface.co/Hahad14","description":"Hahad14/Parkinsons_Disease_Speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Accueil_UBS","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/Accueil_UBS","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nCe jeu de donn√©es rassemble 339 extraits de conversation t√©l√©phoniques extraites du jeu de donn√©es Accueil_UBS.\nL'objectif est de faciliter l'√©valuation des syst√®mes de reconnaissance automatique de la parole dans des situations r√©elles, sp√©cifiquement dans les centres d'appel et en fran√ßais.\n\n\t\n\t\t\n\t\tAccueil UBS\n\t\n\nLe corpus Accueil_UBS est un corpus pilote de dialogue oral homme-homme finalis√© correspondant √† une t√¢che d‚Äôaccueil t√©l√©phonique par le standard d‚Äôune‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/Accueil_UBS.","first_N":5,"first_N_keywords":["French","cc-by-sa-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"bark-detection","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rmarcosg/bark-detection","creator_name":"Rodrigo Marcos Garc√≠a","creator_url":"https://huggingface.co/rmarcosg","description":"\n\t\n\t\t\n\t\tBark detection dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset comprises both positive and negative samples of audio of 1 second in WAV format, recorded at 44.1kHz.\nNegative samples include music, voice, claps, whistles and vacuum cleaner noise, among other sound you may record inside a house.\nCaveats:\n\nThis is an imbalanced dataset: ~10k negatives vs ~500 positives.\nPositive samples may include human generated barks.\nSome (few) positive samples are false positives.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rmarcosg/bark-detection.","first_N":5,"first_N_keywords":["audio-classification","apache-2.0","10K<n<100K","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"bark-detection","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rmarcosg/bark-detection","creator_name":"Rodrigo Marcos Garc√≠a","creator_url":"https://huggingface.co/rmarcosg","description":"\n\t\n\t\t\n\t\tBark detection dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset comprises both positive and negative samples of audio of 1 second in WAV format, recorded at 44.1kHz.\nNegative samples include music, voice, claps, whistles and vacuum cleaner noise, among other sound you may record inside a house.\nCaveats:\n\nThis is an imbalanced dataset: ~10k negatives vs ~500 positives.\nPositive samples may include human generated barks.\nSome (few) positive samples are false positives.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rmarcosg/bark-detection.","first_N":5,"first_N_keywords":["audio-classification","apache-2.0","10K<n<100K","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"otis.dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brandon12333/otis.dataset","creator_name":"brandon werkheiser","creator_url":"https://huggingface.co/brandon12333","description":"brandon12333/otis.dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Mario","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NicoBelicoBRUS/Mario","creator_name":"NICholas","creator_url":"https://huggingface.co/NicoBelicoBRUS","description":"NicoBelicoBRUS/Mario dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"yjb","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/yjb","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/yjb dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Video","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Semove","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/icaro23/Semove","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/icaro23","description":"icaro23/Semove dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"S_VOICES","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vikcashew/S_VOICES","creator_name":"vikcashew","creator_url":"https://huggingface.co/vikcashew","description":"vikcashew/S_VOICES dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Wraith","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ksanjeev284/Wraith","creator_name":"Sanjeev Kumar","creator_url":"https://huggingface.co/ksanjeev284","description":"ksanjeev284/Wraith dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Italian_Parkinsons_Voice_and_Speech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/birgermoell/Italian_Parkinsons_Voice_and_Speech","creator_name":"Birger Moell","creator_url":"https://huggingface.co/birgermoell","description":"The original dataset is located here\nThe citation for this dataset:\n@data{aw6b-tg17-19,\n  doi = {10.21227/aw6b-tg17},\n  url = {https://dx.doi.org/10.21227/aw6b-tg17},\n  author = {Dimauro, Giovanni and Girardi, Francesco},\n  publisher = {IEEE Dataport},\n  title = {Italian Parkinson's Voice and Speech},\n  year = {2019}\n}\n\nThe author of the dataset requests that academic users of the dataset cite the following articles, the latter of which describes how the dataset was created:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/birgermoell/Italian_Parkinsons_Voice_and_Speech.","first_N":5,"first_N_keywords":["Italian","cc-by-4.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"NikoBellic","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ksanjeev284/NikoBellic","creator_name":"Sanjeev Kumar","creator_url":"https://huggingface.co/ksanjeev284","description":"ksanjeev284/NikoBellic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"octane","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ksanjeev284/octane","creator_name":"Sanjeev Kumar","creator_url":"https://huggingface.co/ksanjeev284","description":"ksanjeev284/octane dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"dzqge","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yangjinlong/dzqge","creator_name":"sdafadsf","creator_url":"https://huggingface.co/yangjinlong","description":"yangjinlong/dzqge dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Babar_Azam","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/espidermon/Babar_Azam","creator_name":"Subhan","creator_url":"https://huggingface.co/espidermon","description":"espidermon/Babar_Azam dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"shotokan","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fillipean/shotokan","creator_name":"Fillipe Alfredo Neves","creator_url":"https://huggingface.co/fillipean","description":"fillipean/shotokan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"shilohdynasty","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ksanjeev284/shilohdynasty","creator_name":"Sanjeev Kumar","creator_url":"https://huggingface.co/ksanjeev284","description":"ksanjeev284/shilohdynasty dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Leandrinha","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/836M4X/Leandrinha","creator_name":"Davi Costa Rabelo","creator_url":"https://huggingface.co/836M4X","description":"836M4X/Leandrinha dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mydataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/imseldrith/mydataset","creator_name":"Ashiq Hussain Mir","creator_url":"https://huggingface.co/imseldrith","description":"imseldrith/mydataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"tasks","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/huggingfacejs/tasks","creator_name":"Huggingface.js","creator_url":"https://huggingface.co/huggingfacejs","description":"This dataset is for storing assets for https://huggingface.co/tasks and https://github.com/huggingface/huggingface.js/tree/main/packages/tasks\n","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"SourceDetection_mb23-music_caps_4sec_wave_type","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/SourceDetection_mb23-music_caps_4sec_wave_type","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/SourceDetection_mb23-music_caps_4sec_wave_type dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Icaro","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/icaro23/Icaro","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/icaro23","description":"icaro23/Icaro dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"icarofrw","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/icaro23/icarofrw","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/icaro23","description":"icaro23/icarofrw dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"icarokfk","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/icaro23/icarokfk","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/icaro23","description":"icaro23/icarokfk dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"papini","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Papini/papini","creator_name":"Alex Papini","creator_url":"https://huggingface.co/Papini","description":"Papini/papini dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"MSC","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smcproject/MSC","creator_name":"Swathanthra Malayalam Computing","creator_url":"https://huggingface.co/smcproject","description":"\n\t\n\t\t\n\t\tDataset Card for [msc]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n1541 speech samples\n75 speech contributors\n1:38:16 hours of speech\n482 unique sentences\n1400 unique words\n553 unique syllables\n48 unique phonemes\n\nFor more detailed analysis see the python notebook provided here\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nAutomatic Speech Recognition system development, gender and age identification of speakers\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nMalayalam\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\nfile_name‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smcproject/MSC.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"amharic-language-voices","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Am4nu3l/amharic-language-voices","creator_name":"Amanuel Alemayehu","creator_url":"https://huggingface.co/Am4nu3l","description":"Am4nu3l/amharic-language-voices dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"ICASSP2024-Acoustic_Scattering_AI-Noninvasive_Object_Classifications","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dangkhoadl/ICASSP2024-Acoustic_Scattering_AI-Noninvasive_Object_Classifications","creator_name":"Dang Le Dang Khoa","creator_url":"https://huggingface.co/dangkhoadl","description":"dangkhoadl/ICASSP2024-Acoustic_Scattering_AI-Noninvasive_Object_Classifications dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"falando","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Angela56/falando","creator_name":"angela hank","creator_url":"https://huggingface.co/Angela56","description":"Angela56/falando dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Gojo","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Saturo1234567/Gojo","creator_name":"Geto","creator_url":"https://huggingface.co/Saturo1234567","description":"Saturo1234567/Gojo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"gojo2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Saturo1234567/gojo2","creator_name":"Geto","creator_url":"https://huggingface.co/Saturo1234567","description":"Saturo1234567/gojo2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"uaspeechall","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Vinotha/uaspeechall","creator_name":"R","creator_url":"https://huggingface.co/Vinotha","description":"Vinotha/uaspeechall dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ASPED","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/urbanaudiosensing/ASPED","creator_name":"Urban Audio Sensing","creator_url":"https://huggingface.co/urbanaudiosensing","description":"\n\t\n\t\t\n\t\n\t\n\t\tASPED: An Audio Dataset for Detecting Pedestrians\n\t\n\nThis repo contains the data for the ASPED dataset, presented at ICASSP 2024.\n\nPaper Link, Project Homepage\n\nPavan Seshadri, Chaeyeon Han, Bon-Woo Koo, Noah Posner, Suhbrajit Guhathakurta, Alexander Lerch\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nThis dataset contains audio and video recordings of pedestrian activity collected at various locations in and around Georgia Tech. \nLabels of pedestrian counts per each second of audio/video are provided as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/urbanaudiosensing/ASPED.","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","n>1T","arxiv:2309.06531","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"red8369","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rogerio8369/red8369","creator_name":"santos","creator_url":"https://huggingface.co/rogerio8369","description":"rogerio8369/red8369 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ai-hosanna","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuanmo/ai-hosanna","creator_name":"MatthewHan","creator_url":"https://huggingface.co/yuanmo","description":"yuanmo/ai-hosanna dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Patrick_Star","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/communistrigger/Patrick_Star","creator_name":"communist_trigger","creator_url":"https://huggingface.co/communistrigger","description":"communistrigger/Patrick_Star dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_1_ca_up_5","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xaviviro/common_voice_16_1_ca_up_5","creator_name":"Xavi","creator_url":"https://huggingface.co/xaviviro","description":"\n\t\n\t\t\n\t\tCommon Voice Corpus 16.1 Catal√† (up_votes>5)\n\t\n\nDataset extret de mozilla-foundation/common_voice_16_1 nom√©s els splits train i test del Catal√† i amb up_votes > 5\n","first_N":5,"first_N_keywords":["Catalan","cc0-1.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Voice","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XxHimaruxX/Voice","creator_name":"Flavio M freitas","creator_url":"https://huggingface.co/XxHimaruxX","description":"XxHimaruxX/Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["afl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"clip13","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Clip11/clip13","creator_name":"Clipnight11","creator_url":"https://huggingface.co/Clip11","description":"Clip11/clip13 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ami","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/diarizers-community/ami","creator_name":"diarizers-community","creator_url":"https://huggingface.co/diarizers-community","description":"\n\t\n\t\t\n\t\tDataset Card for the AMI dataset for speaker diarization\n\t\n\nThe AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/diarizers-community/ami.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ami","keyword":"voice-activity-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/diarizers-community/ami","creator_name":"diarizers-community","creator_url":"https://huggingface.co/diarizers-community","description":"\n\t\n\t\t\n\t\tDataset Card for the AMI dataset for speaker diarization\n\t\n\nThe AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/diarizers-community/ami.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"vais1000","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vais1000","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VAIS-1000\n\t\n\nofficial announcement: https://vais.vn/vi/tai-ve/hts_for_vietnamese (dead)\nmirror: https://github.com/undertheseanlp/text_to_speech/tree/run/data/vais1000/raw\nsmall only 1h40min audio - 1 speaker (female northern accent) - 1k samples\npre-process: none\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q \"datasets[audio]\"\nfrom datasets import load_dataset\nfrom torch.utils.data import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vais1000.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"fake_voices","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Fake Voices\n\t\n\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Portuguese","mit","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"fake_voices","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Fake Voices\n\t\n\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Portuguese","mit","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"archive_Yandex-Intensive_Speech_Technologies_Spring_2024","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CCRss/archive_Yandex-Intensive_Speech_Technologies_Spring_2024","creator_name":"CCR","creator_url":"https://huggingface.co/CCRss","description":"CCRss/archive_Yandex-Intensive_Speech_Technologies_Spring_2024 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"LSVSC","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/LSVSC","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of LSVSC dataset (novel large-scale Vietnamese speech corpus)\n\t\n\nofficial announcement: https://www.mdpi.com/2079-9292/13/5/977\nofficial download: https://drive.google.com/drive/folders/1tiPKaIOC7bt6isv5qFqf61O_2jFK8ZOI\n100h, 57k samples\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/clean-lsvsc.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/LSVSC.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/parsee-mizuhashi/2","creator_name":"Parsee Mizuhashi","creator_url":"https://huggingface.co/parsee-mizuhashi","description":"parsee-mizuhashi/2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"mabama-v5","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ovieyra21/mabama-v5","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","description":"ovieyra21/mabama-v5 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Spanish","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Speech-Irish","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the Tatoeba dataset, consisting of 1,983 text segments.\nThe dataset consists of two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 2 hours and 39 minutes (02:39:31) spread across 3,966 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio', 'text_ga'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"edacc","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ml-for-speech/edacc","creator_name":"ML for Speech","creator_url":"https://huggingface.co/ml-for-speech","description":"Reformatted version of https://huggingface.co/datasets/edinburghcstr/edacc for audio classification\nMake sure to remove the \"Don't know\" label:\ndataset = dataset.filter(lambda example: example[\"label\"] != 15)\n\n","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ASCEND_CLEAN","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/georgechang8/ASCEND_CLEAN","creator_name":"Chih-Chiang Chang","creator_url":"https://huggingface.co/georgechang8","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset is derived from CAiRE/ASCEND. More information is available at https://huggingface.co/datasets/CAiRE/ASCEND.\n\nRemoved ÂóØ ÂëÉ um uh\nResolved [UNK]'s using whisper-medium\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\nDefault utterances with cleaned transcripts\n\nfrom datasets import load_dataset\ndata = load_dataset(\"georgechang8/ASCEND_CLEAN\")  # add split=\"train\" for train set, etc.\n\n\nConcatenated 30s utterances with cleaned transcripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/georgechang8/ASCEND_CLEAN.","first_N":5,"first_N_keywords":["English","Chinese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"arena","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/borderlajn/arena","creator_name":"Maksymilian Rubak","creator_url":"https://huggingface.co/borderlajn","description":"borderlajn/arena dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Polish","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Wikimedia-Speech-Irish","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the Wikimedia dataset, consisting of 7,545 text segments.\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 34 hours and 23 minutes (34:23:12) spread across 15,090 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio', 'text_ga'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"audio-alpaca","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/declare-lab/audio-alpaca","creator_name":"Deep Cognition and Language Research (DeCLaRe) Lab","creator_url":"https://huggingface.co/declare-lab","description":"\n\t\n\t\t\n\t\tAudio-alpaca: A preference dataset for aligning text-to-audio models\n\t\n\nAudio-alpaca is a pairwise preference dataset containing about 15k (prompt,chosen, rejected) triplets where given a textual prompt, chosen is the preferred generated audio and rejected is the undesirable audio.\n\n\t\n\t\t\n\t\tField details\n\t\n\nprompt: Given textual prompt\nchosen: The preferred audio sample\nrejected: The rejected audio sample\n","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"vtdataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rashmi21/vtdataset","creator_name":"Shinde","creator_url":"https://huggingface.co/Rashmi21","description":"Rashmi21/vtdataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_1_zh_TW_pseudo_labelled","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JiHungLin/common_voice_16_1_zh_TW_pseudo_labelled","creator_name":"JiHungLin","creator_url":"https://huggingface.co/JiHungLin","description":"JiHungLin/common_voice_16_1_zh_TW_pseudo_labelled dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"perezGaldos","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vpuente/perezGaldos","creator_name":"Valentin Puente Varona","creator_url":"https://huggingface.co/vpuente","description":"\n\t\n\t\t\n\t\tDataset Card for Spanish Single Speaker Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\n\t\tContext\n\t\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a single volunteer and their aligned text sourced from LibriVox.\n\n\t\n\t\t\n\t\tContent\n\t\n\nEach line in transcript.txt is delimited by | into four fields, i.e., audio file location, original script, normalized script, and audio duration.\nVisit here to check out our‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vpuente/perezGaldos.","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"flemish-mozilla-common-voice","keyword":"audio","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fibleep/flemish-mozilla-common-voice","creator_name":"Filip Nowak","creator_url":"https://huggingface.co/fibleep","description":"A port of dutch-vl-tts [https://github.com/r-dh/dutch-vl-tts] to hugging face.\nUses 15 000 samples of a male Dutch Flemish voice. Extracted from Mozilla Common Voice project [https://github.com/common-voice/common-voice/tree/master/server/data/nl].\n","first_N":5,"first_N_keywords":["Dutch","mpl-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kaleza2000/quran","creator_name":"soliman","creator_url":"https://huggingface.co/kaleza2000","description":"kaleza2000/quran dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AtharvA7k/ClArTTS","creator_name":"Atharva Kulkarni","creator_url":"https://huggingface.co/AtharvA7k","description":"\n\t\n\t\t\n\t\tDataset Card for ClArTTS\n\t\n\nSpeech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAt present, Text-to-speech (TTS) systems that are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AtharvA7k/ClArTTS.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ClArTTS","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe present a speech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated. The final ClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nA typical data point comprises the name of the audio file, called‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ClArTTS.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ClArTTS","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe present a speech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated. The final ClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nA typical data point comprises the name of the audio file, called‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ClArTTS.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ClArTTS","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe present a speech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated. The final ClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nA typical data point comprises the name of the audio file, called‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ClArTTS.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"bimbim","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/master-frog/bimbim","creator_name":"Frog","creator_url":"https://huggingface.co/master-frog","description":"master-frog/bimbim dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"pony-speech","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-speech","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"pony-speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-speech","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-1.0-en-client_id-grouped","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-1.0-en-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 60 samples and a maximum of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","English"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-1.0-en-client_id-grouped","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-1.0-en-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 60 samples and a maximum of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","English"],"keywords_longer_than_N":true},
	{"name":"pony-singing","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-singing","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-singing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"pony-singing","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-singing","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-singing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"speech_MitrAI","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kanishk128/speech_MitrAI","creator_name":"Kanishk Singhal","creator_url":"https://huggingface.co/kanishk128","description":"kanishk128/speech_MitrAI dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mitrAI","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kanishk128/mitrAI","creator_name":"Kanishk Singhal","creator_url":"https://huggingface.co/kanishk128","description":"kanishk128/mitrAI dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-CN-client_id-grouped","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-zh-CN-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-CN-client_id-grouped","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-zh-CN-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-TW-client_id-grouped","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-zh-TW-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-TW-client_id-grouped","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-zh-TW-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-ja-client_id-grouped","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-ja-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Japanese"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-ja-client_id-grouped","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-ja-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Japanese"],"keywords_longer_than_N":true},
	{"name":"quran-recitation-errors","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sobolev210/quran-recitation-errors","creator_name":"Andrey Sobolev","creator_url":"https://huggingface.co/sobolev210","description":"\n\t\n\t\t\n\t\tExamples\n\t\n\nLoading dataset:\nfrom datasets import load_dataset\nds = load_dataset('sobolev210/quran-recitation-errors',)\nprint(ds[\"train\"][0])\n\n","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DATN_2024_Train","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duc2k1nh191468/DATN_2024_Train","creator_name":"DUC NGUYEN","creator_url":"https://huggingface.co/Duc2k1nh191468","description":"Duc2k1nh191468/DATN_2024_Train dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DATN_2024_Test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duc2k1nh191468/DATN_2024_Test","creator_name":"DUC NGUYEN","creator_url":"https://huggingface.co/Duc2k1nh191468","description":"Duc2k1nh191468/DATN_2024_Test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"twi_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d3vnerd/twi_dataset","creator_name":"jeffery crentsil","creator_url":"https://huggingface.co/d3vnerd","description":"d3vnerd/twi_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"zh-taiwan","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ivanzhu109/zh-taiwan","creator_name":"IvanZhu","creator_url":"https://huggingface.co/ivanzhu109","description":"ivanzhu109/zh-taiwan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"likun_v1","keyword":"audio","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yousaforever/likun_v1","creator_name":"Algacez","creator_url":"https://huggingface.co/yousaforever","description":"yousaforever/likun_v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["agpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"yellows","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/lottienatlie/yellows","creator_name":"ana carolina","creator_url":"https://huggingface.co/lottienatlie","description":"lottienatlie/yellows dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"M4rkim","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Solikkk/M4rkim","creator_name":"Solikitsu","creator_url":"https://huggingface.co/Solikkk","description":"Solikkk/M4rkim dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"asr-farsi-youtube-chunked-30-seconds","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/asr-farsi-youtube-chunked-30-seconds","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\n\t\n\t\t\n\t\tHow To Use\n\t\n\nfrom datasets import load_dataset\ntrain = load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='train+val')\ntest =load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='test')\n\n+300 Hours ASR dataset generated from this kaggle dataset\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"LucyHeartfilia","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/Astral-P/LucyHeartfilia","creator_name":"the music maker","creator_url":"https://huggingface.co/Astral-P","description":"Astral-P/LucyHeartfilia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"omega-multimodal","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/omegalabsinc/omega-multimodal","creator_name":"OMEGA Labs, Inc.","creator_url":"https://huggingface.co/omegalabsinc","description":"\n\t\n\t\t\n\t\tOMEGA Labs Bittensor Subnet: Multimodal Dataset for AGI Research\n\t\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe OMEGA Labs Bittensor Subnet Dataset is a groundbreaking resource for accelerating Artificial General Intelligence (AGI) research and development. This dataset, powered by the Bittensor decentralized network, aims to be the world's largest multimodal dataset, capturing the vast landscape of human knowledge and creation.\nWith over 1 million hours of footage and 30 million+ 2-minute video‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omegalabsinc/omega-multimodal.","first_N":5,"first_N_keywords":["video-text-to-text","video-classification","image-classification","image-to-text","image-to-video"],"keywords_longer_than_N":true},
	{"name":"omega-multimodal","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/omegalabsinc/omega-multimodal","creator_name":"OMEGA Labs, Inc.","creator_url":"https://huggingface.co/omegalabsinc","description":"\n\t\n\t\t\n\t\tOMEGA Labs Bittensor Subnet: Multimodal Dataset for AGI Research\n\t\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe OMEGA Labs Bittensor Subnet Dataset is a groundbreaking resource for accelerating Artificial General Intelligence (AGI) research and development. This dataset, powered by the Bittensor decentralized network, aims to be the world's largest multimodal dataset, capturing the vast landscape of human knowledge and creation.\nWith over 1 million hours of footage and 30 million+ 2-minute video‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omegalabsinc/omega-multimodal.","first_N":5,"first_N_keywords":["video-text-to-text","video-classification","image-classification","image-to-text","image-to-video"],"keywords_longer_than_N":true},
	{"name":"omega-multimodal","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/omegalabsinc/omega-multimodal","creator_name":"OMEGA Labs, Inc.","creator_url":"https://huggingface.co/omegalabsinc","description":"\n\t\n\t\t\n\t\tOMEGA Labs Bittensor Subnet: Multimodal Dataset for AGI Research\n\t\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe OMEGA Labs Bittensor Subnet Dataset is a groundbreaking resource for accelerating Artificial General Intelligence (AGI) research and development. This dataset, powered by the Bittensor decentralized network, aims to be the world's largest multimodal dataset, capturing the vast landscape of human knowledge and creation.\nWith over 1 million hours of footage and 30 million+ 2-minute video‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omegalabsinc/omega-multimodal.","first_N":5,"first_N_keywords":["video-text-to-text","video-classification","image-classification","image-to-text","image-to-video"],"keywords_longer_than_N":true},
	{"name":"Minhavozz","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/trickrascunho/Minhavozz","creator_name":"Patrick Dias de Campos","creator_url":"https://huggingface.co/trickrascunho","description":"trickrascunho/Minhavozz dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"audio_dataset_1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/0xdev23/audio_dataset_1","creator_name":"Akshay Srivastava","creator_url":"https://huggingface.co/0xdev23","description":"0xdev23/audio_dataset_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ProbaEstructura","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JJFrancisco/ProbaEstructura","creator_name":"jose javier francisco marini","creator_url":"https://huggingface.co/JJFrancisco","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JJFrancisco/ProbaEstructura.","first_N":5,"first_N_keywords":["expert-generated","monolingual","Galician","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Irelia","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/Astral-P/Irelia","creator_name":"the music maker","creator_url":"https://huggingface.co/Astral-P","description":"Astral-P/Irelia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"College-Entrance-English-Examination-Listening-Part","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Uni-MoE/College-Entrance-English-Examination-Listening-Part","creator_name":"Uni-MoE","creator_url":"https://huggingface.co/Uni-MoE","description":"Uni-MoE/College-Entrance-English-Examination-Listening-Part dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"MinakoAino","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/Astral-P/MinakoAino","creator_name":"the music maker","creator_url":"https://huggingface.co/Astral-P","description":"Astral-P/MinakoAino dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Albures","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thejorseman/Albures","creator_name":"Miguel","creator_url":"https://huggingface.co/thejorseman","description":"thejorseman/Albures dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"urdu-emotions","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/2DamnWav/urdu-emotions","creator_name":"2damn","creator_url":"https://huggingface.co/2DamnWav","description":"\n\t\n\t\t\n\t\tURDU-Dataset\n\t\n\n\n\t\n\t\t\n\t\t1. General information\n\t\n\nURDU dataset contains emotional utterances of Urdu speech gathered from Urdu talk shows. It contains 300 utterances of four basic emotions: Angry, Happy, and Neutral. There are 38 speakers (27 male and 11 female). This data is created from YouTube. Speakers are selected randomly.\nFor more details about dataset, please refer the complete paper \"Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages\".‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/2DamnWav/urdu-emotions.","first_N":5,"first_N_keywords":["audio-classification","Urdu","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"urdu-emotions","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/2DamnWav/urdu-emotions","creator_name":"2damn","creator_url":"https://huggingface.co/2DamnWav","description":"\n\t\n\t\t\n\t\tURDU-Dataset\n\t\n\n\n\t\n\t\t\n\t\t1. General information\n\t\n\nURDU dataset contains emotional utterances of Urdu speech gathered from Urdu talk shows. It contains 300 utterances of four basic emotions: Angry, Happy, and Neutral. There are 38 speakers (27 male and 11 female). This data is created from YouTube. Speakers are selected randomly.\nFor more details about dataset, please refer the complete paper \"Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages\".‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/2DamnWav/urdu-emotions.","first_N":5,"first_N_keywords":["audio-classification","Urdu","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"bambara_audio_synthetic","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OumarDicko/bambara_audio_synthetic","creator_name":"Oumar Dicko","creator_url":"https://huggingface.co/OumarDicko","description":"OumarDicko/bambara_audio_synthetic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Bambara","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for CML-TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for CML-TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xppast/voice","creator_name":"choi","creator_url":"https://huggingface.co/xppast","description":"xppast/voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Applio-RVC-Fork","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lununlu/Applio-RVC-Fork","creator_name":"Aigerim","creator_url":"https://huggingface.co/Lununlu","description":"Lununlu/Applio-RVC-Fork dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"english_dialects","keyword":"text-to-audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/english_dialects","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for \"english_dialects\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 31 hours of transcribed high-quality audio of English sentences recorded by 120 volunteers speaking with different accents of the British Isles. The dataset is intended for linguistic analysis as well as use for speech technologies. The speakers self-identified as native speakers of Southern England, Midlands, Northern England, Welsh, Scottish and Irish varieties of English.\nThe recording scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/english_dialects.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"english_dialects","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/english_dialects","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for \"english_dialects\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 31 hours of transcribed high-quality audio of English sentences recorded by 120 volunteers speaking with different accents of the British Isles. The dataset is intended for linguistic analysis as well as use for speech technologies. The speakers self-identified as native speakers of Southern England, Midlands, Northern England, Welsh, Scottish and Irish varieties of English.\nThe recording scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/english_dialects.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"google-chilean-spanish","keyword":"text-to-audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-chilean-spanish","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for Tamil Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 7 hours of transcribed high-quality audio of Chilean Spanish sentences recorded by 31 volunteers. The dataset is intended for speech technologies. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).\nautomatic-speech-recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-chilean-spanish.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Spanish","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"google-chilean-spanish","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-chilean-spanish","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for Tamil Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 7 hours of transcribed high-quality audio of Chilean Spanish sentences recorded by 31 volunteers. The dataset is intended for speech technologies. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).\nautomatic-speech-recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-chilean-spanish.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Spanish","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"speechocean762","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mispeech/speechocean762","creator_name":"Horizon Team, Xiaomi MiLM Plus","creator_url":"https://huggingface.co/mispeech","description":"\n\t\n\t\t\n\t\tspeechocean762: A non-native English corpus for pronunciation scoring task\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nPronunciation scoring is a crucial technology in computer-assisted language learning (CALL) systems. The pronunciation quality scores might be given at phoneme-level, word-level, and sentence-level for a typical pronunciation scoring task.\nThis corpus aims to provide a free public dataset for the pronunciation scoring task.\nKey features:\n\nIt is available for free download for both‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mispeech/speechocean762.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Synthetic_audio_bambara","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OumarDicko/Synthetic_audio_bambara","creator_name":"Oumar Dicko","creator_url":"https://huggingface.co/OumarDicko","description":"OumarDicko/Synthetic_audio_bambara dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Quaid-audio-only","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EazyAl/Quaid-audio-only","creator_name":"Ali Imran","creator_url":"https://huggingface.co/EazyAl","description":"EazyAl/Quaid-audio-only dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"WESTFAL","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fabsss/WESTFAL","creator_name":"F√°bio Sousa","creator_url":"https://huggingface.co/fabsss","description":"fabsss/WESTFAL dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"westfalmelado","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fabsss/westfalmelado","creator_name":"F√°bio Sousa","creator_url":"https://huggingface.co/fabsss","description":"fabsss/westfalmelado dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"speaker-identification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"natanmodelo2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neyruto10/natanmodelo2","creator_name":"natan melo","creator_url":"https://huggingface.co/neyruto10","description":"neyruto10/natanmodelo2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"modelonatan22","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neyruto10/modelonatan22","creator_name":"natan melo","creator_url":"https://huggingface.co/neyruto10","description":"neyruto10/modelonatan22 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ShalevVoice17","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gsabriel/ShalevVoice17","creator_name":"Estevam","creator_url":"https://huggingface.co/Gsabriel","description":"Gsabriel/ShalevVoice17 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"rao-vandromme-purcell-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GregoryVandromme/rao-vandromme-purcell-dataset","creator_name":"Gregory Vandromme","creator_url":"https://huggingface.co/GregoryVandromme","description":"GregoryVandromme/rao-vandromme-purcell-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"CarlosF","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KayoSilva88777/CarlosF","creator_name":"Silva","creator_url":"https://huggingface.co/KayoSilva88777","description":"KayoSilva88777/CarlosF dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ZED","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/on1onmangoes/ZED","creator_name":"Amit Lamba","creator_url":"https://huggingface.co/on1onmangoes","description":"\n\t\n\t\t\n\t\tDataset Card for My Dataset\n\t\n\n","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"icaro5","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/icaro23/icaro5","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/icaro23","description":"icaro23/icaro5 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"icaro4","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/icaro23/icaro4","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/icaro23","description":"icaro23/icaro4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vacuum1333","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stoptalk344/vacuum1333","creator_name":"–í–∞–¥–∏–º –ü–µ—Ä–µ—Ö—Ä–µ—Å—Ç","creator_url":"https://huggingface.co/stoptalk344","description":"stoptalk344/vacuum1333 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/n3gflash/test","creator_name":"anderson rocha leal","creator_url":"https://huggingface.co/n3gflash","description":"n3gflash/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"first-demo","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Saire2023/first-demo","creator_name":"Saire David Conejo Pichamba","creator_url":"https://huggingface.co/Saire2023","description":"Saire2023/first-demo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"first-demo","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Saire2023/first-demo","creator_name":"Saire David Conejo Pichamba","creator_url":"https://huggingface.co/Saire2023","description":"Saire2023/first-demo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"vozporkinbrasileiro","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/batatarixa/vozporkinbrasileiro","creator_name":"do barco","creator_url":"https://huggingface.co/batatarixa","description":"batatarixa/vozporkinbrasileiro dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"gn_common_voice_15","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mfidabel/gn_common_voice_15","creator_name":"Mateo Fidabel","creator_url":"https://huggingface.co/mfidabel","description":"mfidabel/gn_common_voice_15 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Carson","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PikwikCStudios/Carson","creator_name":"Carson Kelly","creator_url":"https://huggingface.co/PikwikCStudios","description":"PikwikCStudios/Carson dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"urban_sounds_small","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanSounds/urban_sounds_small","creator_name":"Sensemakers Amsterdam UrbanSounds repo","creator_url":"https://huggingface.co/UrbanSounds","description":"The Urban Sounds dataset consists of audio samples collected in Amsterdam in the period 2018 - 2020. \nThe datasamples were collected for a project to create a sensor to classify audio events, with the goal of tackling noise pollution in the city.\nThis 'urban sounds small' dataset is a small part of the dataset, used for testing and prototyping purposes.\nMore on the sensor can be found here: https://github.com/sensemakersamsterdam/OpenEars \n","first_N":5,"first_N_keywords":["audio-classification","Dutch","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"urban_sounds_small","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanSounds/urban_sounds_small","creator_name":"Sensemakers Amsterdam UrbanSounds repo","creator_url":"https://huggingface.co/UrbanSounds","description":"The Urban Sounds dataset consists of audio samples collected in Amsterdam in the period 2018 - 2020. \nThe datasamples were collected for a project to create a sensor to classify audio events, with the goal of tackling noise pollution in the city.\nThis 'urban sounds small' dataset is a small part of the dataset, used for testing and prototyping purposes.\nMore on the sensor can be found here: https://github.com/sensemakersamsterdam/OpenEars \n","first_N":5,"first_N_keywords":["audio-classification","Dutch","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"swam","keyword":"audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/euswam/swam","creator_name":"vitor Mateus","creator_url":"https://huggingface.co/euswam","description":"euswam/swam dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["artistic-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Public-Domain-Music","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SoundSafari/Public-Domain-Music","creator_name":"SoundSafari","creator_url":"https://huggingface.co/SoundSafari","description":"SoundSafari/Public-Domain-Music dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"AAVESpeechRecognition_CORAAL","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/AAVESpeechRecognition_CORAAL","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/AAVESpeechRecognition_CORAAL dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"PTBRSpeechRecognition_CORAA","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/PTBRSpeechRecognition_CORAA","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/PTBRSpeechRecognition_CORAA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"aihub-132-preprocessed-D22-0","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/choejiin/aihub-132-preprocessed-D22-0","creator_name":"choe yejin","creator_url":"https://huggingface.co/choejiin","description":"choejiin/aihub-132-preprocessed-D22-0 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Clapping_Sound_Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/Clapping_Sound_Dataset","creator_name":"ninjagamer","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/Clapping_Sound_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"cc_audio_8","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qgyd2021/cc_audio_8","creator_name":"Êô¥ËÄïÈõ®ËØª","creator_url":"https://huggingface.co/qgyd2021","description":"\n\t\n\t\t\n\t\tÂõΩÈôÖËØ≠Èü≥,ÁîµËØùÂú∫ÊôØ‰∏≠ÁöÑÂ£∞Èü≥ÂàÜÁ±ª\n\t\n\n","first_N":5,"first_N_keywords":["Chinese","English","Spanish","Korean","Japanese"],"keywords_longer_than_N":true},
	{"name":"CodeSwitchingSpeechIdentification_ASCEND","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/CodeSwitchingSpeechIdentification_ASCEND","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/CodeSwitchingSpeechIdentification_ASCEND dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"SongSeparation_SingSet","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/SongSeparation_SingSet","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/SongSeparation_SingSet dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"LyricTranslation_SingSet","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/LyricTranslation_SingSet","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/LyricTranslation_SingSet dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"S2ST_X2En_FLEURS","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/S2ST_X2En_FLEURS","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/S2ST_X2En_FLEURS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"S2ST_En2X_FLEURS","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/S2ST_En2X_FLEURS","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/S2ST_En2X_FLEURS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"HebDB","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SLPRL-HUJI/HebDB","creator_name":"Spoken Launguage Processing Research Lab","creator_url":"https://huggingface.co/SLPRL-HUJI","description":"\n\t\n\t\t\n\t\tHebDB\n\t\n\n Paper: http://arxiv.org/abs/2407.07566\nIf you use our datasets,  please use the following:\n@article{turetzky2024hebdb,\n  title={HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing},\n  author={Turetzky, Arnon and Tal, Or and Segal-Feldman, Yael and Dissen, Yehoshua and Zeldes, Ella and Roth, Amit and Cohen, Eyal and Shrem, Yosi and Chernyak, Bronya R and Seleznova, Olga and others},\n  journal={arXiv preprint arXiv:2407.07566},\n  year={2024}\n}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SLPRL-HUJI/HebDB.","first_N":5,"first_N_keywords":["cc-by-4.0","1M - 10M","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"sampleDental","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/srirama/sampleDental","creator_name":"srirama","creator_url":"https://huggingface.co/srirama","description":"srirama/sampleDental dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"wav-classical-music","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/drengskapur/wav-classical-music","creator_name":"drengskapur","creator_url":"https://huggingface.co/drengskapur","description":"drengskapur/wav-classical-music dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"new_accent_CV","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/snousind/new_accent_CV","creator_name":"Sarayu Nousind","creator_url":"https://huggingface.co/snousind","description":"snousind/new_accent_CV dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Speech-MASSIVE_vie","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/Speech-MASSIVE_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tVietnamse subset of the Speech-MASSIVE dataset\n\t\n\nextracted from:\n\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE-test\n\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-speechmassive.py\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ASCEND-phoneme","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/katyayego/ASCEND-phoneme","creator_name":"Katya Yegorova","creator_url":"https://huggingface.co/katyayego","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a modified version of the ASCEND dataset which consists of spontaneous Mandarin-English code-switched speech. The ASCEND dataset was published by Lovenia et al. (2022) (Check here for the dataset and here for the paper). \nThis dataset adds a phonetic transcription column to the dataset using the eSpeak backend from the phonemizer library created by Bernard et al. (2021) (Check it out here).\n\n\t\n\t\n\t\n\t\tthe following documentation is a modified version of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/katyayego/ASCEND-phoneme.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","Chinese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BibleMMS_vie","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/BibleMMS_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tVietnamse subset of the BibleMMS dataset\n\t\n\nextracted from: https://huggingface.co/datasets/Flux9665/BibleMMS\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-biblemms.py\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haidermasood99/quran","creator_name":"Haider Masood","creator_url":"https://huggingface.co/haidermasood99","description":"haidermasood99/quran dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"quran-small-data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haidermasood99/quran-small-data","creator_name":"Haider Masood","creator_url":"https://huggingface.co/haidermasood99","description":"haidermasood99/quran-small-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Josemo97","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bustaflt97/Josemo97","creator_name":"Jose Moreno","creator_url":"https://huggingface.co/Bustaflt97","description":"Bustaflt97/Josemo97 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ksd_120hours_kk","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gassirbek/ksd_120hours_kk","creator_name":"Gassyrbek Kosherbay","creator_url":"https://huggingface.co/gassirbek","description":"gassirbek/ksd_120hours_kk dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Michisor","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bustaflt97/Michisor","creator_name":"Jose Moreno","creator_url":"https://huggingface.co/Bustaflt97","description":"Bustaflt97/Michisor dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"AudioConvert","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Michito97/AudioConvert","creator_name":"Adrian De La Cruz","creator_url":"https://huggingface.co/Michito97","description":"Michito97/AudioConvert dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"aihub-132-preprocessed-D23-0","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/choejiin/aihub-132-preprocessed-D23-0","creator_name":"choe yejin","creator_url":"https://huggingface.co/choejiin","description":"choejiin/aihub-132-preprocessed-D23-0 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"arabic_quranic_asr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadique5/arabic_quranic_asr","creator_name":"Sadique Abdullah","creator_url":"https://huggingface.co/Sadique5","description":"\n\t\n\t\t\n\t\tDataset details\n\t\n\nThis dataset contains quran recitations of every ayats or verses. Also contains 10k unique words from quran.\n\n\t\n\t\t\n\t\tDataset Purpose\n\t\n\nThis dataset can be used to train ASR models that can be used for teaching beginners to recite quran. It can also be used for training TTS models that produces quran recitations in a way so that beginners can easily learn.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"violine_dataset","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/violine_dataset","creator_name":"ninjagamer","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/violine_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-audio","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"violine_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/violine_dataset","creator_name":"ninjagamer","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/violine_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-audio","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"save_audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cdactvm/save_audio","creator_name":"CDAC","creator_url":"https://huggingface.co/cdactvm","description":"cdactvm/save_audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","csv","Audio","Tabular"],"keywords_longer_than_N":true},
	{"name":"quran_new_small","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haidermasood99/quran_new_small","creator_name":"Haider Masood","creator_url":"https://huggingface.co/haidermasood99","description":"haidermasood99/quran_new_small dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"persian_tts_stt","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SmartGitiCorp/persian_tts_stt","creator_name":"Smart Giti Corporation","creator_url":"https://huggingface.co/SmartGitiCorp","description":"This dataset contains more than 10k records and 15 hours of clear vocal voice aligning with text in csv file.\n","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"persian_tts_stt","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SmartGitiCorp/persian_tts_stt","creator_name":"Smart Giti Corporation","creator_url":"https://huggingface.co/SmartGitiCorp","description":"This dataset contains more than 10k records and 15 hours of clear vocal voice aligning with text in csv file.\n","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"somali-voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/adityaedy01/somali-voice","creator_name":"Aditya Kumawat","creator_url":"https://huggingface.co/adityaedy01","description":"adityaedy01/somali-voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Somali","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"VietMed_unlabeled","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) unlabeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the unlabeled set: 966h - 230k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-unlabeled.py\nneed to do: check misspelling, restore foreign words phonetised to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"VietMed_labeled","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_labeled","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) labeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the labeled set: 9.2k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-labeled.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_labeled.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hutao-audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/hutao-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"ÂéüÁ•ûÁöÑËÉ°Ê°ÉËØ≠Èü≥Êï∞ÊçÆ\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"ViSpeech-Gender-Dialect-Classification","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/ViSpeech-Gender-Dialect-Classification","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"import datasets as hugDS\nimport pandas as pd\nimport os\nos.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\nfrom df.io import resample\nfrom df.enhance import enhance, init_df\nimport torch\nimport warnings\n\ndf_model, df_state, _ = init_df()\n\nSAMPLING_RATE = 16_000\n\ndef normalize_vietmed(example):\n    global vietmed_info\n    example[\"gender\"] = vietmed_info[vietmed_info[\"Speaker ID\"] == example[\"Speaker ID\"]][\"Gender\"].values[0].lower()\n    example[\"dialect\"] = vietmed_info[vietmed_info[\"Speaker ID\"] ==‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hr16/ViSpeech-Gender-Dialect-Classification.","first_N":5,"first_N_keywords":["audio-classification","Vietnamese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ViSpeech-Gender-Dialect-Classification","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/ViSpeech-Gender-Dialect-Classification","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"import datasets as hugDS\nimport pandas as pd\nimport os\nos.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\nfrom df.io import resample\nfrom df.enhance import enhance, init_df\nimport torch\nimport warnings\n\ndf_model, df_state, _ = init_df()\n\nSAMPLING_RATE = 16_000\n\ndef normalize_vietmed(example):\n    global vietmed_info\n    example[\"gender\"] = vietmed_info[vietmed_info[\"Speaker ID\"] == example[\"Speaker ID\"]][\"Gender\"].values[0].lower()\n    example[\"dialect\"] = vietmed_info[vietmed_info[\"Speaker ID\"] ==‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hr16/ViSpeech-Gender-Dialect-Classification.","first_N":5,"first_N_keywords":["audio-classification","Vietnamese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Alend","keyword":"audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alokaosman00/Alend","creator_name":"Aloka","creator_url":"https://huggingface.co/alokaosman00","description":"alokaosman00/Alend dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["artistic-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"robotfreddsr","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TrinityRixV/robotfreddsr","creator_name":"Joran Vu≈°alj","creator_url":"https://huggingface.co/TrinityRixV","description":"TrinityRixV/robotfreddsr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"stock_market_asx_audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sdeering/stock_market_asx_audio","creator_name":"Sam","creator_url":"https://huggingface.co/sdeering","description":"\n\t\n\t\t\n\t\tDataset Card for Stock Market ASX Audio\n\t\n\nContains audios for every listed company on the Australian Stock Exchange (ASX). The dataset contains 2329 audio files of people saying the name of the company.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nsentence_id (string): An id for the sentence used for the recording.\nvoice_id (string): An id for which client (voice) made the recording.\naudio (dict): A dictionary containing the path to the downloaded audio file.\nsentence (string): The sentence the user was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sdeering/stock_market_asx_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","sdeering","google translate","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"darija_speech_to_text","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adiren7/darija_speech_to_text","creator_name":"Adil Oubaibou","creator_url":"https://huggingface.co/adiren7","description":"adiren7/darija_speech_to_text dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"qiqi-audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/qiqi-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"lissette/qiqi-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"yaoyao-audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/yaoyao-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"lissette/yaoyao-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"example_mmdata_mnbvc","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracleyin/example_mmdata_mnbvc","creator_name":"yin zhang","creator_url":"https://huggingface.co/miracleyin","description":"\n\t\n\t\t\n\t\tmnbvc mm dataset v2.0\n\t\n\nMNBVC Â§öÊ®°ÊÄÅËØ≠ÊñôÊï∞ÊçÆÊ†ºÂºè„ÄÇÂéüÈìæÊé•Ôºöhttps://huggingface.co/datasets/wanng/example_mmdata_mnbvc\n\n\t\n\t\t\nÂ≠óÊÆµÂêçÁß∞\nÂ≠óÊÆµËØ¥Êòé\nÂèØÈÄâ\n\n\n\t\t\nÂÆû‰ΩìID\nÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊ†áËØÜÁ¨¶„ÄÇÁî®‰∫éÂú®Êï∞ÊçÆÈõÜ‰∏≠Á°ÆÂÆöÊòØÂì™‰∏ÄÊù°Êï∞ÊçÆ„ÄÇÂú®Âçï‰∏™Êï∞ÊçÆÈõÜ‰∏≠Á°ÆÂÆö‰∏ÄÊù°Êï∞ÊçÆÁöÑÂÆû‰ΩìÂØπË±°„ÄÇ\nÂøÖÈÄâ\n\n\nÂùóID\n‰∏Ä‰∏™ÂÆû‰ΩìÂØπË±°ÂÜÖÁöÑÊ†áËØÜÁ¨¶„ÄÇÁî®‰∫éÁ°ÆÂÆö‰∏ÄÊù°Êï∞ÊçÆÂÜÖÁöÑ‰∏Ä‰∏™ÈÉ®ÂàÜÊï∞ÊçÆ„ÄÇparquet Ë°åÁöÑÊúÄÂ∞èÂçïÂÖÉ„ÄÇ\nÂøÖÈÄâ\n\n\nÊó∂Èó¥\nËØ≠ÊñôÈ¶ñÊ¨°Âá∫Áé∞ÁöÑÊó∂Èó¥ÔºåÂ¶ÇÊó†Ê≥ïÁ°ÆÂÆöÂàô‰∏∫Â§ÑÁêÜËØ•Êï∞ÊçÆÂÆû‰ΩìÁöÑÊó∂Èó¥\nÂøÖÈÄâ\n\n\nÊâ©Â±ïÂ≠óÊÆµ\nÁî®‰∫é‰øùÂ≠òÂùóÁöÑÂÖÉ‰ø°ÊÅØ„ÄÇ‰∏∫ÂèØ‰ª•Ë¢´ÊàêÂäü load ÁöÑ json Â≠óÁ¨¶‰∏≤„ÄÇÂêéÊúüÂèØÁªßÁª≠Êâ©Â±ï\nÂøÖÈÄâ\n\n\nÊñáÊú¨\nÊñáÊú¨ÂùóÁöÑÂÜÖÂÆπ\nÂøÖÈÄâ\n\n\nÂõæÁâá\nÂõæÁâáÂùóÁöÑÂÜÖÂÆπ\nÂøÖÈÄâ\n\n\nOCRÊñáÊú¨\nÂõæÁâáÁöÑ OCR ÁªìÊûú\nÂøÖÈÄâ\n\n\nÈü≥È¢ë\nÈü≥È¢ëÂùóÁöÑÂÜÖÂÆπ\nÂøÖÈÄâ\n\n\nSTTÊñáÊú¨\nÈü≥È¢ëÁöÑ STT ÁªìÊûú\nÂøÖÈÄâ\n\n\nÂùóÁ±ªÂûã\nÁî®‰∫é‰øùÂ≠òÂùóÁöÑÁ±ªÂà´„ÄÇ‰∏∫Â≠óÁ¨¶‰∏≤Ôºå‰ΩøÁî®ËØ•Á±ªÂûãÂèØ‰ª•‰ªéÂÜÖÂÆπ‰∏≠ÊèêÂèñÂØπÂ∫î‰ø°ÊÅØ„ÄÇÁ±ªÂà´ÁöÑÂê´‰πâ‰∏∫‚ÄúÊ®°ÊÄÅ‚Äù„ÄÇ\nÂøÖÈÄâ\n\n\nÊñá‰ª∂md5\nÂΩì entity/blcok‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracleyin/example_mmdata_mnbvc.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"darija_to_french_speech_to_text","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adiren7/darija_to_french_speech_to_text","creator_name":"Adil Oubaibou","creator_url":"https://huggingface.co/adiren7","description":"adiren7/darija_to_french_speech_to_text dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["French","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Libriheavy-HQ","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\n\t\n\t\t\n\t\tDataset Card for Libriheavy-HQ\n\t\n\n\n\nLibriheavy: a 50,000 hours ASR corpus with punctuation casing \nand context. Libriheavy is a labeled version of Libri-Light.\nLibriheavy-HQ replaces the default Libri-Light audio files with the highest quality available versions from librivox \nwithout re-encoding them. \nIn most cases, this consists an upgrade of the source audio from a 64kbps .mp3 to a 128kbps .mp3.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis is the Libriheavy-HQ dataset, adapted for the datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Libriheavy-HQ","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\n\t\n\t\t\n\t\tDataset Card for Libriheavy-HQ\n\t\n\n\n\nLibriheavy: a 50,000 hours ASR corpus with punctuation casing \nand context. Libriheavy is a labeled version of Libri-Light.\nLibriheavy-HQ replaces the default Libri-Light audio files with the highest quality available versions from librivox \nwithout re-encoding them. \nIn most cases, this consists an upgrade of the source audio from a 64kbps .mp3 to a 128kbps .mp3.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis is the Libriheavy-HQ dataset, adapted for the datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"quran_asr_final","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haidermasood99/quran_asr_final","creator_name":"Haider Masood","creator_url":"https://huggingface.co/haidermasood99","description":"haidermasood99/quran_asr_final dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"quran_asr_final_wbw","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haidermasood99/quran_asr_final_wbw","creator_name":"Haider Masood","creator_url":"https://huggingface.co/haidermasood99","description":"haidermasood99/quran_asr_final_wbw dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"sugarhillkeem","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gangslamma123/sugarhillkeem","creator_name":"Desmand Kyoto","creator_url":"https://huggingface.co/gangslamma123","description":"gangslamma123/sugarhillkeem dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mabama-v6","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gitgato/mabama-v6","creator_name":"Git Porter","creator_url":"https://huggingface.co/gitgato","description":"\n\t\n\t\t\n\t\tDataset mabama-v6\n\t\n\nDataset de audio para entrenar modelos de s√≠ntesis de voz (TTS) en espa√±ol.\n\n\t\n\t\t\n\t\tDescripci√≥n\n\t\n\n\nContenido: Audios en espa√±ol con sus transcripciones textuales.\nHablante: mabama (voz √∫nica).\nDuraci√≥n total: X horas (ajusta este valor).\nTasa de muestreo: 22.05 kHz (o la que uses).\n\n\n\t\n\t\t\n\t\tEstructura\n\t\n\n","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"knesset_melia_asr_poc","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yoad/knesset_melia_asr_poc","creator_name":"Yoad Snapir","creator_url":"https://huggingface.co/yoad","description":"yoad/knesset_melia_asr_poc dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"instruction-speech-encodec-v1.5","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Menlo/instruction-speech-encodec-v1.5","creator_name":"Menlo Research","creator_url":"https://huggingface.co/Menlo","description":"\n\t\n\t\t\n\t\tDataset Card for \"Instruction Speech\"\n\t\n\n\nThe largest open-source English speech instruction to text answer dataset\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains over 332,000 English speech instruction to text answer samples, using:\n\nA subset of jan-hq/prompt-voice-v1.5.\nAudio generation using WhisperSpeech.\nTokenized using Encodec.\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset, Audio\n# Load Instruction Speech dataset\n\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Menlo/instruction-speech-encodec-v1.5.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"tamil_youtube_voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arunprabu/tamil_youtube_voice","creator_name":"nallasamy","creator_url":"https://huggingface.co/arunprabu","description":"annotations_creators: []\nlanguage:\n\nta-IN\nlanguage_creators:\nother\nlicense:\nafl-3.0\nmultilinguality:\nmonolingual\npretty_name: 'tamil voice '\nsize_categories: []\nsource_datasets: []\ntags:\ntamil\naudio\ntask_categories:\naudio-classification\naudio-to-audio\ntask_ids: []\n\n","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"asante-twi-tts","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kojo-george/asante-twi-tts","creator_name":"George Birikorang","creator_url":"https://huggingface.co/kojo-george","description":"kojo-george/asante-twi-tts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"code-mixed-bangla-english-asr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fayez94/code-mixed-bangla-english-asr","creator_name":"Mohammad Fayez Ullah","creator_url":"https://huggingface.co/fayez94","description":"fayez94/code-mixed-bangla-english-asr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"kuon-audio","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/kuon-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"‰πÖËøúËØ≠Èü≥\nÊù•Ê∫ê‰∫éTVÂä®ÁîªÊèêÂèñÔºåËøõËøáuvrÂàÜÁ¶ªËÉåÊôØÈü≥Ôºå‰∫∫Â∑•Á≠õÈÄâË¥®ÈáèËæÉÂ•ΩÁöÑ„ÄÇ\n610‰∏™Áü≠ËØ≠Èü≥Ôºå1‰∏™Ê≠åÊõ≤\n","first_N":5,"first_N_keywords":["audio-to-audio","text-to-audio","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"kuon-audio","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/kuon-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"‰πÖËøúËØ≠Èü≥\nÊù•Ê∫ê‰∫éTVÂä®ÁîªÊèêÂèñÔºåËøõËøáuvrÂàÜÁ¶ªËÉåÊôØÈü≥Ôºå‰∫∫Â∑•Á≠õÈÄâË¥®ÈáèËæÉÂ•ΩÁöÑ„ÄÇ\n610‰∏™Áü≠ËØ≠Èü≥Ôºå1‰∏™Ê≠åÊõ≤\n","first_N":5,"first_N_keywords":["audio-to-audio","text-to-audio","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"kuon-audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/kuon-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"‰πÖËøúËØ≠Èü≥\nÊù•Ê∫ê‰∫éTVÂä®ÁîªÊèêÂèñÔºåËøõËøáuvrÂàÜÁ¶ªËÉåÊôØÈü≥Ôºå‰∫∫Â∑•Á≠õÈÄâË¥®ÈáèËæÉÂ•ΩÁöÑ„ÄÇ\n610‰∏™Áü≠ËØ≠Èü≥Ôºå1‰∏™Ê≠åÊõ≤\n","first_N":5,"first_N_keywords":["audio-to-audio","text-to-audio","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LUMA","keyword":"audio-classification","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bezirganyan/LUMA","creator_name":"Grigor Bezirganyan","creator_url":"https://huggingface.co/bezirganyan","description":"\n    LUMA\n    A Benchmark Dataset for Learning from Uncertain and Multimodal Data\n    \n        üìÑ\n        üì∑\n        üéµ\n        üìä\n        ‚ùì\n    \n    Multimodal Uncertainty Quantification at Your Fingertips\n\n\nThe LUMA dataset is a multimodal dataset, including audio, text, and image modalities, intended for benchmarking multimodal learning and multimodal uncertainty quantification.\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nLUMA is a multimodal dataset that consists of audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bezirganyan/LUMA.","first_N":5,"first_N_keywords":["image-classification","audio-classification","text-classification","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"LUMA","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bezirganyan/LUMA","creator_name":"Grigor Bezirganyan","creator_url":"https://huggingface.co/bezirganyan","description":"\n    LUMA\n    A Benchmark Dataset for Learning from Uncertain and Multimodal Data\n    \n        üìÑ\n        üì∑\n        üéµ\n        üìä\n        ‚ùì\n    \n    Multimodal Uncertainty Quantification at Your Fingertips\n\n\nThe LUMA dataset is a multimodal dataset, including audio, text, and image modalities, intended for benchmarking multimodal learning and multimodal uncertainty quantification.\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nLUMA is a multimodal dataset that consists of audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bezirganyan/LUMA.","first_N":5,"first_N_keywords":["image-classification","audio-classification","text-classification","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"one-shot-hip-hop-drums","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yojul/one-shot-hip-hop-drums","creator_name":"Jules Sintes","creator_url":"https://huggingface.co/yojul","description":"yojul/one-shot-hip-hop-drums dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Cantaosu/test","creator_name":"Cantao Su","creator_url":"https://huggingface.co/Cantaosu","description":"Cantaosu/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DisfluencySpeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amaai-lab/DisfluencySpeech","creator_name":"AMAAI Lab","creator_url":"https://huggingface.co/amaai-lab","description":"\n\t\n\t\t\n\t\tDisfluencySpeech Dataset\n\t\n\nThe DisfluencySpeech Dataset is a single-speaker studio-quality labeled English speech dataset with paralanguage. \nA single speaker recreates nearly 10 hours of expressive utterances from the Switchboard-1 Telephone Speech Corpus \n(Switchboard), simulating realistic informal conversations. To aid the development of a text-to-speech (TTS) model that is able to \npredictively synthesise paralanguage from text without such components, we provide three different‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amaai-lab/DisfluencySpeech.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"50-words-stephen-fry","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smfreeze/50-words-stephen-fry","creator_name":"SMFreeze","creator_url":"https://huggingface.co/smfreeze","description":"Dataset of Stephen Fry from his singing on 50 Words For Snow by kate bush.\n","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Blankluk26","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blankluk/Blankluk26","creator_name":"Gianluca","creator_url":"https://huggingface.co/blankluk","description":"blankluk/Blankluk26 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"voxconverse","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/diarizers-community/voxconverse","creator_name":"diarizers-community","creator_url":"https://huggingface.co/diarizers-community","description":"\n\t\n\t\t\n\t\tDataset Card for the Voxconverse dataset\n\t\n\nVoxConverse is an audio-visual diarisation dataset consisting of multispeaker clips of human speech, extracted from YouTube videos. Updates and additional information about the dataset can be found on the dataset website.\nNote: This dataset has been preprocessed using diarizers. It makes the dataset compatible with diarizers to fine-tune pyannote segmentation models.\n\n\t\n\t\t\n\t\n\t\n\t\tExample Usage\n\t\n\nfrom datasets import load_dataset\nds =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/diarizers-community/voxconverse.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"rvc","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Friedrich88/rvc","creator_name":"Friedrich Goldmauer","creator_url":"https://huggingface.co/Friedrich88","description":"Friedrich88/rvc dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"p225_dataset2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oxschaos/p225_dataset2","creator_name":"Ê∏∏Êô∫Ë∂Ö","creator_url":"https://huggingface.co/oxschaos","description":"oxschaos/p225_dataset2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"PerceptionTest","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lmms-lab/PerceptionTest","creator_name":"LMMs-Lab","creator_url":"https://huggingface.co/lmms-lab","description":"lmms-lab/PerceptionTest dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"MaikRVC","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Robette/MaikRVC","creator_name":"Mie","creator_url":"https://huggingface.co/Robette","description":"Robette/MaikRVC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ICAROIAV","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lcaruss/ICAROIAV","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/Lcaruss","description":"Lcaruss/ICAROIAV dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"icaroia","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lcaruss/icaroia","creator_name":"icaro guilherme","creator_url":"https://huggingface.co/Lcaruss","description":"Lcaruss/icaroia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"dylan","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/48xrf/dylan","creator_name":"bogdan","creator_url":"https://huggingface.co/48xrf","description":"48xrf/dylan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"sampledsadata","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emwebaze/sampledsadata","creator_name":"Ernest Mwebaze","creator_url":"https://huggingface.co/emwebaze","description":"emwebaze/sampledsadata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Nanami-Chiaki-audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/Nanami-Chiaki-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"Âºπ‰∏∏ËÆ∫Á†¥ÁöÑ‰∏ÉÊµ∑ÂçÉÁßãËØ≠Èü≥Êï∞ÊçÆ\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"dsadata","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emwebaze/dsadata","creator_name":"Ernest Mwebaze","creator_url":"https://huggingface.co/emwebaze","description":"emwebaze/dsadata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Yokodera-audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/Yokodera-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"„ÄäÂèòÊÄÅÁéãÂ≠ê‰∏é‰∏çÁ¨ëÁå´„ÄãÁî∑‰∏ªËßíÔºåÊ®™ÂØ∫Èò≥‰∫∫ÔºåÂ£∞‰ºòÔºöÊ¢∂Ë£ïË¥µ\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"tdata","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emwebaze/tdata","creator_name":"Ernest Mwebaze","creator_url":"https://huggingface.co/emwebaze","description":"emwebaze/tdata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"voxangeles_annotations","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech31/voxangeles_annotations","creator_name":"Eunjung Yeo","creator_url":"https://huggingface.co/speech31","description":"speech31/voxangeles_annotations dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"spoken_sts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juice500/spoken_sts","creator_name":"Kwanghee Choi","creator_url":"https://huggingface.co/juice500","description":"\n\t\n\t\t\n\t\tSpokenSTS Dataset\n\t\n\nSpoken versions of the Semantic Textual Similarity dataset for testing semantic sentence level embeddings.\nContains thousands of sentence pairs annotated by humans for semantic similarity.\nThe spoken sentences can be used in sentence embedding models to test whether your model learns to capture sentence semantics.\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThis distribution is not official.\nThis subset only contains sentences from 4 human voices. Synthesized voices are excluded.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/juice500/spoken_sts.","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"kikongo-bible-asr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/kikongo-bible-asr","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tKikongo Bible ASR\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/kikongo-bible-asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kongo","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"VAAC","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ResearcherT98/VAAC","creator_name":"T","creator_url":"https://huggingface.co/ResearcherT98","description":"\n\t\n\t\t\n\t\tDataset Card for Video and Audio Aligned Caption Dataset (VAAC)\n\t\n\nDataset that contains different captions for videos with audio.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nWe present a framework for annotating videos with audiovisual textual descriptions. Our three-step process involves generating auditory captions from sounds using an audio captioner, generating visual captions from the video content using a video captioner, and using concatenation or instruction fine-tuned large language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ResearcherT98/VAAC.","first_N":5,"first_N_keywords":["video-classification","zero-shot-classification","audio-classification","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"killkan","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ctaguchi/killkan","creator_name":"Chihiro Taguchi","creator_url":"https://huggingface.co/ctaguchi","description":"\n\t\n\t\t\n\t\tKillkan: Speech Recognition dataset for Kichwa\n\t\n\nKillkan (Kichwa uyachkata payllatak killkak anta) is the first automatic speech recognition (ASR) dataset for the Kichwa language.\nSee also our paper (https://arxiv.org/abs/2404.15501).\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Quechua","Imbabura Highland Quichua","Chimborazo Highland Quichua","Salasaca Highland Quichua"],"keywords_longer_than_N":true},
	{"name":"akuapem-twi-tts","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kojo-george/akuapem-twi-tts","creator_name":"George Birikorang","creator_url":"https://huggingface.co/kojo-george","description":"kojo-george/akuapem-twi-tts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"GLOBE","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tUpdated\n\t\n\n\n\t\n\t\t\n\t\tYou can use the V3 version, which includes more data, detailed speech quality annotations, and the original Common Voice IDs.\n\t\n\n\n\t\n\t\t\n\t\tAlternatively, you can use the V2 version to avoid the abnormal voice volume issue in this version.\n\t\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"GLOBE","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tUpdated\n\t\n\n\n\t\n\t\t\n\t\tYou can use the V3 version, which includes more data, detailed speech quality annotations, and the original Common Voice IDs.\n\t\n\n\n\t\n\t\t\n\t\tAlternatively, you can use the V2 version to avoid the abnormal voice volume issue in this version.\n\t\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"GLOBE","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tUpdated\n\t\n\n\n\t\n\t\t\n\t\tYou can use the V3 version, which includes more data, detailed speech quality annotations, and the original Common Voice IDs.\n\t\n\n\n\t\n\t\t\n\t\tAlternatively, you can use the V2 version to avoid the abnormal voice volume issue in this version.\n\t\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"GLOBE","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tUpdated\n\t\n\n\n\t\n\t\t\n\t\tYou can use the V3 version, which includes more data, detailed speech quality annotations, and the original Common Voice IDs.\n\t\n\n\n\t\n\t\t\n\t\tAlternatively, you can use the V2 version to avoid the abnormal voice volume issue in this version.\n\t\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"BibleMMS","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flux9665/BibleMMS","creator_name":"Florian Lux","creator_url":"https://huggingface.co/Flux9665","description":"The Dataset associated with the Paper \"Meta Learning Text-to-Speech Synthesis in over 7000 Languages\" by Florian Lux, Sarina Meyer, Lyonel Behringer, Frank Zalkow, Phat Do, Matt Coler, Emanu√´l A. P. Habets and Ngoc Thang Vu (Interspeech 2024).\nWe generate 2000 spoken utterances per language using the subsets of the eBible dataset [1] that are under free licenses as the text input to the MMS TTS models [2]. \nThe languages associated with the following ISO-639-3 codes are represented in this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Flux9665/BibleMMS.","first_N":5,"first_N_keywords":["text-to-speech","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"CodecFake","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rogertseng/CodecFake","creator_name":"Yuan Tseng","creator_url":"https://huggingface.co/rogertseng","description":"\n\t\n\t\t\n\t\tCodecFake: Enhancing Anti-Spoofing Models Against Deepfake Audios from Codec-Based Speech Synthesis Systems\n\t\n\n  \n    Paper,\n    Code,\n    Project Page\n\n  \n    Interspeech 2024\n\n\nTL;DR: We show that better detection of deepfake speech from codec-based TTS systems can be achieved by training models on speech re-synthesized with neural audio codecs.\nThis dataset is released for this purpose.\nSee our paper and Github for more details on using our dataset.\n\n\t\n\t\n\t\n\t\tAcknowledgement‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rogertseng/CodecFake.","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"esd_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oxschaos/esd_dataset","creator_name":"Ê∏∏Êô∫Ë∂Ö","creator_url":"https://huggingface.co/oxschaos","description":"oxschaos/esd_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"mabama-v","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aztro/mabama-v","creator_name":"Jose Omar Vieyra","creator_url":"https://huggingface.co/aztro","description":"aztro/mabama-v dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"ManaAudio","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/Th3ro/ManaAudio","creator_name":"Thero","creator_url":"https://huggingface.co/Th3ro","description":"Th3ro/ManaAudio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"nurc-sp_pseudo_labelled","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RodrigoLimaRFL/nurc-sp_pseudo_labelled","creator_name":"Rodrigo de Freitas Lima","creator_url":"https://huggingface.co/RodrigoLimaRFL","description":"RodrigoLimaRFL/nurc-sp_pseudo_labelled dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"SpeakerDiarization_SparseLibriMix2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/SpeakerDiarization_SparseLibriMix2","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/SpeakerDiarization_SparseLibriMix2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"uzbek_speech_data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uzbek_speech_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uzbek_speech_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v1","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tEwe bible for Text-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Ewe","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Hindi-Podcasts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shuyuej/Hindi-Podcasts","creator_name":"Shuyue Jia (Bruce)","creator_url":"https://huggingface.co/shuyuej","description":"shuyuej/Hindi-Podcasts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"twi_bible_v1","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tTwi Text-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Twi"],"keywords_longer_than_N":true},
	{"name":"HeartAnomalyDetection_HeartbeatSounds","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/HeartAnomalyDetection_HeartbeatSounds","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/HeartAnomalyDetection_HeartbeatSounds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"kcik","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Redcalx34B/kcik","creator_name":"Caldrex","creator_url":"https://huggingface.co/Redcalx34B","description":"Redcalx34B/kcik dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"NextNotePredictionInMusic","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/NextNotePredictionInMusic","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/NextNotePredictionInMusic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"AudioSpatialDistancePrediction_SpatialLibriSpeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/AudioSpatialDistancePrediction_SpatialLibriSpeech","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/AudioSpatialDistancePrediction_SpatialLibriSpeech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"GenderVoiceRecognition","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/GenderVoiceRecognition","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/GenderVoiceRecognition dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"EmotionalVoiceConversion_ESD","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/EmotionalVoiceConversion_ESD","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/EmotionalVoiceConversion_ESD dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Lupitarbd3","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Phinea/Lupitarbd3","creator_name":"Phinea ","creator_url":"https://huggingface.co/Phinea","description":"Phinea/Lupitarbd3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v2_tts","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tText-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","translation","Ewe"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v2_tts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tText-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","translation","Ewe"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v2_tts","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tText-to-Speech Dataset\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Twi","Akan"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v2_tts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tText-to-Speech Dataset\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Twi","Akan"],"keywords_longer_than_N":true},
	{"name":"uz-data","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uz-data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uz-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"maxShaneModel","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wellloy/maxShaneModel","creator_name":"Shane","creator_url":"https://huggingface.co/Wellloy","description":"Wellloy/maxShaneModel dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Russian","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"common_voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/snousind/common_voice","creator_name":"Sarayu Nousind","creator_url":"https://huggingface.co/snousind","description":"snousind/common_voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"jukedatasetforsomeone","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/loganhuggingface/jukedatasetforsomeone","creator_name":"Logan Hall","creator_url":"https://huggingface.co/loganhuggingface","description":"loganhuggingface/jukedatasetforsomeone dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"EU_Euskera661Audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AItool/EU_Euskera661Audio","creator_name":"AI tool","creator_url":"https://huggingface.co/AItool","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n661 files handpicked from common voice 12 and 13 (clean voice recordings)\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{commonvoice:2020,\n  author = {Ardila, R. and Branson, M. and Davis, K. and Henretty, M. and Kohler, M. and Meyer, J. and Morais, R. and Saunders, L. and Tyers, F. M. and Weber, G.},\n  title = {Common Voice: A Massively-Multilingual Speech Corpus},\n  booktitle = {Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AItool/EU_Euskera661Audio.","first_N":5,"first_N_keywords":["Basque","mit","< 1K","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"CatMeows","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeddez/CatMeows","creator_name":"Zed","creator_url":"https://huggingface.co/zeddez","description":"\nfrom https://zenodo.org/records/4008297#.YZRl82BByUn\nCatMeows: A Publicly-Available Dataset of Cat Vocalizations\nLudovico, L. A., Ntalampiras, S., Presti, G., Cannas, S., Battini, M., & Mattiello, S. (2020). CatMeows: A Publicly-Available Dataset of Cat Vocalizations (1.0.2) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.4008297\n\n\n\t\n\t\t\n\t\n\t\n\t\tAbstract\n\t\n\nThis dataset, composed of 440 sounds, contains meows emitted by cats in different contexts. Specifically, 21 cats belonging to 2 breeds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zeddez/CatMeows.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"arabic_quran_asr_final","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haidermasood99/arabic_quran_asr_final","creator_name":"Haider Masood","creator_url":"https://huggingface.co/haidermasood99","description":"haidermasood99/arabic_quran_asr_final dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"GariAndLunaVoiceover-Samples","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Moneerrashed/GariAndLunaVoiceover-Samples","creator_name":"Moneer Rashed","creator_url":"https://huggingface.co/Moneerrashed","description":"Moneerrashed/GariAndLunaVoiceover-Samples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"EUbookshop-Speech-Irish","keyword":"audio","license":"European Union Public License 1.1","license_url":"https://choosealicense.com/licenses/eupl-1.1/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the EUbookshop dataset, consisting of 33,634 text segments.\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 159 hours and 45 minutes (159:45:05) spread across 67,268 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"Anelucie","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Medradome/Anelucie","creator_name":"santos","creator_url":"https://huggingface.co/Medradome","description":"Medradome/Anelucie dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"BadBella","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Medradome/BadBella","creator_name":"santos","creator_url":"https://huggingface.co/Medradome","description":"Medradome/BadBella dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Coswara","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/Coswara","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/Coswara dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"libritts_r_filtered","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/libritts_r_filtered","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Filtered LibriTTS-R\n\t\n\nThis is a filtered version of LibriTTS-R. It has been filtered based on two sources:\n\nLibriTTS-R paper [1], which lists samples for which speech restoration have failed\nLibriTTS-P [2] list of excluded speakers for which multiple speakers have been detected.\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_filtered.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"dsftest","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fazemasta/dsftest","creator_name":"Faze Masta","creator_url":"https://huggingface.co/fazemasta","description":"fazemasta/dsftest dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"musica","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zaibutcooler/musica","creator_name":"Zai","creator_url":"https://huggingface.co/zaibutcooler","description":"zaibutcooler/musica dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"common_voice_pseudo","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ojro/common_voice_pseudo","creator_name":"Ochirsukh Batbold","creator_url":"https://huggingface.co/Ojro","description":"Ojro/common_voice_pseudo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_eu_v2.1","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1","creator_name":"Asier Herranz","creator_url":"https://huggingface.co/asierhv","description":"\n\t\n\t\t\n\t\tComposite dataset for Basque made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/eu: \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\ngttsehu/basque_parliament_1/eu: \"train_clean\" split removing some of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic-ASR","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AhmedBoin/Arabic-ASR","creator_name":"Mohamed Ahmed Taha","creator_url":"https://huggingface.co/AhmedBoin","description":"AhmedBoin/Arabic-ASR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Vaudeville","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/simodo79/Vaudeville","creator_name":"Simone Odoardi","creator_url":"https://huggingface.co/simodo79","description":"simodo79/Vaudeville dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"vox-pretrain","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/vox-pretrain","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"xacer/vox-pretrain dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","English","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"vox-pretrain","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/vox-pretrain","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"xacer/vox-pretrain dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","English","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"dataset-mmb-v1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gitgato/dataset-mmb-v1","creator_name":"Git Porter","creator_url":"https://huggingface.co/gitgato","description":"\n\t\n\t\t\n\t\tmabama-v6-audio Dataset\n\t\n\nEste dataset, mabama-v6-audio, est√° dise√±ado para tareas de text-to-speech (TTS) y contiene grabaciones de audio junto con sus correspondientes transcripciones en espa√±ol. Est√° dividido en tres partes: entrenamiento, prueba y validaci√≥n, permitiendo un desarrollo y evaluaci√≥n efectivos de modelos TTS.\n\n\t\n\t\t\n\t\tEstructura del Dataset\n\t\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nfile_name: Nombre del archivo de audio.\ntext: Transcripci√≥n del audio.\nspeaker_id: Identificador del‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gitgato/dataset-mmb-v1.","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"HumanNonSpeechSoundRecognition_Nonspeech7k-test_CommonVoice-DeltaSegment-15","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/HumanNonSpeechSoundRecognition_Nonspeech7k-test_CommonVoice-DeltaSegment-15","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/HumanNonSpeechSoundRecognition_Nonspeech7k-test_CommonVoice-DeltaSegment-15 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DaviNojentoVerme","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DaviVerme123/DaviNojentoVerme","creator_name":"Davi Vermoso Cremoso","creator_url":"https://huggingface.co/DaviVerme123","description":"DaviVerme123/DaviNojentoVerme dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["afl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"HumanScreamingDetection_Environmentdb","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/HumanScreamingDetection_Environmentdb","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/HumanScreamingDetection_Environmentdb dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"whynxzipmusic","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gate369/whynxzipmusic","creator_name":"limin(gate)","creator_url":"https://huggingface.co/gate369","description":"gate369/whynxzipmusic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"AudioSearch","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/AudioSearch","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/AudioSearch dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Audio_speaker_needle_in_haystack","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/omniway/Audio_speaker_needle_in_haystack","creator_name":"omniway","creator_url":"https://huggingface.co/omniway","description":"omniway/Audio_speaker_needle_in_haystack dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"mother_tongue_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MothersTongue/mother_tongue_dataset","creator_name":"Patronela  Tiwaringe ","creator_url":"https://huggingface.co/MothersTongue","description":"MothersTongue/mother_tongue_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Shona","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"yuyinmoxing","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/STONE11112/yuyinmoxing","creator_name":"X","creator_url":"https://huggingface.co/STONE11112","description":"STONE11112/yuyinmoxing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"chuvash_voice","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexantonov/chuvash_voice","creator_name":"Alexander Antonov","creator_url":"https://huggingface.co/alexantonov","description":"\n\t\n\t\t\n\t\tHow to use\n\t\n\nWe recommend using our dataset in conjunction with the Common Voice Corpus. We have attempted to maintain a consistent structure.\nfrom datasets import load_dataset, DatasetDict, concatenate_datasets, Audio\n\ncomm_voice = DatasetDict()\ncomm_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"train+validation\", use_auth_token=True)\ncomm_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"test\", use_auth_token=True)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexantonov/chuvash_voice.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chuvash","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"test-10-sec-zip_001","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Starky7/test-10-sec-zip_001","creator_name":"Starky Starr","creator_url":"https://huggingface.co/Starky7","description":"Starky7/test-10-sec-zip_001 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"MaxYuki","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MaxYuki/MaxYuki","creator_name":"Max Yuki","creator_url":"https://huggingface.co/MaxYuki","description":"MaxYuki/MaxYuki dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai_saamgwokjinji","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/zoengjyutgaai_saamgwokjinji","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑‰∏âÂúãÊºîÁæ©\n\t\n\nFork from laubonghaudoi/zoengjyutgaai_saamgwokjinji\nWe found the original wav files are not splitted correctly, so we asked the author to provide the srt file and un-splitted wav files. We then re-split the wav files and align the srt file to the wav files. We also filtered some samples that are too short.\nsubtitles = []\nsplits = librosa.effects.split(audio) # shape: (682, 2)\n\n!mkdir -p dataset/zoengjyutgaai_saamgwokjinji/wavs\n\n# split audio by srt time\nfor i, sub in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/zoengjyutgaai_saamgwokjinji.","first_N":5,"first_N_keywords":["Yue Chinese","cc0-1.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai_saamgwokjinji","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/zoengjyutgaai_saamgwokjinji","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑‰∏âÂúãÊºîÁæ©\n\t\n\nFork from laubonghaudoi/zoengjyutgaai_saamgwokjinji\nWe found the original wav files are not splitted correctly, so we asked the author to provide the srt file and un-splitted wav files. We then re-split the wav files and align the srt file to the wav files. We also filtered some samples that are too short.\nsubtitles = []\nsplits = librosa.effects.split(audio) # shape: (682, 2)\n\n!mkdir -p dataset/zoengjyutgaai_saamgwokjinji/wavs\n\n# split audio by srt time\nfor i, sub in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/zoengjyutgaai_saamgwokjinji.","first_N":5,"first_N_keywords":["Yue Chinese","cc0-1.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ja-audio-test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Joowonton/ja-audio-test","creator_name":"Joowon Ton","creator_url":"https://huggingface.co/Joowonton","description":"Joowonton/ja-audio-test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"coral-tts","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CoRal-project/coral-tts","creator_name":"CoRal","creator_url":"https://huggingface.co/CoRal-project","description":"\n\t\n\t\t\n\t\tDataset Card for CoRal TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of two professional Danish speakers, female and male, recording roughly 17 hours of Danish speech each.\nThe dataset is part of the CoRal project which is funded by the Danish Innovation Fund.\nThe text data was selected by the Alexandra Institute (Github repo for the dataset creation) and consists of sentences from sundhed.dk, borger.dk, names of bus stops and stations, manually filtered Reddit comments, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CoRal-project/coral-tts.","first_N":5,"first_N_keywords":["text-to-speech","Danish","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ViSQA_plus","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IAmSkyDra/ViSQA_plus","creator_name":"Long Nguyen Song Thien","creator_url":"https://huggingface.co/IAmSkyDra","description":"IAmSkyDra/ViSQA_plus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"esb-datasets-test-only-sorted","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/piotrzelasko/esb-datasets-test-only-sorted","creator_name":"Piotr ≈ªelasko","creator_url":"https://huggingface.co/piotrzelasko","description":"piotrzelasko/esb-datasets-test-only-sorted dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"sounds","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZeroWw/sounds","creator_name":"Robert Sinclair","creator_url":"https://huggingface.co/ZeroWw","description":"Sound Dataset\nUpdated on: Thu Jul 18, 18:09:58\n","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"threat_sounds","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tensorkelechi/threat_sounds","creator_name":"kelechic","creator_url":"https://huggingface.co/tensorkelechi","description":"tensorkelechi/threat_sounds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"freesound_audio_sm","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tensorkelechi/freesound_audio_sm","creator_name":"kelechic","creator_url":"https://huggingface.co/tensorkelechi","description":"tensorkelechi/freesound_audio_sm dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"UZ_voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/UZ_voice","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/UZ_voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"DFADD","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/isjwdu/DFADD","creator_name":"Jiawei Du","creator_url":"https://huggingface.co/isjwdu","description":"isjwdu/DFADD dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Slepn","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/0nexx/Slepn","creator_name":"Yaroslav","creator_url":"https://huggingface.co/0nexx","description":"0nexx/Slepn dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"STT_uz","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/STT_uz","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"The dataset is organized into the following directories and files:\naudio/\nother/: Contains .tar archives like uz_other_0.taruz_other_1.tar\ntrain/: Contains .tar archives like uz_train_0.tar.\nvalidated/: Contains .tar archives like uz_validated_0.tar, uz_validated_1.tar, and uz_validated_2.tar.\ntest/: Contains individual .wav files.\ntranscription/: Contains .tsv files including:\nother.tsv\ntrain.tsv\nvalidated.tsv\ntest.tsv\nThe .tsv files have two columns: file_name and transcription. Each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Beehzod/STT_uz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"STT_uz","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/STT_uz","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"The dataset is organized into the following directories and files:\naudio/\nother/: Contains .tar archives like uz_other_0.taruz_other_1.tar\ntrain/: Contains .tar archives like uz_train_0.tar.\nvalidated/: Contains .tar archives like uz_validated_0.tar, uz_validated_1.tar, and uz_validated_2.tar.\ntest/: Contains individual .wav files.\ntranscription/: Contains .tsv files including:\nother.tsv\ntrain.tsv\nvalidated.tsv\ntest.tsv\nThe .tsv files have two columns: file_name and transcription. Each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Beehzod/STT_uz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"uzbek_stt_data","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uzbek_stt_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uzbek_stt_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"moziila_common_voice_th","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pother/moziila_common_voice_th","creator_name":"t","creator_url":"https://huggingface.co/pother","description":"pother/moziila_common_voice_th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"PicoAudio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amphion/PicoAudio","creator_name":"Amphion","creator_url":"https://huggingface.co/amphion","description":"The dataset utilized in PicoAudio\n","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","json","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"FakeSound","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZeyuXie/FakeSound","creator_name":"Zeyu Xie","creator_url":"https://huggingface.co/ZeyuXie","description":"Dataset utilized in FakeSound\n","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Aris","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PotatoOff/Aris","creator_name":"Crunchy Potato","creator_url":"https://huggingface.co/PotatoOff","description":"Youtube Content\n","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"wordshk_cantonese_speech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/wordshk_cantonese_speech","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"AlienKevin/wordshk_cantonese_speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Tater-Ramirez","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aquillesdaamizade/Tater-Ramirez","creator_name":"Aquilles da Amizade","creator_url":"https://huggingface.co/aquillesdaamizade","description":"aquillesdaamizade/Tater-Ramirez dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"speaker-identification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"GTZAN_genre_classification","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/danilotpnta/GTZAN_genre_classification","creator_name":"Danilo Toapanta","creator_url":"https://huggingface.co/danilotpnta","description":"danilotpnta/GTZAN_genre_classification dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"catalan","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Trimux/catalan","creator_name":"Facundo Campos","creator_url":"https://huggingface.co/Trimux","description":"Trimux/catalan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Catalan","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"soda-audio","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fixie-ai/soda-audio","creator_name":"Ultravox.ai","creator_url":"https://huggingface.co/fixie-ai","description":"Parent dataset: SODA\nThe dataset was created based on SODA by first subsetting it and then adding two synthetic columns for training the Ultravox model:\n\nalt_last_turn: is an alternative for the last turn of the dialogue (dialogue[-1]) and was (re-)generated by Llama-3-8B Instruct;\naudio_one_but_last: is the TTS'd speech for the turn before the last one (dialogue[-2]) using the Eleven Labs voice API using a set of random voices.\n\n","first_N":5,"first_N_keywords":["machine-generated","monolingual","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"accent_CV","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/snousind/accent_CV","creator_name":"Sarayu Nousind","creator_url":"https://huggingface.co/snousind","description":"snousind/accent_CV dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Vehicle_sounds_classification_dataset","keyword":"audio","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/Vehicle_sounds_classification_dataset","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/Vehicle_sounds_classification_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["gpl-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ESLTTS","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/ESLTTS","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tESLTTS\n\t\n\nThe full paper can be accessed here: arXiv, IEEE Xplore.\n\n\t\n\t\t\n\t\tDataset Access\n\t\n\nYou can access this dataset through Huggingface or Google Driver or IEEE Dataport.\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nWith the progress made in speaker-adaptive TTS approaches, advanced approaches have shown a remarkable capacity to reproduce the speaker‚Äôs voice in the commonly used TTS datasets. However, mimicking voices characterized by substantial accents, such as non-native English speakers, is still‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/ESLTTS.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","English"],"keywords_longer_than_N":true},
	{"name":"ESLTTS","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/ESLTTS","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tESLTTS\n\t\n\nThe full paper can be accessed here: arXiv, IEEE Xplore.\n\n\t\n\t\t\n\t\tDataset Access\n\t\n\nYou can access this dataset through Huggingface or Google Driver or IEEE Dataport.\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nWith the progress made in speaker-adaptive TTS approaches, advanced approaches have shown a remarkable capacity to reproduce the speaker‚Äôs voice in the commonly used TTS datasets. However, mimicking voices characterized by substantial accents, such as non-native English speakers, is still‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/ESLTTS.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","English"],"keywords_longer_than_N":true},
	{"name":"ESLTTS","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/ESLTTS","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tESLTTS\n\t\n\nThe full paper can be accessed here: arXiv, IEEE Xplore.\n\n\t\n\t\t\n\t\tDataset Access\n\t\n\nYou can access this dataset through Huggingface or Google Driver or IEEE Dataport.\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nWith the progress made in speaker-adaptive TTS approaches, advanced approaches have shown a remarkable capacity to reproduce the speaker‚Äôs voice in the commonly used TTS datasets. However, mimicking voices characterized by substantial accents, such as non-native English speakers, is still‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/ESLTTS.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","English"],"keywords_longer_than_N":true},
	{"name":"ESLTTS","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/ESLTTS","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tESLTTS\n\t\n\nThe full paper can be accessed here: arXiv, IEEE Xplore.\n\n\t\n\t\t\n\t\tDataset Access\n\t\n\nYou can access this dataset through Huggingface or Google Driver or IEEE Dataport.\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nWith the progress made in speaker-adaptive TTS approaches, advanced approaches have shown a remarkable capacity to reproduce the speaker‚Äôs voice in the commonly used TTS datasets. However, mimicking voices characterized by substantial accents, such as non-native English speakers, is still‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/ESLTTS.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","English"],"keywords_longer_than_N":true},
	{"name":"open-identities","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jbilcke-hf/open-identities","creator_name":"Julian Bilcke","creator_url":"https://huggingface.co/jbilcke-hf","description":"A dataset of creative common identities (faces, voices, driving videos) you can use as actors in your Clapper project.\nThere are only a couple for now, but the goal is to reach at least 100-200 unique voices to be confortable with AI movie projects, so contributions are extremely welcome.\n","first_N":5,"first_N_keywords":["French","English","cc-by-sa-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"bengalese-finch-subset-with-csv-label","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nccratliri/bengalese-finch-subset-with-csv-label","creator_name":"TTF Datascience, NCCR@LiRI, UZH","creator_url":"https://huggingface.co/nccratliri","description":"nccratliri/bengalese-finch-subset-with-csv-label dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"aihub-132-preprocessed-test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/choejiin/aihub-132-preprocessed-test","creator_name":"choe yejin","creator_url":"https://huggingface.co/choejiin","description":"choejiin/aihub-132-preprocessed-test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"aihub-132-preprocessed-D20-1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/choejiin/aihub-132-preprocessed-D20-1","creator_name":"choe yejin","creator_url":"https://huggingface.co/choejiin","description":"ai hub Ïùò 132 Î≤à ÌöåÏùòÏùåÏÑ± Îç∞Ïù¥ÌÑ∞ÏÖãÏùò D20_0 Îç∞Ïù¥ÌÑ∞ÏÖã. Í∑∏Îü¨ÎÇò 16khz Í∞Ä ÏïÑÎãå 44.1khz Í∑∏ÎåÄÎ°ú Ïò¨Î†§Î≤ÑÎ†∏ÏäµÎãàÎã§\nwhisper Î•º ÌïôÏäµÌïòÍ∏∞ Ï†ÑÏóê 16khz Î°ú Ï†ÑÏ≤òÎ¶¨ Î∞è ÎùºÎ≤®ÎßÅ Îç∞Ïù¥ÌÑ∞Ïùò ÏòÅÏñ¥/Ïà´Ïûê -> ÌïúÍµ≠Ïñ¥ Î≥ÄÌòï, ÌäπÏàòÎ∂ÄÎ°ú Ï†úÍ±∞ ÌôïÏù∏ ÌïÑÏöî\n","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"aihub-132-preprocessed-D20-2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/choejiin/aihub-132-preprocessed-D20-2","creator_name":"choe yejin","creator_url":"https://huggingface.co/choejiin","description":"AI Hub 132 ÌöåÏùòÏùåÏÑ± Îç∞Ïù¥ÌÑ∞ÏÖãÏùò D20-1, D21_0 ÏùÑ ÌïúÎ≤àÏóê(...) Ïò¨Î¶∞ Îç∞Ïù¥ÌÑ∞\nwhisper Î•º ÌïôÏäµÌïòÍ∏∞ Ï†ÑÏóê ÎùºÎ≤®ÎßÅ Îç∞Ïù¥ÌÑ∞Ïùò ÏòÅÏñ¥/Ïà´Ïûê -> ÌïúÍµ≠Ïñ¥ Î≥ÄÌòï, ÌäπÏàòÎ∂ÄÌò∏ Ï†úÍ±∞ ÌôïÏù∏ ÌïÑÏöî\n","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"asrFineTune","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shailendra12/asrFineTune","creator_name":"shailendra","creator_url":"https://huggingface.co/Shailendra12","description":"Shailendra12/asrFineTune dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"instruction-speech-encodec-v1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Menlo/instruction-speech-encodec-v1","creator_name":"Menlo Research","creator_url":"https://huggingface.co/Menlo","description":"\n\t\n\t\t\n\t\tDataset Card for \"Instruction Speech\"\n\t\n\n\nThe largest open-source English speech instruction to text answer dataset\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains nearly 450,000 English speech instruction to text answer samples, using:\n\nA subset of OpenHermes 2.5 with user's prompt length less than 64.\nAudio generation using WhisperSpeech.\nTokenized using Encodec.\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset, Audio\n# Load Instruction Speech dataset\n\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Menlo/instruction-speech-encodec-v1.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","arrow","Audio"],"keywords_longer_than_N":true},
	{"name":"JessicaSimpsonRVCDataset","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mmaluchnick/JessicaSimpsonRVCDataset","creator_name":"Mack","creator_url":"https://huggingface.co/mmaluchnick","description":"mmaluchnick/JessicaSimpsonRVCDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"JessicaSimpsonRVCDataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mmaluchnick/JessicaSimpsonRVCDataset","creator_name":"Mack","creator_url":"https://huggingface.co/mmaluchnick","description":"mmaluchnick/JessicaSimpsonRVCDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"SpeechSeparation_MiniLibriMix","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/SpeechSeparation_MiniLibriMix","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"The MiniLibriMix dataset is a subset of LibriMix which is generated from LibriSpeech\nFiles used here were obtained from\nhttps://zenodo.org/records/3871592\n","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"BritneySpearsSpeakingDataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mmaluchnick/BritneySpearsSpeakingDataset","creator_name":"Mack","creator_url":"https://huggingface.co/mmaluchnick","description":"mmaluchnick/BritneySpearsSpeakingDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"aihub-132-preprocessed-D21-1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/choejiin/aihub-132-preprocessed-D21-1","creator_name":"choe yejin","creator_url":"https://huggingface.co/choejiin","description":"AI hub Ïùò 132 Î≤à ÌöåÏùòÏùåÏÑ± Îç∞Ïù¥ÌÑ∞ÏÖãÏùò D21_1 Îç∞Ïù¥ÌÑ∞ÏÖã.\nwhisper Î•º ÌïôÏäµÌïòÍ∏∞ Ï†ÑÏóêÎùºÎ≤®ÎßÅ Îç∞Ïù¥ÌÑ∞Ïùò ÏòÅÏñ¥/Ïà´Ïûê -> ÌïúÍµ≠Ïñ¥ Î≥ÄÌòï, ÌäπÏàòÎ∂ÄÌò∏ Ï†úÍ±∞ ÌôïÏù∏ ÌïÑÏöî\n","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ThirdToneSandhiRecognition_NCCUCorpusofSpokenTaiwanMandarin","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/ThirdToneSandhiRecognition_NCCUCorpusofSpokenTaiwanMandarin","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/ThirdToneSandhiRecognition_NCCUCorpusofSpokenTaiwanMandarin dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"jenny-tts-6h","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shacharu/jenny-tts-6h","creator_name":"Shachar Mendelowitz","creator_url":"https://huggingface.co/shacharu","description":"shacharu/jenny-tts-6h dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"commonvoice_16_1_bert_vits2","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/commonvoice_16_1_bert_vits2","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\n\t\n\t\t\n\t\tCantonese Common Voice 16.1 for Bert-VITS2 fine tuning format\n\t\n\nThis dataset contains 14.5 hours of validated speech data in Cantonese (yue and zh-hk) from the Common Voice project, but with some cleansing and fixing of common Chinese characters, and used facebook/seamless-m4t-v2-large to cross check the data. The dataset is in the format required for fine-tuning the Bert-VITS2.\nFor more detail of cleansing, fixing and filtering, please refer to the notebook.\n\n\t\n\t\t\n\t\n\t\n\t\tData format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/commonvoice_16_1_bert_vits2.","first_N":5,"first_N_keywords":["Yue Chinese","cc0-1.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"dstl_v3_ps_pseudo_labelled","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/koochikoo25/dstl_v3_ps_pseudo_labelled","creator_name":"Awais Nawaz","creator_url":"https://huggingface.co/koochikoo25","description":"koochikoo25/dstl_v3_ps_pseudo_labelled dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"profanity-speech-suroboyoan","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jaal047/profanity-speech-suroboyoan","creator_name":"Rijal Akhdan Khirulah","creator_url":"https://huggingface.co/Jaal047","description":"\n\t\n\t\t\n\t\tDataset Audio Perkataan Vulgar Bahasa Jawa Dialek Surabaya\n\t\n\n\n\t\n\t\t\n\t\tDeskripsi\n\t\n\nDataset ini berisi audio rekaman percakapan dalam bahasa Jawa dialek Surabaya yang mengandung perkataan vulgar. Setiap rekaman dilengkapi dengan transkripsi teks yang sesuai.Dataset ini dibuat sebagai bagian dari penelitian skripsi saya dengan tujuan untuk mendukung analisis dan pengembangan dalam bidang deteksi perkataan vulgar dalam bahasa Jawa dialek Surabaya menggunakan teknologi speech-to-text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jaal047/profanity-speech-suroboyoan.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Indonesian","Javanese","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"common","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/manjugeorge/common","creator_name":"Manju G","creator_url":"https://huggingface.co/manjugeorge","description":"manjugeorge/common dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","csv","Audio","Tabular"],"keywords_longer_than_N":true},
	{"name":"akosua_jed_twi_dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FarmerlineML/akosua_jed_twi_dataset","creator_name":"Farmerline","creator_url":"https://huggingface.co/FarmerlineML","description":"FarmerlineML/akosua_jed_twi_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"InstrumentCombinationRecognition_OpenMIC-2018","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/InstrumentCombinationRecognition_OpenMIC-2018","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/InstrumentCombinationRecognition_OpenMIC-2018 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"test1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xuefengs/test1","creator_name":"zhao","creator_url":"https://huggingface.co/xuefengs","description":"xuefengs/test1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"gender_audio_1080","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AsmaaQ/gender_audio_1080","creator_name":"Asmaa","creator_url":"https://huggingface.co/AsmaaQ","description":"\n\t\n\t\t\n\t\tDataset Card for mcv_spk_emb\n\t\n\n\n\nThis is the speaker embeddings (xvectors) of mozilla common voice_11 speakers, -with the original audios-. Vectors are extracted with speechBrain's xvector model using this script\nby concatinating 11 splits from MCV_11 making a set of 1080 different speakers and 30k audio samples using this script.\nThe main goal of this data was to train and test a voice gender detection classifier.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AsmaaQ/gender_audio_1080.","first_N":5,"first_N_keywords":["audio-classification","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"gender_audio_1080","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AsmaaQ/gender_audio_1080","creator_name":"Asmaa","creator_url":"https://huggingface.co/AsmaaQ","description":"\n\t\n\t\t\n\t\tDataset Card for mcv_spk_emb\n\t\n\n\n\nThis is the speaker embeddings (xvectors) of mozilla common voice_11 speakers, -with the original audios-. Vectors are extracted with speechBrain's xvector model using this script\nby concatinating 11 splits from MCV_11 making a set of 1080 different speakers and 30k audio samples using this script.\nThe main goal of this data was to train and test a voice gender detection classifier.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AsmaaQ/gender_audio_1080.","first_N":5,"first_N_keywords":["audio-classification","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"imagebind-example-data","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EduardoPacheco/imagebind-example-data","creator_name":"Eduardo Pacheco","creator_url":"https://huggingface.co/EduardoPacheco","description":"EduardoPacheco/imagebind-example-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"nurc-sp_pseudo_labelled-dev","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RodrigoLimaRFL/nurc-sp_pseudo_labelled-dev","creator_name":"Rodrigo de Freitas Lima","creator_url":"https://huggingface.co/RodrigoLimaRFL","description":"RodrigoLimaRFL/nurc-sp_pseudo_labelled-dev dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"google-la-voices","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ittailup/google-la-voices","creator_name":"Gabriel Puliatti","creator_url":"https://huggingface.co/ittailup","description":"\n\t\n\t\t\n\t\tDataset Card for \"google-la-voices\"\n\t\n\n\n\t\n\t\t\n\t\tSpeaker Durations\n\t\n\n\n\t\n\t\t\nSpeaker\nDuration (seconds)\n\n\n\t\t\n00295\n1606.144\n\n\n00610\n7026.261\n\n\n01208\n3284.907\n\n\n01523\n6309.888\n\n\n02121\n4687.445\n\n\n02436\n4654.080\n\n\n02484\n9379.925\n\n\n02485\n130.219\n\n\n03034\n5186.048\n\n\n03349\n5143.381\n\n\n03397\n7852.203\n\n\n03398\n118.101\n\n\n03853\n638.037\n\n\n04310\n8260.437\n\n\n04311\n105.472\n\n\n04766\n590.165\n\n\n05223\n8257.773\n\n\n05679\n846.251\n\n\n0613610207.707\n\n\n06592\n863.659\n\n\n07049\n7580.715\n\n\n07060\n575.659\n\n\n07505\n1743.531‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ittailup/google-la-voices.","first_N":5,"first_N_keywords":["Spanish","cc-by-sa-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"irescvtt","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/subahponraj/irescvtt","creator_name":"subahponraj","creator_url":"https://huggingface.co/subahponraj","description":"subahponraj/irescvtt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"CodecFake_wavs","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rogertseng/CodecFake_wavs","creator_name":"Yuan Tseng","creator_url":"https://huggingface.co/rogertseng","description":"\n\t\n\t\t\n\t\tCodecFake: Enhancing Anti-Spoofing Models Against Deepfake Audios from Codec-Based Speech Synthesis Systems\n\t\n\n  \n    Paper,\n    Code,\n    Project Page\n\n  \n    Interspeech 2024\n\n\nTL;DR: We show that better detection of deepfake speech from codec-based TTS systems can be achieved by training models on speech re-synthesized with neural audio codecs.\nThis dataset is released for this purpose.\nSee our paper and Github for more details on using our dataset.\n\n\t\n\t\n\t\n\t\tAcknowledgement‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rogertseng/CodecFake_wavs.","first_N":5,"first_N_keywords":["cc-by-4.0","Audio","arxiv:2406.07237","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"edacc_whisper","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sage-bergerson/edacc_whisper","creator_name":"Sage Bergerson","creator_url":"https://huggingface.co/sage-bergerson","description":"sage-bergerson/edacc_whisper dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"MW_MENTOR","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silvervieira/MW_MENTOR","creator_name":"Silver Vieira","creator_url":"https://huggingface.co/silvervieira","description":"silvervieira/MW_MENTOR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-openslr-80","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (OpenSLR-80)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual OpenSLR dataset. \nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof OpenSLR HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nOpenSLR is a site devoted to hosting speech and language resources, such as training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Dataset-AB-RN-ABKS","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mohammadsp99/Dataset-AB-RN-ABKS","creator_name":"Mohammad Sohrabipour","creator_url":"https://huggingface.co/mohammadsp99","description":"mohammadsp99/Dataset-AB-RN-ABKS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"up_test","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NOTSOFARDB/up_test","creator_name":"NOTSOFAR_DB","creator_url":"https://huggingface.co/NOTSOFARDB","description":"NOTSOFARDB/up_test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"parlament_parla_v3","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/parlament_parla_v3","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for ParlamentParla v3 - Speech Corpus of Catalan Parliamentary Sessions\n\t\n\nA speech corpus composed of Catalan Parliamentary Sessions.The v3 and last version of the corpus includes both clean and other quality segments, divided into short segments (less than 30 seconds) and long segments (more than 30 seconds). The total dataset encompasses 1059h 48m 04s of speech, including 945h 51m 06s for the short segments and 113h 56m 58s for the long segments, with a total of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/parlament_parla_v3.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Catalan","cc-by-4.0","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"audiocaps","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/inogii/audiocaps","creator_name":"I√±igo Varas","creator_url":"https://huggingface.co/inogii","description":"inogii/audiocaps dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"BIRDeep_AudioAnnotations","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GrunCrow/BIRDeep_AudioAnnotations","creator_name":"Alba M√°rquez-Rodr√≠guez","creator_url":"https://huggingface.co/GrunCrow","description":"\n\t\n\t\t\n\t\tBIRDeep Audio Annotations\n\t\n\n\n\nThe BIRDeep Audio Annotations dataset is a collection of bird vocalizations from Do√±ana National Park, Spain. It was created as part of the BIRDeep project, which aims to optimize the detection and classification of bird species in audio recordings using deep learning techniques. The dataset is intended for use in training and evaluating models for bird vocalization detection and identification.\nThe research code and further information is available at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GrunCrow/BIRDeep_AudioAnnotations.","first_N":5,"first_N_keywords":["audio-classification","English","Spanish","mit","n<1K"],"keywords_longer_than_N":true},
	{"name":"BIRDeep_AudioAnnotations","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GrunCrow/BIRDeep_AudioAnnotations","creator_name":"Alba M√°rquez-Rodr√≠guez","creator_url":"https://huggingface.co/GrunCrow","description":"\n\t\n\t\t\n\t\tBIRDeep Audio Annotations\n\t\n\n\n\nThe BIRDeep Audio Annotations dataset is a collection of bird vocalizations from Do√±ana National Park, Spain. It was created as part of the BIRDeep project, which aims to optimize the detection and classification of bird species in audio recordings using deep learning techniques. The dataset is intended for use in training and evaluating models for bird vocalization detection and identification.\nThe research code and further information is available at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GrunCrow/BIRDeep_AudioAnnotations.","first_N":5,"first_N_keywords":["audio-classification","English","Spanish","mit","n<1K"],"keywords_longer_than_N":true},
	{"name":"Tuda-De","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/uhhlt/Tuda-De","creator_name":"LT Group at UHH","creator_url":"https://huggingface.co/uhhlt","description":"\n\t\n\t\t\n\t\tOpen speech data for German speech recognition\n\t\n\nLanguage Technology, Universit√§t Hamburg, Germany\nhttps://www.inf.uni-hamburg.de/en/inst/ab/lt (formerly TU-Darmstadt)\nhttps://www.lt.tu-darmstadt.de\nTelecooperation labs, TU-Darmstadt, Germany\nhttps://www.tk.informatik.tu-darmstadt.de\n\n\t\n\t\t\n\t\n\t\n\t\tGeneral information\n\t\n\n\nThe speech data was collected in a controlled environment (same room, same microphone distances, etc. )\nDistance between speakers and the microphones is about 1 meter‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uhhlt/Tuda-De.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"eng_hindi_5k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmeraki/eng_hindi_5k","creator_name":"meraki","creator_url":"https://huggingface.co/cmeraki","description":"cmeraki/eng_hindi_5k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"audio-set-16khz","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/audio-set-16khz","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tRe-Upload\n\t\n\nThis repository is a re-upload of akgphysics/AudioSet in Parquet format, with all audio resampled to 16 KHz using torchaudio.transforms.Resample.\n\n\t\n\t\t\n\t\tAuthor's Description\n\t\n\n\nAudio Set: An ontology and human-labeled dataset for audio events\nAudio event recognition, the human-like ability to identify and relate sounds from audio, is a nascent problem in machine perception. Comparable problems such as object detection in images have reaped enormous benefits from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/audio-set-16khz.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"en_spontaneous_profanity","keyword":"audio","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Lameus/en_spontaneous_profanity","creator_name":"Ivan Smirnov","creator_url":"https://huggingface.co/Lameus","description":"Dataset from this article: Multimodal prediction of profanity based on speech analysis includes \"cleaned_cv.zip\" which consists of \"Common voice\" dataset's records with profanity speech. It can be treated as train data. \"collected_records.zip\" is manually collected from YouTube videos with spontaneous speech with profanity.\nAnnotation files have the names of files and transcribed speech.\nThe dataset was used to test solution for real-time profanity prediction, solution is located here: github‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lameus/en_spontaneous_profanity.","first_N":5,"first_N_keywords":["bsd-3-clause","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"SPIRE_EMA_CORPUS","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/viks66/SPIRE_EMA_CORPUS","creator_name":"Sathvik Udupa","creator_url":"https://huggingface.co/viks66","description":"This corpus contains paired data of speech, articulatory movements and phonemes. There are 38 speakers in the corpus, each with 460 utterances.\nThe raw audio files are in audios.zip. The ema data and preprocessed data is stored in processed.zip. The processed data can be loaded with pytorch and has the following keys - \n\nema_raw : The raw ema data\n\nema_clipped : The ema data after trimming using being-end time stamps\n\nema_trimmed_and_normalised_with_6_articulators: The ema data after trimming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/viks66/SPIRE_EMA_CORPUS.","first_N":5,"first_N_keywords":["cc-by-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"audiodata","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Subham1121/audiodata","creator_name":"Subham ","creator_url":"https://huggingface.co/Subham1121","description":"Subham1121/audiodata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ind_famal","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Majiang213/ind_famal","creator_name":"Majiang","creator_url":"https://huggingface.co/Majiang213","description":"Majiang213/ind_famal dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Indonesian","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Angry_Birds_Project_R_With_All_Versions","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIRBoat2876/Angry_Birds_Project_R_With_All_Versions","creator_name":"xHazardEpicly0824","creator_url":"https://huggingface.co/AIRBoat2876","description":"AIRBoat2876/Angry_Birds_Project_R_With_All_Versions dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"Human-Animal-Cartoon","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hdong51/Human-Animal-Cartoon","creator_name":"Hao Dong","creator_url":"https://huggingface.co/hdong51","description":"\n\t\n\t\t\n\t\n\t\n\t\tHuman-Animal-Cartoon dataset\n\t\n\nOur Human-Animal-Cartoon (HAC) dataset consists of seven actions (‚Äòsleeping‚Äô, ‚Äòwatching tv‚Äô, ‚Äòeating‚Äô, ‚Äòdrinking‚Äô, ‚Äòswimming‚Äô, ‚Äòrunning‚Äô, and ‚Äòopening door‚Äô) performed by humans, animals, and cartoon figures, forming three different domains. We collect 3381 video clips from the internet with around 1000 for each domain and provide three modalities in our dataset: video, audio, and pre-computed optical flow.\nThe dataset can be used for Multi-modal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hdong51/Human-Animal-Cartoon.","first_N":5,"first_N_keywords":["zero-shot-classification","English","apache-2.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"asr_bangla_2024","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/raiyan007/asr_bangla_2024","creator_name":"Raiyan Ahmed","creator_url":"https://huggingface.co/raiyan007","description":"raiyan007/asr_bangla_2024 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","100K - 1M","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"gujarati-interspeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/gujarati-interspeech","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\n\t\n\t\t\n\t\tGujarati Interspeech\n\t\n\nInterspeech data downloaded from https://github.com/Open-Speech-EkStep/ULCA-asr-dataset-corpus\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nGujarati Data (Most of the entries are <5 seconds and hence Whisper Models can be used for accurate timestamp prediction)\nAlso, the audio seems to have been spoken by a single person.\n\n","first_N":5,"first_N_keywords":["Gujarati","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"DomesticEnvironmentSoundEventDetection_DESED-PublicEval","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/DomesticEnvironmentSoundEventDetection_DESED-PublicEval","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/DomesticEnvironmentSoundEventDetection_DESED-PublicEval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TypicalAndSLI","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ManyaGupta/TypicalAndSLI","creator_name":"Manya Gupta","creator_url":"https://huggingface.co/ManyaGupta","description":"ManyaGupta/TypicalAndSLI dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"LSW1_The_Video_Game","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIRBoat2876/LSW1_The_Video_Game","creator_name":"xHazardEpicly0824","creator_url":"https://huggingface.co/AIRBoat2876","description":"AIRBoat2876/LSW1_The_Video_Game dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"nepali-number-speech-to-text","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bibek1129/nepali-number-speech-to-text","creator_name":"Bibek Thapa","creator_url":"https://huggingface.co/Bibek1129","description":"Bibek1129/nepali-number-speech-to-text dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"gujarati-f-openslr","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/gujarati-f-openslr","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\n\t\n\t\t\n\t\tGujarati OpenSLR Female\n\t\n\nInterspeech data downloaded from https://www.openslr.org/resources/78/gu_in_female.zip\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nGujarati Data (Most of the entries are <30 seconds and hence Whisper Models can be used for accurate timestamp prediction)\nAlso, the audio seems to have been spoken by a single female.\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Gujarati","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"openai-voices","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leafspark/openai-voices","creator_name":"leafspark","creator_url":"https://huggingface.co/leafspark","description":"\n\t\n\t\t\n\t\tOpenAI Voices\n\t\n\nA collection of TTS samples collected from the OpenAI API and app.\nCurrently the following voices are available:\n\nSky\nJuniper\n\nThese are not labeled, however they are clean lossless audio files, and may contain noise from the model.\nPlease refer to sky/statement.wav for the highest quality voice sample!\n","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Sample_Osho","keyword":"audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Barrstin/Sample_Osho","creator_name":"Barney Stinson","creator_url":"https://huggingface.co/Barrstin","description":"Barrstin/Sample_Osho dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["feature-extraction","English","artistic-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"quran-recitation-errors-test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sobolev210/quran-recitation-errors-test","creator_name":"Andrey Sobolev","creator_url":"https://huggingface.co/sobolev210","description":"sobolev210/quran-recitation-errors-test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ChildrenSLI","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ManyaGupta/ChildrenSLI","creator_name":"Manya Gupta","creator_url":"https://huggingface.co/ManyaGupta","description":"ManyaGupta/ChildrenSLI dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"mixed_shona_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kittech/mixed_shona_dataset","creator_name":"Bright Chirindo","creator_url":"https://huggingface.co/Kittech","description":"Kittech/mixed_shona_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text-classification","automatic-speech-recognition","Shona","English"],"keywords_longer_than_N":true},
	{"name":"ambience-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/igorriti/ambience-audio","creator_name":"Ignacio Ezequiel Gorriti","creator_url":"https://huggingface.co/igorriti","description":"\n\t\n\t\t\n\t\tAmbience audio dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was generated by scraping videos from prominent YouTube channels focused on ambient audio. The dataset includes a collection of videos that feature various ambient sounds, such as nature sounds, relaxing music, and environmental noises. For each video, essential metadata was extracted, and a caption was generated using an AI model to enhance the discoverability of the content. This dataset can be useful in various applications‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/igorriti/ambience-audio.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","csv","Image"],"keywords_longer_than_N":true},
	{"name":"ambience-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/igorriti/ambience-audio","creator_name":"Ignacio Ezequiel Gorriti","creator_url":"https://huggingface.co/igorriti","description":"\n\t\n\t\t\n\t\tAmbience audio dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was generated by scraping videos from prominent YouTube channels focused on ambient audio. The dataset includes a collection of videos that feature various ambient sounds, such as nature sounds, relaxing music, and environmental noises. For each video, essential metadata was extracted, and a caption was generated using an AI model to enhance the discoverability of the content. This dataset can be useful in various applications‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/igorriti/ambience-audio.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","csv","Image"],"keywords_longer_than_N":true},
	{"name":"MODELOSDETESTE","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Abcdefghijklmnopqrstuvwxyz12/MODELOSDETESTE","creator_name":"Samuel da Cruz Bastos ","creator_url":"https://huggingface.co/Abcdefghijklmnopqrstuvwxyz12","description":"Abcdefghijklmnopqrstuvwxyz12/MODELOSDETESTE dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"quiz_audio_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DrewMens/quiz_audio_dataset","creator_name":"Andrew Kojo Mensah-Onumah","creator_url":"https://huggingface.co/DrewMens","description":"DrewMens/quiz_audio_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts-100-v1","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mastermani305/tts-100-v1","creator_name":"Manikandan","creator_url":"https://huggingface.co/mastermani305","description":"mastermani305/tts-100-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-audio","Tamil","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-100-v1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mastermani305/tts-100-v1","creator_name":"Manikandan","creator_url":"https://huggingface.co/mastermani305","description":"mastermani305/tts-100-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-audio","Tamil","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Orpheus_Hearing","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BOB12311/Orpheus_Hearing","creator_name":"BOBSSSSSS","creator_url":"https://huggingface.co/BOB12311","description":"\n\t\n\t\t\n\t\tOrpheus Dataset: Enhanced Audio-to-ABC Notation Conversion\n\t\n\nThis dataset was specifically designed to train models for converting audio signals into ABC music notation, leveraging a customized workflow and mutation mechanisms specially designed with music theory.\nIt includes diverse musical scores, covering various styles and complexities, formatted to ensure consistency and usability in model training. The data has been carefully processed, cleaned, and augmented to support‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BOB12311/Orpheus_Hearing.","first_N":5,"first_N_keywords":["mit","10K - 100K","Audio","Text","arxiv:2410.17209"],"keywords_longer_than_N":true},
	{"name":"Porjai-Thai-voice-dataset-central","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMKL/Porjai-Thai-voice-dataset-central","creator_name":"CMKL University","creator_url":"https://huggingface.co/CMKL","description":"\n\t\n\t\t\n\t\tPorjai-Thai-voice-dataset-central\n\t\n\nThis corpus contains a officially split of 700 hours for Central Thai, and 40 hours for the three dialect each. The corpus is designed such that there are some parallel sentences between the dialects, making it suitable for Speech and Machine translation research.\nOur demo ASR model can be found at https://www.cmkl.ac.th/research/porjai. The Thai Central data was collected using Wang Data Market.\nSince parts of this corpus are in the ML-SUPERB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMKL/Porjai-Thai-voice-dataset-central.","first_N":5,"first_N_keywords":["Thai","cc-by-sa-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ru-vc-test","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alphacep/ru-vc-test","creator_name":"Alpha Cephei Inc","creator_url":"https://huggingface.co/alphacep","description":"Dataset to test Russian zero-short voice conversion\nBased on test subset of yt-vad-650-clean from https://github.com/GeorgeFedoseev/DeepSpeech\n","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DeepFakeVoiceRecognition_DEEP-VOICE","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/DeepFakeVoiceRecognition_DEEP-VOICE","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/DeepFakeVoiceRecognition_DEEP-VOICE dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"whisper-large-v3-sttt-btb-cy2en-evals","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DewiBrynJones/whisper-large-v3-sttt-btb-cy2en-evals","creator_name":"Dewi Bryn Jones","creator_url":"https://huggingface.co/DewiBrynJones","description":"Model: openai/whisper-large-v3\nTest Set: DewiBrynJones/banc-trawsgrifiadau-bangor\nSplit: translations\n\nBLEU:{'score': 17.989840438267308, 'counts': [5645, 2817, 1604, 957], 'totals': [13118, 12618, 12118, 11619], 'precisions': [43.03247446257051, 22.325249643366618, 13.236507674533751, 8.236509166021172], 'bp': 1.0, 'sys_len': 13118, 'ref_len': 12107}\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"LZHUA_ASR","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3FIRE/LZHUA_ASR","creator_name":"Fuhong Huang","creator_url":"https://huggingface.co/3FIRE","description":"3FIRE/LZHUA_ASR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mega-ssum","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/komats/mega-ssum","creator_name":"Kohei Matsuura","creator_url":"https://huggingface.co/komats","description":"\n\t\n\t\t\n\t\tMega-SSum\n\t\n\n\nA large-scale English sentence-wise speech summarization (Sen-SSum) dataset\nConsists of 3.8M+ synthesized speech, transcription, summary triplets\nDerived from the Gigaword dataset Rush+2015\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nThe dataset is divided into five splits: train/core/dev/eval/duc2003. (See below table)\nWe added a new evaluation split \"test\" for in-domain evaluation.\nThe train split is here: MegaSSum(train).\n\n\n\n\n\t\n\t\t\norig. data\nsplit\n#samples\n#speakers\ntotal dur. (hrs)\nave.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/komats/mega-ssum.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"soundutils_unittest","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/soundutils_unittest","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"\n\t\n\t\t\n\t\tUnittest Assets for SoundUtils\n\t\n\nAssests for unittest for deepghs/soundutils.\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Porjai-Thai-voice-dataset-korat","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMKL/Porjai-Thai-voice-dataset-korat","creator_name":"CMKL University","creator_url":"https://huggingface.co/CMKL","description":"\n\t\n\t\t\n\t\tPorjai-Thai-voice-dataset-korat\n\t\n\nThis corpus contains a officially split of 700 hours for Central Thai, and 40 hours for the three dialect each. The corpus is designed such that there are some parallel sentences between the dialects, making it suitable for Speech and Machine translation research.\nOur demo ASR model can be found at https://www.cmkl.ac.th/research/porjai. The Thai Central data was collected using Wang Data Market.\nSince parts of this corpus are in the ML-SUPERB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMKL/Porjai-Thai-voice-dataset-korat.","first_N":5,"first_N_keywords":["Thai","cc-by-sa-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"wolof_tts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galsenai/wolof_tts","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","description":"\n\t\n\t\t\n\t\tWolof TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a Wolof Text To Speech (TTS) dataset collected by Baamtu Datamation as part of the AI4D African language program. \nThe original dataset is hosted on Zenodo and it contains recordings from two (02) natif Wolof speakers (a male and female voice). Each speaker recored more than 20,000 sentences.\n\n\t\n\t\t\n\t\n\t\n\t\tSpeaking time:\n\t\n\n-- Male: 22h 28mn 41s\n-- Female: 18h 47mn 19s\n\nThe text dataset comes from news websites, Wikipedia and self‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/galsenai/wolof_tts.","first_N":5,"first_N_keywords":["text-to-speech","Wolof","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"test_case","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ceram1324/test_case","creator_name":"Tanad Singlow","creator_url":"https://huggingface.co/ceram1324","description":"ceram1324/test_case dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"korebaju_corpus","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/YuDZEN/korebaju_corpus","creator_name":"Yu CHEN","creator_url":"https://huggingface.co/YuDZEN","description":"\n\t\n\t\t\n\t\tThis is a Korebaju language dataset under construction.\n\t\n\ncheck https://github.com/YuDZEN/korebaju-ASR for the Kaldi and MFA project for the same project\n\n\t\n\t\t\n\t\tAudio Data\n\t\n\nAudio data is in the audio folder. The audio data is in the wav format.\n\n\t\n\t\t\n\t\tTranscription Data\n\t\n\nTranscription data is test.jsonl and train.jsonl in the racine folder. The transcription data is in the jsonl format.\n\n\t\n\t\t\n\t\tData Split\n\t\n\nThe data is split into train and test sets. \nThe train set contains 90%‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuDZEN/korebaju_corpus.","first_N":5,"first_N_keywords":["Koreguaje","mit","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"SFZBuilder-Factory-Library-Demo","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michl1149/SFZBuilder-Factory-Library-Demo","creator_name":"rab","creator_url":"https://huggingface.co/michl1149","description":"\n\t\n\t\t\n\t\tSFZBuilder Factory Library Demo\n\t\n\nA selection of public domain sample libraries in WAV format (except percussion, those are FLAC), intended but not limited to use for SFZBuilder or musical instruments. Curated samples to fit with SFZBuilder needs and SFZ files with mapping data.\n","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mit-impulse-response-survey","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/mit-impulse-response-survey","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAuthor's Description\n\t\n\n\nThese are environmental Impulse Responses (IRs) measured in the real-world IR survey as described in Traer and McDermott, PNAS, 2016.\nThe survey locations were selected by tracking the motions of 7 volunteers over the course of 2 weeks of daily life. We sent the volunteers 24 text messages every day at randomized times and asked the volunteers to respond with their location at the time the text was sent. We then retraced their steps and measured the acoustic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/mit-impulse-response-survey.","first_N":5,"first_N_keywords":["audio-to-audio","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"mit-impulse-response-survey","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/mit-impulse-response-survey","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAuthor's Description\n\t\n\n\nThese are environmental Impulse Responses (IRs) measured in the real-world IR survey as described in Traer and McDermott, PNAS, 2016.\nThe survey locations were selected by tracking the motions of 7 volunteers over the course of 2 weeks of daily life. We sent the volunteers 24 text messages every day at randomized times and asked the volunteers to respond with their location at the time the text was sent. We then retraced their steps and measured the acoustic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/mit-impulse-response-survey.","first_N":5,"first_N_keywords":["audio-to-audio","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"GawrGura_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AmazingToast/GawrGura_dataset","creator_name":"AmazingToast","creator_url":"https://huggingface.co/AmazingToast","description":"AmazingToast/GawrGura_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"audiollm-evals","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sarvamai/audiollm-evals","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"This evaluation set contains ~100 questions in both text and audio format in Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Odia, Punjabi, Tamil, and Telugu. We use this dataset internally at Sarvam to evaluate the performance of our audio models. We open-source this data to enable the research community to replicate the results mentioned in our Shuka blog.\nBy deisgn, the questions are sometimes vague, and the audio has noise and other inconsistencies, to measure the robustness of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/audiollm-evals.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"cv-ru-test-speaker","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FluentaAI/cv-ru-test-speaker","creator_name":"FluentaAI","creator_url":"https://huggingface.co/FluentaAI","description":"\n\t\n\t\t\n\t\tBenchmark for Speaker Similarity Evaluation in VC Systems for the Russian Language.\n\t\n\nBenchmark for speaker similarity evaluation based on the Common Voice dataset. \n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nThe dataset is based on the development (dev) portion of the Russian subset from the Common Voice dataset v18.0. The data are filtered according to the following conditions:\n\nFiles with a duration of less than 2 seconds are discarded.\nFiles that are empty after applying VAD‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FluentaAI/cv-ru-test-speaker.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"SUMM-RE","keyword":"voice-activity-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/SUMM-RE","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"Note: if the data viewer is not working, use the \"example\" subset.\n\n\t\n\t\t\n\t\tSUMM-RE\n\t\n\nThe SUMM-RE dataset is a collection of transcripts of French conversations, aligned with the audio signal.\nIt is a corpus of meeting-style conversations in French created for the purpose of the SUMM-RE project (ANR-20-CE23-0017). \nThe full dataset is described in Hunter et al. (2024): \"SUMM-RE: A corpus of French meeting-style conversations\".\n\nCreated by: Recording and manual correction of the corpus was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/SUMM-RE.","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","French","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SUMM-RE","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/SUMM-RE","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"Note: if the data viewer is not working, use the \"example\" subset.\n\n\t\n\t\t\n\t\tSUMM-RE\n\t\n\nThe SUMM-RE dataset is a collection of transcripts of French conversations, aligned with the audio signal.\nIt is a corpus of meeting-style conversations in French created for the purpose of the SUMM-RE project (ANR-20-CE23-0017). \nThe full dataset is described in Hunter et al. (2024): \"SUMM-RE: A corpus of French meeting-style conversations\".\n\nCreated by: Recording and manual correction of the corpus was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/SUMM-RE.","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","French","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"AgeClassification_CommonVoiceCorpus-Test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DynamicSuperb/AgeClassification_CommonVoiceCorpus-Test","creator_name":"Dynamic-SUPERB","creator_url":"https://huggingface.co/DynamicSuperb","description":"DynamicSuperb/AgeClassification_CommonVoiceCorpus-Test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ar-eg-dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DrAliGomaa/ar-eg-dataset","creator_name":"arabic_speech","creator_url":"https://huggingface.co/DrAliGomaa","description":"An in-progress dataset for arabic-egyptian-dialect, specifically made from transcripton of DrAliGomaa videos on youtube.\nDr Ali Gomaa is a famous Egyptian Islamic Scholar and he was the mufti of Egypt from 2003-2013\n\nLink to his youtube channel: https://www.youtube.com/@DrAliGomaa\nLink to his page on facebook: https://www.facebook.com/DrAliGomaa\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-full","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-full","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nYou are looking at the full dataset which contains 403,146 unique sounds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-full.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-full","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-full","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nYou are looking at the full dataset which contains 403,146 unique sounds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-full.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-full","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-full","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nYou are looking at the full dataset which contains 403,146 unique sounds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-full.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-large","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-large","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nYou are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-large.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-large","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-large","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nYou are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-large.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-large","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-large","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nYou are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-large.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-medium","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-medium","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nThe large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-medium.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-medium","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-medium","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nThe large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-medium.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-medium","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-medium","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nThe large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-medium.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-small","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-small","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nThe large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-small.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-small","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-small","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nThe large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-small.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-small","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-small","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nThe large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-small.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-tiny","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-tiny","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nThe large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-tiny.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-tiny","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-tiny","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nThe large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-tiny.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"freesound-laion-640k-commercial-16khz-tiny","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-tiny","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tAbout this Repository\n\t\n\nThis repository is the training split of the complete FreeSound LAION 640k dataset, limited only to licenses that permit commercial works, resampled to 16khz using torchaudio.transforms.Resample.\nThis is ideal for use cases where a variety of audio is desired but fidelity and labels are unnecessary, such as background audio for augmenting other datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Versions\n\t\n\n\nThe full dataset contains 403,146 unique sounds totaling 37.5 GB.\nThe large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/freesound-laion-640k-commercial-16khz-tiny.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"DEMAND-acoustic-noise","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/voice-biomarkers/DEMAND-acoustic-noise","creator_name":"Stan Kirdey","creator_url":"https://huggingface.co/voice-biomarkers","description":"About Dataset\nA database of 16-channel environmental noise recordings\nSource: https://www.kaggle.com/datasets/chrisfilo/demand\nLicense: CC-BY-4.0\nIntroduction\nMicrophone arrays, a (typically regular) arrangement of several microphones, allow for a number of interesting signal processing techniques. The correlation of audio signals from microphones that are located in close proximity with each other can, for example, be used to determine the spatial location of sound source relative to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/voice-biomarkers/DEMAND-acoustic-noise.","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"DEMAND-acoustic-noise","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/voice-biomarkers/DEMAND-acoustic-noise","creator_name":"Stan Kirdey","creator_url":"https://huggingface.co/voice-biomarkers","description":"About Dataset\nA database of 16-channel environmental noise recordings\nSource: https://www.kaggle.com/datasets/chrisfilo/demand\nLicense: CC-BY-4.0\nIntroduction\nMicrophone arrays, a (typically regular) arrangement of several microphones, allow for a number of interesting signal processing techniques. The correlation of audio signals from microphones that are located in close proximity with each other can, for example, be used to determine the spatial location of sound source relative to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/voice-biomarkers/DEMAND-acoustic-noise.","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"DEMAND-acoustic-noise","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/voice-biomarkers/DEMAND-acoustic-noise","creator_name":"Stan Kirdey","creator_url":"https://huggingface.co/voice-biomarkers","description":"About Dataset\nA database of 16-channel environmental noise recordings\nSource: https://www.kaggle.com/datasets/chrisfilo/demand\nLicense: CC-BY-4.0\nIntroduction\nMicrophone arrays, a (typically regular) arrangement of several microphones, allow for a number of interesting signal processing techniques. The correlation of audio signals from microphones that are located in close proximity with each other can, for example, be used to determine the spatial location of sound source relative to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/voice-biomarkers/DEMAND-acoustic-noise.","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"quran-audio","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nounouss2006/quran-audio","creator_name":"elmarra Nouss","creator_url":"https://huggingface.co/nounouss2006","description":"nounouss2006/quran-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"OseDialogs","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MakarMD/OseDialogs","creator_name":"Mariya","creator_url":"https://huggingface.co/MakarMD","description":"MakarMD/OseDialogs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","text-to-audio","Ossetian","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"OseDialogs","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MakarMD/OseDialogs","creator_name":"Mariya","creator_url":"https://huggingface.co/MakarMD","description":"MakarMD/OseDialogs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","text-to-audio","Ossetian","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"blossoming-white-mirror","keyword":"audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smolboy/blossoming-white-mirror","creator_name":"Sydney","creator_url":"https://huggingface.co/smolboy","description":"\n\t\n\t\t\n\t\tBlossoming White Mirror\n\t\n\n\nLicense: Artistic-2.0Dataset ID: smolboy/blossoming-white-mirror\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains a complete science-fiction novel and associated media assets, structured in four narrative phases:\n\nPolitical Thriller  \nTechno-Mystery  \nMythic Science Fiction  \nSpiritual Metaphysics\n\nIt is provided for reading, audio playback, and research into narrative structure and multimedia processing.\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\n\t\n\t\t\nFile\nType\nNotes\n\n\n\t\t\nNovel.pdf\nPDF‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smolboy/blossoming-white-mirror.","first_N":5,"first_N_keywords":["artistic-2.0","< 1K","imagefolder","Audio","Document"],"keywords_longer_than_N":true},
	{"name":"std-sqi-test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brity/std-sqi-test","creator_name":"Sipu Qi","creator_url":"https://huggingface.co/brity","description":"brity/std-sqi-test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"INDspeech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dzakybd/INDspeech","creator_name":"Dzaky Zakiyal Fawwaz","creator_url":"https://huggingface.co/dzakybd","description":"dzakybd/INDspeech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Indonesian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ay","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/etrrr/ay","creator_name":"Petr Pix","creator_url":"https://huggingface.co/etrrr","description":"etrrr/ay dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"rubbish","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zh-liu799/rubbish","creator_name":"Zihang Liu","creator_url":"https://huggingface.co/zh-liu799","description":"zh-liu799/rubbish dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts_turkce_kiper","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/omersaidd/tts_turkce_kiper","creator_name":"√ñmer Said Yilmaz","creator_url":"https://huggingface.co/omersaidd","description":"omersaidd/tts_turkce_kiper dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts_tur_kip","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/omersaidd/tts_tur_kip","creator_name":"√ñmer Said Yilmaz","creator_url":"https://huggingface.co/omersaidd","description":"omersaidd/tts_tur_kip dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"swiss-ner","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/i4ds/swiss-ner","creator_name":"Institute for Data Science","creator_url":"https://huggingface.co/i4ds","description":"SwissNER-Spoken is a curated collection of 173 short, spoken-style German sentences\n    designed to evaluate Named-Entity Recognition (NER) and Automatic Speech Recognition (ASR)\n    systems on Swiss-specific proper nouns.\n\n\t\n\t\t\n\t\tKey features\n\t\n\n‚Ä¢ Focus on Switzerland ‚Äì Every sentence contains up to three named entities that appear\nin everyday Swiss contexts: cities, villages, cantons, companies, mountains, lakes,\nrivers, landmarks, organizations, events and well-known personalities.\n‚Ä¢‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/i4ds/swiss-ner.","first_N":5,"first_N_keywords":["German","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"OseProverb_Voice","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MakarMD/OseProverb_Voice","creator_name":"Mariya","creator_url":"https://huggingface.co/MakarMD","description":"MakarMD/OseProverb_Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","text-to-audio","Ossetian","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"OseProverb_Voice","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MakarMD/OseProverb_Voice","creator_name":"Mariya","creator_url":"https://huggingface.co/MakarMD","description":"MakarMD/OseProverb_Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","text-to-audio","Ossetian","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tüéØ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tüéØ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tüéØ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CREAMAD-transcribed","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenitsu09/CREAMAD-transcribed","creator_name":"Himanshu Gangwar","creator_url":"https://huggingface.co/zenitsu09","description":"zenitsu09/CREAMAD-transcribed dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"libriSpeech_phoneme","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cheikh1499/libriSpeech_phoneme","creator_name":"cheikh Sadibou SIDIBE","creator_url":"https://huggingface.co/cheikh1499","description":"cheikh1499/libriSpeech_phoneme dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"sample_zx1","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/capsul1912/sample_zx1","creator_name":"capsul","creator_url":"https://huggingface.co/capsul1912","description":"\n\t\n\t\t\n\t\tUzbek Speech Transcription Dataset\n\t\n\nThis dataset contains Uzbek speech audio chunks with their transcriptions. The audio files are automatically segmented using VAD (Voice Activity Detection).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate) - playable in the dataset viewer\ntext: Uzbek transcription text\nchunk_id: Unique identifier for the audio chunk\nvideo_id: YouTube video ID\nchannel_name: YouTube channel name\nvideo_title:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/capsul1912/sample_zx1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"sample_zx1","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/capsul1912/sample_zx1","creator_name":"capsul","creator_url":"https://huggingface.co/capsul1912","description":"\n\t\n\t\t\n\t\tUzbek Speech Transcription Dataset\n\t\n\nThis dataset contains Uzbek speech audio chunks with their transcriptions. The audio files are automatically segmented using VAD (Voice Activity Detection).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate) - playable in the dataset viewer\ntext: Uzbek transcription text\nchunk_id: Unique identifier for the audio chunk\nvideo_id: YouTube video ID\nchannel_name: YouTube channel name\nvideo_title:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/capsul1912/sample_zx1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"speaker-identification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"y","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GAS17/y","creator_name":"gasgas","creator_url":"https://huggingface.co/GAS17","description":"GAS17/y dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"free-music-archive-commercial-16khz-full","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/free-music-archive-commercial-16khz-full","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tFMA: A Dataset for Music Analysis\n\t\n\nMicha√´l Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson.\nInternational Society for Music Information Retrieval Conference (ISMIR), 2017.\n\nWe introduce the Free Music Archive (FMA), an open and easily accessible dataset suitable for evaluating several tasks in MIR, a field concerned with browsing, searching, and organizing large music collections. The community's growing interest in feature and end-to-end learning is however restrained‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/free-music-archive-commercial-16khz-full.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"free-music-archive-commercial-16khz-full","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/free-music-archive-commercial-16khz-full","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tFMA: A Dataset for Music Analysis\n\t\n\nMicha√´l Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson.\nInternational Society for Music Information Retrieval Conference (ISMIR), 2017.\n\nWe introduce the Free Music Archive (FMA), an open and easily accessible dataset suitable for evaluating several tasks in MIR, a field concerned with browsing, searching, and organizing large music collections. The community's growing interest in feature and end-to-end learning is however restrained‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/free-music-archive-commercial-16khz-full.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"free-music-archive-commercial-16khz-full","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjamin-paine/free-music-archive-commercial-16khz-full","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","description":"\n\t\n\t\t\n\t\tFMA: A Dataset for Music Analysis\n\t\n\nMicha√´l Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson.\nInternational Society for Music Information Retrieval Conference (ISMIR), 2017.\n\nWe introduce the Free Music Archive (FMA), an open and easily accessible dataset suitable for evaluating several tasks in MIR, a field concerned with browsing, searching, and organizing large music collections. The community's growing interest in feature and end-to-end learning is however restrained‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/free-music-archive-commercial-16khz-full.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"voxa","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MAdel121/voxa","creator_name":"MAdel","creator_url":"https://huggingface.co/MAdel121","description":"MAdel121/voxa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TTSEval_v2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ClaudeChen/TTSEval_v2","creator_name":"ClaudeChen","creator_url":"https://huggingface.co/ClaudeChen","description":"ClaudeChen/TTSEval_v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"output","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nevreal/output","creator_name":"neva","creator_url":"https://huggingface.co/nevreal","description":"nevreal/output dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"TTSEval_longtext_v2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ClaudeChen/TTSEval_longtext_v2","creator_name":"ClaudeChen","creator_url":"https://huggingface.co/ClaudeChen","description":"ClaudeChen/TTSEval_longtext_v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ssi-speech-emotion-recognition","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stapesai/ssi-speech-emotion-recognition","creator_name":"Stapes AI","creator_url":"https://huggingface.co/stapesai","description":"\n\t\n\t\t\n\t\tDataset Card for SSI: Speech Emotion Recognition - Stapes AI\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Format for Audio Files\n\t\n\nThis is the format for the audio files in the dataset. We'll open-source the dataset soon.\n\n\t\n\t\t\n\t\tGender\n\t\n\n\nM - Male\nF - Female\n\n\n\t\n\t\t\n\t\tAge Group\n\t\n\n\nCH - Child (0-12)\nTE - Teenager (13-19)\nAD - Adult (20-60)\nSE - Senior (60+)\nUNK - Unknown\n\n\n\t\n\t\t\n\t\tUtterance Type\n\t\n\n\nSEN: Sentence\nWOR: Word\nPHR: Phrase\n\n\n\t\n\t\t\n\t\tSentence\n\t\n\n\nDFA: \"Don't Forget A‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stapesai/ssi-speech-emotion-recognition.","first_N":5,"first_N_keywords":["English","Hindi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"speech-to-text","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LeVy4/speech-to-text","creator_name":"Le Thao Vy","creator_url":"https://huggingface.co/LeVy4","description":"LeVy4/speech-to-text dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"CMM","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DAMO-NLP-SG/CMM","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\n\t\n\t\t\n\t\tThe Curse of Multi-Modalities (CMM) Dataset Card\n\t\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nDataset type:\nCMM is a curated benchmark designed to evaluate hallucination vulnerabilities in Large Multi-Modal Models (LMMs). It is constructed to rigorously test LMMs‚Äô capabilities across visual, audio, and language modalities, focusing on hallucinations arising from inter-modality spurious correlations and uni-modal over-reliance.\nDataset detail:\nCMM introduces 2,400 probing questions across 1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/CMM.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","audio-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"CMM","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DAMO-NLP-SG/CMM","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\n\t\n\t\t\n\t\tThe Curse of Multi-Modalities (CMM) Dataset Card\n\t\n\n\n    \n\n\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nDataset type:\nCMM is a curated benchmark designed to evaluate hallucination vulnerabilities in Large Multi-Modal Models (LMMs). It is constructed to rigorously test LMMs‚Äô capabilities across visual, audio, and language modalities, focusing on hallucinations arising from inter-modality spurious correlations and uni-modal over-reliance.\nDataset detail:\nCMM introduces 2,400 probing questions across 1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/CMM.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","audio-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"VC_Eval","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ClaudeChen/VC_Eval","creator_name":"ClaudeChen","creator_url":"https://huggingface.co/ClaudeChen","description":"ClaudeChen/VC_Eval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"urdu_tts_hf_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omarrran/urdu_tts_hf_dataset","creator_name":"HAQ NAWAZ MALIK","creator_url":"https://huggingface.co/Omarrran","description":"Omarrran/urdu_tts_hf_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Urdu","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Malagasy","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AndryNirina/Malagasy","creator_name":"ANDRIANARISON","creator_url":"https://huggingface.co/AndryNirina","description":"\n\t\n\t\t\n\t\tDataset for ASR\n\t\n\n\n\t\n\t\t\n\t\tSource :\n\t\n\n\nNy Baiboly\n\n","first_N":5,"first_N_keywords":["Malagasy","mit","< 1K","csv","Audio"],"keywords_longer_than_N":true},
	{"name":"ManaAudioV2","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/Th3ro/ManaAudioV2","creator_name":"Thero","creator_url":"https://huggingface.co/Th3ro","description":"Th3ro/ManaAudioV2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"znanio-audios","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/znanio-audios","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Znanio.ru Educational Audio\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 3,417 educational audio files from the znanio.ru platform, a resource for teachers, educators, students, and parents providing diverse educational content. Znanio.ru has been a pioneer in educational technologies and distance learning in the Russian-speaking internet since 2009.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, with potential multilingual content:\n\nRussian (ru): The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/znanio-audios.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"znanio-audios","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/znanio-audios","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Znanio.ru Educational Audio\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 3,417 educational audio files from the znanio.ru platform, a resource for teachers, educators, students, and parents providing diverse educational content. Znanio.ru has been a pioneer in educational technologies and distance learning in the Russian-speaking internet since 2009.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, with potential multilingual content:\n\nRussian (ru): The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/znanio-audios.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"znanio-audios","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/znanio-audios","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Znanio.ru Educational Audio\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 3,417 educational audio files from the znanio.ru platform, a resource for teachers, educators, students, and parents providing diverse educational content. Znanio.ru has been a pioneer in educational technologies and distance learning in the Russian-speaking internet since 2009.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, with potential multilingual content:\n\nRussian (ru): The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/znanio-audios.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"MixEval-X","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MixEval/MixEval-X","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","description":"\n\n\nüöÄ Project Page | üìú arXiv | üë®‚Äçüíª Github | üèÜ Leaderboard | üìù blog | ü§ó HF Paper | ùïè Twitter\n\n\n\n\n\n\n\nMixEval-X encompasses eight input-output modality combinations and can be further extended. Its data points reflect real-world task distributions. The last grid presents the scores of frontier organizations‚Äô flagship models on MixEval-X, normalized to a 0-100 scale, with MMG tasks using win rates instead of Elo. Section C of the paper presents example data samples and model responses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval-X.","first_N":5,"first_N_keywords":["image-to-text","video-text-to-text","audio-classification","text-generation","text-to-audio"],"keywords_longer_than_N":true},
	{"name":"MixEval-X","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MixEval/MixEval-X","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","description":"\n\n\nüöÄ Project Page | üìú arXiv | üë®‚Äçüíª Github | üèÜ Leaderboard | üìù blog | ü§ó HF Paper | ùïè Twitter\n\n\n\n\n\n\n\nMixEval-X encompasses eight input-output modality combinations and can be further extended. Its data points reflect real-world task distributions. The last grid presents the scores of frontier organizations‚Äô flagship models on MixEval-X, normalized to a 0-100 scale, with MMG tasks using win rates instead of Elo. Section C of the paper presents example data samples and model responses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval-X.","first_N":5,"first_N_keywords":["image-to-text","video-text-to-text","audio-classification","text-generation","text-to-audio"],"keywords_longer_than_N":true},
	{"name":"MixEval-X","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MixEval/MixEval-X","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","description":"\n\n\nüöÄ Project Page | üìú arXiv | üë®‚Äçüíª Github | üèÜ Leaderboard | üìù blog | ü§ó HF Paper | ùïè Twitter\n\n\n\n\n\n\n\nMixEval-X encompasses eight input-output modality combinations and can be further extended. Its data points reflect real-world task distributions. The last grid presents the scores of frontier organizations‚Äô flagship models on MixEval-X, normalized to a 0-100 scale, with MMG tasks using win rates instead of Elo. Section C of the paper presents example data samples and model responses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval-X.","first_N":5,"first_N_keywords":["image-to-text","video-text-to-text","audio-classification","text-generation","text-to-audio"],"keywords_longer_than_N":true},
	{"name":"productllm","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nolimtmide6x/productllm","creator_name":"sabiAI","creator_url":"https://huggingface.co/nolimtmide6x","description":"nolimtmide6x/productllm dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"AudioSetCaps","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/baijs/AudioSetCaps","creator_name":"Jisheng Bai","creator_url":"https://huggingface.co/baijs","description":"\n\t\n\t\t\n\t\tAudioSetCaps: An Enriched Audio-Caption Dataset using Automated Generation Pipeline with Large Audio and Language Models\n\t\n\n\nNeurIPS 2024 Workshop Paper \nGithub\n\n\nThis repo contains captions for 6,117,099 10-second audio files, sourcing from AudioSet, YouTube-8M and VGGSound.\nWe also provide our intermediate Q&A result for each audio (18,414,789 paired Q&A data in total).\n\nWe hope AudioSetCaps can facilitate the scaling up of future Audio-Language multimodal research.\n‚ÄºÔ∏è AudioCaps and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/baijs/AudioSetCaps.","first_N":5,"first_N_keywords":["cc-by-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Hack49-Alzheimer-Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/codejedi/Hack49-Alzheimer-Dataset","creator_name":"Darcy Daxi Liu","creator_url":"https://huggingface.co/codejedi","description":"codejedi/Hack49-Alzheimer-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"voicebench","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hlt-lab/voicebench","creator_name":"Human Language Technology Lab @ NUS","creator_url":"https://huggingface.co/hlt-lab","description":"\n\t\n\t\t\n\t\tLicense\n\t\n\nThe dataset is available under the Apache 2.0 license.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use the VoiceBench dataset in your research, please cite the following paper:\n@article{chen2024voicebench,\n  title={VoiceBench: Benchmarking LLM-Based Voice Assistants},\n  author={Chen, Yiming and Yue, Xianghu and Zhang, Chen and Gao, Xiaoxue and Tan, Robby T. and Li, Haizhou},\n  journal={arXiv preprint arXiv:2410.17196},\n  year={2024}\n}\n\n","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"TTS_English_Technical_Terms","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Shabdobhedi/TTS_English_Technical_Terms","creator_name":"Manas Pratim Kundu","creator_url":"https://huggingface.co/Shabdobhedi","description":"Shabdobhedi/TTS_English_Technical_Terms dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"CV18-THCenter","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MagiBoss/CV18-THCenter","creator_name":"Mongkol Boondamnoen","creator_url":"https://huggingface.co/MagiBoss","description":"MagiBoss/CV18-THCenter dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Whisper-train-data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tarakeshwaran/Whisper-train-data","creator_name":"Tarakeshwaran","creator_url":"https://huggingface.co/Tarakeshwaran","description":"Tarakeshwaran/Whisper-train-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ami-disfluent","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/ami-disfluent","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/ami-disfluent dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Fenrir-Voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Fenrir-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Fenrir-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Trending-Song","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FutureMa/Trending-Song","creator_name":"MaShijian","creator_url":"https://huggingface.co/FutureMa","description":"FutureMa/Trending-Song dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Alexis","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Alexis","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Alexis dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dr_andrew_Huberman_eng_tts_hf_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omarrran/dr_andrew_Huberman_eng_tts_hf_dataset","creator_name":"HAQ NAWAZ MALIK","creator_url":"https://huggingface.co/Omarrran","description":"\n\t\n\t\t\n\t\tOmarrran/dr_andrew_Huberman_eng_tts_hf_dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains English text-to-speech (TTS) data, including paired text and audio files.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal number of samples: 3159\nNumber of samples in train split: 2527\nNumber of samples in test split: 632\n\n\n\t\n\t\t\n\t\tAudio Statistics\n\t\n\n\nTotal audio duration: 31563.23 seconds (8.77 hours)\nAverage audio duration: 9.99 seconds\nMinimum audio duration: 1.09 seconds\nMaximum audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Omarrran/dr_andrew_Huberman_eng_tts_hf_dataset.","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dr_andrew_Huberman_yt_tts_hf_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omarrran/dr_andrew_Huberman_yt_tts_hf_dataset","creator_name":"HAQ NAWAZ MALIK","creator_url":"https://huggingface.co/Omarrran","description":"Omarrran/dr_andrew_Huberman_yt_tts_hf_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"HeightCeleb","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stachu86/HeightCeleb","creator_name":"Stanis≈Çaw Kacprzak","creator_url":"https://huggingface.co/stachu86","description":"\n\t\n\t\t\n\t\tHeightCeleb\n\t\n\nThis repository contains the dataset described in article \"HeightCeleb - an enrichment of VoxCeleb dataset with speaker height information\",\nwhich was presented at SLT 2024 conference in Macau, China.\nThe dataset is an extension to Voxceleb dataset and contains\nheight information that was scraped from the Internet.\n\n\t\n\t\t\n\t\n\t\n\t\tLive demo of system trained with HeightCeleb\n\t\n\nDemo system deployed in HuggingFace Spaces\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Attribution\n\t\n\nHeightCeleb dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stachu86/HeightCeleb.","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"EGY2K","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahafvii/EGY2K","creator_name":"xx","creator_url":"https://huggingface.co/rahafvii","description":"rahafvii/EGY2K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"EGY2K","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahafvii/EGY2K","creator_name":"xx","creator_url":"https://huggingface.co/rahafvii","description":"rahafvii/EGY2K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"LJSpeech_speaker","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Reeya112/LJSpeech_speaker","creator_name":"Riya Yadav","creator_url":"https://huggingface.co/Reeya112","description":"Reeya112/LJSpeech_speaker dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"LibriSpeechSmall_","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CharlesLeclarc/LibriSpeechSmall_","creator_name":"Hadia Arshad","creator_url":"https://huggingface.co/CharlesLeclarc","description":"CharlesLeclarc/LibriSpeechSmall_ dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"laion-audio-preview","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/laion-audio-preview","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"laion/laion-audio-preview dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Tereshuk","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Warlock700/Tereshuk","creator_name":"Warlock700","creator_url":"https://huggingface.co/Warlock700","description":"Warlock700/Tereshuk dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Plahov","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Warlock700/Plahov","creator_name":"Warlock700","creator_url":"https://huggingface.co/Warlock700","description":"Warlock700/Plahov dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Uzbek_Speech_Corpus","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tUzbek Speech Corpus (USC)\n\t\n\nPaper: USC: An Open-Source Uzbek Speech Corpus and Initial Speech Recognition Experiments\nSummary: This repository contains dataset for reproducing the results presented in the paper \"USC: An Open-Source Uzbek Speech Corpus\". USC is a freely available, manually checked speech corpus comprising 958 speakers and 105 hours of transcribed audio recordings. \nDataset Summary:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nLanguage\nUzbek\n\n\nSize\n105 hours of audio\n\n\nNumber of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Uzbek_Speech_Corpus","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tUzbek Speech Corpus (USC)\n\t\n\nPaper: USC: An Open-Source Uzbek Speech Corpus and Initial Speech Recognition Experiments\nSummary: This repository contains dataset for reproducing the results presented in the paper \"USC: An Open-Source Uzbek Speech Corpus\". USC is a freely available, manually checked speech corpus comprising 958 speakers and 105 hours of transcribed audio recordings. \nDataset Summary:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nLanguage\nUzbek\n\n\nSize\n105 hours of audio\n\n\nNumber of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Multilingual_Speech_Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tMultilingual Speech Dataset\n\t\n\nPaper: A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\nRepository: https://github.com/IS2AI/MultilingualASR\nDescription: This repository provides the dataset used in the paper \"A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\". The paper focuses on training a single end-to-end (E2E) ASR model for Kazakh, Russian, and English, comparing monolingual and multilingual approaches‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","Russian","English","mit"],"keywords_longer_than_N":true},
	{"name":"Multilingual_Speech_Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tMultilingual Speech Dataset\n\t\n\nPaper: A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\nRepository: https://github.com/IS2AI/MultilingualASR\nDescription: This repository provides the dataset used in the paper \"A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\". The paper focuses on training a single end-to-end (E2E) ASR model for Kazakh, Russian, and English, comparing monolingual and multilingual approaches‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","Russian","English","mit"],"keywords_longer_than_N":true},
	{"name":"Kazakh_Speech_Corpus_2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tKazakh Speech Corpus 2 (KSC2)\n\t\n\nThis dataset card describes the KSC2, an industrial-scale, open-source speech corpus for the Kazakh language.\nPaper: KSC2: An Industrial-Scale Open-Source Kazakh Speech Corpus\nSummary: KSC2 corpus subsumes the previously introduced two corpora: Kazakh Speech Corpus and Kazakh Text-To-Speech 2, and supplements additional data from other sources like tv programs, radio, senate, and podcasts. In total, KSC2 contains around 1.2k hours of high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Kazakh_Speech_Corpus_2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tKazakh Speech Corpus 2 (KSC2)\n\t\n\nThis dataset card describes the KSC2, an industrial-scale, open-source speech corpus for the Kazakh language.\nPaper: KSC2: An Industrial-Scale Open-Source Kazakh Speech Corpus\nSummary: KSC2 corpus subsumes the previously introduced two corpora: Kazakh Speech Corpus and Kazakh Text-To-Speech 2, and supplements additional data from other sources like tv programs, radio, senate, and podcasts. In total, KSC2 contains around 1.2k hours of high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"audiosnippets_long_50k","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mitermix/audiosnippets_long_50k","creator_name":"Miter Mix","creator_url":"https://huggingface.co/mitermix","description":"mitermix/audiosnippets_long_50k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"GDSC_common_voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GDSC-NTNU/GDSC_common_voice","creator_name":"GDSC NTNU","creator_url":"https://huggingface.co/GDSC-NTNU","description":"GDSC-NTNU/GDSC_common_voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"my-speech-dataset-hr","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mmuz1/my-speech-dataset-hr","creator_name":"Mia","creator_url":"https://huggingface.co/mmuz1","description":"mmuz1/my-speech-dataset-hr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts-2-12-24","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Irathernotsay/tts-2-12-24","creator_name":"Shobhit Sharma","creator_url":"https://huggingface.co/Irathernotsay","description":"Irathernotsay/tts-2-12-24 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"whisper-large-v3-ec-eval-ec","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/whisper-large-v3-ec-eval-ec","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"Model: wanasash/whisper-large-v3-ec\nTest Set: wanasash/enwaucymraeg\nSplit: test\n\nWER: 28.331177\nCER: 7.949406\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"whisper-large-v3-ec-eval-cv","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/whisper-large-v3-ec-eval-cv","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"Model: wanasash/whisper-large-v3-ec\nTest Set: DewiBrynJones/commonvoice_18_0_cy\nSplit: test\n\nWER: 38.786166\nCER: 11.659708\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"whisper-large-v2-eval-cv","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/whisper-large-v2-eval-cv","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"Model: openai/whisper-large-v2\nTest Set: DewiBrynJones/commonvoice_18_0_cy\nSplit: test\n\nWER: 41.304748\nCER: 16.138398\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"youtube_audio_samples","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hanifa-fy/youtube_audio_samples","creator_name":"Hanifa Fakhriza Yaroh","creator_url":"https://huggingface.co/hanifa-fy","description":"hanifa-fy/youtube_audio_samples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["afl-3.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Ar-MUSA","keyword":"audio-classification","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Skhaled/Ar-MUSA","creator_name":"Salma Khaled Ali","creator_url":"https://huggingface.co/Skhaled","description":"\n\t\n\t\t\n\t\tData Directory Structure\n\t\n\nThe Ar-MUSA directory contains annotated datasets organized by batches and annotation teams. Each batch is labeled with a number, and the annotation team is indicated by a letter. The structure is as follows:\nAr-MUSA\n‚îú‚îÄ‚îÄ Annotation 1a\n‚îÇ   ‚îú‚îÄ‚îÄ frames        # Contains the extracted frames for each record\n‚îÇ   ‚îú‚îÄ‚îÄ audios        # Contains the corresponding audio files\n‚îÇ   ‚îú‚îÄ‚îÄ transcripts   # Contains the transcripts of the audio files\n‚îÇ   ‚îî‚îÄ‚îÄ annotations.csv  #‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Skhaled/Ar-MUSA.","first_N":5,"first_N_keywords":["text-classification","audio-classification","image-classification","Arabic","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"Ar-MUSA","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Skhaled/Ar-MUSA","creator_name":"Salma Khaled Ali","creator_url":"https://huggingface.co/Skhaled","description":"\n\t\n\t\t\n\t\tData Directory Structure\n\t\n\nThe Ar-MUSA directory contains annotated datasets organized by batches and annotation teams. Each batch is labeled with a number, and the annotation team is indicated by a letter. The structure is as follows:\nAr-MUSA\n‚îú‚îÄ‚îÄ Annotation 1a\n‚îÇ   ‚îú‚îÄ‚îÄ frames        # Contains the extracted frames for each record\n‚îÇ   ‚îú‚îÄ‚îÄ audios        # Contains the corresponding audio files\n‚îÇ   ‚îú‚îÄ‚îÄ transcripts   # Contains the transcripts of the audio files\n‚îÇ   ‚îî‚îÄ‚îÄ annotations.csv  #‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Skhaled/Ar-MUSA.","first_N":5,"first_N_keywords":["text-classification","audio-classification","image-classification","Arabic","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"audio-classification","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and merges‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and merges‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"heck","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/superdrew100/heck","creator_name":"drew thomasson","creator_url":"https://huggingface.co/superdrew100","description":"superdrew100/heck dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Gem","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Gem","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Gem dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"BERSt","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rosie-Lab/BERSt","creator_name":"SFU Robots with Social Intelligence and Empathy Lab","creator_url":"https://huggingface.co/Rosie-Lab","description":"\n\t\n\t\t\n\t\tBERSt Dataset\n\t\n\nWe release the BERSt Dataset for various speech recognition tasks including Automatic Speech Recognition (ASR) and Speech Emotion Recogniton (SER)\nRead the paper here\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n4526 single phrase recordings (~3.75h)\n98 professional actors\n19 phone positions\n7 emotion classes\n3 vocal intensity levels\nvaried regional and non-native English accents\nnonsense phrases covering all English Phonemes\n\n\n\t\n\t\t\n\t\tData collection\n\t\n\nThe BERSt dataset represents data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rosie-Lab/BERSt.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"BERSt","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rosie-Lab/BERSt","creator_name":"SFU Robots with Social Intelligence and Empathy Lab","creator_url":"https://huggingface.co/Rosie-Lab","description":"\n\t\n\t\t\n\t\tBERSt Dataset\n\t\n\nWe release the BERSt Dataset for various speech recognition tasks including Automatic Speech Recognition (ASR) and Speech Emotion Recogniton (SER)\nRead the paper here\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n4526 single phrase recordings (~3.75h)\n98 professional actors\n19 phone positions\n7 emotion classes\n3 vocal intensity levels\nvaried regional and non-native English accents\nnonsense phrases covering all English Phonemes\n\n\n\t\n\t\t\n\t\tData collection\n\t\n\nThe BERSt dataset represents data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rosie-Lab/BERSt.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jl-speech","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jl-speech","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\n\t\n\t\t\n\t\tJL Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJL Speech is a male voice version of the LJ Speech dataset. It contains 13,100 short audio clips of a single speaker reading passages from books. The total audio duration is approximately 24 hours, with audio quality improved to 48 kHz sampling rate.\nThis dataset is licensed under the CC-BY-4.0 License.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tCreation\n\t\n\nThe JL Speech dataset was created by converting the original LJ Speech dataset to a male‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/jl-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jl-speech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jl-speech","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\n\t\n\t\t\n\t\tJL Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJL Speech is a male voice version of the LJ Speech dataset. It contains 13,100 short audio clips of a single speaker reading passages from books. The total audio duration is approximately 24 hours, with audio quality improved to 48 kHz sampling rate.\nThis dataset is licensed under the CC-BY-4.0 License.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tCreation\n\t\n\nThe JL Speech dataset was created by converting the original LJ Speech dataset to a male‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/jl-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiosnippets_long_1M","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mitermix/audiosnippets_long_1M","creator_name":"Miter Mix","creator_url":"https://huggingface.co/mitermix","description":"mitermix/audiosnippets_long_1M dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"real-fake-voices-dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WpythonW/real-fake-voices-dataset","creator_name":"Andrew","creator_url":"https://huggingface.co/WpythonW","description":"WpythonW/real-fake-voices-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Zeroth-STT-Korean","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/o0dimplz0o/Zeroth-STT-Korean","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\n\t\n\t\t\n\t\tZeroth-STT-Korean Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a shuffled version of the Zeroth-STT-Ko dataset.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0 license.\nJunhoee/STT_Korean_Dataset_80000 Dataset, created by [Junhoee], 2024.\nAvailable at https://huggingface.co/datasets/Junhoee/STT_Korean_Dataset_80000\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"audiosnippets_long_2_5M","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mitermix/audiosnippets_long_2_5M","creator_name":"Miter Mix","creator_url":"https://huggingface.co/mitermix","description":"mitermix/audiosnippets_long_2_5M dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"nba_soccer_nfl","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kennethzhang/nba_soccer_nfl","creator_name":"Kenneth Chandra","creator_url":"https://huggingface.co/kennethzhang","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kennethzhang/nba_soccer_nfl.","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ClassicInstruments","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lazarerd/ClassicInstruments","creator_name":"Lazare Ricour-Dumas","creator_url":"https://huggingface.co/lazarerd","description":"lazarerd/ClassicInstruments dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","mit","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"ClassicInstruments","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lazarerd/ClassicInstruments","creator_name":"Lazare Ricour-Dumas","creator_url":"https://huggingface.co/lazarerd","description":"lazarerd/ClassicInstruments dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","mit","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_es_v1.0","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/composite_corpus_es_v1.0","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tComposite dataset for Spanish made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/es: \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\nopenslr: a train split made from the SLR(39,61,67,71,72,73,74,75,108) subsets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_es_v1.0.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ANNA75","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/annalogiacomo67/ANNA75","creator_name":"Anna lo giacomo","creator_url":"https://huggingface.co/annalogiacomo67","description":"annalogiacomo67/ANNA75 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Nezox","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NeoPy/Nezox","creator_name":"NeoDev","creator_url":"https://huggingface.co/NeoPy","description":"NeoPy/Nezox dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"cvss-t","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bismarck91/cvss-t","creator_name":"Bismarck Bamfo Odoom","creator_url":"https://huggingface.co/bismarck91","description":"bismarck91/cvss-t dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"princess-merida","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stevenyam/princess-merida","creator_name":"Stephen Nyamweya","creator_url":"https://huggingface.co/stevenyam","description":"stevenyam/princess-merida dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","text","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and CML-TTS\n\t\n\nThis dataset is a filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Polish"],"keywords_longer_than_N":true},
	{"name":"kkkk","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Alex201800/kkkk","creator_name":"Silva","creator_url":"https://huggingface.co/Alex201800","description":"Alex201800/kkkk dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0-argmax_subset-400","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argmaxinc/common_voice_17_0-argmax_subset-400","creator_name":"Argmax","creator_url":"https://huggingface.co/argmaxinc","description":"argmaxinc/common_voice_17_0-argmax_subset-400 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"ESC50","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/ESC50","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\tESC50\n\t\n\nThis is an audio classification dataset for Environmental Sound Classification.\nClasses = 50  ¬†¬†,¬†¬†  Split = Train-Test\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ncsv_files folder contains CSV files for five-fold cross-validation.\nTo perform cross-validation on fold 1, train_1.csv will be used for the training split and test_1.csv for the testing split, with the same pattern followed for the other folds.\nTo perform training and testing witout cross-validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/ESC50.","first_N":5,"first_N_keywords":["mit","10K - 100K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ASR_En_Ar_CodeSwitching","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nash-pAnDiTa/ASR_En_Ar_CodeSwitching","creator_name":"Mohamed Samir","creator_url":"https://huggingface.co/Nash-pAnDiTa","description":"Nash-pAnDiTa/ASR_En_Ar_CodeSwitching dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"GT-Music-Genre","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/GT-Music-Genre","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\tGT-Music-Genre\n\t\n\nThis is an audio classification dataset for Music Analysis.\nClasses = 10  ¬†¬†,¬†¬†  Split = Train-Test\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ntrain.csv for training split and test.csv for the testing split.\n\n\n\t\n\t\t\n\t\tDownload\n\t\n\nimport os\nimport huggingface_hub\naudio_datasets_path = \"DATASET_PATH/Audio-Datasets\"\nif not os.path.exists(audio_datasets_path): print(f\"Given {audio_datasets_path=} does not exist. Specify a valid path ending with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/GT-Music-Genre.","first_N":5,"first_N_keywords":["mit","< 1K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"CREMA-D","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/CREMA-D","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\tCREMA-D\n\t\n\nThis is an audio classification dataset for Emotion Recognition.\nClasses = 6  ¬†¬†,¬†¬†  Split = Train-Test\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ntrain.csv for training split and test.csv for the testing split.\n\n\n\t\n\t\t\n\t\tDownload\n\t\n\nimport os\nimport huggingface_hub\naudio_datasets_path = \"DATASET_PATH/Audio-Datasets\"\nif not os.path.exists(audio_datasets_path): print(f\"Given {audio_datasets_path=} does not exist. Specify a valid path ending with 'Audio-Datasets'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/CREMA-D.","first_N":5,"first_N_keywords":["mit","1K - 10K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TUT2017","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/TUT2017","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\tTUT2017\n\t\n\nThis is an audio classification dataset for Acoustic Scene Classification.\nClasses = 15  ¬†¬†,¬†¬†  Split = four-fold \n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ncsv_files folder contains CSV files for four-fold cross-validation.\nTo perform cross-validation on fold 1, train_1.csv will be used for the training split and test_1.csv for the testing split, with the same pattern followed for the other folds.\nTo perform training and testing witout cross-validation, use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/TUT2017.","first_N":5,"first_N_keywords":["mit","10K - 100K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"RAVDESS","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/RAVDESS","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\tRAVDESS\n\t\n\nThis is an audio classification dataset for Emotion Recognition.\nClasses = 8  ¬†¬†,¬†¬†  Split = Train-Test \n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ntrain.csv for training split and test.csv for the testing split.\n\n\n\t\n\t\t\n\t\tDownload\n\t\n\nimport os\nimport huggingface_hub\naudio_datasets_path = \"DATASET_PATH/Audio-Datasets\"\nif not os.path.exists(audio_datasets_path): print(f\"Given {audio_datasets_path=} does not exist. Specify a valid path ending with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/RAVDESS.","first_N":5,"first_N_keywords":["mit","1K - 10K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"colab-snippets","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ariG23498/colab-snippets","creator_name":"Aritra Roy Gosthipaty","creator_url":"https://huggingface.co/ariG23498","description":"ariG23498/colab-snippets dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"beats-with-different-tools-and-materials","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mcamara/beats-with-different-tools-and-materials","creator_name":"Mateo C√°mara","creator_url":"https://huggingface.co/mcamara","description":"mcamara/beats-with-different-tools-and-materials dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"librispeech_pt","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murilo-as/librispeech_pt","creator_name":"Murilo Alvares Silva","creator_url":"https://huggingface.co/murilo-as","description":"murilo-as/librispeech_pt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","cc0-1.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"BNK","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Imran1/BNK","creator_name":"Imran ullah","creator_url":"https://huggingface.co/Imran1","description":"Imran1/BNK dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"FUTGA","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JoshuaW1997/FUTGA","creator_name":"Junda Wu","creator_url":"https://huggingface.co/JoshuaW1997","description":"\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use our models or datasets in your research, please cite it as follows:\n@article{wu2024futga,\n  title={Futga: Towards Fine-grained Music Understanding through Temporally-enhanced Generative Augmentation},\n  author={Wu, Junda and Novack, Zachary and Namburi, Amit and Dai, Jiaheng and Dong, Hao-Wen and Xie, Zhouhang and Chen, Carol and McAuley, Julian},\n  journal={arXiv preprint arXiv:2407.20445},\n  year={2024}\n}\n\n","first_N":5,"first_N_keywords":["text-generation","audio-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"pdmx-multi-instrument-synthesized","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openmusic/pdmx-multi-instrument-synthesized","creator_name":"OpenMusic","creator_url":"https://huggingface.co/openmusic","description":"A synthesized subset of the PDMX dataset containing only MIDI files with multiple instruments.\nCaptions are auto-generated with Qwen2 Audio.\nAudio is licensed under CC0 (from PDMX). Captions are licensed under CC-BY.\n","first_N":5,"first_N_keywords":["cc0-1.0","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"liam44","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nasser84/liam44","creator_name":"soria haidra","creator_url":"https://huggingface.co/nasser84","description":"nasser84/liam44 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"lispsamples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rawag/lispsamples","creator_name":"Ramy Nabil","creator_url":"https://huggingface.co/rawag","description":"rawag/lispsamples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"enwaucymraeg","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/enwaucymraeg","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"The training and development set sentences are taken from CoVoST and have been compared to all validated sentences in the Welsh Common Voice data to ensure none of the already recorded sentences will be used here. Then all sentences containing personal names have been extracted and replaced with a randomly generated name using the Faker library and a custom Welsh names list. The sentences were then recorded by 26 volunteers from North-West Wales, 15 women, 10 men and one non-binary person.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wanasash/enwaucymraeg.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Welsh","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MASC","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hirundo-io/MASC","creator_name":"Hirundo","creator_url":"https://huggingface.co/hirundo-io","description":"This dataset is Massive Arabic Speech Corpus (MASC). MASC is a dataset that contains 1,000 hours of speech sampled at 16 kHz and crawled from over 700 YouTube channels. The dataset is multi-regional, multi-genre, and multi-dialect intended to advance the research and development of Arabic speech technology with a special emphasis on Arabic speech recognition. In addition to MASC, a pre-trained 3-gram language model and a pre-trained automatic speech recognition model are also developed and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hirundo-io/MASC.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"RoboShaul","keyword":"audio","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/hirundo-io/RoboShaul","creator_name":"Hirundo","creator_url":"https://huggingface.co/hirundo-io","description":"About this resource:\nThis dataset contains approximately 30 hours of audio spoken by Shaul Amsterdamski in a recording studio at 44100Hz with corresponding transcriptions.\nThe data is divided into a gold-standard subset of roughly 4 hours with manual transcriptions and an automatic subset with machine-generated transcriptions.\n","first_N":5,"first_N_keywords":["bsd-2-clause","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"JA_audio_EN_text_tedx_18k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_EN_text_tedx_18k","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":"Sin2pi/JA_audio_EN_text_tedx_18k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"whisper-large-v2-ec-eval-cv","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/whisper-large-v2-ec-eval-cv","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"Model: wanasash/whisper-large-v2-ec\nTest Set: DewiBrynJones/commonvoice_18_0_cy\nSplit: test\n\nWER: 38.194402\nCER: 11.612194\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"jeli-asr","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"jeli-asr","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"region3","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/san457/region3","creator_name":"Sanskar Singh ","creator_url":"https://huggingface.co/san457","description":"san457/region3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"region4","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/san457/region4","creator_name":"Sanskar Singh ","creator_url":"https://huggingface.co/san457","description":"san457/region4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"region5","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/san457/region5","creator_name":"Sanskar Singh ","creator_url":"https://huggingface.co/san457","description":"san457/region5 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"region6","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/san457/region6","creator_name":"Sanskar Singh ","creator_url":"https://huggingface.co/san457","description":"san457/region6 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"wolof-audio-data","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galsenai/wolof-audio-data","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","description":"\n\t\n\t\t\n\t\tWolof Audio Dataset\n\t\n\nThe Wolof Audio Dataset is a collection of audio recordings and their corresponding transcriptions in Wolof. This dataset is designed to support the development of Automatic Speech Recognition (ASR) models for the Wolof language. It was created by combining four existing datasets:\n\nALFFA: Available at serge-wilson/wolof_speech_transcription\nFLEURS: Available at vonewman/fleurs-wolof-dataset\nUrban Bus Wolof Speech Dataset: Available at vonewman/urban-bus-wolof‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/galsenai/wolof-audio-data.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Wolof","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Tomori-Voice-Spilt","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DenebT/Tomori-Voice-Spilt","creator_name":"DenebT","creator_url":"https://huggingface.co/DenebT","description":"DenebT/Tomori-Voice-Spilt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"CanaryAura","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nkazi/CanaryAura","creator_name":"Nazmul Kazi","creator_url":"https://huggingface.co/nkazi","description":"\n\t\n\t\t\n\t\tDataset Card for \"Canary Aura\"\n\t\n\nThis is a dataset for...\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Applio-Dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IAHispano/Applio-Dataset","creator_name":"AI Hispano","creator_url":"https://huggingface.co/IAHispano","description":"VCTK dataset used to train Applio base models.\n","first_N":5,"first_N_keywords":["English","cc-by-4.0","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"AV_Odyssey_Bench_LMMs_Eval","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AV-Odyssey/AV_Odyssey_Bench_LMMs_Eval","creator_name":"AV-Odyssey Bench","creator_url":"https://huggingface.co/AV-Odyssey","description":"AV-Odyssey/AV_Odyssey_Bench_LMMs_Eval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"WillyShakes","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/scenecoachai/WillyShakes","creator_name":"Janis Deedy","creator_url":"https://huggingface.co/scenecoachai","description":"cd your-dataset-name\ncp /path/to/your/data/* .\ngit add .\ngit commit -m \"Add my dataset\"\ngit push\n","first_N":5,"first_N_keywords":["feature-extraction","Latin","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CORDI","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SinaAhmadi/CORDI","creator_name":"Sina Ahm","creator_url":"https://huggingface.co/SinaAhmadi","description":"\n\t\n\t\t\n\t\tCORDI ‚Äî Corpus of Dialogues in Central Kurdish\n\t\n\n\n  \n\n\n‚û°Ô∏è See the repository on GitHub\nThis repository provides resources for language and speech technology for Central Kurdish varieties discussed in our LREC-COLING 2024 paper, particularly the first annotated corpus of spoken Central Kurdish varieties ‚Äî CORDI. Given the financial burden of traditional ways of documenting languages and varieties as in fieldwork, we follow a rather novel alternative where movies and series are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SinaAhmadi/CORDI.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"my_dataset_yo_asr","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Harcuracy/my_dataset_yo_asr","creator_name":"Akande soji ","creator_url":"https://huggingface.co/Harcuracy","description":"Harcuracy/my_dataset_yo_asr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Yoruba","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"NeuroPiano-data","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anusfoil/NeuroPiano-data","creator_name":"Huan Zhang","creator_url":"https://huggingface.co/anusfoil","description":"\n\t\n\t\t\n\t\tDataset Card for NeuroPiano-data\n\t\n\n\n\nThis dataset contains 2255 entries of audio-question-answer pairs that specializes in music education. Questions ranges from cleaness of attack to hands balancing, each one come with verbal response as well as a rating within 6. There are 104 unique student recordings of piano excercises and part of them are rated by multiple teachers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nCurated by: Hayato Nishioka, Vincent Cheung, Huan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anusfoil/NeuroPiano-data.","first_N":5,"first_N_keywords":["audio-classification","Japanese","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NeuroPiano-data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anusfoil/NeuroPiano-data","creator_name":"Huan Zhang","creator_url":"https://huggingface.co/anusfoil","description":"\n\t\n\t\t\n\t\tDataset Card for NeuroPiano-data\n\t\n\n\n\nThis dataset contains 2255 entries of audio-question-answer pairs that specializes in music education. Questions ranges from cleaness of attack to hands balancing, each one come with verbal response as well as a rating within 6. There are 104 unique student recordings of piano excercises and part of them are rated by multiple teachers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nCurated by: Hayato Nishioka, Vincent Cheung, Huan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anusfoil/NeuroPiano-data.","first_N":5,"first_N_keywords":["audio-classification","Japanese","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TTSEval_v1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sugarfreez/TTSEval_v1","creator_name":"PaParaZz1","creator_url":"https://huggingface.co/sugarfreez","description":"sugarfreez/TTSEval_v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"sillied","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/sillysillysilly/sillied","creator_name":"silly billy","creator_url":"https://huggingface.co/sillysillysilly","description":"sillysillysilly/sillied dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["wtfpl","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\n(linagora/linto-asr-ar-tn).\n\nDataset Summary\nDataset composition\nSources\nData Table\nData sources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian is a diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\n(linagora/linto-asr-ar-tn).\n\nDataset Summary\nDataset composition\nSources\nData Table\nData sources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian is a diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\n\nDataset Summary\nDataset composition\nSources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on LinTO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\n\nDataset Summary\nDataset composition\nSources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on LinTO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"syntheory","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meganwei/syntheory","creator_name":"Megan Wei","creator_url":"https://huggingface.co/meganwei","description":"\n\t\n\t\t\n\t\tDataset Card for SynTheory\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSynTheory is a synthetic dataset of music theory concepts, specifically rhythmic (tempos and time signatures) and tonal (notes, intervals, scales, chords, and chord progressions). \nEach of these 7 concepts has its own config.\ntempos consist of 161 total integer tempos (bpm) ranging from 50 BPM to 210 BPM (inclusive), 5 percussive instrument types (click_config_name), and 5 random start time offsets (offset_time).\ntime_signatures‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meganwei/syntheory.","first_N":5,"first_N_keywords":["audio-classification","feature-extraction","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"syntheory","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meganwei/syntheory","creator_name":"Megan Wei","creator_url":"https://huggingface.co/meganwei","description":"\n\t\n\t\t\n\t\tDataset Card for SynTheory\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSynTheory is a synthetic dataset of music theory concepts, specifically rhythmic (tempos and time signatures) and tonal (notes, intervals, scales, chords, and chord progressions). \nEach of these 7 concepts has its own config.\ntempos consist of 161 total integer tempos (bpm) ranging from 50 BPM to 210 BPM (inclusive), 5 percussive instrument types (click_config_name), and 5 random start time offsets (offset_time).\ntime_signatures‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meganwei/syntheory.","first_N":5,"first_N_keywords":["audio-classification","feature-extraction","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"syntheory","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meganwei/syntheory","creator_name":"Megan Wei","creator_url":"https://huggingface.co/meganwei","description":"\n\t\n\t\t\n\t\tDataset Card for SynTheory\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSynTheory is a synthetic dataset of music theory concepts, specifically rhythmic (tempos and time signatures) and tonal (notes, intervals, scales, chords, and chord progressions). \nEach of these 7 concepts has its own config.\ntempos consist of 161 total integer tempos (bpm) ranging from 50 BPM to 210 BPM (inclusive), 5 percussive instrument types (click_config_name), and 5 random start time offsets (offset_time).\ntime_signatures‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meganwei/syntheory.","first_N":5,"first_N_keywords":["audio-classification","feature-extraction","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"sada2022","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m6011/sada2022","creator_name":"mohammed alharbi","creator_url":"https://huggingface.co/m6011","description":"\n\t\n\t\t\n\t\tDataset Card for SADA - Saudi Audio Dataset for Arabic\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe SADA (Saudi Audio Dataset for Arabic) is a comprehensive dataset consisting of audio recordings from over 57 TV shows aired by the Saudi Broadcasting Authority (SBA). The dataset contains approximately 667 hours of audio data with transcripts, the majority of which are in various Saudi dialects (Najdi, Hijazi, Khaliji, etc.). \n\nCurated by: The National Center for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m6011/sada2022.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"earnings21","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Revai/earnings21","creator_name":"Rev","creator_url":"https://huggingface.co/Revai","description":"\n\t\n\t\t\n\t\tEarnings 21\n\t\n\nThe Earnings 21 dataset ( also referred to as earnings21 ) is a 39-hour corpus of earnings calls containing entity dense speech from nine different financial sectors. This corpus is intended to benchmark automatic speech recognition (ASR) systems in the wild with special attention towards named entity recognition (NER).\nIn this repo, we provided the transcoded files to 16KHz with the formatted text. This limits the utility of the original dataset due to the restrictions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Revai/earnings21.","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","Audio","arxiv:2104.11348","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"earnings21","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Revai/earnings21","creator_name":"Rev","creator_url":"https://huggingface.co/Revai","description":"\n\t\n\t\t\n\t\tEarnings 21\n\t\n\nThe Earnings 21 dataset ( also referred to as earnings21 ) is a 39-hour corpus of earnings calls containing entity dense speech from nine different financial sectors. This corpus is intended to benchmark automatic speech recognition (ASR) systems in the wild with special attention towards named entity recognition (NER).\nIn this repo, we provided the transcoded files to 16KHz with the formatted text. This limits the utility of the original dataset due to the restrictions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Revai/earnings21.","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","Audio","arxiv:2104.11348","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"tr_audio_validation","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdulbarisoylemez/tr_audio_validation","creator_name":"Abdulbari S√∂ylemez","creator_url":"https://huggingface.co/Abdulbarisoylemez","description":"Abdulbarisoylemez/tr_audio_validation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tr_audio_train","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdulbarisoylemez/tr_audio_train","creator_name":"Abdulbari S√∂ylemez","creator_url":"https://huggingface.co/Abdulbarisoylemez","description":"Abdulbarisoylemez/tr_audio_train dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ml","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/diveman/ml","creator_name":"diveman","creator_url":"https://huggingface.co/diveman","description":"diveman/ml dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"atc-sample","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xingyulll/atc-sample","creator_name":"chenxingyu","creator_url":"https://huggingface.co/xingyulll","description":"xingyulll/atc-sample dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"filatov_24000","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/patriotyk/filatov_24000","creator_name":"Serhiy Stetskovych ","creator_url":"https://huggingface.co/patriotyk","description":"patriotyk/filatov_24000 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"eng_ipa_audioset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VirtualX/eng_ipa_audioset","creator_name":"Xavier Dedenbach","creator_url":"https://huggingface.co/VirtualX","description":"VirtualX/eng_ipa_audioset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"esse-sensitivo","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patmcm/esse-sensitivo","creator_name":"Pat McMaster","creator_url":"https://huggingface.co/patmcm","description":"patmcm/esse-sensitivo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"SBCSAE","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dklement/SBCSAE","creator_name":"Dominik Klement","creator_url":"https://huggingface.co/dklement","description":"A detailed dataset description (including description, audio samples, and statistics) is provided here: https://domklement.github.io/sbcsae/\nIf you use the dataset, please, do not forget to cite our work:\n@inproceedings{maciejewski24_interspeech,\n  title     = {Evaluating the Santa Barbara Corpus: Challenges of the Breadth of Conversational Spoken Language},\n  author    = {Matthew Maciejewski and Dominik Klement and Ruizhe Huang and Matthew Wiesner and Sanjeev Khudanpur},\n  year      = {2024}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dklement/SBCSAE.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ksponspeech-eval","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yfyeung/ksponspeech-eval","creator_name":"Yifan Yang","creator_url":"https://huggingface.co/yfyeung","description":"paper link: https://www.mdpi.com/846876\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","cc-by-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"inbrowser-proctor-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset","creator_name":"Aayush Man Shrestha","creator_url":"https://huggingface.co/lord-reso","description":"\n\t\n\t\t\n\t\tDataset Card for Inbrowser Proctor Dataset\n\t\n\n\n\t\n\t\t\n\t\tProject Description\n\t\n\nInbrowser Proctoring is an online browser proctoring application designed to supervise exams and prevent cheating in real-time. Utilizing a combination of video, audio, and screen recording technologies, along with advanced AI algorithms, the system closely monitors test-takers to identify suspicious behaviors and activities. By analyzing audio and visual data, it can detect anomalies that may indicate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"tr_audio_train_1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdulbarisoylemez/tr_audio_train_1","creator_name":"Abdulbari S√∂ylemez","creator_url":"https://huggingface.co/Abdulbarisoylemez","description":"Abdulbarisoylemez/tr_audio_train_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Sidorovich","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Warlock700/Sidorovich","creator_name":"Warlock700","creator_url":"https://huggingface.co/Warlock700","description":"Warlock700/Sidorovich dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Kardan","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Warlock700/Kardan","creator_name":"Warlock700","creator_url":"https://huggingface.co/Warlock700","description":"Warlock700/Kardan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Infinity","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Infinity","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Infinity dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"STT-v1","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FILM6912/STT-v1","creator_name":"FILM","creator_url":"https://huggingface.co/FILM6912","description":"FILM6912/STT-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Thai","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"parler_tts_mini_V01_TestVoice_Italian","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/udanet/parler_tts_mini_V01_TestVoice_Italian","creator_name":"Ud'Anet G. D'Annunzio Chieti","creator_url":"https://huggingface.co/udanet","description":"udanet/parler_tts_mini_V01_TestVoice_Italian dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Italian","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"parler_tts_mini_V01_TestVoice_Italian","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/udanet/parler_tts_mini_V01_TestVoice_Italian","creator_name":"Ud'Anet G. D'Annunzio Chieti","creator_url":"https://huggingface.co/udanet","description":"udanet/parler_tts_mini_V01_TestVoice_Italian dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Italian","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"LnNor","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiBridge/LnNor","creator_name":"MultiBridge","creator_url":"https://huggingface.co/MultiBridge","description":"\n\t\n\t\t\n\t\tDataset Card for the LnNor Corpus\n\t\n\n\nA multilingual dataset of high-quality speech recordings in Norwegian, English, and Polish, designed for research into cross-linguistic influence, multilingual language acquisition, and applications in NLP and speech processing such as ASR, TTS, and linguistic variability modeling. The dataset features structured experimental tasks such as reading, picture and video description, and spontaneous conversation to capture phonological, syntactic, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MultiBridge/LnNor.","first_N":5,"first_N_keywords":["token-classification","text-classification","automatic-speech-recognition","audio-classification","Norwegian"],"keywords_longer_than_N":true},
	{"name":"LnNor","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiBridge/LnNor","creator_name":"MultiBridge","creator_url":"https://huggingface.co/MultiBridge","description":"\n\t\n\t\t\n\t\tDataset Card for the LnNor Corpus\n\t\n\n\nA multilingual dataset of high-quality speech recordings in Norwegian, English, and Polish, designed for research into cross-linguistic influence, multilingual language acquisition, and applications in NLP and speech processing such as ASR, TTS, and linguistic variability modeling. The dataset features structured experimental tasks such as reading, picture and video description, and spontaneous conversation to capture phonological, syntactic, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MultiBridge/LnNor.","first_N":5,"first_N_keywords":["token-classification","text-classification","automatic-speech-recognition","audio-classification","Norwegian"],"keywords_longer_than_N":true},
	{"name":"VCTK","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/badayvedat/VCTK","creator_name":"Vedat Baday","creator_url":"https://huggingface.co/badayvedat","description":"badayvedat/VCTK dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ABPR_with_More_Versions","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIRBoat2876/ABPR_with_More_Versions","creator_name":"xHazardEpicly0824","creator_url":"https://huggingface.co/AIRBoat2876","description":"AIRBoat2876/ABPR_with_More_Versions dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"india-supreme-court-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/divi212/india-supreme-court-audio","creator_name":"Divyanshu Pachisia","creator_url":"https://huggingface.co/divi212","description":"divi212/india-supreme-court-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Death_from_puss_and_boots","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/drewThomasson/Death_from_puss_and_boots","creator_name":"Andrew P Thomasson","creator_url":"https://huggingface.co/drewThomasson","description":"drewThomasson/Death_from_puss_and_boots dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"kashmiri_tts_hf_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omarrran/kashmiri_tts_hf_dataset","creator_name":"HAQ NAWAZ MALIK","creator_url":"https://huggingface.co/Omarrran","description":"\n\t\n\t\t\n\t\tOmarrran/kashmiri_tts_hf_dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Kashmiri text-to-speech (TTS) data, including paired text and audio files.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal number of samples: 33\nNumber of samples in train split: 26\nNumber of samples in test split: 7\n\n\n\t\n\t\t\n\t\tAudio Statistics\n\t\n\n\nTotal audio duration: 9766.49 seconds (2.71 hours)\nAverage audio duration: 295.95 seconds\nMinimum audio duration: 84.60 seconds\nMaximum audio duration: 606.91‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Omarrran/kashmiri_tts_hf_dataset.","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dataset_TTS_uz","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/dataset_TTS_uz","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/dataset_TTS_uz dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Sign_language_dataset1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Bhavuk/Sign_language_dataset1","creator_name":"Bhavuk Agrawal","creator_url":"https://huggingface.co/Bhavuk","description":"Bhavuk/Sign_language_dataset1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Video"],"keywords_longer_than_N":true},
	{"name":"nigerian-pidgin-1.0","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asr-nigerian-pidgin/nigerian-pidgin-1.0","creator_name":"Nigerian Pidgin Research","creator_url":"https://huggingface.co/asr-nigerian-pidgin","description":"\n\t\n\t\t\n\t\tLanguage:\n- Nigerian Pidgin English (West African Pidgin variant)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDataset Summary\nThe Nigerian Pidgin ASR dataset (v1.0) is the first publicly released speech-to-text corpus for Nigerian Pidgin English, a widely spoken lingua franca across Nigeria and West Africa. This dataset comprises over 3,000 audio recordings paired with sentence-level transcriptions, recorded by native speakers across different genders and age groups. It is tailored for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/asr-nigerian-pidgin/nigerian-pidgin-1.0.","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"libri2mix_clean_target","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beilong/libri2mix_clean_target","creator_name":"Beilong Tang","creator_url":"https://huggingface.co/Beilong","description":"This repository contains the libri2mix_dev and libri2mix_test used in TSELM: Target Speaker Extractoion using Discrete Tokens and Language Models.\nDetails can be found here.\n","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"speakeroverlap_multiseg","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zbrunner/speakeroverlap_multiseg","creator_name":"Zoe Brunner","creator_url":"https://huggingface.co/zbrunner","description":"\n\t\n\t\t\n\t\tMultiSeg Dataset for ASR Hallucinations\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nMultiSeg is a perturbed and altered version of the TEDLIUM3 dataset, specifically created for evaluating the robustness of Automatic Speech Recognition (ASR) systems. This dataset is derived from the 'speakeroverlap' subset, which consists of held-back training data from TEDLIUM3.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThe primary purpose of the MultiSeg dataset is to:\n\nElicit hallucinations from ASR systems\nEvaluate ASR performance under‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zbrunner/speakeroverlap_multiseg.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"TrainingSpeech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wasertech/TrainingSpeech","creator_name":"Danny Waser","creator_url":"https://huggingface.co/wasertech","description":"TrainingSpeech is an initiative to provide open and freely reusable dataset of voices \n\nfor speech-to-text models training\n\non non-english languages \n\nusing already available data (such as audio-books).\n\n\nRight now, data are extracted exclusively from audio-books and in French language. Let me know if you are intersted to contribute by creating an issue.\n\n\t\n\t\t\n\t\n\t\n\t\tTooling\n\t\n\nTrainingSpeech  comes with a CLI that automate and simplify:\n\ntranscript extraction\nforced-alignment (using aeneas)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wasertech/TrainingSpeech.","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"whisper-french","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MaximeDde/whisper-french","creator_name":"Maxime Dubois d'Enghien","creator_url":"https://huggingface.co/MaximeDde","description":"MaximeDde/whisper-french dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["French","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0-debug","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argmaxinc/common_voice_17_0-debug","creator_name":"Argmax","creator_url":"https://huggingface.co/argmaxinc","description":"argmaxinc/common_voice_17_0-debug dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ViSQA-new","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IAmSkyDra/ViSQA-new","creator_name":"Long Nguyen Song Thien","creator_url":"https://huggingface.co/IAmSkyDra","description":"IAmSkyDra/ViSQA-new dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"rel_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m522t/rel_dataset","creator_name":"Mehrshad Taji","creator_url":"https://huggingface.co/m522t","description":"m522t/rel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiMed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leduckhai/MultiMed","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","description":"\n\t\n\t\t\n\t\tMultiMed: Multilingual Medical Speech Recognition via Attention Encoder Decoder\n\t\n\nACL 2025\nKhai Le-Duc, Phuc Phan, Tan-Hanh Pham, Bach Phan Tat,\n\nMinh-Huong Ngo, Chris Ngo, Thanh Nguyen-Tang, Truong-Son Hy\n\n\nPlease press ‚≠ê button and/or cite papers if you feel helpful.\n\n\n  \n\n\n\nAbstract:\nMultilingual automatic speech recognition (ASR) in the medical domain serves as a foundational task for various downstream applications such as speech translation, spoken language understanding, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/MultiMed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","English","German","French"],"keywords_longer_than_N":true},
	{"name":"tr_audio_validation_1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdulbarisoylemez/tr_audio_validation_1","creator_name":"Abdulbari S√∂ylemez","creator_url":"https://huggingface.co/Abdulbarisoylemez","description":"Abdulbarisoylemez/tr_audio_validation_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Kore-Voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Kore-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Kore-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"dataset_for_STT_TTSmodels","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/dataset_for_STT_TTSmodels","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/dataset_for_STT_TTSmodels dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"soomali-asr-dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skydheere/soomali-asr-dataset","creator_name":"imran adam ","creator_url":"https://huggingface.co/skydheere","description":"\n\t\n\t\t\n\t\tSomali ASR Dataset\n\t\n\nThis dataset contains audio recordings and corresponding transcriptions in Somali, designed for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Somali (so)\nSize: 10K - 100K samples\nFormat: Parquet\nModalities: Audio + Text\nLicense: CC-BY 4.0\nTask: Automatic Speech Recognition\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used to train and evaluate ASR models for the Somali language. It is particularly helpful for developing speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skydheere/soomali-asr-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Somali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"LJSpeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Reeya112/LJSpeech","creator_name":"Riya Yadav","creator_url":"https://huggingface.co/Reeya112","description":"Reeya112/LJSpeech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Hadza_translation_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/earl562/Hadza_translation_dataset","creator_name":"Earl Perry","creator_url":"https://huggingface.co/earl562","description":"earl562/Hadza_translation_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Obama-Sample-Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ModelsLab/Obama-Sample-Dataset","creator_name":"ModelsLab","creator_url":"https://huggingface.co/ModelsLab","description":"\n\n\t\n\t\t\n\t\tObama Voice Sample Dataset for RVC Training\n\t\n\nA curated dataset of Barack Obama's voice samples, specifically prepared for training Demo RVC (Retrieval-based Voice Conversion) model on ModelsLab.\n\n\t\n\t\t\n\t\tDataset Specifications\n\t\n\n\nTotal Duration: 25+ minutes\nAudio Format: WAV\nSampling Rate: 24 kHz\nContent Type: Clean speech samples from speeches and addresses\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is designed for training RVC (Retrieval-based Voice Conversion) models. The minimum recommended‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ModelsLab/Obama-Sample-Dataset.","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Obama-Sample-Dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ModelsLab/Obama-Sample-Dataset","creator_name":"ModelsLab","creator_url":"https://huggingface.co/ModelsLab","description":"\n\n\t\n\t\t\n\t\tObama Voice Sample Dataset for RVC Training\n\t\n\nA curated dataset of Barack Obama's voice samples, specifically prepared for training Demo RVC (Retrieval-based Voice Conversion) model on ModelsLab.\n\n\t\n\t\t\n\t\tDataset Specifications\n\t\n\n\nTotal Duration: 25+ minutes\nAudio Format: WAV\nSampling Rate: 24 kHz\nContent Type: Clean speech samples from speeches and addresses\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is designed for training RVC (Retrieval-based Voice Conversion) models. The minimum recommended‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ModelsLab/Obama-Sample-Dataset.","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"icsi-meetings","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argmaxinc/icsi-meetings","creator_name":"Argmax","creator_url":"https://huggingface.co/argmaxinc","description":"argmaxinc/icsi-meetings dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"voxceleb2-dev-wds","keyword":"audio-classification","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaunernst/voxceleb2-dev-wds","creator_name":"Thien Tran","creator_url":"https://huggingface.co/gaunernst","description":"\n\t\n\t\t\n\t\tVoxCeleb2 - dev set\n\t\n\nThis is a copy of VoxCeleb2 dev set in WebDataset format. The audio data is the original AAC-encoded files without any transcoding. Refer to https://arxiv.org/abs/1806.05622 for more details about the dataset.\nThere are 1,092,009 samples covering 5,994 unique speakers. The dataset is split into 779 shards of ~100MB.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport torchaudio\nimport webdataset as wds\nfrom datasets import load_dataset\n\ndef decode_audio(sample):\n    audio, fs =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaunernst/voxceleb2-dev-wds.","first_N":5,"first_N_keywords":["audio-classification","cc-by-sa-4.0","1M - 10M","webdataset","Text"],"keywords_longer_than_N":true},
	{"name":"VoiceBank-DEMAND-16k","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/VoiceBank-DEMAND-16k","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/VoiceBank-DEMAND-16k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"VoiceBank-DEMAND-16k","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/VoiceBank-DEMAND-16k","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/VoiceBank-DEMAND-16k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_1_zh_TW_clean","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/common_voice_16_1_zh_TW_clean","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"This dataset is derived from mozilla-foundation/common_voice_16_1, with a clean (denoised) audio column using MP-SENet. The original \"noisy\" audio is stored in the \"original\" column.\n","first_N":5,"first_N_keywords":["mozilla-foundation/common_voice_16_1","Chinese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"mumospee_libritts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/meetween/mumospee_libritts","creator_name":"Meetween","creator_url":"https://huggingface.co/meetween","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a derived version of the LibriTTS corpus, converted into larger parquet files for optimized I/O performance on high-performance computing clusters. The dataset maintains the high-quality, multi-speaker, text-to-speech (TTS) alignment of LibriTTS, with over 585 hours of English audiobook recordings and corresponding transcriptions. This format is ideal for large-scale training in speech synthesis and TTS tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\n\nOriginal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meetween/mumospee_libritts.","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"mumospee_librispeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/meetween/mumospee_librispeech","creator_name":"Meetween","creator_url":"https://huggingface.co/meetween","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a modified version of the LibriSpeech corpus, converted into parquet format to enhance I/O efficiency in high-performance computing environments. LibriSpeech is widely used for speech recognition research and includes over 1,000 hours of English read speech. This modification retains the original data attributes while improving data handling for distributed training on large-scale models.\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\n\nOriginal Dataset: LibriSpeech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meetween/mumospee_librispeech.","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"common_voice_19_0_zh-TW","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/common_voice_19_0_zh-TW","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\n\t\n\t\t\n\t\tCommon Voice Corpus 19.0 Chinese (Taiwan)\n\t\n\nThe test set is the same as the original test set, while validated_without_test includes all validated examples except those with sentence IDs that appear in the test set.\n\nvalidated_without_test has about 50,000 examples in total, equivalent to approximately 44 hours, and is intended for use as the training set.\ntest has about 5,000 examples, which is approximately 5 hours.\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"quran-audio","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fawazahmed0/quran-audio","creator_name":"Fawaz Ahmed","creator_url":"https://huggingface.co/fawazahmed0","description":"fawazahmed0/quran-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"indicvoices_pa_tagged_transcripts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_pa_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"indicvoices_mr_tagged_transcripts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_mr_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"indicvoices_bn_tagged_transcripts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_bn_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"NS-Instruments","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/NS-Instruments","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\n\t\n\t\tNS-Instruments\n\t\n\nThis is an audio classification dataset for Music Instruments Classification.\nClasses = 10  ¬†¬†,¬†¬†  Split = Train-Test\n\n\t\n\t\t\n\t\n\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ntrain.csv for training split and test.csv for the testing split.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nimport os\nimport zipfile\nimport shutil\nimport huggingface_hub\naudio_datasets_path = \"DATASET_PATH/Audio-Datasets\"\nif not os.path.exists(audio_datasets_path): print(f\"Given {audio_datasets_path=}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/NS-Instruments.","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"SingMOS","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TangRain/SingMOS","creator_name":"Tang","creator_url":"https://huggingface.co/TangRain","description":"paper link: SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction\nNOTICE: Our new paper has not been released and the information in SingMOS paper remain in SingMOS_v1. We will update it soon.\nIf you want to use the dataset of the singing track in VoiceMOS 2024, you can visit SingMOS_v1.\nIf you want to use our pretrained SingMOS model, you can visit our repo at Singing MOS Predictor.\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nSingMOS includes 6583 Chinese and Japanese vocal clips, totaling 9.07‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS.","first_N":5,"first_N_keywords":["Chinese","Japanese","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Theresa","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0-debug-zip","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argmaxinc/common_voice_17_0-debug-zip","creator_name":"Argmax","creator_url":"https://huggingface.co/argmaxinc","description":"argmaxinc/common_voice_17_0-debug-zip dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"XTTS_v2_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vunhucuongit/XTTS_v2_dataset","creator_name":"Cuong Vu","creator_url":"https://huggingface.co/vunhucuongit","description":"vunhucuongit/XTTS_v2_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Beijing-Opera","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/Beijing-Opera","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\tBeijing-Opera\n\t\n\nThis is an audio classification dataset for Instrument Classification.\nClasses = 4  ¬†¬†,¬†¬†  Split = Five-Fold \n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ncsv_files folder contains CSV files for five-fold cross-validation.\nTo perform cross-validation on fold 1, train_1.csv will be used for the training split and test_1.csv for the testing split, with the same pattern followed for the other folds.\nTo perform training and testing witout cross-validation, use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/Beijing-Opera.","first_N":5,"first_N_keywords":["mit","1K - 10K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ESC50-Actions","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/ESC50-Actions","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\tESC50-Actions\n\t\n\nThis is an audio classification dataset for Environmental Sound Classification.\nClasses = 10  ¬†¬†,¬†¬†  Split = Five-Fold \n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ncsv_files folder contains CSV files for five-fold cross-validation.\nTo perform cross-validation on fold 1, train_1.csv will be used for the training split and test_1.csv for the testing split, with the same pattern followed for the other folds.\nTo perform training and testing witout‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/ESC50-Actions.","first_N":5,"first_N_keywords":["mit","1K - 10K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"SESA","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/SESA","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\tSESA\n\t\n\nThis is an audio classification dataset for Surveillance Sound Classification.\nClasses = 4  ¬†¬†,¬†¬†  Split = Train-Test \n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ntrain.csv for training split and test.csv for the testing split.\n\n\n\t\n\t\t\n\t\tDownload\n\t\n\nimport os\nimport huggingface_hub\naudio_datasets_path = \"DATASET_PATH/Audio-Datasets\"\nif not os.path.exists(audio_datasets_path): print(f\"Given {audio_datasets_path=} does not exist. Specify a valid path ending with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/SESA.","first_N":5,"first_N_keywords":["mit","< 1K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"UrbanSound8K","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/UrbanSound8K","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\tUrbanSound8K\n\t\n\nThis is an audio classification dataset for Sound Event Classification.\nClasses = 10  ¬†¬†,¬†¬†  Split = Ten-Fold \n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ncsv_files folder contains CSV files for ten-fold cross-validation.\nTo perform cross-validation on fold 1, train_1.csv will be used for the training split and test_1.csv for the testing split, with the same pattern followed for the other folds.\nTo perform training and testing witout cross-validation, use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/UrbanSound8K.","first_N":5,"first_N_keywords":["mit","10K - 100K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Xtts-finetune-David-Walliams","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/drewThomasson/Xtts-finetune-David-Walliams","creator_name":"Andrew P Thomasson","creator_url":"https://huggingface.co/drewThomasson","description":"drewThomasson/Xtts-finetune-David-Walliams dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"voicesample","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adarshtrain/voicesample","creator_name":"Adarsh Verma","creator_url":"https://huggingface.co/adarshtrain","description":"adarshtrain/voicesample dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"voxforge_pt","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murilo-as/voxforge_pt","creator_name":"Murilo Alvares Silva","creator_url":"https://huggingface.co/murilo-as","description":"murilo-as/voxforge_pt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"SpokenPortugueseGeographicalSocialVarieties","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jarbas/SpokenPortugueseGeographicalSocialVarieties","creator_name":"Casimiro Ferreira","creator_url":"https://huggingface.co/Jarbas","description":"\n\t\n\t\t\n\t\tSpoken Portuguese - Geographical and Social Varieties\n\t\n\ndataset source: https://www.clul.ulisboa.pt\n(1995-1997 - European Commission DGXXII, Programme LINGUA/SOCRATES)\nThe project is concluded and the materials are published in CD-ROM, with the exclusive publishing support of Instituto Cam√µes, under the title Portugu√™s Falado - Documentos Aut√™nticos: Grava√ß√µes √°udio com transcri√ß√£o alinhada. Its distribution outside of Portugal is ensured by Instituto Cam√µes and in Portugal by CLUL.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jarbas/SpokenPortugueseGeographicalSocialVarieties.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"tr_audio_data_speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdulbarisoylemez/tr_audio_data_speech","creator_name":"Abdulbari S√∂ylemez","creator_url":"https://huggingface.co/Abdulbarisoylemez","description":"Abdulbarisoylemez/tr_audio_data_speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"youtube-cc-by-music","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music","creator_name":"WaveAI","creator_url":"https://huggingface.co/WaveGenAI","description":"üì∫ YouTube-CC-BY-Music üì∫\nYouTube-CC-BY-Music is a comprehensive collection of metadata for 316,000 music tracks shared on YouTube.\nIf you want the version of this dataset including prompt, see https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music_annoted.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe dataset includes descriptions, tags, and other metadata associated with 316,000 music videos uploaded to YouTube under the CC-BY license. These videos come from a diverse range of artists and genres, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","text-to-audio","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"youtube-cc-by-music","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music","creator_name":"WaveAI","creator_url":"https://huggingface.co/WaveGenAI","description":"üì∫ YouTube-CC-BY-Music üì∫\nYouTube-CC-BY-Music is a comprehensive collection of metadata for 316,000 music tracks shared on YouTube.\nIf you want the version of this dataset including prompt, see https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music_annoted.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe dataset includes descriptions, tags, and other metadata associated with 316,000 music videos uploaded to YouTube under the CC-BY license. These videos come from a diverse range of artists and genres, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","text-to-audio","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"youtube-cc-by-music","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music","creator_name":"WaveAI","creator_url":"https://huggingface.co/WaveGenAI","description":"üì∫ YouTube-CC-BY-Music üì∫\nYouTube-CC-BY-Music is a comprehensive collection of metadata for 316,000 music tracks shared on YouTube.\nIf you want the version of this dataset including prompt, see https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music_annoted.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe dataset includes descriptions, tags, and other metadata associated with 316,000 music videos uploaded to YouTube under the CC-BY license. These videos come from a diverse range of artists and genres, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","text-to-audio","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"youtube-cc-by-music","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music","creator_name":"WaveAI","creator_url":"https://huggingface.co/WaveGenAI","description":"üì∫ YouTube-CC-BY-Music üì∫\nYouTube-CC-BY-Music is a comprehensive collection of metadata for 316,000 music tracks shared on YouTube.\nIf you want the version of this dataset including prompt, see https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music_annoted.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe dataset includes descriptions, tags, and other metadata associated with 316,000 music videos uploaded to YouTube under the CC-BY license. These videos come from a diverse range of artists and genres, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","text-to-audio","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"youtube-cc-by-music","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music","creator_name":"WaveAI","creator_url":"https://huggingface.co/WaveGenAI","description":"üì∫ YouTube-CC-BY-Music üì∫\nYouTube-CC-BY-Music is a comprehensive collection of metadata for 316,000 music tracks shared on YouTube.\nIf you want the version of this dataset including prompt, see https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music_annoted.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe dataset includes descriptions, tags, and other metadata associated with 316,000 music videos uploaded to YouTube under the CC-BY license. These videos come from a diverse range of artists and genres, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","text-to-audio","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Nepali_ASR_Data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kshitizzzzzzz/Nepali_ASR_Data","creator_name":"kshitiz poudel","creator_url":"https://huggingface.co/kshitizzzzzzz","description":"kshitizzzzzzz/Nepali_ASR_Data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tr_500","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdulbarisoylemez/tr_500","creator_name":"Abdulbari S√∂ylemez","creator_url":"https://huggingface.co/Abdulbarisoylemez","description":"Abdulbarisoylemez/tr_500 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"synthetic_dem","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/synthetic_dem","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for synthetic_dem\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Synthetic DEM Corpus is the result of the first phase of a collaboration between El Colegio de M√©xico (COLMEX) and the Barcelona Supercomputing Center (BSC).\nIt all began when COLMEX was looking for a way to have its Diccionario del Espa√±ol de M√©xico (DEM), which can be accessed online, include the option to play each of its words with a Mexican accent through synthetic speech files. On the other hand, BSC is always on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/synthetic_dem.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"a","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HUY2612/a","creator_name":"LE","creator_url":"https://huggingface.co/HUY2612","description":"HUY2612/a dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"random500_text_audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdulbarisoylemez/random500_text_audio","creator_name":"Abdulbari S√∂ylemez","creator_url":"https://huggingface.co/Abdulbarisoylemez","description":"Abdulbarisoylemez/random500_text_audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"JA_audio_JA_text_180k_samples","keyword":"text-to-audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":"","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Japanese"],"keywords_longer_than_N":true},
	{"name":"JA_audio_JA_text_180k_samples","keyword":"audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":"","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Japanese"],"keywords_longer_than_N":true},
	{"name":"TV-44kHz-Full","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full","creator_name":"Thorsten M√ºller","creator_url":"https://huggingface.co/Thorsten-Voice","description":"\n\t\n\t\t\n\t\tThe \"Thorsten-Voice\" dataset\n\t\n\nThis truly open source (CC0 license) german (üá©üá™) voice dataset contains about 40 hours of transcribed voice recordings by Thorsten M√ºller, \na single male, native speaker in over 38.000 wave files.\n\nMono\nSamplerate: 44.100Hz\nTrimmed silence at begin/end\nDenoised\nNormalized to -24dB\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\n\"Please keep in mind, I am not a professional speaker, just an open source speech technology enthusiast who donates his voice. I contribute my personal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","German","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TV-44kHz-Full","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full","creator_name":"Thorsten M√ºller","creator_url":"https://huggingface.co/Thorsten-Voice","description":"\n\t\n\t\t\n\t\tThe \"Thorsten-Voice\" dataset\n\t\n\nThis truly open source (CC0 license) german (üá©üá™) voice dataset contains about 40 hours of transcribed voice recordings by Thorsten M√ºller, \na single male, native speaker in over 38.000 wave files.\n\nMono\nSamplerate: 44.100Hz\nTrimmed silence at begin/end\nDenoised\nNormalized to -24dB\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\n\"Please keep in mind, I am not a professional speaker, just an open source speech technology enthusiast who donates his voice. I contribute my personal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","German","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"RogerFlac84","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nadz88/RogerFlac84","creator_name":"nasser bassel","creator_url":"https://huggingface.co/nadz88","description":"nadz88/RogerFlac84 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"politico","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/labay/politico","creator_name":"Adam Labay","creator_url":"https://huggingface.co/labay","description":"\n\t\n\t\t\n\t\tPolitical Attack Ad Voices\n\t\n\nMore or less what it says on the tin. Male and Female voices trained on a couple dozen 2024 political attack ads each.\nSome day I might finetune them. Today is not that day.\n","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"rhapsodie","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datasets-CNRS/rhapsodie","creator_name":"datasets-CNRS","creator_url":"https://huggingface.co/datasets-CNRS","description":"\n[!NOTE]\nDataset origin: https://www.ortolang.fr/market/corpora/rhapsodie\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nCorpus de fran√ßais parl√© annot√© pour la prosodie et la syntaxe\nUn probl√®me central dans l‚Äô√©tude des langues parl√©es est la compr√©hension du r√¥le que jouent les indices intonosyntaxiques dans la segmentation du continuum sonore en unit√©s informationnelles et discursives. Se posent notamment les questions suivantes : quel est le degr√© de congruence entre les diff√©rentes unit√©s manipul√©es par la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datasets-CNRS/rhapsodie.","first_N":5,"first_N_keywords":["French","cc0-1.0","< 1K","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Harbour_hvm","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fivetech/Harbour_hvm","creator_name":"Antonio Linares","creator_url":"https://huggingface.co/fivetech","description":"fivetech/Harbour_hvm dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"text_to_speech_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kishor798/text_to_speech_dataset","creator_name":"Kishor thagunna","creator_url":"https://huggingface.co/Kishor798","description":"Kishor798/text_to_speech_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"AIME","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/disco-eth/AIME","creator_name":"DISCO","creator_url":"https://huggingface.co/disco-eth","description":"from datasets import load_dataset\ndataset = load_dataset('disco-eth/AIME')\n\n\n\t\n\t\t\n\t\tAIME: AI Music Evaluation Dataset\n\t\n\nThe AIME dataset contains 6,000 audio tracks generated by 12 music generation models in addition to 500 tracks from MTG-Jamendo.\nThe prompts used to generate music are combinations of representative and diverse tags from the MTG-Jamendo dataset.\nThe AIME dataset consists of two subsets. The AIME audio dataset and the AIME survey dataset.\nThe dataset contains the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/disco-eth/AIME.","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TaxaBench-8k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MVRL/TaxaBench-8k","creator_name":"Multimodal Vision Research Laboratory @ WashU","creator_url":"https://huggingface.co/MVRL","description":"\n\t\n\t\t\n\t\tPaper: TaxaBind: A Unified Embedding Space for Ecological Applications \n\t\n\n\n\t\n\t\t\n\t\tVenue: WACV 2025 \n\t\n\n\n\t\n\t\t\n\t\tGithub: https://github.com/mvrl/TaxaBind\n\t\n\n\n\t\n\t\t\n\t\tDataset Name: TaxaBench-8k\n\t\n\n\n\t\n\t\t\n\t\tDataset Description:\n\t\n\nTaxaBench-8k is a multimodal dataset containing six modalities - image, text, satellite image, audio, geographic location, and environmental features for evaluating large ecological models.\n\n\t\n\t\t\n\t\tUsage:\n\t\n\nPlease use the test_df.csv for reading data which‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MVRL/TaxaBench-8k.","first_N":5,"first_N_keywords":["zero-shot-classification","mit","1K - 10K","csv","Audio"],"keywords_longer_than_N":true},
	{"name":"TIE_shorts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raianand/TIE_shorts","creator_name":"Anand Rai","creator_url":"https://huggingface.co/raianand","description":"\n\t\n\t\t\n\t\tDataset Card for TIE_Shorts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTIE_shorts is a derived version of the Technical Indian English (TIE) dataset, a large-scale speech dataset (~ 8K hours) originally consisting of approximately 750 GB of content \nsourced from the NPTEL platform. The original TIE dataset contains around 9.8K technical lectures in English delivered by instructors from various regions across India, \nwith each lecture averaging about 50 minutes. These lectures cover a wide range of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/raianand/TIE_shorts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Itako","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jyunaichan/Itako","creator_name":"Li Nianci","creator_url":"https://huggingface.co/Jyunaichan","description":"Jyunaichan/Itako dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"VocalSound","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MahiA/VocalSound","creator_name":"Maha Tufail Agro","creator_url":"https://huggingface.co/MahiA","description":"\n\t\n\t\t\n\t\n\t\n\t\tVocalSound\n\t\n\nThis is an audio classification dataset for Vocal Sound Classification.\nClasses = 6  ¬†¬†,¬†¬†  Split = Train-Test\n\n\t\n\t\t\n\t\n\t\n\t\tStructure\n\t\n\n\naudios folder contains audio files.\ntrain.csv for training split and test.csv for the testing split.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nimport os\nimport zipfile\nimport shutil\nimport huggingface_hub\naudio_datasets_path = \"DATASET_PATH/Audio-Datasets\"\nif not os.path.exists(audio_datasets_path): print(f\"Given {audio_datasets_path=} does not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahiA/VocalSound.","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"indicvoices_hi_tagged_transcripts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_hi_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"PIAST","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hayeonbang/PIAST","creator_name":"Hayeon Bang","creator_url":"https://huggingface.co/Hayeonbang","description":"\n\t\n\t\t\n\t\n\t\n\t\tPIAST Dataset\n\t\n\nThis repo is for downloading transcribed MIDI & and text data of the PIAST Dataset. The audio files can be downloaded by following the process in the github.\n\n\t\n\t\t\n\t\n\t\n\t\tUPDATES\n\t\n\n\nNov 13, 2024: The MIDI files and text data for both PIAST-AT and PIAST-YT have been uploaded! However, due to a data preprocessing issue, some files are missing compared to the numbers reported in the paper. These will be added in a future version update, so please stay tuned!‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hayeonbang/PIAST.","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US","music"],"keywords_longer_than_N":true},
	{"name":"PIAST","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hayeonbang/PIAST","creator_name":"Hayeon Bang","creator_url":"https://huggingface.co/Hayeonbang","description":"\n\t\n\t\t\n\t\n\t\n\t\tPIAST Dataset\n\t\n\nThis repo is for downloading transcribed MIDI & and text data of the PIAST Dataset. The audio files can be downloaded by following the process in the github.\n\n\t\n\t\t\n\t\n\t\n\t\tUPDATES\n\t\n\n\nNov 13, 2024: The MIDI files and text data for both PIAST-AT and PIAST-YT have been uploaded! However, due to a data preprocessing issue, some files are missing compared to the numbers reported in the paper. These will be added in a future version update, so please stay tuned!‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hayeonbang/PIAST.","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US","music"],"keywords_longer_than_N":true},
	{"name":"Vulpisfoglia","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Vulpisfoglia","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Vulpisfoglia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"Vulpisfoglia","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Vulpisfoglia","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Vulpisfoglia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_ca","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_ca","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Catalan","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Pelafalan_Huruf_Hijaiyah","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Reinjin/Pelafalan_Huruf_Hijaiyah","creator_name":"Fawwaz Ijlal Muqsith","creator_url":"https://huggingface.co/Reinjin","description":"Ini adalah dataset suara pelafalan huruf hijaiyah yang memiliki 84 kelas, \ndataset diambil dari santri MTS / MA Pondok Tahfidz Yanbuul Qur'an Menawan Kudus,\nDataset ini saya gunakan untuk melakukan skripsi dan silahkan gunakan jika diperlukan\n","first_N":5,"first_N_keywords":["afl-3.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pavanyellow/librispeech_asr","creator_name":"Pavan Katta","creator_url":"https://huggingface.co/pavanyellow","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tLibriSpeech ASR 2s Splits Dataset\n\t\n\nVersion of LibriSpeech ASR corpus split into 2s clips.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset from the Hub\ndataset = load_dataset(\"pavanyellow/librispeech_asr\")\n\n# Or load a specific split\ndataset = load_dataset(\"pavanyellow/librispeech_asr\", split=\"train\")\n\n# Access the data\nfor example in dataset['train'][:5]:\n   audio = example['audio']\n   text = example['text']\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr","keyword":"speaker-identification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pavanyellow/librispeech_asr","creator_name":"Pavan Katta","creator_url":"https://huggingface.co/pavanyellow","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tLibriSpeech ASR 2s Splits Dataset\n\t\n\nVersion of LibriSpeech ASR corpus split into 2s clips.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset from the Hub\ndataset = load_dataset(\"pavanyellow/librispeech_asr\")\n\n# Or load a specific split\ndataset = load_dataset(\"pavanyellow/librispeech_asr\", split=\"train\")\n\n# Access the data\nfor example in dataset['train'][:5]:\n   audio = example['audio']\n   text = example['text']\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Lappland-the-Decadenza","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland-the-Decadenza","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland-the-Decadenza dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"Lappland-the-Decadenza","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland-the-Decadenza","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland-the-Decadenza dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"tatar-speech-commands","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/tatar-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tAn Open-Source Tatar Speech Commands Dataset\n\t\n\nPaper: Paper\nAn Open-Source Tatar Speech Commands Dataset for IoT and Robotics Applications\nGitHub: https://github.com/IS2AI/TatarSCR\nDescription:\nThe dataset covers 35 commands used in robotics, IoT, and smart systems. In total, the dataset contains 3,547 one-second utterances from 153 people. The utterances were saved in the WAV format with a sampling rate of 16 kHz. \nCitation: The project was developed in academic collaboration between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/tatar-speech-commands.","first_N":5,"first_N_keywords":["audio-classification","Tatar","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"tatar-speech-commands","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/tatar-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tAn Open-Source Tatar Speech Commands Dataset\n\t\n\nPaper: Paper\nAn Open-Source Tatar Speech Commands Dataset for IoT and Robotics Applications\nGitHub: https://github.com/IS2AI/TatarSCR\nDescription:\nThe dataset covers 35 commands used in robotics, IoT, and smart systems. In total, the dataset contains 3,547 one-second utterances from 153 people. The utterances were saved in the WAV format with a sampling rate of 16 kHz. \nCitation: The project was developed in academic collaboration between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/tatar-speech-commands.","first_N":5,"first_N_keywords":["audio-classification","Tatar","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"tatar-speech-commands","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/tatar-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tAn Open-Source Tatar Speech Commands Dataset\n\t\n\nPaper: Paper\nAn Open-Source Tatar Speech Commands Dataset for IoT and Robotics Applications\nGitHub: https://github.com/IS2AI/TatarSCR\nDescription:\nThe dataset covers 35 commands used in robotics, IoT, and smart systems. In total, the dataset contains 3,547 one-second utterances from 153 people. The utterances were saved in the WAV format with a sampling rate of 16 kHz. \nCitation: The project was developed in academic collaboration between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/tatar-speech-commands.","first_N":5,"first_N_keywords":["audio-classification","Tatar","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Turkish_Speech_Corpus","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Turkish_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tTurkish Speech Corpus (TSC)\n\t\n\nThis repository presents an open-source Turkish Speech Corpus, introduced in \"Multilingual Speech Recognition for Turkic Languages\". The corpus contains 218.2 hours of transcribed speech with 186,171 utterances and is the largest publicly available Turkish dataset of its kind at that time. \nPaper: Multilingual Speech Recognition for Turkic Languages.  \nGitHub Repository: https://github.com/IS2AI/TurkicASR\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\n@Article{info14020074‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Turkish_Speech_Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Turkish_Speech_Corpus","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Turkish_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tTurkish Speech Corpus (TSC)\n\t\n\nThis repository presents an open-source Turkish Speech Corpus, introduced in \"Multilingual Speech Recognition for Turkic Languages\". The corpus contains 218.2 hours of transcribed speech with 186,171 utterances and is the largest publicly available Turkish dataset of its kind at that time. \nPaper: Multilingual Speech Recognition for Turkic Languages.  \nGitHub Repository: https://github.com/IS2AI/TurkicASR\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\n@Article{info14020074‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Turkish_Speech_Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"kazakh-speech-commands","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/kazakh-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tKazakh Speech Commands Dataset\n\t\n\nPaper: Speech Command Recognition: Text-to-Speech and Speech Corpus Scraping Are All You Need\nRepository: https://github.com/IS2AI/Kazakh-Speech-Commands-Dataset\nDescription: The dataset contains 3,623 utterances for 35 commands. The utterances were saved in the WAV format with a sampling rate of 16 kHz. The dataset was collected from 119 participants (62 males, 57 females) from different regions of Kazakhstan.\n\n\t\n\t\t\nID\nCommand (en)\nCommand (kk)\n#‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/kazakh-speech-commands.","first_N":5,"first_N_keywords":["audio-classification","Kazakh","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"kazakh-speech-commands","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/kazakh-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tKazakh Speech Commands Dataset\n\t\n\nPaper: Speech Command Recognition: Text-to-Speech and Speech Corpus Scraping Are All You Need\nRepository: https://github.com/IS2AI/Kazakh-Speech-Commands-Dataset\nDescription: The dataset contains 3,623 utterances for 35 commands. The utterances were saved in the WAV format with a sampling rate of 16 kHz. The dataset was collected from 119 participants (62 males, 57 females) from different regions of Kazakhstan.\n\n\t\n\t\t\nID\nCommand (en)\nCommand (kk)\n#‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/kazakh-speech-commands.","first_N":5,"first_N_keywords":["audio-classification","Kazakh","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"kazakh-speech-commands","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/kazakh-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tKazakh Speech Commands Dataset\n\t\n\nPaper: Speech Command Recognition: Text-to-Speech and Speech Corpus Scraping Are All You Need\nRepository: https://github.com/IS2AI/Kazakh-Speech-Commands-Dataset\nDescription: The dataset contains 3,623 utterances for 35 commands. The utterances were saved in the WAV format with a sampling rate of 16 kHz. The dataset was collected from 119 participants (62 males, 57 females) from different regions of Kazakhstan.\n\n\t\n\t\t\nID\nCommand (en)\nCommand (kk)\n#‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/kazakh-speech-commands.","first_N":5,"first_N_keywords":["audio-classification","Kazakh","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"example_TTS","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yasel/example_TTS","creator_name":"Yassine ELKHEIR","creator_url":"https://huggingface.co/Yasel","description":"Yasel/example_TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dataset_cp","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NaSugu/dataset_cp","creator_name":"Yame","creator_url":"https://huggingface.co/NaSugu","description":"NaSugu/dataset_cp dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"zeroth-STT-Ko","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\n\t\n\t\t\n\t\tZeroth-STT-Ko Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset combines the following publicly available Korean language datasets:\nJunhoee/STT_Korean_Dataset_80000\nand\nZeroth-Korean Dataset (from Project: Zeroth, by GoodAtlas and Gridspace)\nThis provides over 102K rows of data (sentences) in total.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"jacob-common-voice-19-zh-TW-curated","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jacob-common-voice-19-zh-TW-curated","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/jacob-common-voice-19-zh-TW-curated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chinese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"voice","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"GnA_Voices","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Stoned-Code/GnA_Voices","creator_name":"Javin Tanoue","creator_url":"https://huggingface.co/Stoned-Code","description":"\n\t\n\t\t\n\t\tGnA Voices\n\t\n\nA collection of voices from Anime and Games.\n\n\t\n\t\t\n\t\tVoices\n\t\n\nGLaDOS: 1069 Samples\n","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ar-SA-xVectore","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ISTNetworks/ar-SA-xVectore","creator_name":"RAD team","creator_url":"https://huggingface.co/ISTNetworks","description":"ISTNetworks/ar-SA-xVectore dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TangWingSum_11458020_TseBatYik_11458056","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eduhk-lin3046/TangWingSum_11458020_TseBatYik_11458056","creator_name":"EdUHK LIN3046 Language Information Management","creator_url":"https://huggingface.co/eduhk-lin3046","description":"eduhk-lin3046/TangWingSum_11458020_TseBatYik_11458056 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"asm3_ray_riley_chloe","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eduhk-lin3046/asm3_ray_riley_chloe","creator_name":"EdUHK LIN3046 Language Information Management","creator_url":"https://huggingface.co/eduhk-lin3046","description":"This is a recorded memo in Cantonese for people to try telling jokes.\n11553167 Lin Ching Yee 11542704 Chau Tsz Yu 11541475 Yu Kwok Hung\n\n","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vi-songs-2k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nghialt/vi-songs-2k","creator_name":"L√™ T√≠n Nghƒ©a","creator_url":"https://huggingface.co/nghialt","description":"\n\t\n\t\t\n\t\tMusic Query Dataset\n\t\n\nA comprehensive dataset designed to support music recognition systems. This dataset includes metadata, audio, and lyrics for 2,000 popular songs, enabling advanced music retrieval and query applications. The dataset was built by crawling and processing data from hopamchuan.com and YouTube.\n\n\n\t\n\t\t\n\t\tDataset Contents\n\t\n\nThe dataset is structured into three components:\n\ninfos.jsonA JSON file containing metadata for each song. Each entry includes:\n\nSong name\nAuthor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nghialt/vi-songs-2k.","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"EchoSet","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JusperLee/EchoSet","creator_name":"Kai Li","creator_url":"https://huggingface.co/JusperLee","description":"JusperLee/EchoSet dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"uzbek-speech-corpus","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murodbek/uzbek-speech-corpus","creator_name":"Abror Shopulatov","creator_url":"https://huggingface.co/murodbek","description":"\n\t\n\t\t\n\t\tUzbek Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Uzbek speech corpus (USC) has been developed in collaboration between ISSAI and the Image and Speech Processing Laboratory in the Department of Computer Systems of the Tashkent University of Information Technologies. The USC comprises 958 different speakers with a total of 105 hours of transcribed audio recordings. To ensure high quality, the USC has been manually checked by native speakers. The USC is primarily designed for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/murodbek/uzbek-speech-corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-test2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deniskaanalpay/tts-test2","creator_name":"denis kaan alpay","creator_url":"https://huggingface.co/deniskaanalpay","description":"deniskaanalpay/tts-test2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Turkish","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"HAS-Corpus","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Prasanna18/HAS-Corpus","creator_name":"Prasanna Muppidwar","creator_url":"https://huggingface.co/Prasanna18","description":"Prasanna18/HAS-Corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"HAS-Corpus","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Prasanna18/HAS-Corpus","creator_name":"Prasanna Muppidwar","creator_url":"https://huggingface.co/Prasanna18","description":"Prasanna18/HAS-Corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Tamazight-ASR-Dataset-v2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2","creator_name":"Soufiane Dahimi","creator_url":"https://huggingface.co/SoufianeDahimi","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains speech segments in Tamazight (specifically focusing on the Tachelhit dialect) paired with their corresponding Arabic transcriptions. It is designed to support the development of automatic speech recognition (ASR) systems for the Tamazight language, particularly for translation into Modern Standard Arabic.\nThis is an actively growing dataset, with regular updates and new data points being‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ase","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gafoart/ase","creator_name":"Cesar Rodriguez","creator_url":"https://huggingface.co/gafoart","description":"gafoart/ase dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Video"],"keywords_longer_than_N":true},
	{"name":"Throat_and_Acoustic_Pairing_Speech_Dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yskim3271/Throat_and_Acoustic_Pairing_Speech_Dataset","creator_name":"yunsik kim","creator_url":"https://huggingface.co/yskim3271","description":"\n\t\n\t\t\n\t\tTAPS: Throat and Acoustic Paired Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\t1. DATASET SUMMARY\n\t\n\nThe Throat and Acoustic Paired Speech (TAPS) dataset is a standardized corpus designed for deep learning-based speech enhancement, specifically targeting throat microphone recordings. Throat microphones effectively suppress background noise but suffer from high-frequency attenuation due to the low-pass filtering effect of the skin and tissue. The dataset provides paired recordings from 60 native Korean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yskim3271/Throat_and_Acoustic_Pairing_Speech_Dataset.","first_N":5,"first_N_keywords":["Korean","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Audio_PAIRS","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/UCSC-VLAA/Audio_PAIRS","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","description":"UCSC-VLAA/Audio_PAIRS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai_saamgwokjinji_jyutping","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/zoengjyutgaai_saamgwokjinji_jyutping","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ - Á≤µÊãºÊ©üÊ¢∞ÁøªË≠Ø\n\t\n\nÂë¢ÂÄã dataset ‰øÇÂà©Áî® Wav2Vec Bert 2.0  hon9kon9ize/wav2vec2bert-jyutping Â∞á ÁøªË≠ØÊàêÁ≤µË™ûÊãºÈü≥„ÄÇË¶ÅÊ≥®ÊÑèÔºÅÁøªË≠Ø‰∏≠ÂèØËÉΩÊúâÈåØË™§ÔºåÁøªË≠ØÁµêÊûúÊú™Á∂ì‰∫∫ÊâãÈ©óË≠â„ÄÇ\n","first_N":5,"first_N_keywords":["Yue Chinese","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Theresa-Recording","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa-Recording","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa-Recording dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Japanese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ICKAN","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NMLAB8/ICKAN","creator_name":"NM.LAB","creator_url":"https://huggingface.co/NMLAB8","description":"NMLAB8/ICKAN dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Necaxa_1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/plesniar/Necaxa_1","creator_name":"Allan Plesniarski","creator_url":"https://huggingface.co/plesniar","description":"plesniar/Necaxa_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"asr_malayalam","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aoxo/asr_malayalam","creator_name":"Alosh Denny","creator_url":"https://huggingface.co/aoxo","description":"aoxo/asr_malayalam dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"anta_women_tts","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galsenai/anta_women_tts","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","description":"\n\t\n\t\t\n\t\tAnta Women TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a cleaned version of the Wolof TTS dataset by GalsenAI. \nWe extracted the female voice, denoised it and enhanced it with the Resemble Enhance library. \nWe also cleaned up the annotations by removing special characters, emojis, Arabic and Russian characters. \nWe've corrected a few annotation errors, but there are potentially many more to come. \nSome lines and audios judged not qualitative enough have been removed from the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/galsenai/anta_women_tts.","first_N":5,"first_N_keywords":["text-to-speech","Wolof","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ipapack_plus_2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anyspeech/ipapack_plus_2","creator_name":"AnySpeech","creator_url":"https://huggingface.co/anyspeech","description":"anyspeech/ipapack_plus_2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"ipapack_plus_3","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anyspeech/ipapack_plus_3","creator_name":"AnySpeech","creator_url":"https://huggingface.co/anyspeech","description":"anyspeech/ipapack_plus_3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ipapack_plus_4","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anyspeech/ipapack_plus_4","creator_name":"AnySpeech","creator_url":"https://huggingface.co/anyspeech","description":"anyspeech/ipapack_plus_4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ipapack_plus_6","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anyspeech/ipapack_plus_6","creator_name":"AnySpeech","creator_url":"https://huggingface.co/anyspeech","description":"anyspeech/ipapack_plus_6 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Ado1stalbum","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aeska4444/Ado1stalbum","creator_name":"aeska","creator_url":"https://huggingface.co/aeska4444","description":"aeska4444/Ado1stalbum dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"VZ","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/medallo/VZ","creator_name":"ciry","creator_url":"https://huggingface.co/medallo","description":"medallo/VZ dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"CTMU","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fivetech/CTMU","creator_name":"Antonio Linares","creator_url":"https://huggingface.co/fivetech","description":"fivetech/CTMU dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Bengali","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tBengali Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Bengali monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Bengali\nTotal Duration: ~15.06 hours (Male: 10.05 hours, Female: 5.01 hours)\nAudio Format: WAV\nSampling Rate:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali.","first_N":5,"first_N_keywords":["text-to-speech","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"latam-spanish-speech-orpheus-tts-24khz","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz","creator_name":"Gian Diego Javes Lecca","creator_url":"https://huggingface.co/GianDiego","description":"\n\t\n\t\t\n\t\tLATAM Spanish High-Quality Speech Dataset (24kHz - Orpheus TTS Ready)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains approximately 24 hours of high-quality speech audio in Latin American Spanish, specifically prepared for Text-to-Speech (TTS) applications like OrpheusTTS, which require a 24kHz sampling rate.\nThe audio files are derived from the Crowdsourced high-quality speech datasets made by Google and were obtained via OpenSLR. The original recordings were high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","monolingual","original:openslr","Spanish"],"keywords_longer_than_N":true},
	{"name":"latam-spanish-speech-orpheus-tts-24khz","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz","creator_name":"Gian Diego Javes Lecca","creator_url":"https://huggingface.co/GianDiego","description":"\n\t\n\t\t\n\t\tLATAM Spanish High-Quality Speech Dataset (24kHz - Orpheus TTS Ready)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains approximately 24 hours of high-quality speech audio in Latin American Spanish, specifically prepared for Text-to-Speech (TTS) applications like OrpheusTTS, which require a 24kHz sampling rate.\nThe audio files are derived from the Crowdsourced high-quality speech datasets made by Google and were obtained via OpenSLR. The original recordings were high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","monolingual","original:openslr","Spanish"],"keywords_longer_than_N":true},
	{"name":"acoustic-music-scenes","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/boxallcharlie/acoustic-music-scenes","creator_name":"Charlie Boxall","creator_url":"https://huggingface.co/boxallcharlie","description":"boxallcharlie/acoustic-music-scenes dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ViVoicePP","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/ViVoicePP","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"hr16/ViVoicePP dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","text","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"google-cloud-voice-mix","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/google-cloud-voice-mix","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"unlimitedbytes/google-cloud-voice-mix dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"talromur3_without_emotions","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/atlithor/talromur3_without_emotions","creator_name":"Atli","creator_url":"https://huggingface.co/atlithor","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis corpus is an emotion-less version of Talromur3_with_prompts. talromur_3_without_emotions is a prompt-labelled corpus that can be used for fine-tuning models, such as ParlerTTS.The corpus consists of approximately 15,000 utterances, spoken by 7 named speakers in 6 different emotions (see more info here).\nThe dataset is an expanded version of Talromur-3: an Icelandic emotional speech corpus.We have added natural-language descriptions of utterance-level pitch, speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/atlithor/talromur3_without_emotions.","first_N":5,"first_N_keywords":["text-to-speech","Icelandic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","description":"\n\n  \n\n\n\n  \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to use.For a detailed guide on how this dataset was created, follow the steps outlined in the GitHub repository: ParquetToHuggingFace.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","description":"\n\n  \n\n\n\n  \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to use.For a detailed guide on how this dataset was created, follow the steps outlined in the GitHub repository: ParquetToHuggingFace.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","description":"\n\n  \n\n\n\n  \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to use.For a detailed guide on how this dataset was created, follow the steps outlined in the GitHub repository: ParquetToHuggingFace.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"Dog-Vocal-Separation","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Dog-Vocal-Separation","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\t[Dataset] Dog Vocal Separation\n\t\n\nIMPORTANT NOTE for the IJCAI-2025 challenge\n\n[Jun. 1st, 2025] The validation set has been updated.\n[Apr. 25th, 2025] The dataset has some changes. Sorry for the inconvenience.\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n.\n‚îú‚îÄ‚îÄ train\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ train_pairs.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ dog\n‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 6357ca529eec8ca42a1fa588e0725904.wav\n‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ cd06d290e0ebc76a137bd44ebec4d5fd.wav\n‚îÇ   ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ mixture\n‚îÇ¬†¬†  ¬†¬† ‚îú‚îÄ‚îÄ f046b186c4def7428cd627ae98d1762d.wav\n‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Dog-Vocal-Separation.","first_N":5,"first_N_keywords":["audio-to-audio","English","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Dog-Vocal-Separation","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Dog-Vocal-Separation","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\t[Dataset] Dog Vocal Separation\n\t\n\nIMPORTANT NOTE for the IJCAI-2025 challenge\n\n[Jun. 1st, 2025] The validation set has been updated.\n[Apr. 25th, 2025] The dataset has some changes. Sorry for the inconvenience.\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n.\n‚îú‚îÄ‚îÄ train\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ train_pairs.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ dog\n‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 6357ca529eec8ca42a1fa588e0725904.wav\n‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ cd06d290e0ebc76a137bd44ebec4d5fd.wav\n‚îÇ   ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ mixture\n‚îÇ¬†¬†  ¬†¬† ‚îú‚îÄ‚îÄ f046b186c4def7428cd627ae98d1762d.wav\n‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Dog-Vocal-Separation.","first_N":5,"first_N_keywords":["audio-to-audio","English","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Dog-Vocal-Separation","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArlingtonCL2/Dog-Vocal-Separation","creator_name":"Arlington Computational Linguistic Lab","creator_url":"https://huggingface.co/ArlingtonCL2","description":"\n\t\n\t\t\n\t\t[Dataset] Dog Vocal Separation\n\t\n\nIMPORTANT NOTE for the IJCAI-2025 challenge\n\n[Jun. 1st, 2025] The validation set has been updated.\n[Apr. 25th, 2025] The dataset has some changes. Sorry for the inconvenience.\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n.\n‚îú‚îÄ‚îÄ train\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ train_pairs.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ dog\n‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 6357ca529eec8ca42a1fa588e0725904.wav\n‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ cd06d290e0ebc76a137bd44ebec4d5fd.wav\n‚îÇ   ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ mixture\n‚îÇ¬†¬†  ¬†¬† ‚îú‚îÄ‚îÄ f046b186c4def7428cd627ae98d1762d.wav\n‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArlingtonCL2/Dog-Vocal-Separation.","first_N":5,"first_N_keywords":["audio-to-audio","English","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"EN_Emilia_Yodas_616h","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MrDragonFox/EN_Emilia_Yodas_616h","creator_name":"MrDragonFox","creator_url":"https://huggingface.co/MrDragonFox","description":"the dataset is 616h out of the English part from https://huggingface.co/datasets/amphion/Emilia-Dataset ( Emilia Yodas - cc by 4.0)\naudio event classified via scribe v1 (elevenlabs stt/asr)\nfacebook audio aestetics to be used as prefilter\nthe dataset is very much at a v1 -\nif you want to help - lets talk\nhttps://discord.gg/RUs3uzBdW3 (nsfw is fully opt in only - as sfw)\nif you want full transaction timestamps as they come from scribe v1 - they are cc by 4.0 NC and can be found here‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrDragonFox/EN_Emilia_Yodas_616h.","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"muz-kz","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/01gumano1d/muz-kz","creator_name":"gumano1d","creator_url":"https://huggingface.co/01gumano1d","description":"01gumano1d/muz-kz dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"SoulTide-AudioData-Dataset","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zwa73/SoulTide-AudioData-Dataset","creator_name":"zwa73","creator_url":"https://huggingface.co/zwa73","description":"character____[char]________resource____________audio     - ÂéüÂßãÈü≥È¢ë____________srt       - ÂéüÂßãsrt____________processed - Âà©Áî® Process-Resource Ê†πÊçÆÂéüÂßãËµÑÊ∫êÂ§ÑÁêÜÂêéÁöÑËµÑÊ∫ê________recognized    - Whisper-LargeV2 ËØÜÂà´ÁöÑsrt________calibrated    - ‰∫∫Â∑•Ê†°ÂáÜÁöÑsrt________tmp           - build‰∏¥Êó∂Êñá‰ª∂  \nÊê≠ÈÖçÊ≠§ÁÆ°ÁêÜÂô®Êù•ÁîüÊàêÊâÄÈúÄÁöÑËÆ≠ÁªÉÈõÜ:https://github.com/Sosarciel/SoulTide-AudioData-Manager\n","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"JA_Emilia_Yodas_266h","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MrDragonFox/JA_Emilia_Yodas_266h","creator_name":"MrDragonFox","creator_url":"https://huggingface.co/MrDragonFox","description":"the dataset is 266h out of the japanese part from https://huggingface.co/datasets/amphion/Emilia-Dataset ( Emilia Yodas - cc by 4.0)\naudio event classified via scribe v1 (elevenlabs stt/asr)\nfacebook audio aestetics to be used as prefilter\nthe dataset is very much at a v1 -\nif you want to help - lets talk\nhttps://discord.gg/RUs3uzBdW3 (nsfw is fully opt in only - as sfw)\nif you want full transaction timestamps as they come from scribe v1 - they are cc by 4.0 NC and can be found here‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrDragonFox/JA_Emilia_Yodas_266h.","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"multi-dataset_audio","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yuting-Zhao/multi-dataset_audio","creator_name":"ZHAO YUTING","creator_url":"https://huggingface.co/Yuting-Zhao","description":"Yuting-Zhao/multi-dataset_audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"thai-ser","keyword":"audio-classification","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/airesearch/thai-ser","creator_name":"VISTEC-depa AI Research Institute of Thailand","creator_url":"https://huggingface.co/airesearch","description":"\n\t\n\t\t\n\t\tüáπüá≠ THAI-SER Dataset üé≠\n\t\n\n[üìù Paper (preprint)]\nPublished by: AI Research Institute of Thailand (AIResearch)\nIn collaboration with:  \n\nVidyasirimedhi Institute of Science and Technology (VISTEC)  \nDigital Economy Promotion Agency (depa)  \nDepartment of Computer Engineering, Faculty of Engineering, Chulalongkorn University  \nDepartment of Dramatic Arts, Faculty of Arts, Chulalongkorn University\n\nSponsored by: Advanced Info Services Public Company Limited (AIS), and Siam Commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/airesearch/thai-ser.","first_N":5,"first_N_keywords":["audio-classification","Thai","cc-by-sa-4.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"thai-ser","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/airesearch/thai-ser","creator_name":"VISTEC-depa AI Research Institute of Thailand","creator_url":"https://huggingface.co/airesearch","description":"\n\t\n\t\t\n\t\tüáπüá≠ THAI-SER Dataset üé≠\n\t\n\n[üìù Paper (preprint)]\nPublished by: AI Research Institute of Thailand (AIResearch)\nIn collaboration with:  \n\nVidyasirimedhi Institute of Science and Technology (VISTEC)  \nDigital Economy Promotion Agency (depa)  \nDepartment of Computer Engineering, Faculty of Engineering, Chulalongkorn University  \nDepartment of Dramatic Arts, Faculty of Arts, Chulalongkorn University\n\nSponsored by: Advanced Info Services Public Company Limited (AIS), and Siam Commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/airesearch/thai-ser.","first_N":5,"first_N_keywords":["audio-classification","Thai","cc-by-sa-4.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"thai-ser","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/airesearch/thai-ser","creator_name":"VISTEC-depa AI Research Institute of Thailand","creator_url":"https://huggingface.co/airesearch","description":"\n\t\n\t\t\n\t\tüáπüá≠ THAI-SER Dataset üé≠\n\t\n\n[üìù Paper (preprint)]\nPublished by: AI Research Institute of Thailand (AIResearch)\nIn collaboration with:  \n\nVidyasirimedhi Institute of Science and Technology (VISTEC)  \nDigital Economy Promotion Agency (depa)  \nDepartment of Computer Engineering, Faculty of Engineering, Chulalongkorn University  \nDepartment of Dramatic Arts, Faculty of Arts, Chulalongkorn University\n\nSponsored by: Advanced Info Services Public Company Limited (AIS), and Siam Commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/airesearch/thai-ser.","first_N":5,"first_N_keywords":["audio-classification","Thai","cc-by-sa-4.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_eseu_v1.0","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/composite_corpus_eseu_v1.0","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tComposite bilingual dataset for Spanish and Basque made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/es: a portion of the \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\nmozilla-foundation/common_voice_18_0/eu:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_eseu_v1.0.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","Spanish","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"CycleGan_selected","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/audio-tau/CycleGan_selected","creator_name":"audio-tau","creator_url":"https://huggingface.co/audio-tau","description":"audio-tau/CycleGan_selected dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"BirdCLEF-2023","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wesfggfd/BirdCLEF-2023","creator_name":"Xinyu Chen","creator_url":"https://huggingface.co/wesfggfd","description":"wesfggfd/BirdCLEF-2023 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"indic-en-bn","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/satarupa22/indic-en-bn","creator_name":"Satarupa Deb","creator_url":"https://huggingface.co/satarupa22","description":"\n\t\n\t\t\n\t\tReferences:\n\t\n\n@article{jain2024bhasaanuvaad,\n  title   = {BhasaAnuvaad: A Speech Translation Dataset for 14 Indian Languages},\n  author  = {Sparsh Jain and Ashwin Sankar and Devilal Choudhary and Dhairya Suman and Nikhil Narasimhan and Mohammed Safi Ur Rahman Khan and Anoop Kunchukuttan and Mitesh M Khapra and Raj Dabre},\n  year    = {2024},\n  journal = {arXiv preprint arXiv: 2411.04699}\n}\n\n","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"qirimtatar-tts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/qirimtatar-tts","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tVoices\n\t\n\n\n\t\n\t\t\n\t\tMale\n\t\n\n\n\t\n\t\t\n\t\tAbibullah\n\t\n\n\nQuality: high\nDuration: 2h + 50m\nAudio formats: OPUS\nFrequency: 48000 Hz\n\n\n\t\n\t\t\n\t\tArslan\n\t\n\n\nQuality: high\nDuration: 40m + 40m\nAudio formats: OPUS\nFrequency: 48000 Hz\n\n\n\t\n\t\t\n\t\tFemale\n\t\n\n\n\t\n\t\t\n\t\tSevil\n\t\n\n\nQuality:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/qirimtatar-tts.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"dataset3","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlenJoy47/dataset3","creator_name":"Alen Joy","creator_url":"https://huggingface.co/AlenJoy47","description":"AlenJoy47/dataset3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts-crh-abibullah","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/tts-crh-abibullah","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\nThis is subset of Abibullah voice with train/test splits.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nQuality: high\nDuration: 2h50m\nFrequency: 48 kHz\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { qirimtatar-tts (Revision c2ceec6)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-abibullah.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-crh-sevil","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/tts-crh-sevil","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\nThis is subset of Sevil voice with train/test splits.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nQuality: high\nDuration: 2h29m\nFrequency: 48 kHz\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { qirimtatar-tts (Revision c2ceec6) }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-sevil.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-crh-arslan","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/tts-crh-arslan","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\nThis is subset of Arslan voice with train/test splits.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nQuality: high\nDuration: 1h20m\nFrequency: 48 kHz\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { qirimtatar-tts (Revision c2ceec6) }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-arslan.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-tetiana","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-tetiana","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-tetiana.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-mykyta","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-mykyta","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-mykyta.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ScreenTalk-XS","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Itbanque/ScreenTalk-XS","creator_name":"Itbanque","creator_url":"https://huggingface.co/Itbanque","description":"\n\t\n\t\t\n\t\tüé¨ ScreenTalk-XS: Sample Speech Dataset from Screen Content üñ•Ô∏è\n\t\n\n  \n\n\t\n\t\t\n\t\n\t\n\t\tüì¢ What is ScreenTalk-XS?\n\t\n\nScreenTalk-XS is a high-quality transcribed speech dataset containing 10k speech samples from diverse screen content.It is designed for automatic speech recognition (ASR), natural language processing (NLP), and conversational AI research.  \n‚úÖ This dataset is freely available for research and educational use.üîπ If you need a larger dataset with more diverse speech samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Itbanque/ScreenTalk-XS.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"FLEURS_translation_en","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Allen172/FLEURS_translation_en","creator_name":"Allen yu","creator_url":"https://huggingface.co/Allen172","description":"Allen172/FLEURS_translation_en dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"voice-of-america","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/voice-of-america","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tVoice of America for  üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\nDuration: 390.99 hours\n\nmean: 4.315471\nstd: 3.63682\nmin: 0.2995625\n25%: 1.82\n50%: 3.42\n75%: 5.628\nmax: 29.98\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/voice-of-america.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Ukrainian","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"nepali_speech_to_text","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text","creator_name":"Pujan Paudel","creator_url":"https://huggingface.co/pujanpaudel","description":"\n\t\n\t\t\n\t\tNepali Speech-to-Text Dataset\n\t\n\nThis repository contains a dataset for Automatic Speech Recognition (ASR) in the Nepali language. The dataset is designed for supervised learning tasks and includes audio files along with their corresponding transcriptions. The audio samples have been collected from various open-source platforms and other publicly available sources on the internet.  \nEach audio file has an average length of 15 seconds and has been converted into a consistent WAV format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Nepali","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"SpeechInstructBench","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ddwang2000/SpeechInstructBench","creator_name":"ElaineWang","creator_url":"https://huggingface.co/ddwang2000","description":"\n\t\n\t\t\n\t\tSpeechInstructBench\n\t\n\nArxiv: https://arxiv.org/abs/2503.02769\nThis is the SpeechInstructBench dataset download page.  \nSpeechInstructBench is a multilingual (Chinese and English) benchmark designed to evaluate the instruction-following capabilities of speech models. Instruction-following refers to a model‚Äôs ability to accurately interpret and execute user-provided natural language directives while strictly adhering to all specified constraints and requirements. To comprehensively‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ddwang2000/SpeechInstructBench.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"havacilik-veriseti","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mehmedadymn/havacilik-veriseti","creator_name":"adƒ±yaman","creator_url":"https://huggingface.co/mehmedadymn","description":"\n\t\n\t\t\n\t\tATC Veri K√ºmesi - Whisper Modeli ile ƒ∞nce Ayar\n\t\n\nBu veri k√ºmesi, OpenAI'nin Whisper modelini, Hava Trafik Kontrol√º (ATC) ileti≈üimlerinde transkripsiyon doƒüruluƒüunu artƒ±rmak amacƒ±yla ince ayar yapmak i√ßin olu≈üturulmu≈ütur. Veri k√ºmesi, iki ana kaynaktan alƒ±nan transkripsiyonlar ve kar≈üƒ±lƒ±k gelen ses dosyalarƒ±nƒ± i√ßermektedir: ATCO2 ve UWB-ATCC korpusu, √∂zellikle havacƒ±lƒ±kla ilgili ileti≈üimler i√ßin se√ßilmi≈ütir. Veri k√ºmesi, Otomatik Konu≈üma Tanƒ±ma (ASR) projelerinde kullanƒ±lmak √ºzere‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mehmedadymn/havacilik-veriseti.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","Turkish","English","mit"],"keywords_longer_than_N":true},
	{"name":"havacilik-veriseti","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mehmedadymn/havacilik-veriseti","creator_name":"adƒ±yaman","creator_url":"https://huggingface.co/mehmedadymn","description":"\n\t\n\t\t\n\t\tATC Veri K√ºmesi - Whisper Modeli ile ƒ∞nce Ayar\n\t\n\nBu veri k√ºmesi, OpenAI'nin Whisper modelini, Hava Trafik Kontrol√º (ATC) ileti≈üimlerinde transkripsiyon doƒüruluƒüunu artƒ±rmak amacƒ±yla ince ayar yapmak i√ßin olu≈üturulmu≈ütur. Veri k√ºmesi, iki ana kaynaktan alƒ±nan transkripsiyonlar ve kar≈üƒ±lƒ±k gelen ses dosyalarƒ±nƒ± i√ßermektedir: ATCO2 ve UWB-ATCC korpusu, √∂zellikle havacƒ±lƒ±kla ilgili ileti≈üimler i√ßin se√ßilmi≈ütir. Veri k√ºmesi, Otomatik Konu≈üma Tanƒ±ma (ASR) projelerinde kullanƒ±lmak √ºzere‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mehmedadymn/havacilik-veriseti.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","Turkish","English","mit"],"keywords_longer_than_N":true},
	{"name":"trove-lib-documentation-assets","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BatsResearch/trove-lib-documentation-assets","creator_name":"Bats Research","creator_url":"https://huggingface.co/BatsResearch","description":"BatsResearch/trove-lib-documentation-assets dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"vocsim-applications-avian-perception","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymous-submission000/vocsim-applications-avian-perception","creator_name":"Anonymous","creator_url":"https://huggingface.co/anonymous-submission000","description":"\n\t\n\t\t\n\t\tDataset Card for VocSim - Avian Perception Alignment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is used in the VocSim benchmark paper, specifically designed to evaluate how well neural audio embeddings align with biological perceptual judgments of similarity. It utilizes data from Zandberg et al. (2024), which includes recordings of zebra finch (Taeniopygia guttata) song syllables and results from behavioral experiments (probe and triplet tasks) measuring the birds' perception of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anonymous-submission000/vocsim-applications-avian-perception.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"vocsim-applications-avian-perception","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymous-submission000/vocsim-applications-avian-perception","creator_name":"Anonymous","creator_url":"https://huggingface.co/anonymous-submission000","description":"\n\t\n\t\t\n\t\tDataset Card for VocSim - Avian Perception Alignment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is used in the VocSim benchmark paper, specifically designed to evaluate how well neural audio embeddings align with biological perceptual judgments of similarity. It utilizes data from Zandberg et al. (2024), which includes recordings of zebra finch (Taeniopygia guttata) song syllables and results from behavioral experiments (probe and triplet tasks) measuring the birds' perception of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anonymous-submission000/vocsim-applications-avian-perception.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Vietnam-Celeb","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/Vietnam-Celeb","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of Vietnam-Celeb dataset\n\t\n\nofficial announcement:\n\nhttps://www.isca-archive.org/interspeech_2023/pham23b_interspeech.html\nhttps://github.com/Vietnam-Celeb/Vietnam-Celeb\nhttps://huggingface.co/datasets/hustep-lab/Vietnam-Celeb\n\nofficial download:\n\nPart 0: https://drive.google.com/file/d/1pMuT3DFzSwib7SVcRS8VkDwPuLTsemSG/view?usp=share_link     \nPart 1: https://drive.google.com/file/d/1xayHt2HRqE1aJ4HvtUT40_9XlgvfDfRY/view?usp=share_linkPart 2:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/Vietnam-Celeb.","first_N":5,"first_N_keywords":["Vietnamese","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"background_noise","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bear3/background_noise","creator_name":"Snorf Yang","creator_url":"https://huggingface.co/Bear3","description":"Bear3/background_noise dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philip120/voice","creator_name":"Philip Pa≈°kov","creator_url":"https://huggingface.co/philip120","description":"philip120/voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"VietMDD","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMDD","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMMD (Mispronunciation Detection and Diagnosis)\n\t\n\nofficial announcement: https://github.com/VietMDDDataset/VietMDD\nofficial download: https://drive.google.com/drive/folders/1TjTluTxEB99QhGFTYFWb-vEdWXM-lyKJ?usp=sharing\nDOI: 10.21437/Interspeech.2023-364\n5h, 4.2k samples\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/viet-mdd.py\n\ncustom split: orphan: speech without any transcription unlike in train/validation/test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMDD.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Hin_Male_Orpheus","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sk1382/Hin_Male_Orpheus","creator_name":"Srivathsava","creator_url":"https://huggingface.co/Sk1382","description":"Sk1382/Hin_Male_Orpheus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts_deu","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chrde/tts_deu","creator_name":"CD","creator_url":"https://huggingface.co/chrde","description":"chrde/tts_deu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC0","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons 0 (CC0) license, making them effectively public domain works. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC0","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons 0 (CC0) license, making them effectively public domain works. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-SA-4.0","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-SA-4.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-SA-4.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution-ShareAlike 4.0 International (CC-BY-SA-4.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-SA-4.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-SA-4.0","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-SA-4.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-SA-4.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution-ShareAlike 4.0 International (CC-BY-SA-4.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-SA-4.0.","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"AudioSpoofing","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HuShou-ZMZN/AudioSpoofing","creator_name":"shou","creator_url":"https://huggingface.co/HuShou-ZMZN","description":"\n\t\n\t\t\n\t\tAudioSpoof ËôöÂÅáÈü≥È¢ëÊ£ÄÊµãÊï∞ÊçÆÈõÜ\n\t\n\nÈöèÁùÄTTSÔºàText-to-SpeechÔºâÊäÄÊúØÁöÑÂø´ÈÄüÂèëÂ±ïÔºåÂΩìÂâçËØ≠Èü≥ÂÖãÈöÜÊ®°ÂûãÁîüÊàêÁöÑÂ£∞Èü≥Â∑≤Èöæ‰ª•ÈÄöËøáÁÆÄÂçïÂê¨ËßâÂà§Êñ≠Áúü‰º™„ÄÇÁÑ∂ËÄåÔºåÈíàÂØπ‰∏≠ÊñáÂú∫ÊôØÁöÑÈü≥È¢ë‰º™ÈÄ†Ê£ÄÊµãÈ¢ÜÂüü‰ªçÂ≠òÂú®ÊòæËëóÁ©∫ÁôΩÔºö1Ô∏è‚É£ Áº∫‰πèÂü∫‰∫éÊúÄÊñ∞ËØ≠Èü≥ÂêàÊàêÊäÄÊúØÁîüÊàêÁöÑ‰º™ÈÄ†Èü≥È¢ëÊï∞ÊçÆÈõÜÔºàAudio Spoofing DatasetÔºâ2Ô∏è‚É£ Áé∞ÊúâÊ£ÄÊµãÊñπÊ≥ïÂØπÈõ∂Ê†∑Êú¨ËØ≠Èü≥ÂÖãÈöÜÊîªÂáªÁöÑÈò≤Âæ°ËÉΩÂäõ‰∏çË∂≥  \n‰∏∫Ê≠§ÔºåÊàë‰ª¨Âü∫‰∫é MagicData ‰∏≠ÊñáÊôÆÈÄöËØùËØ≠ÊñôÂ∫ìÔºåÈÄöËøáÂõõÂ§ßÂâçÊ≤øÂºÄÊ∫êTTSÊ®°ÂûãËøõË°åÈõ∂Ê†∑Êú¨ËØ≠Èü≥ÂÖãÈöÜ: NaturalSpeech3, CosyVoice  , F5-TTS, Spark-TTS, ÊûÑÂª∫È¶ñ‰∏™‰∏ìÊ≥®‰∫é‰∏≠ÊñáÂú∫ÊôØÁöÑÂ§öÊ®°Âûã‰º™ÈÄ†Èü≥È¢ëÊ£ÄÊµãÂü∫ÂáÜÊï∞ÊçÆÈõÜ„ÄÇ  \n\n\t\n\t\t\n\t\n\t\n\t\tÊ®°Âûã‰∏ãËΩΩ\n\t\n\nÊï∞ÊçÆÈõÜÂ∑≤ÊâòÁÆ°Ëá≥ Hugging Face HubÔºö  AudioSpoofÁõ¥Êé•Âä†ËΩΩÊï∞ÊçÆÈõÜÔºö\nfrom datasets import load_dataset\ndataset = load_dataset(\"HuShou-ZMZN/audiofake\")\n\n\n\t\t\n\t\n\t\tÊï∞ÊçÆÊûÑÂª∫ÊñπÊ≥ï‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuShou-ZMZN/AudioSpoofing.","first_N":5,"first_N_keywords":["audio-classification","Chinese","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"AudioSpoofing","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HuShou-ZMZN/AudioSpoofing","creator_name":"shou","creator_url":"https://huggingface.co/HuShou-ZMZN","description":"\n\t\n\t\t\n\t\tAudioSpoof ËôöÂÅáÈü≥È¢ëÊ£ÄÊµãÊï∞ÊçÆÈõÜ\n\t\n\nÈöèÁùÄTTSÔºàText-to-SpeechÔºâÊäÄÊúØÁöÑÂø´ÈÄüÂèëÂ±ïÔºåÂΩìÂâçËØ≠Èü≥ÂÖãÈöÜÊ®°ÂûãÁîüÊàêÁöÑÂ£∞Èü≥Â∑≤Èöæ‰ª•ÈÄöËøáÁÆÄÂçïÂê¨ËßâÂà§Êñ≠Áúü‰º™„ÄÇÁÑ∂ËÄåÔºåÈíàÂØπ‰∏≠ÊñáÂú∫ÊôØÁöÑÈü≥È¢ë‰º™ÈÄ†Ê£ÄÊµãÈ¢ÜÂüü‰ªçÂ≠òÂú®ÊòæËëóÁ©∫ÁôΩÔºö1Ô∏è‚É£ Áº∫‰πèÂü∫‰∫éÊúÄÊñ∞ËØ≠Èü≥ÂêàÊàêÊäÄÊúØÁîüÊàêÁöÑ‰º™ÈÄ†Èü≥È¢ëÊï∞ÊçÆÈõÜÔºàAudio Spoofing DatasetÔºâ2Ô∏è‚É£ Áé∞ÊúâÊ£ÄÊµãÊñπÊ≥ïÂØπÈõ∂Ê†∑Êú¨ËØ≠Èü≥ÂÖãÈöÜÊîªÂáªÁöÑÈò≤Âæ°ËÉΩÂäõ‰∏çË∂≥  \n‰∏∫Ê≠§ÔºåÊàë‰ª¨Âü∫‰∫é MagicData ‰∏≠ÊñáÊôÆÈÄöËØùËØ≠ÊñôÂ∫ìÔºåÈÄöËøáÂõõÂ§ßÂâçÊ≤øÂºÄÊ∫êTTSÊ®°ÂûãËøõË°åÈõ∂Ê†∑Êú¨ËØ≠Èü≥ÂÖãÈöÜ: NaturalSpeech3, CosyVoice  , F5-TTS, Spark-TTS, ÊûÑÂª∫È¶ñ‰∏™‰∏ìÊ≥®‰∫é‰∏≠ÊñáÂú∫ÊôØÁöÑÂ§öÊ®°Âûã‰º™ÈÄ†Èü≥È¢ëÊ£ÄÊµãÂü∫ÂáÜÊï∞ÊçÆÈõÜ„ÄÇ  \n\n\t\n\t\t\n\t\n\t\n\t\tÊ®°Âûã‰∏ãËΩΩ\n\t\n\nÊï∞ÊçÆÈõÜÂ∑≤ÊâòÁÆ°Ëá≥ Hugging Face HubÔºö  AudioSpoofÁõ¥Êé•Âä†ËΩΩÊï∞ÊçÆÈõÜÔºö\nfrom datasets import load_dataset\ndataset = load_dataset(\"HuShou-ZMZN/audiofake\")\n\n\n\t\t\n\t\n\t\tÊï∞ÊçÆÊûÑÂª∫ÊñπÊ≥ï‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuShou-ZMZN/AudioSpoofing.","first_N":5,"first_N_keywords":["audio-classification","Chinese","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"AudioSpoofing","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HuShou-ZMZN/AudioSpoofing","creator_name":"shou","creator_url":"https://huggingface.co/HuShou-ZMZN","description":"\n\t\n\t\t\n\t\tAudioSpoof ËôöÂÅáÈü≥È¢ëÊ£ÄÊµãÊï∞ÊçÆÈõÜ\n\t\n\nÈöèÁùÄTTSÔºàText-to-SpeechÔºâÊäÄÊúØÁöÑÂø´ÈÄüÂèëÂ±ïÔºåÂΩìÂâçËØ≠Èü≥ÂÖãÈöÜÊ®°ÂûãÁîüÊàêÁöÑÂ£∞Èü≥Â∑≤Èöæ‰ª•ÈÄöËøáÁÆÄÂçïÂê¨ËßâÂà§Êñ≠Áúü‰º™„ÄÇÁÑ∂ËÄåÔºåÈíàÂØπ‰∏≠ÊñáÂú∫ÊôØÁöÑÈü≥È¢ë‰º™ÈÄ†Ê£ÄÊµãÈ¢ÜÂüü‰ªçÂ≠òÂú®ÊòæËëóÁ©∫ÁôΩÔºö1Ô∏è‚É£ Áº∫‰πèÂü∫‰∫éÊúÄÊñ∞ËØ≠Èü≥ÂêàÊàêÊäÄÊúØÁîüÊàêÁöÑ‰º™ÈÄ†Èü≥È¢ëÊï∞ÊçÆÈõÜÔºàAudio Spoofing DatasetÔºâ2Ô∏è‚É£ Áé∞ÊúâÊ£ÄÊµãÊñπÊ≥ïÂØπÈõ∂Ê†∑Êú¨ËØ≠Èü≥ÂÖãÈöÜÊîªÂáªÁöÑÈò≤Âæ°ËÉΩÂäõ‰∏çË∂≥  \n‰∏∫Ê≠§ÔºåÊàë‰ª¨Âü∫‰∫é MagicData ‰∏≠ÊñáÊôÆÈÄöËØùËØ≠ÊñôÂ∫ìÔºåÈÄöËøáÂõõÂ§ßÂâçÊ≤øÂºÄÊ∫êTTSÊ®°ÂûãËøõË°åÈõ∂Ê†∑Êú¨ËØ≠Èü≥ÂÖãÈöÜ: NaturalSpeech3, CosyVoice  , F5-TTS, Spark-TTS, ÊûÑÂª∫È¶ñ‰∏™‰∏ìÊ≥®‰∫é‰∏≠ÊñáÂú∫ÊôØÁöÑÂ§öÊ®°Âûã‰º™ÈÄ†Èü≥È¢ëÊ£ÄÊµãÂü∫ÂáÜÊï∞ÊçÆÈõÜ„ÄÇ  \n\n\t\n\t\t\n\t\n\t\n\t\tÊ®°Âûã‰∏ãËΩΩ\n\t\n\nÊï∞ÊçÆÈõÜÂ∑≤ÊâòÁÆ°Ëá≥ Hugging Face HubÔºö  AudioSpoofÁõ¥Êé•Âä†ËΩΩÊï∞ÊçÆÈõÜÔºö\nfrom datasets import load_dataset\ndataset = load_dataset(\"HuShou-ZMZN/audiofake\")\n\n\n\t\t\n\t\n\t\tÊï∞ÊçÆÊûÑÂª∫ÊñπÊ≥ï‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuShou-ZMZN/AudioSpoofing.","first_N":5,"first_N_keywords":["audio-classification","Chinese","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"FeruzaSpeech_to_fine_tuning","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickoo004/FeruzaSpeech_to_fine_tuning","creator_name":"Nicholas","creator_url":"https://huggingface.co/nickoo004","description":"\n\t\n\t\t\n\t\tFeruzaSpeech_to_fine_tuning\n\t\n\nA speech corpus of ‚è±Ô∏è¬†~59.1 total hours of Uzbek audio paired with Latin‚Äëscript transcripts, intended for fine‚Äëtuning ASR / speech‚Äëto‚Äëtext models.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains recordings of native Uzbek speakers reading a mix of classical literature excerpts and school‚Äëlevel writing prompts:\n\n001:‚ÄØCholiqushi (a novel by Rashod‚ÄØNuri‚ÄØGuntekin, trans. by Mirzakalon‚ÄØIsmoiliy; first pub. Sept‚ÄØ1900).  \n002:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nickoo004/FeruzaSpeech_to_fine_tuning.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-audio","Uzbek","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"FeruzaSpeech_to_fine_tuning","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickoo004/FeruzaSpeech_to_fine_tuning","creator_name":"Nicholas","creator_url":"https://huggingface.co/nickoo004","description":"\n\t\n\t\t\n\t\tFeruzaSpeech_to_fine_tuning\n\t\n\nA speech corpus of ‚è±Ô∏è¬†~59.1 total hours of Uzbek audio paired with Latin‚Äëscript transcripts, intended for fine‚Äëtuning ASR / speech‚Äëto‚Äëtext models.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains recordings of native Uzbek speakers reading a mix of classical literature excerpts and school‚Äëlevel writing prompts:\n\n001:‚ÄØCholiqushi (a novel by Rashod‚ÄØNuri‚ÄØGuntekin, trans. by Mirzakalon‚ÄØIsmoiliy; first pub. Sept‚ÄØ1900).  \n002:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nickoo004/FeruzaSpeech_to_fine_tuning.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-audio","Uzbek","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"B5","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DmitryRyumin/B5","creator_name":"Dmitry Ryumin","creator_url":"https://huggingface.co/DmitryRyumin","description":"DmitryRyumin/B5 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","Audio","Video","Datasets"],"keywords_longer_than_N":true},
	{"name":"EmoVoice-DB","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yhaha/EmoVoice-DB","creator_name":"yangguanrou","creator_url":"https://huggingface.co/yhaha","description":"\n\t\n\t\t\n\t\tDataset Card for EmoVoice-DB\n\t\n\n\n\t\n\t\t\n\t\tOverview of EmoVoice-DB\n\t\n\nEmoVoice-DB is an English emotional speech dataset featuring fine-grained emotion labels expressed through natural language descriptions. This dataset contains over 20,000 emotionally expressive speech samples, each annotated with detailed and precise emotional descriptions, totaling approximately 40 hours of audio. EmoVoice-DB is built using synthetic data generated by the powerful‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yhaha/EmoVoice-DB.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"transcription-scorer","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/transcription-scorer","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"\n\t\n\t\t\n\t\tTranscription Scorer Dataset\n\t\n\nThe Transcription Scorer dataset was created to support research in reference-free evaluation of Automatic Speech Recognition (ASR) systems using human feedback. Unlike traditional evaluation metrics such as WER and its derivatives, this dataset reflects subjective judgments of ASR outputs by human raters across multiple criteria, simulating the way a teacher grades students.\n\n\t\n\t\t\n\t\n\t\n\t\t‚öôÔ∏è What‚Äôs Inside\n\t\n\nThis dataset contains 2153 audio samples (from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RobotsMali/transcription-scorer.","first_N":5,"first_N_keywords":["automatic-speech-recognition","reinforcement-learning","audio-classification","expert-annotated","found"],"keywords_longer_than_N":true},
	{"name":"transcription-scorer","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/transcription-scorer","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"\n\t\n\t\t\n\t\tTranscription Scorer Dataset\n\t\n\nThe Transcription Scorer dataset was created to support research in reference-free evaluation of Automatic Speech Recognition (ASR) systems using human feedback. Unlike traditional evaluation metrics such as WER and its derivatives, this dataset reflects subjective judgments of ASR outputs by human raters across multiple criteria, simulating the way a teacher grades students.\n\n\t\n\t\t\n\t\n\t\n\t\t‚öôÔ∏è What‚Äôs Inside\n\t\n\nThis dataset contains 2153 audio samples (from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RobotsMali/transcription-scorer.","first_N":5,"first_N_keywords":["automatic-speech-recognition","reinforcement-learning","audio-classification","expert-annotated","found"],"keywords_longer_than_N":true},
	{"name":"transcription-scorer","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/transcription-scorer","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"\n\t\n\t\t\n\t\tTranscription Scorer Dataset\n\t\n\nThe Transcription Scorer dataset was created to support research in reference-free evaluation of Automatic Speech Recognition (ASR) systems using human feedback. Unlike traditional evaluation metrics such as WER and its derivatives, this dataset reflects subjective judgments of ASR outputs by human raters across multiple criteria, simulating the way a teacher grades students.\n\n\t\n\t\t\n\t\n\t\n\t\t‚öôÔ∏è What‚Äôs Inside\n\t\n\nThis dataset contains 2153 audio samples (from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RobotsMali/transcription-scorer.","first_N":5,"first_N_keywords":["automatic-speech-recognition","reinforcement-learning","audio-classification","expert-annotated","found"],"keywords_longer_than_N":true},
	{"name":"cmu_haitian_creole_speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jsbeaudry/cmu_haitian_creole_speech","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","description":"###########################################################################\n\n\t\n\t\t\n\t\t\n\t\n\n\n\t\n\t\t\n\t\tLanguage Technologies Institute\n\t\n\n\n\t\n\t\t\n\t\tCarnegie Mellon University\n\t\n\n\n\t\n\t\t\n\t\tCopyright (c) 2010\n\t\n\n\n\t\n\t\t\n\t\tAll Rights Reserved.\n\t\n\n\n\t\n\t\t\n\t\t\n\t\n\n\n\t\n\t\t\n\t\tPermission is hereby granted, free of charge, to use and distribute\n\t\n\n\n\t\n\t\t\n\t\tthis data and its documentation without restriction, including\n\t\n\n\n\t\n\t\t\n\t\twithout limitation the rights to use, copy, modify, merge, publish,\n\t\n\n\n\t\n\t\t\n\t\tdistribute‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/cmu_haitian_creole_speech.","first_N":5,"first_N_keywords":["Haitian","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"training_dataset","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishi70612/training_dataset","creator_name":"Rishikesh Kumar Sharma","creator_url":"https://huggingface.co/rishi70612","description":"\n\t\n\t\t\n\t\tDataset Card for OpenSLR Nepali Large ASR Cleaned\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis data set contains transcribed audio data for Nepali. The data set consists of flac files, and a TSV file. The file utt_spk_text.tsv contains a FileID, anonymized UserID and the transcription of audio in the file.\nThe data set has been manually quality-checked, but there might still be errors.\nThe audio files are sampled at a rate of 16KHz, and leading and trailing silences are trimmed using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rishi70612/training_dataset.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"RivaBench","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tsinghua-ee/RivaBench","creator_name":"Electronic Engineering @Tsinghua University","creator_url":"https://huggingface.co/tsinghua-ee","description":"This dataset repo contains three partitions of the Reasoning-Intensive Video with Audio understanding Benchmark (RivaBench).\nAcademic.json: The Academic partition. Video and audio resources can be found at https://github.com/Jack-ZC8/M3AV-dataset StandUp.json: The Standup partition. Videos and audios are provided.synthdec.json: The synthetic video detection partition. Videos and whether they are synthesized or not are provided.\n\n\t\n\t\t\n\t\n\t\n\t\tReference\n\t\n\n@inproceedings{\n  sun2025videosalmonno1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tsinghua-ee/RivaBench.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Video"],"keywords_longer_than_N":true},
	{"name":"clean_clarinet_audio","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bernoulli1667/clean_clarinet_audio","creator_name":"Jamie Vitacco","creator_url":"https://huggingface.co/Bernoulli1667","description":"Bernoulli1667/clean_clarinet_audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"fucker","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bernoulli1667/fucker","creator_name":"Jamie Vitacco","creator_url":"https://huggingface.co/Bernoulli1667","description":"Bernoulli1667/fucker dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"MuChin1k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/karl-wang/MuChin1k","creator_name":"carlwang","creator_url":"https://huggingface.co/karl-wang","description":"https://github.com/CarlWangChina/MuChin\n","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"audiofake_detect_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WpythonW/audiofake_detect_dataset","creator_name":"Andrew","creator_url":"https://huggingface.co/WpythonW","description":"WpythonW/audiofake_detect_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_20k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_20k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (20k)\n\t\n\nThis dataset contains 40000 synthetic speech recordings in the Pashto language,\nwith 20000 male voice recordings and 20000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 20000 sentences\nTotal Recordings: 40000 audio files (20000 male + 20000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_20k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_20k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_20k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (20k)\n\t\n\nThis dataset contains 40000 synthetic speech recordings in the Pashto language,\nwith 20000 male voice recordings and 20000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 20000 sentences\nTotal Recordings: 40000 audio files (20000 male + 20000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_20k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ahead_ds","keyword":"audio-classification","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hzhongresearch/ahead_ds","creator_name":"Henry Zhong","creator_url":"https://huggingface.co/hzhongresearch","description":"\n\t\n\t\t\n\t\tAnother HEaring AiD DataSet (AHEAD-DS)\n\t\n\nAnother HEaring AiD DataSet (AHEAD-DS) is an audio dataset labelled with audiologically relevant scene categories for hearing aids.\n\n\t\n\t\t\n\t\tDescription of data\n\t\n\nAll files are encoded as single channel WAV, 16 bit signed, sampled at 16 kHz with 10 seconds per recording.\n\n\t\n\t\t\nCategory\nTraining\nValidation\nTesting\nAll\n\n\n\t\t\ncocktail_party\n934\n134\n266\n1334\n\n\ninterfering_speakers\n733\n105\n209\n1047\n\n\nin_traffic\n370\n53\n105\n528\n\n\nin_vehicle\n409\n59\n116‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hzhongresearch/ahead_ds.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-sa-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"ahead_ds","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hzhongresearch/ahead_ds","creator_name":"Henry Zhong","creator_url":"https://huggingface.co/hzhongresearch","description":"\n\t\n\t\t\n\t\tAnother HEaring AiD DataSet (AHEAD-DS)\n\t\n\nAnother HEaring AiD DataSet (AHEAD-DS) is an audio dataset labelled with audiologically relevant scene categories for hearing aids.\n\n\t\n\t\t\n\t\tDescription of data\n\t\n\nAll files are encoded as single channel WAV, 16 bit signed, sampled at 16 kHz with 10 seconds per recording.\n\n\t\n\t\t\nCategory\nTraining\nValidation\nTesting\nAll\n\n\n\t\t\ncocktail_party\n934\n134\n266\n1334\n\n\ninterfering_speakers\n733\n105\n209\n1047\n\n\nin_traffic\n370\n53\n105\n528\n\n\nin_vehicle\n409\n59\n116‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hzhongresearch/ahead_ds.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-sa-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"ahead_ds","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hzhongresearch/ahead_ds","creator_name":"Henry Zhong","creator_url":"https://huggingface.co/hzhongresearch","description":"\n\t\n\t\t\n\t\tAnother HEaring AiD DataSet (AHEAD-DS)\n\t\n\nAnother HEaring AiD DataSet (AHEAD-DS) is an audio dataset labelled with audiologically relevant scene categories for hearing aids.\n\n\t\n\t\t\n\t\tDescription of data\n\t\n\nAll files are encoded as single channel WAV, 16 bit signed, sampled at 16 kHz with 10 seconds per recording.\n\n\t\n\t\t\nCategory\nTraining\nValidation\nTesting\nAll\n\n\n\t\t\ncocktail_party\n934\n134\n266\n1334\n\n\ninterfering_speakers\n733\n105\n209\n1047\n\n\nin_traffic\n370\n53\n105\n528\n\n\nin_vehicle\n409\n59\n116‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hzhongresearch/ahead_ds.","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-sa-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"CSALT_FLEURS","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mscs23021/CSALT_FLEURS","creator_name":"mustafiz ur Rehman","creator_url":"https://huggingface.co/mscs23021","description":"mscs23021/CSALT_FLEURS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"AnaDeArmas-Data","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hardlyworking/AnaDeArmas-Data","creator_name":"workinghardly","creator_url":"https://huggingface.co/hardlyworking","description":"Fair use collection of Ana De Armas one-sided interviews. All background noise has been removed and silences have been truncated.\n","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"TurkicTTS-Chuvash","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tTurkic_TTS-Chuvash\n\t\n\n[Original repository] \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkic_TTS-Chuvash is a speech dataset sourced from the Turkic_TTS GitHub repository. The dataset comprises recordings of text extracted from news articles on chuvash.org and list of digits, all read by a single female speaker at a rapid tempo. The dataset is intended for text-to-speech (TTS) research and development in the Chuvash language. The license and citation information presented in this dataset card has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Chuvash","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TurkicTTS-Chuvash","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tTurkic_TTS-Chuvash\n\t\n\n[Original repository] \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkic_TTS-Chuvash is a speech dataset sourced from the Turkic_TTS GitHub repository. The dataset comprises recordings of text extracted from news articles on chuvash.org and list of digits, all read by a single female speaker at a rapid tempo. The dataset is intended for text-to-speech (TTS) research and development in the Chuvash language. The license and citation information presented in this dataset card has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Chuvash","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"My_Dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sergeantzero/My_Dataset","creator_name":"zero","creator_url":"https://huggingface.co/Sergeantzero","description":"Sergeantzero/My_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Kimi-Audio-GenTest","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/moonshotai/Kimi-Audio-GenTest","creator_name":"Moonshot AI","creator_url":"https://huggingface.co/moonshotai","description":"\n\t\n\t\t\n\t\tKimi-Audio-Generation-Testset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSummary: This dataset is designed to benchmark and evaluate the conversational capabilities of audio-based dialogue models. It consists of a collection of audio files containing various instructions and conversational prompts. The primary goal is to assess a model's ability to generate not just relevant, but also appropriately styled audio responses.\nSpecifically, the dataset targets the model's proficiency in:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/moonshotai/Kimi-Audio-GenTest.","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"89823872","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zh-liu799/89823872","creator_name":"Zihang Liu","creator_url":"https://huggingface.co/zh-liu799","description":"zh-liu799/89823872 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"plug_socket_single","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_single","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 65,\n    \"total_frames\": 24999,\n    \"total_tasks\": 1,\n    \"total_videos\": 195,\n    \"total_audio\": 195,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:65\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_single.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"plug_socket_single","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_single","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 65,\n    \"total_frames\": 24999,\n    \"total_tasks\": 1,\n    \"total_videos\": 195,\n    \"total_audio\": 195,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:65\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_single.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"MFA_tutorial_2025-04-28_PAPPS","keyword":"audio","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenmule/MFA_tutorial_2025-04-28_PAPPS","creator_name":"Miao Zhang","creator_url":"https://huggingface.co/zenmule","description":"This repo contains the material for this Montreal Forced Aligner Tutorial.\nThe recordings are from ALLSTAR and Mozilla Common Voice.\n","first_N":5,"first_N_keywords":["mpl-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amazeble/test","creator_name":"na","creator_url":"https://huggingface.co/amazeble","description":"amazeble/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"odia-english-ASR","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mohan-diffuser/odia-english-ASR","creator_name":"Mohan Dash","creator_url":"https://huggingface.co/Mohan-diffuser","description":"Mohan-diffuser/odia-english-ASR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Oriya","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"carlos-it-tts","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/carlos-it-tts","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/carlos-it-tts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"whisper-internal-test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulus/whisper-internal-test","creator_name":"Minseok Lee","creator_url":"https://huggingface.co/neulus","description":"Original datasets can be found in shb777/gemini-flash-2.0-speech.\nFor personal testing purposes.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"childs_melody_movement_one","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nickolasnikolic/childs_melody_movement_one","creator_name":"Nickolas Aleksandar Nikolic","creator_url":"https://huggingface.co/nickolasnikolic","description":"If you would like to do work on original music left freely for the community, here is a piece that has all metadata, including sheet music in pdf, midi, and mp3. There also is musicXML for those that might need it.\n","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ruslan_sova_ai","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/intexcp/ruslan_sova_ai","creator_name":"Ivan Shivalov","creator_url":"https://huggingface.co/intexcp","description":"This is a saved ruslan dataset from SOVA AI\n","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"Audio-FLAN-Dataset","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\n\t\n\t\t\n\t\tAudio-FLAN Dataset (Paper)\n\t\n\n(the FULL audio files and jsonl files are still updating)\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \n\n\t\n\t\t\n\t\t1. Dataset Structure\n\t\n\nThe Audio-FLAN-Dataset has the following directory structure:\nAudio-FLAN-Dataset/\n‚îú‚îÄ‚îÄ audio_files/\n‚îÇ   ‚îú‚îÄ‚îÄ audio/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 177_TAU_Urban_Acoustic_Scenes_2022/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 179_Audioset_for_Audio_Inpainting/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îÇ   ‚îú‚îÄ‚îÄ music/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Audio-FLAN-Dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\n\t\n\t\t\n\t\tAudio-FLAN Dataset (Paper)\n\t\n\n(the FULL audio files and jsonl files are still updating)\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \n\n\t\n\t\t\n\t\t1. Dataset Structure\n\t\n\nThe Audio-FLAN-Dataset has the following directory structure:\nAudio-FLAN-Dataset/\n‚îú‚îÄ‚îÄ audio_files/\n‚îÇ   ‚îú‚îÄ‚îÄ audio/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 177_TAU_Urban_Acoustic_Scenes_2022/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 179_Audioset_for_Audio_Inpainting/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îÇ   ‚îú‚îÄ‚îÄ music/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Audio-FLAN-Dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\n\t\n\t\t\n\t\tAudio-FLAN Dataset (Paper)\n\t\n\n(the FULL audio files and jsonl files are still updating)\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \n\n\t\n\t\t\n\t\t1. Dataset Structure\n\t\n\nThe Audio-FLAN-Dataset has the following directory structure:\nAudio-FLAN-Dataset/\n‚îú‚îÄ‚îÄ audio_files/\n‚îÇ   ‚îú‚îÄ‚îÄ audio/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 177_TAU_Urban_Acoustic_Scenes_2022/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 179_Audioset_for_Audio_Inpainting/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îÇ   ‚îú‚îÄ‚îÄ music/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"audioTest","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Luka-He/audioTest","creator_name":"HeXinyu","creator_url":"https://huggingface.co/Luka-He","description":"Luka-He/audioTest dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"audiosnippets-tiny","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cahya/audiosnippets-tiny","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","description":"\n\t\n\t\t\n\t\tTiny audio snippets\n\t\n\n","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"AdvSpeech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Renyi444/AdvSpeech","creator_name":"Renyi Yang","creator_url":"https://huggingface.co/Renyi444","description":"Renyi444/AdvSpeech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"NTUT-GenAI-2025-HW","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/t113598022/NTUT-GenAI-2025-HW","creator_name":"Ken","creator_url":"https://huggingface.co/t113598022","description":"\n\t\n\t\t\n\t\tMP3 Speech Recognition Dataset\n\t\n\nThis dataset contains MP3 files of spoken English phrases, along with their corresponding text transcriptions. It is designed for training and evaluating speech recognition models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset includes:\n\n5,000 MP3 audio files of English speech.\nEach file contains a 3-5 second spoken phrase recorded by various speakers.\nThe audio files are accompanied by text transcriptions.\nThe dataset is divided into training, validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/t113598022/NTUT-GenAI-2025-HW.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"NTUT-GenAI-2025-HW","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/t113598022/NTUT-GenAI-2025-HW","creator_name":"Ken","creator_url":"https://huggingface.co/t113598022","description":"\n\t\n\t\t\n\t\tMP3 Speech Recognition Dataset\n\t\n\nThis dataset contains MP3 files of spoken English phrases, along with their corresponding text transcriptions. It is designed for training and evaluating speech recognition models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset includes:\n\n5,000 MP3 audio files of English speech.\nEach file contains a 3-5 second spoken phrase recorded by various speakers.\nThe audio files are accompanied by text transcriptions.\nThe dataset is divided into training, validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/t113598022/NTUT-GenAI-2025-HW.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"cv10-uk-testset-clean","keyword":"audio","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/cv10-uk-testset-clean","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\n\t\n\t\t\n\t\tThe cleaned Common Voice 10 (test set) that has been checked by a human for Ukrainian üá∫üá¶\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains the archive of Common Voice 10 (test set) with checked Ukrainian transcriptions and audios.\nAll audios have been checked by a human to be sure that they are correct. \nThis archive is used to test all ASR models listed here: https://github.com/egorsmkv/speech-recognition-uk\n\n\t\n\t\t\n\t\n\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/cv10-uk-testset-clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Ukrainian","mpl-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"cv10-uk-testset-clean","keyword":"audio","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/cv10-uk-testset-clean","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\n\t\n\t\t\n\t\tThe cleaned Common Voice 10 (test set) that has been checked by a human for Ukrainian üá∫üá¶\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains the archive of Common Voice 10 (test set) with checked Ukrainian transcriptions and audios.\nAll audios have been checked by a human to be sure that they are correct. \nThis archive is used to test all ASR models listed here: https://github.com/egorsmkv/speech-recognition-uk\n\n\t\n\t\t\n\t\n\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/cv10-uk-testset-clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Ukrainian","mpl-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"URO-Bench","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Honggao/URO-Bench","creator_name":"Ricky","creator_url":"https://huggingface.co/Honggao","description":"\n\t\n\t\t\n\t\tURO-Bench\n\t\n\nThis is an anonymous repo that includes data of URO-Bench: Towards Comprehensive Evaluation for End-to-End Spoken Dialogue Models.URO-Bench-data.zip contains test sets in jsonl format.URO-Bench-mini.zip is a carefully-curated miniset of URO-Bench, including 25 high-quality samples per test set, 1000 samples in total.\n\n\t\n\t\t\n\t\tAcknowledgment\n\t\n\nLCSTS-zh was adapted from LCSTSGaokaoEval was adapted from GaokaoHSK5-zh was curated from past exam papersUnderEmotion-en used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Honggao/URO-Bench.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"wiki-en-in-neerja-speech","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"This dataset contains 10K audio samples generated using Microsoft Edge Text-to-Speech via EdgeTTS. \n\nTotal samples: 10K\nAudio format: MP3\nSample rate: 24kHz\nTotal duration: 95735.86 seconds (26.59 hours)\nAverage duration: 9.57 seconds\nLanguages included: English\nVoices used: en-IN-NeerjaExpressiveNeural\n\nOverall this is low quality and should only be used for training toy tts models.\nIn my case this was for finetuning a low quality Piper TTS model.\nInput sentences were randomly sampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wiki-en-in-neerja-speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"This dataset contains 10K audio samples generated using Microsoft Edge Text-to-Speech via EdgeTTS. \n\nTotal samples: 10K\nAudio format: MP3\nSample rate: 24kHz\nTotal duration: 95735.86 seconds (26.59 hours)\nAverage duration: 9.57 seconds\nLanguages included: English\nVoices used: en-IN-NeerjaExpressiveNeural\n\nOverall this is low quality and should only be used for training toy tts models.\nIn my case this was for finetuning a low quality Piper TTS model.\nInput sentences were randomly sampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wiki-en-in-neerja-speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"This dataset contains 10K audio samples generated using Microsoft Edge Text-to-Speech via EdgeTTS. \n\nTotal samples: 10K\nAudio format: MP3\nSample rate: 24kHz\nTotal duration: 95735.86 seconds (26.59 hours)\nAverage duration: 9.57 seconds\nLanguages included: English\nVoices used: en-IN-NeerjaExpressiveNeural\n\nOverall this is low quality and should only be used for training toy tts models.\nIn my case this was for finetuning a low quality Piper TTS model.\nInput sentences were randomly sampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"minecraft-note-block","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/v2ray/minecraft-note-block","creator_name":"LagPixelLOL","creator_url":"https://huggingface.co/v2ray","description":"\n\t\n\t\t\n\t\tMinecraft Note Block\n\t\n\nLiterally just note block samples.\n","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"SpeechBrown","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-lab/SpeechBrown","creator_name":"LLM-Lab-Org  @QCRI-ALT","creator_url":"https://huggingface.co/llm-lab","description":"  \nModels | Springer Link | arXiv Link | Proposed Dataset  | ACM Digital Library | Website\n\n\t\t\n\t\tDataset Summary\n\t\n\nSpeech Brown is a comprehensive, synthetic, and diverse paired speech-text dataset in 15 categories, covering a wide range of topics from fiction to religion. This dataset consists of over 55,000 sentence-level samples.  \nTo train the CLASP model, we created this dataset based on the Brown Corpus. The synthetic speech was generated using the NVIDIA Tacotron 2 text-to-speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llm-lab/SpeechBrown.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"audiosnippets_small_with_detailed_annotation2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mitermix/audiosnippets_small_with_detailed_annotation2","creator_name":"Miter Mix","creator_url":"https://huggingface.co/mitermix","description":"mitermix/audiosnippets_small_with_detailed_annotation2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dhivehi-shaafiu-speech-train","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chumputy/dhivehi-shaafiu-speech-train","creator_name":"Ubaidulla Ali","creator_url":"https://huggingface.co/chumputy","description":"chumputy/dhivehi-shaafiu-speech-train dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Puck-Voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Puck-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Puck-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Aoede-Voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Aoede-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Aoede-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"LJSpeech-1.1-48kHz","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alibabasglab/LJSpeech-1.1-48kHz","creator_name":"Alibaba_Speech_Lab_SG","creator_url":"https://huggingface.co/alibabasglab","description":"\n\t\n\t\t\n\t\tLJSpeech-1.1 High-Resolution Dataset (48,000 Hz)\n\t\n\nThis dataset was created using the method described in HiFi-SR: A Unified Generative Transformer-Convolutional Adversarial Network for High-Fidelity Speech Super-Resolution and is part of ClearerVoice-Studio: Bridging Advanced Speech Processing Research and Practical Deployment (Github).\nThe LJSpeech-1.1 dataset, widely recognized for its utility in text-to-speech (TTS) and other speech processing tasks, has now been enhanced through‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alibabasglab/LJSpeech-1.1-48kHz.","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"LJSpeech-1.1-48kHz","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alibabasglab/LJSpeech-1.1-48kHz","creator_name":"Alibaba_Speech_Lab_SG","creator_url":"https://huggingface.co/alibabasglab","description":"\n\t\n\t\t\n\t\tLJSpeech-1.1 High-Resolution Dataset (48,000 Hz)\n\t\n\nThis dataset was created using the method described in HiFi-SR: A Unified Generative Transformer-Convolutional Adversarial Network for High-Fidelity Speech Super-Resolution and is part of ClearerVoice-Studio: Bridging Advanced Speech Processing Research and Practical Deployment (Github).\nThe LJSpeech-1.1 dataset, widely recognized for its utility in text-to-speech (TTS) and other speech processing tasks, has now been enhanced through‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alibabasglab/LJSpeech-1.1-48kHz.","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"sayha","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sadece/sayha","creator_name":"de","creator_url":"https://huggingface.co/sadece","description":"\n\t\n\t\t\n\t\tSayha\n\t\n\n\n\t\n\t\t\n\t\tYouTube Video Audio and Subtitles Extraction\n\t\n\nSayha is a tool designed to download YouTube videos and extract their audio and subtitle data. This can be particularly useful for creating datasets for machine learning projects, transcription services, or language studies.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nDownload YouTube videos.\nExtract audio tracks from videos.\nRetrieve and process subtitle files.\nPrepare datasets for various applications.\n\n\n\t\n\t\t\n\t\tInstallation\n\t\n\n\n\t\n\t\t\n\t\tClone‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sadece/sayha.","first_N":5,"first_N_keywords":["Turkish","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"f5_tts_ru_accent","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TVI/f5_tts_ru_accent","creator_name":"Zhulin","creator_url":"https://huggingface.co/TVI","description":"\n\t\n\t\t\n\t\tOriginal datasets:\n\t\n\n\nhttps://huggingface.co/datasets/mozilla-foundation/common_voice_17_0\nhttps://huggingface.co/datasets/bond005/sberdevices_golos_10h_crowd\nhttps://huggingface.co/datasets/bond005/sberdevices_golos_100h_farfield\nhttps://huggingface.co/datasets/bond005/sova_rudevices\nhttps://huggingface.co/datasets/Aniemore/resd_annotated\n\n","first_N":5,"first_N_keywords":["Russian","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"multispeaker-storycloze","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/multispeaker-storycloze","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\n\t\n\t\t\n\t\tMulti Speaker StoryCloze\n\t\n\nA multispeaker spoken version of StoryCloze Synthesized with Kokoro TTS.\nThe dataset was synthesized to evaluate the performance of speech language models as detailed in the paper \"Scaling Analysis of Interleaved Speech-Text Language Models\".\nWe refer you to the SlamKit codebase to see how you can evaluate your SpeechLM with this dataset.\n\n\t\n\t\t\n\t\n\t\n\t\tsSC and tSC\n\t\n\nWe split the generation for spoken-stroycloze and topic-storycloze as detailed in Twist.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slprl/multispeaker-storycloze.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"SolomonVoice1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanLegendXV/SolomonVoice1","creator_name":"Dallas Urban","creator_url":"https://huggingface.co/UrbanLegendXV","description":"UrbanLegendXV/SolomonVoice1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"VietNamVoice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TriAB/VietNamVoice","creator_name":"Ung","creator_url":"https://huggingface.co/TriAB","description":"TriAB/VietNamVoice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Indian_Englsih_SSML_dataset_for_orpheus_fine_tuning","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sk1382/Indian_Englsih_SSML_dataset_for_orpheus_fine_tuning","creator_name":"Srivathsava","creator_url":"https://huggingface.co/Sk1382","description":"Sk1382/Indian_Englsih_SSML_dataset_for_orpheus_fine_tuning dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dcase2025","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Anon4445/dcase2025","creator_name":"Tahrim Rahman Anon","creator_url":"https://huggingface.co/Anon4445","description":"Anon4445/dcase2025 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"audio_recordings","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/da2ce7/audio_recordings","creator_name":"Cam","creator_url":"https://huggingface.co/da2ce7","description":"\n\t\n\t\t\n\t\tAudio Recordings\n\t\n\nThese are some personal and open source audio recordings. Feel free to use.\n","first_N":5,"first_N_keywords":["audio-to-audio","audio-text-to-text","any-to-any","text-to-speech","English"],"keywords_longer_than_N":true},
	{"name":"audio_recordings","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/da2ce7/audio_recordings","creator_name":"Cam","creator_url":"https://huggingface.co/da2ce7","description":"\n\t\n\t\t\n\t\tAudio Recordings\n\t\n\nThese are some personal and open source audio recordings. Feel free to use.\n","first_N":5,"first_N_keywords":["audio-to-audio","audio-text-to-text","any-to-any","text-to-speech","English"],"keywords_longer_than_N":true},
	{"name":"audio_dataset_2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickfuryavg/audio_dataset_2","creator_name":"Sandipan Ray","creator_url":"https://huggingface.co/nickfuryavg","description":"nickfuryavg/audio_dataset_2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"common_voice_20_armenian","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chillarmo/common_voice_20_armenian","creator_name":"Movses Movsesyan","creator_url":"https://huggingface.co/Chillarmo","description":"\n\t\n\t\t\n\t\tCommon Voice 20 - Armenian\n\t\n\nThis dataset is the Armenian portion of Mozilla's Common Voice 20.0 release, \na massively multilingual collection of transcribed speech intended for speech technology research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Armenian (hy)\nSource: Mozilla Common Voice\nVersion: 20.0\nLicense: CC0-1.0\n\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Armenian","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"sinhala-bank-speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech","creator_name":"Ishan Sugathadasa","creator_url":"https://huggingface.co/IshanSuga","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThis dataset contains 100 audio files, one male voice in the format .wav. \nThe domain of this dataset is Banking.Only Language is Sinhalese(Sinhala,si)\nTotal Duration: 700.283 seconds.\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Sinhala","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"eng-kaz-rus-fleurs","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/adilakimshe/eng-kaz-rus-fleurs","creator_name":"Adilet Akimshe","creator_url":"https://huggingface.co/adilakimshe","description":"adilakimshe/eng-kaz-rus-fleurs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ThoughtsOrganize_Samples","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nguyenbh/ThoughtsOrganize_Samples","creator_name":"Nguyen Bach","creator_url":"https://huggingface.co/nguyenbh","description":"nguyenbh/ThoughtsOrganize_Samples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Finaldatasetig","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Finalprojectfour/Finaldatasetig","creator_name":"bleeehh ","creator_url":"https://huggingface.co/Finalprojectfour","description":"Finalprojectfour/Finaldatasetig dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"YCSEP_v1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stcoats/YCSEP_v1","creator_name":"Steven Coats","creator_url":"https://huggingface.co/stcoats","description":"\n\t\n\t\t\n\t\tThe YouTube Corpus of Singapore English Podcasts (YCSEP)\n\t\n\nThe YouTube Corpus of Singapore English Podcasts (YCSEP) contains ASR transcripts and audio from 620 hours of over 1,300 podcast episodes by Singapore-based content creators, comprising 756k individual turns and 8.38 million word tokens. \n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nYCSEP was created using a pipeline comprising yt-dlp, WhisperX, and pyannote.audio, and is intended to advance the study of the linguistic and discourse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stcoats/YCSEP_v1.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"thirukural-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Selvakumarduraipandian/thirukural-audio","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","description":"\n\t\n\t\t\n\t\tThirukural Voice-Based Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìñ About the Dataset\n\t\n\nThis dataset contains voice recordings of all 1330 thirukural couplets, generated using the gTTS (Google Text-to-Speech) Python package. It aims to make thirukural more accessible for AI/ML applications, educational tools, and Tamil language preservation efforts.\n\n\t\n\t\t\n\t\tüèõ Dataset Contents\n\t\n\nEach record in this dataset includes:\n\nID ‚Äì The unique number of the Kural (1 to 1330)\nKural ‚Äì The original Tamil couplet\nAudio ‚Äì‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Selvakumarduraipandian/thirukural-audio.","first_N":5,"first_N_keywords":["Tamil","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"thirukural-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Selvakumarduraipandian/thirukural-audio","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","description":"\n\t\n\t\t\n\t\tThirukural Voice-Based Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìñ About the Dataset\n\t\n\nThis dataset contains voice recordings of all 1330 thirukural couplets, generated using the gTTS (Google Text-to-Speech) Python package. It aims to make thirukural more accessible for AI/ML applications, educational tools, and Tamil language preservation efforts.\n\n\t\n\t\t\n\t\tüèõ Dataset Contents\n\t\n\nEach record in this dataset includes:\n\nID ‚Äì The unique number of the Kural (1 to 1330)\nKural ‚Äì The original Tamil couplet\nAudio ‚Äì‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Selvakumarduraipandian/thirukural-audio.","first_N":5,"first_N_keywords":["Tamil","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"mal_speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aparna29/mal_speech","creator_name":"Aparna Padmakumar","creator_url":"https://huggingface.co/aparna29","description":"aparna29/mal_speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"voice-activity-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"hindi_voice_transcriptions","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aliMohammad16/hindi_voice_transcriptions","creator_name":"Mohammad Ali","creator_url":"https://huggingface.co/aliMohammad16","description":"aliMohammad16/hindi_voice_transcriptions dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","translation","Hindi","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"kinyarwanda","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/codewithRiz/kinyarwanda","creator_name":"Rizwan Muzmmal","creator_url":"https://huggingface.co/codewithRiz","description":"codewithRiz/kinyarwanda dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"shona1","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/realtime-speech/shona1","creator_name":"chinhoyi final","creator_url":"https://huggingface.co/realtime-speech","description":"realtime-speech/shona1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Ambi_only_test","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Finalprojectfour/Ambi_only_test","creator_name":"bleeehh ","creator_url":"https://huggingface.co/Finalprojectfour","description":"Finalprojectfour/Ambi_only_test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["afl-3.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"IndicTTS-Deepfake-Challenge-Data","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SherryT997/IndicTTS-Deepfake-Challenge-Data","creator_name":"Sherry Thomas","creator_url":"https://huggingface.co/SherryT997","description":"\n\t\n\t\t\n\t\tIndicTTS Deepfake Detection Challenge\n\t\n\nParticipants will use the SherryT997/IndicTTS-Deepfake-Challenge-Data dataset, hosted on Hugging Face. This dataset consists of train and test splits and contains speech samples in 16 Indian languages, along with metadata for each audio clip.  \n\n\t\n\t\t\n\t\n\t\n\t\tüöÄ Dataset to Use: SherryT997/IndicTTS-Deepfake-Challenge-Data\n\t\n\nThis is the official dataset for the challenge and must be used for training and evaluation.  \n\n\n\t\n\t\n\t\n\t\tüìå Dataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SherryT997/IndicTTS-Deepfake-Challenge-Data.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"AS-SRL","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Santu00/AS-SRL","creator_name":"HUIYAO CHEN","creator_url":"https://huggingface.co/Santu00","description":"\n\t\n\t\t\n\t\tAS-SRL: A Chinese Speech-based Semantic Role Labeling Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nAS-SRL is the first Chinese speech-based Semantic Role Labeling (SRL) dataset, created by annotating the open-source Mandarin speech corpus AISHELL-1 with semantic role labels following the guidelines of Chinese Proposition Bank 1.0 (CPB1.0). The dataset contains 9,000 speech-text pairs with corresponding SRL annotations, split into training (7,500), development (500), and test (1,000) sets.\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Santu00/AS-SRL.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"HumSpeechBlend","keyword":"voice-activity-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend","creator_name":"Sourabh Saini","creator_url":"https://huggingface.co/CuriousMonkey7","description":"\n\t\n\t\t\n\t\tWORK IN PROGRESS\n\t\n\n\n\t\n\t\t\n\t\t[WIP]HumSpeechBlend Dataset: Humming vs Speech Detection\n\t\n\n\n\t\n\t\t\n\t\tüìå Overview\n\t\n\nHumSpeechBlend is a dataset designed to fine-tune Voice Activity Detection (VAD) models to distinguish between humming and actual speech. Current VAD models often misclassify humming as speech, leading to incorrect segmentation in speech processing tasks. This dataset provides a structured collection of humming audio interspersed with speech to help improve model accuracy.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend.","first_N":5,"first_N_keywords":["voice-activity-detection","English","cc-by-sa-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"HumSpeechBlend","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend","creator_name":"Sourabh Saini","creator_url":"https://huggingface.co/CuriousMonkey7","description":"\n\t\n\t\t\n\t\tWORK IN PROGRESS\n\t\n\n\n\t\n\t\t\n\t\t[WIP]HumSpeechBlend Dataset: Humming vs Speech Detection\n\t\n\n\n\t\n\t\t\n\t\tüìå Overview\n\t\n\nHumSpeechBlend is a dataset designed to fine-tune Voice Activity Detection (VAD) models to distinguish between humming and actual speech. Current VAD models often misclassify humming as speech, leading to incorrect segmentation in speech processing tasks. This dataset provides a structured collection of humming audio interspersed with speech to help improve model accuracy.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend.","first_N":5,"first_N_keywords":["voice-activity-detection","English","cc-by-sa-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"HumSpeechBlend","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend","creator_name":"Sourabh Saini","creator_url":"https://huggingface.co/CuriousMonkey7","description":"\n\t\n\t\t\n\t\tWORK IN PROGRESS\n\t\n\n\n\t\n\t\t\n\t\t[WIP]HumSpeechBlend Dataset: Humming vs Speech Detection\n\t\n\n\n\t\n\t\t\n\t\tüìå Overview\n\t\n\nHumSpeechBlend is a dataset designed to fine-tune Voice Activity Detection (VAD) models to distinguish between humming and actual speech. Current VAD models often misclassify humming as speech, leading to incorrect segmentation in speech processing tasks. This dataset provides a structured collection of humming audio interspersed with speech to help improve model accuracy.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend.","first_N":5,"first_N_keywords":["voice-activity-detection","English","cc-by-sa-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Max_Black","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Groupproject/Max_Black","creator_name":"school","creator_url":"https://huggingface.co/Groupproject","description":"Group Members: Chan Tsz Ching, Lam Tin Lok, Tang Wing Man,Iris \n","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"chunking-test-data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/chunking-ai/chunking-test-data","creator_name":"Chunking AI","creator_url":"https://huggingface.co/chunking-ai","description":"chunking-ai/chunking-test-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","Audio","Text","Video"],"keywords_longer_than_N":true},
	{"name":"baoshidaoren_music_snippets","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zuona/baoshidaoren_music_snippets","creator_name":"chenzuona","creator_url":"https://huggingface.co/zuona","description":"zuona/baoshidaoren_music_snippets dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"souq-elhikayat","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/01Yassine/souq-elhikayat","creator_name":"Yassine El Kheir","creator_url":"https://huggingface.co/01Yassine","description":"01Yassine/souq-elhikayat dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"InstUnd-Omni-Eval-v1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JavisGPT-dev/InstUnd-Omni-Eval-v1","creator_name":"JavisGPT-dev","creator_url":"https://huggingface.co/JavisGPT-dev","description":"JavisGPT-dev/InstUnd-Omni-Eval-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","Audio","Video","Datasets"],"keywords_longer_than_N":true},
	{"name":"QualiSpeech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tsinghua-ee/QualiSpeech","creator_name":"Electronic Engineering @Tsinghua University","creator_url":"https://huggingface.co/tsinghua-ee","description":"\n\t\n\t\t\n\t\tQualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions\n\t\n\n\n    \n\n\n\nüìÑ Paper: https://arxiv.org/abs/2503.20290\n\nQualiSpeech is a comprehensive English-language speech quality assessment dataset designed to go beyond traditional numerical scores. It introduces detailed natural language comments with reasoning, capturing low-level speech perception aspects such as noise, distortion, continuity, speed, naturalness, listening effort, and overall‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tsinghua-ee/QualiSpeech.","first_N":5,"first_N_keywords":["audio-text-to-text","mit","10K - 100K","csv","Audio"],"keywords_longer_than_N":true},
	{"name":"S2TT","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhifeixie/S2TT","creator_name":"XIE ZHIFEI","creator_url":"https://huggingface.co/zhifeixie","description":"zhifeixie/S2TT dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-google-fleurs","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (Google Fleurs)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual Google Fleurs dataset.\nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof Google Fleurs HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"free-music-archive-retrieval","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval","creator_name":"Ryan","creator_url":"https://huggingface.co/ryanleeme17","description":"\n\t\n\t\t\n\t\tFMAR: A Dataset for Robust Song Identification\n\t\n\nAuthors: Ryan Lee, Yi-Chieh Chiu, Abhir Karande, Ayush Goyal, Harrison Pearl, Matthew Hong, Spencer Cobb\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTo improve copyright infringement detection, we introduce Free-Music-Archive-Retrieval (FMAR), a structured dataset designed to test a model's capability to identify songs based on 5-second clips, or queries. We create adversarial queries to replicate common strategies to evade copyright infringement detectors‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"free-music-archive-retrieval","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval","creator_name":"Ryan","creator_url":"https://huggingface.co/ryanleeme17","description":"\n\t\n\t\t\n\t\tFMAR: A Dataset for Robust Song Identification\n\t\n\nAuthors: Ryan Lee, Yi-Chieh Chiu, Abhir Karande, Ayush Goyal, Harrison Pearl, Matthew Hong, Spencer Cobb\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTo improve copyright infringement detection, we introduce Free-Music-Archive-Retrieval (FMAR), a structured dataset designed to test a model's capability to identify songs based on 5-second clips, or queries. We create adversarial queries to replicate common strategies to evade copyright infringement detectors‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"free-music-archive-retrieval","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval","creator_name":"Ryan","creator_url":"https://huggingface.co/ryanleeme17","description":"\n\t\n\t\t\n\t\tFMAR: A Dataset for Robust Song Identification\n\t\n\nAuthors: Ryan Lee, Yi-Chieh Chiu, Abhir Karande, Ayush Goyal, Harrison Pearl, Matthew Hong, Spencer Cobb\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTo improve copyright infringement detection, we introduce Free-Music-Archive-Retrieval (FMAR), a structured dataset designed to test a model's capability to identify songs based on 5-second clips, or queries. We create adversarial queries to replicate common strategies to evade copyright infringement detectors‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"free-music-archive-retrieval","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval","creator_name":"Ryan","creator_url":"https://huggingface.co/ryanleeme17","description":"\n\t\n\t\t\n\t\tFMAR: A Dataset for Robust Song Identification\n\t\n\nAuthors: Ryan Lee, Yi-Chieh Chiu, Abhir Karande, Ayush Goyal, Harrison Pearl, Matthew Hong, Spencer Cobb\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTo improve copyright infringement detection, we introduce Free-Music-Archive-Retrieval (FMAR), a structured dataset designed to test a model's capability to identify songs based on 5-second clips, or queries. We create adversarial queries to replicate common strategies to evade copyright infringement detectors‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryanleeme17/free-music-archive-retrieval.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_en","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minghanw/sdf_dataset_en","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_en.","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_en","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minghanw/sdf_dataset_en","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_en.","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MSMarco-ES-TTS-small4.5ksamples","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ejbejaranos/MSMarco-ES-TTS-small4.5ksamples","creator_name":"Edison Bejarano Sepulveda","creator_url":"https://huggingface.co/ejbejaranos","description":"\n\t\n\t\t\n\t\tMSMarco-ES-TTS-small4.5ksamples üéôÔ∏èüìö\n\t\n\nEste dataset contiene 4,500 muestras de consultas y respuestas en espa√±ol generadas a partir del dataset MS Marco ES y convertidas a audio mediante un sistema de Text-to-Speech (TTS). \n\n\t\n\t\t\n\t\tEjemplo de audio\n\t\n\nPuedes escuchar un ejemplo de audio generado a partir del dataset aqu√≠:\n\n\t\n\t\t\n\t\tInstruction audio\n\t\n\n\n  \n  Tu navegador no soporta la reproducci√≥n de audio.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOutput audio\n\t\n\n\n  \n\t\n\t\t\n\t\tDescripci√≥n\n\t\n\nEl conjunto de datos‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ejbejaranos/MSMarco-ES-TTS-small4.5ksamples.","first_N":5,"first_N_keywords":["question-answering","Spanish","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"UAT_Data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suhaibrashid17/UAT_Data","creator_name":"Muhammad Suhaib Rashid","creator_url":"https://huggingface.co/suhaibrashid17","description":"suhaibrashid17/UAT_Data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Speech-Translation-Instructions","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mesolitica/Speech-Translation-Instructions","creator_name":"Mesolitica","creator_url":"https://huggingface.co/mesolitica","description":"\n\t\n\t\t\n\t\tSpeech-Translation-Instructions\n\t\n\nThe instructions translated from 120 languages Common Voice to english, arabic, japanese, mandarin and french from common voice speech dataset. Suitable to use to finetune Speech LLM.\n","first_N":5,"first_N_keywords":["multilingual","Malay","English","Chinese","Japanese"],"keywords_longer_than_N":true},
	{"name":"ipapack_plus_train_3","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anyspeech/ipapack_plus_train_3","creator_name":"AnySpeech","creator_url":"https://huggingface.co/anyspeech","description":"anyspeech/ipapack_plus_train_3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Audio-Children-Stories-Collection-Large","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Audio-Children-Stories-Collection-Large","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Audio Chidren Stories Collection Large\nThis dataset has 5600++ audio files in .mp3 format. This has been created using my existing dataset Children-Stories-Collection.\nI have used first 5600++ stories from Children-Stories-1-Final.json file for creating this audio dataset.\nYou can use this for training and research purpose.\nThank you for your love & support.\n","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Audio-Children-Stories-Collection-Large","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Audio-Children-Stories-Collection-Large","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Audio Chidren Stories Collection Large\nThis dataset has 5600++ audio files in .mp3 format. This has been created using my existing dataset Children-Stories-Collection.\nI have used first 5600++ stories from Children-Stories-1-Final.json file for creating this audio dataset.\nYou can use this for training and research purpose.\nThank you for your love & support.\n","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"spanish_Audios","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sirekist98/spanish_Audios","creator_name":"Jose Mar√≠a","creator_url":"https://huggingface.co/sirekist98","description":"sirekist98/spanish_Audios dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"work6","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlenJoy47/work6","creator_name":"Alen Joy","creator_url":"https://huggingface.co/AlenJoy47","description":"AlenJoy47/work6 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"recitation-segmentation","keyword":"voice-activity-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/obadx/recitation-segmentation","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","description":"\n\t\n\t\t\n\t\tRecitation Segmentation Dataset\n\t\n\nThis dataset is aiming to build a model that aplit the Holy Quran recitations using puase (ŸàŸÇŸÅ).\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\nfull description\nfeature description\n\n","first_N":5,"first_N_keywords":["voice-activity-detection","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ZIP-Dumps","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/samikhan121/ZIP-Dumps","creator_name":"Mohammed Sami Khan","creator_url":"https://huggingface.co/samikhan121","description":"samikhan121/ZIP-Dumps dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"AIhub_foreign_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jwh1449/AIhub_foreign_dataset","creator_name":"jwh1449","creator_url":"https://huggingface.co/jwh1449","description":"jwh1449/AIhub_foreign_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"banda-da-casa-edison-gramophone-dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lukiebub-house-band-ai/banda-da-casa-edison-gramophone-dataset","creator_name":"Lubub IA","creator_url":"https://huggingface.co/lukiebub-house-band-ai","description":"lukiebub-house-band-ai/banda-da-casa-edison-gramophone-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_2k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_2k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset (2k)\n\t\n\nThis dataset contains 4000 synthetic speech recordings in the Pashto language,\nwith 2000 male voice recordings and 2000 female voice recordings.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 2000 sentences\nTotal Recordings: 4000 audio files (2000 male + 2000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM\nSampling Rate: 44.1kHz (44100 Hz)\nVoices: \nMale: ps-AF-GulNawazNeural\nFemale: ps-AF-LatifaNeural\n\n\nTotal Audio Duration: \nMale: 0.00 seconds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_2k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_2k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_2k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset (2k)\n\t\n\nThis dataset contains 4000 synthetic speech recordings in the Pashto language,\nwith 2000 male voice recordings and 2000 female voice recordings.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 2000 sentences\nTotal Recordings: 4000 audio files (2000 male + 2000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM\nSampling Rate: 44.1kHz (44100 Hz)\nVoices: \nMale: ps-AF-GulNawazNeural\nFemale: ps-AF-LatifaNeural\n\n\nTotal Audio Duration: \nMale: 0.00 seconds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_2k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"VoxLingua107-Top-10","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silky1708/VoxLingua107-Top-10","creator_name":"Silky Singh","creator_url":"https://huggingface.co/silky1708","description":"silky1708/VoxLingua107-Top-10 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"BeijingOpera","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silky1708/BeijingOpera","creator_name":"Silky Singh","creator_url":"https://huggingface.co/silky1708","description":"silky1708/BeijingOpera dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"LibriCount","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silky1708/LibriCount","creator_name":"Silky Singh","creator_url":"https://huggingface.co/silky1708","description":"silky1708/LibriCount dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"prueba_parquet","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/prueba_parquet","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with parquet files only.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"urban_sounds_micro","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanSounds/urban_sounds_micro","creator_name":"Sensemakers Amsterdam UrbanSounds repo","creator_url":"https://huggingface.co/UrbanSounds","description":"UrbanSounds/urban_sounds_micro dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"VIETTTS","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hoanghiepv77/VIETTTS","creator_name":"VuHoangHiep","creator_url":"https://huggingface.co/hoanghiepv77","description":"hoanghiepv77/VIETTTS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"Corinth_dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OlameMend/Corinth_dataset","creator_name":"leo","creator_url":"https://huggingface.co/OlameMend","description":"OlameMend/Corinth_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Free-Spoken-Digit-Dataset","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silky1708/Free-Spoken-Digit-Dataset","creator_name":"Silky Singh","creator_url":"https://huggingface.co/silky1708","description":"silky1708/Free-Spoken-Digit-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ga_multispeaker_audio_transcribed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tGa Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ga Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Ga, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Irish","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ga_multispeaker_audio_transcribed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tGa Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ga Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Ga, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Irish","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"WorldSense","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmms-lab/WorldSense","creator_name":"LMMs-Lab","creator_url":"https://huggingface.co/lmms-lab","description":"lmms-lab/WorldSense dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"SASRBench-v1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mjwong/SASRBench-v1","creator_name":"Ming Jie Wong","creator_url":"https://huggingface.co/mjwong","description":"\n\t\n\t\t\n\t\tSASRBench-v1: Singlish ASR Benchmark V1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSASRBench-v1 is a benchmark dataset for evaluating Automatic Speech Recognition (ASR) performance on Singlish. It is derived exclusively from the Part 3 Same Room Environment Close-talk Mic recordings of IMDA's NSC Corpus.\n\n\t\n\t\t\n\t\tDataset Derivation\n\t\n\nFrom the Part 3 Same Room Environment Close-talk Mic recordings, audio segments were extracted with the following criteria:\n\nMinimum Word Count: 10 words  \nMaximum‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mjwong/SASRBench-v1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"voice_orders_data_sample","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Amirmerfan/voice_orders_data_sample","creator_name":"Amirmohammad Erfan","creator_url":"https://huggingface.co/Amirmerfan","description":"Amirmerfan/voice_orders_data_sample dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","text-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"voice_orders_data_sample","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Amirmerfan/voice_orders_data_sample","creator_name":"Amirmohammad Erfan","creator_url":"https://huggingface.co/Amirmerfan","description":"Amirmerfan/voice_orders_data_sample dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","text-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"whisper_asr_traindata","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sarannair/whisper_asr_traindata","creator_name":"Saran Nair","creator_url":"https://huggingface.co/sarannair","description":"\n\t\n\t\t\n\t\tEnglish Accent Audio-transcript Dataset.\n\t\n\nAudio is extracted from movies, shows, speeches, talks to capture diverse accents - mainly scottish and indian\nThis dataset contains 30-second audio clips with aligned transcript text. \n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach entry includes:\n\naudio: 30-second speech segment\ntext: Corresponding transcript\nstart_time / end_time: Segment timestamps\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nLicensed under CC-BY-4.0.\n","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"w-i-w","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/01gumano1d/w-i-w","creator_name":"gumano1d","creator_url":"https://huggingface.co/01gumano1d","description":"To unzip chunks and combine .wav files into one folder use:   \nmkdir audio && for i in {1..10}; do unzip -q chunk$i.zip -d chunk$i && mv chunk$i/*.wav audio/; done\n\nTo unzip test ds: \nunzip -q train.zip -d test\n\n","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"voices-with-captions","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/voices-with-captions","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Synthetic Voice Description Dataset for Voice Conversion\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains 3.180 synthetically generated voice samples, each paired with a caption that roughly describes how the voice sounds. Captions typically include information about the age, gender, accent, and sometimes general vocal qualities (e.g., \"old woman, Irish accent\").\nAll voices are synthetically generated and do not represent any real person. This makes the dataset ideal for training and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/voices-with-captions.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TAVGBench_1m","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kkail8/TAVGBench_1m","creator_name":"KAI LIU","creator_url":"https://huggingface.co/kkail8","description":"\n\t\n\t\t\n\t\tInstallation\n\t\n\nDownload this repo to a local folder, and unzip these *.zip files under the TAVGBench_1m/data/. Then, you can manually rename the TAVGBench_1m as TAVGBench, and you will get:\nTAVGBench/data/jhy3up8D9ro_30000_40000.mp4\nTAVGBench/data/N-6bJ6nW2NM_200000_210000.mp4\n...\n\nIn the TAVGBench_1m/meta_info.csv, each row corresponds to an sounding video instance, where the text column contains the audio-visual description from TAVGBench and other meta-info with Open-Sora's tools‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kkail8/TAVGBench_1m.","first_N":5,"first_N_keywords":["mit","1M - 10M","Audio","Video","Datasets"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_3k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_3k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (3k)\n\t\n\nThis dataset contains 6000 synthetic speech recordings in the Pashto language,\nwith 3000 male voice recordings and 3000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 3000 sentences\nTotal Recordings: 6000 audio files (3000 male + 3000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz (44100‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_3k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_3k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_3k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (3k)\n\t\n\nThis dataset contains 6000 synthetic speech recordings in the Pashto language,\nwith 3000 male voice recordings and 3000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 3000 sentences\nTotal Recordings: 6000 audio files (3000 male + 3000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz (44100‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_3k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"orpheus-es-dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/javiercubas/orpheus-es-dataset","creator_name":"Javier Cubas","creator_url":"https://huggingface.co/javiercubas","description":"javiercubas/orpheus-es-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"syntetic_necoarc_rus","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kostya165/syntetic_necoarc_rus","creator_name":"pleroma_cascade","creator_url":"https://huggingface.co/Kostya165","description":"\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n–≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏, –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ RVC (Retrieval-based Voice Conversion) NecoArc. –î–∞—Ç–∞—Å–µ—Ç –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π —Å–∏–Ω—Ç–µ–∑–∞ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n–Ø –Ω–µ –æ—Å–∏–ª–∏–ª —Ñ–∞–π–Ω—Ç—é–Ω TTS –º–æ–¥–µ–ª–∏ –ª–µ–≥–∫–æ–≤–µ—Å–Ω–æ–π , —Ç–∞–∫ —á—Ç–æ –µ—Å–ª–∏ —Å–º–æ–∂–µ—Ç–µ —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –±—É–¥—É –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω –∑–∞ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å\n\n–Ø–∑—ã–∫: –†—É—Å—Å–∫–∏–π\n–õ–∏—Ü–µ–Ω–∑–∏—è: MIT\n\n\n\t\n\t\t\n\t\n\t\n\t\t–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø–æ–ª—è:\n\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kostya165/syntetic_necoarc_rus.","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"YouTube_Video_Transkriptleri_TR","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anilosan15/YouTube_Video_Transkriptleri_TR","creator_name":"H√ºseyin Anƒ±l √áakmak","creator_url":"https://huggingface.co/Anilosan15","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of nearly 5 hours of video from over 40 Creative Commons-licensed videos on YouTube. The videos contain the voices of more than 100 different people. The audio files have been resampled to 16 kHz. The videos have been divided into chunks of up to 25 seconds. This dataset is intended for developing Turkish STT (Speech-to-Text) models.\n\n\t\n\t\t\n\t\tDatasets Preparetion\n\t\n\nThe audio files and transcript data were scraped from YouTube. The scraped‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anilosan15/YouTube_Video_Transkriptleri_TR.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"HusTep_ViSEC","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vinh727/HusTep_ViSEC","creator_name":"Nguyen Quang Vinh","creator_url":"https://huggingface.co/Vinh727","description":"Vinh727/HusTep_ViSEC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"ViSEC","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hustep-lab/ViSEC","creator_name":"HuSTeP - Human Speech and Text Processing Lab","creator_url":"https://huggingface.co/hustep-lab","description":"This dataset is part of a conference paper accepted to IEEE ICASSP 2024: paper.Please cite as:\n@INPROCEEDINGS{10448373,\n  author={Thanh, Pham Viet and Huyen, Ngo Thi Thu and Quan, Pham Ngoc and Trang, Nguyen Thi Thu},\n  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, \n  title={A Robust Pitch-Fusion Model for Speech Emotion Recognition in Tonal Languages}, \n  year={2024},\n  volume={},\n  number={},\n  pages={12386-12390}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hustep-lab/ViSEC.","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"marathi_voice_data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/milind0415/marathi_voice_data","creator_name":"Milind Ahirkar","creator_url":"https://huggingface.co/milind0415","description":"milind0415/marathi_voice_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Marathi","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"bccfqkzmusic","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/01gumano1d/bccfqkzmusic","creator_name":"gumano1d","creator_url":"https://huggingface.co/01gumano1d","description":"01gumano1d/bccfqkzmusic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"bccfqwhoiswho_open","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/01gumano1d/bccfqwhoiswho_open","creator_name":"gumano1d","creator_url":"https://huggingface.co/01gumano1d","description":"01gumano1d/bccfqwhoiswho_open dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DuplexMamba-state_discrimination","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Xiangyu1/DuplexMamba-state_discrimination","creator_name":"LuXiangyu","creator_url":"https://huggingface.co/Xiangyu1","description":"Xiangyu1/DuplexMamba-state_discrimination dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"fma-dataset-aug-caption","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/solbon1212/fma-dataset-aug-caption","creator_name":"JUNYOUNG KOH","creator_url":"https://huggingface.co/solbon1212","description":"\n\t\n\t\t\n\t\tFMA-CLAP Caption Augmentation Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is an enhanced version of the FMA (Free Music Archive) dataset, where we have augmented the original metadata with natural language captions generated using the CLAP (Contrastive Language-Audio Pretraining) model. The captions describe the genre, style, mood, and instrumentation of each track, making it more suitable for zero-shot learning, music classification, and text-to-music generation tasks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/solbon1212/fma-dataset-aug-caption.","first_N":5,"first_N_keywords":["audio-classification","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"fma-dataset-aug-caption","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/solbon1212/fma-dataset-aug-caption","creator_name":"JUNYOUNG KOH","creator_url":"https://huggingface.co/solbon1212","description":"\n\t\n\t\t\n\t\tFMA-CLAP Caption Augmentation Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is an enhanced version of the FMA (Free Music Archive) dataset, where we have augmented the original metadata with natural language captions generated using the CLAP (Contrastive Language-Audio Pretraining) model. The captions describe the genre, style, mood, and instrumentation of each track, making it more suitable for zero-shot learning, music classification, and text-to-music generation tasks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/solbon1212/fma-dataset-aug-caption.","first_N":5,"first_N_keywords":["audio-classification","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"fma-dataset-aug-caption","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/solbon1212/fma-dataset-aug-caption","creator_name":"JUNYOUNG KOH","creator_url":"https://huggingface.co/solbon1212","description":"\n\t\n\t\t\n\t\tFMA-CLAP Caption Augmentation Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is an enhanced version of the FMA (Free Music Archive) dataset, where we have augmented the original metadata with natural language captions generated using the CLAP (Contrastive Language-Audio Pretraining) model. The captions describe the genre, style, mood, and instrumentation of each track, making it more suitable for zero-shot learning, music classification, and text-to-music generation tasks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/solbon1212/fma-dataset-aug-caption.","first_N":5,"first_N_keywords":["audio-classification","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"common-voice-20-mn-normalized","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized","creator_name":"Ankhbayasgalan Davaadorj","creator_url":"https://huggingface.co/warmestman","description":"\n\t\n\t\t\n\t\tCommon Voice 20.0 Mongolian Dataset\n\t\n\nThis dataset is a subset of Mozilla's Common Voice project, containing Mongolian speech data. It's part of Common Voice 20.0 release.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio clips in .mp3 format\nTranscriptions for each audio clip\nTrain/test/dev splits\nAdditional metadata including speaker demographics\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nSpeech Recognition\nVoice Analysis\nLinguistic Research\nSpeech Processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Mongolian","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"common-voice-20-mn-normalized","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized","creator_name":"Ankhbayasgalan Davaadorj","creator_url":"https://huggingface.co/warmestman","description":"\n\t\n\t\t\n\t\tCommon Voice 20.0 Mongolian Dataset\n\t\n\nThis dataset is a subset of Mozilla's Common Voice project, containing Mongolian speech data. It's part of Common Voice 20.0 release.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio clips in .mp3 format\nTranscriptions for each audio clip\nTrain/test/dev splits\nAdditional metadata including speaker demographics\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nSpeech Recognition\nVoice Analysis\nLinguistic Research\nSpeech Processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Mongolian","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AudioNormalizationDatasetRVC","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Illia56/AudioNormalizationDatasetRVC","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","description":"Illia56/AudioNormalizationDatasetRVC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","Russian","apache-2.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"AudioNormalizationDatasetRVC","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Illia56/AudioNormalizationDatasetRVC","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","description":"Illia56/AudioNormalizationDatasetRVC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","Russian","apache-2.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"AudioNormalizationDatasetRVC","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Illia56/AudioNormalizationDatasetRVC","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","description":"Illia56/AudioNormalizationDatasetRVC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","Russian","apache-2.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"human_5_all","keyword":"audio","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/pipecat-ai/human_5_all","creator_name":"Pipecat","creator_url":"https://huggingface.co/pipecat-ai","description":"pipecat-ai/human_5_all dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["bsd-2-clause","1K - 10K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Shrutilipi","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Shrutilipi","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tShrutilipi\n\t\n\n\n  \n  \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nShrutilipi is a labelled ASR corpus obtained by mining parallel audio and text pairs at the document scale from All India Radio news bulletins for 12 Indian languages: Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Odia, Punjabi, Sanskrit, Tamil, Telugu, Urdu. The corpus has over 6400 hours of data across all languages.\nThis work is funded by Bhashini, MeitY and Nilekani Philanthropies\n\t\n\t\t\n\t\tUsage\n\t\n\nThe datasets library‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Shrutilipi.","first_N":5,"first_N_keywords":["cc-by-4.0","1M - 10M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Kathbath","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Kathbath","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tKathbath\n\t\n\nKathbath is an human-labeled ASR dataset containing 1,684 hours of labelled speech data across 12 Indian languages from 1,218 contributors located in 203 districts in India\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nBengali\nGujarati\nKannada\nHindi\nMalayalam\nMarathi\nOdia\nPunjabi\nSanskrit\nTamil\nTelugu\nUrdu\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe IndicSUPERB dataset is released under this licensing scheme:\n\nWe do not own any of the raw text used in creating this dataset.\nThe text data comes from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Kathbath.","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"diffrhythm-instrument-cc0-oepngamearg-10x5-generated","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Akjava/diffrhythm-instrument-cc0-oepngamearg-10x5-generated","creator_name":"Akihito Miyazaki","creator_url":"https://huggingface.co/Akjava","description":"\n\t\n\t\t\n\t\tWhat is this\n\t\n\nA dataset of 50 instrumental music tracks generated with the DiffRhythm model, using 10 CC0-licensed instrument samples from OEPN Game Art.\nPaper: https://huggingface.co/papers/2503.01183\nProject page: https://nzqian.github.io/DiffRhythm/\n\n\t\n\t\t\n\t\tModels\n\t\n\nThis dataset was created by running the DiffRhythm model on 2025 Mar 05 using a copy of the space available at https://huggingface.co/spaces/ASLP-lab/DiffRhythm.\nThe exact architecture (base or VAE) of the DiffRhythm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Akjava/diffrhythm-instrument-cc0-oepngamearg-10x5-generated.","first_N":5,"first_N_keywords":["audio-to-audio","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"diffrhythm-instrument-cc0-oepngamearg-10x5-generated","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Akjava/diffrhythm-instrument-cc0-oepngamearg-10x5-generated","creator_name":"Akihito Miyazaki","creator_url":"https://huggingface.co/Akjava","description":"\n\t\n\t\t\n\t\tWhat is this\n\t\n\nA dataset of 50 instrumental music tracks generated with the DiffRhythm model, using 10 CC0-licensed instrument samples from OEPN Game Art.\nPaper: https://huggingface.co/papers/2503.01183\nProject page: https://nzqian.github.io/DiffRhythm/\n\n\t\n\t\t\n\t\tModels\n\t\n\nThis dataset was created by running the DiffRhythm model on 2025 Mar 05 using a copy of the space available at https://huggingface.co/spaces/ASLP-lab/DiffRhythm.\nThe exact architecture (base or VAE) of the DiffRhythm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Akjava/diffrhythm-instrument-cc0-oepngamearg-10x5-generated.","first_N":5,"first_N_keywords":["audio-to-audio","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"FINALLL","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Finalprojectfour/FINALLL","creator_name":"bleeehh ","creator_url":"https://huggingface.co/Finalprojectfour","description":"Finalprojectfour/FINALLL dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"bark-wave-semantic","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeper371/bark-wave-semantic","creator_name":"Hao H.","creator_url":"https://huggingface.co/sleeper371","description":"sleeper371/bark-wave-semantic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"drone-audio-detection-samples","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/geronimobasso/drone-audio-detection-samples","creator_name":"Geronimo","creator_url":"https://huggingface.co/geronimobasso","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDrone Audio Detection Samples (DADS) is currently the largest publicly available drone audio database, specifically designed for developing drone detection systems using deep learning techniques. All audio files are standardized to a sample rate of 16,000 Hz, 16-bit depth, mono-channel, and vary in length from 500 milliseconds to several minutes.\nMost drone audio files were manually trimmed to ensure that a drone was always present in the recording. However, some‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/geronimobasso/drone-audio-detection-samples.","first_N":5,"first_N_keywords":["audio-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"drone-audio-detection-samples","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/geronimobasso/drone-audio-detection-samples","creator_name":"Geronimo","creator_url":"https://huggingface.co/geronimobasso","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDrone Audio Detection Samples (DADS) is currently the largest publicly available drone audio database, specifically designed for developing drone detection systems using deep learning techniques. All audio files are standardized to a sample rate of 16,000 Hz, 16-bit depth, mono-channel, and vary in length from 500 milliseconds to several minutes.\nMost drone audio files were manually trimmed to ensure that a drone was always present in the recording. However, some‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/geronimobasso/drone-audio-detection-samples.","first_N":5,"first_N_keywords":["audio-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Each002/audio","creator_name":"Each","creator_url":"https://huggingface.co/Each002","description":"1\n","first_N":5,"first_N_keywords":["translation","Avestan","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"TalkingHeadBench","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/luchaoqi/TalkingHeadBench","creator_name":"Luchao Qi","creator_url":"https://huggingface.co/luchaoqi","description":"\n\t\n\t\t\n\t\tTalkingHeadBench\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe TalkingHeadBench(THB) is a curated dataset designed to support the training and evaluation of deepfake detection models, especially in audio-visual and cross-method generalization scenarios. It includes synthetic videos generated using six modern face animation techniques:\n\nLivePortrait\nAniPortraitAudio\nAniPortraitVideo\nHallo\nHallo2\nEmoPortrait\n\nEach video is named using the format:\n[image]--[driving_signals]--[generation_method].mp4\n\n\nimage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/luchaoqi/TalkingHeadBench.","first_N":5,"first_N_keywords":["mit","1K - 10K","Audio","Video","Datasets"],"keywords_longer_than_N":true},
	{"name":"e","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Each002/e","creator_name":"Each","creator_url":"https://huggingface.co/Each002","description":"Each002/e dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Afar","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Jailbreak-AudioBench","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/researchtopic/Jailbreak-AudioBench","creator_name":"research","creator_url":"https://huggingface.co/researchtopic","description":"researchtopic/Jailbreak-AudioBench dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DitingBench","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/DitingBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDiting Benchmark\n\t\n\nOur paperGithub\nOur benchmark is designed to evaluate the speech comprehension capabilities of Speech LLMs. We tested both humans and Speech LLMs in terms of speech understanding and provided further analysis of the results, along with a comparative study between the two. This offers insights for the future development of Speech LLMs. For more details, please refer to our paper.\n\n\t\n\t\t\n\t\n\t\n\t\tResult\n\t\n\n\n\t\n\t\t\nLevel\nTask\nHuman Baseline\nGPT-4o\nMuLLaMA\nGAMA\nSALMONN‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/DitingBench.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","csv","Audio"],"keywords_longer_than_N":true},
	{"name":"libri_mel","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kaizhang04/libri_mel","creator_name":"Yaokai","creator_url":"https://huggingface.co/kaizhang04","description":"kaizhang04/libri_mel dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"fongbe-speech-dataset-female","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/beethogedeon/fongbe-speech-dataset-female","creator_name":"Gedeon J. Gbedonou","creator_url":"https://huggingface.co/beethogedeon","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: Fr√©jus LALEYE\nShared by [optional]: Fr√©jus LALEYE\nLanguage(s) (NLP): Fongbe\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://github.com/laleye/pyFongbe\nPaper [optional]:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/beethogedeon/fongbe-speech-dataset-female.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Aria_Dataset-Unsorted","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pt-sk/Aria_Dataset-Unsorted","creator_name":"Sathish Kumar","creator_url":"https://huggingface.co/pt-sk","description":"pt-sk/Aria_Dataset-Unsorted dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Video","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"suno","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/suno","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Suno.ai Music Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 659,788 songs generated by artificial intelligence on the suno.com platform, a service that generates music using artificial intelligence. The songs were discovered by search queries with words from the dwyl/english-words word list.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual with English as the primary language:\n\nEnglish (en): Primary language for metadata and most lyrics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/suno.","first_N":5,"first_N_keywords":["audio-classification","text-to-audio","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"suno","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/suno","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Suno.ai Music Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 659,788 songs generated by artificial intelligence on the suno.com platform, a service that generates music using artificial intelligence. The songs were discovered by search queries with words from the dwyl/english-words word list.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual with English as the primary language:\n\nEnglish (en): Primary language for metadata and most lyrics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/suno.","first_N":5,"first_N_keywords":["audio-classification","text-to-audio","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"suno","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/suno","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Suno.ai Music Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 659,788 songs generated by artificial intelligence on the suno.com platform, a service that generates music using artificial intelligence. The songs were discovered by search queries with words from the dwyl/english-words word list.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual with English as the primary language:\n\nEnglish (en): Primary language for metadata and most lyrics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/suno.","first_N":5,"first_N_keywords":["audio-classification","text-to-audio","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"suno","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/suno","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Suno.ai Music Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 659,788 songs generated by artificial intelligence on the suno.com platform, a service that generates music using artificial intelligence. The songs were discovered by search queries with words from the dwyl/english-words word list.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual with English as the primary language:\n\nEnglish (en): Primary language for metadata and most lyrics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/suno.","first_N":5,"first_N_keywords":["audio-classification","text-to-audio","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Lappland","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"Lappland","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"yt_test","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vasukumarp/yt_test","creator_name":"Vasukumar Palanisamy","creator_url":"https://huggingface.co/vasukumarp","description":"vasukumarp/yt_test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"prueba","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Beyonder616/prueba","creator_name":"Armando Jesus Foronda Pesso","creator_url":"https://huggingface.co/Beyonder616","description":"Beyonder616/prueba dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Crystal","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Crystal","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Crystal dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Jade","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Jade","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Jade dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"inset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hev832s/inset","creator_name":"Hev832","creator_url":"https://huggingface.co/hev832s","description":"hev832s/inset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Raina","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Raina","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Raina dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"fleurs_yo_en","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bloomcode/fleurs_yo_en","creator_name":"Hidiat Ibrahim","creator_url":"https://huggingface.co/Bloomcode","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the Yoruba-to-English translation dataset culled from the Google FLEURS dataset. The Yoruba portion consists of utterances corresponding to 13:48:32 hours of audio data in the train set, 44:32 minutes of audio data in validation set, and 45:27 minutes of audio data in the test set. The audio recordings are sampled at 16kHz. The dataset consists of the audio recording with Yoruba transcriptions and corresponding English translations.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bloomcode/fleurs_yo_en.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"FLEURS-BN-EN","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/satarupa22/FLEURS-BN-EN","creator_name":"Satarupa Deb","creator_url":"https://huggingface.co/satarupa22","description":"satarupa22/FLEURS-BN-EN dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"speech-translation-uk-en","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oovword/speech-translation-uk-en","creator_name":"Y","creator_url":"https://huggingface.co/oovword","description":"This dataset has been created from 3 different datasets processed for the speech translation task.\nTotal number of samples by split:\n\ntrain: 10390\nvalidation: 2058\ntest:  2828\n\nTotal audio duration by split:\n\ntrain: 10 hours 45 minutes 12 seconds\nvalidation: 1 hour 36 minutes 7 seconds\ntest:  3 hours 1 minute 28 seconds\n\n\n\t\n\t\t\n\t\n\t\n\t\tFleurs google/fleurs\n\t\n\nNo major preprocessing has been done for this subset, except for extracting the Ukrainian and English parallel sentences.\n\n\t\n\t\n\t\n\t\tSpoken‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oovword/speech-translation-uk-en.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Nepali-Small","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NKRSubedi/Nepali-Small","creator_name":"NKRS","creator_url":"https://huggingface.co/NKRSubedi","description":"NKRSubedi/Nepali-Small dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Nepali","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"opendata-iisys-hui","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Paradoxia/opendata-iisys-hui","creator_name":"Firat Tay","creator_url":"https://huggingface.co/Paradoxia","description":"\n\n\t\n\t\t\n\t\tHUI-Audio-Corpus-German Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe HUI-Audio-Corpus-German is a high-quality Text-To-Speech (TTS) dataset developed by researchers at the Institute of Information Systems (IISYS). This dataset is designed to facilitate the development and training of TTS applications, particularly in the German language. The associated research paper can be found here.\n\n\t\n\t\t\n\t\tDataset Contents\n\t\n\nThe dataset comprises recordings from multiple speakers, with the five most‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paradoxia/opendata-iisys-hui.","first_N":5,"first_N_keywords":["German","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"sample-id","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/grandhigh/sample-id","creator_name":"Reyhan Al","creator_url":"https://huggingface.co/grandhigh","description":"grandhigh/sample-id dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Indonesian","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"evals-ec-whisper-btb-cv-ft-enwaucymru-lm","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DewiBrynJones/evals-ec-whisper-btb-cv-ft-enwaucymru-lm","creator_name":"Dewi Bryn Jones","creator_url":"https://huggingface.co/DewiBrynJones","description":"Model: DewiBrynJones/whisper-btb-cv-ft-enwaucymru-lm\nTest Set: wanasash/enwaucymraeg\nSplit: test\n\nWER: 21.647262\nCER: 7.527788\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ai-gospel-music-dictionaries","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries","creator_name":"Cruz Macias","creator_url":"https://huggingface.co/cmathhug","description":"\n\t\n\t\t\n\t\tAI Gospel Music Dictionaries\n\t\n\nA comprehensive collection of JSON dictionaries designed to support AI-powered gospel music and lyrics generation, with a focus on biblical and theological content.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a curated set of dictionaries that can be used for:\n\nMusic generation tasks\nLyrics generation with biblical themes\nInstrument and genre specifications\nBiblical reference materials\n\n\n\t\n\t\t\n\t\tDictionaries\n\t\n\n\n\t\n\t\t\n\t\tBiblical Content‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","cc0-1.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"LnNor_raw","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiBridge/LnNor_raw","creator_name":"MultiBridge","creator_url":"https://huggingface.co/MultiBridge","description":"\n\t\n\t\t\n\t\tDataset Card for the LnNor Corpus\n\t\n\n\n\nIMPORTANT: This is the raw version of the LnNor corpus. If you intend to use the dataset for training or evaluation, you may be more interested in MultiBridge/LnNor, which contains the same audio recordings, but segmented into smaller samples and converted to mono at 16 kHz.\nA multilingual dataset of high-quality speech recordings in Norwegian, English, and Polish, designed for research into cross-linguistic influence, multilingual language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MultiBridge/LnNor_raw.","first_N":5,"first_N_keywords":["Norwegian","Polish","English","cc-by-4.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"jhin_xtts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/twph/jhin_xtts","creator_name":"twph","creator_url":"https://huggingface.co/twph","description":"twph/jhin_xtts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"vads","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/politeles/vads","creator_name":"JosePons","creator_url":"https://huggingface.co/politeles","description":"\n\t\n\t\t\n\t\tpretty_name: VADS\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for VADS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVADS (Violin Audio Dataset for Sound Synthesis) is a dataset for violin technique classification and sound synthesis research. It consists of over 10,000 violin samples played with various techniques, recorded with different microphones. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset does not contain any spoken language; it consists of audio recordings of violin sounds.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/politeles/vads.","first_N":5,"first_N_keywords":["audio-classification","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"vads","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/politeles/vads","creator_name":"JosePons","creator_url":"https://huggingface.co/politeles","description":"\n\t\n\t\t\n\t\tpretty_name: VADS\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for VADS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVADS (Violin Audio Dataset for Sound Synthesis) is a dataset for violin technique classification and sound synthesis research. It consists of over 10,000 violin samples played with various techniques, recorded with different microphones. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset does not contain any spoken language; it consists of audio recordings of violin sounds.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/politeles/vads.","first_N":5,"first_N_keywords":["audio-classification","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"vads","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/politeles/vads","creator_name":"JosePons","creator_url":"https://huggingface.co/politeles","description":"\n\t\n\t\t\n\t\tpretty_name: VADS\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for VADS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVADS (Violin Audio Dataset for Sound Synthesis) is a dataset for violin technique classification and sound synthesis research. It consists of over 10,000 violin samples played with various techniques, recorded with different microphones. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset does not contain any spoken language; it consists of audio recordings of violin sounds.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/politeles/vads.","first_N":5,"first_N_keywords":["audio-classification","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"new_data","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/varunjanumpally21/new_data","creator_name":"Janumpally Varun Aditya","creator_url":"https://huggingface.co/varunjanumpally21","description":"varunjanumpally21/new_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"audio_public","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SayantanJoker/audio_public","creator_name":"Sayantan Ray","creator_url":"https://huggingface.co/SayantanJoker","description":"SayantanJoker/audio_public dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Indic_parler_tts_audio_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickfuryavg/Indic_parler_tts_audio_dataset","creator_name":"Sandipan Ray","creator_url":"https://huggingface.co/nickfuryavg","description":"nickfuryavg/Indic_parler_tts_audio_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"F5-TTS-Small_audio_testing_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickfuryavg/F5-TTS-Small_audio_testing_dataset","creator_name":"Sandipan Ray","creator_url":"https://huggingface.co/nickfuryavg","description":"nickfuryavg/F5-TTS-Small_audio_testing_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"audio_quality","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickfuryavg/audio_quality","creator_name":"Sandipan Ray","creator_url":"https://huggingface.co/nickfuryavg","description":"nickfuryavg/audio_quality dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dataset-for-peft-cv-nepds","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kiranpantha/dataset-for-peft-cv-nepds","creator_name":"Kiran Pantha","creator_url":"https://huggingface.co/kiranpantha","description":"kiranpantha/dataset-for-peft-cv-nepds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Nepali","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"MSA_train_set","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/MSA_train_set","creator_name":"√ñmer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed MSA data based on https://huggingface.co/datasets/mozilla-foundation/common_voice_16_1.\n","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Musa-FA_EN-Public-Phone-Audio-Dataset","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mah92/Musa-FA_EN-Public-Phone-Audio-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","description":"Same as: https://huggingface.co/datasets/mah92/Khadijah-FA_EN-Public-Phone-Audio-Dataset\n","first_N":5,"first_N_keywords":["Persian","English","cc0-1.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"AISHELL-4","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shenyunhang/AISHELL-4","creator_name":"Ê≤à‰∫ëËà™ Yunhang Shen","creator_url":"https://huggingface.co/shenyunhang","description":"\n AISHELL-4\n \n Identifier: SLR111 \n Summary: A Free Mandarin Multi-channel Meeting Speech Corpus, provided by Beijing Shell Shell Technology Co.,Ltd\n \n Category: Speech\n \n License: CC BY-SA 4.0\n \n Downloads (use a mirror closer to you): \n train_L.tar.gz  [7.0G] ¬† ( Training set of large room, 8-channel microphone array speech\n) ¬†  Mirrors: \n [US]  ¬†\n [EU]  ¬†\n [CN]  ¬†\ntrain_M.tar.gz  [25G] ¬† ( Training set of medium room, 8-channel microphone array speech\n) ¬†  Mirrors: \n [US]  ¬†\n [EU]  ¬†\n [CN]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shenyunhang/AISHELL-4.","first_N":5,"first_N_keywords":["apache-2.0","Audio","Text","arxiv:2104.03603","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Voice","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/Voice","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"Introducing dataset of professional voice actors where actors have spoken X sentences. It includes data from all the voices (approx. 9, 920) from voices.com website. Where professional actors have provided examples of their voices. \n\n\t\n\t\t\n\t\tWhat's Voices.com?\n\t\n\nIt is a website where professional voice actors can be found for different voice acting activities for a cheap price. Much like Fiverr but for actual voices. \n\n\t\n\t\t\n\t\tWhat's included?\n\t\n\n\nVoice tracks (approx. 4) for each actor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/Voice.","first_N":5,"first_N_keywords":["English","Arabic","afl-3.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"audio1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlenJoy47/audio1","creator_name":"Alen Joy","creator_url":"https://huggingface.co/AlenJoy47","description":"AlenJoy47/audio1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"czech_time_shards_recordings","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/night12/czech_time_shards_recordings","creator_name":"Robert","creator_url":"https://huggingface.co/night12","description":"night12/czech_time_shards_recordings dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"ShiftySpeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ash56/ShiftySpeech","creator_name":"Ashi Garg","creator_url":"https://huggingface.co/ash56","description":"This repository introduces:  üåÄ ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution Shifts\n\n\t\n\t\t\n\t\tüî• Key Features\n\t\n\n\n3000+ hours of synthetic speech\nDiverse Distribution Shifts: The dataset spans 7 key distribution shifts, including:  \nüìñ Reading Style  \nüéôÔ∏è Podcast  \nüé• YouTube  \nüó£Ô∏è Languages (Three different languages)  \nüåé Demographics (including variations in age, accent, and gender)\n\n\nMultiple Speech Generation Systems: Includes data synthesized from various TTS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ash56/ShiftySpeech.","first_N":5,"first_N_keywords":["English","Chinese","Japanese","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ShiftySpeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ash56/ShiftySpeech","creator_name":"Ashi Garg","creator_url":"https://huggingface.co/ash56","description":"This repository introduces:  üåÄ ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution Shifts\n\n\t\n\t\t\n\t\tüî• Key Features\n\t\n\n\n3000+ hours of synthetic speech\nDiverse Distribution Shifts: The dataset spans 7 key distribution shifts, including:  \nüìñ Reading Style  \nüéôÔ∏è Podcast  \nüé• YouTube  \nüó£Ô∏è Languages (Three different languages)  \nüåé Demographics (including variations in age, accent, and gender)\n\n\nMultiple Speech Generation Systems: Includes data synthesized from various TTS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ash56/ShiftySpeech.","first_N":5,"first_N_keywords":["English","Chinese","Japanese","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"PhonemeFakeV2","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phonemefake/PhonemeFakeV2","creator_name":"PhonemeFake Dataset","creator_url":"https://huggingface.co/phonemefake","description":"\n\t\n\t\t\n\t\tPhonemeFake -  A Phonetic Deepfake Dataset\n\t\n\n\n\nWe introduce PhonemeFake, a DF attack that manipulates critical speech segments using language reasoning, significantly reducing human perception and SoTA\nmodel accuracies.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nWe provide example spoof audio in the viewers tab along with the transcription of the bonafide sample, the manipulated transcription and the audio timings for a small set of the data.\nThe dataset is split into three subsets. The spoof samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phonemefake/PhonemeFakeV2.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"PhonemeFakeV2","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phonemefake/PhonemeFakeV2","creator_name":"PhonemeFake Dataset","creator_url":"https://huggingface.co/phonemefake","description":"\n\t\n\t\t\n\t\tPhonemeFake -  A Phonetic Deepfake Dataset\n\t\n\n\n\nWe introduce PhonemeFake, a DF attack that manipulates critical speech segments using language reasoning, significantly reducing human perception and SoTA\nmodel accuracies.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nWe provide example spoof audio in the viewers tab along with the transcription of the bonafide sample, the manipulated transcription and the audio timings for a small set of the data.\nThe dataset is split into three subsets. The spoof samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phonemefake/PhonemeFakeV2.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"YSSY_2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lmejias/YSSY_2","creator_name":"Luis Mejias","creator_url":"https://huggingface.co/lmejias","description":"lmejias/YSSY_2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"DNE","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IamPre/DNE","creator_name":"Priyanka Ojha","creator_url":"https://huggingface.co/IamPre","description":"IamPre/DNE dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"audio3","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlenJoy47/audio3","creator_name":"Alen Joy","creator_url":"https://huggingface.co/AlenJoy47","description":"AlenJoy47/audio3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"sep28k-mvp","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/luigimontaleone/sep28k-mvp","creator_name":"Luigi Montaleone","creator_url":"https://huggingface.co/luigimontaleone","description":"luigimontaleone/sep28k-mvp dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"libritts-r-webdataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lucasnewman/libritts-r-webdataset","creator_name":"Lucas Newman","creator_url":"https://huggingface.co/lucasnewman","description":"Official website: https://www.openslr.org/141/\nThis repository contains LibriTTS-R converted to a WebDataset. The original Wave files have been converted to 64kbps MP3 files for efficient streaming.\nLibriTTS-R (paper) is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately 585 hours of read English speech at 24kHz sampling rate, published in 2019. The constituent samples of LibriTTS-R are identical to those of LibriTTS, with only the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lucasnewman/libritts-r-webdataset.","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"kinh-phap-hoa-ke-trom-huong","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"Normalized using https://github.com/oysterlanguage/emiliapipex\n@article{emilia,\n      title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},\n      author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},\n      journal={arXiv},\n      volume={abs/2407.05361}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"kinh-phap-hoa-ke-trom-huong","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"Normalized using https://github.com/oysterlanguage/emiliapipex\n@article{emilia,\n      title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},\n      author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},\n      journal={arXiv},\n      volume={abs/2407.05361}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"DVoice-VoxLingua107-trialrun1","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kazeric/DVoice-VoxLingua107-trialrun1","creator_name":"Eric Kazungu Kahindi","creator_url":"https://huggingface.co/kazeric","description":"kazeric/DVoice-VoxLingua107-trialrun1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","csv","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"laions_got_talent_enhanced_no_metadata","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/laions_got_talent_enhanced_no_metadata","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"laion/laions_got_talent_enhanced_no_metadata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"eng-kaz-rus-commands","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/adilakimshe/eng-kaz-rus-commands","creator_name":"Adilet Akimshe","creator_url":"https://huggingface.co/adilakimshe","description":"adilakimshe/eng-kaz-rus-commands dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"MultiMed-ST","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leduckhai/MultiMed-ST","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","description":"\n\t\n\t\t\n\t\tMultiMed-ST: Large-scale Many-to-many Multilingual Medical Speech Translation\n\t\n\nPreprint\nKhai Le-Duc*, Tuyen Tran*,\nBach Phan Tat, Nguyen Kim Hai Bui, Quan Dang, Hung-Phong Tran, Thanh-Thuy Nguyen, Ly Nguyen, Tuan-Minh Phan, Thi Thu Phuong Tran, Chris Ngo,\nNguyen X. Khanh**, Thanh Nguyen-Tang**\n\n\n*Equal contribution\n**Equal supervision\n\n\nAbstract:\nMultilingual speech translation (ST) in the medical domain  enhances patient care by enabling efficient communication across language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/MultiMed-ST.","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","Vietnamese","English","German"],"keywords_longer_than_N":true},
	{"name":"SpokenSwag","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/SpokenSwag","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\n\t\n\t\t\n\t\tSpokenSwag\n\t\n\nWe present here SpokenSwag as described in the paper \"Slamming: Training a Speech Language Model on One GPU in a Day\".\nThis dataset is based on allenai/swag and synthetised with 4 speakers from hexgrad/Kokoro-82M.\nWe show that perfoming DPO over the dataset can really improve performance of Speech Language Models.\nWe encourage you to also see the following resources, for further information:\nProject Page: https://pages.cs.huji.ac.il/adiyoss-lab/slamming/ Paper:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slprl/SpokenSwag.","first_N":5,"first_N_keywords":["audio-to-audio","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SpokenSwag","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/SpokenSwag","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\n\t\n\t\t\n\t\tSpokenSwag\n\t\n\nWe present here SpokenSwag as described in the paper \"Slamming: Training a Speech Language Model on One GPU in a Day\".\nThis dataset is based on allenai/swag and synthetised with 4 speakers from hexgrad/Kokoro-82M.\nWe show that perfoming DPO over the dataset can really improve performance of Speech Language Models.\nWe encourage you to also see the following resources, for further information:\nProject Page: https://pages.cs.huji.ac.il/adiyoss-lab/slamming/ Paper:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slprl/SpokenSwag.","first_N":5,"first_N_keywords":["audio-to-audio","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"facebook_m4t_v2_syndata","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/grdphilip/facebook_m4t_v2_syndata","creator_name":"Rettig","creator_url":"https://huggingface.co/grdphilip","description":"grdphilip/facebook_m4t_v2_syndata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"opentts-uk-aesthetics","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\n\t\n\t\t\n\t\tAesthetics of Open Text-to-Speech for üá∫üá¶ Ukrainian dataset\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis dataset contains metrics for https://huggingface.co/datasets/Yehor/opentts-uk dataset retrieved by https://github.com/facebookresearch/audiobox-aesthetics \n\n\t\n\t\t\n\t\tHow metrics calculated?\n\t\n\nYou can find a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"opentts-uk-aesthetics","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\n\t\n\t\t\n\t\tAesthetics of Open Text-to-Speech for üá∫üá¶ Ukrainian dataset\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis dataset contains metrics for https://huggingface.co/datasets/Yehor/opentts-uk dataset retrieved by https://github.com/facebookresearch/audiobox-aesthetics \n\n\t\n\t\t\n\t\tHow metrics calculated?\n\t\n\nYou can find a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"AISHELL-3","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shenyunhang/AISHELL-3","creator_name":"Ê≤à‰∫ëËà™ Yunhang Shen","creator_url":"https://huggingface.co/shenyunhang","description":"\n AISHELL-3\n \n Identifier: SLR93 \n Summary: Mandarin data, provided by Beijing Shell Shell Technology Co., Ltd.\n \n Category: Speech\n \n License: Apache License v.2.0\n \n Downloads (use a mirror closer to you): \n data_aishell3.tgz  [19G] ¬† (speech data and transcripts\n) ¬†  Mirrors: \n [US]  ¬†\n [EU]  ¬†\n [CN]  ¬†\nAbout this resource:AISHELL-3 is a large-scale and high-fidelity multi-speaker Mandarin speech corpus \npublished by Beijing Shell Shell Technology Co.,Ltd. It can be used to train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shenyunhang/AISHELL-3.","first_N":5,"first_N_keywords":["apache-2.0","Audio","arxiv:2010.11567","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"testing","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ultahost329/testing","creator_name":"Ulta Host Power","creator_url":"https://huggingface.co/ultahost329","description":"ultahost329/testing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"common-voice-tamil-english-labeled-Data","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lingalingeswaran/common-voice-tamil-english-labeled-Data","creator_name":"Sathiyalokeswaran","creator_url":"https://huggingface.co/Lingalingeswaran","description":"Lingalingeswaran/common-voice-tamil-english-labeled-Data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Tamil","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/MANGO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n255,150 human ratings of TTS-generated outputs and ground-truth human speech.\nCovers two major Indian languages: Hindi & Tamil, and English.\nBased on the MUSHRA (Multiple Stimuli with Hidden Reference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/MANGO.","first_N":5,"first_N_keywords":["text-to-speech","crowd-sourced","Hindi","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"sTinyStories","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/sTinyStories","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\n\t\n\t\t\n\t\tsTinyStories\n\t\n\nA spoken version of TinyStories Synthesized with LJ voice using FastSpeech2.\nThe dataset was synthesized to boost the training of Speech Language Models as detailed in the paper \"Slamming: Training a Speech Language Model on One GPU in a Day\".\nIt was first suggested by Cuervo et. al 2024.\nWe refer you to the SlamKit codebase to see how you can train a SpeechLM with this dataset.\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slprl/sTinyStories.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"sTinyStories","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/sTinyStories","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\n\t\n\t\t\n\t\tsTinyStories\n\t\n\nA spoken version of TinyStories Synthesized with LJ voice using FastSpeech2.\nThe dataset was synthesized to boost the training of Speech Language Models as detailed in the paper \"Slamming: Training a Speech Language Model on One GPU in a Day\".\nIt was first suggested by Cuervo et. al 2024.\nWe refer you to the SlamKit codebase to see how you can train a SpeechLM with this dataset.\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slprl/sTinyStories.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"sTinyStories","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/sTinyStories","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\n\t\n\t\t\n\t\tsTinyStories\n\t\n\nA spoken version of TinyStories Synthesized with LJ voice using FastSpeech2.\nThe dataset was synthesized to boost the training of Speech Language Models as detailed in the paper \"Slamming: Training a Speech Language Model on One GPU in a Day\".\nIt was first suggested by Cuervo et. al 2024.\nWe refer you to the SlamKit codebase to see how you can train a SpeechLM with this dataset.\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slprl/sTinyStories.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"EpiBERT","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/introvoyz041/EpiBERT","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","description":"introvoyz041/EpiBERT dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","soundfolder","Audio","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Genshin-Yanfei","keyword":"audio","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/Tomime/Genshin-Yanfei","creator_name":"Tomislav Horvat","creator_url":"https://huggingface.co/Tomime","description":"These are voice clips from Yanfei from Genshin Impact, taken from the simon3000 genshin voice dataset, re-transcribed with whisper, to remove the weird transcription and vocal effects,\nsampled to 22.05khz sampling rate, run through simple noise reduction with librosa, and the longer entries were chunked to be up to 15 seconds long, and the silent parts were trimmed, also the\nvery small unintelligible audios that couldn't even be transcribed were scrapped from the set. Finally my plan is to run‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tomime/Genshin-Yanfei.","first_N":5,"first_N_keywords":["English","wtfpl","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"semi-Voxpopuli","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli","creator_name":"Jagadeesh Rachapudi","creator_url":"https://huggingface.co/Jagadeesh9580","description":"\n\t\n\t\t\n\t\tVoxPopuli Multilingual Audio Dataset\n\t\n\nThis dataset contains audio recordings in English (EN), Polish (PL), and Swedish (SV) languages. It is derived from the VoxPopuli dataset and tailored for multilingual language processing tasks.\nThe dataset includes audio clips and corresponding metadata to support research and development in multilingual audio processing.\n\n\t\n\t\t\n\t\tDataset Files\n\t\n\nThe dataset includes the following files:\n\ndata.csv: Contains metadata about the audio files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"semi-Voxpopuli","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli","creator_name":"Jagadeesh Rachapudi","creator_url":"https://huggingface.co/Jagadeesh9580","description":"\n\t\n\t\t\n\t\tVoxPopuli Multilingual Audio Dataset\n\t\n\nThis dataset contains audio recordings in English (EN), Polish (PL), and Swedish (SV) languages. It is derived from the VoxPopuli dataset and tailored for multilingual language processing tasks.\nThe dataset includes audio clips and corresponding metadata to support research and development in multilingual audio processing.\n\n\t\n\t\t\n\t\tDataset Files\n\t\n\nThe dataset includes the following files:\n\ndata.csv: Contains metadata about the audio files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"semi-Voxpopuli","keyword":"speaker-identification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli","creator_name":"Jagadeesh Rachapudi","creator_url":"https://huggingface.co/Jagadeesh9580","description":"\n\t\n\t\t\n\t\tVoxPopuli Multilingual Audio Dataset\n\t\n\nThis dataset contains audio recordings in English (EN), Polish (PL), and Swedish (SV) languages. It is derived from the VoxPopuli dataset and tailored for multilingual language processing tasks.\nThe dataset includes audio clips and corresponding metadata to support research and development in multilingual audio processing.\n\n\t\n\t\t\n\t\tDataset Files\n\t\n\nThe dataset includes the following files:\n\ndata.csv: Contains metadata about the audio files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"be-bel-audio-corpus","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fosters/be-bel-audio-corpus","creator_name":"Lary","creator_url":"https://huggingface.co/fosters","description":"Belarusian audio corpus.\n3 different sets under the hood.\n\ndataset_1 - –õ—é–¥–∑—ñ –Ω–∞ –±–∞–ª–æ—Ü–µ\nCorresponded text https://knihi.com/Ivan_Mielez/Ludzi_na_balocie.html\nTotal duration: 13:42:04\n\ndataset_2 - Donar.by\nTotal duration: 37h 5m 34s\n\ndataset-3 - Knihi.by\nSources (with kind permission by): PRASTORA.BY (https://prastora.by)\nTotal durations: 36:50:54\n","first_N":5,"first_N_keywords":["Belarusian","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"be-bel-audio-corpus","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fosters/be-bel-audio-corpus","creator_name":"Lary","creator_url":"https://huggingface.co/fosters","description":"Belarusian audio corpus.\n3 different sets under the hood.\n\ndataset_1 - –õ—é–¥–∑—ñ –Ω–∞ –±–∞–ª–æ—Ü–µ\nCorresponded text https://knihi.com/Ivan_Mielez/Ludzi_na_balocie.html\nTotal duration: 13:42:04\n\ndataset_2 - Donar.by\nTotal duration: 37h 5m 34s\n\ndataset-3 - Knihi.by\nSources (with kind permission by): PRASTORA.BY (https://prastora.by)\nTotal durations: 36:50:54\n","first_N":5,"first_N_keywords":["Belarusian","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Seed-VC_app","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chunping-vi/Seed-VC_app","creator_name":"ruan chunping","creator_url":"https://huggingface.co/chunping-vi","description":"Check out the configuration reference at https://huggingface.co/docs/hub/spaces-config-reference\n","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"laion-audio-small","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cahya/laion-audio-small","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","description":"cahya/laion-audio-small dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"MiSide-Japanese","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AkitoP/MiSide-Japanese","creator_name":"L","creator_url":"https://huggingface.co/AkitoP","description":"AkitoP/MiSide-Japanese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Japanese","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"stst_google","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BIOSSHOT/stst_google","creator_name":"BIOSSHOT","creator_url":"https://huggingface.co/BIOSSHOT","description":"BIOSSHOT/stst_google dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","arrow","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"mlc-mlsw-melspects","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/einstein8612/mlc-mlsw-melspects","creator_name":"Joey Li","creator_url":"https://huggingface.co/einstein8612","description":"\n\t\n\t\t\n\t\tMLCommons Multilingual Spoken Words Mel-Spectograms\n\t\n\nThis dataset contains all English words from the dataset available at MLCommons (or also available on huggingface). These audio files have been processed into Mel spectrograms for downstream usage in DCNNs or similar processes.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset description\n\t\n\nThere's a total of 6624343 samples of Mel spectograms. There are a total of 38150 different words, the cls is the index of that word in alphabetical order. With every entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/einstein8612/mlc-mlsw-melspects.","first_N":5,"first_N_keywords":["zero-shot-classification","audio-classification","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"MSA_test_set","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/MSA_test_set","creator_name":"√ñmer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed MSA data based on https://huggingface.co/datasets/mozilla-foundation/common_voice_16_1.\n","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Khadijah-FA_EN-Public-Phone-Audio-Dataset","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mah92/Khadijah-FA_EN-Public-Phone-Audio-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","description":"\nText got from here. \n\nAll chinese letters be replaced with \"chinese letter\" because espeak reads them so...\n\nRemove all persian/english single alphabet as they are not read correctly(same as espeak) by my reader...\n\nReplace these chars with space, as they where not read correctly(same as espeak) :\nüî∫\n@\n/\n)\n(\n]\n[\n‚ñ™Ô∏è\nüîπÔ∏è\nüî∑\nüî∂\nüîÜ\nüìå\n‚ö´Ô∏è\n‚Ñ¢\n‚ù§\nüèÜ\n‚óâ\nüëç\nüî•\nüò±\nüëå\nüìç\n‚úàÔ∏é\n‚òÅÔ∏é\n‚ö°Ô∏è\n‚ûñ\nüçÖ\nüòÅ\nüëá\nü§©\nüò¢\nü•∞\nüòÅ\nü§Ø\nü§≤\nüëè\nüé¨\n‚úä\nüíô\nü§ù\nüòÆ\nüòé\nüòá\nüôè\nü•Ä\n‚¨áÔ∏è‚¨áÔ∏è\nüåÄ\nüñ§\nüòµ\nüçø\nüëáüèº\nü§î\nüéâ\nü•∞\n‚úÖ\nüÜî\nüòç\nü§£\nüî¥\nü™ê\nüïä \nüóì\nüá∫üá≥\n‚ú¥Ô∏è\n\n\n\nüîπÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mah92/Khadijah-FA_EN-Public-Phone-Audio-Dataset.","first_N":5,"first_N_keywords":["Persian","English","cc0-1.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"eng-kaz-rus-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/adilakimshe/eng-kaz-rus-dataset","creator_name":"Adilet Akimshe","creator_url":"https://huggingface.co/adilakimshe","description":"adilakimshe/eng-kaz-rus-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"YSSY_1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lmejias/YSSY_1","creator_name":"Luis Mejias","creator_url":"https://huggingface.co/lmejias","description":"\n\t\n\t\t\n\t\tDataset Card for ATCOSYDNEY corpus\n\t\n\n","first_N":5,"first_N_keywords":["monolingual","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"11labs-train","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/11labs-train","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"A custom training dataset for seed-vc model based on 11labs dataset.\n","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüéôÔ∏è Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüéôÔ∏è Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüéôÔ∏è Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"voice","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüéôÔ∏è Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"real-world-noise-through-zoom","keyword":"audio","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KoelLabs/real-world-noise-through-zoom","creator_name":"Koel Labs","creator_url":"https://huggingface.co/KoelLabs","description":"\n\t\n\t\t\n\t\tReal-World Noise Through Zoom (RWNTZ)\n\t\n\n\n5 different real world noise settings (bedroom, crowded room, background music, rain, road with cars)\n2 different speakers\nvarious microphone distances (6 inches, 24 inches)\n32 total samples with different phrases\nrecorded through Zoom to simulate real-world linguistic fieldwork scenarios\nmanually verified word level transcriptions\ng2p phoneme trancriptions\naudio to phoneme trancriptions with a variety of Wav2Vec2 based models\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","agpl-3.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"melodymaster-v1","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opentunes-ai/melodymaster-v1","creator_name":"Opentunes AI","creator_url":"https://huggingface.co/opentunes-ai","description":"\n\t\n\t\t\n\t\tMelodyMaster V1 Training Dataset\n\t\n\nThis dataset contains music-text pairs for fine-tuning MelodyMaster V1, an AI music generation model. Based on MusicCaps dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\n\nFile Type: Parquet\nContains music-text pairs for fine-tuning\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nyoutube_id,start_s,end_s,caption\n\n\nyoutube_id: Identifier for the audio source\nstart_s: Start time in seconds\nend_s: End time in seconds\ncaption: Text description of the music‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opentunes-ai/melodymaster-v1.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"melodymaster-v1","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opentunes-ai/melodymaster-v1","creator_name":"Opentunes AI","creator_url":"https://huggingface.co/opentunes-ai","description":"\n\t\n\t\t\n\t\tMelodyMaster V1 Training Dataset\n\t\n\nThis dataset contains music-text pairs for fine-tuning MelodyMaster V1, an AI music generation model. Based on MusicCaps dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\n\nFile Type: Parquet\nContains music-text pairs for fine-tuning\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nyoutube_id,start_s,end_s,caption\n\n\nyoutube_id: Identifier for the audio source\nstart_s: Start time in seconds\nend_s: End time in seconds\ncaption: Text description of the music‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opentunes-ai/melodymaster-v1.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"melodymaster-v1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opentunes-ai/melodymaster-v1","creator_name":"Opentunes AI","creator_url":"https://huggingface.co/opentunes-ai","description":"\n\t\n\t\t\n\t\tMelodyMaster V1 Training Dataset\n\t\n\nThis dataset contains music-text pairs for fine-tuning MelodyMaster V1, an AI music generation model. Based on MusicCaps dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\n\nFile Type: Parquet\nContains music-text pairs for fine-tuning\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nyoutube_id,start_s,end_s,caption\n\n\nyoutube_id: Identifier for the audio source\nstart_s: Start time in seconds\nend_s: End time in seconds\ncaption: Text description of the music‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opentunes-ai/melodymaster-v1.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"melodymaster-v1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opentunes-ai/melodymaster-v1","creator_name":"Opentunes AI","creator_url":"https://huggingface.co/opentunes-ai","description":"\n\t\n\t\t\n\t\tMelodyMaster V1 Training Dataset\n\t\n\nThis dataset contains music-text pairs for fine-tuning MelodyMaster V1, an AI music generation model. Based on MusicCaps dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\n\nFile Type: Parquet\nContains music-text pairs for fine-tuning\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nyoutube_id,start_s,end_s,caption\n\n\nyoutube_id: Identifier for the audio source\nstart_s: Start time in seconds\nend_s: End time in seconds\ncaption: Text description of the music‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opentunes-ai/melodymaster-v1.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"mp3s","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lanyuer/mp3s","creator_name":"chan.j.steven","creator_url":"https://huggingface.co/lanyuer","description":"lanyuer/mp3s dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"audiocaps","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Olivia714/audiocaps","creator_name":"Zijun Wang","creator_url":"https://huggingface.co/Olivia714","description":"Olivia714/audiocaps dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","csv","Audio","Tabular"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"audio-classification","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_SER_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","monolingual","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_SER_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","monolingual","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_SER_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","monolingual","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"voice","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_SER_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","monolingual","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"ACG","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abooooo/ACG","creator_name":"Jiarui Chen","creator_url":"https://huggingface.co/Abooooo","description":"Âü∫‰∫éCodecfake(AISHELL3 + VCTK)ÔºåÂàÜÂà´‰ΩøÁî®GPT-SoVITÂíåChatTTSÂêàÊàêÂØπÂ∫îÁöÑ‰º™ÈÄ†Èü≥È¢ëÔºåÁî®‰∫é‰º™ÈÄ†Èü≥È¢ëËØÜÂà´Á≠â‰ªªÂä°ÔºåÊîØÊåÅ‰∏≠ÊñáÂíåËã±Êñá„ÄÇ\n","first_N":5,"first_N_keywords":["audio-classification","Chinese","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ACG","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abooooo/ACG","creator_name":"Jiarui Chen","creator_url":"https://huggingface.co/Abooooo","description":"Âü∫‰∫éCodecfake(AISHELL3 + VCTK)ÔºåÂàÜÂà´‰ΩøÁî®GPT-SoVITÂíåChatTTSÂêàÊàêÂØπÂ∫îÁöÑ‰º™ÈÄ†Èü≥È¢ëÔºåÁî®‰∫é‰º™ÈÄ†Èü≥È¢ëËØÜÂà´Á≠â‰ªªÂä°ÔºåÊîØÊåÅ‰∏≠ÊñáÂíåËã±Êñá„ÄÇ\n","first_N":5,"first_N_keywords":["audio-classification","Chinese","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"feng-stream-data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Watsonnn/feng-stream-data","creator_name":"Lin","creator_url":"https://huggingface.co/Watsonnn","description":"Watsonnn/feng-stream-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"wolof-audio-data","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vonewman/wolof-audio-data","creator_name":"Abdoulaye Diallo","creator_url":"https://huggingface.co/vonewman","description":"\n\t\n\t\t\n\t\tWolof Audio Dataset\n\t\n\nThe Wolof Audio Dataset is a collection of audio recordings and their corresponding transcriptions in Wolof. This dataset is designed to support the development of Automatic Speech Recognition (ASR) models for the Wolof language. It was created by combining three existing datasets:\n\nALFFA: Available at serge-wilson/wolof_speech_transcription\nFLEURS: Available at vonewman/fleurs-wolof-dataset\nUrban Bus Wolof Speech Dataset: Available at vonewman/urban-bus-wolof‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vonewman/wolof-audio-data.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Wolof","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ipapack_plus_1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anyspeech/ipapack_plus_1","creator_name":"AnySpeech","creator_url":"https://huggingface.co/anyspeech","description":"anyspeech/ipapack_plus_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ipapack_plus_5","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anyspeech/ipapack_plus_5","creator_name":"AnySpeech","creator_url":"https://huggingface.co/anyspeech","description":"anyspeech/ipapack_plus_5 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai_saamgwokjinji_jyutping_crossValidated","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/zoengjyutgaai_saamgwokjinji_jyutping_crossValidated","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"hon9kon9ize/zoengjyutgaai_saamgwokjinji_jyutping_crossValidated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Deaftest_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AV-Odyssey/Deaftest_dataset","creator_name":"AV-Odyssey Bench","creator_url":"https://huggingface.co/AV-Odyssey","description":"Official Deaftest dataset for the paper \"AV-Odyssey: Can Your Multimodal LLMs Really Understand Audio-Visual Information?\".\nüåü For more details, please refer to the project page with data examples: https://av-odyssey.github.io/.\n[üåê Webpage] [üìñ Paper] [ü§ó Huggingface AV-Odyssey Dataset] [ü§ó Huggingface Deaftest Dataset] [üèÜ Leaderboard]\n\n\n\t\n\t\n\t\n\t\tüî• News\n\t\n\n\n2024.11.24 üåü We release AV-Odyssey, the first-ever comprehensive evaluation benchmark to explore whether MLLMs really understand‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AV-Odyssey/Deaftest_dataset.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Tamil","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tTamil Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Tamil monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Tamil\nTotal Duration: ~20.33 hours (Male: 10.3 hours, Female: 10.03 hours)\nAudio Format: WAV\nSampling Rate:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil.","first_N":5,"first_N_keywords":["text-to-speech","Tamil","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-231k","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-231K\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-231K is a comprehensive dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-231K is part of EMOVA-Datasets collection and is used in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"audio-classification","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"indian_songs","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yav1327/indian_songs","creator_name":"Yash Vishe","creator_url":"https://huggingface.co/yav1327","description":"yav1327/indian_songs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ASVspoofLD","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hashim19/ASVspoofLD","creator_name":"Hashim Ali","creator_url":"https://huggingface.co/hashim19","description":"========================================================================================================\nASVspoof Laundered Database: This database is based on ASVspoof 2019 logical access (LA) eval partition.\nThe Asvspoof 2019 LA eval database is passed through five different types of additive noise at three \ndifferent Signal-to-Noise ratio (SNR) levels, three types of reverberation noise, six different re-compression rates, four \ndifferent resampling factors, and one type of low pass‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hashim19/ASVspoofLD.","first_N":5,"first_N_keywords":["mit","1M - 10M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ghanaian_languages_to_english_translation_and_transcription_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theonlyamos/ghanaian_languages_to_english_translation_and_transcription_dataset","creator_name":"Amos Amissah","creator_url":"https://huggingface.co/theonlyamos","description":"theonlyamos/ghanaian_languages_to_english_translation_and_transcription_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"wargame-reddragon-unit-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/III111II1I1/wargame-reddragon-unit-audio","creator_name":"II1I1I1I1I","creator_url":"https://huggingface.co/III111II1I1","description":"War game: Red dragon‰∏≠ÂêÑÂçï‰ΩçÁöÑËØ≠Ë®ÄÔºå‰∏≠ÊñáÊàëÊ†∏ÂØπËøáÔºåÂÖ∂‰ªñËØ≠Ë®ÄÊòØwhisperËØÜÂà´ÁöÑ. ËØ≠Èü≥ÈÄöËøá https://github.com/is-consulting/moddingSuite ‰ªéÊ∏∏ÊàèÊñá‰ª∂‰∏≠ÊèêÂèñÔºåÁî±‰∫émoddingSuiteÈáåÊ≤°ÊúâÊâπÈáèÊèêÂèñÈü≥È¢ëÁöÑÂäüËÉΩÔºåÊàëÂèà‰∏ç‰ºöÊîπC#ÔºåÊâÄ‰ª•ÊàëÁøªËØë‰∫Ü‰∏™pythonËÑöÊú¨ËΩ¨Êñá‰ª∂Ê†ºÂºè https://github.com/II11ll/moddingSuite-ess-py\n","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Serer","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/taiyintaiyang/Serer","creator_name":"Andy Hou","creator_url":"https://huggingface.co/taiyintaiyang","description":"taiyintaiyang/Serer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tts_281124","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Irathernotsay/tts_281124","creator_name":"Shobhit Sharma","creator_url":"https://huggingface.co/Irathernotsay","description":"Irathernotsay/tts_281124 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"OOGABOOGA","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eduhk-lin3046/OOGABOOGA","creator_name":"EdUHK LIN3046 Language Information Management","creator_url":"https://huggingface.co/eduhk-lin3046","description":"eduhk-lin3046/OOGABOOGA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"nba_dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kennethzhang/nba_dataset","creator_name":"Kenneth Chandra","creator_url":"https://huggingface.co/kennethzhang","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kennethzhang/nba_dataset.","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"elevenlabs-0.9test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WpythonW/elevenlabs-0.9test","creator_name":"Andrew","creator_url":"https://huggingface.co/WpythonW","description":"WpythonW/elevenlabs-0.9test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"region2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/san457/region2","creator_name":"Sanskar Singh ","creator_url":"https://huggingface.co/san457","description":"san457/region2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"youtube_audio_samples2","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hanifa-fy/youtube_audio_samples2","creator_name":"Hanifa Fakhriza Yaroh","creator_url":"https://huggingface.co/hanifa-fy","description":"hanifa-fy/youtube_audio_samples2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["afl-3.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"QuEsT","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VoiceProfiler/QuEsT","creator_name":"Alex Chung","creator_url":"https://huggingface.co/VoiceProfiler","description":"\n\t\n\t\t\n\t\tDataset Card for QuEsT\n\t\n\n\n\nThe Quechua Spanish Translations dataset (QuEsT) is a language pair dataset of quechua sentences and its translations to spanish.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe QuEsT Dataset is conformed of two subsets: train and test. In this section we are going to refer as dataset to the train subset only.\nThe dataset consists of pairs of audios and their transcriptions in the languages of Quechua Cuzco (quz) and Spanish (spa), each pair‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VoiceProfiler/QuEsT.","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"big_bench_audio","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArtificialAnalysis/big_bench_audio","creator_name":"Artificial Analysis","creator_url":"https://huggingface.co/ArtificialAnalysis","description":"\n\t\n\t\t\n\t\tArtificial Analysis Big Bench Audio\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBig Bench Audio is an audio version of a subset of Big Bench Hard questions. The dataset can be used for evaluating the reasoning capabilities of models that support audio input.\nThe dataset includes 1000 audio recordings for all questions from the following Big Bench Hard categories. Descriptions are taken from Suzgun et al. (2022):\n\nFormal Fallacies Syllogisms Negation (Formal Fallacies) - 250 questions\nGiven a context‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArtificialAnalysis/big_bench_audio.","first_N":5,"first_N_keywords":["audio-to-audio","English","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"big_bench_audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ArtificialAnalysis/big_bench_audio","creator_name":"Artificial Analysis","creator_url":"https://huggingface.co/ArtificialAnalysis","description":"\n\t\n\t\t\n\t\tArtificial Analysis Big Bench Audio\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBig Bench Audio is an audio version of a subset of Big Bench Hard questions. The dataset can be used for evaluating the reasoning capabilities of models that support audio input.\nThe dataset includes 1000 audio recordings for all questions from the following Big Bench Hard categories. Descriptions are taken from Suzgun et al. (2022):\n\nFormal Fallacies Syllogisms Negation (Formal Fallacies) - 250 questions\nGiven a context‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArtificialAnalysis/big_bench_audio.","first_N":5,"first_N_keywords":["audio-to-audio","English","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"emova-alignment-7m","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-Alignment-7M\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-Alignment-7M is a comprehensive dataset curated for omni-modal pre-training, including vision-language and speech-language alignment. \nThis dataset is created using open-sourced image-text pre-training datasets, OCR datasets, and 2,000 hours of ASR and TTS data. \nThis dataset is part of the EMOVA-Datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"Lyra-Eval","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zszhong/Lyra-Eval","creator_name":"Zhisheng Zhong","creator_url":"https://huggingface.co/zszhong","description":"zszhong/Lyra-Eval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Vocal-burst","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/Vocal-burst","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"A dataset all about vocal-bursts. to reconstruct the zip file use this command\ncat vocal-burst_part_* > vocal-burst.zip\n\n\n\t\n\t\t\n\t\tA few stats:\n\t\n\nTraining samples: 355,452\nMetadata: Yes, included!\nEach audio snippet duration: 8 seconds\nExamples Provided: Yes, 4 example audio is provdied. \n","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"common-voice-tamil-english-labeled-Data-v2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lingalingeswaran/common-voice-tamil-english-labeled-Data-v2","creator_name":"Sathiyalokeswaran","creator_url":"https://huggingface.co/Lingalingeswaran","description":"Lingalingeswaran/common-voice-tamil-english-labeled-Data-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Tamil","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"enhanced-vocal-burst","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/enhanced-vocal-burst","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"sleeping-ai/enhanced-vocal-burst dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"common_voice_tamil_english-labeled-Data-filtered-v4","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lingalingeswaran/common_voice_tamil_english-labeled-Data-filtered-v4","creator_name":"Sathiyalokeswaran","creator_url":"https://huggingface.co/Lingalingeswaran","description":"Lingalingeswaran/common_voice_tamil_english-labeled-Data-filtered-v4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","Tamil","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"commonvoice-12.0-arabic-voice-converted","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted","creator_name":"Modar M. Alfadly","creator_url":"https://huggingface.co/xmodar","description":"\n\t\n\t\t\n\t\tDataset Card for Voice Converted Arabic Common Voice 12.0\n\t\n\nThis dataset is derived from the Common Voice Arabic Corpus 12.0 and includes automatically diacritized transcriptions and phoneme representations for the original augmented audio data. The recordings feature Arabic text read aloud by users, where the text was initially undiacritized, allowing for potential reading errors. The diacritization and phonemes were generated automatically, resulting in a dataset that is valuable‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"DVOICEv1.1-Darija","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/DVOICEv1.1-Darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"Dialectal Voice is a community project initiated by AIOX Labs to facilitate voice recognition by Intelligent Systems. Today, the need for AI systems capable of recognizing the human voice is increasingly expressed within communities. However, we note that for some languages such as Darija, there are not enough voice technology solutions. To meet this need, we then proposed to establish this program of iterative and interactive construction of a dialectal database open to all in order to help‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/DVOICEv1.1-Darija.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"darija-speech-to-text","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/darija-speech-to-text","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"\n\t\n\t\t\n\t\tSpeech To Text Darija dataset\n\t\n\nReupload of adiren7/darija_speech_to_text\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","apache-2.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"laion-audio-preview-split","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/krishnakalyan3/laion-audio-preview-split","creator_name":"krishna","creator_url":"https://huggingface.co/krishnakalyan3","description":"krishnakalyan3/laion-audio-preview-split dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DisfluencySpeech-preprocessed-mms-tts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Meshwa/DisfluencySpeech-preprocessed-mms-tts","creator_name":"Meshwa Patel","creator_url":"https://huggingface.co/Meshwa","description":"Meshwa/DisfluencySpeech-preprocessed-mms-tts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ali-meetings","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argmaxinc/ali-meetings","creator_name":"Argmax","creator_url":"https://huggingface.co/argmaxinc","description":"argmaxinc/ali-meetings dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"tamil","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sp03/tamil","creator_name":"sethu prasad s","creator_url":"https://huggingface.co/sp03","description":"\n\t\n\t\t\n\t\tMy Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains audio recordings with corresponding text transcriptions. It is designed for speech recognition and natural language processing tasks.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\ndata/audio/: Contains audio files.\nmetadata.csv: Metadata file with transcription and additional information.\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\n[Your License Name] - [License URL]\n\n\t\n\t\t\n\t\tCitation\n\t\n\nPlease cite this dataset as follows:\n","first_N":5,"first_N_keywords":["Tamil","cc0-1.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"MMAudio-precomputed-results","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkchengrex/MMAudio-precomputed-results","creator_name":"Ho Kei Cheng","creator_url":"https://huggingface.co/hkchengrex","description":"\n\t\n\t\t\n\t\tPrecomputed results for MMAudio\n\t\n\nResults from four model variants of MMAudio. \nAll results are in the .flac format with lossless compression.\nA cache folder contains the feature caches computed by the evaluation script.\nCode: https://github.com/hkchengrex/MMAudio\nEvaluation: https://github.com/hkchengrex/av-benchmark\n\n\t\n\t\t\n\t\n\t\n\t\tVGGSound\n\t\n\nContains the VGGSound test set results. There are 15220 videos, collected with our best effort. Not all videos in the test sets are available‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hkchengrex/MMAudio-precomputed-results.","first_N":5,"first_N_keywords":["mit","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"laions_got_talent_preview","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/laions_got_talent_preview","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"laion/laions_got_talent_preview dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"LastFM_120K","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/takarajordan/LastFM_120K","creator_name":"Jordan Legg","creator_url":"https://huggingface.co/takarajordan","description":"\n\t\n\t\t\n\t\tLast.fm Dataset 2020 (Parquet Edition)\n\t\n\nA consolidated version of the Last.fm Dataset optimized for music auto-tagging classification tasks, containing 122,877 tracks with 100 binary-encoded tags and associated metadata (Last.fm URLs, Spotify preview URLs).\nBased on Rene Semela's original work (https://github.com/renesemela/lastfm-dataset-2020).\nMIT License\n","first_N":5,"first_N_keywords":["audio-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Mongolian_number_1-10","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Otgonbaatar/Mongolian_number_1-10","creator_name":"Otgonbaatar","creator_url":"https://huggingface.co/Otgonbaatar","description":"Otgonbaatar/Mongolian_number_1-10 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"English_lyrics","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Wayne577/English_lyrics","creator_name":"zz","creator_url":"https://huggingface.co/Wayne577","description":"Wayne577/English_lyrics dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"wavepulse-radio-raw-transcripts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-raw-transcripts","creator_name":"NYU DICE Lab","creator_url":"https://huggingface.co/nyu-dice-lab","description":"\n\t\n\t\t\n\t\tWavePulse Radio Raw Transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWavePulse Radio Raw Transcripts is a large-scale dataset containing segment-level transcripts from 396 radio stations across the United States, collected between June 26, 2024, and Dec 29th, 2024. The dataset comprises >250 million text segments derived from 750,000+ hours of radio broadcasts, primarily covering news, talk shows, and political discussions.\nThe summarized version of these transcripts is available here. For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyu-dice-lab/wavepulse-radio-raw-transcripts.","first_N":5,"first_N_keywords":["text-generation","text-classification","news-articles-summarization","topic-classification","sentiment-analysis"],"keywords_longer_than_N":true},
	{"name":"commonvoice_17_tr_fixed","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ysdede/commonvoice_17_tr_fixed","creator_name":"Yunus Dede","creator_url":"https://huggingface.co/ysdede","description":"\n\t\n\t\t\n\t\tImproving CommonVoice 17 Turkish Dataset\n\t\n\nI recently worked on enhancing the Mozilla CommonVoice 17 Turkish dataset to create a higher quality training set for speech recognition models.Here's an overview of my process and findings.\n\n\t\n\t\t\n\t\tInitial Analysis and Split Organization\n\t\n\nMy first step was analyzing the dataset organization to understand its structure.Through analysis of filename stems as unique keys, I revealed and documented an important aspect of CommonVoice's design‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ysdede/commonvoice_17_tr_fixed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"StethoText","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neilshahnms/StethoText","creator_name":"Neil Shah","creator_url":"https://huggingface.co/neilshahnms","description":"neilshahnms/StethoText dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"SPIRE_EMA_CORPUS","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SpireLab/SPIRE_EMA_CORPUS","creator_name":"SPIRE LAB","creator_url":"https://huggingface.co/SpireLab","description":"This corpus contains paired data of speech, articulatory movements and phonemes. There are 38 speakers in the corpus, each with 460 utterances.\nThe raw audio files are in audios.zip. The ema data and preprocessed data is stored in processed.zip. The processed data can be loaded with pytorch and has the following keys - \n\nema_raw : The raw ema data\n\nema_clipped : The ema data after trimming using being-end time stamps\n\nema_trimmed_and_normalised_with_6_articulators: The ema data after trimming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SpireLab/SPIRE_EMA_CORPUS.","first_N":5,"first_N_keywords":["cc-by-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"laion-audio-tiny","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cahya/laion-audio-tiny","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","description":"cahya/laion-audio-tiny dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"CBU0521DD_stories_expanded","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hunterhere/CBU0521DD_stories_expanded","creator_name":"HunterRong","creator_url":"https://huggingface.co/Hunterhere","description":"This project is for CBU5201 coursework under BUPT & QM joint programme.We constructed a dataset that told either a true story or a false story, in a mix of Chinese and English, with a total of 100 audio pieces.And data augmentation is applied on it preparing to afterwards training.More datails please refer to github https://github.com/Hunterhere/CBU5201_miniproject  \n","first_N":5,"first_N_keywords":["audio-classification","Chinese","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"CBU0521DD_stories_expanded","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hunterhere/CBU0521DD_stories_expanded","creator_name":"HunterRong","creator_url":"https://huggingface.co/Hunterhere","description":"This project is for CBU5201 coursework under BUPT & QM joint programme.We constructed a dataset that told either a true story or a false story, in a mix of Chinese and English, with a total of 100 audio pieces.And data augmentation is applied on it preparing to afterwards training.More datails please refer to github https://github.com/Hunterhere/CBU5201_miniproject  \n","first_N":5,"first_N_keywords":["audio-classification","Chinese","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"hugo_parler","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rcarvalo/hugo_parler","creator_name":"Carvalot","creator_url":"https://huggingface.co/Rcarvalo","description":"Rcarvalo/hugo_parler dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"luquet4","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Zakrom/luquet4","creator_name":"rom","creator_url":"https://huggingface.co/Zakrom","description":"Zakrom/luquet4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"synthetic_vocal_bursts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/synthetic_vocal_bursts","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"This repository contains the vocal bursts like giggling, laughter, shouting, crying, etc. from the following repository.\nhttps://huggingface.co/datasets/sleeping-ai/Vocal-burst\nWe captioned them using Gemini Flash Audio 2.0. This dataset contains, this dataset contains ~ 365,000 vocal bursts from all kinds of categories. \nIt might be helpful for pre-training audio text foundation models to generate and understand all kinds of nuances in vocal bursts.\n \n","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"elevenlabs_multilingual_v2-technical-speech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WpythonW/elevenlabs_multilingual_v2-technical-speech","creator_name":"Andrew","creator_url":"https://huggingface.co/WpythonW","description":"\n\t\n\t\t\n\t\tElevenLabs Multilingual V2 Technical Speech Dataset\n\t\n\nThis dataset contains automatically generated technical phrases in three domains, converted to speech using the ElevenLabs Multilingual V2 model with Adam voice.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes audio samples of technical phrases across three categories:\n\nMachine Learning (ML)\nScience\nTechnology\n\nEach entry contains:\n\nAudio file in MP3 format (22050Hz)\nSource text\nText length\nCategory label\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WpythonW/elevenlabs_multilingual_v2-technical-speech.","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"stst","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BIOSSHOT/stst","creator_name":"BIOSSHOT","creator_url":"https://huggingface.co/BIOSSHOT","description":"BIOSSHOT/stst dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"BEAT","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-Liu1997/BEAT","creator_name":"Haiyang Liu","creator_url":"https://huggingface.co/H-Liu1997","description":"H-Liu1997/BEAT dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"english_accent","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kennethzhang/english_accent","creator_name":"Kenneth Chandra","creator_url":"https://huggingface.co/kennethzhang","description":"kennethzhang/english_accent dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"bam-asr-early","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/bam-asr-early","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Bambara-ASR-Early Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \nData sources include all publicly available collections of audio with Bambara transcriptions as of December 2024, organized for accessibility and usability.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"bam-asr-early","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/bam-asr-early","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Bambara-ASR-Early Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \nData sources include all publicly available collections of audio with Bambara transcriptions as of December 2024, organized for accessibility and usability.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"picovoice-wake-word-benchmark","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark","creator_name":"Adam Jones","creator_url":"https://huggingface.co/domdomegg","description":"\n\t\n\t\t\n\t\tPicovoice Wake Word Benchmark Dataset\n\t\n\nThis dataset contains a collection of wake word recordings used for benchmarking wake word detection systems. The dataset has been reformatted from the original Picovoice Wake Word Benchmark repository for easier use with Hugging Face's ecosystem.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains over 300 recordings of six different wake words from more than 50 distinct speakers. These recordings were originally used to benchmark different‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"picovoice-wake-word-benchmark","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark","creator_name":"Adam Jones","creator_url":"https://huggingface.co/domdomegg","description":"\n\t\n\t\t\n\t\tPicovoice Wake Word Benchmark Dataset\n\t\n\nThis dataset contains a collection of wake word recordings used for benchmarking wake word detection systems. The dataset has been reformatted from the original Picovoice Wake Word Benchmark repository for easier use with Hugging Face's ecosystem.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains over 300 recordings of six different wake words from more than 50 distinct speakers. These recordings were originally used to benchmark different‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"emo-small","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cahya/emo-small","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","description":"cahya/emo-small dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"corpus-siarad-test-set","keyword":"audio","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/corpus-siarad-test-set","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"wanasash/corpus-siarad-test-set dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["gpl-3.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"nature_sound_generation","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Stoned-Code/nature_sound_generation","creator_name":"Javin Tanoue","creator_url":"https://huggingface.co/Stoned-Code","description":"A dataset from downloaded youtube videos of nature sounds. Each audio clip is two seconds long.\n","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"tts_2301","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/tts_2301","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/tts_2301 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"whisper-large-v2-ec-eval-ec","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/whisper-large-v2-ec-eval-ec","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"Model: wanasash/whisper-large-v2-ec\nTest Set: wanasash/enwaucymraeg\nSplit: test\n\nWER: 27.899957\nCER: 8.233039\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"whisper-large-v2-eval-ec","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/whisper-large-v2-eval-ec","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"Model: openai/whisper-large-v2\nTest Set: wanasash/enwaucymraeg\nSplit: test\n\nWER: 46.959897\nCER: 17.439632\n","first_N":5,"first_N_keywords":["Welsh","cc0-1.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Sidney_ptbr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HenryEngels/Sidney_ptbr","creator_name":"Henry Engels de Aguiar","creator_url":"https://huggingface.co/HenryEngels","description":"HenryEngels/Sidney_ptbr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"hamner","keyword":"audio","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hackersgame/hamner","creator_name":"David Hamner","creator_url":"https://huggingface.co/hackersgame","description":"hackersgame/hamner dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["agpl-3.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Trash","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jinsaryko/Trash","creator_name":"Ty Jones","creator_url":"https://huggingface.co/Jinsaryko","description":"Jinsaryko/Trash dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"cvss-c-dataset","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bismarck91/cvss-c-dataset","creator_name":"Bismarck Bamfo Odoom","creator_url":"https://huggingface.co/bismarck91","description":"bismarck91/cvss-c-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","100K - 1M","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"new_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/new_dataset","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/new_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DVOICEv2.0-Darija","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/DVOICEv2.0-Darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"DVoice is a community initiative that aims to provide African languages and dialects with data and models to facilitate their use of voice technologies. The lack of data on these languages makes it necessary to collect data using methods that are specific to each language. Two different approaches are currently used: the DVoice platform, which is based on Mozilla Common Voice, for collecting authentic recordings from the community, and transfer learning techniques for automatically labeling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/DVOICEv2.0-Darija.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"earnings21","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argmaxinc/earnings21","creator_name":"Argmax","creator_url":"https://huggingface.co/argmaxinc","description":"argmaxinc/earnings21 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-eval","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-Eval\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-Eval is an evaluation dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-Eval is part of EMOVA-Datasets collection, and the training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"YorubaTTS2","keyword":"audio","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vadewumi/YorubaTTS2","creator_name":"Victor Olufemi Adewumi","creator_url":"https://huggingface.co/vadewumi","description":"vadewumi/YorubaTTS2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Yoruba","afl-3.0","< 1K","text","Audio"],"keywords_longer_than_N":true},
	{"name":"wikitongues-darija","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/wikitongues-darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"\n\t\n\t\t\n\t\tWikitongues-Darija\n\t\n\nThis is a small test dataset for Automatic Speech Recognition in Darija language, built from 2 captioned videos of the WikiTongues project:\n\nnawal\nanass\n\nProcess:\n\neach webm video has been converted to monochannel 16khz wav files with ffmpeg :\n\nffmpeg -i WIKITONGUES-_Nawal_speaking_Moroccan_Arabic.webm.1080p.vp9.webm -ar 16000 -ac 1 nawal.wav\n\n\neach audio has been cut in samples of less than 30 seconds audio according to the captions timestamps. The script may be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/wikitongues-darija.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc-by-sa-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"bambara-speech-recognition-leaderboard","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MALIBA-AI/bambara-speech-recognition-leaderboard","creator_name":"MALIBA-AI","creator_url":"https://huggingface.co/MALIBA-AI","description":"MALIBA-AI/bambara-speech-recognition-leaderboard dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"sefon","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/01gumano1d/sefon","creator_name":"gumano1d","creator_url":"https://huggingface.co/01gumano1d","description":"01gumano1d/sefon dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Audio-Children-Stories-Collection","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Audio-Children-Stories-Collection","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Audio Chidren Stories Collection\nThis dataset has 600 audio files in .mp3 format. This has been created using my existing dataset Children-Stories-Collection.\nI have used only first 600 stories for creating this audio dataset.\nYou can use this for training and research purpose.\nThank you for your love & support.\n","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Audio-Children-Stories-Collection","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Audio-Children-Stories-Collection","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Audio Chidren Stories Collection\nThis dataset has 600 audio files in .mp3 format. This has been created using my existing dataset Children-Stories-Collection.\nI have used only first 600 stories for creating this audio dataset.\nYou can use this for training and research purpose.\nThank you for your love & support.\n","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-for-asr","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-for-asr","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset for ASR\n\t\n\nThis dataset is a comprehensive collection of Myanmar language speech data specifically curated for Automatic Speech Recognition (ASR) task. It combines following datasets:\n\nMyanmar Speech Dataset (Google Fleurs)\nMyanmar Speech Dataset (OpenSLR-80)\n\nBy merging these complementary resources, this dataset provides a more robust foundation for training and evaluating ASR models for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-for-asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"hal9000","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cgb/hal9000","creator_name":"cody berlin","creator_url":"https://huggingface.co/cgb","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a speech dataset containing audio recordings with their transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\naudio: The audio file\ntext: The transcription of the audio\naudio_id: Unique identifier for the audio file\n\n","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"creole-text-voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jsbeaudry/creole-text-voice","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","description":"jsbeaudry/creole-text-voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_zh","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minghanw/sdf_dataset_zh","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_zh.","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_zh","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minghanw/sdf_dataset_zh","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_zh.","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"LAION's Got Talent: Generated Voice Acting Dataset\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\"LAION's Got Talent\" is a synthetic voice acting dataset designed to offer a broad range of emotional expressions, vocal bursts, and multi-language utterances. This dataset is a component of the BUD-E project, led by LAION with support from Intel, and aims to drive forward research in context-aware and empathetic AI voice assistants.\n\n\n\t\n\t\t\n\t\tUpdated Composition\n\t\n\n\nVoices and Languages  \n\nEnglish: 11 OpenAI voices, each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning.","first_N":5,"first_N_keywords":["English","French","German","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","keyword":"voice","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"LAION's Got Talent: Generated Voice Acting Dataset\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\"LAION's Got Talent\" is a synthetic voice acting dataset designed to offer a broad range of emotional expressions, vocal bursts, and multi-language utterances. This dataset is a component of the BUD-E project, led by LAION with support from Intel, and aims to drive forward research in context-aware and empathetic AI voice assistants.\n\n\n\t\n\t\t\n\t\tUpdated Composition\n\t\n\n\nVoices and Languages  \n\nEnglish: 11 OpenAI voices, each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning.","first_N":5,"first_N_keywords":["English","French","German","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"MSMarco-ES-TTS-Big95.1ksamples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ejbejaranos/MSMarco-ES-TTS-Big95.1ksamples","creator_name":"Edison Bejarano Sepulveda","creator_url":"https://huggingface.co/ejbejaranos","description":"\n\t\n\t\t\n\t\tMSMarco-ES-TTS-Big95.1ksamples üéôÔ∏èüìñ\n\t\n\n\nExtensi√≥n del dataset ejbejaranos/MSMarco-ES-TTS-small4.5ksamples que contiene 95,108 muestras adicionales de pares pregunta-respuesta en espa√±ol convertidos a audio mediante s√≠ntesis de voz (TTS). Los samples son distintos a los de la versi√≥n anterior, por lo que pueden usarse como extensi√≥n.\n\n\t\n\t\t\n\t\n\t\n\t\tüîç Vista r√°pida\n\t\n\n\n  \n\n\n\n\t\n\t\n\t\n\t\tüéß Demostraci√≥n de audio\n\t\n\nAudio de instrucci√≥n (pregunta):\n\n  Tu navegador no soporta audio HTML5.\n\nAudio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ejbejaranos/MSMarco-ES-TTS-Big95.1ksamples.","first_N":5,"first_N_keywords":["question-answering","Spanish","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MSMarco-ES-TTS-Big95.1ksamples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ejbejaranos/MSMarco-ES-TTS-Big95.1ksamples","creator_name":"Edison Bejarano Sepulveda","creator_url":"https://huggingface.co/ejbejaranos","description":"\n\t\n\t\t\n\t\tMSMarco-ES-TTS-Big95.1ksamples üéôÔ∏èüìñ\n\t\n\n\nExtensi√≥n del dataset ejbejaranos/MSMarco-ES-TTS-small4.5ksamples que contiene 95,108 muestras adicionales de pares pregunta-respuesta en espa√±ol convertidos a audio mediante s√≠ntesis de voz (TTS). Los samples son distintos a los de la versi√≥n anterior, por lo que pueden usarse como extensi√≥n.\n\n\t\n\t\t\n\t\n\t\n\t\tüîç Vista r√°pida\n\t\n\n\n  \n\n\n\n\t\n\t\n\t\n\t\tüéß Demostraci√≥n de audio\n\t\n\nAudio de instrucci√≥n (pregunta):\n\n  Tu navegador no soporta audio HTML5.\n\nAudio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ejbejaranos/MSMarco-ES-TTS-Big95.1ksamples.","first_N":5,"first_N_keywords":["question-answering","Spanish","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"swahili-tts-dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jacksonwambali/swahili-tts-dataset","creator_name":"Jackson Wambali","creator_url":"https://huggingface.co/jacksonwambali","description":"\n\t\n\t\t\n\t\tSwahili TTS Dataset\n\t\n\nThis dataset contains 10 Swahili audio clips with corresponding transcripts, used to train a Text-to-Speech (TTS) model using Coqui TTS.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nwavs/: Contains WAV audio files (One.wav to Ten.wav).\nmetadata.csv: Contains the following columns:\nfile_name: Name of the audio file.\naudio_path: Path to the audio file.\ntranscript: Swahili transcript of the audio.\nduration: Duration of the audio in seconds.\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nThis dataset can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jacksonwambali/swahili-tts-dataset.","first_N":5,"first_N_keywords":["Swahili","cc-by-4.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"swahili-tts-dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jacksonwambali/swahili-tts-dataset","creator_name":"Jackson Wambali","creator_url":"https://huggingface.co/jacksonwambali","description":"\n\t\n\t\t\n\t\tSwahili TTS Dataset\n\t\n\nThis dataset contains 10 Swahili audio clips with corresponding transcripts, used to train a Text-to-Speech (TTS) model using Coqui TTS.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nwavs/: Contains WAV audio files (One.wav to Ten.wav).\nmetadata.csv: Contains the following columns:\nfile_name: Name of the audio file.\naudio_path: Path to the audio file.\ntranscript: Swahili transcript of the audio.\nduration: Duration of the audio in seconds.\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nThis dataset can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jacksonwambali/swahili-tts-dataset.","first_N":5,"first_N_keywords":["Swahili","cc-by-4.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"samples","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GAS17/samples","creator_name":"gasgas","creator_url":"https://huggingface.co/GAS17","description":"GAS17/samples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"MultiFoley-VGGSound-Test-Audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/czyang/MultiFoley-VGGSound-Test-Audio","creator_name":"Ziyang Chen","creator_url":"https://huggingface.co/czyang","description":"\n\t\n\t\t\n\t\tVideo-Guided Foley Sound Generation with Multimodal Controls\n\t\n\nPaper & Project page\nThis dataset contains the generated results of our MultiFoley work on the filtered VGGSound test cases. We generate 4 samples for each 8s video (we use the first 8s video for evaluation).\nThe results are generated with both silent video inputs and text inputs (we use the VGGSound category name for simplicity).\nEach wave file is named in the format of {category_name}/{u_id}_{start_time}_{idx}.wav, where‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/czyang/MultiFoley-VGGSound-Test-Audio.","first_N":5,"first_N_keywords":["mit","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"multimodal-genshin-impact","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/multimodal-genshin-impact","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\n\t\n\t\t\n\t\tGenshin Impact Fandom Wiki Multimodal Dataset\n\t\n\nGithub repo here\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset is a comprehensive collection of 22,162 fandom wiki pages for the popular game Genshin Impact.\nThe dataset includes markdown-formatted English content from the wiki, featuring interleaved text, as well as image, video, and audio file links. Additionally, the associated multimodal files (images, videos, and audio) have been downloaded and organized to facilitate the multimodal dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/multimodal-genshin-impact.","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","10K<n<100K","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"Indic_parler_tts_testing_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickfuryavg/Indic_parler_tts_testing_dataset","creator_name":"Sandipan Ray","creator_url":"https://huggingface.co/nickfuryavg","description":"nickfuryavg/Indic_parler_tts_testing_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Audio_quality_testing","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickfuryavg/Audio_quality_testing","creator_name":"Sandipan Ray","creator_url":"https://huggingface.co/nickfuryavg","description":"nickfuryavg/Audio_quality_testing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TOSD","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tamazight-NLP/TOSD","creator_name":"Tamazight NLP","creator_url":"https://huggingface.co/Tamazight-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Tamazight Open Speech Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tamazight-NLP/TOSD.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Standard Moroccan Tamazight","ber","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Vietnamese-Voice","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thaihoa/Vietnamese-Voice","creator_name":"Th√°i H√≤a Nguy·ªÖn","creator_url":"https://huggingface.co/Thaihoa","description":"Thaihoa/Vietnamese-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Vietnamese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"nutshell","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maikezu/nutshell","creator_name":"Maike Z√ºfle","creator_url":"https://huggingface.co/maikezu","description":"\n\t\n\t\t\n\t\tNUTSHELL: A Dataset for Abstract Generation from Scientific Talks\n\t\n\nScientific communication is receiving increasing attention in natural language processing, especially to help researches access, summarize, and generate content. \nOne emerging application in this area is Speech-to-Abstract Generation (SAG), which aims to automatically generate abstracts from recorded scientific presentations. \nSAG enables researchers to efficiently engage with conference talks, but progress has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maikezu/nutshell.","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"nutshell","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maikezu/nutshell","creator_name":"Maike Z√ºfle","creator_url":"https://huggingface.co/maikezu","description":"\n\t\n\t\t\n\t\tNUTSHELL: A Dataset for Abstract Generation from Scientific Talks\n\t\n\nScientific communication is receiving increasing attention in natural language processing, especially to help researches access, summarize, and generate content. \nOne emerging application in this area is Speech-to-Abstract Generation (SAG), which aims to automatically generate abstracts from recorded scientific presentations. \nSAG enables researchers to efficiently engage with conference talks, but progress has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maikezu/nutshell.","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"audio-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"voice-activity-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"igboaudio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ratsamm666/igboaudio","creator_name":"ratsamy pathammavong","creator_url":"https://huggingface.co/ratsamm666","description":"ratsamm666/igboaudio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"shkolkovo-bobr.video-webinars-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","description":"\n\t\n\t\t\n\t\tshkolkovo-bobr.video-webinars-audio\n\t\n\nDataset of audio of ‚âà2573 webinars from bobr.video with text transcription made with whisper and VAD. Webinars are parts of free online school exams training courses made by Shkolkovo.\nLanguage: Russian, includes some webinars on English\nDataset structure:\n\nmp3 files in format ID.mp3, where ID is webinar ID. You can check original webinar with url like bobr.video/watch/ID. Some webinars may contain multiple speakers and music.\ntxt file in format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Russian","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"shkolkovo-bobr.video-webinars-audio","keyword":"voice","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","description":"\n\t\n\t\t\n\t\tshkolkovo-bobr.video-webinars-audio\n\t\n\nDataset of audio of ‚âà2573 webinars from bobr.video with text transcription made with whisper and VAD. Webinars are parts of free online school exams training courses made by Shkolkovo.\nLanguage: Russian, includes some webinars on English\nDataset structure:\n\nmp3 files in format ID.mp3, where ID is webinar ID. You can check original webinar with url like bobr.video/watch/ID. Some webinars may contain multiple speakers and music.\ntxt file in format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Russian","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"shkolkovo-bobr.video-webinars-audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","description":"\n\t\n\t\t\n\t\tshkolkovo-bobr.video-webinars-audio\n\t\n\nDataset of audio of ‚âà2573 webinars from bobr.video with text transcription made with whisper and VAD. Webinars are parts of free online school exams training courses made by Shkolkovo.\nLanguage: Russian, includes some webinars on English\nDataset structure:\n\nmp3 files in format ID.mp3, where ID is webinar ID. You can check original webinar with url like bobr.video/watch/ID. Some webinars may contain multiple speakers and music.\ntxt file in format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Russian","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"3hr_myanmar_asr_raw_audio","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìö 3-Hour Burmese Speech Dataset from FOEIM Academy (ASR-ready)\n\t\n\nThis is a curated ~3-hour dataset of Burmese-language audio-transcript pairs derived from the official public-service educational media of FOEIM Academy, a civic platform affiliated with FOEIM.ORG.\nIt is structured for fine-grained automatic speech recognition (ASR) training and testing.All data is aligned from timestamped subtitle files (.srt) and segmented into high-quality .mp3 mono files with aligned transcripts.\n‚û°Ô∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"3hr_myanmar_asr_raw_audio","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìö 3-Hour Burmese Speech Dataset from FOEIM Academy (ASR-ready)\n\t\n\nThis is a curated ~3-hour dataset of Burmese-language audio-transcript pairs derived from the official public-service educational media of FOEIM Academy, a civic platform affiliated with FOEIM.ORG.\nIt is structured for fine-grained automatic speech recognition (ASR) training and testing.All data is aligned from timestamped subtitle files (.srt) and segmented into high-quality .mp3 mono files with aligned transcripts.\n‚û°Ô∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"3hr_myanmar_asr_raw_audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìö 3-Hour Burmese Speech Dataset from FOEIM Academy (ASR-ready)\n\t\n\nThis is a curated ~3-hour dataset of Burmese-language audio-transcript pairs derived from the official public-service educational media of FOEIM Academy, a civic platform affiliated with FOEIM.ORG.\nIt is structured for fine-grained automatic speech recognition (ASR) training and testing.All data is aligned from timestamped subtitle files (.srt) and segmented into high-quality .mp3 mono files with aligned transcripts.\n‚û°Ô∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"samples20250604","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanSounds/samples20250604","creator_name":"Sensemakers Amsterdam UrbanSounds repo","creator_url":"https://huggingface.co/UrbanSounds","description":"Samples were recorded with the audio sensor on the Marineterrein in the evening of June 4th 2025. Windforce: 3 Bft with gusts of 4 Bft / 41 km/h\n","first_N":5,"first_N_keywords":["audio-classification","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"samples20250604","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanSounds/samples20250604","creator_name":"Sensemakers Amsterdam UrbanSounds repo","creator_url":"https://huggingface.co/UrbanSounds","description":"Samples were recorded with the audio sensor on the Marineterrein in the evening of June 4th 2025. Windforce: 3 Bft with gusts of 4 Bft / 41 km/h\n","first_N":5,"first_N_keywords":["audio-classification","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"twi-words-speech-text-parallel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 413463 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 413463 audio files >‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"CUBE-MT","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/albertmeronyo/CUBE-MT","creator_name":"Albert Mero√±o Pe√±uela","creator_url":"https://huggingface.co/albertmeronyo","description":"\n\t\n\t\t\n\t\tCUBE-MT: A Cultural Benchmark for Multimodal Knowledge Graph Construction with Generative Models\n\t\n\n\nCUBE-MT (CUltural BEnchmark with Multimodal Transformations) is an extension to the CUltural BEnchmark for Text-to-Image models (CUBE). CUBE contains 300K cultural artifacts across 8 countries (Brazil, France, India, Italy, Japan, Nigeria, Turkey, and USA) and 3 domains (cuisine, landmarks, art) extracted from Wikidata; and 1K text-to-image generation prompts that enable evaluation of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/albertmeronyo/CUBE-MT.","first_N":5,"first_N_keywords":["translation","English","cc-by-4.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"TST_Output_DatasetCombine","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/archivartaunik/TST_Output_DatasetCombine","creator_name":"vartaunik","creator_url":"https://huggingface.co/archivartaunik","description":"archivartaunik/TST_Output_DatasetCombine dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"plant-sounds","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NonSittinon/plant-sounds","creator_name":"Sittinon Yongyutwichai","creator_url":"https://huggingface.co/NonSittinon","description":"\n\t\n\t\t\n\t\tüåø Plant Sound Dataset: Dry vs Water\n\t\n\nThis dataset contains audio recordings of plant sounds in two watering conditions:\n\ndry/ ‚Äì Sounds recorded when the plant is dry or lacking water.\nwater/ ‚Äì Sounds recorded when the plant has been adequately watered.\n\nThe audio files are in .wav format, approximately 30 seconds long each.\n\n\t\n\t\t\n\t\tüìÅ Dataset Structure\n\t\n\n","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"gigaspeech2_denoise","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duyynh/gigaspeech2_denoise","creator_name":"Do Phu Duy","creator_url":"https://huggingface.co/Duyynh","description":"Duyynh/gigaspeech2_denoise dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"ga-speech-text-parallel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tGa Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 98343 parallel speech-text pairs for Ga, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Ga - gaa\nTask: Speech Recognition, Text-to-Speech\nSize: 98343 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Ga"],"keywords_longer_than_N":true},
	{"name":"115hours_pvtv_myanmar_asr","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t115 Hours PVTV Myanmar ASR\n\t\n\nThis dataset contains 156,262 audio-transcript pairs of spoken Burmese, totaling approximately 115.31 hours. The audio segments were extracted from publicly available YouTube videos published by PVTV and aligned using subtitle timestamps.\n\n\t\n\t\t\n\t\tDedication\n\t\n\nThis dataset would not exist without the persistent voices of PVTV editors, journalists, narrators, and production teams, who continue to speak to the people under difficult conditions. PVTV is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"115hours_pvtv_myanmar_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t115 Hours PVTV Myanmar ASR\n\t\n\nThis dataset contains 156,262 audio-transcript pairs of spoken Burmese, totaling approximately 115.31 hours. The audio segments were extracted from publicly available YouTube videos published by PVTV and aligned using subtitle timestamps.\n\n\t\n\t\t\n\t\tDedication\n\t\n\nThis dataset would not exist without the persistent voices of PVTV editors, journalists, narrators, and production teams, who continue to speak to the people under difficult conditions. PVTV is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"115hours_pvtv_myanmar_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t115 Hours PVTV Myanmar ASR\n\t\n\nThis dataset contains 156,262 audio-transcript pairs of spoken Burmese, totaling approximately 115.31 hours. The audio segments were extracted from publicly available YouTube videos published by PVTV and aligned using subtitle timestamps.\n\n\t\n\t\t\n\t\tDedication\n\t\n\nThis dataset would not exist without the persistent voices of PVTV editors, journalists, narrators, and production teams, who continue to speak to the people under difficult conditions. PVTV is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"NADI-2025-Sub-task-3-all","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/NADI-2025-Sub-task-3-all","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"For training and developing your models in the closed track, we provide the following datasets, which are publicly available on Hugging Face: The datasets represent a wide range of Arabic varieties and recording conditions, with over 85K training sentences in total. The datasets consist of dialectal, modern standard, classical, and code-switched Arabic speech and transcriptions. All except the Mixat and ArzEn subset are diacritized.\n\n\t\n\t\t\nDataset\nType\nDiacritized\nTrain\nDev\n\n\n\t\t\nMDASPC‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/NADI-2025-Sub-task-3-all.","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"kachin_asr_audio","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/kachin_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the first public Kachin language ASR dataset in history.\nKachin ASR Audio is a collection of speech data in the Kachin (Jinghpaw) language, sourced entirely from publicly available PVTV (People‚Äôs Voice Television) broadcasts. The dataset includes narration, interviews, and spoken reports intended to support the development of automatic speech recognition (ASR) systems for rare-resource indigenous languages in Myanmar.\nEach audio file is paired with metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/kachin_asr_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","manual","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"kachin_asr_audio","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/kachin_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the first public Kachin language ASR dataset in history.\nKachin ASR Audio is a collection of speech data in the Kachin (Jinghpaw) language, sourced entirely from publicly available PVTV (People‚Äôs Voice Television) broadcasts. The dataset includes narration, interviews, and spoken reports intended to support the development of automatic speech recognition (ASR) systems for rare-resource indigenous languages in Myanmar.\nEach audio file is paired with metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/kachin_asr_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","manual","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"IndicVoices_bengali","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/subratasarkar32/IndicVoices_bengali","creator_name":"Subrata Sarkar","creator_url":"https://huggingface.co/subratasarkar32","description":"\n\t\n\t\t\n\t\tIndicVoices_bengali\n\t\n\nThis dataset has been created from ai4bharat/IndicVoices. Since directly trying to load the dataset for bengali was not working with IndicVoices due to errors in some files, this dataset addresses those files by removing them.\nTo use this dataset with lazyloading for training speech to text models, below is sample code with wav2vec2.\nimport pandas as pd\nimport torchaudio\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import Wav2Vec2Processor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/subratasarkar32/IndicVoices_bengali.","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"SpokenVisIT","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ICTNLP/SpokenVisIT","creator_name":"Natural Language Processing Group, Institute of Computing Technology, Chinese Academy of Science","creator_url":"https://huggingface.co/ICTNLP","description":"SpokenVisIT\nSpokenVisIT is a real-world visual-speech interaction benchmark built upon VisIT-Bench, designed to evaluate the visual-grounded speech interaction capabilities of omni large multimodal models (LMMs).\nOur deepest acknowledgment goes to VisIT-Bench ‚Äî A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use ‚Äî which collects a diverse set of real-world visual instructions. SpokenVisIT builds on this foundation by converting the textual instructions into spoken‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ICTNLP/SpokenVisIT.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part001","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part001","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 1 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 1 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part001.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"FMA-music-dataset","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/calixtemayoraz/FMA-music-dataset","creator_name":"Calixte Mayoraz","creator_url":"https://huggingface.co/calixtemayoraz","description":"calixtemayoraz/FMA-music-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"FMA-music-dataset","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/calixtemayoraz/FMA-music-dataset","creator_name":"Calixte Mayoraz","creator_url":"https://huggingface.co/calixtemayoraz","description":"calixtemayoraz/FMA-music-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part003","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 3 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 3 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part004","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 4 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 4 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"arabic-tts-wav-24k","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NeoBoy/arabic-tts-wav-24k","creator_name":"Sharjeel Abid Butt","creator_url":"https://huggingface.co/NeoBoy","description":"\n\t\n\t\t\n\t\tArabic TTS WAV 24k Dataset\n\t\n\nA high-quality, open-source dataset for Arabic Text-to-Speech (TTS) research, containing paired audio and text samples from both male and female speakers. All audio is provided in 24kHz WAV format, with rich metadata and phonetic transcriptions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is designed for training and evaluating neural TTS systems in Modern Standard Arabic. It includes:\n\nAudio: Clean, studio-quality WAV files at 24,000 Hz.\nText: Original Arabic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeoBoy/arabic-tts-wav-24k.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"it_youtube_uzbek_speech_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/islomov/it_youtube_uzbek_speech_dataset","creator_name":"Sardor Islomov","creator_url":"https://huggingface.co/islomov","description":"\n\t\n\t\t\n\t\tIT Uzbek Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio clips and their corresponding transcriptions in the Uzbek language and with some english to better generalization. The data was collected from publicly available videos on YouTube related to the Information Technology (IT) field. It is designed for training and evaluating Automatic Speech Recognition (ASR) models.\nMost of the content comes from the Mohir Dev YouTube channel (respect to the team for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/islomov/it_youtube_uzbek_speech_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"podcasts_tashkent_dialect_youtube_uzbek_speech_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/islomov/podcasts_tashkent_dialect_youtube_uzbek_speech_dataset","creator_name":"Sardor Islomov","creator_url":"https://huggingface.co/islomov","description":"\n\t\n\t\t\n\t\tTashkent dialect focused podcasts youtube uzbek speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio clips and their corresponding transcriptions in the Uzbek language with mostly tashkent dialects. The data was collected from publicly available podcast videos on YouTube. It is designed for training and evaluating Automatic Speech Recognition (ASR) models.\nMost of the content comes from the Jahongir Latipov interviews and Bu podcast (respect authors) YouTube videos. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/islomov/podcasts_tashkent_dialect_youtube_uzbek_speech_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Seamless_Dummy_Dataset_Fixed","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rajjanardhan00/Seamless_Dummy_Dataset_Fixed","creator_name":"Raj Janardhan","creator_url":"https://huggingface.co/rajjanardhan00","description":"\n\t\n\t\t\n\t\tMMLU-Pro json\n\t\n\nThis is a reupload of MMLU-Pro in json format. Please, refer to the original dataset for details.\n","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","Audio"],"keywords_longer_than_N":true},
	{"name":"arabic_myanmar_quran_voices","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìñ Arabic-Myanmar Quran Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tüïå Overview\n\t\n\nThis dataset contains high-quality MP3 audio recordings of the entire Holy Qur‚Äôan with:\n\nArabic recitation of each verse\nFollowed immediately by its Myanmar (Burmese) translation\n\nIt is the first complete Arabic-Myanmar Quran audio interpretation of its kind publicly released in Myanmar. The goal is to make the Qur‚Äôan more accessible to:\n\nElderly persons\nBlind or visually impaired people\nMyanmar speakers who wish to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","automatic-speech-recognition","text-to-speech","human-annotated"],"keywords_longer_than_N":true},
	{"name":"arabic_myanmar_quran_voices","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìñ Arabic-Myanmar Quran Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tüïå Overview\n\t\n\nThis dataset contains high-quality MP3 audio recordings of the entire Holy Qur‚Äôan with:\n\nArabic recitation of each verse\nFollowed immediately by its Myanmar (Burmese) translation\n\nIt is the first complete Arabic-Myanmar Quran audio interpretation of its kind publicly released in Myanmar. The goal is to make the Qur‚Äôan more accessible to:\n\nElderly persons\nBlind or visually impaired people\nMyanmar speakers who wish to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","automatic-speech-recognition","text-to-speech","human-annotated"],"keywords_longer_than_N":true},
	{"name":"arabic_myanmar_quran_voices","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìñ Arabic-Myanmar Quran Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tüïå Overview\n\t\n\nThis dataset contains high-quality MP3 audio recordings of the entire Holy Qur‚Äôan with:\n\nArabic recitation of each verse\nFollowed immediately by its Myanmar (Burmese) translation\n\nIt is the first complete Arabic-Myanmar Quran audio interpretation of its kind publicly released in Myanmar. The goal is to make the Qur‚Äôan more accessible to:\n\nElderly persons\nBlind or visually impaired people\nMyanmar speakers who wish to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","automatic-speech-recognition","text-to-speech","human-annotated"],"keywords_longer_than_N":true},
	{"name":"arabic_myanmar_quran_voices","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìñ Arabic-Myanmar Quran Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tüïå Overview\n\t\n\nThis dataset contains high-quality MP3 audio recordings of the entire Holy Qur‚Äôan with:\n\nArabic recitation of each verse\nFollowed immediately by its Myanmar (Burmese) translation\n\nIt is the first complete Arabic-Myanmar Quran audio interpretation of its kind publicly released in Myanmar. The goal is to make the Qur‚Äôan more accessible to:\n\nElderly persons\nBlind or visually impaired people\nMyanmar speakers who wish to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","automatic-speech-recognition","text-to-speech","human-annotated"],"keywords_longer_than_N":true},
	{"name":"BSP-S4-lb_lu","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tun-Wellens/BSP-S4-lb_lu","creator_name":"Tun Wellens","creator_url":"https://huggingface.co/Tun-Wellens","description":"\n\t\n\t\t\n\t\tLuxembourgish ASR Training Data (Custom)\n\t\n\nThis dataset contains Luxembourgish audio-text pairs manually collected and aligned for training an Automatic Speech Recognition (ASR) model.\n\n\t\n\t\t\n\t\tSources\n\t\n\n\nManually aligned transcripts from the Chambre des D√©put√©s (Luxembourg Parliament sessions).\nSelf-recorded audio: Recordings of texts from the official Luxembourg Government Reader for Lyc√©e Students.\n\n\n\t\n\t\t\n\t\tIntended Use\n\t\n\n\nFine-tuning ASR models for Luxembourgish speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tun-Wellens/BSP-S4-lb_lu.","first_N":5,"first_N_keywords":["Luxembourgish","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"CommonVoice-17.0-Spanish","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thermostatic/CommonVoice-17.0-Spanish","creator_name":"Irving Ernesto Quezada Ram√≠rez","creator_url":"https://huggingface.co/Thermostatic","description":"Thermostatic/CommonVoice-17.0-Spanish dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","1M - 10M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"css10-ljspeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/css10-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"\n\t\n\t\t\n\t\tCSS10-LJSpeech\n\t\n\nCSS10-LJSpeech „ÅØ„ÄÅPark et al. „ÅåÂÖ¨Èñã„Åó„Åü CSS10 „Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÄÅLJSpeech‰∫íÊèõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Å´Â§âÊèõ„Åó„Åü10Ë®ÄË™û„ÅÆÈü≥Â£∞ÂêàÊàêÁî®„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇÂêÑË®ÄË™û„ÅÆÊñáÂ≠¶‰ΩúÂìÅ„ÇíÈü≥Â£∞Âåñ„Åó„ÅüÈ´òÂìÅË≥™„Å™Èü≥Â£∞„Éá„Éº„Çø„ÇíÊèê‰æõ„Åó„ÄÅLJSpeech„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÔºàid|text & wavs/*.wavÔºâ„Å´Áµ±‰∏Ä„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Éº„ÇøÊ¶ÇË¶Å\n\t\n\n\n\t\n\t\t\nÈ†ÖÁõÆ\nÂÄ§\n\n\n\t\t\nË©±ËÄÖÊï∞\n10 (Ë®ÄË™ûÂà•)\n\n\nÁ∑èÈü≥Â£∞Êï∞\n64,196\n\n\nÂêàË®àÊôÇÈñì\nÁ¥Ñ 140 ÊôÇÈñì\n\n\n„Çµ„É≥„Éó„É™„É≥„Ç∞„É¨„Éº„Éà\n22,050 Hz\n\n\nÈü≥Â£∞„Éï„Ç©„Éº„Éû„ÉÉ„Éà\nIEEEÊµÆÂãïÂ∞èÊï∞ÁÇπ (32bit)\n\n\n„ÉÜ„Ç≠„Çπ„ÉàË®ÄË™û\n10Ë®ÄË™û\n\n\n„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n`id\n\n\n\t\n\n\n\t\n\t\t\n\t\tË®ÄË™ûÂà•Áµ±Ë®à\n\t\n\n\n\t\n\t\t\nË®ÄË™û\nË®ÄË™û„Ç≥„Éº„Éâ\nÈü≥Â£∞Êï∞\nÂêàË®àÊôÇÈñì\n\n\n\t\t\n„Éâ„Ç§„ÉÑË™û\nde\n7,428\n16.14ÊôÇÈñì\n\n\n„ÇÆ„É™„Ç∑„É£Ë™û\nel\n1,844\n4.14ÊôÇÈñì\n\n\n„Çπ„Éö„Ç§„É≥Ë™û\nes\n11,016\n19.15ÊôÇÈñì\n\n\n„Éï„Ç£„É≥„É©„É≥„ÉâË™û\nfi\n4,842\n10.53ÊôÇÈñì‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ljspeech.","first_N":5,"first_N_keywords":["German","Greek","Spanish","Finnish","French"],"keywords_longer_than_N":true},
	{"name":"css10-ljspeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/css10-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"\n\t\n\t\t\n\t\tCSS10-LJSpeech\n\t\n\nCSS10-LJSpeech „ÅØ„ÄÅPark et al. „ÅåÂÖ¨Èñã„Åó„Åü CSS10 „Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÄÅLJSpeech‰∫íÊèõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Å´Â§âÊèõ„Åó„Åü10Ë®ÄË™û„ÅÆÈü≥Â£∞ÂêàÊàêÁî®„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇÂêÑË®ÄË™û„ÅÆÊñáÂ≠¶‰ΩúÂìÅ„ÇíÈü≥Â£∞Âåñ„Åó„ÅüÈ´òÂìÅË≥™„Å™Èü≥Â£∞„Éá„Éº„Çø„ÇíÊèê‰æõ„Åó„ÄÅLJSpeech„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÔºàid|text & wavs/*.wavÔºâ„Å´Áµ±‰∏Ä„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Éº„ÇøÊ¶ÇË¶Å\n\t\n\n\n\t\n\t\t\nÈ†ÖÁõÆ\nÂÄ§\n\n\n\t\t\nË©±ËÄÖÊï∞\n10 (Ë®ÄË™ûÂà•)\n\n\nÁ∑èÈü≥Â£∞Êï∞\n64,196\n\n\nÂêàË®àÊôÇÈñì\nÁ¥Ñ 140 ÊôÇÈñì\n\n\n„Çµ„É≥„Éó„É™„É≥„Ç∞„É¨„Éº„Éà\n22,050 Hz\n\n\nÈü≥Â£∞„Éï„Ç©„Éº„Éû„ÉÉ„Éà\nIEEEÊµÆÂãïÂ∞èÊï∞ÁÇπ (32bit)\n\n\n„ÉÜ„Ç≠„Çπ„ÉàË®ÄË™û\n10Ë®ÄË™û\n\n\n„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n`id\n\n\n\t\n\n\n\t\n\t\t\n\t\tË®ÄË™ûÂà•Áµ±Ë®à\n\t\n\n\n\t\n\t\t\nË®ÄË™û\nË®ÄË™û„Ç≥„Éº„Éâ\nÈü≥Â£∞Êï∞\nÂêàË®àÊôÇÈñì\n\n\n\t\t\n„Éâ„Ç§„ÉÑË™û\nde\n7,428\n16.14ÊôÇÈñì\n\n\n„ÇÆ„É™„Ç∑„É£Ë™û\nel\n1,844\n4.14ÊôÇÈñì\n\n\n„Çπ„Éö„Ç§„É≥Ë™û\nes\n11,016\n19.15ÊôÇÈñì\n\n\n„Éï„Ç£„É≥„É©„É≥„ÉâË™û\nfi\n4,842\n10.53ÊôÇÈñì‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ljspeech.","first_N":5,"first_N_keywords":["German","Greek","Spanish","Finnish","French"],"keywords_longer_than_N":true},
	{"name":"CommonVoicesDelta21_ro","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro","creator_name":"Ionut Visan","creator_url":"https://huggingface.co/ionut-visan","description":"\n\t\n\t\t\n\t\tCommon Voices Delta 21.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoicesDelta21_ro","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro","creator_name":"Ionut Visan","creator_url":"https://huggingface.co/ionut-visan","description":"\n\t\n\t\t\n\t\tCommon Voices Delta 21.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoicesDelta21_ro","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro","creator_name":"Ionut Visan","creator_url":"https://huggingface.co/ionut-visan","description":"\n\t\n\t\t\n\t\tCommon Voices Delta 21.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåü Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåü Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"rain","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLoubris/rain","creator_name":"Liam Loubris","creator_url":"https://huggingface.co/LLoubris","description":"LLoubris/rain dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech-Test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NightPrince/MasriSpeech-Test","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","description":"NightPrince/MasriSpeech-Test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"xenocanto-two-species","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/capa2000/xenocanto-two-species","creator_name":"Christian Palma","creator_url":"https://huggingface.co/capa2000","description":"capa2000/xenocanto-two-species dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"neg_meow","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akiq2016/neg_meow","creator_name":"akiq","creator_url":"https://huggingface.co/akiq2016","description":"akiq2016/neg_meow dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"xenocanto-two_species","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/capa2000/xenocanto-two_species","creator_name":"Christian Palma","creator_url":"https://huggingface.co/capa2000","description":"capa2000/xenocanto-two_species dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"binary","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/capa2000/binary","creator_name":"Christian Palma","creator_url":"https://huggingface.co/capa2000","description":"capa2000/binary dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"google_myanmar_asr_voices","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/google_myanmar_asr_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tGoogle Myanmar ASR Dataset (WebDataset Version)\n\t\n\nThis repository provides a clean, user-friendly, and robust version of the Google Myanmar ASR Dataset, which is derived from the OpenSLR-80 Burmese Speech Corpus.\nThis version has been carefully re-processed into the WebDataset format. Each sample consists of a .wav audio file and a clean .json metadata file, packaged into sharded .tar archives. This format is highly efficient for large-scale training of ASR models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/google_myanmar_asr_voices.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","cc0-1.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"google_myanmar_asr_voices","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/google_myanmar_asr_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tGoogle Myanmar ASR Dataset (WebDataset Version)\n\t\n\nThis repository provides a clean, user-friendly, and robust version of the Google Myanmar ASR Dataset, which is derived from the OpenSLR-80 Burmese Speech Corpus.\nThis version has been carefully re-processed into the WebDataset format. Each sample consists of a .wav audio file and a clean .json metadata file, packaged into sharded .tar archives. This format is highly efficient for large-scale training of ASR models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/google_myanmar_asr_voices.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","cc0-1.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"mordar_1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mbouih/mordar_1","creator_name":"Mehdi BOUIH","creator_url":"https://huggingface.co/mbouih","description":"mbouih/mordar_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ToneBooksPlus","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/ToneBooksPlus","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tToneBooksPlus\n\t\n\nToneBooksPlus ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ Vikhrmodels/ToneBooks, –Ω–æ –±–µ–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏. –í –¥–∞—Ç–∞—Å–µ—Ç–µ 179.16 —á–∞—Å–æ–≤ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 9.42 —á–∞—Å–∞ –¥–ª—è validation.\n–ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ its5Q –∑–∞ –ø–æ–º–æ—â—å –≤ —Å–±–æ—Ä–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n\n\n\t\n\t\t\n\t\n\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Å–æ–±—Ä–∞–Ω—ã:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ MP3-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ò–º—è –≥–æ–ª–æ—Å–∞ (voice_name) ‚Äî –æ–¥–Ω–æ –∏–∑ –∏–º—ë–Ω –¥–∏–∫—Ç–æ—Ä–æ–≤:\nAleksandr Kotov  \nAleksandr Zbarovskii  \nAlina Archibasova  \nDaniel Che‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneBooksPlus.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_openai","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - OpenAI GPT-4o Transcribe\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando OpenAI GPT-4o Transcribe.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: OpenAI GPT-4o Transcribe\nPre√ßo: $6.00/1M tokens\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo Whisper de alta precis√£o da OpenAI para transcri√ß√£o de √°udio.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Estat√≠sticas‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_openai","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - OpenAI GPT-4o Transcribe\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando OpenAI GPT-4o Transcribe.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: OpenAI GPT-4o Transcribe\nPre√ßo: $6.00/1M tokens\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo Whisper de alta precis√£o da OpenAI para transcri√ß√£o de √°udio.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Estat√≠sticas‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"captioned-ai-music-snippets","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/captioned-ai-music-snippets","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"laion/captioned-ai-music-snippets dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"VB-DemandEx","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NikolaiKyhne/VB-DemandEx","creator_name":"Nikolai Lund K√ºhne","creator_url":"https://huggingface.co/NikolaiKyhne","description":"NikolaiKyhne/VB-DemandEx dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","10K<n<100K","Audio","doi:10.57967/hf/5907"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian_annotated","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_annotated","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Annotated\n\t\n\nThis is a dataset with Russian annotated audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\nutterance_pitch_mean: The average pitch of the speech utterance (float64).\nutterance_pitch_std: The standard deviation of pitch, representing variability in intonation (float64)\nsnr:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_annotated.","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian_annotated","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_annotated","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Annotated\n\t\n\nThis is a dataset with Russian annotated audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\nutterance_pitch_mean: The average pitch of the speech utterance (float64).\nutterance_pitch_std: The standard deviation of pitch, representing variability in intonation (float64)\nsnr:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_annotated.","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"emotion-tagged-small-v1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/emotion-tagged-small-v1","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"WhissleAI/emotion-tagged-small-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"integration-test-files","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/corti/integration-test-files","creator_name":"Corti","creator_url":"https://huggingface.co/corti","description":"corti/integration-test-files dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"Dataset_EigenTroops","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/daraayuiswandari/Dataset_EigenTroops","creator_name":"Dara Ayu Iswandari","creator_url":"https://huggingface.co/daraayuiswandari","description":"daraayuiswandari/Dataset_EigenTroops dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"vocalset-mirror","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bill13579/vocalset-mirror","creator_name":"Shiko Kudo","creator_url":"https://huggingface.co/Bill13579","description":"Mirror of https://zenodo.org/records/1442513.\nSee the original dataset creators,\nWilkins, J., Prem Seetharaman, Alison Wahl, & Bryan Pardo. (2018). VocalSet: A Singing Voice Dataset (1.2) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.1442513\n","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"fsd50k","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philgzl/fsd50k","creator_name":"Philippe Gonzalez","creator_url":"https://huggingface.co/philgzl","description":"\n\t\n\t\t\n\t\tFSD50K: An open dataset of human-labeled sound events\n\t\n\nThis is a mirror of the FSD50K sound event dataset.\nThe original files were converted from WAV to Opus to reduce the size and accelerate streaming.\n\nSampling rate: 48 kHz\nChannels: 1\nFormat: Opus\nSplits:\nDev: 80 hours, 40966 clips.\nEval: 28 hours, 10231 clips.\n\n\nLicense: FSD50K is released under CC-BY. However, each clip has its own licence. Clip licenses include CC0, CC-BY, CC-BY-NC and CC Sampling+. Clip licenses are specified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philgzl/fsd50k.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"chinese_sermon_train","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michel314/chinese_sermon_train","creator_name":"Michelle Deng","creator_url":"https://huggingface.co/michel314","description":"michel314/chinese_sermon_train dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"noise-dataset-de","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rolgor/noise-dataset-de","creator_name":"rol gor","creator_url":"https://huggingface.co/rolgor","description":"\n\t\n\t\t\n\t\tGerman Noise-Augmented Speech Demo Dataset\n\t\n\nThis dataset provides German speech samples augmented with realistic noise scenarios such as office noise, street noise, white noise, echo, and lowpass filtering.It is designed for testing and improving the robustness of ASR (Automatic Speech Recognition) systems.\n\n\t\n\t\t\n\t\tüí° Source\n\t\n\n\nOriginal voice samples: Mozilla Common Voice (CC0)\nNoise layers: custom augmented (see noise.rolgor.de)\n\n\n\t\n\t\t\n\t\t‚ö†Ô∏è Privacy\n\t\n\nPlease respect speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rolgor/noise-dataset-de.","first_N":5,"first_N_keywords":["keyword-spotting","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"som_tts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zakihassan/som_tts","creator_name":"Zakarie Hassan Abdi","creator_url":"https://huggingface.co/zakihassan","description":"\n\t\n\t\t\n\t\tSomali TTS Dataset\n\t\n\nThis dataset contains high-quality Somali speech recordings with corresponding transcriptions.It is designed for training Text-to-Speech (TTS) models such as Coqui XTTS v2, FastSpeech, or VITS for the Somali language.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: .wav audio + metadata.csv (tab-separated: wav_path, transcription)\nLanguage: Somali\nTotal Samples: ~20,000 clips\nSampling Rate: 22050 Hz\n\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo train with Coqui TTS:\ntts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zakihassan/som_tts.","first_N":5,"first_N_keywords":["text-to-speech","Somali","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"OseDitionary_Voice","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MakarMD/OseDitionary_Voice","creator_name":"Mariya","creator_url":"https://huggingface.co/MakarMD","description":"MakarMD/OseDitionary_Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","text-to-audio","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malaysia-ai/common_voice_17_0","creator_name":"Malaysia AI","creator_url":"https://huggingface.co/malaysia-ai","description":"\n\t\n\t\t\n\t\tCommon Voice Corpus 17.0\n\t\n\nMirror for mozilla-foundation/common_voice_17_0, easy to download and extract instead audio in parquet files.\n\n\t\n\t\t\n\t\tHow to prepare the dataset\n\t\n\nhuggingface-cli download --repo-type dataset \\\n--include '*.zip' \\\n--local-dir './' \\\n--max-workers 20 \\\nmalaysia-ai/common_voice_17_0\n\nwget https://gist.githubusercontent.com/huseinzol05/2e26de4f3b29d99e993b349864ab6c10/raw/9b2251f3ff958770215d70c8d82d311f82791b78/unzip.py\npython3 unzip.py\n\n","first_N":5,"first_N_keywords":["cc0-1.0","1M - 10M","parquet","Audio","Tabular"],"keywords_longer_than_N":true},
	{"name":"87878788787","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zh-liu799/87878788787","creator_name":"Zihang Liu","creator_url":"https://huggingface.co/zh-liu799","description":"zh-liu799/87878788787 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TTS_eval_datasets","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/k2-fsa/TTS_eval_datasets","creator_name":"k2-fsa","creator_url":"https://huggingface.co/k2-fsa","description":"\n\t\n\t\t\n\t\tTTS evaluation datasets\n\t\n\nThis repository contains three testsets for zero-shot TTS models:\n\ndialog_testset: Chinese and English testsets for spoken dialogue generation models, introduced in paper ZipVoice-Dialog.\nlibrispeech_pc_testset: English testset for zero-shot TTS models, introduced in paper F5-TTS.\nseedtts_testset: Chinese and English testsets for zero-shot TTS models, introduced in paper Seed-TTS.\n\n","first_N":5,"first_N_keywords":["text-to-speech","Chinese","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sitata","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/casperdewith/sitata","creator_name":"Casper de With","creator_url":"https://huggingface.co/casperdewith","description":"This dataset contains an audio recording of each sentence in the book jan Sitata.\nThe author pronoucned each sentence, including questions and exclamations,\nwith the intonation as that of a declarative sentence.\nThis makes the dataset quite homogeneous.\nEvery tenth fragment is in the test folder; the rest is in the train folder.\nEach is a .wav file with a bit rate of 16¬†kHz. In total, there is 63¬†minutes of audio in this dataset.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Toki Pona","cc0-1.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"TikTok_MostComment_Video_Transcription_Example","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MasaFoundation/TikTok_MostComment_Video_Transcription_Example","creator_name":"MasaAI","creator_url":"https://huggingface.co/MasaFoundation","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MasaFoundation/TikTok_MostComment_Video_Transcription_Example.","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"TikTok_Hottest_Video_Transcript_Example","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MasaFoundation/TikTok_Hottest_Video_Transcript_Example","creator_name":"MasaAI","creator_url":"https://huggingface.co/MasaFoundation","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MasaFoundation/TikTok_Hottest_Video_Transcript_Example.","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"audio_bassa","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dama03/audio_bassa","creator_name":"Damarus","creator_url":"https://huggingface.co/Dama03","description":"Dama03/audio_bassa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Notcrowy","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mobinx/Notcrowy","creator_name":"Mobin Chowdhury","creator_url":"https://huggingface.co/mobinx","description":"\n\t\n\t\t\n\t\tAudio Dataset Statistics\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal audio files\n556,667\n\n\nTotal duration\n1,024.71 hours (3,688,949 seconds)\n\n\nAverage duration\n6.63 seconds\n\n\nShortest clip\n0.41 seconds\n\n\nLongest clip\n44.97 seconds\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSpeaker Breakdown\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tTop 10 Speakers by Clip Count\n\t\n\n\n\t\n\t\t\nSpeaker\nClips\nDuration\n% of Total\n\n\n\t\t\nDespina\n60,150\n118.07 hours\n11.5%\n\n\nSulafat\n31,593\n58.15 hours\n5.7%\n\n\nAchernar29,889\n54.53 hours\n5.3%\n\n\nAutonoe\n27,897‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mobinx/Notcrowy.","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"RAVDESS-transcribed","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenitsu09/RAVDESS-transcribed","creator_name":"Himanshu Gangwar","creator_url":"https://huggingface.co/zenitsu09","description":"zenitsu09/RAVDESS-transcribed dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"lapsbm2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/falabrasil/lapsbm2","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","description":"falabrasil/lapsbm2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"carlos_it_2H","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/carlos_it_2H","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/carlos_it_2H dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"WutheringWaves-Encore-voice-en","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Juicesyo/WutheringWaves-Encore-voice-en","creator_name":"Juice","creator_url":"https://huggingface.co/Juicesyo","description":"\n\t\n\t\t\n\t\tThis dataset is for non-commercial use only. All rights reserved by Guangzhou Kuluo Technology Co., Ltd.\n\t\n\n","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"spokenwoz-whisper","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pirxus/spokenwoz-whisper","creator_name":"≈†imon Sedl√°ƒçek","creator_url":"https://huggingface.co/pirxus","description":"\n\t\n\t\t\n\t\tSpokenWOZ With Whisper Transcripts\n\t\n\nThis is a custom version of the SpokenWOZ dataset with all the original transcripts replaced by transcripts generated by Whisper-large-v3. We manually\ntranscribed 1000 utterances from the test set and like this estimate the WER of the original ASR to be ~29% and the WER of the Whisper transcripts to\nbe ~5.3%.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@misc{si2024spokenwozlargescalespeechtextbenchmark,\n      title={SpokenWOZ: A Large-Scale Speech-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pirxus/spokenwoz-whisper.","first_N":5,"first_N_keywords":["English","cc-by-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"plug_socket_mixed","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_mixed","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 50,\n    \"total_frames\": 15095,\n    \"total_tasks\": 1,\n    \"total_videos\": 150,\n    \"total_audio\": 150,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_mixed.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"plug_socket_mixed","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_mixed","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 50,\n    \"total_frames\": 15095,\n    \"total_tasks\": 1,\n    \"total_videos\": 150,\n    \"total_audio\": 150,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:50\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_mixed.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"VlogQA","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Konnmjn/VlogQA","creator_name":"Minh Phan","creator_url":"https://huggingface.co/Konnmjn","description":"Konnmjn/VlogQA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Vietnamese","apache-2.0","10K<n<100K","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"VlogQA","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Konnmjn/VlogQA","creator_name":"Minh Phan","creator_url":"https://huggingface.co/Konnmjn","description":"Konnmjn/VlogQA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Vietnamese","apache-2.0","10K<n<100K","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TASTE-Dump","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MediaTek-Research/TASTE-Dump","creator_name":"MediaTek Research","creator_url":"https://huggingface.co/MediaTek-Research","description":"MediaTek-Research/TASTE-Dump dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10M - 100M","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_2_7","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_2_7","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"vocalno","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/t0bi4s/vocalno","creator_name":"sujiuheng","creator_url":"https://huggingface.co/t0bi4s","description":"\n\t\n\t\t\n\t\tTobias Chinese TTS Dataset\n\t\n\nËøôÊòØ‰∏Ä‰∏™‰∏≠ÊñáÊñáÊú¨ËΩ¨ËØ≠Èü≥(TTS)Êï∞ÊçÆÈõÜÔºåÂåÖÂê´Á∫¶997‰∏™È´òË¥®ÈáèÁöÑ‰∏≠ÊñáÈü≥È¢ë-ÊñáÊú¨ÂØπ„ÄÇ\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ\n\t\n\n\nËØ≠Ë®Ä: ‰∏≠Êñá (Chinese)\n‰ªªÂä°: ÊñáÊú¨ËΩ¨ËØ≠Èü≥ (Text-to-Speech)\nÊ†∑Êú¨Êï∞Èáè: ~997‰∏™Èü≥È¢ë-ÊñáÊú¨ÂØπ\nÈü≥È¢ëÊ†ºÂºè: WAV, 16kHzÈááÊ†∑Áéá\nËÆ∏ÂèØËØÅ: MIT\nÂèëË®Ä‰∫∫: Âçï‰∏ÄÂèëË®Ä‰∫∫\n\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜÁªìÊûÑ\n\t\n\nfrom datasets import load_dataset\n\n# Âä†ËΩΩÂÆåÊï¥Êï∞ÊçÆÈõÜ\ndataset = load_dataset(\"your_username/tobias-tts-chinese\")\n\n# Âè™Âä†ËΩΩËÆ≠ÁªÉÈõÜ\ntrain_dataset = load_dataset(\"your_username/tobias-tts-chinese\", split=\"train\")\n\n# Âè™Âä†ËΩΩÈ™åËØÅÈõÜ\nvalidation_dataset = load_dataset(\"your_username/tobias-tts-chinese\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/t0bi4s/vocalno.","first_N":5,"first_N_keywords":["text-to-speech","Chinese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"vocalno","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/t0bi4s/vocalno","creator_name":"sujiuheng","creator_url":"https://huggingface.co/t0bi4s","description":"\n\t\n\t\t\n\t\tTobias Chinese TTS Dataset\n\t\n\nËøôÊòØ‰∏Ä‰∏™‰∏≠ÊñáÊñáÊú¨ËΩ¨ËØ≠Èü≥(TTS)Êï∞ÊçÆÈõÜÔºåÂåÖÂê´Á∫¶997‰∏™È´òË¥®ÈáèÁöÑ‰∏≠ÊñáÈü≥È¢ë-ÊñáÊú¨ÂØπ„ÄÇ\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ\n\t\n\n\nËØ≠Ë®Ä: ‰∏≠Êñá (Chinese)\n‰ªªÂä°: ÊñáÊú¨ËΩ¨ËØ≠Èü≥ (Text-to-Speech)\nÊ†∑Êú¨Êï∞Èáè: ~997‰∏™Èü≥È¢ë-ÊñáÊú¨ÂØπ\nÈü≥È¢ëÊ†ºÂºè: WAV, 16kHzÈááÊ†∑Áéá\nËÆ∏ÂèØËØÅ: MIT\nÂèëË®Ä‰∫∫: Âçï‰∏ÄÂèëË®Ä‰∫∫\n\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜÁªìÊûÑ\n\t\n\nfrom datasets import load_dataset\n\n# Âä†ËΩΩÂÆåÊï¥Êï∞ÊçÆÈõÜ\ndataset = load_dataset(\"your_username/tobias-tts-chinese\")\n\n# Âè™Âä†ËΩΩËÆ≠ÁªÉÈõÜ\ntrain_dataset = load_dataset(\"your_username/tobias-tts-chinese\", split=\"train\")\n\n# Âè™Âä†ËΩΩÈ™åËØÅÈõÜ\nvalidation_dataset = load_dataset(\"your_username/tobias-tts-chinese\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/t0bi4s/vocalno.","first_N":5,"first_N_keywords":["text-to-speech","Chinese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang-zip","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip.","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang-zip","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip.","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"speech_to_text_benchmark","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ionio-ai/speech_to_text_benchmark","creator_name":"Ionio","creator_url":"https://huggingface.co/Ionio-ai","description":"\n\t\n\t\t\n\t\tMy Audio Dataset\n\t\n\nThis dataset contains audio recordings with corresponding transcriptions and metadata.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\naudio: Audio files (WAV format).\ntext: Transcription of the audio.\ncategory: Category of the audio (if applicable).\nduration: Duration of the audio in seconds.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset using the datasets library:\nfrom datasets import load_dataset\ndataset = load_dataset(\"jaishah2808/speech-to-text-benchmark\")\n\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"june_3_italian","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/june_3_italian","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/june_3_italian dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"raw_1hr_myanmar_asr_audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüá≤üá≤ Raw 1-Hour Burmese ASR Audio Dataset\n\t\n\nA 1-hour dataset of Burmese (Myanmar language) spoken audio clips with transcripts, curated from official public-service media broadcasts by PVTV Myanmar ‚Äî the media voice of Myanmar‚Äôs National Unity Government (NUG).\nThis dataset is intended for automatic speech recognition (ASR) and Burmese speech-processing research.\n‚û°Ô∏è Author: freococo‚û°Ô∏è License: MIT‚û°Ô∏è Language: Burmese (my)\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ Dataset Summary\n\t\n\n\nDuration: ~1 hour\nChunks:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Hy-Generated-audio-data-2","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ErikMkrtchyan/Hy-Generated-audio-data-2","creator_name":"Erik Mkrtchyan","creator_url":"https://huggingface.co/ErikMkrtchyan","description":"\n\t\n\t\t\n\t\tHy-Generated Audio Data 2\n\t\n\nThis dataset provides Armenian speech data consisting of generated audio clips and is addition to this dataset.\n\nThe generated split contains 137,419 high-quality clips synthesized using a fine-tuned F5-TTS model, covering 404 equal distribution of synthetic voices.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Statistics\n\t\n\n\n\t\n\t\t\nSplit\n# Clips\nDuration (hours)\n\n\n\t\t\ngenerated\n137,419\n173.76\n\n\n\t\n\nTotal duration: ~173 hours\n\n\t\n\t\n\t\n\t\tüõ†Ô∏è Loading the Dataset\n\t\n\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ErikMkrtchyan/Hy-Generated-audio-data-2.","first_N":5,"first_N_keywords":["Armenian","cc0-1.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"TeleSpeech-AudioBench","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tele-AI/TeleSpeech-AudioBench","creator_name":"Tele-AI","creator_url":"https://huggingface.co/Tele-AI","description":"Êõ¥Â§öÁªÜËäÇÔºåËØ∑ÂèÇËßÅGithubÔºöhttps://github.com/Tele-AI/TeleSpeech-AudioBench\nTeleSpeech-AudioBench Êó®Âú®Êé¢Á¥¢ËØ≠Èü≥ÂØπËØùÂ§ßÊ®°Âûã (Spoken-Language Models, SLMs) Âú®ÁúüÂÆûÂ∫îÁî®‰∏≠ÁöÑÂèØË°åÊÄß‰∏éÂÆûÁî®ÊÄßÔºåÁªìÂêàÂÆûÈôÖ‰∫§‰∫íÈúÄÊ±Ç (Â¶ÇÁü•ËØÜÈóÆÁ≠î„ÄÅÊãü‰∫∫Èô™‰º¥Á≠â)Ôºå‰ªé 7 ‰∏™ÂÖ≥ÈîÆÁª¥Â∫¶ÂÖ®Èù¢Ë°°ÈáèÊ®°ÂûãËÉΩÂäõÔºåÂåÖÊã¨ÔºöÂ∏∏ËØÜÁêÜËß£„ÄÅÂâØËØ≠Ë®Ä‰ø°ÊÅØÊÑüÁü•‰∏éÂõûÂ∫î„ÄÅÊãü‰∫∫Á®ãÂ∫¶„ÄÅÂ£∞Â≠¶È≤ÅÊ£íÊÄß„ÄÅÈü≥È¢ëÁîüÊàêËÉΩÂäõ„ÄÅ‰∏ä‰∏ãÊñáÁêÜËß£ÂèäÂûÇÁ±ªÁü•ËØÜÊéåÊè°\nÊï¥‰ΩìËÆæËÆ°‰ª•ÁúüÂÆûÂ∫îÁî®‰∏∫ÂØºÂêëÔºåÂº∫Ë∞ÉËØ≠Ë®ÄÂ§öÊ†∑ÊÄßË¶ÜÁõñ„ÄÅ‰∫§‰∫íËá™ÁÑ∂ÊÄß‰∏éËØÑ‰º∞ÂÆ¢ËßÇÊÄßÔºå‰∏ªË¶ÅÁâπÁÇπÂåÖÊã¨Ôºö\n\nÂ§öÁª¥ÂÆûÁî®ÊÄßËØÑ‰º∞ üß†ÔºöË¶ÜÁõñ 7 Â§ßÊ†∏ÂøÉÁª¥Â∫¶‰∏éÂ§ö‰∏™ÁªÜÂàÜ‰ªªÂä°ÔºåÂÖ®Èù¢Ê£ÄÈ™åÊ®°ÂûãÂú®ÁúüÂÆû‰∫§‰∫í‰∏≠ÁöÑÁªºÂêàË°®Áé∞„ÄÇ\nÈõ∂Ê†∑Êú¨ÁúüÂÆû‰∫§‰∫íÊµãËØï üéßÔºöÊ®°ÊãüÁúüÂÆû‰ΩøÁî®Âú∫ÊôØÔºåÊâÄÊúâÊµãËØïÂùáÂü∫‰∫é zero-shot Èü≥È¢ëËæìÂÖ•ÔºåÊó†‰ªª‰ΩïÊñáÊú¨Êåá‰ª§ÊàñÂÖàÈ™åÊèêÁ§∫ÔºåÂÖ®Èù¢ËÄÉÂØüÊ®°ÂûãÂØπËØ≠Èü≥Êåá‰ª§ÁöÑÁõ¥Êé•ÂìçÂ∫îËÉΩÂäõ„ÄÇ\n‰ªªÂä°È©±Âä®ÂºèËØÑ‰º∞Ê†áÂáÜ üéØÔºö‰∏çÂêå‰ªªÂä°Áª¥Â∫¶ÂØπÊ®°ÂûãËæìÂá∫ËÆæÂÆö‰∏çÂêåË¶ÅÊ±ÇÔºå‰æãÂ¶ÇÂ∏∏ËØÜÈóÆÁ≠îÂÖÅËÆ∏ÁîüÊàêËæÉÈïøÂõûÁ≠îÔºåËÄåÊãü‰∫∫Èô™‰º¥‰ªªÂä°Êõ¥Ê≥®ÈáçÂìçÂ∫îÁöÑËá™ÁÑ∂Â∫¶‰∏éÈïøÂ∫¶ÊéßÂà∂„ÄÇ\nÂ§öËØ≠Áßç‰∏éÂ§öÊñπË®ÄÊï∞ÊçÆÊîØÊåÅ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tele-AI/TeleSpeech-AudioBench.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"may_30_english","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/may_30_english","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/may_30_english dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"LLM_Dys","keyword":"audio-classification","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tong0/LLM_Dys","creator_name":"huanpm","creator_url":"https://huggingface.co/tong0","description":"\n\t\n\t\t\n\t\tüîä LLM-Dys Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLLM-Dys is an innovative dataset that leverages large language models to help realistic dysfluent speech synthesis. This comprehensive dataset supports multiple types of dysfluency at different linguistic levels, enabling advanced research in speech synthesis and dysfluency analysis.\n\n\t\n\t\t\n\t\tüîç Dysfluency Types\n\t\n\nOur dataset supports multiple types of dysfluency at both word and phoneme levels:\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\nNatural and authentic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tong0/LLM_Dys.","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","automatic-speech-recognition","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LLM_Dys","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tong0/LLM_Dys","creator_name":"huanpm","creator_url":"https://huggingface.co/tong0","description":"\n\t\n\t\t\n\t\tüîä LLM-Dys Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLLM-Dys is an innovative dataset that leverages large language models to help realistic dysfluent speech synthesis. This comprehensive dataset supports multiple types of dysfluency at different linguistic levels, enabling advanced research in speech synthesis and dysfluency analysis.\n\n\t\n\t\t\n\t\tüîç Dysfluency Types\n\t\n\nOur dataset supports multiple types of dysfluency at both word and phoneme levels:\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\nNatural and authentic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tong0/LLM_Dys.","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","automatic-speech-recognition","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LLM_Dys","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tong0/LLM_Dys","creator_name":"huanpm","creator_url":"https://huggingface.co/tong0","description":"\n\t\n\t\t\n\t\tüîä LLM-Dys Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLLM-Dys is an innovative dataset that leverages large language models to help realistic dysfluent speech synthesis. This comprehensive dataset supports multiple types of dysfluency at different linguistic levels, enabling advanced research in speech synthesis and dysfluency analysis.\n\n\t\n\t\t\n\t\tüîç Dysfluency Types\n\t\n\nOur dataset supports multiple types of dysfluency at both word and phoneme levels:\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\nNatural and authentic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tong0/LLM_Dys.","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","automatic-speech-recognition","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"pitch_rate","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doublesizebed/pitch_rate","creator_name":"chong","creator_url":"https://huggingface.co/doublesizebed","description":"doublesizebed/pitch_rate dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"FeruzaSpeechDualText","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickoo004/FeruzaSpeechDualText","creator_name":"Nicholas","creator_url":"https://huggingface.co/nickoo004","description":"nickoo004/FeruzaSpeechDualText dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"process_dataset_mini","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doublesizebed/process_dataset_mini","creator_name":"chong","creator_url":"https://huggingface.co/doublesizebed","description":"doublesizebed/process_dataset_mini dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Malay","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"music_test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zerostratos/music_test","creator_name":"Nguy·ªÖn Ti·∫øn Kh√¥i","creator_url":"https://huggingface.co/zerostratos","description":"zerostratos/music_test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","arrow","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"bench","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymous-rebuttal/bench","creator_name":"anonymous rebuttal","creator_url":"https://huggingface.co/anonymous-rebuttal","description":"anonymous-rebuttal/bench dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-multispeaker","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 21138 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 21138 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"Custom-LRS3","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhaoyang9425/Custom-LRS3","creator_name":"Zhao Yang","creator_url":"https://huggingface.co/zhaoyang9425","description":"zhaoyang9425/Custom-LRS3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_5_10","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 252\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_5_10","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 252\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"test-assets","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/easyparser/test-assets","creator_name":"easyparser","creator_url":"https://huggingface.co/easyparser","description":"easyparser/test-assets dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","Audio","Document","Text"],"keywords_longer_than_N":true},
	{"name":"synthetic-speaker-diarization-dataset-fa-large-3000","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uncleMehrzad/synthetic-speaker-diarization-dataset-fa-large-3000","creator_name":"Amirreza Mehrzadian","creator_url":"https://huggingface.co/uncleMehrzad","description":"uncleMehrzad/synthetic-speaker-diarization-dataset-fa-large-3000 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"synthetic-speaker-diarization-dataset-fa-large-3000","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uncleMehrzad/synthetic-speaker-diarization-dataset-fa-large-3000","creator_name":"Amirreza Mehrzadian","creator_url":"https://huggingface.co/uncleMehrzad","description":"uncleMehrzad/synthetic-speaker-diarization-dataset-fa-large-3000 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"XF-Denoise","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/clatter-1/XF-Denoise","creator_name":"shangzengqiang","creator_url":"https://huggingface.co/clatter-1","description":"Far-field speech enhancement plays a crucial role in speech signal processing, primarily aimed at improving speech intelligibility and other speech-based applications in real-world scenarios. However, models trained on simulated data or existing real-world far-field datasets often exhibit limited performance in extreme far-field conditions. To address these challenges, we present XF-Denoise, a real-world dataset specifically designed for extreme far-field speech enhancement. The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clatter-1/XF-Denoise.","first_N":5,"first_N_keywords":["mit","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Voice-Model","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aryan0424/Voice-Model","creator_name":"Aryan Babariya","creator_url":"https://huggingface.co/aryan0424","description":"aryan0424/Voice-Model dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"SINE","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PeacefulData/SINE","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","description":"\n\t\n\t\t\n\t\tSINE Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Speech INfilling Edit (SINE) dataset is a comprehensive collection for speech deepfake detection and audio authenticity verification. This dataset contains ~87GB of audio data distributed across 32 splits, featuring both authentic and synthetically manipulated speech samples.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Size: ~87GB\nNumber of Splits: 32 (split-0.tar.gz to split-31.tar.gz)\nAudio Format: WAV files\nSource: Speech edited from LibriLight‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PeacefulData/SINE.","first_N":5,"first_N_keywords":["audio-classification","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"SINE","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PeacefulData/SINE","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","description":"\n\t\n\t\t\n\t\tSINE Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Speech INfilling Edit (SINE) dataset is a comprehensive collection for speech deepfake detection and audio authenticity verification. This dataset contains ~87GB of audio data distributed across 32 splits, featuring both authentic and synthetically manipulated speech samples.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Size: ~87GB\nNumber of Splits: 32 (split-0.tar.gz to split-31.tar.gz)\nAudio Format: WAV files\nSource: Speech edited from LibriLight‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PeacefulData/SINE.","first_N":5,"first_N_keywords":["audio-classification","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"SINE","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PeacefulData/SINE","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","description":"\n\t\n\t\t\n\t\tSINE Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Speech INfilling Edit (SINE) dataset is a comprehensive collection for speech deepfake detection and audio authenticity verification. This dataset contains ~87GB of audio data distributed across 32 splits, featuring both authentic and synthetically manipulated speech samples.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Size: ~87GB\nNumber of Splits: 32 (split-0.tar.gz to split-31.tar.gz)\nAudio Format: WAV files\nSource: Speech edited from LibriLight‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PeacefulData/SINE.","first_N":5,"first_N_keywords":["audio-classification","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"vasertoken","keyword":"audio","license":"BSD 3-Clause Clear License","license_url":"https://choosealicense.com/licenses/bsd-3-clause-clear/","language":"en","dataset_url":"https://huggingface.co/datasets/DRDELATV/vasertoken","creator_name":"IGNACIO TAPIA","creator_url":"https://huggingface.co/DRDELATV","description":"DRDELATV/vasertoken dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["bsd-3-clause-clear","< 1K","Audio","Document","Datasets"],"keywords_longer_than_N":true},
	{"name":"fleurs-farsi","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi","creator_name":"Mohammad Sadegh Gholizadeh","creator_url":"https://huggingface.co/MohammadGholizadeh","description":"\n\t\n\t\t\n\t\tFLEURS Farsi (fa_ir) - Processed Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the Farsi (Persian, fa_ir) portion of the FLEURS (Few-shot Learning Evaluation of Universal Representations of Speech) dataset, processed into a Hugging Face datasets compatible format. FLEURS is a many-language speech dataset created by Google, designed for evaluating speech recognition systems, particularly in low-resource scenarios.\nThis version includes audio recordings and their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fleurs-farsi","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi","creator_name":"Mohammad Sadegh Gholizadeh","creator_url":"https://huggingface.co/MohammadGholizadeh","description":"\n\t\n\t\t\n\t\tFLEURS Farsi (fa_ir) - Processed Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the Farsi (Persian, fa_ir) portion of the FLEURS (Few-shot Learning Evaluation of Universal Representations of Speech) dataset, processed into a Hugging Face datasets compatible format. FLEURS is a many-language speech dataset created by Google, designed for evaluating speech recognition systems, particularly in low-resource scenarios.\nThis version includes audio recordings and their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"english_june_3_data","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/english_june_3_data","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/english_june_3_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Ranjan-Hindi33min","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BBSRguy/Ranjan-Hindi33min","creator_name":"Rashmi Ranjan Dash","creator_url":"https://huggingface.co/BBSRguy","description":"\n\t\n\t\t\n\t\tRanjan-Hindi33min\n\t\n\nOwner: @BBSRguyCreated: 2025-06-03Year: 2025Language: Hindi üáÆüá≥Region Focus: Odisha, IndiaSample Rate Variants: 16 kHz, 24 kHz, 32 kHzTotal Files: 29 pairs (speech + text)Duration: Approximately 33 minutes of speech  \n\n\n\t\n\t\t\n\t\n\t\n\t\tüìú Description\n\t\n\nRanjan-Hindi33min is a meticulously curated dataset comprising high-quality Hindi speech samples and their corresponding textual transcriptions. This dataset is designed to support various speech processing tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BBSRguy/Ranjan-Hindi33min.","first_N":5,"first_N_keywords":["text-to-speech","Hindi","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/audiobooks","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"170 hours of aligned audiobooks taken from tatkniga.ru. There are 4 speakers with 17+ hours of audio and 20 speakers in total. All the books are in free access and most of them in public domain.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/audiobooks","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"170 hours of aligned audiobooks taken from tatkniga.ru. There are 4 speakers with 17+ hours of audio and 20 speakers in total. All the books are in free access and most of them in public domain.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/audiobooks","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"170 hours of aligned audiobooks taken from tatkniga.ru. There are 4 speakers with 17+ hours of audio and 20 speakers in total. All the books are in free access and most of them in public domain.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Children_Counsel","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ironDong/Children_Counsel","creator_name":"sindongwoo","creator_url":"https://huggingface.co/ironDong","description":"\n\t\n\t\t\n\t\tÏïÑÎèô¬∑Ï≤≠ÏÜåÎÖÑ ÏÉÅÎã¥ Îç∞Ïù¥ÌÑ∞ÏÖã (Children Counseling Dataset)\n\t\n\nThis dataset contains counseling data for children and adolescents, including both audio recordings and transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n\naudio/: Contains the audio recordings of counseling sessions in MP3 format\ndata/: Contains JSON files with transcriptions and metadata for each session\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nTraining speech recognition models for counseling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ironDong/Children_Counsel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Children_Counsel","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ironDong/Children_Counsel","creator_name":"sindongwoo","creator_url":"https://huggingface.co/ironDong","description":"\n\t\n\t\t\n\t\tÏïÑÎèô¬∑Ï≤≠ÏÜåÎÖÑ ÏÉÅÎã¥ Îç∞Ïù¥ÌÑ∞ÏÖã (Children Counseling Dataset)\n\t\n\nThis dataset contains counseling data for children and adolescents, including both audio recordings and transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n\naudio/: Contains the audio recordings of counseling sessions in MP3 format\ndata/: Contains JSON files with transcriptions and metadata for each session\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nTraining speech recognition models for counseling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ironDong/Children_Counsel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"speech_to_text_yixing_dialect","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lubobill1990/speech_to_text_yixing_dialect","creator_name":"Bill Lu","creator_url":"https://huggingface.co/lubobill1990","description":"lubobill1990/speech_to_text_yixing_dialect dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","arrow","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"denes_tts","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Denhotech/denes_tts","creator_name":"Denes Mbezi","creator_url":"https://huggingface.co/Denhotech","description":"\n\t\n\t\t\n\t\tAudio-Text Dataset\n\t\n\nThis dataset contains 1 audio segments with their corresponding text.\n\n\t\n\t\t\n\t\tFormat\n\t\n\n\naudio: Audio files in WAV format\ntext: Corresponding text transcription\n\n\n\t\n\t\t\n\t\tCreated on\n\t\n\n2025-05-16 17:33:45\n","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Whisper_pharmacy","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ohkoonza/Whisper_pharmacy","creator_name":"chayungkoon puimtien","creator_url":"https://huggingface.co/ohkoonza","description":"ohkoonza/Whisper_pharmacy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ljs-mos-120","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stefantaubert/ljs-mos-120","creator_name":"Stefan Taubert","creator_url":"https://huggingface.co/stefantaubert","description":"\n\t\n\t\t\n\t\tLJS-MOS-120: Human MOS Ratings for 120 Samples of the LJ Speech Dataset\n\t\n\nLJS-MOS-120 provides Mean Opinion Score (MOS) ratings for 120 text-to-speech (TTS) samples based on the LJ Speech dataset. Each sample was rated by human annotators for intelligibility and naturalness across four experimental TTS conditions. The dataset follows the Tidy data format, with one row per rating per dimension.\nRatings were collected via Amazon Mechanical Turk (MTurk) in 2022. Each entry includes the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stefantaubert/ljs-mos-120.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"synthetic_audio_conversations_v2","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FINGU-AI/synthetic_audio_conversations_v2","creator_name":"GRINDA AI","creator_url":"https://huggingface.co/FINGU-AI","description":"FINGU-AI/synthetic_audio_conversations_v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Korean","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"malay-tts-tags","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doublesizebed/malay-tts-tags","creator_name":"chong","creator_url":"https://huggingface.co/doublesizebed","description":"doublesizebed/malay-tts-tags dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Malay","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MoCha-Generation-on-MoChaBench-Visualizer","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CongWei1230/MoCha-Generation-on-MoChaBench-Visualizer","creator_name":"Cong Wei","creator_url":"https://huggingface.co/CongWei1230","description":"This is just a Visualizer. Refer to this GitHub repo for detailed usage instructions: üîóMoChaBench.\n\n\n\n\t\n\t\t\n\t\tMoChaBench\n\t\n\nMoCha is a pioneering model for Dialogue-driven Movie Shot Generation.\n| üåêProject Page | üìñPaper | üîóGithub | ü§óDemo|\nWe introduce our evaluation benchmark \"MoChaBench\", as described in Section 4.3 of the MoCha Paper.\nMoChaBench is tailored for Dialogue-driven Movie Shot Generation ‚Äî generating movie shots from a combination of speech and text(speech + text ‚Üí video).\nIt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CongWei1230/MoCha-Generation-on-MoChaBench-Visualizer.","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","Text","Video"],"keywords_longer_than_N":true},
	{"name":"MoCha-Generation-on-MoChaBench-Visualizer","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CongWei1230/MoCha-Generation-on-MoChaBench-Visualizer","creator_name":"Cong Wei","creator_url":"https://huggingface.co/CongWei1230","description":"This is just a Visualizer. Refer to this GitHub repo for detailed usage instructions: üîóMoChaBench.\n\n\n\n\t\n\t\t\n\t\tMoChaBench\n\t\n\nMoCha is a pioneering model for Dialogue-driven Movie Shot Generation.\n| üåêProject Page | üìñPaper | üîóGithub | ü§óDemo|\nWe introduce our evaluation benchmark \"MoChaBench\", as described in Section 4.3 of the MoCha Paper.\nMoChaBench is tailored for Dialogue-driven Movie Shot Generation ‚Äî generating movie shots from a combination of speech and text(speech + text ‚Üí video).\nIt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CongWei1230/MoCha-Generation-on-MoChaBench-Visualizer.","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","Text","Video"],"keywords_longer_than_N":true},
	{"name":"malay-voice-test-1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ssyok/malay-voice-test-1","creator_name":"Daniel Sim","creator_url":"https://huggingface.co/ssyok","description":"ssyok/malay-voice-test-1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Malay","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"malay-voice-test-1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ssyok/malay-voice-test-1","creator_name":"Daniel Sim","creator_url":"https://huggingface.co/ssyok","description":"ssyok/malay-voice-test-1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Malay","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"commonvoiceaudi","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bolorjin/commonvoiceaudi","creator_name":"Bolorjin Batbaatar","creator_url":"https://huggingface.co/Bolorjin","description":"Bolorjin/commonvoiceaudi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"voice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Bolorjin/voice","creator_name":"Bolorjin Batbaatar","creator_url":"https://huggingface.co/Bolorjin","description":"Bolorjin/voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"plug_socket_single_2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_single_2","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 30,\n    \"total_frames\": 11536,\n    \"total_tasks\": 1,\n    \"total_videos\": 90,\n    \"total_audio\": 90,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:30\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_single_2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"plug_socket_single_2","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarolinePascal/plug_socket_single_2","creator_name":"Caroline Pascal","creator_url":"https://huggingface.co/CarolinePascal","description":"This dataset was created using LeRobot.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"so100\",\n    \"total_episodes\": 30,\n    \"total_frames\": 11536,\n    \"total_tasks\": 1,\n    \"total_videos\": 90,\n    \"total_audio\": 90,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:30\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarolinePascal/plug_socket_single_2.","first_N":5,"first_N_keywords":["robotics","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"tts_italian_may_7","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/tts_italian_may_7","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/tts_italian_may_7 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"indictts-malayalam","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kavyamanohar/indictts-malayalam","creator_name":"Kavya Manohar","creator_url":"https://huggingface.co/kavyamanohar","description":"The Malayalam Split of IndicTTS dataset. This is part of AI4Bharat Vistaar dataset.\n","first_N":5,"first_N_keywords":["Malayalam","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"2hr_myanmar_asr_raw_audio","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüá≤üá≤ Raw 2-Hour Burmese ASR Audio Dataset\n\t\n\nA ~2-hour Burmese (Myanmar language) ASR dataset featuring 1,612 audio clips with aligned transcripts, curated from official public-service educational broadcasts by FOEIM Academy ‚Äî a civic media arm of FOEIM.ORG, operating under the Myanmar National Unity Government (NUG).\nThis dataset is MIT-licensed as a public good ‚Äî a shared asset for the Burmese-speaking world. It serves speech technology, education, and cultural preservation efforts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"2hr_myanmar_asr_raw_audio","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüá≤üá≤ Raw 2-Hour Burmese ASR Audio Dataset\n\t\n\nA ~2-hour Burmese (Myanmar language) ASR dataset featuring 1,612 audio clips with aligned transcripts, curated from official public-service educational broadcasts by FOEIM Academy ‚Äî a civic media arm of FOEIM.ORG, operating under the Myanmar National Unity Government (NUG).\nThis dataset is MIT-licensed as a public good ‚Äî a shared asset for the Burmese-speaking world. It serves speech technology, education, and cultural preservation efforts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"2hr_myanmar_asr_raw_audio","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüá≤üá≤ Raw 2-Hour Burmese ASR Audio Dataset\n\t\n\nA ~2-hour Burmese (Myanmar language) ASR dataset featuring 1,612 audio clips with aligned transcripts, curated from official public-service educational broadcasts by FOEIM Academy ‚Äî a civic media arm of FOEIM.ORG, operating under the Myanmar National Unity Government (NUG).\nThis dataset is MIT-licensed as a public good ‚Äî a shared asset for the Burmese-speaking world. It serves speech technology, education, and cultural preservation efforts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"ASA-dataset","keyword":"audio-classification","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymousbyneurips/ASA-dataset","creator_name":"anonymous","creator_url":"https://huggingface.co/anonymousbyneurips","description":"üéß Auditory Scene Analysis 2 (ASA2) Dataset \n\nWe constructed a new dataset for multichannel USS and polyphonic audio classification tasks. The proposed dataset is designed to reflect various conditions, including moving sources with temporal onsets and offsets. For foreground sound sources, signals from 13 audio classes were selected from open-source databases (Pixabay¬π, FSD50K, Librispeech, MUSDB18, Vocalsound). These signals were resampled to 16 kHz and pre-processed by either padding zeros‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anonymousbyneurips/ASA-dataset.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"ASA-dataset","keyword":"audio-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymousbyneurips/ASA-dataset","creator_name":"anonymous","creator_url":"https://huggingface.co/anonymousbyneurips","description":"üéß Auditory Scene Analysis 2 (ASA2) Dataset \n\nWe constructed a new dataset for multichannel USS and polyphonic audio classification tasks. The proposed dataset is designed to reflect various conditions, including moving sources with temporal onsets and offsets. For foreground sound sources, signals from 13 audio classes were selected from open-source databases (Pixabay¬π, FSD50K, Librispeech, MUSDB18, Vocalsound). These signals were resampled to 16 kHz and pre-processed by either padding zeros‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anonymousbyneurips/ASA-dataset.","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian_backup","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_backup","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Backup\n\t\n\nThis is a backup dataset with Russian audio data, split into train_0 to train_49 for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\n\n\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian_backup\", split=\"train_0\")  # Or any train_X‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_backup.","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian_backup","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_backup","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Backup\n\t\n\nThis is a backup dataset with Russian audio data, split into train_0 to train_49 for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\n\n\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian_backup\", split=\"train_0\")  # Or any train_X‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_backup.","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"tts_italian_9_may","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/tts_italian_9_may","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/tts_italian_9_may dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Malayalam_Song","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sandhya2002/Malayalam_Song","creator_name":"Sandhya S","creator_url":"https://huggingface.co/Sandhya2002","description":"Sandhya2002/Malayalam_Song dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"may_10_italian_m","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/may_10_italian_m","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/may_10_italian_m dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Argentinian-audio-transcriptions","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LautaroOcho/Argentinian-audio-transcriptions","creator_name":"Lautaro Ochotorena","creator_url":"https://huggingface.co/LautaroOcho","description":"\n\t\n\t\t\n\t\tArgentinian audio transcriptions dataset\n\t\n\nThe dataset choosen contains audio recordings  of Argentinian speaker along with their corresponding transcription. It was obtain from this link.\nIt consists of 3,921 recordings from female speakers and 1,818 recordings from male speakers.\nThese recordings were downsampled to a 16‚ÄØkHz sample rate.\nThe spectrogram folder contains the spectrograms of the recordings, as well as spectrograms of augmented versions of those recordings.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LautaroOcho/Argentinian-audio-transcriptions.","first_N":5,"first_N_keywords":["translation","Spanish","cc-by-sa-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Argentinian-audio-transcriptions","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LautaroOcho/Argentinian-audio-transcriptions","creator_name":"Lautaro Ochotorena","creator_url":"https://huggingface.co/LautaroOcho","description":"\n\t\n\t\t\n\t\tArgentinian audio transcriptions dataset\n\t\n\nThe dataset choosen contains audio recordings  of Argentinian speaker along with their corresponding transcription. It was obtain from this link.\nIt consists of 3,921 recordings from female speakers and 1,818 recordings from male speakers.\nThese recordings were downsampled to a 16‚ÄØkHz sample rate.\nThe spectrogram folder contains the spectrograms of the recordings, as well as spectrograms of augmented versions of those recordings.\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LautaroOcho/Argentinian-audio-transcriptions.","first_N":5,"first_N_keywords":["translation","Spanish","cc-by-sa-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"stt_tts_deu","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chrde/stt_tts_deu","creator_name":"CD","creator_url":"https://huggingface.co/chrde","description":"Thorsten-Voice Dataset 2022.10 (Neutral)\nM√ºller, T. und Kreutz, D. (2022) ‚ÄûThorsten-Voice Dataset 2022.10‚Äú. Zenodo. doi: 10.5281/zenodo.7265581.\n","first_N":5,"first_N_keywords":["cc0-1.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"video-dataset","keyword":"voice-activity-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ProgramerSalar/video-dataset","creator_name":"ProgramerSalar","creator_url":"https://huggingface.co/ProgramerSalar","description":"\n\t\n\t\t\n\t\tVideo Dataset on Hugging Face\n\t\n\nThis repository hosts the  video dataset, a widely used benchmark dataset for human action recognition in videos. The dataset has been processed and uploaded to the Hugging Face Hub for easy access, sharing, and integration into machine learning workflows.\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe  dataset is a large-scale video dataset designed for action recognition tasks. It contains 13,320 video clips across 101 action categories, making it one of the most‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ProgramerSalar/video-dataset.","first_N":5,"first_N_keywords":["text-to-video","video-classification","video-text-to-text","voice-activity-detection","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/audiobooks","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tCrimean Tatar Audiobooks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCrimean Tatar Audiobooks is a speech dataset sourced from different sources (public radio stations/youtube channels) containing audiobooks in Crimean Tatar. The dataset comprises recordings of different native fiction books, all read by a single female speaker (for now). The dataset is intended for text-to-speech (TTS) research and development in the Crimean Tatar language. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/audiobooks.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Crimean Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/audiobooks","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tCrimean Tatar Audiobooks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCrimean Tatar Audiobooks is a speech dataset sourced from different sources (public radio stations/youtube channels) containing audiobooks in Crimean Tatar. The dataset comprises recordings of different native fiction books, all read by a single female speaker (for now). The dataset is intended for text-to-speech (TTS) research and development in the Crimean Tatar language. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/audiobooks.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Crimean Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/audiobooks","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tCrimean Tatar Audiobooks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCrimean Tatar Audiobooks is a speech dataset sourced from different sources (public radio stations/youtube channels) containing audiobooks in Crimean Tatar. The dataset comprises recordings of different native fiction books, all read by a single female speaker (for now). The dataset is intended for text-to-speech (TTS) research and development in the Crimean Tatar language. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/audiobooks.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Crimean Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NPTL_SPEAKER_DATASETS","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FariqF/NPTL_SPEAKER_DATASETS","creator_name":"Fariq Rahman","creator_url":"https://huggingface.co/FariqF","description":"FariqF/NPTL_SPEAKER_DATASETS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"audio_clone","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QyQy/audio_clone","creator_name":"Huy Le","creator_url":"https://huggingface.co/QyQy","description":"QyQy/audio_clone dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"JALMBench","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AnonymousUser000/JALMBench","creator_name":"Anonymous User","creator_url":"https://huggingface.co/AnonymousUser000","description":"\n\t\n\t\t\n\t\tAbout the Dataset\n\t\n\nüì¶ JALMBench contains 51,381 adversarial audio samples and 2,200 text prompts to benchmark jailbreak attacks against audio-language models (ALMs). It consists of three main categories:\n\nüî• Harmful Query Category:Includes 50 harmful text queries ($T_{Harm}$), their corresponding audio ($A_{Harm}$), and a diverse audio set ($A_{Div}$) with 9 languages, 2 genders, and 3 accents synthesized via Google TTS.\n\nüìí Text-Transferred Jailbreak Category:Features adversarial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AnonymousUser000/JALMBench.","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"russian_librispeech","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/istupakov/russian_librispeech","creator_name":"Ilya Stupakov","creator_url":"https://huggingface.co/istupakov","description":"\n\t\n\t\t\n\t\tRussian LibriSpeech (RuLS)\n\t\n\nIdentifier: SLR96 from openslr.org\nSummary: This dataset is based on LibriVox audiobooks\nCategory: Speech\nLicense: The dataset is Public Domain in the USA.\nAbout this resource:\nRussian LibriSpeech (RuLS) dataset is based on LibriVox's public domain audio books (see BOOKS.TXT for the list of included books) and contains about 98 hours of audio data.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"tufs_malay","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Raz/tufs_malay","creator_name":"Raz Hoe","creator_url":"https://huggingface.co/Raz","description":"\n\t\n\t\t\n\t\tTUFS Bahasa Malaysia Speech Dataset (ms)\n\t\n\nThis dataset originated from TUFS Open Language Resources provided by the Tokyo University of Foreign Studies (TUFS).\nIt contains audio recordings and transcriptions of Bahasa Malaysia speech materials intended for language learning and research.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset includes:\n\nAudio files in .mp3 format\nMachine-readable transcriptions in a structured prompt format\nMetadata such as duration and unique identifiers\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Raz/tufs_malay.","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TST_Input_DatasetCombine","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/archivartaunik/TST_Input_DatasetCombine","creator_name":"vartaunik","creator_url":"https://huggingface.co/archivartaunik","description":"archivartaunik/TST_Input_DatasetCombine dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Belarusian","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"western_poe_karen_asr","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/western_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Western Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tWestern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned transcriptions in the Western Poe Karen language (also known in linguistic literature as Western Pwo or Delta Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in the Ayeyarwady Delta region of Myanmar. Although linguists commonly refer to this language as Western Pwo Karen, the community and this project prefer the spelling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/western_poe_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"western_poe_karen_asr","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/western_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Western Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tWestern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned transcriptions in the Western Poe Karen language (also known in linguistic literature as Western Pwo or Delta Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in the Ayeyarwady Delta region of Myanmar. Although linguists commonly refer to this language as Western Pwo Karen, the community and this project prefer the spelling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/western_poe_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"western_poe_karen_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/western_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Western Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tWestern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned transcriptions in the Western Poe Karen language (also known in linguistic literature as Western Pwo or Delta Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in the Ayeyarwady Delta region of Myanmar. Although linguists commonly refer to this language as Western Pwo Karen, the community and this project prefer the spelling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/western_poe_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"western_poe_karen_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/western_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Western Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tWestern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned transcriptions in the Western Poe Karen language (also known in linguistic literature as Western Pwo or Delta Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in the Ayeyarwady Delta region of Myanmar. Although linguists commonly refer to this language as Western Pwo Karen, the community and this project prefer the spelling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/western_poe_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"sagaw_karen_asr","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/sagaw_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Sagaw Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tSagaw Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Sagaw Karen language (ISO 639-3: ksw), a major Sgaw Karenic language spoken throughout southern and eastern Myanmar. The language is sometimes also referred to as Sgaw Karen or Sakaw Karen in English transliterations.\nAll audio segments in this dataset were sourced from publicly available news broadcasts published by PVTV‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/sagaw_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"sagaw_karen_asr","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/sagaw_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Sagaw Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tSagaw Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Sagaw Karen language (ISO 639-3: ksw), a major Sgaw Karenic language spoken throughout southern and eastern Myanmar. The language is sometimes also referred to as Sgaw Karen or Sakaw Karen in English transliterations.\nAll audio segments in this dataset were sourced from publicly available news broadcasts published by PVTV‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/sagaw_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"sagaw_karen_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/sagaw_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Sagaw Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tSagaw Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Sagaw Karen language (ISO 639-3: ksw), a major Sgaw Karenic language spoken throughout southern and eastern Myanmar. The language is sometimes also referred to as Sgaw Karen or Sakaw Karen in English transliterations.\nAll audio segments in this dataset were sourced from publicly available news broadcasts published by PVTV‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/sagaw_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"sagaw_karen_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/sagaw_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Sagaw Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tSagaw Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Sagaw Karen language (ISO 639-3: ksw), a major Sgaw Karenic language spoken throughout southern and eastern Myanmar. The language is sometimes also referred to as Sgaw Karen or Sakaw Karen in English transliterations.\nAll audio segments in this dataset were sourced from publicly available news broadcasts published by PVTV‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/sagaw_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"eastern_poe_karen_asr","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/eastern_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Eastern Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tEastern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Eastern Poe Karen language (a regional variety of Eastern Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in Mon State and Kayin State in southeastern Myanmar. While linguistically described as Eastern Pwo Karen, the community and this project prefer the term Poe as a community-endorsed spelling.\nAll audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/eastern_poe_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"eastern_poe_karen_asr","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/eastern_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Eastern Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tEastern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Eastern Poe Karen language (a regional variety of Eastern Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in Mon State and Kayin State in southeastern Myanmar. While linguistically described as Eastern Pwo Karen, the community and this project prefer the term Poe as a community-endorsed spelling.\nAll audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/eastern_poe_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"eastern_poe_karen_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/eastern_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Eastern Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tEastern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Eastern Poe Karen language (a regional variety of Eastern Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in Mon State and Kayin State in southeastern Myanmar. While linguistically described as Eastern Pwo Karen, the community and this project prefer the term Poe as a community-endorsed spelling.\nAll audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/eastern_poe_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"eastern_poe_karen_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/eastern_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Eastern Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tEastern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Eastern Poe Karen language (a regional variety of Eastern Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in Mon State and Kayin State in southeastern Myanmar. While linguistically described as Eastern Pwo Karen, the community and this project prefer the term Poe as a community-endorsed spelling.\nAll audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/eastern_poe_karen_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"zomi_asr","keyword":"audio-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/zomi_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Zomi language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tZomi ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Zomi language ‚Äî a collective ethnolinguistic identity adopted by some Kuki-Chin language-speaking communities in Myanmar and India. The term Zomi means \"Zo people\", derived from the root word Zo (ancestral identity) and mi meaning \"people.\" While originally coined to encompass all Zo-related communities, usage of the term varies regionally and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/zomi_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"zomi_asr","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/zomi_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Zomi language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tZomi ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Zomi language ‚Äî a collective ethnolinguistic identity adopted by some Kuki-Chin language-speaking communities in Myanmar and India. The term Zomi means \"Zo people\", derived from the root word Zo (ancestral identity) and mi meaning \"people.\" While originally coined to encompass all Zo-related communities, usage of the term varies regionally and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/zomi_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"zomi_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/zomi_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Zomi language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tZomi ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Zomi language ‚Äî a collective ethnolinguistic identity adopted by some Kuki-Chin language-speaking communities in Myanmar and India. The term Zomi means \"Zo people\", derived from the root word Zo (ancestral identity) and mi meaning \"people.\" While originally coined to encompass all Zo-related communities, usage of the term varies regionally and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/zomi_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"zomi_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/zomi_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"This is the first public Zomi language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tZomi ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Zomi language ‚Äî a collective ethnolinguistic identity adopted by some Kuki-Chin language-speaking communities in Myanmar and India. The term Zomi means \"Zo people\", derived from the root word Zo (ancestral identity) and mi meaning \"people.\" While originally coined to encompass all Zo-related communities, usage of the term varies regionally and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/zomi_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"June-14-IT","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/June-14-IT","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/June-14-IT dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"c_w","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/01gumano1d/c_w","creator_name":"gumano1d","creator_url":"https://huggingface.co/01gumano1d","description":"01gumano1d/c_w dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Audio","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"aus_voice4","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dst19/aus_voice4","creator_name":"Sow Behl","creator_url":"https://huggingface.co/dst19","description":"\n\t\n\t\t\n\t\tOrpheus TTS Dataset\n\t\n\nThis dataset is prepared for training Orpheus TTS models.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal samples: 564\nAudio sampling rate: 44100 Hz\nFormat: Single-speaker TTS dataset with 'text' and 'audio' columns\n\nThis dataset is specifically formatted for Orpheus TTS single-speaker models. It includes:\n\nText content in the 'text' column\nAudio files properly structured for training\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided in multiple formats:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dst19/aus_voice4.","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"css10-ja-ljspeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/css10-ja-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"\n\t\n\t\t\n\t\tCSS100-LJSpeech (Japanese / Meian)\n\t\n\ncss100-ljspeech „ÅØ„ÄÅPark et al. „ÅåÂÖ¨Èñã„Åó„Åü CSS10 Êó•Êú¨Ë™û„Ç≥„Éº„Éë„ÇπÔºàÊòéÊöóÔºâ„Çí„ÄÅLJ Speech ‰∫íÊèõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà (id|text & wavs/*.wav) „Å∏Â§âÊèõ„Åó„ÅüÊ¥æÁîü„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Éº„ÇøÊ¶ÇË¶Å\n\t\n\n\n\t\n\t\t\nÈ†ÖÁõÆ\nÂÄ§\n\n\n\t\t\nË©±ËÄÖ\n1 (ekzemplaro)\n\n\nÈü≥Â£∞Êï∞\n6,841\n\n\nÂêàË®àÊôÇÈñì\nÁ¥Ñ 15 ÊôÇÈñì\n\n\n„Çµ„É≥„Éó„É™„É≥„Ç∞„É¨„Éº„Éà\n22,050 Hz\n\n\n„ÉÜ„Ç≠„Çπ„ÉàË®ÄË™û\nÊó•Êú¨Ë™û\n\n\n„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n``id\n\n\n\t\n\n\n\t\n\t\t\n\t\t„Éï„Ç°„Ç§„É´ÊßãÊàê\n\t\n\ncss100-ljspeech/\n‚îú‚îÄ‚îÄ metadata.csv   # 2 Âàó (id|text)\n‚îî‚îÄ‚îÄ wavs/\n    ‚îú‚îÄ‚îÄ meian_0000.wav\n    ‚îú‚îÄ‚îÄ meian_0001.wav\n    ‚îî‚îÄ‚îÄ ...\n\n\n\t\n\t\t\n\t\t‰ΩøÁî®‰æã (ü§ó Datasets)\n\t\n\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ja-ljspeech.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"css10-ja-ljspeech","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/css10-ja-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"\n\t\n\t\t\n\t\tCSS100-LJSpeech (Japanese / Meian)\n\t\n\ncss100-ljspeech „ÅØ„ÄÅPark et al. „ÅåÂÖ¨Èñã„Åó„Åü CSS10 Êó•Êú¨Ë™û„Ç≥„Éº„Éë„ÇπÔºàÊòéÊöóÔºâ„Çí„ÄÅLJ Speech ‰∫íÊèõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà (id|text & wavs/*.wav) „Å∏Â§âÊèõ„Åó„ÅüÊ¥æÁîü„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Éº„ÇøÊ¶ÇË¶Å\n\t\n\n\n\t\n\t\t\nÈ†ÖÁõÆ\nÂÄ§\n\n\n\t\t\nË©±ËÄÖ\n1 (ekzemplaro)\n\n\nÈü≥Â£∞Êï∞\n6,841\n\n\nÂêàË®àÊôÇÈñì\nÁ¥Ñ 15 ÊôÇÈñì\n\n\n„Çµ„É≥„Éó„É™„É≥„Ç∞„É¨„Éº„Éà\n22,050 Hz\n\n\n„ÉÜ„Ç≠„Çπ„ÉàË®ÄË™û\nÊó•Êú¨Ë™û\n\n\n„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n``id\n\n\n\t\n\n\n\t\n\t\t\n\t\t„Éï„Ç°„Ç§„É´ÊßãÊàê\n\t\n\ncss100-ljspeech/\n‚îú‚îÄ‚îÄ metadata.csv   # 2 Âàó (id|text)\n‚îî‚îÄ‚îÄ wavs/\n    ‚îú‚îÄ‚îÄ meian_0000.wav\n    ‚îú‚îÄ‚îÄ meian_0001.wav\n    ‚îî‚îÄ‚îÄ ...\n\n\n\t\n\t\t\n\t\t‰ΩøÁî®‰æã (ü§ó Datasets)\n\t\n\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ja-ljspeech.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"Rural_Women_Bhojpuri","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Rural_Women_Bhojpuri","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tRural Bhojpuri ASR Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is curated to foster the development of inclusive Automatic Speech Recognition (ASR) systems, with a special focus on the underrepresented voices of rural Bhojpuri women. It contains audio clips in both Bhojpuri and Hindi, collected from real-world and synthetic sources, designed to train and evaluate ASR models that can accurately recognize diverse speech patterns.\nThis work is part of the research presented in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Rural_Women_Bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bhojpuri","Hindi","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part002","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 2 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 2 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part005","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 5 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 5 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"news_youtube_uzbek_speech_dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/islomov/news_youtube_uzbek_speech_dataset","creator_name":"Sardor Islomov","creator_url":"https://huggingface.co/islomov","description":"\n\t\n\t\t\n\t\tNews Youtube Uzbek Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio clips and their corresponding transcriptions in the Uzbek language with differenent dialects. The data was collected from publicly available news videos on YouTube. It is designed for training and evaluating Automatic Speech Recognition (ASR) models.\nMost of the content comes from the Kunuz, Qalampir YouTube channels. The data was transcribed using Gemini 2.5 Pro and was intelligently‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/islomov/news_youtube_uzbek_speech_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"nb-librivox","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/nb-librivox","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\n\t\n\t\t\n\t\tüìÑ NB-LibriVox\n\t\n\nA high-quality Norwegian text-to-speech (TTS) dataset derived from LibriVox public domain audiobooks. It includes audio clips with pseudo-aligned transcripts and punctuation, curated by the National Library of Norway for speech synthesis and ASR research.\n\n\n\t\n\t\t\n\t\tüìÇ Dataset Overview\n\t\n\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nfile_name\nAudio file name in .wav format\n\n\nid\nUnique identifier for each utterance/sample\n\n\ntext\nTranscript automatically generated using NB-Whisper Large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/nb-librivox.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Norwegian","Norwegian Bokm√•l","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"italian_june_17","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/italian_june_17","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/italian_june_17 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"spanish_17_june","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/spanish_17_june","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/spanish_17_june dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Seamless_Dummy_Dataset_Fixed_3","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rajjanardhan00/Seamless_Dummy_Dataset_Fixed_3","creator_name":"Raj Janardhan","creator_url":"https://huggingface.co/rajjanardhan00","description":"\n\t\n\t\t\n\t\tMMLU-Pro json\n\t\n\nThis is a reupload of MMLU-Pro in json format. Please, refer to the original dataset for details.\n","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"InstructTTSEval","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CaasiHUANG/InstructTTSEval","creator_name":"Kexin Huang","creator_url":"https://huggingface.co/CaasiHUANG","description":"\n\t\n\t\t\n\t\tInstructTTSEval\n\t\n\nInstructTTSEval is a comprehensive benchmark designed to evaluate Text-to-Speech (TTS) systems' ability to follow complex natural-language style instructions. The dataset provides a hierarchical evaluation framework with three progressively challenging tasks that test both low-level acoustic control and high-level style generalization capabilities.\n\nGithub Repository: https://github.com/KexinHUANG19/InstructTTSEval\nPaper: InstructTTSEval: Benchmarking Complex‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaasiHUANG/InstructTTSEval.","first_N":5,"first_N_keywords":["text-to-speech","English","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"InstructTTSEval","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CaasiHUANG/InstructTTSEval","creator_name":"Kexin Huang","creator_url":"https://huggingface.co/CaasiHUANG","description":"\n\t\n\t\t\n\t\tInstructTTSEval\n\t\n\nInstructTTSEval is a comprehensive benchmark designed to evaluate Text-to-Speech (TTS) systems' ability to follow complex natural-language style instructions. The dataset provides a hierarchical evaluation framework with three progressively challenging tasks that test both low-level acoustic control and high-level style generalization capabilities.\n\nGithub Repository: https://github.com/KexinHUANG19/InstructTTSEval\nPaper: InstructTTSEval: Benchmarking Complex‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaasiHUANG/InstructTTSEval.","first_N":5,"first_N_keywords":["text-to-speech","English","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"swahili-speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stem-content-ai-project/swahili-speech","creator_name":"Harnessing AI Project","creator_url":"https://huggingface.co/stem-content-ai-project","description":"\n\t\n\t\t\n\t\tSwahili Speech-to-Text Dataset\n\t\n\nThis dataset contains paired audio and text data for training and evaluating speech-to-text models in Swahili. The audio files have been processed to remove silence, converted to 44.1kHz mono FLAC format, and are paired with corresponding transcriptions.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudio_*.flac: Audio files in FLAC format, named by their corresponding text corpus ID.\nmetadata.jsonl: JSON Lines file with metadata for each audio-text pair. Each line is a JSON‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stem-content-ai-project/swahili-speech.","first_N":5,"first_N_keywords":["text-to-speech","Swahili","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"CommonVoice-17.0-Spanish-Filtered","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thermostatic/CommonVoice-17.0-Spanish-Filtered","creator_name":"Irving Ernesto Quezada Ram√≠rez","creator_url":"https://huggingface.co/Thermostatic","description":"Thermostatic/CommonVoice-17.0-Spanish-Filtered dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Shart","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunit17/Shart","creator_name":"Richard Barbuto","creator_url":"https://huggingface.co/kunit17","description":"kunit17/Shart dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"ASMR-Archive-Processed","keyword":"audio","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OmniAICreator/ASMR-Archive-Processed","creator_name":"OmniAICreator","creator_url":"https://huggingface.co/OmniAICreator","description":"\n\t\n\t\t\n\t\tASMR-Archive-Processed (WIP)\n\t\n\n\nWork in Progress ‚Äî expect breaking changes while the pipeline and data layout stabilize.\n\nThis dataset contains ASMR audio data sourced from DeliberatorArchiver/asmr-archive-data-01 and DeliberatorArchiver/asmr-archive-data-02, which has undergone the following preprocessing steps:\n\n\n\t\n\t\t\n\t\n\t\n\t\tPreprocessing Steps\n\t\n\n\nLow-Quality Data Filtering:\nAudio files are filtered to remove low-quality samples. This process checks for:\n\nUndesirable codecs (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/ASMR-Archive-Processed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Japanese","agpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ASMR-Archive-Processed","keyword":"audio","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OmniAICreator/ASMR-Archive-Processed","creator_name":"OmniAICreator","creator_url":"https://huggingface.co/OmniAICreator","description":"\n\t\n\t\t\n\t\tASMR-Archive-Processed (WIP)\n\t\n\n\nWork in Progress ‚Äî expect breaking changes while the pipeline and data layout stabilize.\n\nThis dataset contains ASMR audio data sourced from DeliberatorArchiver/asmr-archive-data-01 and DeliberatorArchiver/asmr-archive-data-02, which has undergone the following preprocessing steps:\n\n\n\t\n\t\t\n\t\n\t\n\t\tPreprocessing Steps\n\t\n\n\nLow-Quality Data Filtering:\nAudio files are filtered to remove low-quality samples. This process checks for:\n\nUndesirable codecs (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/ASMR-Archive-Processed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Japanese","agpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ASMR-Archive-Processed","keyword":"voice","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OmniAICreator/ASMR-Archive-Processed","creator_name":"OmniAICreator","creator_url":"https://huggingface.co/OmniAICreator","description":"\n\t\n\t\t\n\t\tASMR-Archive-Processed (WIP)\n\t\n\n\nWork in Progress ‚Äî expect breaking changes while the pipeline and data layout stabilize.\n\nThis dataset contains ASMR audio data sourced from DeliberatorArchiver/asmr-archive-data-01 and DeliberatorArchiver/asmr-archive-data-02, which has undergone the following preprocessing steps:\n\n\n\t\n\t\t\n\t\n\t\n\t\tPreprocessing Steps\n\t\n\n\nLow-Quality Data Filtering:\nAudio files are filtered to remove low-quality samples. This process checks for:\n\nUndesirable codecs (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/ASMR-Archive-Processed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Japanese","agpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"swahili-words-speech-text-parallel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tSwahili Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 411048 parallel speech-text pairs for Swahili, a widely spoken language in East Africa. The dataset consists of audio recordings paired with corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Swahili - sw\nTask: Speech Recognition, Text-to-Speech\nSize: 411048 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"xenocanto-two-species-3","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/capa2000/xenocanto-two-species-3","creator_name":"Christian Palma","creator_url":"https://huggingface.co/capa2000","description":"capa2000/xenocanto-two-species-3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"xenocanto-binary","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/capa2000/xenocanto-binary","creator_name":"Christian Palma","creator_url":"https://huggingface.co/capa2000","description":"capa2000/xenocanto-binary dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"mrtv_news_voices","keyword":"audio-classification","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/mrtv_news_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Overview\n\t\n\nMRTV Voices is a large-scale Burmese speech dataset built from publicly available news broadcasts and programs aired on Myanma Radio and Television (MRTV) ‚Äî the official state-run media channel of Myanmar.\n\nüéôÔ∏è It contains over 130,000 short audio clips (‚âà117 hours) with aligned transcripts derived from auto-generated subtitles.\n\nThis dataset captures:\n\nFormal Burmese used in government bulletins and official reports  \nClear pronunciation, enunciation, and pacing ‚Äî‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/mrtv_news_voices.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mrtv_news_voices","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/mrtv_news_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Overview\n\t\n\nMRTV Voices is a large-scale Burmese speech dataset built from publicly available news broadcasts and programs aired on Myanma Radio and Television (MRTV) ‚Äî the official state-run media channel of Myanmar.\n\nüéôÔ∏è It contains over 130,000 short audio clips (‚âà117 hours) with aligned transcripts derived from auto-generated subtitles.\n\nThis dataset captures:\n\nFormal Burmese used in government bulletins and official reports  \nClear pronunciation, enunciation, and pacing ‚Äî‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/mrtv_news_voices.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mrtv_news_voices","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/mrtv_news_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Overview\n\t\n\nMRTV Voices is a large-scale Burmese speech dataset built from publicly available news broadcasts and programs aired on Myanma Radio and Television (MRTV) ‚Äî the official state-run media channel of Myanmar.\n\nüéôÔ∏è It contains over 130,000 short audio clips (‚âà117 hours) with aligned transcripts derived from auto-generated subtitles.\n\nThis dataset captures:\n\nFormal Burmese used in government bulletins and official reports  \nClear pronunciation, enunciation, and pacing ‚Äî‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/mrtv_news_voices.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"triage_transcriptions","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuriyvnv/triage_transcriptions","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","description":"\n\t\n\t\t\n\t\tMedical Triage Transcriptions Dataset\n\t\n\n\n\t\n\t\t\n\t\tCredits and Acknowledgments\n\t\n\nThis dataset is based on the original NLie2/TRIAGE dataset. We thank the original creators for providing the foundational triage classification data that enabled this synthetic transcription generation.\nOriginal Dataset: NLie2/TRIAGELicense: Please refer to the original dataset license  \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetic medical triage transcriptions generated from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/triage_transcriptions.","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"triage_transcriptions","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuriyvnv/triage_transcriptions","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","description":"\n\t\n\t\t\n\t\tMedical Triage Transcriptions Dataset\n\t\n\n\n\t\n\t\t\n\t\tCredits and Acknowledgments\n\t\n\nThis dataset is based on the original NLie2/TRIAGE dataset. We thank the original creators for providing the foundational triage classification data that enabled this synthetic transcription generation.\nOriginal Dataset: NLie2/TRIAGELicense: Please refer to the original dataset license  \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetic medical triage transcriptions generated from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/triage_transcriptions.","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_gemini","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - Google Gemini 2.0 Flash\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando Google Gemini 2.0 Flash.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: Google Gemini 2.0 Flash\nPre√ßo: $0.075/1M tokens\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo de IA multimodal avan√ßado da Google com capacidades de an√°lise contextual de √°udio.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_gemini","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - Google Gemini 2.0 Flash\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando Google Gemini 2.0 Flash.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: Google Gemini 2.0 Flash\nPre√ßo: $0.075/1M tokens\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo de IA multimodal avan√ßado da Google com capacidades de an√°lise contextual de √°udio.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_deepgram","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - Deepgram Nova 2\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando Deepgram Nova 2.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: Deepgram Nova 2\nPre√ßo: $0.0043/minuto\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo de transcri√ß√£o em tempo real da Deepgram com baixa lat√™ncia.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Estat√≠sticas\n\t\n\n\nTotal de amostras: 198‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_deepgram","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - Deepgram Nova 2\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando Deepgram Nova 2.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: Deepgram Nova 2\nPre√ßo: $0.0043/minuto\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo de transcri√ß√£o em tempo real da Deepgram com baixa lat√™ncia.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Estat√≠sticas\n\t\n\n\nTotal de amostras: 198‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"agentCourse_storage","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/person9601/agentCourse_storage","creator_name":"Carl","creator_url":"https://huggingface.co/person9601","description":"storage for gaia question files\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"CHATTISGARHI-TTS-F","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sameerbanchhor/CHATTISGARHI-TTS-F","creator_name":"sameer banchhor","creator_url":"https://huggingface.co/sameerbanchhor","description":"sameerbanchhor/CHATTISGARHI-TTS-F dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"vctk","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jspaulsen/vctk","creator_name":"Jacob Paulsen","creator_url":"https://huggingface.co/jspaulsen","description":"\n\t\n\t\t\n\t\tVCTK\n\t\n\nThis is a processed clone of the VCTK dataset with leading and trailing silence removed using Silero VAD. A fixed 25‚ÄØms of padding has been added to both ends of each audio clip to (hopefully) imrprove training and finetuning.\nThe original dataset is available at: https://datashare.ed.ac.uk/handle/10283/3443.\n\n\t\n\t\t\n\t\tReproducing\n\t\n\nThis repository notably lacks a requirements.txt file. There's likely a missing dependency or two, but roughly:\npydub\ntqdm\ntorch\ntorchaudio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jspaulsen/vctk.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"vctk","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jspaulsen/vctk","creator_name":"Jacob Paulsen","creator_url":"https://huggingface.co/jspaulsen","description":"\n\t\n\t\t\n\t\tVCTK\n\t\n\nThis is a processed clone of the VCTK dataset with leading and trailing silence removed using Silero VAD. A fixed 25‚ÄØms of padding has been added to both ends of each audio clip to (hopefully) imrprove training and finetuning.\nThe original dataset is available at: https://datashare.ed.ac.uk/handle/10283/3443.\n\n\t\n\t\t\n\t\tReproducing\n\t\n\nThis repository notably lacks a requirements.txt file. There's likely a missing dependency or two, but roughly:\npydub\ntqdm\ntorch\ntorchaudio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jspaulsen/vctk.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"vagla-speech-text-parallel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tVagla Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 48605 parallel speech-text pairs for Vagla, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vagla - vag\nTask: Speech Recognition, Text-to-Speech\nSize: 48605 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vagla"],"keywords_longer_than_N":true},
	{"name":"all-words-in-english-with-pink-trombone","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mcamara/all-words-in-english-with-pink-trombone","creator_name":"Mateo C√°mara","creator_url":"https://huggingface.co/mcamara","description":"\n\t\n\t\t\n\t\tDataset Card for Pink Trombone English Phonetic & Landmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains audio samples of English words generated by the Pink Trombone, a popular open-source vocal tract synthesizer. The primary goal of this dataset is to provide a clean, large-scale resource linking phonetic sequences to both their acoustic realization and the underlying articulatory landmarks.\nEach sample in the dataset corresponds to a word from the Oxford English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mcamara/all-words-in-english-with-pink-trombone.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"all-words-in-english-with-pink-trombone","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mcamara/all-words-in-english-with-pink-trombone","creator_name":"Mateo C√°mara","creator_url":"https://huggingface.co/mcamara","description":"\n\t\n\t\t\n\t\tDataset Card for Pink Trombone English Phonetic & Landmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains audio samples of English words generated by the Pink Trombone, a popular open-source vocal tract synthesizer. The primary goal of this dataset is to provide a clean, large-scale resource linking phonetic sequences to both their acoustic realization and the underlying articulatory landmarks.\nEach sample in the dataset corresponds to a word from the Oxford English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mcamara/all-words-in-english-with-pink-trombone.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"yoruba-speech-text-parallel","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tYoruba Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1647022 parallel speech-text pairs for Yoruba, a language spoken primarily in Nigeria and other West African countries. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Yoruba - yo\nTask: Speech Recognition, Text-to-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"emouerj-sed","keyword":"audio-classification","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdeoyeLadele/emouerj-sed","creator_name":"Adeoye Sunday Ladele","creator_url":"https://huggingface.co/AdeoyeLadele","description":"\n\t\n\t\t\n\t\tDataset Card for \"emouerj-sed\"\n\t\n\nThis Dataset is adapted from emoUERJ for the Speech Emotion Diarization Task.\nThe dataset is created following the recipe for described in the (SPEECH EMOTION DIARIZATION: WHICH EMOTION APPEARS WHEN?)[https://arxiv.org/pdf/2306.12991] paper.\n","first_N":5,"first_N_keywords":["audio-classification","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"emouerj-sed","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdeoyeLadele/emouerj-sed","creator_name":"Adeoye Sunday Ladele","creator_url":"https://huggingface.co/AdeoyeLadele","description":"\n\t\n\t\t\n\t\tDataset Card for \"emouerj-sed\"\n\t\n\nThis Dataset is adapted from emoUERJ for the Speech Emotion Diarization Task.\nThe dataset is created following the recipe for described in the (SPEECH EMOTION DIARIZATION: WHICH EMOTION APPEARS WHEN?)[https://arxiv.org/pdf/2306.12991] paper.\n","first_N":5,"first_N_keywords":["audio-classification","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Silvar-Med","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hanhpt23/Silvar-Med","creator_name":"Tan-Hanh Pham","creator_url":"https://huggingface.co/Hanhpt23","description":"Hanhpt23/Silvar-Med dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Audio","Image"],"keywords_longer_than_N":true},
	{"name":"Arknights_Theresa","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RyrieNorth/Arknights_Theresa","creator_name":"NorthSky","creator_url":"https://huggingface.co/RyrieNorth","description":"RyrieNorth/Arknights_Theresa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","soundfolder","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"NgocHuyenViVoice","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thangnzt/NgocHuyenViVoice","creator_name":"Thang Nguyen Duc","creator_url":"https://huggingface.co/thangnzt","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thangnzt/NgocHuyenViVoice.","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"emotion-tagged-small-v1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenitsu09/emotion-tagged-small-v1","creator_name":"Himanshu Gangwar","creator_url":"https://huggingface.co/zenitsu09","description":"zenitsu09/emotion-tagged-small-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"dubs","keyword":"audio-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/dubs","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"yasalma/dubs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"dubs","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/dubs","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"yasalma/dubs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"dubs","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/dubs","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"yasalma/dubs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"nepali-tts-streamable","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biplov-thapa/nepali-tts-streamable","creator_name":"Biplov Thapa","creator_url":"https://huggingface.co/biplov-thapa","description":"biplov-thapa/nepali-tts-streamable dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"W2WMovie-Voice-2","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thanghp456/W2WMovie-Voice-2","creator_name":"Thangh Nguyen Duc","creator_url":"https://huggingface.co/thanghp456","description":"thanghp456/W2WMovie-Voice-2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Vietnamese","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"jess-voice-tts-dataset","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dst19/jess-voice-tts-dataset","creator_name":"Sow Behl","creator_url":"https://huggingface.co/dst19","description":"\n\t\n\t\t\n\t\tjess_voice_tts\n\t\n\nThis dataset contains TTS training data generated from text using Play.ht.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal samples: 137\nAudio sampling rate: 48000 Hz\nFormat: Single-speaker TTS dataset with 'text' and 'audio' columns\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"dst19/jess-voice-tts-dataset\")\n\n","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"CREMAD-emotion-transcribed","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenitsu09/CREMAD-emotion-transcribed","creator_name":"Himanshu Gangwar","creator_url":"https://huggingface.co/zenitsu09","description":"zenitsu09/CREMAD-emotion-transcribed dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"samples_S_straat_20250704","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanSounds/samples_S_straat_20250704","creator_name":"Sensemakers Amsterdam UrbanSounds repo","creator_url":"https://huggingface.co/UrbanSounds","description":"UrbanSounds/samples_S_straat_20250704 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"samromur_asr","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidErikMollberg/samromur_asr","creator_name":"David Erik Mollberg","creator_url":"https://huggingface.co/DavidErikMollberg","description":"\n\t\n\t\t\n\t\tDataset Card for samromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a modfied copy of the dataset from The Language and Voice Laboratory in RU.\nThis is the first release of the Samr√≥mur Icelandic Speech corpus that contains 100.000 validated utterances.\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab at the Reykjavik University, in cooperation with Almannar√≥mur, Center for Language Technology.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe audio is in Icelandic.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DavidErikMollberg/samromur_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"samromur_asr","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidErikMollberg/samromur_asr","creator_name":"David Erik Mollberg","creator_url":"https://huggingface.co/DavidErikMollberg","description":"\n\t\n\t\t\n\t\tDataset Card for samromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a modfied copy of the dataset from The Language and Voice Laboratory in RU.\nThis is the first release of the Samr√≥mur Icelandic Speech corpus that contains 100.000 validated utterances.\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab at the Reykjavik University, in cooperation with Almannar√≥mur, Center for Language Technology.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe audio is in Icelandic.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DavidErikMollberg/samromur_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"SpokenPortugueseGeographicalSocialVarieties_splits","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jarbas/SpokenPortugueseGeographicalSocialVarieties_splits","creator_name":"Casimiro Ferreira","creator_url":"https://huggingface.co/Jarbas","description":"sentence splits from SpokenPortugueseGeographicalSocialVarieties generated via forced alignment\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"OpenS2S_Datasets","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CASIA-LM/OpenS2S_Datasets","creator_name":"CASIA-LM","creator_url":"https://huggingface.co/CASIA-LM","description":"\n\t\n\t\t\n\t\tHow to Use?\n\t\n\nDownload, merge the files, and extract\nYou can run the following command to merge the compressed file parts after downloading.\ncat en_response_wav.tar.gz.* > en_response_wav.tar.gz\ncat zh_response_wav.tar.gz.* > zh_response_wav.tar.gz\n\n","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"koel-benchmark","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark","creator_name":"Nisarg Bhavsar","creator_url":"https://huggingface.co/NisargBhavsar25","description":"\n\t\n\t\t\n\t\tKoel Benchmark Suite\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Koel Benchmark Suite is a comprehensive set of evaluation datasets designed to rigorously test the real-world performance of Text-to-Speech (TTS) models for major Indian languages. The suite focuses on challenges unique to the Indian context, such as code-switching, domain-specific terminology, proper nouns, and complex numeric formats.\nThis dataset was created to help developers and researchers build more natural, accurate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark.","first_N":5,"first_N_keywords":["English","Hindi","Tamil","Telugu","Kannada"],"keywords_longer_than_N":true},
	{"name":"koel-benchmark","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark","creator_name":"Nisarg Bhavsar","creator_url":"https://huggingface.co/NisargBhavsar25","description":"\n\t\n\t\t\n\t\tKoel Benchmark Suite\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Koel Benchmark Suite is a comprehensive set of evaluation datasets designed to rigorously test the real-world performance of Text-to-Speech (TTS) models for major Indian languages. The suite focuses on challenges unique to the Indian context, such as code-switching, domain-specific terminology, proper nouns, and complex numeric formats.\nThis dataset was created to help developers and researchers build more natural, accurate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark.","first_N":5,"first_N_keywords":["English","Hindi","Tamil","Telugu","Kannada"],"keywords_longer_than_N":true},
	{"name":"librispeech-alignments_clean100","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ErfanAShams/librispeech-alignments_clean100","creator_name":"Erfan Shams","creator_url":"https://huggingface.co/ErfanAShams","description":"\n\t\n\t\t\n\t\tlibrispeech-alignments_clean100\n\t\n\nThis is a subset of librispeech-alignments (https://huggingface.co/datasets/gilkeyio/librispeech-alignments) which only includes train_clean_100 and test_clean splits for small experiments and tutorials.\nCite:\n@inproceedings{panayotov2015librispeech,  \n  title={Librispeech: an ASR corpus based on public domain audio books},\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},  \n  booktitle={ICASSP},   \n  year={2015}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ErfanAShams/librispeech-alignments_clean100.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"slr-co-male-training-piper","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/igortamara/slr-co-male-training-piper","creator_name":"Igor T√°mara","creator_url":"https://huggingface.co/igortamara","description":"Training checkpoints for colombian male voice from lessac as a base\n","first_N":5,"first_N_keywords":["text-to-speech","Spanish","cc-by-sa-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"EchoFake","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TobyZT/EchoFake","creator_name":"Tong","creator_url":"https://huggingface.co/TobyZT","description":"TobyZT/EchoFake dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"sada-validation-preprocessed","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mosama/sada-validation-preprocessed","creator_name":"Muhammad Osama","creator_url":"https://huggingface.co/mosama","description":"\n\t\n\t\t\n\t\tDetails\n\t\n\nThis is the SADA 2022 dataset with the input_features whish are log mels and the cleaned_labels which is the tokenized version of the cleaned_text. You can directly use this as the validation dataset when training Whisper Tiny, Small, Base & Medium models, as they all use the same tokenizer. Please double check this as well from the original model repo.\nIn addtition, the following filters were applied to this data:\n\nAll audios are less than 30 seconds and greater than 0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mosama/sada-validation-preprocessed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"improved_synthetic_vocal_burts","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/improved_synthetic_vocal_burts","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"laion/improved_synthetic_vocal_burts dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"cleaned_mixed_cantonese_and_english_speech","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JackyHoCL/cleaned_mixed_cantonese_and_english_speech","creator_name":"JackyHoCL","creator_url":"https://huggingface.co/JackyHoCL","description":"All right reserved by and credit to AlienKevin/mixed_cantonese_and_english_speech \nThis is a cleaned verison from AlienKevin/mixed_cantonese_and_english_speech:\nhttps://huggingface.co/datasets/AlienKevin/mixed_cantonese_and_english_speech\n\nRemoved '\"' in the preffix and suffix\nRemoved empty records in order to reduce hallucination\n\n","first_N":5,"first_N_keywords":["Chinese","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Test","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/imenLa/Test","creator_name":"imen laouirine","creator_url":"https://huggingface.co/imenLa","description":"Test Dataset\n","first_N":5,"first_N_keywords":["text-to-speech","Arabic","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"french_data_july_1","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mih12345/french_data_july_1","creator_name":"Md Ismail Hossain","creator_url":"https://huggingface.co/mih12345","description":"mih12345/french_data_july_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"basr18_18-hour-english-audio-transcript-dataset-by-bangladeshi-speakers","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ssh-rezvi/basr18_18-hour-english-audio-transcript-dataset-by-bangladeshi-speakers","creator_name":"Syed Sazid Hossain Rezvi","creator_url":"https://huggingface.co/ssh-rezvi","description":"ssh-rezvi/basr18_18-hour-english-audio-transcript-dataset-by-bangladeshi-speakers dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"sample-audios","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biswa921/sample-audios","creator_name":"Biswajit Satapathy","creator_url":"https://huggingface.co/biswa921","description":"biswa921/sample-audios dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"key_stroke_sound","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakuzas/key_stroke_sound","creator_name":"Saron Zeleke","creator_url":"https://huggingface.co/Sakuzas","description":"Sakuzas/key_stroke_sound dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"bibletts-asante-twi-max29secs-total9hrs-sr22050","keyword":"audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hci-lab-dcug/bibletts-asante-twi-max29secs-total9hrs-sr22050","creator_name":"DCS HCI LAB","creator_url":"https://huggingface.co/hci-lab-dcug","description":"\n\t\n\t\t\n\t\tBibleTTS Asante Twi Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis dataset is derived from the BibleTTS corpus, specifically focusing on Asante Twi speech data. The original BibleTTS is a large, high-fidelity, multilingual, and uniquely African speech corpus.\n\nTotal Duration: {total_hours:.2f} hours ({total_hours*60:.1f} minutes)\nNumber of Files: {file_count:,}\nSample Rate: {sample_rate:,} Hz\nMax File Duration: {max_duration:.1f} seconds\nFormat: WAV files with corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hci-lab-dcug/bibletts-asante-twi-max29secs-total9hrs-sr22050.","first_N":5,"first_N_keywords":["text-to-speech","Akan","Twi","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"cv-22-de","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fidoriel/cv-22-de","creator_name":"fidoriel","creator_url":"https://huggingface.co/fidoriel","description":"German split of Common Voice 22. cc0 license\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","German","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"french_homophone_asr","keyword":"audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hosein-m/french_homophone_asr","creator_name":"Hosein Mohebbi","creator_url":"https://huggingface.co/hosein-m","description":"The dataset, created and used in Mohebbi et al., (2023), includes instances of homophones in French spoken language, where an ASR model has to attend to syntactic cues in the context to disambiguate spoken words with identical pronunciations for transcription. \nThe test set (fr) of the Common Voice 11.0 (Ardila et al., 2020) is used to discover instances of three specific grammatical syntactic templates in which homophony may appear. \nFor the purpose of analysis, examples are filtered so that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hosein-m/french_homophone_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","French","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"BENYO-S2ST-Corpus-1","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aspmirlab/BENYO-S2ST-Corpus-1","creator_name":"ASPMIR LAB","creator_url":"https://huggingface.co/aspmirlab","description":"\n\t\n\t\t\n\t\tBENYO-S2ST-Corpus-1\n\t\n\nBilingual English-to-Yor√πb√° Speech-to-Speech Translation Corpus Version 1¬†(BENYO-S2ST-Corpus-1)¬†is based on a hybrid architecture we developed for curating large scale dataset for direct speech-to-speech translation(S2ST) at a reduced cost. We leveraged non speech-to-speech Standard Yor√πb√°(SY) real-time recordings in the YORULECT Corpus and synthetic Standard English(SE) transcripts with their corresponding audios generated using pre-trained AI models (i.e.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aspmirlab/BENYO-S2ST-Corpus-1.","first_N":5,"first_N_keywords":["apache-2.0","Audio","arxiv:2507.09342","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"SS-Libri","keyword":"audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Zhuxinjia/SS-Libri","creator_name":"Zhuxinjia","creator_url":"https://huggingface.co/Zhuxinjia","description":"Zhuxinjia/SS-Libri dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"libri","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philgzl/libri","creator_name":"Philippe Gonzalez","creator_url":"https://huggingface.co/philgzl","description":"\n\t\n\t\t\n\t\tLibriSpeech: An ASR corpus based on public domain audio books\n\t\n\nThis is a mirror of the LibriSpeech ASR corpus.\nThe original files were converted from FLAC to Opus to reduce the size and accelerate streaming.\nThe transcripts are not included. This mirror is thus best suited for audio-to-audio tasks.\n\nSampling rate: 16 kHz\nChannels: 1\nFormat: Opus\nSplits:\nTrain: 460 hours, 132553 utterances, train-clean-100 and train-clean-360 sets.\nValidation: 7 hours, 2703 utterances, dev-clean set.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philgzl/libri.","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"hindi-asr-wds","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/collabora/hindi-asr-wds","creator_name":"Collabora","creator_url":"https://huggingface.co/collabora","description":"collabora/hindi-asr-wds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","1M - 10M","webdataset","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Bes-stories","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ayzor/Bes-stories","creator_name":"Andrei Zhirnov","creator_url":"https://huggingface.co/ayzor","description":"ayzor/Bes-stories dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"DS3500","keyword":"audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/peng7554/DS3500","creator_name":"qian peng","creator_url":"https://huggingface.co/peng7554","description":"\nEnglish\n‰∏≠Êñá\n\n\n\t\n\t\t\n\t\tI. Basic Information of the Dataset\n\t\n\n\nDataset Name: Underwater Acoustic Target Radiated Noise Dataset (including the original ShipsEar dataset and the enhanced DS3500 dataset)\nDataset Version: V1.0\nRelease Date: July 2025 (based on the paper submission date)\nUpdate Records: First release, no updates yet\nSource and Contributors:\nOriginal ShipsEar dataset: Collected along the Atlantic coast of Spain from 2012 to 2013\nEnhanced DS3500 dataset: Generated by institutions such‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/peng7554/DS3500.","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"sam6","keyword":"audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gabiro2006/sam6","creator_name":"Gabriel Espinoza","creator_url":"https://huggingface.co/gabiro2006","description":"gabiro2006/sam6 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Audio","Datasets"],"keywords_longer_than_N":true}
]
;
