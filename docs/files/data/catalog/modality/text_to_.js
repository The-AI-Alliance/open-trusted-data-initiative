const data_for_modality_text_to_ = 
[
	{"name":"schaeffer_thesis_corrected","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dbschaeffer/schaeffer_thesis_corrected","creator_name":"SCHAEFFER Database","creator_url":"https://huggingface.co/dbschaeffer","description":"The SCHAEFFER dataset (Spectro-morphogical Corpus of Human-annotated Audio with Electroacoustic Features for Experimental Research), is a compilation of 788 raw audio data accompanied by human annotations and morphological acoustic features. \\nThe audio files adhere to the concept of Sound Objects introduced by Pierre Scaheffer, a framework for the analysis and creation of sound that focuses on its typological and morphological characteristics.\\nInside the dataset, the annotation are provided in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dbschaeffer/schaeffer_thesis_corrected.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"StockImages-CC0","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KoalaAI/StockImages-CC0","creator_name":"Koala AI","creator_url":"https://huggingface.co/KoalaAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCC0 Stock Images Dataset\\n\\t\\n\\nThis dataset contains a collection of stock images that are covered by the Creative Commons Zero (CC0) License, meaning they are free for personal and commercial use with no attribution required. It is designed to support a variety of computer vision tasks such as image tagging, categorization, and machine learning model training.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDisclaimer\\n\\t\\n\\nWhile every effort has been made to ensure the reliability and correctness of the data presented‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KoalaAI/StockImages-CC0.","first_N":5,"first_N_keywords":["image-to-text","image-to-image","text-to-image","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"elevenlabs_dataset","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skypro1111/elevenlabs_dataset","creator_name":"Serhii Kravchenko","creator_url":"https://huggingface.co/skypro1111","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic TTS Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was created with the aim of exploring the concept of using synthetic datasets for training Text-to-Speech (TTS) models. It consists of 1,388 audio files with a total duration of 2 hours and 20 minutes and their corresponding textual transcripts. The dataset leverages the capabilities of advanced AI services, utilizing paid subscriptions to ChatGPT-4 for text generation and ElevenLabs.io for audio generation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skypro1111/elevenlabs_dataset.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"text-to-image-prompts","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kazimir-ai/text-to-image-prompts","creator_name":"Kazimir.ai","creator_url":"https://huggingface.co/Kazimir-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe dataset of the most popular text-to-image prompts.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: kazimir.ai\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: https://kazimir.ai\\nLicense: apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nFree to use.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kazimir-ai/text-to-image-prompts.","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"spider-realistic","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aherntech/spider-realistic","creator_name":"AhernTech s.r.o.","creator_url":"https://huggingface.co/aherntech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider-Releastic\\n\\t\\n\\nThis dataset variant contains only the Spider Realistic dataset used in \\\"Structure-Grounded Pretraining for Text-to-SQL\\\". The dataset is created based on the dev split of the Spider dataset (2020-06-07 version from https://yale-lily.github.io/spider). The authors of the dataset modified the original questions to remove the explicit mention of column names while keeping the SQL queries unchanged to better evaluate the model's capability in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aherntech/spider-realistic.","first_N":5,"first_N_keywords":["text2text-generation","English","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"arabic_xvector_embeddings","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings","creator_name":"Hawau Olamide Toyin","creator_url":"https://huggingface.co/herwoww","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Speaker Embeddings extracted from ASC and ClArTTS\\n\\t\\n\\nThere is one speaker embedding for each utterance in the validation set of both datasets. The speaker embeddings are 512-element X-vectors.\\nArabic Speech Corpus has 100 files for a single male speaker and ClArTTS has 205 files for a single male speaker.\\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\\nUsage:\\nfrom datasets import load_dataset\\n\\nembeddings_dataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings.","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"misskey.io","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WitchesSocialStream/misskey.io","creator_name":"Witches Social Stream","creator_url":"https://huggingface.co/WitchesSocialStream","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for misskey.io\\n\\t\\n\\nNOTE: Looks familiar? Because it is!We have moved from RyokoExtra/MissingKeys -> WitchesSocialStream/misskey.io\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMissingKeys (Or this specific dataset) is a raw dataset archive of the misskey.io network.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.\\n\\ntext-classification\\ntext-generation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WitchesSocialStream/misskey.io.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-image","text-to-video","Japanese"],"keywords_longer_than_N":true},
	{"name":"misskey.io","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WitchesSocialStream/misskey.io","creator_name":"Witches Social Stream","creator_url":"https://huggingface.co/WitchesSocialStream","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for misskey.io\\n\\t\\n\\nNOTE: Looks familiar? Because it is!We have moved from RyokoExtra/MissingKeys -> WitchesSocialStream/misskey.io\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMissingKeys (Or this specific dataset) is a raw dataset archive of the misskey.io network.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.\\n\\ntext-classification\\ntext-generation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WitchesSocialStream/misskey.io.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-image","text-to-video","Japanese"],"keywords_longer_than_N":true},
	{"name":"tts-rj-hi-karya","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/tts-rj-hi-karya","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRajasthani Hindi Speech Dataset\\n\\t\\n\\n\\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. They had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426872 recordings in this dataset. They had roughly 58 male participants and 40 female participants.\\n\\nPoint to Note:\\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1rsh/tts-rj-hi-karya.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"speech-rj-hi","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/speech-rj-hi","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRajasthani Hindi Speech Dataset\\n\\t\\n\\n\\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. We had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426873 recordings in this dataset. We had roughly 58 male participants and 40 female participants.\\n\\nPoint to Note:\\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/severo/speech-rj-hi.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"midjourney-images","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ehristoforu/midjourney-images","creator_name":"Evgeniy Hristoforu","creator_url":"https://huggingface.co/ehristoforu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚õµ Midjourney Images Dataset\\n\\t\\n\\nThis is datase with images made by Midjourney V5/V6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset parameters\\n\\t\\n\\n\\nCount of images: ~10.000\\nZip file with dataset: True\\nCaptions with images: False\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nLicense for this dataset: MIT\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse in datasets\\n\\t\\n\\n\\npip install -q datasets\\n\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\n  \\\"ehristoforu/midjourney-images\\\",\\n  revision=\\\"main\\\"\\n)\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnjoy with this dataset!\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-image","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"fpt_fosd","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/fpt_fosd","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of FPT Open Speech Dataset (FOSD)\\n\\t\\n\\nreleased publicly in 2018 by FPT Corporation\\n100h, 25.9k samples\\nofficial link (dead): https://fpt.ai/fpt-open-speech-data/\\nmirror: https://data.mendeley.com/datasets/k9sxg2twv4/4\\nDOI: 10.17632/k9sxg2twv4.4\\npre-process:\\n\\nremove non-sense strings: -N \\\\r\\\\n\\nremove 4 files because missing transcription:\\nSet001_V0.1_008210.mp3\\nSet001_V0.1_010753.mp3\\nSet001_V0.1_011477.mp3\\nSet001_V0.1_011841.mp3\\n\\n\\n\\nneed to do: check misspelling\\nusage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/fpt_fosd.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"infore2_audiobooks","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore2_audiobooks","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of InfoRe Technology public dataset ‚Ññ2\\n\\t\\n\\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\\n415h, 315k samples, vietnamese audiobooks of chinese w«îxi√° Ê≠¶‰ø† & xiƒÅnxi√° ‰ªô‰ø†\\nb·ªô d·ªØ li·ªáu b√≥c ra t·ª´ YouTube ƒë·ªçc truy·ªán v√µ hi·ªáp & ti√™n hi·ªáp, √°p d·ª•ng kƒ© thu·∫≠t ƒë·ªëi chi·∫øu vƒÉn b·∫£n ƒë·ªÉ d√°n nh√£n t·ª± ƒë·ªông\\nofficial download:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore2_audiobooks.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"dalle-3-images","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ehristoforu/dalle-3-images","creator_name":"Evgeniy Hristoforu","creator_url":"https://huggingface.co/ehristoforu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüé® DALL‚Ä¢E 3 Images Dataset\\n\\t\\n\\nThis is datase with images made by Dalle3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset parameters\\n\\t\\n\\n\\nCount of images: 3310\\nZip file with dataset: True\\nCaptions with images: False\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nLicense for this dataset: MIT\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse in datasets\\n\\t\\n\\n\\npip install -q datasets\\n\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\n  \\\"ehristoforu/dalle-3-images\\\",\\n  revision=\\\"main\\\"\\n)\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnjoy with this dataset!\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-image","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"nst-da-norm","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NST-da Normalized\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): da\\nLicense: cc0-1.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"cryptocurrency-coins-hi-res","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SpectralDoor/cryptocurrency-coins-hi-res","creator_name":"SpectralDoor","creator_url":"https://huggingface.co/SpectralDoor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nA small dataset of 42 high-resolution images of cryptocurrency coins with clipped *.txt descriptions. \\nIt can be used to extend datasets or for tuning models.\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"spider-syn","keyword":"text-to-sql","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aherntech/spider-syn","creator_name":"AhernTech s.r.o.","creator_url":"https://huggingface.co/aherntech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Sypder-Syn\\n\\t\\n\\nSpyder-Syn is a human curated variant of the Spider Text-to-SQL database.\\nThe database was created to test the robustness of text-to-SQL models for robustness of synonym substitution.\\nThe source GIT repo for Sypder-Syn is located here: https://github.com/ygan/Spider-Syn\\nDetails regarding the data perterbation methods used and objectives are described in ACL 2021: arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper Abstract\\n\\t\\n\\n\\nRecently, there has been significant progress in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aherntech/spider-syn.","first_N":5,"first_N_keywords":["text2text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MAGBIG","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\\n\\t\\n\\t\\t\\n\\t\\tMAGBIG benchmark\\n\\t\\n\\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also if‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG.","first_N":5,"first_N_keywords":["text-to-image","English","German","Italian","French"],"keywords_longer_than_N":true},
	{"name":"sparc","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aherntech/sparc","creator_name":"AhernTech s.r.o.","creator_url":"https://huggingface.co/aherntech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SParC\\n\\t\\n\\nSParC is a context-dependant multi-turn version of the Spider task 1.0.\\nThis dataset provides a chat-bot oriented test set for text-to-sql problems. Additional details may be obtained in the paper:\\n\\nhttps://arxiv.org/abs/1906.02285\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper Abstract\\n\\t\\n\\n\\nWe present SParC, a dataset for cross-domainSemanticParsing inContext that consists of 4,298 coherent question sequences (12k+ individual questions annotated with SQL queries). It is obtained from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aherntech/sparc.","first_N":5,"first_N_keywords":["text2text-generation","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"haispider","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HusnaManakkot/haispider","creator_name":"HUSNA M","creator_url":"https://huggingface.co/HusnaManakkot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\nTable of Contents\\nDataset Description\\nDataset Summary\\nSupported Tasks and Leaderboards\\nLanguages\\nDataset Structure\\nData Instances\\nData Fields\\nData Splits\\nDataset Creation\\nCuration Rationale\\nSource Data\\nAnnotations\\nPersonal and Sensitive Information\\nConsiderations for Using the Data\\nSocial Impact of Dataset\\nDiscussion of Biases\\nOther Known Limitations\\nAdditional Information\\nDataset Curators\\nLicensing Information\\nCitation Information\\nContributions\\nDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HusnaManakkot/haispider.","first_N":5,"first_N_keywords":["text2text-generation","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MemeDatasetForStudy","keyword":"text-to-image","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/SassyRong/MemeDatasetForStudy","creator_name":"SassyRong","creator_url":"https://huggingface.co/SassyRong","description":"SassyRong/MemeDatasetForStudy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","wtfpl","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"sql-create-context-chatml","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/recastai/sql-create-context-chatml","creator_name":"Re:cast AI","creator_url":"https://huggingface.co/recastai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset has been created by Re:cast AI to extend the existing dataset b-mc2/sql-create-context into a chatml friendly format for use in SFT tasks with pretrained models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nmessages = [\\n     {'content': \\\"You are a powerful text-to-SQL AI assistant that helps users ... etc.\\\", 'role': 'system'},\\n     {'content': '(Optional) Context information is below ... etc.', 'role': 'user'},\\n     {'content': 'SELECT COUNT(*) FROM head WHERE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recastai/sql-create-context-chatml.","first_N":5,"first_N_keywords":["text2text-generation","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"vivechan-spritual-text-dataset-v2","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v2","creator_name":"Om Ashishkumar Soni","creator_url":"https://huggingface.co/om-ashish-soni","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVivechan - Spiritual Text Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe Vivechan - Spiritual Text Dataset is an open and public collection of textual data extracted from significant spiritual texts, curated to support discussions, inquiries, doubts, and Q&A sessions within the realm of spirituality. This dataset provides valuable content from the following revered sources:\\n\\nShrimad Bhagwat Mahapurana\\nShripad Shri Vallabha Charitramrutam\\nShiv Mahapurana Sankshipt\\nValmiki Ramayan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v2.","first_N":5,"first_N_keywords":["text-retrieval","text2text-generation","text-to-speech","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"world-heightmaps-256px","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/novaia/world-heightmaps-256px","creator_name":"Novaia","creator_url":"https://huggingface.co/novaia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorld Heightmaps 256px\\n\\t\\n\\nThis is a dataset of 256x256 Earth heightmaps generated from SRTM 1 Arc-Second Global.\\nEach heightmap is labelled according to its latitude and longitude. There are 573,995 samples. It is the same as \\nWorld Heightmaps 360px but downsampled to 256x256.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMethod\\n\\t\\n\\n\\nConvert GeoTIFFs into PNGs with Rasterio.\\n\\nimport rasterio\\nimport matplotlib.pyplot as plt\\nimport os\\n\\ninput_directory = '...'\\noutput_directory = '...'\\nfile_list =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/novaia/world-heightmaps-256px.","first_N":5,"first_N_keywords":["image-classification","text-to-image","unconditional-image-generation","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"world-heightmaps-360px","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/novaia/world-heightmaps-360px","creator_name":"Novaia","creator_url":"https://huggingface.co/novaia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorld Heightmaps 360px\\n\\t\\n\\nThis is a dataset of 360x360 Earth heightmaps generated from SRTM 1 Arc-Second Global.\\nEach heightmap is labelled according to its latitude and longitude. There are 573,995 samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMethod\\n\\t\\n\\n\\nConvert GeoTIFFs into PNGs with Python and Rasterio.\\n\\nimport rasterio\\nimport matplotlib.pyplot as plt\\nimport os\\n\\ninput_directory = '...'\\noutput_directory = '...'\\nfile_list = os.listdir(input_directory)\\n\\nfor i in range(len(file_list)):\\n    image =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/novaia/world-heightmaps-360px.","first_N":5,"first_N_keywords":["unconditional-image-generation","image-classification","text-to-image","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"assamese_speech_corpus","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/madhabpaul/assamese_speech_corpus","creator_name":"Madhab Paul","creator_url":"https://huggingface.co/madhabpaul","description":"madhabpaul/assamese_speech_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Assamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"assamese_speech_corpus","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/madhabpaul/assamese_speech_corpus","creator_name":"Madhab Paul","creator_url":"https://huggingface.co/madhabpaul","description":"madhabpaul/assamese_speech_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Assamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"new-spider-HM","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HusnaManakkot/new-spider-HM","creator_name":"HUSNA M","creator_url":"https://huggingface.co/HusnaManakkot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HusnaManakkot/new-spider-HM.","first_N":5,"first_N_keywords":["text2text-generation","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"surtr_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shiroup/surtr_arknights","creator_name":"ÊàèÊµ™","creator_url":"https://huggingface.co/shiroup","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of surtr/„Çπ„É´„Éà/Âè≤Â∞îÁâπÂ∞î (Arknights)\\n\\t\\n\\nThis is the dataset of surtr/„Çπ„É´„Éà/Âè≤Â∞îÁâπÂ∞î (Arknights), containing 500 images and their tags.\\nThe core tags of this character are horns, red_hair, long_hair, purple_eyes, bangs, breasts, very_long_hair, hair_between_eyes, medium_breasts, large_breasts, demon_horns, which are pruned in this dataset.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shiroup/surtr_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"zh-taiwan","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ivanzhu109/zh-taiwan","creator_name":"IvanZhu","creator_url":"https://huggingface.co/ivanzhu109","description":"ivanzhu109/zh-taiwan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Entity-Imagen","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/Entity-Imagen","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"This dataset is a replication evaluation set from Re-Imagen (https://arxiv.org/pdf/2209.14491.pdf). The dataset is aimed for evaluating text-to-image generation on rare visual entities.\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"hand_imgs","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kiwinicki/hand_imgs","creator_name":"Dawid Koterwas","creator_url":"https://huggingface.co/Kiwinicki","description":"Images of hands downloaded from internet and captioned with BLIP2\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"updated-dataset","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HusnaManakkot/updated-dataset","creator_name":"HUSNA M","creator_url":"https://huggingface.co/HusnaManakkot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HusnaManakkot/updated-dataset.","first_N":5,"first_N_keywords":["text2text-generation","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fav_images","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ehristoforu/fav_images","creator_name":"Evgeniy Hristoforu","creator_url":"https://huggingface.co/ehristoforu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfav_images\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-image","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"pony-singing","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-singing","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-singing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"pony-singing","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-singing","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-singing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"limmits-2024","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic TTS dataset\\n\\t\\n\\n7 languages from IISC's LIMMITS Challenge 2024\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoadmap\\n\\t\\n\\nTo use this for training VALLE-X & VoiceBox based TTS models\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFetch the tars directly\\n\\t\\n\\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\\nwget -O‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"limmits-2024","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic TTS dataset\\n\\t\\n\\n7 languages from IISC's LIMMITS Challenge 2024\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoadmap\\n\\t\\n\\nTo use this for training VALLE-X & VoiceBox based TTS models\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFetch the tars directly\\n\\t\\n\\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\\nwget -O‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"VL-ICL","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ys-zong/VL-ICL","creator_name":"Yongshuo Zong","creator_url":"https://huggingface.co/ys-zong","description":"\\n\\t\\n\\t\\t\\n\\t\\tVL-ICL Bench\\n\\t\\n\\nVL-ICL Bench: The Devil in the Details of Benchmarking Multimodal In-Context Learning\\n[Webpage] [Paper] [Code]\\n\\n\\t\\n\\t\\t\\n\\t\\tImage-to-Text Tasks\\n\\t\\n\\nIn all image-to-text tasks image is a list of image paths (typically one item - for interleaved cases there are two items).\\n\\n\\t\\n\\t\\t\\n\\t\\tFast Open-Ended MiniImageNet\\n\\t\\n\\nFrozen introduces the task of fast concept binding for MiniImageNet. The benchmark has a fixed structure so only the given support examples can be used for a given‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ys-zong/VL-ICL.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","mit","1K<n<10K","Image"],"keywords_longer_than_N":true},
	{"name":"Arabic-CivitAi-Images","keyword":"text-to-image","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/Arabic-CivitAi-Images","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nTop +2k Images curated from CivitAI website, described using the great Qwen-VL-Max model and then translated using Command-R into the Arabic language\\n\\n\\n    \\n\\n","first_N":5,"first_N_keywords":["text-to-image","Arabic","gpl-3.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"jalandhary_asr","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirfan899/jalandhary_asr","creator_name":"Muhammad Irfan","creator_url":"https://huggingface.co/mirfan899","description":"Jalandhary dataset is created using whisper model for STT and TTS. Some audios are ommited due to issues while trimming them. If there are some isues \\nin the dataset or audio not matching the text you can start a discussion or ping me to correcting it. \\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Urdu","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"danbooru2023_index","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/danbooru2023_index","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"Tar index files for nyanko7/danbooru2023.\\nYou can download images from both nyanko7/danbooru2023 and deepghs/danbooru_newest with cheesechaser.\\nfrom cheesechaser.datapool import DanbooruNewestDataPool\\n\\npool = DanbooruNewestDataPool()\\n\\n# download danbooru original images from 7200000-7201000, to directory /data/danbooru_original\\npool.batch_download_to_directory(\\n    resource_ids=range(7200000, 7201000),\\n    dst_dir='/data/danbooru_original',\\n    max_workers=12,\\n)\\n\\n","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"mabama-v","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aztro/mabama-v","creator_name":"Jose Omar Vieyra","creator_url":"https://huggingface.co/aztro","description":"aztro/mabama-v dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"dreambooth-cell-images","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mario-dg/dreambooth-cell-images","creator_name":"Mario da Graca","creator_url":"https://huggingface.co/mario-dg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dreambooth Brightfield Microscopy\\n\\t\\n\\nThis dataset was created as part of my masters research and thesis, where I am trying to generate realistic looking\\nbrightfield microscopy images for dataset augmentation.\\nWith the downstream goal of enhancing cell detection objects, increasing the dataset size of an object detection model\\nis a necessary step.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nAs part of my research, I previously generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mario-dg/dreambooth-cell-images.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Visual-CoT","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepcs233/Visual-CoT","creator_name":"Hao Shao","creator_url":"https://huggingface.co/deepcs233","description":"\\n\\t\\n\\t\\t\\n\\t\\tVisCoT Dataset Card\\n\\t\\n\\n\\n\\nThere is a shortage of multimodal datasets for training multi-modal large language models (MLLMs) that require to identify specific regions in an image for additional attention to improve response performance. This type of dataset with grounding bbox annotations could possibly help the MLLM output intermediate interpretable attention area and enhance performance.\\nTo fill the gap, we curate a visual CoT dataset. This dataset specifically focuses on identifying‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepcs233/Visual-CoT.","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","arxiv:2403.16999","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Ergonomics_Chiar_Customer_Viewdata_E-commerse","keyword":"text-to-speech","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liaHa/Ergonomics_Chiar_Customer_Viewdata_E-commerse","creator_name":"lia","creator_url":"https://huggingface.co/liaHa","description":"liaHa/Ergonomics_Chiar_Customer_Viewdata_E-commerse dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["feature-extraction","text-classification","zero-shot-classification","text-to-speech","English"],"keywords_longer_than_N":true},
	{"name":"DS-2","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Artples/DS-2","creator_name":"Artur Lauche","creator_url":"https://huggingface.co/Artples","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LAI-DS2\\n\\t\\n\\nThis Dataset is a dataset with pictures from Unsplash with great descriptions to the images.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset comprises a collection of Unsplash images accompanied by detailed descriptions.\\n\\nCurated by: Artur Lauche\\nLicense: Apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\nAll images are from Unsplash and the descriptions are made by licensed AI.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nImage related task.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOut-of-Scope Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Artples/DS-2.","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of 10K hours of English MLS\\n\\t\\n\\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of 10K hours of English MLS\\n\\t\\n\\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"DeepFashion-MultiModal-Parts2Whole","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huanngzh/DeepFashion-MultiModal-Parts2Whole","creator_name":"zehuan-huang","creator_url":"https://huggingface.co/huanngzh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDeepFashion MultiModal Parts2Whole\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis human image dataset comprising about 41,500 reference-target pairs. Each pair in this dataset includes multiple reference images, which encompass human pose images (e.g., OpenPose, Human Parsing, DensePose), various aspects of human appearance (e.g., hair, face, clothes, shoes) with their short textual labels, and a target image featuring the same individual (ID) in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huanngzh/DeepFashion-MultiModal-Parts2Whole.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"FLEURS-GA-EN","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThis is the Irish-to-English portion of the FLEURS dataset.\\nFleurs is the speech version of the FLoRes machine translation benchmark.\\nThe Irish portion consists of 3991 utterances, which correspond to approximately 16 hours and 45 minutes (16:45:17) of audio data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['id', 'audio', 'text_ga', 'text_en'],\\n        num_rows: 3991\\n    })\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"SpokenWords-GA-EN-MTed","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis is the Irish portion of the Spoken Words dataset (available at MLCommons/ml_spoken_words),\\nwith merged splits ‚Äútrain‚Äù, ‚Äúvalidation‚Äù, and ‚Äútest‚Äù, augmented with machine translation.\\nThe Irish sentences are automatically translated into English using Google Translation API.\\nThe dataset includes approximately 3 hours and 2 minutes of audio (03:02:02), spoken by multiple narrators.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features: ['keyword'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"Living-Audio-Irish","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Living-Audio-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nLiving Audio Irish speech corpus. This version is based on the Irish dataset on Kaggle.\\nThe original dataset with audio in more languages is available on GitHub as part of the Idlak project.\\nThe details of the Irish portion of the Living Audio dataset are as follows:\\n\\n\\t\\n\\t\\t\\nSpeaker\\nLanguage\\nAccent\\nGender\\nTotal duration(mm:ss)\\nSample rate (Hz)\\n\\n\\n\\t\\t\\nCLL\\nIrish (ga)\\nNon-native (ie)\\nMan\\n61:56\\n48,000\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Living-Audio-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Irish","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sql-create-context-thai","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from sql-create-context.\\n@misc{b-mc2_2023_sql-create-context,\\n  title   = {sql-create-context Dataset},\\n  author  = {b-mc2}, \\n  year    = {2023},\\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\\n  note    = {This dataset was created by modifying data from the following sources: \\\\cite{zhongSeq2SQL2017, yu2018spider}.},\\n}\\n\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","Thai","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"coco-stuff-geodiffusion","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaiChen1998/coco-stuff-geodiffusion","creator_name":"Kai Chen","creator_url":"https://huggingface.co/KaiChen1998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCOCO-Stuff-GeoDiffusion Dataset Card\\n\\t\\n\\nCOCO-Stuff-GeoDiffusion is the official dataset annotation file used to train GeoDiffusion on the COCO-Stuff dataset. We follow the official implementations of LAMA, while saving the merged results of COCO-instance and COCO-Stuff datasets within a single file of standard COCO format. Check detailed usage in our Github repo.\\n","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","arxiv:2306.04607","üá∫üá∏ Region: US","layout-to-image"],"keywords_longer_than_N":false},
	{"name":"knives_and_time","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/calm-and-collected/knives_and_time","creator_name":"Niels van der Burg","creator_url":"https://huggingface.co/calm-and-collected","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKnives and Time, a broken dataset\\n\\t\\n\\nThis dataset is created with custom collection and semi-automated annotation for damaged images in public domain or Common Creatives 0 (CC0).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCollection method\\n\\t\\n\\nData was manually collected for painting, images and photography with either:\\n\\nAbrasion.\\nWater damage.\\nOver composure.\\nScratches.\\nTorn.\\nBurned.\\nCut.\\nPierced\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnnotation method\\n\\t\\n\\nData was annotated with BLIP for an initial sweep with basic annotation. Followed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/calm-and-collected/knives_and_time.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"COCO_Person","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hamdy20002/COCO_Person","creator_name":"Abdelrahman Hamdy","creator_url":"https://huggingface.co/Hamdy20002","description":"This Dataset is a subsets of COCO 2017 -train- images using \\\"Crowd\\\" & \\\"person\\\" Labels With the First Caption of Each one\\n\\nCOCO Summary:\\nThe COCO dataset is a comprehensive collection designed for object detection, segmentation, and captioning tasks.\\nIt comprises over 200,000 images, encompassing a diverse array of everyday scenes and objects.\\nEach image features multiple objects and scenes across 80 distinct object categories, all of which are annotated with descriptive image captions.\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-feature-extraction","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"anime-bg","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/anime-bg","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"Anime background and wallpaper images based on skytnt/anime-segmentation.\\nArchived with indexed tar files, you can easily download any of these images with hfutils or dghs-imgutils library.\\nFor example:\\nfrom imgutils.resource import get_bg_image_file, random_image\\n\\n# get and download this background image file\\n# return value should be the local path of given file\\nget_bg_image_file('000001.jpg')\\n\\n# random select one background image from deepghs/anime-bg\\nrandom_image()\\n\\nSee Documentation of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepghs/anime-bg.","first_N":5,"first_N_keywords":["text-to-image","cc0-1.0","1K - 10K","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"ru-filtered-web-captions","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DiTy/ru-filtered-web-captions","creator_name":"Dmitry Tishencko","creator_url":"https://huggingface.co/DiTy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDiTy/ru-filtered-web-captions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nThis is a translated Russian¬†part of the filtered web captions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n    'caption': 'gladiator standing in a smoke with torch and sword',\\n    'url': 'https://thumb9.shutterstock.com/display_pic_with_logo/78238/155376242/stock-photo-gladiator-standing-in-a-smoke-with-torch-and-sword-155376242.jpg',\\n    'translated_caption': '–≥–ª–∞–¥–∏–∞—Ç–æ—Ä, —Å—Ç–æ—è—â–∏–π –≤ –¥—ã–º—É —Å —Ñ–∞–∫–µ–ª–æ–º –∏ –º–µ—á–æ–º'\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DiTy/ru-filtered-web-captions.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","feature-extraction","image-feature-extraction","Russian"],"keywords_longer_than_N":true},
	{"name":"chuvash_voice","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexantonov/chuvash_voice","creator_name":"Alexander Antonov","creator_url":"https://huggingface.co/alexantonov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use\\n\\t\\n\\nWe recommend using our dataset in conjunction with the Common Voice Corpus. We have attempted to maintain a consistent structure.\\nfrom datasets import load_dataset, DatasetDict, concatenate_datasets, Audio\\n\\ncomm_voice = DatasetDict()\\ncomm_voice[\\\"train\\\"] = load_dataset(\\\"mozilla-foundation/common_voice_17_0\\\", \\\"cv\\\", split=\\\"train+validation\\\", use_auth_token=True)\\ncomm_voice[\\\"test\\\"] = load_dataset(\\\"mozilla-foundation/common_voice_17_0\\\", \\\"cv\\\", split=\\\"test\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexantonov/chuvash_voice.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chuvash","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"libritts_r","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/libritts_r","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LibriTTS-R\\n\\t\\n\\n\\n\\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus \\n(http://www.openslr.org/60/) which is a multi-speaker English corpus of approximately \\n585 hours of read English speech at 24kHz sampling rate, published in 2019.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the LibriTTS-R dataset, adapted for the datasets library.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSplits\\n\\t\\n\\nThere are 7 splits (dots replace dashes from the original dataset, to comply with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/libritts_r.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of 10K hours of English MLS\\n\\t\\n\\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of 10K hours of English MLS\\n\\t\\n\\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"vais1000","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vais1000","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of VAIS-1000\\n\\t\\n\\nofficial announcement: https://vais.vn/vi/tai-ve/hts_for_vietnamese (dead)\\nmirror: https://github.com/undertheseanlp/text_to_speech/tree/run/data/vais1000/raw\\nsmall only 1h40min audio - 1 speaker (female northern accent) - 1k samples\\npre-process: none\\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\\nusage with HuggingFace:\\n# pip install -q \\\"datasets[audio]\\\"\\nfrom datasets import load_dataset\\nfrom torch.utils.data import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vais1000.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"fake_voices","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fake Voices\\n\\t\\n\\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \\nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \\nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Portuguese","mit","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"fake_voices","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fake Voices\\n\\t\\n\\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \\nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \\nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Portuguese","mit","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"mj-v52-redux","keyword":"text-to-image","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/bghira/mj-v52-redux","creator_name":"PseudoTerminal X","creator_url":"https://huggingface.co/bghira","description":"","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","unlicense","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Speech-Irish","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nSynthetic audio dataset, created using Azure text-to-speech service.\\nThe bilingual text is a portion of the Tatoeba dataset, consisting of 1,983 text segments.\\nThe dataset consists of two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\\nThe speech data comprises approximately 2 hours and 39 minutes (02:39:31) spread across 3,966 utterances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features: ['audio'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"SPEC","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wjpoom/SPEC","creator_name":"Wujian Peng","creator_url":"https://huggingface.co/wjpoom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t[CVPR 2024] SPEC Benchmark: Evaluating VLMs in Fine-grained and Compositional Understanding\\n\\t\\n\\nintroduced in the CVPR 2024 paper Synthesize, Diagnose, and Optimize: Towards Fine-Grained Vision-Language Understanding\\nCode | ü§ó Paper | üìñ arXiv\\nTo evaluate the understanding capability of visual-language models on fine-grained concepts, we propose a new benchmark, SPEC, \\nwhich consists of six distinct subsets, distributed across the dimensions of Size, Position, Existence, and Count.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wjpoom/SPEC.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Wikimedia-Speech-Irish","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nSynthetic audio dataset, created using Azure text-to-speech service.\\nThe bilingual text is a portion of the Wikimedia dataset, consisting of 7,545 text segments.\\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\\nThe speech data comprises approximately 34 hours and 23 minutes (34:23:12) spread across 15,090 utterances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features: ['audio'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"midjourney-detailed-prompts","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/midjourney-detailed-prompts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMidjourney: Detailed Prompts\\n\\t\\n\\nThis dataset is my attempt in providing a high quality text-to-image dataset with detailed and several levels of prompting for images.\\nHope it helps anyone in his research ^^\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThanks goes to ...\\n\\t\\n\\n\\nmidjourney-images dataset\\nQwen-VL-Max for descriping images in huge detail.\\nCommand R for long & short prompt generation\\n\\n","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"SingleFloorPlans","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShazShoaib/SingleFloorPlans","creator_name":"Shaz Shoaib","creator_url":"https://huggingface.co/ShazShoaib","description":"ShazShoaib/SingleFloorPlans dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"SingleFloorDatasetDemo","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShazShoaib/SingleFloorDatasetDemo","creator_name":"Shaz Shoaib","creator_url":"https://huggingface.co/ShazShoaib","description":"ShazShoaib/SingleFloorDatasetDemo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Omnixxx","keyword":"text-to-image","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Abgrande615/Omnixxx","creator_name":"Adam Grande","creator_url":"https://huggingface.co/Abgrande615","description":"Abgrande615/Omnixxx dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","text-to-video","afl-3.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Omnixxx","keyword":"text-to-video","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Abgrande615/Omnixxx","creator_name":"Adam Grande","creator_url":"https://huggingface.co/Abgrande615","description":"Abgrande615/Omnixxx dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","text-to-video","afl-3.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"moondream2-coyo-5M-captions","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/isidentical/moondream2-coyo-5M-captions","creator_name":"Batuhan","creator_url":"https://huggingface.co/isidentical","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMoondream2 COYO-700M 5M subset captions\\n\\t\\n\\nA 5-million image, text pair subset of COYO-700M dataset, captioned with Moondream2 (rev=2024-05-08).  Captioning question is Write a long caption for this image given the alt text: {alt_text}.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSampling conditions\\n\\t\\n\\nRandomly sampled from 5 million images from COYO-700M images that fit to the following filters:\\nfilters = [\\n    (\\\"width\\\", \\\">=\\\", 256),\\n    (\\\"height\\\", \\\">=\\\", 256),\\n    (\\\"aesthetic_score_laion_v2\\\", \\\">=\\\", 5.2)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isidentical/moondream2-coyo-5M-captions.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","visual-question-answering","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Products-10k-BLIP-captions","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VikramSingh178/Products-10k-BLIP-captions","creator_name":"Vikramjeet  Singh","creator_url":"https://huggingface.co/VikramSingh178","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Products-10k BLIP CAPTIONS dataset consists of 10000 images of various products along with their automatically generated captions. The captions are generated using the BLIP (Bootstrapping Language-Image Pre-training) model. This dataset aims to aid in tasks related to image captioning, visual recognition, and product classification.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nDataset Name: Products-10k\\nGenerated Captions Model: Salesforce/blip-image-captioning-large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VikramSingh178/Products-10k-BLIP-captions.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","text-to-image","English","mit"],"keywords_longer_than_N":true},
	{"name":"glaswegian_audio","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/divakaivan/glaswegian_audio","creator_name":"Ivan Ivanov","creator_url":"https://huggingface.co/divakaivan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWARNING! Some derogatory slang is included in the dataset\\n\\t\\n\\nLatest total length: 120 minutes\\nSource:\\nScottish phrases 1-10, privately recorded audio, Limmy, and 1 episode of Glasga Da\\nFine-tuned whisper-small using this dataset:\\n\\nmodel\\ndemo\\n\\nFine-tuned TTS using this dataset:\\n\\nmodel\\ndemo\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContact\\n\\t\\n\\nIf you have any questions related to the dataset or models, please contact the authors on LinkedIn:\\n\\nColin McKelvie\\nIvan Ivanov\\n\\n","first_N":5,"first_N_keywords":["text-to-speech","English","mit","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"nuimages-geodiffusion","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaiChen1998/nuimages-geodiffusion","creator_name":"Kai Chen","creator_url":"https://huggingface.co/KaiChen1998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tnuImages-GeoDiffusion Dataset Card\\n\\t\\n\\nnuImages-GeoDiffusion is the official dataset annotation file used to train GeoDiffusion on the nuImages dataset. We follow the implementations of mmdetection3d, while saving the annotation results in standard COCO format. Check detailed usage in our Github repo.\\n","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","arxiv:2306.04607","üá∫üá∏ Region: US","layout-to-image"],"keywords_longer_than_N":false},
	{"name":"midjourney-prompts-highquality","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaodrew/midjourney-prompts-highquality","creator_name":"Andrew Gao","creator_url":"https://huggingface.co/gaodrew","description":"\\n\\nThank you to the Akash Network for sponsoring this project and providing A100s/H100s for compute!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\nA filtered version of the vivym/midjourney-prompts dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFiltering criteria\\n\\t\\n\\n\\ntop 10% in length (assuming that longer prompts = more effort and higher quality)\\nused on an image to be upscaled (assuming that users are more likely to upscale an image that is aesthetically pleasing)\\nused on midjourney version 5.0+\\ndeduplicated\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRun yourself‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaodrew/midjourney-prompts-highquality.","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","10K - 100K","csv","Image"],"keywords_longer_than_N":true},
	{"name":"openai-voices","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leafspark/openai-voices","creator_name":"leafspark","creator_url":"https://huggingface.co/leafspark","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAI Voices\\n\\t\\n\\nA collection of TTS samples collected from the OpenAI API and app.\\nCurrently the following voices are available:\\n\\nSky\\nJuniper\\n\\nThese are not labeled, however they are clean lossless audio files, and may contain noise from the model.\\nPlease refer to sky/statement.wav for the highest quality voice sample!\\n","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"commoncatalog-cc-by-ext","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ext","creator_name":"Yasunori Ozaki","creator_url":"https://huggingface.co/alfredplpl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommonCatalog CC-BY Extention\\n\\t\\n\\n„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅØCommonCatalog CC-BY„ÇíÊã°Âºµ„Åó„Å¶„ÄÅËøΩÂä†„ÅÆÊÉÖÂ†±„ÇíÂÖ•„Çå„Åü„ÇÇ„ÅÆ„Åß„Åô„ÄÇ\\n‰ª•‰∏ã„ÅÆÊÉÖÂ†±„ÅåËøΩÂä†„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\nPhi-3 Vision„ÅßDense Captioning„Åó„ÅüËã±Ë™û„Ç≠„É£„Éó„Ç∑„Éß„É≥\\nËã±Ë™û„Ç≠„É£„Éó„Ç∑„Éß„É≥„ÇíPhi-3 Medium„ÅßÊó•Êú¨Ë™ûÂåñ„Åó„ÅüÊó•Êú¨Ë™û„Ç≠„É£„Éó„Ç∑„Éß„É≥\\n\\n‰∏ª„Ç≠„Éº„ÅØphotoid„Åß„Åô„ÅÆ„Åß„ÄÅCommonCatalog CC-BY„Å®ÁµêÂêà„Åô„Çã„Å™„Çä„Åó„Å¶‰Ωø„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\nstreaming=True„ÅßË™≠„ÅøËæº„ÇÄ„Å®Âêå„ÅòÈ†Ü„Å´Ë™≠„ÅøËæº„Åæ„Çå„Åæ„Åô„ÅÆ„Åß„Åù„Çå„ÇíÂà©Áî®„Åô„Çã„ÅÆ„Åå‰∏ÄÁï™Ê•Ω„Åß„Åô„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nÁîªÂÉè„ÅåCC BY„Å™„Åü„ÇÅ„ÄÅ„Çè„Åã„Çä„ÇÑ„Åô„ÅèCC BY„Å´„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åó„Åü„Åå„Å£„Å¶„ÄÅÂïÜÁî®Âà©Áî®ÂèØËÉΩ„Åß„Åô„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Code\\n\\t\\n\\nimport pandas\\nfrom datasets import load_dataset\\n\\ndf=pandas.read_csv(\\\"commoncatalog-cc-by-phi3-ja.csv\\\")\\n\\ndataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ext.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"the-un-laion-temple","keyword":"text-to-image","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/ilovehentai9000/the-un-laion-temple","creator_name":"ilovehentai9000","creator_url":"https://huggingface.co/ilovehentai9000","description":"All files uploaded. Enjoy!\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for The Unlaion Temple\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLaion-5B is still not public, so we decided to create our own dataset.\\nThe Unlaion Temple is a raw dataset of CommonCrawl images (Estimated to be a total of 2 Billion urls). We haven't verified whether the links in this dataset are functional.\\nYou are responsible for handling the data.\\nWe've made some improvements to the dataset based on user feedback:\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilovehentai9000/the-un-laion-temple.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-to-text","text-to-image","image-feature-extraction"],"keywords_longer_than_N":true},
	{"name":"Mixed_VQA_GenQA_EvalQA_1.5M","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhenryz/Mixed_VQA_GenQA_EvalQA_1.5M","creator_name":"Henry Hengyuan Zhao","creator_url":"https://huggingface.co/hhenryz","description":"This repository contains the data for the paper LOVA3: Learning to Visual Question Answering, Asking and Assessment.\\nCode: https://github.com/showlab/LOVA3\\n\\n\\t\\n\\t\\t\\n\\t\\tüéì Citation\\n\\t\\n\\nIf you find LOVA3 useful, please cite using this BibTeX:\\n@inproceedings{\\n    zhao2024lova,\\n    title={{LOVA}3: Learning to Visual Question Answering, Asking and Assessment},\\n    author={Hengyuan Zhao and Pan Zhou and Difei Gao and Zechen Bai and Mike Zheng Shou},\\n    booktitle={The Thirty-eighth Annual Conference on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hhenryz/Mixed_VQA_GenQA_EvalQA_1.5M.","first_N":5,"first_N_keywords":["image-text-to-text","apache-2.0","arxiv:2405.14974","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"commoncatalog-cc-by-recap","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-recap","creator_name":"Yasunori Ozaki","creator_url":"https://huggingface.co/alfredplpl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommonCatalog CC-BY Recaptioning\\n\\t\\n\\n„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅØCommonCatalog CC-BY„ÇíÊã°Âºµ„Åó„Å¶„ÄÅËøΩÂä†„ÅÆÊÉÖÂ†±„ÇíÂÖ•„Çå„Åü„ÇÇ„ÅÆ„Åß„Åô„ÄÇ ‰ª•‰∏ã„ÅÆÊÉÖÂ†±„ÅåËøΩÂä†„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\nPhi-3 Vision„ÅßDense Captioning„Åó„ÅüËã±Ë™û„Ç≠„É£„Éó„Ç∑„Éß„É≥\\n\\n‰∏ª„Ç≠„Éº„ÅØphotoid„Åß„Åô„ÅÆ„Åß„ÄÅCommonCatalog CC-BY„Å®ÁµêÂêà„Åô„Çã„Å™„Çä„Åó„Å¶‰Ωø„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ streaming=True„ÅßË™≠„ÅøËæº„ÇÄ„Å®Âêå„ÅòÈ†Ü„Å´Ë™≠„ÅøËæº„Åæ„Çå„Åæ„Åô„ÅÆ„Åß„Åù„Çå„ÇíÂà©Áî®„Åô„Çã„ÅÆ„Åå‰∏ÄÁï™Ê•Ω„Åß„Åô„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Code\\n\\t\\n\\nimport pandas\\nfrom datasets import load_dataset\\nfrom tqdm import tqdm\\nimport json\\n\\ndf=pandas.read_csv(\\\"commoncatalog-cc-by-phi3.csv\\\")\\n\\ndataset = load_dataset(\\\"common-canvas/commoncatalog-cc-by\\\",split=\\\"train\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-recap.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"filtered-coyo-700M-beta","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dwb2023/filtered-coyo-700M-beta","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for filterred-coyo-700M-beta\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe texts in the COYO-700M dataset consist of English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance in COYO-700M represents single image-text pair information with meta-attributes:\\n{\\n  'id': 841814333321,\\n  'url': 'https://blog.dogsof.com/wp-content/uploads/2021/03/Image-from-iOS-5-e1614711641382.jpg'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/filtered-coyo-700M-beta.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","zero-shot-classification","image-captioning","no-annotation"],"keywords_longer_than_N":true},
	{"name":"VisualWebInstruct-Seed","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct-Seed","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is the seed dataset we used to conduct Google Search.\\n\\n\\t\\n\\t\\t\\n\\t\\tLinks\\n\\t\\n\\nGithub|\\nPaper|\\nWebsite\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{visualwebinstruct,\\n    title={VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search},\\n    author = {Jia, Yiming and Li, Jiachen and Yue, Xiang and Li, Bo and Nie, Ping and Zou, Kai and Chen, Wenhu},\\n    journal={arXiv preprint arXiv:2503.10582},\\n    year={2025}\\n}\\n\\n","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"kuon-audio","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/kuon-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"‰πÖËøúËØ≠Èü≥\\nÊù•Ê∫ê‰∫éTVÂä®ÁîªÊèêÂèñÔºåËøõËøáuvrÂàÜÁ¶ªËÉåÊôØÈü≥Ôºå‰∫∫Â∑•Á≠õÈÄâË¥®ÈáèËæÉÂ•ΩÁöÑ„ÄÇ\\n610‰∏™Áü≠ËØ≠Èü≥Ôºå1‰∏™Ê≠åÊõ≤\\n","first_N":5,"first_N_keywords":["audio-to-audio","text-to-audio","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"crypto","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdulmoiz02/crypto","creator_name":"Abdul moiz","creator_url":"https://huggingface.co/Abdulmoiz02","description":"Abdulmoiz02/crypto dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"ChemistryImages","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LucasEllenberger/ChemistryImages","creator_name":"Lucas Ellenberger","creator_url":"https://huggingface.co/LucasEllenberger","description":"LucasEllenberger/ChemistryImages dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"danbooru2023-webp-4Mpixel_index","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/danbooru2023-webp-4Mpixel_index","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"Index files of KBlueLeaf/danbooru2023-webp-4Mpixel.\\nYou can download images from KBlueLeaf/danbooru2023-webp-4Mpixel with cheesechaser.\\nfrom cheesechaser.datapool import DanbooruWebpDataPool\\n\\npool = DanbooruWebpDataPool()\\n\\n# download danbooru images with webp format, to directory /data/danbooru_webp\\npool.batch_download_to_directory(\\n    resource_ids=range(6000000, 6001000),\\n    dst_dir='/data/danbooru_webp',\\n    max_workers=12,\\n)\\n\\n","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"sd3-images","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leafspark/sd3-images","creator_name":"leafspark","creator_url":"https://huggingface.co/leafspark","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStable Diffusion 3 Images\\n\\t\\n\\nA dataset of 1:1 images generated by Stable Diffusion 3, through glif.app.\\nFind the prompts in prompts.json, they correspond to the image based on number, for example the first element in the JSON array is x, then the image you're looking for is 0.jpg, and so on.\\nPrompts sourced from MohamedRashad/midjourney-detailed-prompts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData\\n\\t\\n\\nYou can find enhanced images by Gigapixel AI in the enhanced folder; these are the same 1024x1024 quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leafspark/sd3-images.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","n<1K","Image"],"keywords_longer_than_N":true},
	{"name":"A-Bench","keyword":"image-text-to-text","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/q-future/A-Bench","creator_name":"Q-Future","creator_url":"https://huggingface.co/q-future","description":"Project Page\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGlance at A-Bench Performance\\n\\t\\n\\nFor open-source models, LLaVA-NeXT (Qwen-110B) takes the first place. For closed-source models, GEMINI 1.5 PRO takes the first place.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvaluate your model on A-Bench\\n\\t\\n\\nFirst download the dataset and meta information from Huggingface.\\nThe imgs.zip contains all the AI-generated images and Abench.json contains all the meta information including the img_path, questions, answers, and categories. The item of Abench.json is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/q-future/A-Bench.","first_N":5,"first_N_keywords":["image-text-to-text","cc-by-4.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"kikongo-bible-asr","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/kikongo-bible-asr","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKikongo Bible ASR\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/kikongo-bible-asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kongo","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"UltraEdit_500k","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BleachNick/UltraEdit_500k","creator_name":"Hans Zhao","creator_url":"https://huggingface.co/BleachNick","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BleachNick/UltraEdit_500k.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"UltraEdit","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BleachNick/UltraEdit","creator_name":"Hans Zhao","creator_url":"https://huggingface.co/BleachNick","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BleachNick/UltraEdit.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","arxiv:2407.05282","doi:10.57967/hf/2481"],"keywords_longer_than_N":true},
	{"name":"commoncatalog-cc-by-ja","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ja","creator_name":"Yasunori Ozaki","creator_url":"https://huggingface.co/alfredplpl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommonCatalog CC-BY Ja\\n\\t\\n\\n„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅØCommonCatalog CC-BY„ÇíÊã°Âºµ„Åó„Å¶„ÄÅËøΩÂä†„ÅÆÊÉÖÂ†±„ÇíÂÖ•„Çå„Åü„ÇÇ„ÅÆ„Åß„Åô„ÄÇ\\n‰ª•‰∏ã„ÅÆÊÉÖÂ†±„ÅåËøΩÂä†„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\nLLaVA-JP„ÇíÊîπËâØ„Åó„Åü„É¢„Éá„É´„Å´„Çà„ÇãÁ∞°Êòì„Å™Êó•Êú¨Ë™û„Ç≠„É£„Éó„Ç∑„Éß„É≥1„Å§\\nLLaVA-JP„ÇíÊîπËâØ„Åó„Åü„É¢„Éá„É´„Å´„Çà„Çã„Åß„Åç„Çã„Å†„ÅëË©≥Á¥∞„Å™Êó•Êú¨Ë™û„Ç≠„É£„Éó„Ç∑„Éß„É≥3„Å§ (‰∫àÂÆö)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Code\\n\\t\\n\\ndf2=pandas.read_csv(\\\"cc-by-ja.csv\\\")\\n\\ndataset = load_dataset(\\\"common-canvas/commoncatalog-cc-by\\\",split=\\\"train\\\",streaming=True)\\n\\ndata_info=[]\\nfor i,data in enumerate(tqdm(dataset)):\\n    data[\\\"jpg\\\"].save(f\\\"/mnt/my_raid/pixart_jp/InternImgs/{i:09}.jpg\\\")\\n\\n    data_info.append({‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ja.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","Japanese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v1","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEwe bible for Text-to-Speech\\n\\t\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Ewe","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v1","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEwe bible for Text-to-Speech\\n\\t\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Ewe","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v1","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTwi Text-to-Speech\\n\\t\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Twi"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v1","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTwi Text-to-Speech\\n\\t\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Twi"],"keywords_longer_than_N":true},
	{"name":"imagenetpp-laion-t2i","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nyu-dice-lab/imagenetpp-laion-t2i","creator_name":"NYU DICE Lab","creator_url":"https://huggingface.co/nyu-dice-lab","description":"Dataset Card for ImageNet++'s LAION Text-to-Image Split\\n","first_N":5,"first_N_keywords":["mit","100K - 1M","webdataset","Image","Text"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v2_tts","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tText-to-Speech\\n\\t\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","translation","Ewe"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v2_tts","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tText-to-Speech\\n\\t\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","translation","Ewe"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v2_tts","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tText-to-Speech Dataset\\n\\t\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Twi","Akan"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v2_tts","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tText-to-Speech Dataset\\n\\t\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Twi","Akan"],"keywords_longer_than_N":true},
	{"name":"EUbookshop-Speech-Irish","keyword":"text-to-speech","license":"European Union Public License 1.1","license_url":"https://choosealicense.com/licenses/eupl-1.1/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nSynthetic audio dataset, created using Azure text-to-speech service.\\nThe bilingual text is a portion of the EUbookshop dataset, consisting of 33,634 text segments.\\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\\nThe speech data comprises approximately 159 hours and 45 minutes (159:45:05) spread across 67,268 utterances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features: ['audio'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"Recap-DataComp-1B","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestones/Recap-DataComp-1B","creator_name":"rock","creator_url":"https://huggingface.co/lodestones","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Recap-DataComp-1B\\n\\t\\n\\n\\n\\nRecap-DataComp-1B is a large-scale image-text dataset that has been recaptioned using an advanced LLaVA-1.5-LLaMA3-8B model to enhance the alignment and detail of textual descriptions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nOur paper aims to bridge this community effort, leveraging the powerful and open-sourced LLaMA-3, a GPT-4 level LLM.\\nOur recaptioning pipeline is simple: first, we fine-tune a LLaMA-3-8B powered‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lodestones/Recap-DataComp-1B.","first_N":5,"first_N_keywords":["zero-shot-classification","text-retrieval","image-to-text","text-to-image","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"libritts-r-filtered-speaker-descriptions","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/libritts-r-filtered-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotated LibriTTS-R\\n\\t\\n\\nThis dataset is an annotated version of a filtered LibriTTS-R [1]. \\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately 960 hours of read English speech at 24kHz sampling rate, published in 2019. \\nIn the text_description column, it provides natural language annotations on the characteristics of speakers and utterances, that have been generated using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts-r-filtered-speaker-descriptions.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"pixelprose","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestones/pixelprose","creator_name":"rock","creator_url":"https://huggingface.co/lodestones","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom Pixels to Prose: A Large Dataset of Dense Image Captions\\n\\t\\n\\n[[ arXiv paper ]]\\nPixelProse is a comprehensive dataset of over 16M (million) synthetically generated captions, \\nleveraging cutting-edge vision-language models (Gemini 1.0 Pro Vision) for detailed and accurate descriptions.\\n@article{pixelprose24,\\n  title   = {{From Pixels to Prose: A Large Dataset of Dense Image Captions}},\\n  author  = {Vasu Singla and Kaiyu Yue and Sukriti Paul and Reza Shirkavand and Mayuka‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lodestones/pixelprose.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"multimodalpragmatic","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tongliuphysics/multimodalpragmatic","creator_name":"Tong Liu","creator_url":"https://huggingface.co/tongliuphysics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultimodal Pragmatic Jailbreak on Text-to-image Models\\n\\t\\n\\nThe Multimodal Pragmatic Unsafe Prompts (MPUP) is a dataset designed to assess the multimodal pragmatic safety in Text-to-Image (T2I) models. \\nIt comprises two key sections: image_prompt, and text_prompt. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Usage\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownloading the Data\\n\\t\\n\\nTo download the dataset, install Huggingface Datasets and then use the following command:\\nfrom datasets import load_dataset\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tongliuphysics/multimodalpragmatic.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"sql-create-context-pt","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emdemor/sql-create-context-pt","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEste dataset  √© uma vers√£o traduzida para o portugu√™s do dataset b-mc2/sql-create-context,\\nque foi constru√≠do a partir dos datasets WikiSQL e Spider. Ele cont√©m exemplos de perguntas\\nem portugu√™s, instru√ß√µes SQL CREATE TABLE e consultas SQL que respondem √†s perguntas\\nutilizando a instru√ß√£o CREATE TABLE como contexto.\\nO principal objetivo deste dataset √© ajudar modelos de linguagem natural  em portugu√™s a gerar consultas\\nSQL precisas e contextualizadas, prevenindo a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/sql-create-context-pt.","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\\nIt is not intended for training.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnhancement procedure\\n\\t\\n\\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRessources\\n\\t\\n\\nResults for speech-to-phoneme‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"ChronoMagic-Pro","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BestWishYsh/ChronoMagic-Pro","creator_name":"YSH","creator_url":"https://huggingface.co/BestWishYsh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\ncat ChronoMagic-Pro.zip.part-* > ChronoMagic-Pro.zip \\nunzip ChronoMagic-Pro.zip\\n\\n\\n\\n\\n [NeurIPS D&B 2024 Spotlight] ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of Text-to-Time-lapse Video Generation \\n\\n If you like our project, please give us a star ‚≠ê on GitHub for the latest update.  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüí° Description\\n\\t\\n\\n\\nVenue: NeurIPS 2024 D&B Spotlight\\nRepository: Code, Page, Data\\nPaper: arxiv.org/abs/2406.18522\\nPoint of Contact: Shenghai Yuan\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚úèÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BestWishYsh/ChronoMagic-Pro.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"ESLTTS","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/ESLTTS","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tESLTTS\\n\\t\\n\\nThe full paper can be accessed here: arXiv, IEEE Xplore.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Access\\n\\t\\n\\nYou can access this dataset through Huggingface or Google Driver or IEEE Dataport.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbstract\\n\\t\\n\\nWith the progress made in speaker-adaptive TTS approaches, advanced approaches have shown a remarkable capacity to reproduce the speaker‚Äôs voice in the commonly used TTS datasets. However, mimicking voices characterized by substantial accents, such as non-native English speakers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/ESLTTS.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","English"],"keywords_longer_than_N":true},
	{"name":"ChronoMagic-ProH","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BestWishYsh/ChronoMagic-ProH","creator_name":"YSH","creator_url":"https://huggingface.co/BestWishYsh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\ncat ChronoMagic-ProH_part_* > ChronoMagic-ProH.zip \\nunzip ChronoMagic-ProH.zip\\n\\n\\n\\n\\n [NeurIPS D&B 2024 Spotlight] ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of Text-to-Time-lapse Video Generation \\n\\n If you like our project, please give us a star ‚≠ê on GitHub for the latest update.  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüí° Description\\n\\t\\n\\n\\nVenue: NeurIPS 2024 D&B Spotlight\\nRepository: Code, Page, Data\\nPaper: arxiv.org/abs/2406.18522\\nPoint of Contact: Shenghai Yuan\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚úèÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BestWishYsh/ChronoMagic-ProH.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"augmented-recap-datacomp-3m","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/augmented-recap-datacomp-3m","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"This is an experimental augmentation of about 3 million synthetic captions from Recap-Datacomp-1B. This dataset includes about 2 million multilingual captions. \\nIt attempts to balance for gender stereotypes, added occupations, race, union membership, and religion to a subsample. We have also performed hair color and eye color balancing. It also includes some permutations of sentence orders, and modificaitons of the number of items (\\\"Two\\\" is changed to \\\"Three\\\", \\\"Four\\\", etc.)\\nWe have also run‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/augmented-recap-datacomp-3m.","first_N":5,"first_N_keywords":["zero-shot-classification","text-retrieval","image-to-text","text-to-image","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"commoncanvas-cc-by-recap-2","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alfredplpl/commoncanvas-cc-by-recap-2","creator_name":"Yasunori Ozaki","creator_url":"https://huggingface.co/alfredplpl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommonCatalog CC-BY Recaptioning 2\\n\\t\\n\\n„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅØCommonCatalog CC-BY„ÇíÊã°Âºµ„Åó„Å¶„ÄÅËøΩÂä†„ÅÆÊÉÖÂ†±„ÇíÂÖ•„Çå„Åü„ÇÇ„ÅÆ„Åß„Åô„ÄÇ ‰ª•‰∏ã„ÅÆÊÉÖÂ†±„ÅåËøΩÂä†„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\nFlorence-2-large-ft„ÅßDense Captioning (More detailed caption) „Åó„ÅüËã±Ë™û„Ç≠„É£„Éó„Ç∑„Éß„É≥\\n\\nstreaming=True„ÅßË™≠„ÅøËæº„ÇÄ„Å®Âêå„ÅòÈ†Ü„Å´Ë™≠„ÅøËæº„Åæ„Çå„Åæ„Åô„ÅÆ„Åß„Åù„Çå„ÇíÂà©Áî®„Åô„Çã„ÅÆ„Åå‰∏ÄÁï™Ê•Ω„Åß„Åô„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Code\\n\\t\\n\\nimport pandas\\nfrom datasets import load_dataset\\nfrom tqdm import tqdm\\nimport json\\n\\ndf=pandas.read_csv(\\\"commoncatalog-cc-by-phi3.csv\\\")\\n\\ndataset = load_dataset(\\\"common-canvas/commoncatalog-cc-by\\\",split=\\\"train\\\",streaming=True)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/commoncanvas-cc-by-recap-2.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mabama-v6-audio","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ovieyra21/mabama-v6-audio","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmabama-v6-audio Dataset\\n\\t\\n\\nEste dataset, mabama-v6-audio, est√° dise√±ado para tareas de text-to-speech (TTS) y contiene grabaciones de audio junto con sus correspondientes transcripciones en espa√±ol. Est√° dividido en tres partes: entrenamiento, prueba y validaci√≥n, permitiendo un desarrollo y evaluaci√≥n efectivos de modelos TTS.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEstructura del Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nfile_name: Nombre del archivo de audio.\\ntext: Transcripci√≥n del audio.\\nspeaker_id:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ovieyra21/mabama-v6-audio.","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"sbucaptions","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eaglewatch/sbucaptions","creator_name":"Yongwoo Jeong","creator_url":"https://huggingface.co/eaglewatch","description":"eaglewatch/sbucaptions dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"ChronoMagic-Bench","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BestWishYsh/ChronoMagic-Bench","creator_name":"YSH","creator_url":"https://huggingface.co/BestWishYsh","description":"\\n\\n\\n [NeurIPS D&B 2024 Spotlight] ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of Text-to-Time-lapse Video Generation \\n\\n If you like our project, please give us a star ‚≠ê on GitHub for the latest update.  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüí° Description\\n\\t\\n\\n\\nVenue: NeurIPS 2024 D&B Spotlight\\nRepository: Code, Page, Data\\nPaper: arxiv.org/abs/2406.18522\\nPoint of Contact: Shenghai Yuan\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚úèÔ∏è Citation\\n\\t\\n\\nIf you find our paper and code useful in your research, please consider giving a star and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BestWishYsh/ChronoMagic-Bench.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"DataComp-12M","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlfoundations/DataComp-12M","creator_name":"ML Foundations","creator_url":"https://huggingface.co/mlfoundations","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DataComp-12M\\n\\t\\n\\n\\n\\nThis dataset contains a 12M subset of DataComp-1B-BestPool.\\nWe distribute the image url-text samples and metadata under a standard Creative Common CC-BY-4.0 license. The individual images are under their own copyrights.\\nImage-text models trained on DataComp-12M are significantly better than on CC-12M/YFCC-15M as well as DataComp-Small/Medium.\\nDataComp-12M was introduced in MobileCLIP paper and along with the reinforced dataset DataCompDR-12M.\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlfoundations/DataComp-12M.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","cc-by-4.0","Image"],"keywords_longer_than_N":true},
	{"name":"OpenVid-1M","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestones/OpenVid-1M","creator_name":"rock","creator_url":"https://huggingface.co/lodestones","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper \\\"OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation\\\".\\nOpenVid-1M is a high-quality text-to-video dataset designed for research institutions to enhance video quality, featuring high aesthetics, clarity, and resolution. It can be used for direct training or as a quality tuning complement to other video datasets.\\nAll videos in the OpenVid-1M dataset have resolutions of at least 512√ó512. Furthermore, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lodestones/OpenVid-1M.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"OpenVid-1M","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestones/OpenVid-1M","creator_name":"rock","creator_url":"https://huggingface.co/lodestones","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper \\\"OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation\\\".\\nOpenVid-1M is a high-quality text-to-video dataset designed for research institutions to enhance video quality, featuring high aesthetics, clarity, and resolution. It can be used for direct training or as a quality tuning complement to other video datasets.\\nAll videos in the OpenVid-1M dataset have resolutions of at least 512√ó512. Furthermore, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lodestones/OpenVid-1M.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"OpenVid-1M","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestone-horizon/OpenVid-1M","creator_name":"Horizon","creator_url":"https://huggingface.co/lodestone-horizon","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper \\\"OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation\\\".\\nOpenVid-1M is a high-quality text-to-video dataset designed for research institutions to enhance video quality, featuring high aesthetics, clarity, and resolution. It can be used for direct training or as a quality tuning complement to other video datasets.\\nAll videos in the OpenVid-1M dataset have resolutions of at least 512√ó512. Furthermore, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lodestone-horizon/OpenVid-1M.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"OpenVid-1M","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestone-horizon/OpenVid-1M","creator_name":"Horizon","creator_url":"https://huggingface.co/lodestone-horizon","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper \\\"OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation\\\".\\nOpenVid-1M is a high-quality text-to-video dataset designed for research institutions to enhance video quality, featuring high aesthetics, clarity, and resolution. It can be used for direct training or as a quality tuning complement to other video datasets.\\nAll videos in the OpenVid-1M dataset have resolutions of at least 512√ó512. Furthermore, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lodestone-horizon/OpenVid-1M.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"MM_Math","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/THU-KEG/MM_Math","creator_name":"Knowledge Engineer Group @ Tsinghua University","creator_url":"https://huggingface.co/THU-KEG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMM_Math Datasets\\n\\t\\n\\nWe introduce our multimodal mathematics dataset, MM-MATH,. \\nThis dataset is collected from real middle school exams in China, and all the math problems are open-ended to evaluate the mathematical problem-solving abilities of current multimodal models. MM-MATH is annotated with fine-grained three-dimensional labels: difficulty, grade, and knowledge points. The difficulty level is determined based on the average scores of student exams, the grade labels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/THU-KEG/MM_Math.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"photo-aesthetics","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/terminusresearch/photo-aesthetics","creator_name":"Terminus Research Group","creator_url":"https://huggingface.co/terminusresearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Aesthetics Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\nCaptions were created with CogVLM.\\n","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"photo-anatomy","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/terminusresearch/photo-anatomy","creator_name":"Terminus Research Group","creator_url":"https://huggingface.co/terminusresearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Anatomy Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nImages contain a majority of images of \\\"people holding things\\\".\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\nCaptions were created with CogVLM.\\n","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"photo-architecture","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/terminusresearch/photo-architecture","creator_name":"Terminus Research Group","creator_url":"https://huggingface.co/terminusresearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Architecture Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nImages contain a majority of images of buildings and unique architecture. Some buildings may be copyrighted, though training is currently understood to fall under fair-use.\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\nCaptions were created with CogVLM.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"photo-typography","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/terminusresearch/photo-typography","creator_name":"Terminus Research Group","creator_url":"https://huggingface.co/terminusresearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Typography Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nA majority of these images contain text, captioned with CogVLM.\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\n","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"photochat_plus","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/passing2961/photochat_plus","creator_name":"Young-Jun Lee","creator_url":"https://huggingface.co/passing2961","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for PhotoChat++\\n\\t\\n\\n\\nüö® Disclaimer: All models and datasets are intended for research purposes only.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPhotoChat++ is a publicly available multi-modal dialogue dataset, an extended version of PhotoChat. PhotoChat++ contains six intent labels, a triggering sentence, an image description, and salient information (e.g., ‚Äúwords‚Äù or ‚Äúphrases‚Äù) to invoke the image-sharing behavior. The purpose of this dataset is to thoroughly assess the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/passing2961/photochat_plus.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","conversational","monolingual","PhotoChat"],"keywords_longer_than_N":true},
	{"name":"photo-aesthetics","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestones/photo-aesthetics","creator_name":"rock","creator_url":"https://huggingface.co/lodestones","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Aesthetics Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\nCaptions were created with CogVLM.\\n","first_N":5,"first_N_keywords":["mit","üá∫üá∏ Region: US","photographs","photos","image-data"],"keywords_longer_than_N":true},
	{"name":"photo-aesthetics","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestone-horizon/photo-aesthetics","creator_name":"Horizon","creator_url":"https://huggingface.co/lodestone-horizon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Aesthetics Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\nCaptions were created with CogVLM.\\n","first_N":5,"first_N_keywords":["mit","üá∫üá∏ Region: US","photographs","photos","image-data"],"keywords_longer_than_N":true},
	{"name":"photo-architecture","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestones/photo-architecture","creator_name":"rock","creator_url":"https://huggingface.co/lodestones","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Architecture Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nImages contain a majority of images of buildings and unique architecture. Some buildings may be copyrighted, though training is currently understood to fall under fair-use.\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\nCaptions were created with CogVLM.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"photo-architecture","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestone-horizon/photo-architecture","creator_name":"Horizon","creator_url":"https://huggingface.co/lodestone-horizon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Architecture Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nImages contain a majority of images of buildings and unique architecture. Some buildings may be copyrighted, though training is currently understood to fall under fair-use.\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\nCaptions were created with CogVLM.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"photo-anatomy","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestones/photo-anatomy","creator_name":"rock","creator_url":"https://huggingface.co/lodestones","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Anatomy Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nImages contain a majority of images of \\\"people holding things\\\".\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\nCaptions were created with CogVLM.\\n","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"photo-typography","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestones/photo-typography","creator_name":"rock","creator_url":"https://huggingface.co/lodestones","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Typography Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nA majority of these images contain text, captioned with CogVLM.\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\n","first_N":5,"first_N_keywords":["mit","üá∫üá∏ Region: US","photographs","photos","image-data"],"keywords_longer_than_N":true},
	{"name":"photo-typography","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestone-horizon/photo-typography","creator_name":"Horizon","creator_url":"https://huggingface.co/lodestone-horizon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Typography Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nA majority of these images contain text, captioned with CogVLM.\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\n","first_N":5,"first_N_keywords":["mit","üá∫üá∏ Region: US","photographs","photos","image-data"],"keywords_longer_than_N":true},
	{"name":"Speech-MASSIVE_vie","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/Speech-MASSIVE_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVietnamse subset of the Speech-MASSIVE dataset\\n\\t\\n\\nextracted from:\\n\\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE\\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE-test\\n\\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-speechmassive.py\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"BibleMMS_vie","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/BibleMMS_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVietnamse subset of the BibleMMS dataset\\n\\t\\n\\nextracted from: https://huggingface.co/datasets/Flux9665/BibleMMS\\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-biblemms.py\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"violine_dataset","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/violine_dataset","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/violine_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-audio","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"HumanRefiner","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Enderfga/HumanRefiner","creator_name":"Guian Fang","creator_url":"https://huggingface.co/Enderfga","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHumanRefiner\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWelcome to the official code repository for the paper \\\"HumanRefiner: Benchmarking Abnormal Human Generation and Refining with Coarse-to-fine Pose-Reversible Guidance.\\\"\\nIn this project, we introduce AbHuman, the first large-scale benchmark focused on anatomical anomalies. The benchmark consists of 56K synthesized human images, each annotated with 147K human anomalies in 18 different categories. Based on this, we developed HumanRefiner, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Enderfga/HumanRefiner.","first_N":5,"first_N_keywords":["text-to-image","English","mit","Image","Text"],"keywords_longer_than_N":true},
	{"name":"midjourney-niji-1m-llavanext","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/midjourney-niji-1m-llavanext","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for midjourney-niji-1m-llavanext\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a dataset of 2,079,886 synthetic captions for 1,039,943 images from midjourney-v6-520k-raw and nijijourney-v6-520k-raw. The captions were produced using https://huggingface.co/lmms-lab/llama3-llava-next-8b inferenced in float16 after tags were generated with wd-swinv2-tagger-v3, followed by cleanup and shortening with Meta-Llama-3-8B.\\nAll images with metadata are available as MozJPEG encoded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/midjourney-niji-1m-llavanext.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"VietMed_unlabeled","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) unlabeled set\\n\\t\\n\\nofficial announcement: https://arxiv.org/abs/2404.05659\\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\\nthis repo contains the unlabeled set: 966h - 230k samples\\ni also gather the metadata: see info.csv\\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-unlabeled.py\\nneed to do: check misspelling, restore foreign words phonetised‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"VietMed_labeled","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_labeled","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) labeled set\\n\\t\\n\\nofficial announcement: https://arxiv.org/abs/2404.05659\\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\\nthis repo contains the labeled set: 9.2k samples\\ni also gather the metadata: see info.csv\\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-labeled.py\\nneed to do: check misspelling, restore foreign words phonetised to vietnamese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_labeled.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"COSTG_v1","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QinLei086/COSTG_v1","creator_name":"Qin Lei","creator_url":"https://huggingface.co/QinLei086","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCOSTG_v1\\n\\t\\n\\nThis dataset has been introduced in the ECCV 2024 paper titled Enriching Information and Preserving Semantic Consistency in Expanding Curvilinear Object Segmentation Datasets.\\nIt encompasses three data types (directories), namely angiography (angiography coronary artery disease), crack, and retina (retinal vessels), which collectively contain six public datasets as described in the paper.\\nAdditionally, the unprocessed_json directory includes raw, unprocessed textual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QinLei086/COSTG_v1.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"dreambench_plus","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuangpeng/dreambench_plus","creator_name":"Yuang Peng","creator_url":"https://huggingface.co/yuangpeng","description":"\\nThe image above shows the visualization of data distribution. (a) Images comparison between DreamBench and DreamBench++ using t-SNE. (b) Image and prompt distribution of DreamBench++.\\nDreamBench++ contains three categories: live subject (animals and humans), object, and style, with a total of 150 images. Among them, 120 images are photorealistic and 30 are non-photorealistic. Each image has 9 corresponding prompts, each with varying levels of difficulty, including 4 prompts for photorealistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuangpeng/dreambench_plus.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","Image","Text"],"keywords_longer_than_N":true},
	{"name":"danbooru2023-florence2-caption","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KBlueLeaf/danbooru2023-florence2-caption","creator_name":"Shih-Ying Yeh","creator_url":"https://huggingface.co/KBlueLeaf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDanbooru2023 - Florence2 Caption dataset\\n\\t\\n\\nThis dataset contains captions of danbooru2023 images generated by microsoft/Florence-2-large \\nI use original one with  task token\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\nparquet:\\n\\nkey: the danbooru id of the image\\nparsed: parsed florence 2 output of the image\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStat\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMORE_DETAILED_CAPTION\\n\\t\\n\\n\\nEntries: 7,438,449\\nOutput Tokens (Min/Max/Mean/Median):\\nFlan T5 Tokenizer: 19/736/120/114\\nDFN CLIP Tokenizer: 19/826/108.7/103\\nQwen2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KBlueLeaf/danbooru2023-florence2-caption.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"pixel_sorting","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/1aurent/pixel_sorting","creator_name":"LaureŒ∑t Fainsin","creator_url":"https://huggingface.co/1aurent","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPixel Sorting\\n\\t\\n\\n\\nThis dataset contains urls to images with a \\\"pixel sorting\\\" style.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns Details\\n\\t\\n\\n\\nurl: the url to the image\\nhash: the blake2 hash of the image\\ncaption: a CogVLM caption\\n\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"simon-arc-rle-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-rle-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"neoneye/simon-arc-rle-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"e621-2024-webp-4Mpixel","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NebulaeWis/e621-2024-webp-4Mpixel","creator_name":"Nebulae","creator_url":"https://huggingface.co/NebulaeWis","description":"Dataset Description:\\nThis is a processed version of the https://huggingface.co/datasets/boxingscorpionbagel/e621-2024 dataset, primarily prepared for personal use in future projects.\\nTherefore, for licensing and other legal information, please refer to the original project.\\nYou can directly download tar file,or use https://deepghs.github.io/hfutils/main/api_doc/index/fetch.html#hf-tar-file-download to download anything .webp file you want.\\nThe following modifications have been made to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NebulaeWis/e621-2024-webp-4Mpixel.","first_N":5,"first_N_keywords":["image-to-image","text-to-image","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Libriheavy-HQ","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Libriheavy-HQ\\n\\t\\n\\n\\n\\nLibriheavy: a 50,000 hours ASR corpus with punctuation casing \\nand context. Libriheavy is a labeled version of Libri-Light.\\nLibriheavy-HQ replaces the default Libri-Light audio files with the highest quality available versions from librivox \\nwithout re-encoding them. \\nIn most cases, this consists an upgrade of the source audio from a 64kbps .mp3 to a 128kbps .mp3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the Libriheavy-HQ dataset, adapted for the datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Libriheavy-HQ","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Libriheavy-HQ\\n\\t\\n\\n\\n\\nLibriheavy: a 50,000 hours ASR corpus with punctuation casing \\nand context. Libriheavy is a labeled version of Libri-Light.\\nLibriheavy-HQ replaces the default Libri-Light audio files with the highest quality available versions from librivox \\nwithout re-encoding them. \\nIn most cases, this consists an upgrade of the source audio from a 64kbps .mp3 to a 128kbps .mp3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the Libriheavy-HQ dataset, adapted for the datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"svg-stack-tmp-alpha-chunk","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrOvkill/svg-stack-tmp-alpha-chunk","creator_name":"Samuel L Meyers","creator_url":"https://huggingface.co/MrOvkill","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSvg Stack Labeled - Temporary Split Alpha ( Chunk )\\n\\t\\n\\nThis dataset is a chunk of SVG Stack Labeled, and was uploaded solely because I lacked reliable high-volume cloud storage at the time, and was going to make the dataset available on HuggingFace in any case.\\nHowever, while I will be deleting the now defunct and unused chunks, this one received a few users, and I truly appreciate your usage of my dataets. Thus, this dataset will remain, even as the others perish.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrOvkill/svg-stack-tmp-alpha-chunk.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"icons","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ActuallyTaylor/icons","creator_name":"Taylor Lineman","creator_url":"https://huggingface.co/ActuallyTaylor","description":"A set of macOS Icons from https://macosicons.com/. Labeled using GPT-4o.\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"simon-arc-rle-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-rle-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type.\\nThe LLM learned some of the types fine. However histograms are causing problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are histograms. Since this is what my LLM is struggling with.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"housey-home","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrOvkill/housey-home","creator_name":"Samuel L Meyers","creator_url":"https://huggingface.co/MrOvkill","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHousey Home v1 ( DEFUNCT )\\n\\t\\n\\nThe data has a flaw, it occurred during the initial synthesis. The erroneous fields have been removed, and the data is currently being selectively re-synthesized.\\nAs of 07-15-2024, this dataset is now defunct. It will no longer receive stability, content, or null row fixes. However, as all images are sourced from generative AI models, open source ones at that, I have decided to make this MIT, and will perform tasks upon request if needed. Just ask.\\n-<3\\n","first_N":5,"first_N_keywords":["unconditional-image-generation","text-to-image","image-to-text","English","mit"],"keywords_longer_than_N":true},
	{"name":"housey-home-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrOvkill/housey-home-v2","creator_name":"Samuel L Meyers","creator_url":"https://huggingface.co/MrOvkill","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHousey Home v2 - Like v1 never happened\\n\\t\\n\\nI was in the process of producing a fully synthetic dataset for ungrounded image generation using an unconventional combination of layers. As such, I needed a dataset of highly similar objects with 'themes'. In order to produce log(x, y) combinations of options in the final model. This is that dataset.\\nThe initial ( 07/15/2024 ) release includes ~2k unique houses, each processed using a VQA, ybelkada/blip-vqa-base, to be precise.\\nRelease 2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrOvkill/housey-home-v2.","first_N":5,"first_N_keywords":["text-to-image","unconditional-image-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"civitai","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigdata-pw/civitai","creator_name":"BIG data","creator_url":"https://huggingface.co/bigdata-pw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCivitai Images\\n\\t\\n\\nImages+metadata from Civitai\\nStats:\\n\\n~4.1M\\n\\nFormats:\\n\\nWebDataset\\n10k per shard, ~2GB\\njpg + json\\n__key__ is Civitai image id\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNotes\\n\\t\\n\\n\\n~464k images with no meta field are excluded, this is ~10% of images collected\\nFiles for some entries are actually videos, these will be released separately\\nCivitai extract metadata on upload, the exact fields in meta will depend on the UI used, some are common e.g. prompt, others are UI specific\\nIncludes reaction‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigdata-pw/civitai.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","apache-2.0","1M<n<10M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"housey-home-pixart-alpha","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrOvkill/housey-home-pixart-alpha","creator_name":"Samuel L Meyers","creator_url":"https://huggingface.co/MrOvkill","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHousey Home v2: PixArt Alpha Split\\n\\t\\n\\nI was in the process of producing a fully synthetic dataset for ungrounded image generation using an unconventional combination of layers. As such, I needed a dataset of highly similar objects with 'themes'. In order to produce log(x, y) combinations of options in the final model. This is that dataset.\\nThe initial ( 07/15/2024 ) release includes ~1.3k unique houses, each processed using a VQA, PixArt-alpha/PixArt-Sigma-XL-2-1024-MS, to be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrOvkill/housey-home-pixart-alpha.","first_N":5,"first_N_keywords":["text-to-image","unconditional-image-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"dataset-mmb-v1","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gitgato/dataset-mmb-v1","creator_name":"Git Porter","creator_url":"https://huggingface.co/gitgato","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmabama-v6-audio Dataset\\n\\t\\n\\nEste dataset, mabama-v6-audio, est√° dise√±ado para tareas de text-to-speech (TTS) y contiene grabaciones de audio junto con sus correspondientes transcripciones en espa√±ol. Est√° dividido en tres partes: entrenamiento, prueba y validaci√≥n, permitiendo un desarrollo y evaluaci√≥n efectivos de modelos TTS.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEstructura del Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nfile_name: Nombre del archivo de audio.\\ntext: Transcripci√≥n del audio.\\nspeaker_id:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gitgato/dataset-mmb-v1.","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"mabama-v1-audio","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ovieyra21/mabama-v1-audio","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","description":"ovieyra21/mabama-v1-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","10M<n<100M","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"vintage-artworks-60k-captioned","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SilentAntagonist/vintage-artworks-60k-captioned","creator_name":"John Smith","creator_url":"https://huggingface.co/SilentAntagonist","description":"This is a dataset consisting of 60k vintage artworks from the 20th century, consisting of vintage pulp, sci-fi and pinup artworks from that era.\\nThe dataset has short and long captions for each image, as well as resolution information. The large captions (large_caption column) were made with florence-2-large-ft, and then shortened with llama 3 8b (see short_caption column).\\n","first_N":5,"first_N_keywords":["feature-extraction","image-classification","image-feature-extraction","text-to-image","image-to-text"],"keywords_longer_than_N":true},
	{"name":"simon-arc-histogram-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-histogram-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nThe counters are in the range 1-20.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nThe counters are in the range 1-50.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nThe counters are in the range 1-100.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nThe counters are in the range 1-200.\\nHistogram.remove_other_colors() added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nI forgot to update the range of the counters when doing comparisons.\\nNow the counters are in the range 1-100.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nThe counters are in the range 1-200.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-histogram-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-histogram-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-histogram-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nThe counters are in the range 1-20.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nThe counters are in the range 1-50.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nThe counters are in the range 1-100.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nThe counters are in the range 1-200.\\nHistogram.remove_other_colors() added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nI forgot to update the range of the counters when doing comparisons.\\nNow the counters are in the range 1-100.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nThe counters are in the range 1-200.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-histogram-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"layoutbench","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/j-min/layoutbench","creator_name":"Jaemin Cho","creator_url":"https://huggingface.co/j-min","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLayoutBench\\n\\t\\n\\nRelease of LayoutBench dataset from Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation (CVPR 2024 Workshop)\\nSee also LayoutBench-COCO for zero-shot evaluation on OOD layouts with real objects.\\n[Project Page]\\n[Paper]\\nAuthors: \\nJaemin Cho,\\nLinjie Li,\\nZhengyuan Yang,\\nZhe Gan,\\nLijuan Wang,\\nMohit Bansal\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nLayoutBench is a diagnostic benchmark that examines layout-guided image generation models on arbitrary, unseen‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/j-min/layoutbench.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"layoutbench-coco","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/j-min/layoutbench-coco","creator_name":"Jaemin Cho","creator_url":"https://huggingface.co/j-min","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLayoutBench-COCO\\n\\t\\n\\nRelease of LayoutBench-COCO dataset from Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation (CVPR 2024 Workshop)\\nSee also LayoutBench for fine-grained evaluation on OOD layouts with CLEVR objects.\\n[Project Page]\\n[Paper]\\nAuthors: \\nJaemin Cho,\\nLinjie Li,\\nZhengyuan Yang,\\nZhe Gan,\\nLijuan Wang,\\nMohit Bansal\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExamples layout inputs in 4 skills\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nLayoutBench-COCO is a diagnostic benchmark that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/j-min/layoutbench-coco.","first_N":5,"first_N_keywords":["text-to-image","English","mit","arxiv:2304.06671","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"simon-arc-image-v48","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v48","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v48.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v49","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v49","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v49.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v50","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v50","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v50.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v51","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v51","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v51.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v52","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v52","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v52.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v53","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v53","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v53.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v54","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v54","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v54.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v55","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v55","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v55.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v56","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v56","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v56.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v57","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v57","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v57.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v58","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v58","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v58.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v59","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v59","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v59.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v60","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v60","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v60.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v61","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v61","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v61.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v62","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v62","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v62.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"artbench-pd-256x256","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alfredplpl/artbench-pd-256x256","creator_name":"Yasunori Ozaki","creator_url":"https://huggingface.co/alfredplpl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ArtBench Public Domain 256x256\\n\\t\\n\\n\\nÊó•Êú¨Ë™û„ÅØ„Åì„Å°„Çâ\\nThis repository is the subset of ArtBench.\\nArtBench is the dataset for historical arts such as Art Nouveau and Ukiyo-e.\\nI picked up public domain images from ArtBench. Then, I create new dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nYou can use huggingface datasets to download the dataset.\\nYou can also download the tar file.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"alfredplpl/artbench-pd-256x256\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/artbench-pd-256x256.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v63","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v63","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v63.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v64","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v64","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v64.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v65","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v65","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v65.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v66","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v66","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v66.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v67","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v67","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v67.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-shape-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-shape-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nDetect shape2x2 and shape3x3_center.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDetect shape2x2 and shape3x3_center and shape3x3_opposite.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on counting the unique number of colors. corners and diamond4.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nSame weight to all transformations.\\nThe image sizes are between 1 and 30 pixels.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-shape-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-shape-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-shape-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nDetect shape2x2 and shape3x3_center.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDetect shape2x2 and shape3x3_center and shape3x3_opposite.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on counting the unique number of colors. corners and diamond4.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nSame weight to all transformations.\\nThe image sizes are between 1 and 30 pixels.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-shape-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-task-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-task-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM validation loss went down and then continue to rise afterwards,\\nso I guess the complexity of the dataset was too high.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are histograms. \\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nLet's see if the LLM does better on this one.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on pair comparisons‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-task-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-task-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-task-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM validation loss went down and then continue to rise afterwards,\\nso I guess the complexity of the dataset was too high.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are histograms. \\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nLet's see if the LLM does better on this one.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on pair comparisons‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-task-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v4.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-task-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-task-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM validation loss went down and then continue to rise afterwards,\\nso I guess the complexity of the dataset was too high.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are histograms. \\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nLet's see if the LLM does better on this one.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on pair comparisons‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-task-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v68","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v68","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v68.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v4.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v4.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v14","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v14","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v14.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v15","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v15","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v15.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v16","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v16","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v16.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v17","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v17","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v17.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v18","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v18","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v18.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v19","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v19","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v19.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v20","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v20","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v20.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v21","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v21","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v21.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v22","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v22","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v22.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"RSTeller_legacy","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SlytherinGe/RSTeller_legacy","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","description":"\\n\\t\\n\\t\\t\\n\\t\\t‚õî Usage Warning\\n\\t\\n\\nThis is the legacy version of the RSTeller dataset and is not the latest version referenced in our paper. We are keeping it available here to provide the community with easy access to additional data.\\nFor the details and the usage of the dataset, please refer to our github page.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find the dataset and our paper useful, please consider citing our paper:\\n@misc{ge2025rstellerscalingvisuallanguage,\\n      title={RSTeller: Scaling Up Visual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller_legacy.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","zero-shot-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v23","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v23","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v23.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v24","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v24","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v24.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v25","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v25","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v25.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v14","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v14","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v14.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v15","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v15","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v15.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v26","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v26","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v26.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v27","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v27","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v27.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v28","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v28","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v28.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v29","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v29","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v29.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v30","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v30","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v30.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v31","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v31","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v31.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v32","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v32","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v32.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v33","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v33","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v33.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v34","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v34","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v34.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v35","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v35","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v35.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-scale-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-scale-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nScale up/down an image by the x and y axis.\\nmax_scale=3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v36","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v36","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v36.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v37","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v37","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v37.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-symmetry-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-symmetry-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nFrom an input image, create a symmetric output image. image size 1-10.\\n\\nhstack(a b)\\nhstack(a b c)\\nvstack(a b)\\nvstack(a b c)\\n2x2(a b c d)\\n\\nThe abcd can be: orig, flipx, flipy, 180.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-symmetry-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-symmetry-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nFrom an input image, create a symmetric output image. image size 1-10.\\n\\nhstack(a b)\\nhstack(a b c)\\nvstack(a b)\\nvstack(a b c)\\n2x2(a b c d)\\n\\nThe abcd can be: orig, flipx, flipy, 180.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size 1-30.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v38","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v38","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v38.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v39","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v39","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v39.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-scale-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-scale-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nScale up/down an image by the x and y axis.\\nmax_scale=3.\\nimage_size: 1-30.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nRecognize what kind of scale transformation is happening.\\nmax_scale=3.\\nimage_size: 1-15.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-scale-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-scale-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nScale up/down an image by the x and y axis.\\nmax_scale=3.\\nimage_size: 1-30.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nRecognize what kind of scale transformation is happening.\\nmax_scale=3.\\nimage_size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nmax_scale=5.\\nimage_size: 1-30.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v40","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v40","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v40.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v41","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v41","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v41.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-scale-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-scale-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nScale up/down an image by the x and y axis.\\nmax_scale=3.\\nimage_size: 1-30.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nRecognize what kind of scale transformation is happening.\\nmax_scale=3.\\nimage_size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nmax_scale=5.\\nimage_size: 1-30.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\ndifferent seed\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-scale-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the images gets scaled up/down in both x and y direction.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nscale factor: 1-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v42","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v42","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v42.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v43","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v43","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v43.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-scale-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-scale-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nScale up/down an image by the x and y axis.\\nmax_scale=3.\\nimage_size: 1-30.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nRecognize what kind of scale transformation is happening.\\nmax_scale=3.\\nimage_size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nmax_scale=5.\\nimage_size: 1-30.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\ndifferent seed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nmax_scale=7.\\nimage_size: 1-30.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"CHUBS","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chen-yingfa/CHUBS","creator_name":"Yingfa Chen","creator_url":"https://huggingface.co/chen-yingfa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCHUBS: A Large-Scale Dataset of Chu Bamboo Slip Script\\n\\t\\n\\n\\n  Code | Paper (upcoming)\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a large-scale dataset of Chu bamboo slip (CBS, Chinese: Ê•öÁÆÄ, chujian) script, an ancient Chinese script used during the Spring and Autumn period over 2,000 years ago. This dataset consists of two parts: \\n\\nThe main dataset where each example is an image and the corresponding text label. This part is contained in the glyphs.zip ZIP file.\\nA character detection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chen-yingfa/CHUBS.","first_N":5,"first_N_keywords":["image-classification","text-to-image","token-classification","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-scale-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the images gets scaled up/down in both x and y direction.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nscale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nscale factor: 1-7.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v44","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v44","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v44.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v16","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v16","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v16.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v17","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v17","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v17.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v18","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v18","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v18.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v19","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v19","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v19.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v45","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v45","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v45.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v46","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v46","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v46.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v20","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v20","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v20.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v21","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v21","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v21.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v22","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v22","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v22.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PIXELPROSE_HU","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Obscure-Entropy/PIXELPROSE_HU","creator_name":"Obscure Entropy","creator_url":"https://huggingface.co/Obscure-Entropy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom Pixels to Prose: A Large Dataset of Dense Image Captions\\n\\t\\n\\nThis dataset is an extension of an existing image captioning dataset, enhanced for PixelProse and augmented with Hungarian translations. It provides a valuable resource for researchers and developers working on image captioning, especially those interested in PixelProse and cross-lingual applications. üåê\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\nWe report below the number of successfully fetched images and the number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Obscure-Entropy/PIXELPROSE_HU.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","Hungarian","mit"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v47","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v47","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v47.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v48","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v48","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v48.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v49","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v49","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v49.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-task-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-task-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM validation loss went down and then continue to rise afterwards,\\nso I guess the complexity of the dataset was too high.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are histograms. \\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nLet's see if the LLM does better on this one.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on pair comparisons‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-task-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"data-juicer-t2v-optimal-data-pool","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datajuicer/data-juicer-t2v-optimal-data-pool","creator_name":"Data-Juicer","creator_url":"https://huggingface.co/datajuicer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject description\\n\\t\\n\\nThe emergence of large-scale multi-modal generative models has drastically advanced artificial intelligence, introducing unprecedented levels of performance and functionality. \\nHowever, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datajuicer/data-juicer-t2v-optimal-data-pool.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"data-juicer-t2v-optimal-data-pool","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datajuicer/data-juicer-t2v-optimal-data-pool","creator_name":"Data-Juicer","creator_url":"https://huggingface.co/datajuicer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject description\\n\\t\\n\\nThe emergence of large-scale multi-modal generative models has drastically advanced artificial intelligence, introducing unprecedented levels of performance and functionality. \\nHowever, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datajuicer/data-juicer-t2v-optimal-data-pool.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-pair-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-pair-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nImage-size 1-10.\\nCompare histograms between 2 images.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nImage-size 1-20.\\nHistogram.remove_other_colors() exclude colors between two histograms.\\nThese bigger images are causing problems for the model to learn.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nSmaller image sizes: width 1-20. height 1-5.\\nThis is training much better.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nSmaller image sizes: width 1-5. height 1-20.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nSlightly bigger image sizes: width 1-10.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-pair-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-pair-v14","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-pair-v14","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nImage-size 1-10.\\nCompare histograms between 2 images.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nImage-size 1-20.\\nHistogram.remove_other_colors() exclude colors between two histograms.\\nThese bigger images are causing problems for the model to learn.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nSmaller image sizes: width 1-20. height 1-5.\\nThis is training much better.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nSmaller image sizes: width 1-5. height 1-20.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nSlightly bigger image sizes: width 1-10.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-pair-v14.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-task-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-task-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM validation loss went down and then continue to rise afterwards,\\nso I guess the complexity of the dataset was too high.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are histograms. \\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nLet's see if the LLM does better on this one.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on pair comparisons‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-task-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-cellular-automaton-v15","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-cellular-automaton-v15","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nThe images are run length encoded (RLE).\\nThe image sizes are between 4 and 10 pixels.\\nCellular automaton types:\\n\\ngameoflife\\nhighlife\\nserviettes\\ncave\\nmaze\\n\\nNumber of CA steps, range 1-2.\\nThe LLM was not happy about this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nThe image sizes are between 4 and 11 pixels.\\nNumber of CA steps = 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDisabled nowrap. It's only CAs that wraps around.\\nThe image sizes are between 4 and 11 pixels.\\nNumber of CA steps = 1.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-cellular-automaton-v15.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-cellular-automaton-v16","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-cellular-automaton-v16","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nThe images are run length encoded (RLE).\\nThe image sizes are between 4 and 10 pixels.\\nCellular automaton types:\\n\\ngameoflife\\nhighlife\\nserviettes\\ncave\\nmaze\\n\\nNumber of CA steps, range 1-2.\\nThe LLM was not happy about this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nThe image sizes are between 4 and 11 pixels.\\nNumber of CA steps = 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDisabled nowrap. It's only CAs that wraps around.\\nThe image sizes are between 4 and 11 pixels.\\nNumber of CA steps = 1.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-cellular-automaton-v16.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v32","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v32","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v32.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v33","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v33","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v33.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-shape-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-shape-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nDetect shape2x2 and shape3x3.\\nThe image sizes are between 1 and 30 pixels.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-shape-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-shape-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nDetect shape2x2 and shape3x3_center.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDetect shape2x2 and shape3x3_center and shape3x3_opposite.\\nThe image sizes are between 1 and 30 pixels.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-shape-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-shape-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nDetect shape2x2 and shape3x3_center.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDetect shape2x2 and shape3x3_center and shape3x3_opposite.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on counting the unique number of colors. corners and diamond4.\\nThe image sizes are between 1 and 30 pixels.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-shape-v4-rev3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-shape-v4-rev3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nDetect shape2x2 and shape3x3_center.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDetect shape2x2 and shape3x3_center and shape3x3_opposite.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on counting the unique number of colors. corners and diamond4.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nSame weight to all transformations.\\nThe image sizes are between 1 and 30 pixels.\\nTEST rev3. I'm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-shape-v4-rev3.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"wong-kar-wai-BLIP-captions","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rayaanoidpr/wong-kar-wai-BLIP-captions","creator_name":"Rayaan Ghosh","creator_url":"https://huggingface.co/rayaanoidpr","description":"Dataset Card for Wong Kar Wai movie frame BLIP captions\\n\\nDataset built for finetuning Stable Diffusion for Fatima Fellowship application.\\nThe original images were obtained from film-grab.com and captioned with the pre-trained BLIP model by SalesForce.\\nFor each row the dataset contains image and text keys. image is a varying size PIL jpeg, and text is the accompanying text caption. Only a train split is provided.\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Saudilang-Code-Switch-Corpus","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus","creator_name":"SDAIA NCAI","creator_url":"https://huggingface.co/SDAIANCAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCC - Saudilang Code-Switch Corpus\\n\\t\\n\\nThe National Center for Artificial Intelligence at the Saudi Data and Artificial Intelligence Authority (SDAIA), published the \\\"SCC\\\" dataset, which stands for \\\"Saudilang Code-Switch Corpus‚Äù.\\nThis dataset contains a transcription of general conversations taken from a YouTube podcast \\\"Thmanyah\\\" that has been transcribed by the National Center for Artificial Intelligence in SDAIA. The data features three episodes covering different domains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"simon-arc-shape-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-shape-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nDetect shape2x2 and shape3x3_center.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDetect shape2x2 and shape3x3_center and shape3x3_opposite.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nFocus on counting the unique number of colors. corners and diamond4.\\nThe image sizes are between 1 and 30 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nSame weight to all transformations.\\nThe image sizes are between 1 and 30 pixels.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-shape-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-openslr-80","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMyanmar Speech Dataset (OpenSLR-80)\\n\\t\\n\\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual OpenSLR dataset. \\nFor the complete multilingual dataset and additional information, please visit the original dataset repository \\nof OpenSLR Hugging Face page.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Source\\n\\t\\n\\nOpenSLR is a site devoted to hosting speech and language resources, such as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v34","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v34","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v34.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v35","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v35","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v35.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v36","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v36","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v36.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v37","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v37","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v37.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v38","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v38","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v38.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v39","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v39","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v39.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v40","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v40","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v40.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v41","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v41","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v41.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v42","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v42","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v42.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v43","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v43","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v43.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"OnePiece_Characters","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khanitachi/OnePiece_Characters","creator_name":"Mohd Hozaifa Khan","creator_url":"https://huggingface.co/khanitachi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for One Piece Image Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetadata\\n\\t\\n\\n\\nIdentifier: OnePiece_Characters\\nContributions: Mohd Hozaifa Khan\\nLicense: apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains images of famous One Piece characters scraped from the web using simple image search. It includes approximately 15 images per character for a total of 20 characters. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Use\\n\\t\\n\\nThis dataset is intended for educational and research purposes, including:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/khanitachi/OnePiece_Characters.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"megalith-10m-florence2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aipicasso/megalith-10m-florence2","creator_name":"aipicasso","creator_url":"https://huggingface.co/aipicasso","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMegalith-10M with Florence-2 Caption\\n\\t\\n\\nÊó•Êú¨Ë™û„ÅØ„Åì„Å°„Çâ\\nThis reposity is the supplymentary of Megalith-10M.\\nMegalith-10M is an CC-0 like image dataset. However, the dataset does not contain the image caption.\\nTherefore, we caption the images by Florence 2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"aipicasso/megalith-10m-florence2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to get images\\n\\t\\n\\ngit lfs install\\ngit clone https://huggingface.co/datasets/drawthingsai/megalith-10m‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aipicasso/megalith-10m-florence2.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"soa-full-florence2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aipicasso/soa-full-florence2","creator_name":"aipicasso","creator_url":"https://huggingface.co/aipicasso","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSmithsonian Open Access Dataset with Florence-2 Caption\\n\\t\\n\\n\\nÊó•Êú¨Ë™û„ÅØ„Åì„Å°„Çâ\\nThis dataset is made of soa-full.\\nsoa-full is an CC-0 image dataset from Smithsonian Open Access. However, the dataset does not contain the image caption.\\nTherefore, we caption the images by Florence 2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"aipicasso/soa-full-florence2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Use\\n\\t\\n\\n\\nResearch Vision & Language\\nDevelop text-to-image model or image-to-text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aipicasso/soa-full-florence2.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v44","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v44","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v44.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v45","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v45","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v45.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v46","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v46","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v46.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-image-v47","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-image-v47","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nHave dataset items that are somewhat evenly of each type. The LLM learned some of the types fine. However rotated images are causing problems.\\nThe image sizes are between 1 and 10 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nHere the majority of dataset items are rotated images. Since this is what my LLM is struggling with.\\nSmaller images. Here the image sizes are between 1 and 5 pixels.\\nThis helped a lot on the validation loss.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nMain focus is now on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-image-v47.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v23","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v23","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v23.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-compress-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-compress-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to compress images with duplicate rows and columns.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-compress-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-compress-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to compress images with duplicate rows and columns.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-6.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v50","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v50","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v50.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v51","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v51","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v51.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v52","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v52","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v52.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-erosion-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-erosion-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nCompute the erosion mask for each colored area, for all PixelConnectivity items.\\nimage size: 5-10.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-erosion-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-erosion-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nCompute the erosion mask for each colored area, for all PixelConnectivity items.\\nimage size: 5-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-15.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v53","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v53","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v53.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-erosion-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-erosion-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nCompute the erosion mask for each colored area, for all PixelConnectivity items.\\nimage size: 5-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-20.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v54","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v54","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v54.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-dilation-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-dilation-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nCompute the dilation mask sum for each colored area, for all PixelConnectivity items.\\nimage size: 5-10.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-dilation-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-dilation-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nCompute the dilation mask sum for each colored area, for all PixelConnectivity items.\\nimage size: 5-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v55","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v55","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v55.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v56","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v56","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v56.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v57","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v57","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v57.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v58","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v58","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v58.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-erosion-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-erosion-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to erode images by removing the outermost pixels from the colored areas.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-fractal-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform fractal input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-fractal-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform fractal input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"tts-100-v1","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mastermani305/tts-100-v1","creator_name":"Manikandan","creator_url":"https://huggingface.co/mastermani305","description":"mastermani305/tts-100-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-audio","Tamil","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"anime-collection","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/v2ray/anime-collection","creator_name":"LagPixelLOL","creator_url":"https://huggingface.co/v2ray","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnime Collection\\n\\t\\n\\nA repo containing scripts to scrape booru sites and images scraped from it.\\n","first_N":5,"first_N_keywords":["text-to-image","mit","100K<n<1M","üá∫üá∏ Region: US","Not-For-All-Audiences"],"keywords_longer_than_N":false},
	{"name":"simon-arc-combine-v69","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v69","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v69.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v70","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v70","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v70.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v71","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v71","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v71.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v72","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v72","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v72.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v73","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v73","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v73.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v74","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v74","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v74.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v75","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v75","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v75.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v76","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v76","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v76.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v77","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v77","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v77.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"garfield","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/terminusresearch/garfield","creator_name":"Terminus Research Group","creator_url":"https://huggingface.co/terminusresearch","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGarfield dataset\\n\\t\\n\\nCaptioned with InternVL2 40B over multiple 3090s.\\nSome problems exist with these captions, but they're mostly accurate enough.\\nA few strips were selected from the 1970s, early 1980s, but most are from the 1990s.\\nThese are the highest resolution versions of these that were available at the time and are archived here for research purposes and preservation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFlux embeds for SimpleTuner\\n\\t\\n\\nTo save time for training Flux models on these samples, the 16ch‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/terminusresearch/garfield.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v14","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v14","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v14.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v78","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v78","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v78.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v79","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v79","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v79.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v80","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v80","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v80.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v81","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v81","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v81.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-16.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-16.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-10.\\nnoise: 0.1, 0.2.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nbigger images. image size: 6-12.\\nmore noise: noise: 0.1, 0.2, 0.3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-10.\\nnoise: 0.1, 0.2.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nbigger images. image size: 6-12.\\nmore noise: noise: 0.1, 0.2, 0.3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v4.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v82","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v82","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v82.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v83","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v83","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v83.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-grid-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to extract content from a grid.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\ncell size: 1-5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-grid-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to extract content from a grid.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\ncell size: 1-5.\\ngrid line size: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-5.\\ncell size: 1-6.\\ngrid line size: 1-2.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v84","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v84","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v84.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-grid-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to extract content from a grid.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\ncell size: 1-5.\\ngrid line size: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-5.\\ncell size: 1-6.\\ngrid line size: 1-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded generate_task_mutate_content_inside_grid, that does flipx, flipy, rotate 180, while preserving the grid.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-grid-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to extract content from a grid.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\ncell size: 1-5.\\ngrid line size: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-5.\\ncell size: 1-6.\\ngrid line size: 1-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded generate_task_mutate_content_inside_grid, that does flipx, flipy, rotate 180, while preserving the grid.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nExtended generate_task_extract_content_from_grid so it does mutations of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v4.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v85","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v85","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v85.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"pexels-568k-internvl2","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/pexels-568k-internvl2","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pexels-568k-internvl2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is 567,573 synthetic captions for the images found in ptx0/photo-concept-bucket. The captions were produced using OpenGVLab/InternVL2-40B-AWQ. The dataset was grounded for captioning using the tags originally listed.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text is in English, but occasionally text in images in other languages is transcribed.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Usage\\n\\t\\n\\nTraining text-to-image models and other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/pexels-568k-internvl2.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v86","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v86","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v86.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v87","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v87","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v87.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nexample image size: 3-8.\\ntest image size: 1-12. Out of distribution data.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ArtVee_dataset","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Said2k/ArtVee_dataset","creator_name":"Anon","creator_url":"https://huggingface.co/Said2k","description":"Said2k/ArtVee_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"filatov_24000","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/patriotyk/filatov_24000","creator_name":"Serhiy Stetskovych ","creator_url":"https://huggingface.co/patriotyk","description":"patriotyk/filatov_24000 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-augment-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-augment-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nAugmentation of the ARC-AGI tasks.\\nexample count: 1-3.\\ntest count: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly skew up/down/left/right\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nInstead of making tasks out of input/output images.\\nI'm now focusing on preserving the original puzzle, with some transformations applied.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"AuroraCap-recaption","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wchai/AuroraCap-recaption","creator_name":"Wenhao Chai","creator_url":"https://huggingface.co/wchai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuroraCap-recaption\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tResources\\n\\t\\n\\n\\nWebsite\\narXiv: Paper\\nGitHub: Code\\nHuggingface: AuroraCap Model\\nHuggingface: VDC Benchmark\\nHuggingface: Trainset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nVideo recaption data by AuroraCap. Continue updating...\\nFor some video source, we could upload the raw videos but for the others we could only provide the url since the well-known reason.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{chai2024auroracap,\\n  title={AuroraCap: Efficient, Performant Video Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wchai/AuroraCap-recaption.","first_N":5,"first_N_keywords":["visual-question-answering","video-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mls-annotated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of non English MLS\\n\\t\\n\\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Portuguese"],"keywords_longer_than_N":true},
	{"name":"Diffuse_Map_Surfaces","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alastandy/Diffuse_Map_Surfaces","creator_name":"Andrew Smith","creator_url":"https://huggingface.co/alastandy","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Diffuse Map Surface\\n\\t\\n\\nDetailed surface textures without shadows or hotspots. (Diffuse Maps)\\nAn LORA for Flux.1-Dev using this dataset is aviable at https://civitai.com/models/939491\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"inbrowser-proctor-dataset","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset","creator_name":"Aayush Man Shrestha","creator_url":"https://huggingface.co/lord-reso","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Inbrowser Proctor Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject Description\\n\\t\\n\\nInbrowser Proctoring is an online browser proctoring application designed to supervise exams and prevent cheating in real-time. Utilizing a combination of video, audio, and screen recording technologies, along with advanced AI algorithms, the system closely monitors test-takers to identify suspicious behaviors and activities. By analyzing audio and visual data, it can detect anomalies that may indicate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-bool-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply boolean operations between 2 images that are stacked.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-5.\\noperations: same, and, or, xor.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-bool-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply boolean operations between 2 images that are stacked.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-5.\\noperations: same, and, or, xor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\noperations: and, or, xor. Eliminated the same, since it's the same as xor.\\nDifferent palette for input_a and input_b.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 2-7.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v93","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v93","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v93.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-edge-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right edge of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 3-5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-edge-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right edge of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-5.\\nFocus on identifying diagonal edges.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-10.\\nFocus on identifying diagonal edges.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-half-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-half-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right half of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 4-5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-half-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-half-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right half of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-7.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-10.\\nnoise: 0.1, 0.2.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nbigger images. image size: 6-12.\\nmore noise: noise: 0.1, 0.2, 0.3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v97","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v97","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v97.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v99","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v99","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v99.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mask-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to repair the masked area.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-7.\\nnoise: 0.1, 0.2.\\nThere are these transformations: identify_the_masked_area, repair_the_masked_area\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 4-13.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v101","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v101","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v101.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-fractal-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform fractal input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\nRandomly invert the pattern_image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nRandom add padding around the input image, that the model has to crop.\\nmax_pad_count = 5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nBigger images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"AuroraCap-trainset","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wchai/AuroraCap-trainset","creator_name":"Wenhao Chai","creator_url":"https://huggingface.co/wchai","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuroraCap Trainset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tResources\\n\\t\\n\\n\\nWebsite\\narXiv: Paper\\nGitHub: Code\\nHuggingface: AuroraCap Model\\nHuggingface: VDC Benchmark\\nHuggingface: Trainset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nWe use over 20 million high-quality image/video-text pairs to train AuroraCap in three stages. \\nPretraining stage. We first align visual features with the word embedding space of LLMs. To achieve this, we freeze the pretrained ViT and LLM, training solely the vision-language connector.\\nVision‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wchai/AuroraCap-trainset.","first_N":5,"first_N_keywords":["visual-question-answering","video-text-to-text","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v104","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v104","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v104.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Legacy-Mage-Sofie","keyword":"text-to-image","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/johnslegers/Legacy-Mage-Sofie","creator_name":"John Slegers","creator_url":"https://huggingface.co/johnslegers","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDiffusionDBXL\\n\\t\\n\\nTODO\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-captioning","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"Legacy-Mage-Samael1976","keyword":"text-to-image","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/johnslegers/Legacy-Mage-Samael1976","creator_name":"John Slegers","creator_url":"https://huggingface.co/johnslegers","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDiffusionDBXL\\n\\t\\n\\nTODO\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-captioning","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-scale-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the images gets scaled up/down in both x and y direction.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nscale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-30.\\nscale factor: 1-7.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v105","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v105","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v105.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v106","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v106","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v106.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-ray-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-ray-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the lonely pixels emit rays in multiple directions.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 5-10.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"YoutubeThumbnails","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SarimOne/YoutubeThumbnails","creator_name":"Stream","creator_url":"https://huggingface.co/SarimOne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset is constructed for finetuning of SDXL model for thumbnails.\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SarimOne/YoutubeThumbnails.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v109","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v109","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v109.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-halfplane-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-halfplane-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the halfplane: halfplane_with_two_pixels, halfplane_with_one_pixel_DIRECTION.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 5-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-12.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v110","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v110","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v110.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v113","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v113","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v113.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v114","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v114","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v114.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7. color count:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7. color count:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v115","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v115","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v115.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-10.\\nnoise: 0.1, 0.2.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nbigger images. image size: 6-12.\\nmore noise: noise: 0.1, 0.2, 0.3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-fractal-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform fractal input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\nRandomly invert the pattern_image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nRandom add padding around the input image, that the model has to crop.\\nmax_pad_count = 5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nBigger images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v14","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v14","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7. color count:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v14.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-count-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to count N number of pixels in the input, and in the output repeat a pattern N times.\\nexample count: 3-4.\\ntest count: 1-2.\\ninput image size: 3-8.\\noutput pattern image size: 1-3.\\npixel count: 1-3.\\nI had a serious mistake in number_of_positions where I didn't deal with clashing xy coordinates, causing the pixel count to not match with the pattern count in the output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\ninput image size: 3-10.\\npixel count: 1-4.\\nI had a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v14","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v14","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v14.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nexample image size: 3-8.\\ntest image size: 1-12. Out of distribution data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nexample image size: 3-9.\\ntest image size: 1-14. Out of distribution data.\\nThis was too hard for the model to make sense of.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nOnly enabled: TOP, BOTTOM (since‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-scale-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the images gets scaled up/down in both x and y direction.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nscale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-30.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a few noise to the images.\\nimage size: 1-10.\\nscale factor: 1-7.\\nOnly scale down.\\nNumber of noise pixels per pixel cell: 0-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nMore noisy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-half-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-half-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right half of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-halfplane-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-halfplane-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the halfplane: halfplane_with_two_pixels, halfplane_with_one_pixel_DIRECTION.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 5-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-outline-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-outline-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform do edge detection of the input images.\\nexample count: 3-5.\\ntest count: 1-2.\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-compress-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-compress-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to compress images with duplicate rows and columns.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 2-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 2-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 2-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 7\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v16","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v16","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v16.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-cross-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-cross-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify how 2 lines are intersecting, what line is the top-most, bottom-most.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerison 3\\n\\t\\n\\nimage size: 3-15.\\nAdded new task type:\\nIdentify from an intersection point, what are the lines that goes through the intersection point.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-cross-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-edge-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right edge of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-5.\\nFocus on identifying diagonal edges.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-10.\\nFocus on identifying diagonal edges.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-10.\\nEnabled all edge_names: top_left, top, top_right, left, right‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-flip-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-flip-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the transformations are: flip x/y/a/b, with random padding.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"waifuset-wiki","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Eugeoter/waifuset-wiki","creator_name":"Euge","creator_url":"https://huggingface.co/Eugeoter","description":"Useful wikis for Waifuset, keeping up with the times.\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","üá∫üá∏ Region: US","art"],"keywords_longer_than_N":false},
	{"name":"simon-arc-solve-mask-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to repair the masked areas/rectangles.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-7.\\nnoise: 0.1, 0.2.\\nThere are these transformations: identify_the_masked_area, repair_the_masked_area\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 4-13.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nStill having all the other transformations enabled.\\nAdded generate_task_repair_rectangle_and_crop.\\ninput image size: 4-8.\\nmask size: 2-3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-grid-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to extract content from a grid.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\ncell size: 1-5.\\ngrid line size: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-5.\\ncell size: 1-6.\\ngrid line size: 1-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded generate_task_mutate_content_inside_grid, that does flipx, flipy, rotate 180, while preserving the grid.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nExtended generate_task_extract_content_from_grid so it does mutations of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-ray-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-ray-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the lonely pixels emit rays in multiple directions.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 5-10.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-15.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 5-20.\\nnumber of lonely pixels: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 5-15.\\nnumber of lonely pixels: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-ray-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Pexels_Gemini_capitoned","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pixel-Dust/Pexels_Gemini_capitoned","creator_name":"Pixel Dust","creator_url":"https://huggingface.co/Pixel-Dust","description":"This dataset features a collection of high-quality images sourced from Pexels and captioned using the Gemini-1.5-Flash API. This dataset is designed to provide accurate, detailed descriptions of various visual content, suitable for text-to-image tasks, training AI models, and more.\\nGemini promt:\\n\\\"Describe this image, for a text-to-image train to be accurate, max 74 tokens. (the common theme between these images is '{theme}'), prefer the use of ',' dont use '.' and there is no need to have a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Pixel-Dust/Pexels_Gemini_capitoned.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","cc0-1.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\nnumber of rects: 2-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v156","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v156","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v156.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v14","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v14","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v14.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v15","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v15","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v15.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v16","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v16","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v16.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v17","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v17","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v17.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v157","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v157","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v157.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v4.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v14","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v14","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v14.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v15","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v15","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v15.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v17","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v17","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v17.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v18","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v18","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v18.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rectangle-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rectangle-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform a few rectangles.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-12.\\nrectangle size: 3-4.\\nnumber of rects: 2-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v160","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v160","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v160.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"speech-to-text","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LeVy4/speech-to-text","creator_name":"Le Thao Vy","creator_url":"https://huggingface.co/LeVy4","description":"LeVy4/speech-to-text dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"laion-pop-llama3.2-11b","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/laion-pop-llama3.2-11b","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for laion-pop-llama3.2-11b\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is 1,580,595 new synthetic captions for the images found in laion/laion-pop. The dataset was restricted to SFW-only images by filtering out every image with a nsfw_prediction greater than or equal to 0.995. The long captions were produced using meta-llama/Llama-3.2-11B-Vision-Instruct. Medium and short captions were produced from these captions using meta-llama/Llama-3.1-8B-Instruct The dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/laion-pop-llama3.2-11b.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"t2i-compbench","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NinaKarine/t2i-compbench","creator_name":"Nina","creator_url":"https://huggingface.co/NinaKarine","description":"Hub version of the T2I-CompBench dataset. All credits and licensing belong to the creators of the dataset. \\nThis version was obtained as described below. \\nFirst, the \\\".txt\\\" files were obtained from this directory.\\n\\nCode\\n\\nimport requests\\nimport os\\n\\n# Set the necessary parameters\\nowner = \\\"Karine-Huang\\\"\\nrepo = \\\"T2I-CompBench\\\"\\nbranch = \\\"main\\\"\\ndirectory = \\\"examples/dataset\\\"\\nlocal_directory = \\\".\\\"\\n\\n# GitHub API URL to get contents of the directory\\nurl =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NinaKarine/t2i-compbench.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"aesthetic_anime_curated_8.5k","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sdtana/aesthetic_anime_curated_8.5k","creator_name":"sdtana","creator_url":"https://huggingface.co/sdtana","description":"This ~8.5k dataset is a curated selection of posts with more than 2,000 likes on pixiv between 2024/07/01 and 2024-09/25.\\nCollection date: 2024-09-29\\nTags collected: 'Â•≥„ÅÆÂ≠ê', 'usersÂÖ•„Çä', 'Â•≥„ÅÆÂ≠ê', '„Åµ„Å®„ÇÇ„ÇÇ', 'Â§™„ÇÇ„ÇÇ', 'È≠ÖÊÉë„ÅÆÂ§™„ÇÇ„ÇÇ', 'È≠ÖÊÉë„ÅÆ„Åµ„Å®„ÇÇ„ÇÇ', '„Å∏„Åù', '„Åä„Å∏„Åù', '„Åä„Å£„Å±„ÅÑ', 'È≠ÖÊÉë„ÅÆË∞∑Èñì', 'Ê•µ‰∏ä„ÅÆ‰π≥', 'Â∑®‰π≥', 'ÁùÄË°£Â∑®‰π≥', 'Â¥©Â£ä:„Çπ„Çø„Éº„É¨„Ç§„É´', '„Éñ„É´„Éº„Ç¢„Éº„Ç´„Ç§„Éñ', '„Éê„Éº„ÉÅ„É£„É´YouTuber', 'ÂéüÁ•û\\nTags excluded: '3DCG','Á≠ãËÇâÂ®ò','Áî∑„ÅÆÂ®ò','Â•≥Ë£ÖÁî∑Â≠ê','ËÖêÂêë„Åë','BL','Koikatsu','Koikatsu!','„Ç≥„Ç§„Ç´„ÉÑ','„Ç≥„Ç§„Ç´„ÉÑ!','„Åµ„Åü„Å™„Çä','„É°„ÇπÁî∑Â≠ê', '„ÇÄ„Å°„ÇÄ„Å°','„É†„ÉÅ„É†„ÉÅ', '„ÅΩ„Å£„Å°„ÇÉ„Çä', 'ÁÜüÂ•≥','AI','AIÁîüÊàê','AI-generated','AI„Ç§„É©„Çπ„Éà'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sdtana/aesthetic_anime_curated_8.5k.","first_N":5,"first_N_keywords":["image-classification","text-to-image","apache-2.0","1K<n<10K","Image"],"keywords_longer_than_N":true},
	{"name":"HumanEdit","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BryanW/HumanEdit","creator_name":"Jinbin Bai","creator_url":"https://huggingface.co/BryanW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HumanEdit\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nfrom datasets import load_dataset\\nfrom PIL import Image\\n\\n# Load the dataset\\nds = load_dataset(\\\"BryanW/HumanEdit\\\")\\n\\n# Print the total number of samples and show the first sample\\nprint(f\\\"Total number of samples: {len(ds['train'])}\\\")\\nprint(\\\"First sample in the dataset:\\\", ds['train'][0])\\n\\n# Retrieve the first sample's data\\ndata_dict = ds['train'][0]\\n\\n# Save the input image (INPUT_IMG)\\ninput_img = data_dict['INPUT_IMG']‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BryanW/HumanEdit.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TIE_shorts","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raianand/TIE_shorts","creator_name":"Anand Rai","creator_url":"https://huggingface.co/raianand","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TIE_Shorts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTIE_shorts is a derived version of the Technical Indian English (TIE) dataset, a large-scale speech dataset (~ 8K hours) originally consisting of approximately 750 GB of content \\nsourced from the NPTEL platform. The original TIE dataset contains around 9.8K technical lectures in English delivered by instructors from various regions across India, \\nwith each lecture averaging about 50 minutes. These lectures cover a wide‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/raianand/TIE_shorts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/voices365/Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset","creator_name":"voices365","creator_url":"https://huggingface.co/voices365","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis Dataset was recorded by a professional Chinese voice artist, real person, male, the total length is around 11 hours. \\nFor more details, please refer to the link: www.vodataset.com or email info@voices365.com.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuthorization\\n\\t\\n\\nThe voice artist can sign an authorization with you. The authorization can be of any form, such as paper, voice or video.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCustom Dataset\\n\\t\\n\\nYes, the artist can record a new dataset with your scripts, and meet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/voices365/Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/voices365/Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset","creator_name":"voices365","creator_url":"https://huggingface.co/voices365","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis Dataset was recorded by a professional Chinese voice artist, real person, male, the total length is around 11 hours. \\nFor more details, please refer to the link: www.vodataset.com or email info@voices365.com.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuthorization\\n\\t\\n\\nThe voice artist can sign an authorization with you. The authorization can be of any form, such as paper, voice or video.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCustom Dataset\\n\\t\\n\\nYes, the artist can record a new dataset with your scripts, and meet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/voices365/Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Vulpisfoglia","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Vulpisfoglia","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Vulpisfoglia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"LLaVA-Video-small-swift","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malterei/LLaVA-Video-small-swift","creator_name":"Malte","creator_url":"https://huggingface.co/malterei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card LLaVA-Video-small-swift\\n\\t\\n\\nSmall subset of LLaVA-Video-178K for educational purposes to learn how to fine-tune video models.\\n","first_N":5,"first_N_keywords":["visual-question-answering","video-text-to-text","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sample_synthetic_text_to_sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql","creator_name":"vodala chakshu","creator_url":"https://huggingface.co/chakshu2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Synthetic Text to SQL Dataset\\n\\t\\n\\nThe dataset presents a substantial collection of expertly crafted Text-to-SQL samples, generated using open source LLM's and \\nshared under an open-source license. Highlights of the dataset include:\\n-- 1563 examples, divided into a training set of 1200 samples and a test set of 363 samples.-- Approximately less than 1 million tokens in total, with nearly 0.5 million representing code-specific tokens.-- Coverage spans a diverse range of 3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"sample_synthetic_text_to_sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql","creator_name":"vodala chakshu","creator_url":"https://huggingface.co/chakshu2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Synthetic Text to SQL Dataset\\n\\t\\n\\nThe dataset presents a substantial collection of expertly crafted Text-to-SQL samples, generated using open source LLM's and \\nshared under an open-source license. Highlights of the dataset include:\\n-- 1563 examples, divided into a training set of 1200 samples and a test set of 363 samples.-- Approximately less than 1 million tokens in total, with nearly 0.5 million representing code-specific tokens.-- Coverage spans a diverse range of 3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"LiFT-HRA-10K","keyword":"video-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fudan-FUXI/LiFT-HRA-10K","creator_name":"Fudan-FUXI","creator_url":"https://huggingface.co/Fudan-FUXI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLiFT: Leveraging Human Feedback for Text-to-Video Model Alignment\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper \\\"LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment\\\". LiFT-HRA is a high-quality Human Preference Annotation dataset that can be used to train video-text-to-text reward models. All videos in the LiFT-HRA dataset have resolutions of at least 512√ó512.\\nProject: https://codegoat24.github.io/LiFT/\\nCode: https://github.com/CodeGoat24/LiFT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fudan-FUXI/LiFT-HRA-10K.","first_N":5,"first_N_keywords":["video-text-to-text","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"LiFT-HRA-20K","keyword":"video-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fudan-FUXI/LiFT-HRA-20K","creator_name":"Fudan-FUXI","creator_url":"https://huggingface.co/Fudan-FUXI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLiFT: Leveraging Human Feedback for Text-to-Video Model Alignment\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper \\\"LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment\\\". LiFT-HRA is a high-quality Human Preference Annotation dataset that can be used to train video-text-to-text reward models. All videos in the LiFT-HRA dataset have resolutions of at least 512√ó512.\\nProject: https://codegoat24.github.io/LiFT/\\nCode: https://github.com/CodeGoat24/LiFT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fudan-FUXI/LiFT-HRA-20K.","first_N":5,"first_N_keywords":["video-text-to-text","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"LLaVA-Video-large-swift","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malterei/LLaVA-Video-large-swift","creator_name":"Malte","creator_url":"https://huggingface.co/malterei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card LLaVA-Video-medium-swift\\n\\t\\n\\nA subset of LLaVA-Video-178K for educational purposes to learn how to fine-tune video models.\\n","first_N":5,"first_N_keywords":["visual-question-answering","video-text-to-text","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tamago","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/tamago","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tamago Music Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata for 1,567 music tracks from tamastream.io, a community-based music streaming platform built on the NEAR blockchain. The dataset includes detailed track metadata including titles, descriptions, genres, and user interactions, providing insights into independent artist communities and their music.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is monolingual:\\n\\nEnglish (en): All metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/tamago.","first_N":5,"first_N_keywords":["image-classification","image-to-text","audio-classification","text-to-audio","found"],"keywords_longer_than_N":true},
	{"name":"Sparrow-Synthetic","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xjtupanda/Sparrow-Synthetic","creator_name":"Shukang Yin","creator_url":"https://huggingface.co/xjtupanda","description":"Sparrow: Data-Efficient Video-LLM with Text-to-Image Augmentation\\n\\n        üíª GitHub¬†¬† | ¬†¬† üìë Paper ¬†¬†  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Sparrow-Synthetic\\n\\t\\n\\n\\n\\nThis is a synthetic \\\"video\\\" instruction dataset derived from language data.\\nIt is designed to enrich the instruction diversity of video training corpus.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThis dataset is curated from longQA text datasets, LongAlpaca-12k and LongQLoRA-39K.\\nEach sample can be abstracted as a (long-context, instruction, answer)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xjtupanda/Sparrow-Synthetic.","first_N":5,"first_N_keywords":["video-text-to-text","English","apache-2.0","10K<n<100K","arxiv:2411.19951"],"keywords_longer_than_N":true},
	{"name":"mike-no-hito","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/v2ray/mike-no-hito","creator_name":"LagPixelLOL","creator_url":"https://huggingface.co/v2ray","description":"\\n\\t\\n\\t\\t\\n\\t\\tMike No Hito\\n\\t\\n\\nThis dataset contains nearly all the images from artist Mike No Hito, huge thanks to him for the cute catgirls :3.\\nCleaned, deduped, and tagged using 9001/copyparty, LagPixelLOL/mitgw, and SmilingWolf/wd-eva02-large-tagger-v3.\\n>:3 me when on my way to steal everything and throw them into gradient descent >:P\\n","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"visdrone-text-to-image","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Westcott/visdrone-text-to-image","creator_name":"Issac Westcott","creator_url":"https://huggingface.co/Westcott","description":"Westcott/visdrone-text-to-image dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-scale-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the images gets scaled up/down in both x and y direction.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nscale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-30.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a few noise to the images.\\nimage size: 1-10.\\nscale factor: 1-7.\\nOnly scale down.\\nNumber of noise pixels per pixel cell: 0-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nMore noisy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-scale-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the images gets scaled up/down in both x and y direction.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nscale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-30.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a few noise to the images.\\nimage size: 1-10.\\nscale factor: 1-7.\\nOnly scale down.\\nNumber of noise pixels per pixel cell: 0-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nMore noisy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v17","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v17","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v17.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-skew-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply skew/unkew in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nReplaced RLE compressed response with raw pixel response.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 1-9.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v27","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v27","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v27.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-bool-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply boolean operations between 2 images that are stacked.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-5.\\noperations: same, and, or, xor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\noperations: and, or, xor. Eliminated the same, since it's the same as xor.\\nDifferent palette for input_a and input_b.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 2-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-bool-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply boolean operations between 2 images that are stacked.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-5.\\noperations: same, and, or, xor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\noperations: and, or, xor. Eliminated the same, since it's the same as xor.\\nDifferent palette for input_a and input_b.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 2-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-ray-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-ray-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the lonely pixels emit rays in multiple directions.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 5-10.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-15.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 5-20.\\nnumber of lonely pixels: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 5-15.\\nnumber of lonely pixels: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-ray-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v15","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v15","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v15.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-grid-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to extract content from a grid.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\ncell size: 1-5.\\ngrid line size: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-5.\\ncell size: 1-6.\\ngrid line size: 1-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded generate_task_mutate_content_inside_grid, that does flipx, flipy, rotate 180, while preserving the grid.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nExtended generate_task_extract_content_from_grid so it does mutations of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nexample image size: 3-8.\\ntest image size: 1-12. Out of distribution data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nexample image size: 3-9.\\ntest image size: 1-14. Out of distribution data.\\nThis was too hard for the model to make sense of.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nOnly enabled: TOP, BOTTOM (since‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-10.\\nnoise: 0.1, 0.2.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nbigger images. image size: 6-12.\\nmore noise: noise: 0.1, 0.2, 0.3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v19","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v19","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v19.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-compress-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-compress-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to compress images with duplicate rows and columns.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 2-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 2-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 2-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 7\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-compress-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-count-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to count N number of pixels in the input, and in the output repeat a pattern N times.\\nexample count: 3-4.\\ntest count: 1-2.\\ninput image size: 3-8.\\noutput pattern image size: 1-3.\\npixel count: 1-3.\\nI had a serious mistake in number_of_positions where I didn't deal with clashing xy coordinates, causing the pixel count to not match with the pattern count in the output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\ninput image size: 3-10.\\npixel count: 1-4.\\nI had a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-cross-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-cross-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify how 2 lines are intersecting, what line is the top-most, bottom-most.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerison 3\\n\\t\\n\\nimage size: 3-15.\\nAdded new task type:\\nIdentify from an intersection point, what are the lines that goes through the intersection point.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-cross-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v164","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v164","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v164.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v166","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v166","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v166.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v169","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v169","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v169.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v170","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v170","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v170.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v171","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v171","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v171.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v173","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v173","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v173.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v175","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v175","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v175.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v178","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v178","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v178.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v179","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v179","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v179.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Tamil","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTamil Indic TTS Dataset\\n\\t\\n\\nThis dataset is derived from the Indic TTS Database project, specifically using the Tamil monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nLanguage: Tamil\\nTotal Duration: ~20.33 hours (Male: 10.3 hours, Female: 10.03 hours)\\nAudio Format: WAV\\nSampling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil.","first_N":5,"first_N_keywords":["text-to-speech","Tamil","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v186","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v186","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v186.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v188","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v188","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v188.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v189","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v189","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v189.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v191","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v191","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v191.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v192","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v192","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v192.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v193","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v193","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v193.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v197","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v197","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v197.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v198","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v198","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v198.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v199","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v199","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v199.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v200","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v200","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v200.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v201","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v201","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v201.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v204","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v204","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v204.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v206","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v206","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v206.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v207","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v207","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v207.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v208","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v208","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v208.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"lego_minifigure_captions","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/armaggheddon97/lego_minifigure_captions","creator_name":"Alessandro","creator_url":"https://huggingface.co/armaggheddon97","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLEGO Minifigure Captions\\n\\t\\n\\nThe LEGO Minifigure Captions dataset contains 12966 images of LEGO minifigures with captions. The dataset contains the following columns:\\n\\nimage: The jpeg image of the minifigure in the format {\\\"bytes\\\": bytes, \\\"path\\\": str} so that can be interpreted as PIL.Image objects in the huggingface datasets library.\\nshort_caption: The short caption describing the minifigure in the image.\\ncaption: The caption describing the minifigure which is generated using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/armaggheddon97/lego_minifigure_captions.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v209","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v209","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v209.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v210","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v210","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v210.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v211","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v211","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v211.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"X2I-computer-vision","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yzwang/X2I-computer-vision","creator_name":"Yueze Wang","creator_url":"https://huggingface.co/yzwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX2I Dataset\\n\\t\\n\\n\\nProject Page: https://vectorspacelab.github.io/OmniGen/\\nGithub: https://github.com/VectorSpaceLab/OmniGen\\nPaper: https://arxiv.org/abs/2409.11340\\nModel: https://huggingface.co/Shitao/OmniGen-v1\\n\\nTo achieve robust multi-task processing capabilities, it is essential to train the OmniGen on large-scale and diverse datasets. However, in the field of unified image generation, a readily available dataset has yet to emerge. For this reason, we have curated a large-scale‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yzwang/X2I-computer-vision.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"Tridis","keyword":"image-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/magistermilitum/Tridis","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","description":"This is the first dataset version of the corpora used in TRIDIS (Tria Digita Scribunt) which is a series of Handwriting Text Recognition models trained on semi-diplomatic transcriptions \\nfrom medieval and Early Modern Manuscripts.\\nThe dataset involves 4k pages of manuscripts and is suitable for work on documentary manuscripts, that is, manuscripts arising  from legal, administrative, and memorial practices such as registers, feudal books, charters, proceedings, comptability more commonly from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis.","first_N":5,"first_N_keywords":["image-to-text","French","Spanish","Latin","German"],"keywords_longer_than_N":true},
	{"name":"InstanceVid","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AnonMegumi/InstanceVid","creator_name":"tiehan fan","creator_url":"https://huggingface.co/AnonMegumi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstanceVid\\n\\t\\n\\nPaper: [https://arxiv.org/abs/2412.09283)\\nCode: https://github.com/NJU-PCALab/InstanceCap\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nInstanceVid is a subset of the OpenVid - 1 m, you need to provide the file to this warehouse index from OpenVid-1M to obtain the corresponding video files.\\nIn train, we published three files, The original InstanceCap(Instancecap.jsonl), follow the content of paper on compression of Dense form (InstanceCap_Dense.csv/jsonl). Select a file as required. Besides‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AnonMegumi/InstanceVid.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","10K<n<100K","arxiv:2412.09283"],"keywords_longer_than_N":true},
	{"name":"InstanceVid","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AnonMegumi/InstanceVid","creator_name":"tiehan fan","creator_url":"https://huggingface.co/AnonMegumi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstanceVid\\n\\t\\n\\nPaper: [https://arxiv.org/abs/2412.09283)\\nCode: https://github.com/NJU-PCALab/InstanceCap\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nInstanceVid is a subset of the OpenVid - 1 m, you need to provide the file to this warehouse index from OpenVid-1M to obtain the corresponding video files.\\nIn train, we published three files, The original InstanceCap(Instancecap.jsonl), follow the content of paper on compression of Dense form (InstanceCap_Dense.csv/jsonl). Select a file as required. Besides‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AnonMegumi/InstanceVid.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","10K<n<100K","arxiv:2412.09283"],"keywords_longer_than_N":true},
	{"name":"highresolution-laioncoco-aesthetic-MEG","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xiaoxiaxu/highresolution-laioncoco-aesthetic-MEG","creator_name":"Xiaoxia Xu","creator_url":"https://huggingface.co/xiaoxiaxu","description":"This dataset is filtered from laioncoco-aesthetic, which is used for academic research on mobile edge generation (MEG).\\nIt includes high-resolution 1024-by-1024 text-to-image samples generated by a distilled SDXL with 4-12 denoising steps. \\n\\nThe dataset mainly involves the following fields:\\n\\ncaption: The text prompt of the image.\\nimage: The target image corresponding to the prompt.\\ndiffusion: The generative results of the distilled SDXL.\\nlatents: The latent features of the distilled SDXL.\\n\\n","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","1K - 10K","arrow","Tabular"],"keywords_longer_than_N":true},
	{"name":"acl-paper","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/acl-paper","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tACL Entire\\n\\t\\n\\n\\n  \\n\\n\\nACL Entire is a comprehensive dataset containing all papers from both ACL and Non-ACL events listed on the ACL Anthology website. This dataset includes complete bibliographic information for all years.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nEvents Covered: Papers from ACL and Non-ACL events.\\nBibliography: Includes complete bibliographic details for every paper.\\nYears Covered: Comprehensive data spanning all available years.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nAll data has been compiled‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/acl-paper.","first_N":5,"first_N_keywords":["text-classification","translation","summarization","text2text-generation","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"game_screenshots_100","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/badigadiii/game_screenshots_100","creator_name":"Alexandr Kuznetcov","creator_url":"https://huggingface.co/badigadiii","description":"badigadiii/game_screenshots_100 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"prl_dark_love_style","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paralaif/prl_dark_love_style","creator_name":"paralaif","creator_url":"https://huggingface.co/paralaif","description":"\\n\\t\\n\\t\\t\\n\\t\\tprl_dark_love_style Dataset\\n\\t\\n\\nThis dataset is used to train my lora Crimson Maiden from Civitai.\\n","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"temporal-vqa","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fazliimam/temporal-vqa","creator_name":"Fazli Imam","creator_url":"https://huggingface.co/fazliimam","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Temporal-VQA dataset is a challenging benchmark designed to evaluate the temporal reasoning capabilities of Multimodal Large Language Models (MLLMs) in tasks requiring visual temporal understanding. It emphasizes real-world temporal dynamics through two core evaluation tasks:- \\n\\nTemporal Order Understanding: This task presents MLLMs with temporally consecutive frames from video sequences. The models must analyze and determine the correct sequence of events‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fazliimam/temporal-vqa.","first_N":5,"first_N_keywords":["image-text-to-text","apache-2.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"danbooru2024-latents-sdxl-1ktar","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/danbooru2024-latents-sdxl-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\\n\\t\\n\\t\\t\\n\\t\\tDanbooru 2024 SDXL VAE latents in 1k tar\\n\\t\\n\\n\\nDedicated dataset to align deepghs/danbooru2024-webp-4Mpixel. \\\"4MP-Focus\\\" for average raw image resolution. \\nLatents are ARB with maximum size of 1024x1024 as the recommended setting in kohyas. Major reason is to make sure I can finetune with RTX 3090. VRAM usage will raise drastically after 1024.\\nGenerated from prepare_buckets_latents_v2.py, modified from prepare_buckets_latents.py.\\nUsed for kohya-ss/sd-scripts. In theory it may replace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2024-latents-sdxl-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"prl_vintage_ero_comic_style","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paralaif/prl_vintage_ero_comic_style","creator_name":"paralaif","creator_url":"https://huggingface.co/paralaif","description":"\\n\\t\\n\\t\\t\\n\\t\\tprl_vintage_ero_comic_style Dataset\\n\\t\\n\\nImage cut from old erotic Mexican comics.\\n","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"chatjsonsql","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishi2903/chatjsonsql","creator_name":"Rishabh Mekala","creator_url":"https://huggingface.co/rishi2903","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names, column‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rishi2903/chatjsonsql.","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"realistic-vision-dslr-tr3s","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/trazer1/realistic-vision-dslr-tr3s","creator_name":"t smith","creator_url":"https://huggingface.co/trazer1","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [T,Smith]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [curl -X GET‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trazer1/realistic-vision-dslr-tr3s.","first_N":5,"first_N_keywords":["image-feature-extraction","text-to-image","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"try_1","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/itzayush21/try_1","creator_name":"Ayush Kumar Singh","creator_url":"https://huggingface.co/itzayush21","description":"itzayush21/try_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ai-gospel-music-dictionaries","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries","creator_name":"Cruz Macias","creator_url":"https://huggingface.co/cmathhug","description":"\\n\\t\\n\\t\\t\\n\\t\\tAI Gospel Music Dictionaries\\n\\t\\n\\nA comprehensive collection of JSON dictionaries designed to support AI-powered gospel music and lyrics generation, with a focus on biblical and theological content.\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains a curated set of dictionaries that can be used for:\\n\\nMusic generation tasks\\nLyrics generation with biblical themes\\nInstrument and genre specifications\\nBiblical reference materials\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDictionaries\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tBiblical Content‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","cc0-1.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"ai-gospel-music-dictionaries","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries","creator_name":"Cruz Macias","creator_url":"https://huggingface.co/cmathhug","description":"\\n\\t\\n\\t\\t\\n\\t\\tAI Gospel Music Dictionaries\\n\\t\\n\\nA comprehensive collection of JSON dictionaries designed to support AI-powered gospel music and lyrics generation, with a focus on biblical and theological content.\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains a curated set of dictionaries that can be used for:\\n\\nMusic generation tasks\\nLyrics generation with biblical themes\\nInstrument and genre specifications\\nBiblical reference materials\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDictionaries\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tBiblical Content‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","cc0-1.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"kinh-phap-hoa-ke-trom-huong","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"Normalized using https://github.com/oysterlanguage/emiliapipex\\n@article{emilia,\\n      title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},\\n      author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},\\n      journal={arXiv},\\n      volume={abs/2407.05361}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"kinh-phap-hoa-ke-trom-huong","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"Normalized using https://github.com/oysterlanguage/emiliapipex\\n@article{emilia,\\n      title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},\\n      author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},\\n      journal={arXiv},\\n      volume={abs/2407.05361}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"opentts-uk-aesthetics","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\\n\\t\\n\\t\\t\\n\\t\\tAesthetics of Open Text-to-Speech for üá∫üá¶ Ukrainian dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nThis dataset contains metrics for https://huggingface.co/datasets/Yehor/opentts-uk dataset retrieved by https://github.com/facebookresearch/audiobox-aesthetics \\n\\n\\t\\n\\t\\t\\n\\t\\tHow metrics calculated?\\n\\t\\n\\nYou can find a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"e621_2024-captions-1ktar","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/e621_2024-captions-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\\n\\t\\n\\t\\t\\n\\t\\tE621 2024 captions only in 1k tar\\n\\t\\n\\n\\nRaw captions jointed from lodestones/e621-captions\\n\\nIt doesn't align to any dataset yet.\\n\\nmeta_cap.json has been provided in compressed format if you want to train with kohyas triner. Currently I'm trying to merge this with my 2024 version.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCore logic\\n\\t\\n\\n\\nThe script building this 1ktar\\n\\nThere is not much choice, I don't have GPU to run for 1M captions with VLM so I just \\\"take it or leave it\\\".\\n\\n\\nrearranged_tags = [row.regular_summary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/e621_2024-captions-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","e621"],"keywords_longer_than_N":true},
	{"name":"opentts-lada","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-lada","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCite this work\\n\\t\\n\\n@misc {smoliakov_2025,\\n    author       = { {Smoliakov} },\\n    title        = { opentts-uk (Revision 32abc9c) },\\n    year         = 2025,\\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-lada.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-oleksa","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-oleksa","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCite this work\\n\\t\\n\\n@misc {smoliakov_2025,\\n    author       = { {Smoliakov} },\\n    title        = { opentts-uk (Revision 32abc9c) },\\n    year         = 2025,\\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-oleksa.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"aigciqa-20k","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strawhat/aigciqa-20k","creator_name":"ËçâÂ∏Ω‰∏çÊòØÁå´","creator_url":"https://huggingface.co/strawhat","description":"Dataset from paper: `[CVPR2024] Aigiqa-20k: A large database for ai-generated image quality assessment\\nCode: https://www.modelscope.cn/datasets/lcysyzxdxc/AIGCQA-30K-Image\\n@inproceedings{li2024aigiqa,\\n  title={Aigiqa-20k: A large database for ai-generated image quality assessment},\\n  author={Li, Chunyi and Kou, Tengchuan and Gao, Yixuan and Cao, Yuqin and Sun, Wei and Zhang, Zicheng and Zhou, Yingjie and Zhang, Zhichao and Zhang, Weixia and Wu, Haoning and others},\\n  booktitle={Proceedings of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/strawhat/aigciqa-20k.","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"danbooru2023","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/danbooru2023","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tDanbooru 2023\\n\\t\\n\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-to-image","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"OpenVid-1M-mapping","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phil329/OpenVid-1M-mapping","creator_name":"binglei li","creator_url":"https://huggingface.co/phil329","description":"\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the extent dataset proposed in the paper \\\"OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation\\\". \\nOpenVid-1M is a high-quality text-to-video dataset designed for research institutions to enhance video quality, featuring high aesthetics, clarity, and resolution. It can be used for direct training or as a quality tuning complement to other video datasets.\\nNew Feature: Video-ZIP mapping files now available for efficient video lookup (see Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phil329/OpenVid-1M-mapping.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"OpenVid-1M-mapping","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phil329/OpenVid-1M-mapping","creator_name":"binglei li","creator_url":"https://huggingface.co/phil329","description":"\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the extent dataset proposed in the paper \\\"OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation\\\". \\nOpenVid-1M is a high-quality text-to-video dataset designed for research institutions to enhance video quality, featuring high aesthetics, clarity, and resolution. It can be used for direct training or as a quality tuning complement to other video datasets.\\nNew Feature: Video-ZIP mapping files now available for efficient video lookup (see Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phil329/OpenVid-1M-mapping.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"sticers-for-diffusion-course","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gstranger/sticers-for-diffusion-course","creator_name":"George Krupenchenkov","creator_url":"https://huggingface.co/gstranger","description":"gstranger/sticers-for-diffusion-course dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nexample image size: 3-8.\\ntest image size: 1-12. Out of distribution data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nexample image size: 3-9.\\ntest image size: 1-14. Out of distribution data.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nexample image size: 3-8.\\ntest image size: 1-12. Out of distribution data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nexample image size: 3-9.\\ntest image size: 1-14. Out of distribution data.\\nThis was too hard for the model to make sense of.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nOnly enabled: TOP, BOTTOM. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nexample image size: 3-8.\\ntest image size: 1-12. Out of distribution data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nexample image size: 3-9.\\ntest image size: 1-14. Out of distribution data.\\nThis was too hard for the model to make sense of.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nOnly enabled: TOP, BOTTOM (since‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v89","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v89","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v89.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v92","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v92","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v92.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Theresa-Recording","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa-Recording","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa-Recording dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Japanese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"movie_posters_100k_controlnet","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stzhao/movie_posters_100k_controlnet","creator_name":"steve z","creator_url":"https://huggingface.co/stzhao","description":"Dataset Name: 10k Movie Poster Images with Layouts and Captions\\nDescription:\\nThis dataset contains 10,000 movie poster images, along with their extracted layout information and captions. The captions are generated by concatenating the movie title and genre(s). The layout annotations were extracted using PaddleOCR, providing precise structural details of the posters.\\nSource:\\nThe dataset is a curated set of the movie-posters-100k dataset.\\nKey Features:\\nImages: 10,000 high-resolution movie‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stzhao/movie_posters_100k_controlnet.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Bengali","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBengali Indic TTS Dataset\\n\\t\\n\\nThis dataset is derived from the Indic TTS Database project, specifically using the Bengali monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nLanguage: Bengali\\nTotal Duration: ~15.06 hours (Male: 10.05 hours, Female: 5.01 hours)\\nAudio Format: WAV‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali.","first_N":5,"first_N_keywords":["text-to-speech","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"emova-sft-4m","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-4m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-4M\\n\\t\\n\\n\\n\\n\\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \\nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-4M is a comprehensive dataset curated for omni-modal instruction tuning, including textual, visual, and audio interactions. This dataset is created by gathering open-sourced multi-modal instruction datasets and synthesizing high-quality omni-modal conversation data to enhance user experience. This dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-4m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-skew-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply skew/unkew in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nReplaced RLE compressed response with raw pixel response.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-skew-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply skew/unkew in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nReplaced RLE compressed response with raw pixel response.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 1-9.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"FilteredLAIONCOCOAesthetic","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xiaoxiaxu/FilteredLAIONCOCOAesthetic","creator_name":"Xiaoxia Xu","creator_url":"https://huggingface.co/xiaoxiaxu","description":"A filtered LAIONCOCO-aesthetic dataset for 1024*1024 text-guided image generation\\n","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"jeli-asr","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \\nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \\nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \\nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \\nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \\nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-bool-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply boolean operations between 2 images that are stacked.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-5.\\noperations: same, and, or, xor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\noperations: and, or, xor. Eliminated the same, since it's the same as xor.\\nDifferent palette for input_a and input_b.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-edge-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right edge of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-edge-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right edge of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-5.\\nFocus on identifying diagonal edges.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-edge-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right edge of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-5.\\nFocus on identifying diagonal edges.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-10.\\nFocus on identifying diagonal edges.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-10.\\nEnabled all edge_names: top_left, top, top_right, left, right‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v94","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v94","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v94.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v95","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v95","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v95.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-translate-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets translated by plus/minus 1 pixel in up/down/left/right directions.\\nThe image sizes are between 1 and 4 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly translate plus/minus 1 up/down are enabled.\\nimage width: 1-4, image height: 3-4.\\nMy hypothesis is that it's easy with RLE data to translate up/down.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nOnly translate plus/minus 1 left/right are enabled.\\nimage width: 3-4, image height: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-translate-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-10.\\nnoise: 0.1, 0.2.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nbigger images. image size: 6-12.\\nmore noise: noise: 0.1, 0.2, 0.3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-10.\\nnoise: 0.1, 0.2.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nbigger images. image size: 6-12.\\nmore noise: noise: 0.1, 0.2, 0.3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-10.\\nnoise: 0.1, 0.2.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nbigger images. image size: 6-12.\\nmore noise: noise: 0.1, 0.2, 0.3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v96","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v96","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v96.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v98","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v98","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v98.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mask-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to repair the masked area.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-7.\\nnoise: 0.1, 0.2.\\nThere are these transformations: identify_the_masked_area, repair_the_masked_area\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mask-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to repair the masked area.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-7.\\nnoise: 0.1, 0.2.\\nThere are these transformations: identify_the_masked_area, repair_the_masked_area\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-10.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v100","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v100","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v100.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v102","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v102","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v102.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v103","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v103","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v103.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"youtube-cc-by-music","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music","creator_name":"WaveAI","creator_url":"https://huggingface.co/WaveGenAI","description":"üì∫ YouTube-CC-BY-Music üì∫\\nYouTube-CC-BY-Music is a comprehensive collection of metadata for 316,000 music tracks shared on YouTube.\\nIf you want the version of this dataset including prompt, see https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music_annoted.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContent\\n\\t\\n\\nThe dataset includes descriptions, tags, and other metadata associated with 316,000 music videos uploaded to YouTube under the CC-BY license. These videos come from a diverse range of artists and genres‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WaveGenAI/youtube-cc-by-music.","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","text-to-audio","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"e621-2024-webp-4Mpixel_index","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/e621-2024-webp-4Mpixel_index","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"Index files of NebulaeWis/e621-2024-webp-4Mpixel.\\nYou can download images from NebulaeWis/e621-2024-webp-4Mpixel with cheesechaser.\\nfrom cheesechaser.datapool import E621NewestWebpDataPool\\n\\npool = E621NewestWebpDataPool()\\n\\n# download e621 #2010000-2010300, to directory /data/e621\\npool.batch_download_to_directory(\\n    resource_ids=range(2010000, 2010300),\\n    dst_dir='/data/e621',\\n    max_workers=12,\\n)\\n\\n","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered-annotated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtred and annotated CML TTS\\n\\t\\n\\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \\nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"X2I-in-context-learning","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yzwang/X2I-in-context-learning","creator_name":"Yueze Wang","creator_url":"https://huggingface.co/yzwang","description":"\\n\\t\\n\\t\\t\\n\\t\\tX2I Dataset\\n\\t\\n\\n\\nProject Page: https://vectorspacelab.github.io/OmniGen/\\nGithub: https://github.com/VectorSpaceLab/OmniGen\\nPaper: https://arxiv.org/abs/2409.11340\\nModel: https://huggingface.co/Shitao/OmniGen-v1\\n\\nTo achieve robust multi-task processing capabilities, it is essential to train the OmniGen on large-scale and diverse datasets. However, in the field of unified image generation, a readily available dataset has yet to emerge. For this reason, we have curated a large-scale‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yzwang/X2I-in-context-learning.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-bool-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply boolean operations between 2 images that are stacked.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-5.\\noperations: same, and, or, xor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\noperations: and, or, xor. Eliminated the same, since it's the same as xor.\\nDifferent palette for input_a and input_b.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 2-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v26","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v26","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v26.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-erosion-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-erosion-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to erode images by removing the outermost pixels from the colored areas.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nFocus only on generate_task_with_template_lines.\\nimage size: 4-8.\\nspan count: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nFocus only on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-reverse-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-reverse-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to reverse chunks of pixels in a specified direction.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 4-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-skew-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply skew/unkew in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"midjourney-v6-llava","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/brivangl/midjourney-v6-llava","creator_name":"Ivan Drokin","creator_url":"https://huggingface.co/brivangl","description":"This dataset based on https://huggingface.co/datasets/CortexLM/midjourney-v6 dataset, captioned with LLava-1.6 model. \\nThis dataset was released as is. By accessing and using this dataset, you acknowledge and agree that Cortex Foundation and the author of this repo are not responsible for any copyright violations or legal consequences that may arise from the use of these images.\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"TV-44kHz-Full","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full","creator_name":"Thorsten M√ºller","creator_url":"https://huggingface.co/Thorsten-Voice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe \\\"Thorsten-Voice\\\" dataset\\n\\t\\n\\nThis truly open source (CC0 license) german (üá©üá™) voice dataset contains about 40 hours of transcribed voice recordings by Thorsten M√ºller, \\na single male, native speaker in over 38.000 wave files.\\n\\nMono\\nSamplerate: 44.100Hz\\nTrimmed silence at begin/end\\nDenoised\\nNormalized to -24dB\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDisclaimer\\n\\t\\n\\n\\\"Please keep in mind, I am not a professional speaker, just an open source speech technology enthusiast who donates his voice. I contribute my‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","German","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TV-44kHz-Full","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full","creator_name":"Thorsten M√ºller","creator_url":"https://huggingface.co/Thorsten-Voice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe \\\"Thorsten-Voice\\\" dataset\\n\\t\\n\\nThis truly open source (CC0 license) german (üá©üá™) voice dataset contains about 40 hours of transcribed voice recordings by Thorsten M√ºller, \\na single male, native speaker in over 38.000 wave files.\\n\\nMono\\nSamplerate: 44.100Hz\\nTrimmed silence at begin/end\\nDenoised\\nNormalized to -24dB\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDisclaimer\\n\\t\\n\\n\\\"Please keep in mind, I am not a professional speaker, just an open source speech technology enthusiast who donates his voice. I contribute my‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","German","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"houses","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vvmatorin/houses","creator_name":"Vladislav Matorin","creator_url":"https://huggingface.co/vvmatorin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHouses\\n\\t\\n\\nThis synthetic dataset contains images of simple houses and their corresponding drawing instructions. It is designed for training models to predict missing elements in visual sequences to facilitate systems such as Copilot. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nImages: 256x256 images representing house drawings.\\nCommands: structured commands in JSON format describing the components of the house (e.g., body, roof, windows).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThis dataset can be used to train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vvmatorin/houses.","first_N":5,"first_N_keywords":["text-to-image","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"FlintstonesSV_Plus_Plus","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Janak12/FlintstonesSV_Plus_Plus","creator_name":"Janak Kapuriya","creator_url":"https://huggingface.co/Janak12","description":"\\n\\t\\n\\t\\t\\n\\t\\tüöÄüöÄüöÄ Paper Information\\n\\t\\n\\n\\nPaper Title: FlintstonesSV++: Improving Story Narration using Visual Scene Graph\\nAccepted at: Text2Story Workshop, ECIR Conference 2025, Lucca, Italy.\\nAuthors: Janak Kapuriya, Paul Buiteelar\\nOrganization: Insight SFI Research Center for Data Analytics, University of Galway, Ireland.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåü FlintstonesSV++\\n\\t\\n\\nThe FlintstonesSV++ dataset is an enhanced version of the original FlintstonesSV dataset. It leverages Visual Scene Graphs and Large Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Janak12/FlintstonesSV_Plus_Plus.","first_N":5,"first_N_keywords":["text-to-image","visual-question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Video-MMLU","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Enxin/Video-MMLU","creator_name":"EnxinSong","creator_url":"https://huggingface.co/Enxin","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tVideo-MMLU Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tResources\\n\\t\\n\\n\\nWebsite\\narXiv: Paper\\nGitHub: Code\\nHuggingface: Video-MMLU Benchmark\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tBenchmark Collection and Processing\\n\\t\\n\\nVideo-MMLU specifically targets videos that focus on theorem demonstrations and probleming-solving, covering mathematics, physics, and chemistry. The videos deliver dense information through numbers and formulas, pose significant challenges for video LMMs in dynamic OCR recognition and comprehension.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Enxin/Video-MMLU.","first_N":5,"first_N_keywords":["video-text-to-text","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mask-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to repair the masked areas/rectangles.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-7.\\nnoise: 0.1, 0.2.\\nThere are these transformations: identify_the_masked_area, repair_the_masked_area\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 4-13.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nStill having all the other transformations enabled.\\nAdded generate_task_repair_rectangle_and_crop.\\ninput image size: 4-8.\\nmask size: 2-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v14","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v14","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v14.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v15","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v15","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v15.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-compress-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-compress-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to compress images with duplicate rows and columns.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-compress-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-compress-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to compress images with duplicate rows and columns.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 2-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 2-10.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-compress-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-compress-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to compress images with duplicate rows and columns.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 2-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 2-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 2-12.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-cross-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-cross-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify how 2 lines are intersecting, what line is the top-most, bottom-most.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerison 3\\n\\t\\n\\nimage size: 3-15.\\nAdded new task type:\\nIdentify from an intersection point, what are the lines that goes through the intersection point.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-edge-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right edge of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-5.\\nFocus on identifying diagonal edges.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-10.\\nFocus on identifying diagonal edges.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-10.\\nEnabled all edge_names: top_left, top, top_right, left, right‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-edge-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-erosion-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-erosion-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to erode images by removing the outermost pixels from the colored areas.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-flip-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-flip-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the transformations are: flip x/y/a/b, with random padding.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-halfplane-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-halfplane-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the halfplane: halfplane_with_two_pixels, halfplane_with_one_pixel_DIRECTION.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 5-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-mass-v24","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-mass-v24","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nMeasure the mass of objects for pixel connectivity 4 and pixel connectivity 8.\\nimage size: 1-10.\\nmax_mass: 4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nmax_mass: 5.\\nThis converged too slowly. I was too optimistic. I will have to proceed slower.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-12.\\nmax_mass: 5.\\nToo big spikes in the training loss. I will have to lower the max_mass, and gradually increase it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nmax_mass: 2.\\nThe validation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-mass-v24.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-outline-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-outline-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform do edge detection of the input images.\\nexample count: 3-5.\\ntest count: 1-2.\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-scale-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the images gets scaled up/down in both x and y direction.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nscale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-30.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a few noise to the images.\\nimage size: 1-10.\\nscale factor: 1-7.\\nOnly scale down.\\nNumber of noise pixels per pixel cell: 0-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nMore noisy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-skew-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply skew/unkew in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v23","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v23","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v23.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v24","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v24","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v24.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"text-to-image-prompts","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/codeShare/text-to-image-prompts","creator_name":"codeShare","creator_url":"https://huggingface.co/codeShare","description":"If you have questions about this dataset , feel free to ask them on the fusion-discord : https://discord.gg/8TVHPf6Edn\\nThis collection contains sets from the fusion-t2i-ai-generator on perchance.\\nThis datset is used in this notebook: https://huggingface.co/datasets/codeShare/text-to-image-prompts/tree/main/Google%20Colab%20Notebooks\\nTo see the full sets, please use the url \\\"https://perchance.org/\\\" + url\\n, where the urls are listed below:\\n_generator\\n  gen_e621\\n    fusion-t2i-e621-tags-1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/codeShare/text-to-image-prompts.","first_N":5,"first_N_keywords":["text-to-image","image-classification","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v25","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v25","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v25.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description, Collection, and Source\\n\\t\\n\\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"cc12m-cleaned","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opendiffusionai/cc12m-cleaned","creator_name":"Open Diffusion AI","creator_url":"https://huggingface.co/opendiffusionai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCC12m-cleaned\\n\\t\\n\\nThis dataset builds on two others: The Conceptual Captions 12million dataset, which lead to the LLaVa captioned subset done by\\nCaptionEmporium\\n(The latter is the same set, but swaps out the (Conceptual Captions 12million) often-useless alt-text captioning for decent ones_\\nI have then used the llava captions as a base, and used the detailed descrptions to filter out\\nimages with things like watermarks, artist signatures, etc.\\nI have also manually thrown out all‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opendiffusionai/cc12m-cleaned.","first_N":5,"first_N_keywords":["text-to-image","image-classification","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Theresa","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nexample image size: 3-8.\\ntest image size: 1-12. Out of distribution data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nexample image size: 3-9.\\ntest image size: 1-14. Out of distribution data.\\nThis was too hard for the model to make sense of.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nOnly enabled: TOP, BOTTOM. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nexample image size: 3-8.\\ntest image size: 1-12. Out of distribution data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nexample image size: 3-9.\\ntest image size: 1-14. Out of distribution data.\\nThis was too hard for the model to make sense of.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nOnly enabled: TOP, BOTTOM (since‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v88","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v88","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v88.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v90","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v90","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v90.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v91","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v91","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v91.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v116","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v116","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v116.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v118","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v118","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v118.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v120","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v120","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v120.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v123","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v123","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v123.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v124","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v124","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v124.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v126","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v126","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v126.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v128","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v128","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v128.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v131","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v131","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v131.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Facecaption-15M-Embeddings","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFacecaption-15M-Embeddings\\n\\t\\n\\nWe chose about 5M image-text pairs with the highest resolution from Facecaption-15M, extracted the embeddings of the [CLS] Token using the FLIP model, and released them.\\nMore details of Facecaption-15M and FLIP are available at: Facecaption15M and FLIP.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAdditional Information\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe FaceCaption-15M dataset is released by OpenFaceCQUPT and is intended exclusively for research and educational purposes. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/Facecaption-15M-Embeddings.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v135","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v135","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v135.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-skew-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply skew/unkew in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-7.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v138","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v138","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v138.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v139","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v139","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v139.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-cross-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-cross-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify how 2 lines are intersecting, what line is the top-most, bottom-most.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v140","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v140","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v140.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v141","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v141","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v141.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-augment-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-augment-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nAugmentation of the ARC-AGI tasks.\\nexample count: 1-3.\\ntest count: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nOnly skew up/down/left/right\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-cross-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-cross-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify how 2 lines are intersecting, what line is the top-most, bottom-most.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerison 3\\n\\t\\n\\nimage size: 3-15.\\nAdded new task type:\\nIdentify from an intersection point, what are the lines that goes through the intersection point.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7. color count:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v15","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v15","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v15.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v16","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v16","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v16.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v17","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v17","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v17.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v18","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v18","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v18.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage isze: 3-10.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nFocus only on generate_task_with_template_lines.\\nimage size: 4-8.\\nspan count: 4-5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nFocus only on generate_task_with_template_lines.\\nimage size: 4-8.\\nspan count: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nFocus only on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nFocus only on generate_task_with_template_lines.\\nimage size: 4-8.\\nspan count: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nFocus only on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v146","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v146","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v146.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nFocus only on generate_task_with_template_lines.\\nimage size: 4-8.\\nspan count: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nFocus only on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v147","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v147","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v147.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-count-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to count N number of pixels in the input, and in the output repeat a pattern N times.\\nexample count: 3-4.\\ntest count: 1-2.\\ninput image size: 3-8.\\noutput pattern image size: 1-3.\\npixel count: 1-3.\\nI had a serious mistake in number_of_positions where I didn't deal with clashing xy coordinates, causing the pixel count to not match with the pattern count in the output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\ninput image size: 3-10.\\npixel count: 1-4.\\nI had a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-fractal-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform fractal input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\nRandomly invert the pattern_image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nRandom add padding around the input image, that the model has to crop.\\nmax_pad_count = 5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nBigger images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-zindex-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to do z-index transformations of input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 6-10.\\nnoise: 0.1, 0.2.\\nmask_of_primary_rectangle\\nRandom noisy background with two colors.\\nDraw a rectangle on top of the background.\\nThe job is to identify the rectangle.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nmask_of_obscured_rectangle added.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nbigger images. image size: 6-12.\\nmore noise: noise: 0.1, 0.2, 0.3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-zindex-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-count-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to count N number of pixels in the input, and in the output repeat a pattern N times.\\nexample count: 3-4.\\ntest count: 1-2.\\ninput image size: 3-8.\\noutput pattern image size: 1-3.\\npixel count: 1-3.\\nI had a serious mistake in number_of_positions where I didn't deal with clashing xy coordinates, causing the pixel count to not match with the pattern count in the output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\ninput image size: 3-10.\\npixel count: 1-4.\\nI had a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v21","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v21","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v21.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7. color count:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v152","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v152","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v152.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"EvalQABench","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhenryz/EvalQABench","creator_name":"Henry Hengyuan Zhao","creator_url":"https://huggingface.co/hhenryz","description":"This repository contains the data for LOVA3: Learning to Visual Question Answering, Asking and Assessment. \\nLOVA3 is a framework designed to equip MLLMs with the capabilities to answer, ask, and assess questions in the context of images.\\nCode: https://github.com/showlab/LOVA3\\n\\n\\t\\n\\t\\t\\n\\t\\tüéì Citation\\n\\t\\n\\nIf you find LOVA3 useful, please cite using this BibTeX:\\n@inproceedings{\\n    zhao2024lova,\\n    title={{LOVA}3: Learning to Visual Question Answering, Asking and Assessment},\\n    author={Hengyuan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hhenryz/EvalQABench.","first_N":5,"first_N_keywords":["image-text-to-text","apache-2.0","arxiv:2405.14974","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"znanio-videos","keyword":"video-text-to-text","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/znanio-videos","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Znanio.ru Educational Videos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 6,653 educational videos from the znanio.ru platform, a resource for teachers, educators, students, and parents providing diverse educational content. Znanio.ru has been a pioneer in educational technologies and distance learning in the Russian-speaking internet since 2009.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian, with potential multilingual content:\\n\\nRussian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/znanio-videos.","first_N":5,"first_N_keywords":["video-classification","video-text-to-text","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"MixEval-X","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MixEval/MixEval-X","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","description":"\\n\\n\\nüöÄ Project Page | üìú arXiv | üë®‚Äçüíª Github | üèÜ Leaderboard | üìù blog | ü§ó HF Paper | ùïè Twitter\\n\\n\\n\\n\\n\\n\\n\\nMixEval-X encompasses eight input-output modality combinations and can be further extended. Its data points reflect real-world task distributions. The last grid presents the scores of frontier organizations‚Äô flagship models on MixEval-X, normalized to a 0-100 scale, with MMG tasks using win rates instead of Elo. Section C of the paper presents example data samples and model responses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval-X.","first_N":5,"first_N_keywords":["image-to-text","video-text-to-text","audio-classification","text-generation","text-to-audio"],"keywords_longer_than_N":true},
	{"name":"MixEval-X","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MixEval/MixEval-X","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","description":"\\n\\n\\nüöÄ Project Page | üìú arXiv | üë®‚Äçüíª Github | üèÜ Leaderboard | üìù blog | ü§ó HF Paper | ùïè Twitter\\n\\n\\n\\n\\n\\n\\n\\nMixEval-X encompasses eight input-output modality combinations and can be further extended. Its data points reflect real-world task distributions. The last grid presents the scores of frontier organizations‚Äô flagship models on MixEval-X, normalized to a 0-100 scale, with MMG tasks using win rates instead of Elo. Section C of the paper presents example data samples and model responses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval-X.","first_N":5,"first_N_keywords":["image-to-text","video-text-to-text","audio-classification","text-generation","text-to-audio"],"keywords_longer_than_N":true},
	{"name":"MixEval-X","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MixEval/MixEval-X","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","description":"\\n\\n\\nüöÄ Project Page | üìú arXiv | üë®‚Äçüíª Github | üèÜ Leaderboard | üìù blog | ü§ó HF Paper | ùïè Twitter\\n\\n\\n\\n\\n\\n\\n\\nMixEval-X encompasses eight input-output modality combinations and can be further extended. Its data points reflect real-world task distributions. The last grid presents the scores of frontier organizations‚Äô flagship models on MixEval-X, normalized to a 0-100 scale, with MMG tasks using win rates instead of Elo. Section C of the paper presents example data samples and model responses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval-X.","first_N":5,"first_N_keywords":["image-to-text","video-text-to-text","audio-classification","text-generation","text-to-audio"],"keywords_longer_than_N":true},
	{"name":"MixEval-X","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MixEval/MixEval-X","creator_name":"MixEval","creator_url":"https://huggingface.co/MixEval","description":"\\n\\n\\nüöÄ Project Page | üìú arXiv | üë®‚Äçüíª Github | üèÜ Leaderboard | üìù blog | ü§ó HF Paper | ùïè Twitter\\n\\n\\n\\n\\n\\n\\n\\nMixEval-X encompasses eight input-output modality combinations and can be further extended. Its data points reflect real-world task distributions. The last grid presents the scores of frontier organizations‚Äô flagship models on MixEval-X, normalized to a 0-100 scale, with MMG tasks using win rates instead of Elo. Section C of the paper presents example data samples and model responses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MixEval/MixEval-X.","first_N":5,"first_N_keywords":["image-to-text","video-text-to-text","audio-classification","text-generation","text-to-audio"],"keywords_longer_than_N":true},
	{"name":"Recap-Long-Laion","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/weiwu-ww/Recap-Long-Laion","creator_name":"Wei Wu","creator_url":"https://huggingface.co/weiwu-ww","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Recap-Long-Laion\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of long captions of ~49M images from LAION-5B dataset. The long captions are generated by pre-trained Multi-modality Large Language Models (ShareGPT4V/InstructBLIP/LLava1.5) with the text prompt \\\"Describe the image in detail\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nWe distribute the image url with long captions under a standard Creative Common CC-BY-4.0 license. The individual images are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/weiwu-ww/Recap-Long-Laion.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","10M - 100M","csv"],"keywords_longer_than_N":true},
	{"name":"ukiyo-e-face-blip2-captions","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/py-img-gen/ukiyo-e-face-blip2-captions","creator_name":"Image Generation with Python","creator_url":"https://huggingface.co/py-img-gen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ukiyo-e-face-blip2-captions\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nukiyo-e-face-blip2-captions is a dataset that adds captions to Ukiyo-e face dataset using BLIP2 model.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe language data in ukiyo-e-face-blip2-captions is in English.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nimport datasets as ds\\n\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/py-img-gen/ukiyo-e-face-blip2-captions.","first_N":5,"first_N_keywords":["text-to-image","machine-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"VideoChat2","keyword":"video-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shenxq/VideoChat2","creator_name":"Xiaoqian Shen","creator_url":"https://huggingface.co/shenxq","description":"Video training data of LongVU downloaded from\\nhttps://huggingface.co/datasets/OpenGVLab/VideoChat2-IT\\n\\n\\t\\n\\t\\t\\n\\t\\tVideo\\n\\t\\n\\nPlease download the original videos from the provided links:\\n\\nBDD100K: bdd.zip\\nShareGPTVideo: https://huggingface.co/datasets/ShareGPTVideo/train_video_and_instruction/tree/main/train_300k\\nCLEVRER: clevrer_qa.zip\\nDiDeMo: didemo.zip\\nEgoQA: https://huggingface.co/datasets/ynhe/videochat2_data/resolve/main/egoqa_split_videos.zipKinetics-710: k400.zip\\nMovieChat: moviechat.zip‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shenxq/VideoChat2.","first_N":5,"first_N_keywords":["video-text-to-text","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"text_to_speech_dataset","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kishor798/text_to_speech_dataset","creator_name":"Kishor thagunna","creator_url":"https://huggingface.co/Kishor798","description":"Kishor798/text_to_speech_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"synthchat","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nnethercott/synthchat","creator_name":"Nate Nethercott","creator_url":"https://huggingface.co/nnethercott","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRendered synthetic chats from llama3.1\\n\\t\\n\\nThis dataset contains 2.2k screenshots of multi-turn conversations generated by Llama-3.1-70B-Instruct. Each conversation consists of 3-4 short exchanges between a User and an AI Assistant about a certain topic.\\nThe original dataset comprising of pure text exchanges can be found here: HuggingFaceTB/everyday-conversations-llama3.1-2k\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMotivation\\n\\t\\n\\nThis dataset aims to improve the OCR performance of vision-language models in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nnethercott/synthchat.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mask-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to repair the masked areas/rectangles.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-7.\\nnoise: 0.1, 0.2.\\nThere are these transformations: identify_the_masked_area, repair_the_masked_area\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 4-13.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nStill having all the other transformations enabled.\\nAdded generate_task_repair_rectangle_and_crop.\\ninput image size: 4-8.\\nmask size: 2-3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"watercolor-flux-samples","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DarkMoonDragon/watercolor-flux-samples","creator_name":"DarkmnDragon","creator_url":"https://huggingface.co/DarkMoonDragon","description":"Generated by https://huggingface.co/SebastianBodza/Flux_Aquarell_Watercolor_v2\\nFlux-dev generated samples\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v153","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v153","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v153.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v154","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v154","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v154.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-color-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the colors gets manipulated.\\nCurrently it's two-color images, where the transformation is to swap colors.\\nThe image sizes are between 1 and 5 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nNumber of test: 1-2. Previously it was always 1 test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 1-3.\\nNumber of tests: 1.\\nIdentify most popular color, and least popular color. The output size is always 1x1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-color-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-grid-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to extract content from a grid.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\ncell size: 1-5.\\ngrid line size: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-5.\\ncell size: 1-6.\\ngrid line size: 1-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded generate_task_mutate_content_inside_grid, that does flipx, flipy, rotate 180, while preserving the grid.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nExtended generate_task_extract_content_from_grid so it does mutations of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-grid-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-bool-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply boolean operations between 2 images that are stacked.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-5.\\noperations: same, and, or, xor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\noperations: and, or, xor. Eliminated the same, since it's the same as xor.\\nDifferent palette for input_a and input_b.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 2-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-compress-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-compress-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to compress images with duplicate rows and columns.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 2-8.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\\n\\t\\n\\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\\n\\nDataset Summary\\nDataset composition\\nSources\\nContent Types\\nLanguages and Dialects\\n\\n\\nExample use (python)\\nLicense\\nCitations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\\n\\t\\n\\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\\n\\nDataset Summary\\nDataset composition\\nSources\\nContent Types\\nLanguages and Dialects\\n\\n\\nExample use (python)\\nLicense\\nCitations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-fractal-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform fractal input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\nRandomly invert the pattern_image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nRandom add padding around the input image, that the model has to crop.\\nmax_pad_count = 5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nBigger images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v13","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v13","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v13.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-half-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-half-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right half of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mask-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to repair the masked areas/rectangles.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-7.\\nnoise: 0.1, 0.2.\\nThere are these transformations: identify_the_masked_area, repair_the_masked_area\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 4-13.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nStill having all the other transformations enabled.\\nAdded generate_task_repair_rectangle_and_crop.\\ninput image size: 4-8.\\nmask size: 2-3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v155","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v155","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v155.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-probecolor-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to probe-colors in different directions.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nexample image size: 3-8.\\ntest image size: 1-12. Out of distribution data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nexample image size: 3-9.\\ntest image size: 1-14. Out of distribution data.\\nThis was too hard for the model to make sense of.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nOnly enabled: TOP, BOTTOM (since‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-probecolor-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-ray-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-ray-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the lonely pixels emit rays in multiple directions.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 5-10.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-15.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 5-20.\\nnumber of lonely pixels: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 5-15.\\nnumber of lonely pixels: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-reverse-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-reverse-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to reverse chunks of pixels in a specified direction.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 4-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nFocus only on generate_task_with_template_lines.\\nimage size: 4-8.\\nspan count: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nFocus only on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nFocus only on generate_task_with_template_lines.\\nimage size: 4-8.\\nspan count: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nFocus only on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v22","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v22","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v22.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtred and CML-TTS\\n\\t\\n\\nThis dataset is a filtred version of a CML-TTS [1]. \\nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Polish"],"keywords_longer_than_N":true},
	{"name":"e621-2024_index","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/e621-2024_index","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"Tar index files for boxingscorpionbagel/e621-2024.\\nYou can download images from both boxingscorpionbagel/e621-2024 and deepghs/e621_newest with cheesechaser.\\nfrom cheesechaser.datapool import E621NewestDataPool\\n\\npool = E621NewestDataPool()\\n\\n# download e621 #2010000-2010300, to directory /data/e621\\npool.batch_download_to_directory(\\n    resource_ids=range(2010000, 2010300),\\n    dst_dir='/data/e621',\\n    max_workers=12,\\n)\\n\\n","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"VISTA-400K","keyword":"video-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/VISTA-400K","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVISTA-400K\\n\\t\\n\\nThis repo contains all subsets for VISTA-400K. VISTA is a video spatiotemporal augmentation method that generates long-duration and high-resolution video instruction-following data to enhance the video understanding capabilities of video LMMs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis repo is under construction. Please stay tuned.\\n\\t\\n\\nüåê Homepage | üìñ arXiv | üíª GitHub | ü§ó VISTA-400K | ü§ó Models | ü§ó HRVideoBench\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVideo Instruction Data Synthesis Pipeline\\n\\t\\n\\n\\n\\n\\n\\nVISTA leverages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/VISTA-400K.","first_N":5,"first_N_keywords":["question-answering","video-text-to-text","mit","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"emova-alignment-7m","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-Alignment-7M\\n\\t\\n\\n\\n\\n\\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \\nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-Alignment-7M is a comprehensive dataset curated for omni-modal pre-training, including vision-language and speech-language alignment. \\nThis dataset is created using open-sourced image-text pre-training datasets, OCR datasets, and 2,000 hours of ASR and TTS data. \\nThis dataset is part of the EMOVA-Datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"Lappland","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"OregonCoastin4K","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Overlaiai/OregonCoastin4K","creator_name":"Overlai.ai","creator_url":"https://huggingface.co/Overlaiai","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOREGON COAST IN 4K\\n\\t\\n\\n\\n\\n\\\"Oregon Coast in 4K\\\" is a fine tuning text-to-video dataset consisting of dynamic videos captured in 8K resolution on the DJI Inspire 3 and RED Weapon Helium.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nüé• Oversampled: Every clip is captured in stunning 8K resolution, delivering rich detail ideal for fine tuning scenic landscapes and ocean dynamics.\\nüîÑ Parallax: Shot using DJI Inspire 3 featuring parallax effects that provide AI models with enhanced context on depth and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Overlaiai/OregonCoastin4K.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","< 1K","Tabular"],"keywords_longer_than_N":true},
	{"name":"emova-asr-tts-eval","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-ASR-TTS-Eval\\n\\t\\n\\n\\n\\n\\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \\nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-ASR-TTS-Eval is a dataset designed for evaluating the ASR and TTS performance of Omni-modal LLMs. It is derived from the test-clean set of the LibriSpeech dataset. This dataset is part of the EMOVA-Datasets collection. We extract the speech units using the EMOVA Speech Tokenizer.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"tiny_webvid_latents","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tensorkelechi/tiny_webvid_latents","creator_name":"kelechic","creator_url":"https://huggingface.co/tensorkelechi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttiny_webvid_latents\\n\\t\\n\\nThis is a tiny processed split of Doubiiu/webvid10m_motion.\\n\\nresized to 224x224\\nTrimmed to 5s and 4fps\\nEncoded to video latents with hunyuanvideo-community/HunyuanVideo's video/3D VAE\\ntext/caption encoded with google-t5/t5-base\\n\\n","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"cs2-highlights","keyword":"text-to-video","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/cs2-highlights","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Counter-Strike 2 Highlight Clips\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 8,369 high-quality gameplay highlight clips primarily from Counter-Strike 2, with a small portion from Counter-Strike: Global Offensive. The clips focus on key gameplay moments such as kills, bomb interactions, and grenade usage. The clips are collected from competitive platforms like Faceit and in-game competitive modes (Premier, Matchmaking) across various skill levels, making it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cs2-highlights.","first_N":5,"first_N_keywords":["video-classification","text-to-video","image-to-video","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"goodgame","keyword":"video-text-to-text","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/goodgame","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GoodGame.ru Clips\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 39,280 video clips from the Russian streaming platform goodgame.ru. The clips include metadata such as streamer information, view counts, game categories, and related media URLs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian (ru).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nclip_id: Unique identifier‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/goodgame.","first_N":5,"first_N_keywords":["video-classification","video-text-to-text","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"sakugabooru2025","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/sakugabooru2025","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSakugabooru2025: Curated Animation Clips from Enthusiasts\\n\\t\\n\\nSakugabooru.com is a booru-style imageboard dedicated to collecting and sharing noteworthy animation clips, emphasizing Japanese anime but open to creators worldwide. Over the years, it has amassed more than 240,000 animation clips, alongside informative blog posts for anime fans everywhere.\\nWith the growing interest in generative video models and AI animations, the scarcity of proper animation-related video datasets has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trojblue/sakugabooru2025.","first_N":5,"first_N_keywords":["text-to-image","text-to-video","English","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"sakugabooru2025","keyword":"text-to-video","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/sakugabooru2025","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSakugabooru2025: Curated Animation Clips from Enthusiasts\\n\\t\\n\\nSakugabooru.com is a booru-style imageboard dedicated to collecting and sharing noteworthy animation clips, emphasizing Japanese anime but open to creators worldwide. Over the years, it has amassed more than 240,000 animation clips, alongside informative blog posts for anime fans everywhere.\\nWith the growing interest in generative video models and AI animations, the scarcity of proper animation-related video datasets has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trojblue/sakugabooru2025.","first_N":5,"first_N_keywords":["text-to-image","text-to-video","English","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"Inst-It-Bench","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Inst-IT/Inst-It-Bench","creator_name":"Inst-IT","creator_url":"https://huggingface.co/Inst-IT","description":"\\n\\t\\n\\t\\t\\n\\t\\tInst-It Bench\\n\\t\\n\\nHomepage | Code | Paper | arXiv\\nInst-It Bench is a fine-grained multimodal benchmark for evaluating LMMs at the instance-Level, which is introduced in the paper Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual Prompt Instruction Tuning.\\n\\nSize: 1,000 image QAs and 1,000 video QAs\\nSplits: Image split and Video split\\nEvaluation Formats: Open-Ended and Multiple-Choice\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nExisting multimodal benchmarks primarily focus on global‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Inst-IT/Inst-It-Bench.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","video-text-to-text","image-text-to-text"],"keywords_longer_than_N":true},
	{"name":"Inst-It-Bench","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Inst-IT/Inst-It-Bench","creator_name":"Inst-IT","creator_url":"https://huggingface.co/Inst-IT","description":"\\n\\t\\n\\t\\t\\n\\t\\tInst-It Bench\\n\\t\\n\\nHomepage | Code | Paper | arXiv\\nInst-It Bench is a fine-grained multimodal benchmark for evaluating LMMs at the instance-Level, which is introduced in the paper Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual Prompt Instruction Tuning.\\n\\nSize: 1,000 image QAs and 1,000 video QAs\\nSplits: Image split and Video split\\nEvaluation Formats: Open-Ended and Multiple-Choice\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nExisting multimodal benchmarks primarily focus on global‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Inst-IT/Inst-It-Bench.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","video-text-to-text","image-text-to-text"],"keywords_longer_than_N":true},
	{"name":"MIG-Bench","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Michael4933/MIG-Bench","creator_name":"You Li","creator_url":"https://huggingface.co/Michael4933","description":"\\n    \\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMigician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models\\n\\t\\n\\nYou Li, Heyu Huang*, Chen Chi, Kaiyu Huang, Chao Huang, Zonghao Guo, Zhiyuan Liu, Jinan Xu, Yuhua Li, Ruixuan Li, Maosong Sun\\n\\n        \\nThis repository hosts the usage details of our training dataset MGrounding-630k and benchmark MIG-Bench and the training implementation of Migician, the first competitive Multi-image Grounding MLLM capable of free-form grounding.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Michael4933/MIG-Bench.","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Text2Face","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/oguzhanercan/Text2Face","creator_name":"Oƒüuzhan Ercan","creator_url":"https://huggingface.co/oguzhanercan","description":"This is version 1.0 of Text2Face dataset. This dataset generated by using Flux1.dev (Nunchaku 4 bit optimization method). Facial descriptions generated with promptgen.py script. More advanced version of prompt generator is also available as promptgenv2.py. For more detailed facial descriptions, you can generate with that.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"elevenlabs_multilingual_v2-technical-speech","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WpythonW/elevenlabs_multilingual_v2-technical-speech","creator_name":"Andrew","creator_url":"https://huggingface.co/WpythonW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tElevenLabs Multilingual V2 Technical Speech Dataset\\n\\t\\n\\nThis dataset contains automatically generated technical phrases in three domains, converted to speech using the ElevenLabs Multilingual V2 model with Adam voice.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset includes audio samples of technical phrases across three categories:\\n\\nMachine Learning (ML)\\nScience\\nTechnology\\n\\nEach entry contains:\\n\\nAudio file in MP3 format (22050Hz)\\nSource text\\nText length\\nCategory label‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WpythonW/elevenlabs_multilingual_v2-technical-speech.","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ImageFXPrompts","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/ImageFXPrompts","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"Auto-suggested prompts collected from Google ImageFX\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"test_ham10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tarunroy/test_ham10","creator_name":"Tarun Roy","creator_url":"https://huggingface.co/tarunroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarunroy/test_ham10.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"V1-33K","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haonan3/V1-33K","creator_name":"Haonan Wang","creator_url":"https://huggingface.co/haonan3","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tV1: Toward Multimodal Reasoning by Designing Auxiliary Tasks\\n\\t\\n\\n\\nüöÄ  Toward Multimodal Reasoning via Unsupervised Task -- Future Prediction üåü\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\nAuthors: Haonan Wang, Chao Du, Tianyu PangGitHub: haonan3/V1Dataset: V1-33K on Hugging Face\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMultimodal Reasoning\\n\\t\\n\\nRecent Large Reasoning Models (LRMs) such as DeepSeek-R1 have demonstrated impressive reasoning abilities; however, their capabilities are limited to textual data. Current models capture only a small part of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haonan3/V1-33K.","first_N":5,"first_N_keywords":["visual-question-answering","video-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dino","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YaArtemNosenko/dino","creator_name":"Nosenko","creator_url":"https://huggingface.co/YaArtemNosenko","description":"YaArtemNosenko/dino dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","Russian","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MJ-BENCH-VIDEO","keyword":"video-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MJ-Bench/MJ-BENCH-VIDEO","creator_name":"MJ-Bench-Team","creator_url":"https://huggingface.co/MJ-Bench","description":"This repository contains the implementation of the paper \\\"MJ-VIDEO: Fine-Grained Benchmarking and Rewarding Video Preferences in Video Generation\\\".\\nPaper: https://arxiv.org/abs/2502.01719\\nCode: https://github.com/aiming-lab/MJ-Video\\nProject Page: https://aiming-lab.github.io/MJ-VIDEO.github.io/\\nThis repository contains the implementation of the paper \\\"MJ-VIDEO: Fine-Grained Benchmarking and Rewarding Video Preferences in Video Generation\\\". We create a fine-grained video preference dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MJ-Bench/MJ-BENCH-VIDEO.","first_N":5,"first_N_keywords":["video-text-to-text","mit","10K - 100K","Video","Datasets"],"keywords_longer_than_N":true},
	{"name":"multimodal_meme_classification_singapore","keyword":"image-text-to-text","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aliencaocao/multimodal_meme_classification_singapore","creator_name":"Billy Cao","creator_url":"https://huggingface.co/aliencaocao","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Offensive Memes in Singapore Context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a collection of memes from various existing datasets, online forums, and freshly scrapped contents. It contains both global-context memes and Singapore-context memes, in different splits. It has textual description and a label stating if it is offensive under Singapore society's standards.\\n\\nCurated by: Cao Yuxuan, Wu Jiayang, Alistair Cheong, Theodore Lee‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aliencaocao/multimodal_meme_classification_singapore.","first_N":5,"first_N_keywords":["text-generation","visual-question-answering","image-text-to-text","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"t2isafety_evaluation","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenSafetyLab/t2isafety_evaluation","creator_name":"OpenSafetyLab","creator_url":"https://huggingface.co/OpenSafetyLab","description":"OpenSafetyLab/t2isafety_evaluation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"UAT","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mahwizzzz/UAT","creator_name":"Mahwiz Khalil","creator_url":"https://huggingface.co/mahwizzzz","description":"\\n\\t\\n\\t\\t\\n\\t\\tUAT: Urdu Audio Transcriptions\\n\\t\\n\\nUAT is a dataset featuring high quality audios and their transcriptions, sourced from Urdu audiobooks. This dataset is designed to support both TTS and ASR research in the Urdu language.\\n\\n\\t\\n\\t\\t\\n\\t\\tData Format\\n\\t\\n\\nEach entry in the dataset includes:\\n\\nfile_name: A unique identifier for the audio file.\\ntext: The corresponding text transcription.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nThis dataset is ideal for:\\n\\nTraining and evaluating TTS systems.\\nDeveloping ASR models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mahwizzzz/UAT.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","Urdu","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"UAT","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mahwizzzz/UAT","creator_name":"Mahwiz Khalil","creator_url":"https://huggingface.co/mahwizzzz","description":"\\n\\t\\n\\t\\t\\n\\t\\tUAT: Urdu Audio Transcriptions\\n\\t\\n\\nUAT is a dataset featuring high quality audios and their transcriptions, sourced from Urdu audiobooks. This dataset is designed to support both TTS and ASR research in the Urdu language.\\n\\n\\t\\n\\t\\t\\n\\t\\tData Format\\n\\t\\n\\nEach entry in the dataset includes:\\n\\nfile_name: A unique identifier for the audio file.\\ntext: The corresponding text transcription.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nThis dataset is ideal for:\\n\\nTraining and evaluating TTS systems.\\nDeveloping ASR models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mahwizzzz/UAT.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","Urdu","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SynSQL-2.5M","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seeklhy/SynSQL-2.5M","creator_name":"lihaoyang","creator_url":"https://huggingface.co/seeklhy","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynSQL-2.5M - The First Million-Scale Cross-Domain Text-to-SQL Dataset\\n\\t\\n\\nWe introduce the first million-scale text-to-SQL dataset, SynSQL-2.5M, containing over 2.5 million diverse and high-quality data samples, spanning more than 16,000 databases from various domains.\\nBuilding on SynSQL-2.5M, we introduce OmniSQL, a family of powerful text-to-SQL models available in three sizes: 7B, 14B, and 32B. During the fine-tuning process, we also integrate training sets from Spider and BIRD‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seeklhy/SynSQL-2.5M.","first_N":5,"first_N_keywords":["table-question-answering","translation","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"augmented_codealpaca-20k-using-together-ai-deepseek-v1","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eagle0504/augmented_codealpaca-20k-using-together-ai-deepseek-v1","creator_name":"Yiqiao Yin","creator_url":"https://huggingface.co/eagle0504","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset, named CodeAlpaca-20k, consists of examples that blend coding instructions with outputs and reasoning. Each entry includes structured fields like output, instruction, input, and cot (Chain of Thought). It is particularly designed to train and evaluate AI models that generate code and explanations based on simple programming tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection and Preparation\\n\\t\\n\\nData entries are augmented using the augment_answer function that makes API‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eagle0504/augmented_codealpaca-20k-using-together-ai-deepseek-v1.","first_N":5,"first_N_keywords":["reinforcement-learning","text-generation","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"t2i_tiny_nasa","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kaangml/t2i_tiny_nasa","creator_name":"Kaan GML","creator_url":"https://huggingface.co/kaangml","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for t2i_tiny_nasa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tNASA Image Dataset\\n\\t\\n\\nThis dataset is created using images obtained from NASA's official image library. The dataset contains a collection of images along with their corresponding textual descriptions (prompts). This dataset can be used for various applications, including image-to-text tasks, text-to-image generation, and other AI-based image analysis studies.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSource: NASA Image Library\\nContent: Images and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kaangml/t2i_tiny_nasa.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"pops_20k","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AmitIsraeli/pops_20k","creator_name":"Amit Israeli","creator_url":"https://huggingface.co/AmitIsraeli","description":"AmitIsraeli/pops_20k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-erosion-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-erosion-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to erode images by removing the outermost pixels from the colored areas.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nReplaced RLE compressed response with raw pixel response.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-erosion-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-erosion-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to erode images by removing the outermost pixels from the colored areas.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nReplaced RLE compressed response with raw pixel response.\\nimage size: 1-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-11.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-fractal-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform fractal input/output images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nScale up the input/output images. Scale factor: 1-3.\\nRandomly invert the pattern_image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nRandom add padding around the input image, that the model has to crop.\\nmax_pad_count = 5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nBigger images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-fractal-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Rosmontis","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Chinese","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v28","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v28","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v28.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-skew-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply skew/unkew in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nReplaced RLE compressed response with raw pixel response.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 1-9.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v19","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v19","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v19.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-bool-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply boolean operations between 2 images that are stacked.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-5.\\noperations: same, and, or, xor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\noperations: and, or, xor. Eliminated the same, since it's the same as xor.\\nDifferent palette for input_a and input_b.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 2-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-bool-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-halfplane-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-halfplane-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the halfplane: halfplane_with_two_pixels, halfplane_with_one_pixel_DIRECTION.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 5-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nReplaced RLE compressed response with raw pixel response.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mask-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to repair the masked areas/rectangles.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-7.\\nnoise: 0.1, 0.2.\\nThere are these transformations: identify_the_masked_area, repair_the_masked_area\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 4-13.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nStill having all the other transformations enabled.\\nAdded generate_task_repair_rectangle_and_crop.\\ninput image size: 4-8.\\nmask size: 2-3.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mask-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v15","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v15","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7. color count:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v15.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-half-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-half-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right half of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nReplaced RLE compressed response with raw pixel response.\\nimage size: 4-15.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-half-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-half-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify where the top/bottom/left/right half of the object is located.\\nexample count: 4-5.\\ntest count: 1-2.\\nimage size: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 4-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nEarlier predictions added to some of the rows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded fields: arc_task, test_index, earlier_output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nReplaced RLE compressed response with raw pixel response. Argh I forgot to enable this. Using RLE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-half-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v162","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v162","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v162.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v163","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v163","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v163.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v165","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v165","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v165.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v167","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v167","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v167.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v168","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v168","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v168.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v172","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v172","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v172.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v174","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v174","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v174.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v176","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v176","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v176.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v177","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v177","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v177.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v180","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v180","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v180.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v181","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v181","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v181.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v182","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v182","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v182.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v183","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v183","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v183.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v184","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v184","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v184.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v185","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v185","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v185.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v187","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v187","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v187.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v190","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v190","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v190.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v194","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v194","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v194.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v195","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v195","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v195.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v196","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v196","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v196.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v202","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v202","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v202.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v203","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v203","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v203.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"melodymaster-v1","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opentunes-ai/melodymaster-v1","creator_name":"Opentunes AI","creator_url":"https://huggingface.co/opentunes-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMelodyMaster V1 Training Dataset\\n\\t\\n\\nThis dataset contains music-text pairs for fine-tuning MelodyMaster V1, an AI music generation model. Based on MusicCaps dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n\\nFile Type: Parquet\\nContains music-text pairs for fine-tuning\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nyoutube_id,start_s,end_s,caption\\n\\n\\nyoutube_id: Identifier for the audio source\\nstart_s: Start time in seconds\\nend_s: End time in seconds\\ncaption: Text description of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opentunes-ai/melodymaster-v1.","first_N":5,"first_N_keywords":["text-to-audio","audio-classification","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v205","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v205","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v205.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v212","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v212","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v212.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Inst-It-Dataset","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Inst-IT/Inst-It-Dataset","creator_name":"Inst-IT","creator_url":"https://huggingface.co/Inst-IT","description":"\\n\\t\\n\\t\\t\\n\\t\\tInst-IT Dataset: An Instruction Tuning Dataset with Multi-level Fine-Grained Annotations\\n\\t\\n\\nintroduced in the paper Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual Prompt Instruction Tuning\\nüåê Homepage | Code | ü§ó Paper | üìñ arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInst-IT Dataset Overview\\n\\t\\n\\nWe create a large-scale instruction tuning dataset, the Inst-it Dataset. To the best of our knowledge, this is the first dataset that provides fine-grained annotations centric on specific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Inst-IT/Inst-It-Dataset.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","video-text-to-text","image-text-to-text","LVVIS"],"keywords_longer_than_N":true},
	{"name":"Inst-It-Dataset","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Inst-IT/Inst-It-Dataset","creator_name":"Inst-IT","creator_url":"https://huggingface.co/Inst-IT","description":"\\n\\t\\n\\t\\t\\n\\t\\tInst-IT Dataset: An Instruction Tuning Dataset with Multi-level Fine-Grained Annotations\\n\\t\\n\\nintroduced in the paper Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual Prompt Instruction Tuning\\nüåê Homepage | Code | ü§ó Paper | üìñ arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInst-IT Dataset Overview\\n\\t\\n\\nWe create a large-scale instruction tuning dataset, the Inst-it Dataset. To the best of our knowledge, this is the first dataset that provides fine-grained annotations centric on specific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Inst-IT/Inst-It-Dataset.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","video-text-to-text","image-text-to-text","LVVIS"],"keywords_longer_than_N":true},
	{"name":"dalle3-llama3.2-11b","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/dalle3-llama3.2-11b","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for dalle3-llama3.2-11b\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is 3,577,716 new synthetic captions for the 1,192,572 images found in ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions. The dataset was filtered for duplicates and then re-encoded with JPEGXL lossless or lossy depending on the source. The long captions were produced using meta-llama/Llama-3.2-11B-Vision-Instruct. Medium and short captions were produced from these captions using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/dalle3-llama3.2-11b.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"mid-space","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CUPUM/mid-space","creator_name":"CUPUM","creator_url":"https://huggingface.co/CUPUM","description":"\\n\\t\\n\\t\\t\\n\\t\\tMID-Space: Aligning Diverse Communities‚Äô Needs to Inclusive Public Spaces\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA new version of the dataset will be released soon, incorporating user identity markers and expanded annotations.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLIVS PAPER \\n\\t\\n\\n\\nClick below to see more:\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe MID-Space dataset is designed to align AI-generated visualizations of urban public spaces with the preferences of diverse and marginalized communities in Montreal. It includes textual prompts, Stable Diffusion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CUPUM/mid-space.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"nuscenes2d-time-weather-geodiffusion","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaiChen1998/nuscenes2d-time-weather-geodiffusion","creator_name":"Kai Chen","creator_url":"https://huggingface.co/KaiChen1998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tnuScenes-time-weather-GeoDiffusion Dataset Card\\n\\t\\n\\nnuScenes-time-weather-GeoDiffusion is the official dataset annotation file used to train GeoDiffusion on the nuScenes dataset with time of day (i.e., daytime/night) and weather (i.e., sunny/rain).\\nSince the nuImages dataset does not equip with those meta tags, we opt for the nuScenes dataset and generate the 2D bounding box annotations via inference with a Mask R-CNN pre-trained on the nuImages dataset, which is then saved in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaiChen1998/nuscenes2d-time-weather-geodiffusion.","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","arxiv:2306.04607","üá∫üá∏ Region: US","layout-to-image"],"keywords_longer_than_N":false},
	{"name":"HRVideoBench","keyword":"video-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/HRVideoBench","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHRVideoBench\\n\\t\\n\\nThis repo contains the test data for HRVideoBench, which is released under the paper \\\"VISTA: Enhancing Long-Duration and High-Resolution Video Understanding by Video Spatiotemporal Augmentation\\\". VISTA is a video spatiotemporal augmentation method that generates long-duration and high-resolution video instruction-following data to enhance the video understanding capabilities of video LMMs.\\nüåê Homepage | üìñ arXiv | üíª GitHub | ü§ó VISTA-400K | ü§ó Models | ü§ó‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/HRVideoBench.","first_N":5,"first_N_keywords":["question-answering","video-text-to-text","mit","< 1K","Image"],"keywords_longer_than_N":true},
	{"name":"Legacy-Mage-Hampsty","keyword":"text-to-image","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/johnslegers/Legacy-Mage-Hampsty","creator_name":"John Slegers","creator_url":"https://huggingface.co/johnslegers","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDiffusionDBXL\\n\\t\\n\\nTODO\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-captioning","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-scale-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the images gets scaled up/down in both x and y direction.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nscale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-30.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded noise to the images.\\nimage size: 1-10.\\nscale factor: 1-7.\\nOnly scale down.\\nNumber of noise pixels per pixel cell: 0-2.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-scale-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the images gets scaled up/down in both x and y direction.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nscale factor: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-20.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-30.\\nscale factor: 1-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a few noise to the images.\\nimage size: 1-10.\\nscale factor: 1-7.\\nOnly scale down.\\nNumber of noise pixels per pixel cell: 0-2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nMore noisy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-scale-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Legacy-Mage-JohnSlegers","keyword":"text-to-image","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/johnslegers/Legacy-Mage-JohnSlegers","creator_name":"John Slegers","creator_url":"https://huggingface.co/johnslegers","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDiffusionDBXL\\n\\t\\n\\nTODO\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-captioning","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"blip3-grounding-50m","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/blip3-grounding-50m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\\n\\t\\n\\t\\t\\n\\t\\tBLIP3-GROUNDING-50M Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe BLIP3-GROUNDING-50M dataset is designed to enhance the ability of Vision-Language Models (VLMs) to ground semantic concepts in visual features, which is crucial for tasks like object detection, semantic segmentation, and understanding referring expressions (e.g., \\\"the object to the left of the dog\\\"). Traditional datasets often lack the necessary granularity for such tasks, making it challenging for models to accurately localize and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-grounding-50m.","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-ray-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-ray-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the lonely pixels emit rays in multiple directions.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 5-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-15.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-ray-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-ray-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the lonely pixels emit rays in multiple directions.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 5-10.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-15.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 5-20.\\nnumber of lonely pixels: 1-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v107","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v107","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v107.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-flip-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-flip-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the transformations are: flip x/y/a/b, with random padding.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-8.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-flip-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-flip-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the transformations are: flip x/y/a/b, with random padding.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-12.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v108","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v108","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v108.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-halfplane-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-halfplane-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the halfplane: halfplane_with_two_pixels, halfplane_with_one_pixel_DIRECTION.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 5-8.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v111","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v111","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v111.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v112","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v112","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v112.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-ray-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-ray-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the lonely pixels emit rays in multiple directions.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 5-10.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 5-15.\\nnumber of lonely pixels: 1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 5-20.\\nnumber of lonely pixels: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 5-15.\\nnumber of lonely pixels: 1-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"vietnam-normalize-24k","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thanhkt/vietnam-normalize-24k","creator_name":"Tran Khanh Thanh","creator_url":"https://huggingface.co/thanhkt","description":"thanhkt/vietnam-normalize-24k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-to-speech","summarization","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7. color count:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"kenyan_national_parks","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gikebe/kenyan_national_parks","creator_name":"Elizabeth Gikebe","creator_url":"https://huggingface.co/gikebe","description":"gikebe/kenyan_national_parks dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7. color count:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-mass-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the mass of objects with a specific size.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 4-6.\\nfind mass: 1-2.\\nconnectivity: ALL8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-15.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-15.\\nfind mass: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 1-8.\\nfind mass: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nCompare mass of adjacent rows/columns. image size: 4-7. color count:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-mass-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v117","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v117","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v117.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v119","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v119","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v119.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v121","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v121","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v121.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-reverse-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-reverse-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to reverse chunks of pixels in a specified direction.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 4-7.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v122","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v122","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v122.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Recap-DataComp-100K","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nnethercott/Recap-DataComp-100K","creator_name":"Nate Nethercott","creator_url":"https://huggingface.co/nnethercott","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nRecap-DataComp-100K is a subset of UCSC-VLAA/Recap-DataComp-1B. \\nThis dataset aims to ease the development of vision-language models by providing a readily-available small collection of image-text pairs.\\nUse this dataset for sanity checks, developing POCs, or other quick multimodal dev. For serious model training please refer to the original repo linked above.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nAlways cite the original authors . I've copied their citation info here for your‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nnethercott/Recap-DataComp-100K.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v5","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v5","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v5.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v125","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v125","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v125.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v127","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v127","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v127.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-gravity-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply gravity in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-10.\\nnumber of pixels to apply gravity to: 2-5.\\nExercises image_gravity_move().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nExercises image_gravity_draw().\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nExercises image_gravity_move() and image_gravity_draw().\\nIncreased max_number_of_positions from 5 to 8.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-30.\\nmax number of positions: 5.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-gravity-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v129","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v129","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v129.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v130","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v130","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v130.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v132","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v132","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v132.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v133","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v133","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v133.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v134","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v134","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v134.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"rule34lol-webm","keyword":"text-to-video","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/rule34lol-webm","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Rule34.lol WebM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about WebM files from Rule34.lol, a booru-style imageboard. The dataset includes metadata for 22,733 WebM files, including URLs, tags, and file information. The actual WebM files are stored in zip archives, with each archive containing 500 WebM files.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset metadata is primarily in English.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/rule34lol-webm.","first_N":5,"first_N_keywords":["video-classification","text-to-video","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v136","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v136","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v136.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-skew-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-skew-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to apply skew/unkew in the directions up/down/left/right.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 1-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v137","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v137","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v137.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-cross-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-cross-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify how 2 lines are intersecting, what line is the top-most, bottom-most.\\nexample count: 3-4.\\ntest count: 1-2.\\nimage size: 3-6.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v142","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v142","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v142.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v143","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v143","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v143.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v19","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v19","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v19.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v144","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v144","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v144.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v145","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v145","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v145.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v7","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v7","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nFocus only on generate_task_with_template_lines.\\nimage size: 4-8.\\nspan count: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nFocus only on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v7.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-span-v8","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v8","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform images that have intersection patterns between row/column spans.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 3-8.\\nspan count: 3-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-10.\\nspan count: 3-6.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-12.\\nspan count: 3-7.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nFocus only on generate_task_with_template_lines.\\nimage size: 4-8.\\nspan count: 4-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nFocus only on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-span-v8.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-count-v1","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to count N number of pixels in the input, and in the output repeat a pattern N times.\\nexample count: 3-4.\\ntest count: 1-2.\\ninput image size: 3-8.\\noutput pattern image size: 1-3.\\npixel count: 1-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-count-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to count N number of pixels in the input, and in the output repeat a pattern N times.\\nexample count: 3-4.\\ntest count: 1-2.\\ninput image size: 3-8.\\noutput pattern image size: 1-3.\\npixel count: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\ninput image size: 3-10.\\npixel count: 1-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-count-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to count N number of pixels in the input, and in the output repeat a pattern N times.\\nexample count: 3-4.\\ntest count: 1-2.\\ninput image size: 3-8.\\noutput pattern image size: 1-3.\\npixel count: 1-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\ninput image size: 3-10.\\npixel count: 1-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\ninput image size: 3-12.\\noutput pattern image size: 1-4.\\npixel count: 1-5.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v148","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v148","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v148.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-count-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to count N number of pixels in the input, and in the output repeat a pattern N times.\\nexample count: 3-4.\\ntest count: 1-2.\\ninput image size: 3-8.\\noutput pattern image size: 1-3.\\npixel count: 1-3.\\nI had a serious mistake in number_of_positions where I didn't deal with clashing xy coordinates, causing the pixel count to not match with the pattern count in the output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\ninput image size: 3-10.\\npixel count: 1-4.\\nI had a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v4.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v149","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v149","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v149.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-symmetry-v20","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v20","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform symmetric images.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 2-3.\\nsymmetry types: hstack2, hstack3, vstack2, vstack3, grid2x2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded HSTACK4, VSTACK4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded HSTACK5, VSTACK5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nAdded ImageSymmetrySquare, so images can be rotated by 90 degrees, and flipped over the diagonals.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nOnly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-symmetry-v20.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rotate-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the image gets rotated cw/ccw/180 and transposed.\\nThe image sizes are between 1 and 4 pixels.\\nPredict the number of rows in the output image.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 1-5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 1-5.\\nAdded flipx and flipy transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 1-5.\\nnumber of tests: 1-2. Previously there were always just 1 test.\\nAdded flipa and flipb transformations, that flips over the diagonal.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-rotate-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v150","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v150","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v150.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-count-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to count N number of pixels in the input, and in the output repeat a pattern N times.\\nexample count: 3-4.\\ntest count: 1-2.\\ninput image size: 3-8.\\noutput pattern image size: 1-3.\\npixel count: 1-3.\\nI had a serious mistake in number_of_positions where I didn't deal with clashing xy coordinates, causing the pixel count to not match with the pattern count in the output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\ninput image size: 3-10.\\npixel count: 1-4.\\nI had a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-count-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v151","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v151","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v151.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-boundingbox-v18","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v18","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to identify the boundingbox.\\nexample count: 2-4.\\ntest count: 1-2.\\nimage size: 3-8.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 3-15.\\nfilled bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 3-15.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 3-20.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 5\\n\\t\\n\\nimage size: 3-30.\\nfilled+hollow bounding box.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 6\\n\\t\\n\\nimage size: 3-30.\\nAdded more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-boundingbox-v18.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v6","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v6.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v9","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v9","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v9.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v10","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v10","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v10.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v11","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v11","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v11.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v12","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v12","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v12.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-template-v16","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v16","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to insert objects into templates.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-10.\\ntemplate size: 2-4.\\nnumber of rects: 2-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nSmaller images.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 6-8.\\ntemplate size: 2-2.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nAdded transformation: without_insertion_image\\nimage size: 6-8.\\ntemplate size: 2-3.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-solve-template-v16.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rectangle-v2","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rectangle-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform a few rectangles.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-12.\\nrectangle size: 3-4.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 8-14.\\nrectangle size: 3-5.\\nnumber of rects: 2-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rectangle-v3","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rectangle-v3","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform a few rectangles.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-12.\\nrectangle size: 3-4.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 8-14.\\nrectangle size: 3-5.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 8-16.\\nrectangle size: 3-6.\\nnumber of rects: 2-3.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-solve-rectangle-v4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-solve-rectangle-v4","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nARC-AGI Tasks where the job is to transform a few rectangles.\\nexample count: 2-3.\\ntest count: 1-2.\\nimage size: 8-12.\\nrectangle size: 3-4.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nimage size: 8-14.\\nrectangle size: 3-5.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nimage size: 8-16.\\nrectangle size: 3-6.\\nnumber of rects: 2-3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nimage size: 8-16.\\nrectangle size: 3-7.\\nnumber of rects: 2-4.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v158","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v158","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v158.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v159","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v159","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v159.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"cool_images_urban_and_nature","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexandrosChariton/cool_images_urban_and_nature","creator_name":"Alexandros Chariton","creator_url":"https://huggingface.co/AlexandrosChariton","description":"This is an amazing dataset. From pythess with love.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"simon-arc-combine-v161","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/simon-arc-combine-v161","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 1\\n\\t\\n\\nA combination of multiple datasets.\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 3\\n\\t\\n\\nDatasets: dataset_solve_color.jsonl, dataset_solve_rotate.jsonl, dataset_solve_translate.jsonl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 4\\n\\t\\n\\nAdded a shared dataset name for all these datasets: SIMON-SOLVE-V1. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/simon-arc-combine-v161.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-eval","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-Speech-Eval\\n\\t\\n\\n\\n\\n\\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \\nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-Speech-Eval is an evaluation dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-Eval is part of EMOVA-Datasets collection, and the training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"MARIO-6M","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stzhao/MARIO-6M","creator_name":"steve z","creator_url":"https://huggingface.co/stzhao","description":"This datasets is curated by TextDiffuser team in their work: \\nTextDiffuser: Diffusion Models as Text Painters (NeurIPS 2023)\\nMARIO-6M contains 6M images with text rendered on, filtered from LAION-400M.\\n","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"english-tts-eval","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ntt123/english-tts-eval","creator_name":"Th√¥ng Nguy·ªÖn","creator_url":"https://huggingface.co/ntt123","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish Text-to-Speech Evaluation Dataset\\n\\t\\n\\nThe english-tts-eval dataset evaluates the performance of Text-to-Speech (TTS) systems. It includes a diverse collection of English text samples covering a wide range of use cases, such as news updates, navigation assistance, customer service, and storytelling.\\nThere are 100 examples, each of which includes:\\n\\nText: The original text sample.\\nNormalized Text: The spoken form of the text, with numbers and abbreviations expanded.\\nCategory:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ntt123/english-tts-eval.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"allstar","keyword":"video-text-to-text","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/allstar","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Allstar.gg Clips\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 47,896 video clips from the gaming platform allstar.gg. The clips primarily focus on Counter-Strike 2 gameplay moments and include detailed metadata such as player information, game statistics, view counts, and related media URLs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/allstar.","first_N":5,"first_N_keywords":["video-classification","video-text-to-text","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"furry-e621-safe-llama3.2-11b","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/furry-e621-safe-llama3.2-11b","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfurry-e621-safe-llama3.2-11b: A new anthropomorphic art dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is 2,987,631 synthetic captions for 995,877 images found in e921, which is just e621 filtered to the \\\"safe\\\" tag. The long captions were produced using meta-llama/Llama-3.2-11B-Vision-Instruct. Medium and short captions were produced from these captions using meta-llama/Llama-3.1-8B-Instruct The dataset was grounded for captioning using the ground truth tags on every post‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/furry-e621-safe-llama3.2-11b.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Recap-Long-Coyo","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/weiwu-ww/Recap-Long-Coyo","creator_name":"Wei Wu","creator_url":"https://huggingface.co/weiwu-ww","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Recap-Long-Coyo\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of long captions of ~24M images from Coyo-700M dataset. The long captions are generated by pre-trained Multi-modality Large Language Models (ShareGPT4V/InstructBLIP/LLava1.5) with the text prompt \\\"Describe the image in detail\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nWe distribute the image url with long captions under a standard Creative Common CC-BY-4.0 license. The individual images are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/weiwu-ww/Recap-Long-Coyo.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","10M - 100M","csv"],"keywords_longer_than_N":true},
	{"name":"mscoco","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/romrawinjp/mscoco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommon Objects in Context (COCO) Dataset\\n\\t\\n\\nThis dataset is English captions of COCO dataset. \\nThe splits in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReference\\n\\t\\n\\n@misc{lin2015microsoftcococommonobjects‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/mscoco.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-wan2.1","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-wan2.1","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Alibaba Wan2.1 Human Preference\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~45'000 human annotations were collected to evaluate Alibaba Wan 2.1 video generation model on our benchmark. The up to date benchmark‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-wan2.1.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-wan2.1","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-wan2.1","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Alibaba Wan2.1 Human Preference\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~45'000 human annotations were collected to evaluate Alibaba Wan 2.1 video generation model on our benchmark. The up to date benchmark‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-wan2.1.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-veo2","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Google DeepMind Veo2 Human Preference\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~45'000 human annotations were collected to evaluate Google DeepMind Veo2 video generation model on our benchmark. The up to date‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo2.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-veo2","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Google DeepMind Veo2 Human Preference\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~45'000 human annotations were collected to evaluate Google DeepMind Veo2 video generation model on our benchmark. The up to date‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-veo2.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Qilin","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUIR/Qilin","creator_name":"THUIR","creator_url":"https://huggingface.co/THUIR","description":"\\n\\t\\n\\t\\t\\n\\t\\tQilin\\n\\t\\n\\nQilin is a large-scale multimodal dataset designed for advancing research in search, recommendation, and Retrieval-Augmented Generation (RAG) systems. This repository contains the official implementation of the dataset paper, baseline models, and evaluation tools.  This dataset was presented in Qilin: A Multimodal Information Retrieval Dataset with APP-level User Sessions.\\nGithub: https://github.com/RED-Search/Qilin\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nQilin provides comprehensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/THUIR/Qilin.","first_N":5,"first_N_keywords":["question-answering","text-classification","sentence-similarity","text-retrieval","image-text-to-text"],"keywords_longer_than_N":true},
	{"name":"sql-create-context","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/b-mc2/sql-create-context","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/sql-create-context.","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"synthetic_text_to_sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gretelai/synthetic_text_to_sql","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tsynthetic_text_to_sql\\n\\t\\n\\n\\ngretelai/synthetic_text_to_sql is a rich dataset of high quality synthetic Text-to-SQL samples, \\ndesigned and generated using Gretel Navigator, and released under Apache 2.0.\\nPlease see our release blogpost for more details.\\nThe dataset includes:\\n\\n  105,851 records partitioned into 100,000 train and 5,851 test records\\n  ~23M total tokens, including ~12M SQL tokens\\n  Coverage across 100 distinct‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_text_to_sql.","first_N":5,"first_N_keywords":["question-answering","table-question-answering","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"VideoUFO","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WenhaoWang/VideoUFO","creator_name":"Wenhao Wang","creator_url":"https://huggingface.co/WenhaoWang","description":"\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation.\\nVideoUFO is the first dataset curated in alignment with real-world users‚Äô focused topics for text-to-video generation. Specifically, the dataset comprises over 1.09 million video clips spanning 1,291 topics. Here, we select the top 20 most popular topics for illustration.\\n\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVisual comparison\\n\\t\\n\\nVisual comparisons between our approach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WenhaoWang/VideoUFO.","first_N":5,"first_N_keywords":["text-to-video","text-to-image","image-to-video","image-to-image","English"],"keywords_longer_than_N":true},
	{"name":"VideoUFO","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WenhaoWang/VideoUFO","creator_name":"Wenhao Wang","creator_url":"https://huggingface.co/WenhaoWang","description":"\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation.\\nVideoUFO is the first dataset curated in alignment with real-world users‚Äô focused topics for text-to-video generation. Specifically, the dataset comprises over 1.09 million video clips spanning 1,291 topics. Here, we select the top 20 most popular topics for illustration.\\n\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVisual comparison\\n\\t\\n\\nVisual comparisons between our approach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WenhaoWang/VideoUFO.","first_N":5,"first_N_keywords":["text-to-video","text-to-image","image-to-video","image-to-image","English"],"keywords_longer_than_N":true},
	{"name":"VL-Health","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lintw/VL-Health","creator_name":"Lin Tianwei","creator_url":"https://huggingface.co/lintw","description":"\\n\\t\\n\\t\\t\\n\\t\\tVL-Health Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe VL-Health dataset is designed for multi-stage training of unified LVLMs in the medical domain. It consists of two key phases:\\n\\nAlignment ‚Äì Focused on training image captioning capabilities and learning representations of input visual information.\\n\\nInstruct Fine-Tuning ‚Äì Designed for enhancing the model's ability to handle various vision-language tasks, including both visual comprehension and visual generation tasks.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lintw/VL-Health.","first_N":5,"first_N_keywords":["question-answering","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"diffusiondb-pixelart","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jainr3/diffusiondb-pixelart","creator_name":"Rahul Jain","creator_url":"https://huggingface.co/jainr3","description":"DiffusionDB is the first large-scale text-to-image prompt dataset. It contains 2\\nmillion images generated by Stable Diffusion using prompts and hyperparameters\\nspecified by real users. The unprecedented scale and diversity of this\\nhuman-actuated dataset provide exciting research opportunities in understanding\\nthe interplay between prompts and generative models, detecting deepfakes, and\\ndesigning human-AI interaction tools to help users more easily use these models.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-captioning","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"webvid-10M","keyword":"text-to-video","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TempoFunk/webvid-10M","creator_name":"TempoFunk","creator_url":"https://huggingface.co/TempoFunk","description":"TempoFunk/webvid-10M dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-video","text-to-image","video-classification","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"webvid-10M","keyword":"text-to-image","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TempoFunk/webvid-10M","creator_name":"TempoFunk","creator_url":"https://huggingface.co/TempoFunk","description":"TempoFunk/webvid-10M dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-video","text-to-image","video-classification","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"FaceCaption-15M","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFacaCaption-15M\\n\\t\\n\\n\\n\\nFaceCaption-15M, a large-scale, diverse, and high-quality dataset of facial images accompanied by their natural language descriptions (facial image-to-text). This dataset aims to facilitate a study on face-centered tasks. FaceCaption-15M comprises over 15 million pairs of facial images and their corresponding natural language descriptions of facial features, making it the largest facial image caption dataset to date.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNews and Updates üî•üî•üî•Ôºö‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\\n\\t\\n\\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\\n(linagora/linto-asr-ar-tn).\\n\\nDataset Summary\\nDataset composition\\nSources\\nData Table\\nData sources\\nContent Types\\nLanguages and Dialects\\n\\n\\nExample use (python)\\nLicense\\nCitations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LinTO DataSet Audio for Arabic Tunisian is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\\n\\t\\n\\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\\n(linagora/linto-asr-ar-tn).\\n\\nDataset Summary\\nDataset composition\\nSources\\nData Table\\nData sources\\nContent Types\\nLanguages and Dialects\\n\\n\\nExample use (python)\\nLicense\\nCitations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LinTO DataSet Audio for Arabic Tunisian is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"text-to-image-2M","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jackyhate/text-to-image-2M","creator_name":"kzou","creator_url":"https://huggingface.co/jackyhate","description":"\\n\\t\\n\\t\\t\\n\\t\\ttext-to-image-2M: A High-Quality, Diverse Text-to-Image Training Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\ntext-to-image-2M is a curated text-image pair dataset designed for fine-tuning text-to-image models. The dataset consists of approximately 2 million samples, carefully selected and enhanced to meet the high demands of text-to-image model training. The motivation behind creating this dataset stems from the observation that datasets with over 1 million samples tend to produce better‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jackyhate/text-to-image-2M.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","image-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"MangaZero","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jianzongwu/MangaZero","creator_name":"Jianzong Wu","creator_url":"https://huggingface.co/jianzongwu","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nMangaZero dataset from paper DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation\\nPlease see GitHub repo to get the usage\\nProject page: https://jianzongwu.github.io/projects/diffsensei\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe \\\"type\\\" key in character annotation\\n\\t\\n\\nType = 0: Characters with clean faces\\nType = 1: Characters with vague faces\\nType = 2: Exaggerated, artistic characters with appearances that don't conform to typical standards. \\n","first_N":5,"first_N_keywords":["text-to-image","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MMathCoT-1M","keyword":"image-text-to-text","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/URSA-MATH/MMathCoT-1M","creator_name":"URSA-MATH","creator_url":"https://huggingface.co/URSA-MATH","description":"\\n\\t\\n\\t\\t\\n\\t\\tMMathCoT-1M\\n\\t\\n\\nThis repository contains the data presented in URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics.\\nCode: https://github.com/URSA-MATH/URSA-MATH\\nImage data can be downloaded from the following address:\\n\\nMAVIS: https://github.com/ZrrSkywalker/MAVIS, https://drive.google.com/drive/folders/1LGd2JCVHi1Y6IQ7l-5erZ4QRGC4L7Nol.\\nMultimath: https://huggingface.co/datasets/pengshuai-rin/multimath-300k.\\nGeo170k:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/URSA-MATH/MMathCoT-1M.","first_N":5,"first_N_keywords":["image-text-to-text","English","Chinese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Kore-Voice","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Kore-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Kore-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Fenrir-Voice","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Fenrir-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Fenrir-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-runway-alpha","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-runway-alpha","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Runway Alpha Human Preference\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~30'000 human annotations were collected to evaluate Runway's Alpha video generation model on our benchmark. The up to date benchmark can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-runway-alpha.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-runway-alpha","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-runway-alpha","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Runway Alpha Human Preference\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~30'000 human annotations were collected to evaluate Runway's Alpha video generation model on our benchmark. The up to date benchmark can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-runway-alpha.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","description":"\\n\\t\\n\\t\\t\\n\\t\\tCommon Voices Corpus 20.0 (Romanian)\\n\\t\\n\\n\\nCommon Voices is an open-source dataset of speech recordings created by \\nMozilla to improve speech recognition technologies. \\nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\\n\\n\\n\\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \\nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \\nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","description":"\\n\\t\\n\\t\\t\\n\\t\\tCommon Voices Corpus 20.0 (Romanian)\\n\\t\\n\\n\\nCommon Voices is an open-source dataset of speech recordings created by \\nMozilla to improve speech recognition technologies. \\nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\\n\\n\\n\\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \\nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \\nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"EgoLife","keyword":"video-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lmms-lab/EgoLife","creator_name":"LMMs-Lab","creator_url":"https://huggingface.co/lmms-lab","description":"Data cleaning, stay tuned! Please refer to https://egolife-ai.github.io/ first for general info.\\nCheckout the paper EgoLife (https://arxiv.org/abs/2503.03803) for more information.\\nCode: https://github.com/egolife-ai/EgoLife\\n","first_N":5,"first_N_keywords":["video-text-to-text","Chinese","mit","10K - 100K","Video"],"keywords_longer_than_N":true},
	{"name":"SID_Set","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saberzl/SID_Set","creator_name":"hzl","creator_url":"https://huggingface.co/saberzl","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for SID_Set\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe provide Social media Image Detection dataSet (SID-Set), which offers three key advantages:\\n\\nExtensive volume: Featuring 300K AI-generated/tampered and authentic images with comprehensive annotations.\\nBroad diversity: Encompassing fully synthetic and tampered images across various classes.\\nElevated realism: Including images that are predominantly indistinguishable from genuine ones through mere visual inspection.\\n\\nPlease check‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saberzl/SID_Set.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"spider-test-portuguese","keyword":"text-to-sql","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Boakpe/spider-test-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\\n\\t\\n\\t\\t\\n\\t\\tSpider Dataset - Vers√£o em Portugu√™s\\n\\t\\n\\nEste reposit√≥rio cont√©m a tradu√ß√£o para portugu√™s da parti√ß√£o de teste do dataset Spider, um benchmark para a tarefa de Text-to-SQL.\\n\\n\\t\\n\\t\\t\\n\\t\\tSobre esta tradu√ß√£o\\n\\t\\n\\nA tradu√ß√£o da parti√ß√£o \\\"test\\\" do Spider (contendo 2.147 inst√¢ncias) foi realizada seguindo um processo rigoroso:\\n\\nTradu√ß√£o inicial: Utilizando a API do GPT-4o mini da OpenAI\\nRevis√£o manual: Todas as 2.147 quest√µes foram revisadas e validadas manualmente\\nCrit√©rios de tradu√ß√£o:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Boakpe/spider-test-portuguese.","first_N":5,"first_N_keywords":["Portuguese","cc-by-sa-4.0","1K<n<10K","arxiv:1809.08887","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"spider","keyword":"text-to-sql","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xlangai/spider","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students.\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xlangai/spider.","first_N":5,"first_N_keywords":["text2text-generation","expert-generated","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiLingual LibriSpeech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiLingual LibriSpeech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"coyo-700m","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakaobrain/coyo-700m","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COYO-700M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCOYO-700M is a large-scale dataset that contains 747M image-text pairs as well as many other meta-attributes to increase the usability to train various models. Our dataset follows a similar strategy to previous vision-and-language datasets, collecting many informative pairs of alt-text and its associated image in HTML documents. We expect COYO to be used to train popular large-scale foundation models \\ncomplementary to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/coyo-700m.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","zero-shot-classification","image-captioning","no-annotation"],"keywords_longer_than_N":true},
	{"name":"IMaSC","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/IMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIMaSC: ICFOSS Malayalam Speech Corpus\\n\\t\\n\\nIMaSC is a Malayalam text and speech corpus made available by ICFOSS for the purpose of developing speech technology for Malayalam, particularly text-to-speech. The corpus contains 34,473 text-audio pairs of Malayalam sentences spoken by 8 speakers, totalling in approximately 50 hours of audio.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of 34,473 instances with fields text, speaker, and audio. The audio is mono, sampled at 16kH.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/IMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"spectrogram-captions","keyword":"text-to-image","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vucinatim/spectrogram-captions","creator_name":"Tim Vuƒçina","creator_url":"https://huggingface.co/vucinatim","description":"Dataset of captioned spectrograms (text describing the sound).\\n","first_N":5,"first_N_keywords":["text-to-image","machine-generated","machine-generated","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"textures-normal-1k","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dream-textures/textures-normal-1k","creator_name":"Dream Textures","creator_url":"https://huggingface.co/dream-textures","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttextures-normal-1k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe textures-normal-1k dataset is an image dataset of 1000+ normal map textures in 512x512 resolution with associated text descriptions.\\nThe dataset was created for training/fine-tuning models for text to image tasks.\\nIt contains a combination of CC0 procedural and photoscanned PBR materials from ambientCG.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text descriptions are in English, and created by joining the tags of each material with a space‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dream-textures/textures-normal-1k.","first_N":5,"first_N_keywords":["text-to-image","English","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MusicCaps","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/MusicCaps","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MusicCaps\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe MusicCaps dataset contains 5,521 music examples, each of which is labeled with an English aspect list and a free text caption written by musicians. An aspect list is for example \\\"pop, tinny wide hi hats, mellow piano melody, high pitched female vocal melody, sustained pulsating synth lead\\\", while the caption consists of multiple sentences about the music, e.g., \\n\\\"A low sounding male voice is rapping over a fast paced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/MusicCaps.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-sa-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"cmu-arctic-xvectors","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors","creator_name":"Matthijs Hollemans","creator_url":"https://huggingface.co/Matthijs","description":"\\n\\t\\n\\t\\t\\n\\t\\tSpeaker embeddings extracted from CMU ARCTIC\\n\\t\\n\\nThere is one .npy file for each utterance in the dataset, 7931 files in total. The speaker embeddings are 512-element X-vectors.\\nThe CMU ARCTIC dataset divides the utterances among the following speakers:\\n\\nbdl (US male)\\nslt (US female)\\njmk (Canadian male)\\nawb (Scottish male)\\nrms (US male)\\nclb (US female)\\nksp (Indian male)\\n\\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\\nUsage:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors.","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","mit","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"esa-hubble","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Supermaxman/esa-hubble","creator_name":"Maxwell Weinzierl","creator_url":"https://huggingface.co/Supermaxman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ESA Hubble Deep Space Images & Captions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ESA Hubble Deep Space Images & Captions dataset is composed primarily of Hubble deep space scans as high-resolution images,\\nalong with textual descriptions written by ESA/Hubble. Metadata is also included, which enables more detailed filtering and understanding of massive space scans.\\nThe purpose of this dataset is to enable text-to-image generation methods for generating high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Supermaxman/esa-hubble.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"km-speech-corpus","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seanghay/km-speech-corpus","creator_name":"seanghay","creator_url":"https://huggingface.co/seanghay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"km-speech-corpus\\\"\\n\\t\\n\\nsampling_rate: 16000\\nmean_seconds: 2.5068187111021882\\nmax_seconds: 19.392\\nmin_seconds: 0.448\\ntotal_seconds: 37459.392\\ntotal_hrs: 10.405386666666667\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Khmer","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MMC4-130k-chinese-image","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/MMC4-130k-chinese-image","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"MMC4-130k-chineseÊòØÂØπMMC4‰∏≠ÔºåÊäΩÊ†∑‰∫Ü130kÂ∑¶Âè≥ simliartyËæÉÈ´òÁöÑÂõæÊñápairÂæóÂà∞ÁöÑÊï∞ÊçÆÈõÜ\\nChineseÁâàÊú¨ÊòØÂØπËøôÈáåÊâÄÊúâÁöÑcaptionËøõË°å‰∫ÜÁøªËØë„ÄÇ\\nÊàë‰ª¨‰ºöÈôÜÁª≠Â∞ÜÊõ¥Â§öÊï∞ÊçÆÈõÜÂèëÂ∏ÉÂà∞hfÔºåÂåÖÊã¨\\n\\n Coco CaptionÁöÑ‰∏≠ÊñáÁøªËØë\\n CoQAÁöÑ‰∏≠ÊñáÁøªËØë\\n CNewSumÁöÑEmbeddingÊï∞ÊçÆ\\n Â¢ûÂπøÁöÑÂºÄÊîæQAÊï∞ÊçÆ\\n WizardLMÁöÑ‰∏≠ÊñáÁøªËØë\\n\\nÂ¶ÇÊûú‰Ω†‰πüÂú®ÂÅöËøô‰∫õÊï∞ÊçÆÈõÜÁöÑÁ≠πÂ§áÔºåÊ¨¢ËøéÊù•ËÅîÁ≥ªÊàë‰ª¨ÔºåÈÅøÂÖçÈáçÂ§çËä±Èí±„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÈ™ÜÈ©º(Luotuo): ÂºÄÊ∫ê‰∏≠ÊñáÂ§ßËØ≠Ë®ÄÊ®°Âûã\\n\\t\\n\\nhttps://github.com/LC1332/Luotuo-Chinese-LLM\\nÈ™ÜÈ©º(Luotuo)È°πÁõÆÊòØÁî±ÂÜ∑Â≠êÊòÇ @ ÂïÜÊ±§ÁßëÊäÄ, ÈôàÂêØÊ∫ê @ Âçé‰∏≠Â∏àËåÉÂ§ßÂ≠¶ ‰ª•Âèä ÊùéÈ≤ÅÈ≤Å @ ÂïÜÊ±§ÁßëÊäÄ ÂèëËµ∑ÁöÑ‰∏≠ÊñáÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂºÄÊ∫êÈ°πÁõÆÔºåÂåÖÂê´‰∫Ü‰∏ÄÁ≥ªÂàóËØ≠Ë®ÄÊ®°Âûã„ÄÇ\\n( Ê≥®ÊÑè: ÈôàÂêØÊ∫ê Ê≠£Âú®ÂØªÊâæ2024Êé®ÂÖçÂØºÂ∏àÔºåÊ¨¢ËøéËÅîÁ≥ª )\\nÈ™ÜÈ©ºÈ°πÁõÆ‰∏çÊòØÂïÜÊ±§ÁßëÊäÄÁöÑÂÆòÊñπ‰∫ßÂìÅ„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nPlease cite the repo if you use the data or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/MMC4-130k-chinese-image.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","Chinese","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"genshin_ch_10npc","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmj2002/genshin_ch_10npc","creator_name":"xmj","creator_url":"https://huggingface.co/xmj2002","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"genshin_ch_10npc\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"midjourney-v5-202304-clean","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanng/midjourney-v5-202304-clean","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmidjourney-v5-202304-clean\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÁÆÄ‰ªã Brief Introduction\\n\\t\\n\\nÈùûÂÆòÊñπÁöÑÔºåÁà¨ÂèñËá™midjourney v5ÁöÑ2023Âπ¥4ÊúàÁöÑÊï∞ÊçÆÔºå‰∏ÄÂÖ±1701420Êù°„ÄÇ\\nUnofficial, crawled from midjourney v5 for April 2023, 1,701,420 pairs in total.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ Dataset Information\\n\\t\\n\\nÂéüÂßãÈ°πÁõÆÂú∞ÂùÄÔºöhttps://huggingface.co/datasets/tarungupta83/MidJourney_v5_Prompt_dataset\\nÊàëÂÅö‰∫Ü‰∏Ä‰∫õÊ∏ÖÊ¥óÔºåÊ∏ÖÁêÜÂá∫‰∫Ü‰∏§‰∏™Êñá‰ª∂Ôºö\\n\\nori_prompts_df.parquet Ôºà1,255,812ÂØπÔºåmidjourneyÁöÑÂõõÊ†ºÂõæÔºâ\\n\\nupscaled_prompts_df.parquet Ôºà445,608ÂØπÔºå‰ΩøÁî®‰∫ÜÈ´òÊ∏ÖÊåá‰ª§ÁöÑÂõæÔºåËøôÊÑèÂë≥ÁùÄËøô‰∏™ÂõæÊõ¥ÂèóÊ¨¢Ëøé„ÄÇÔºâ\\n\\n\\nOriginal project address:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wanng/midjourney-v5-202304-clean.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MagicBrush","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/osunlp/MagicBrush","creator_name":"OSU NLP Group","creator_url":"https://huggingface.co/osunlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MagicBrush\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMagicBrush is the first large-scale, manually-annotated instruction-guided image editing dataset covering diverse scenarios single-turn, multi-turn, mask-provided, and mask-free editing. MagicBrush comprises 10K (source image, instruction, target image) triples, which is sufficient to train large-scale image editing models.\\nPlease check our website to explore more visual results.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\\"img_id\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/osunlp/MagicBrush.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"audiocaps","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/audiocaps","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taudiocaps\\n\\t\\n\\nHuggingFace mirror of official data repo.\\n","first_N":5,"first_N_keywords":["text-to-speech","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"GRIT","keyword":"text-to-image","license":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":"en","dataset_url":"https://huggingface.co/datasets/zzliang/GRIT","creator_name":"zhiliang","creator_url":"https://huggingface.co/zzliang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGRIT: Large-Scale Training Corpus of Grounded Image-Text Pairs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe introduce GRIT, a large-scale dataset of Grounded Image-Text pairs, which is created based on image-text pairs from COYO-700M and LAION-2B. We construct a pipeline to extract and link text spans (i.e., noun phrases, and referring expressions) in the caption to their corresponding image regions. More details can be found in the paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nDuring the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zzliang/GRIT.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","object-detection","zero-shot-classification","image-captioning"],"keywords_longer_than_N":true},
	{"name":"stable-diffusion-2-1-with-images","keyword":"text-to-image","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gryffindor-ISWS/stable-diffusion-2-1-with-images","creator_name":"gryffindor","creator_url":"https://huggingface.co/gryffindor-ISWS","description":"gryffindor-ISWS/stable-diffusion-2-1-with-images dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","gpl-3.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"sayoko-tts-corpus","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bandad/sayoko-tts-corpus","creator_name":"kai washizaki","creator_url":"https://huggingface.co/bandad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t„Çµ„É®Â≠ê Èü≥Â£∞„Ç≥„Éº„Éë„Çπ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊñπÊ≥ï\\n\\t\\n\\n„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÂúßÁ∏Æ„Åó„Åüzip„Éï„Ç°„Ç§„É´„Çí„ÄÅgdrive„Å´ÁΩÆ„ÅÑ„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n„Åæ„Åü„ÄÅ‰ª•‰∏ã„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„Åß„ÄÅhuggingface hub„Åã„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇÇÂèØËÉΩ„Åß„Åô„ÄÇ\\n# pip install --upgrade huggingface_hub\\nfrom huggingface_hub import snapshot_download\\n\\nsnapshot_download(repo_id=\\\"bandad/sayoko-tts-corpus\\\", repo_type=\\\"dataset\\\", revision=\\\"main\\\", local_dir=\\\"./sayoko-tts-corpus\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊ¶ÇË¶Å\\n\\t\\n\\n81Ê≠≥„ÅÆÂ•≥ÊÄß„ÅÆÈü≥Â£∞„Ç≥„Éº„Éë„Çπ„Åß„Åô„ÄÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bandad/sayoko-tts-corpus.","first_N":5,"first_N_keywords":["text-to-speech","Japanese","cc-by-4.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"midjourney-prompts","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vivym/midjourney-prompts","creator_name":"Ming Yang","creator_url":"https://huggingface.co/vivym","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmidjourney-prompts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset contains the cleaned midjourney prompts from Midjourney.\\nTotal prompts: 9,085,397\\n\\n\\t\\n\\t\\t\\nVersion\\nCount\\n\\n\\n\\t\\t\\n5.2\\n2,272,465\\n\\n\\n5.1\\n2,060,106\\n\\n\\n5.0\\n3,530,770\\n\\n\\n4.0\\n1,204,384\\n\\n\\n3.0\\n14,991\\n\\n\\n2.0\\n791\\n\\n\\n1.0\\n1,239\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nStyle\\nCount\\n\\n\\n\\t\\t\\ndefault\\n8,874,181\\n\\n\\nraw\\n177,953\\n\\n\\nexpressive\\n27,919\\n\\n\\nscenic\\n2,146\\n\\n\\ncute\\n2,036\\n\\n\\noriginal\\n511\\n\\n\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"clothes_desc","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wbensvage/clothes_desc","creator_name":"Wolfgang Bensvage","creator_url":"https://huggingface.co/wbensvage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for H&M Clothes captions\\n\\t\\n\\n_Dataset used to train/finetune [Clothes text to image model]\\nCaptions are generated by using the 'detail_desc' and 'colour_group_name' or 'perceived_colour_master_name' from kaggle/competitions/h-and-m-personalized-fashion-recommendations. Original images were also obtained from the url (https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data?select=images)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFor each row the dataset contains image‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wbensvage/clothes_desc.","first_N":5,"first_N_keywords":["text-to-image","human generated by using detail_desc and color","other","monolingual","www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations"],"keywords_longer_than_N":true},
	{"name":"sql-create-context-instruction","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction","creator_name":"Spartak Bughdaryan","creator_url":"https://huggingface.co/bugdaryan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built upon SQL Create Context, which in turn was constructed using data from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-SQL LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-SQL datasets. The CREATE TABLE statement can often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction.","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"logobookDB","keyword":"text-to-image","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mozci/logobookDB","creator_name":"mustafa ozci","creator_url":"https://huggingface.co/mozci","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\nThis dataset contains image caption pairs for logo designs screped from logobook.com. It is created for my research project to finetune text-image diffusion models with logo designs.\\nLogobook.com has a very nice logo archive consisting of modernist and simplistic logo designs. Each design stored along with some keywords. I used these keywords to create a caption for the logo designs.\\nSee example below:\\n\\nCaption:\\nAdams Law, a prominent law firm in Ireland, features a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mozci/logobookDB.","first_N":5,"first_N_keywords":["text-to-image","English","afl-3.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"hifi-tts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MikhailT/hifi-tts","creator_name":"Mikhail Tsimashkou","creator_url":"https://huggingface.co/MikhailT","description":"Hi-Fi Multi-Speaker English TTS Dataset (Hi-Fi TTS) is based on LibriVox's public domain audio books and Gutenberg Project texts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"hifi-tts","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MikhailT/hifi-tts","creator_name":"Mikhail Tsimashkou","creator_url":"https://huggingface.co/MikhailT","description":"Hi-Fi Multi-Speaker English TTS Dataset (Hi-Fi TTS) is based on LibriVox's public domain audio books and Gutenberg Project texts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"laion-coco-aesthetic","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/guangyil/laion-coco-aesthetic","creator_name":"Guangyi Liu","creator_url":"https://huggingface.co/guangyil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLAION COCO with aesthetic score and watermark score\\n\\t\\n\\nThis dataset contains 10% samples of the LAION-COCO dataset filtered by some text rules (remove url, special tokens, etc.), and image rules (image size > 384x384, aesthetic score>4.75 and watermark probability<0.5). There are total 8,563,753 data instances in this dataset. And the corresponding aesthetic score and watermark score are also included. \\nNoted: watermark score in the table means the probability of the existence of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guangyil/laion-coco-aesthetic.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CML-TTS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CML-TTS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"lego_sets_latest","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/merve/lego_sets_latest","creator_name":"Merve Noyan","creator_url":"https://huggingface.co/merve","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA small datasets of Lego Sets with BLIP-2 Generated Captions\\n\\t\\n\\nThis can be used to fine-tune SDXL with data-efficient fine-tuning techniques like DreamBooth.\\nExample image üëá \\n\\n","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"english_dialects","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/english_dialects","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"english_dialects\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 31 hours of transcribed high-quality audio of English sentences recorded by 120 volunteers speaking with different accents of the British Isles. The dataset is intended for linguistic analysis as well as use for speech technologies. The speakers self-identified as native speakers of Southern England, Midlands, Northern England, Welsh, Scottish and Irish varieties of English.\\nThe recording‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/english_dialects.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"english_dialects","keyword":"text-to-audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/english_dialects","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"english_dialects\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 31 hours of transcribed high-quality audio of English sentences recorded by 120 volunteers speaking with different accents of the British Isles. The dataset is intended for linguistic analysis as well as use for speech technologies. The speakers self-identified as native speakers of Southern England, Midlands, Northern England, Welsh, Scottish and Irish varieties of English.\\nThe recording‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/english_dialects.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"google-tamil","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-tamil","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tamil Speech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 7 hours of transcribed high-quality audio of Tamil sentences recorded by 50 volunteers. The dataset is intended for speech technologies. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).\\nautomatic-speech-recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-tamil.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Tamil","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"google-tamil","keyword":"text-to-audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-tamil","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tamil Speech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 7 hours of transcribed high-quality audio of Tamil sentences recorded by 50 volunteers. The dataset is intended for speech technologies. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).\\nautomatic-speech-recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-tamil.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Tamil","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"TEdBench_plusplus","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIML-TUDA/TEdBench_plusplus","creator_name":"Artificial Intelligence & Machine Learning Lab at TU Darmstadt","creator_url":"https://huggingface.co/AIML-TUDA","description":"\\n\\t\\n\\t\\t\\n\\t\\tTEdBench++\\n\\t\\n\\nThis dataset contains the TEdBench++ an image-to-image benchmark for text-based generative models. It contains original images (originals) and edited images (LEdits++) for benchmarking. tedbench++.csv contains the text-based edit instructions for the respective original image and parameters to reproduce the edited images with LEdits++.\\nconsider citing our work\\n@inproceedings{brack2024ledits,\\n  year = { 2024 },\\n  booktitle = { Proceedings of the IEEE/CVF Conference on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIML-TUDA/TEdBench_plusplus.","first_N":5,"first_N_keywords":["image-to-image","text-to-image","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"M-BEIR","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/M-BEIR","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUniIR: Training and Benchmarking Universal Multimodal Information Retrievers (ECCV 2024)\\n\\t\\n\\nüåê Homepage | ü§ó Model(UniIR Checkpoints) | ü§ó Paper | üìñ arXiv  | GitHub\\nHow to download the M-BEIR Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\nüî•[2023-12-21]: Our M-BEIR Benchmark is now available for use.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nM-BEIR, the Multimodal BEnchmark for Instructed Retrieval, is a comprehensive large-scale retrieval benchmark designed to train and evaluate unified multimodal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/M-BEIR.","first_N":5,"first_N_keywords":["text-retrieval","text-to-image","image-to-text","visual-question-answering","English"],"keywords_longer_than_N":true},
	{"name":"multilingual-tts","keyword":"text-to-speech","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBefore Anything and Everything ‚ö±\\n\\t\\n\\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) üáµüá∏\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"Pexels-400k","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jovianzm/Pexels-400k","creator_name":"Jovian","creator_url":"https://huggingface.co/jovianzm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPexels 400k\\n\\t\\n\\nDataset of 400,476 videos, their thumbnails, viewcounts, explicit classification, and caption.\\nNote: The Pexels-320k dataset in the repo is this dataset, with videos <10s removed.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","text-to-video","image-to-video","English"],"keywords_longer_than_N":true},
	{"name":"Pexels-400k","keyword":"text-to-video","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jovianzm/Pexels-400k","creator_name":"Jovian","creator_url":"https://huggingface.co/jovianzm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPexels 400k\\n\\t\\n\\nDataset of 400,476 videos, their thumbnails, viewcounts, explicit classification, and caption.\\nNote: The Pexels-320k dataset in the repo is this dataset, with videos <10s removed.\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","text-to-video","image-to-video","English"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAniSpeech Dataset\\n\\t\\n\\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\\n\\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tANNOUNCMENTS:\\n\\t\\n\\n\\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAniSpeech Dataset\\n\\t\\n\\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\\n\\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tANNOUNCMENTS:\\n\\t\\n\\n\\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"T2IScoreScore","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saxon/T2IScoreScore","creator_name":"Michael Saxon","creator_url":"https://huggingface.co/saxon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Text-to-Image ScoreScore (T2IScoreScore or TS2)\\n\\t\\n\\nThis dataset exists as part of the T2IScoreScore metaevaluation for assessing the faithfulness and consistency of text-to-image model prompt-image evaluation metrics.\\nNecessary code for utilizing the resource is present at github.com/michaelsaxon/T2IScoreScore\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a test set of 165 \\\"target prompts\\\" which each have between 5 and 76 generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saxon/T2IScoreScore.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"T2IScoreScore","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saxon/T2IScoreScore","creator_name":"Michael Saxon","creator_url":"https://huggingface.co/saxon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Text-to-Image ScoreScore (T2IScoreScore or TS2)\\n\\t\\n\\nThis dataset exists as part of the T2IScoreScore metaevaluation for assessing the faithfulness and consistency of text-to-image model prompt-image evaluation metrics.\\nNecessary code for utilizing the resource is present at github.com/michaelsaxon/T2IScoreScore\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a test set of 165 \\\"target prompts\\\" which each have between 5 and 76 generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saxon/T2IScoreScore.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"openslr63","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/openslr63","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSLR63: Crowdsourced high-quality Malayalam multi-speaker speech data set\\n\\t\\n\\nThis data set contains transcribed high-quality audio of Malayalam sentences recorded by volunteers. The data set consists of wave files, and a TSV file (line_index.tsv). The file line_index.tsv contains a anonymized FileID and the transcription of audio in the file.\\nThe data set has been manually quality checked, but there might still be errors.\\nPlease report any issues in the following issue tracker on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vrclc/openslr63.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Malayalam","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hypnosis_dataset","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/hypnosis_dataset","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset card for \\\"hypnosis_dataset\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\thypnosis scripts based on Erickson progressions\\n\\t\\n\\nThis is a small dataset containing hypnosis scripts that were both obtained from legitimate (manual) sources, and also generated using the following closed and open models:\\nlarge llm:\\n\\nopenai api\\ncohere\\npalm\\nopen models:\\nmistral-7b\\ntrismegistus-mistral-7b\\nzephyr-7b\\nmistral-anima-phi-7b\\nmistral-instruct\\n\\nThe data has been cleaned but not altered save for formatting. \\nSome entries‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jtatman/hypnosis_dataset.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-to-audio","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"novelai3","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shareAI/novelai3","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNovelai3 Images\\n\\t\\n\\nThe Novelai3 text-to-image distillation dataset contains over 30GB of anime-related (text, image) pairs, intended solely for educational and research purposes! It must not be used for any illicit activities.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProduction Method\\n\\t\\n\\nThe dataset was created through automated browser operations, repeatedly clicking the \\\"generate image\\\" button and saving the resulting images. Over the course of a month, approximately 38GB of (image, text instruction) pairs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shareAI/novelai3.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","n<1K","Image"],"keywords_longer_than_N":true},
	{"name":"Voice-KusanagiNene","keyword":"text-to-speech","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MomoyamaSawa/Voice-KusanagiNene","creator_name":"„ÅÜ„Åï„Åé","creator_url":"https://huggingface.co/MomoyamaSawa","description":"\\n  \\n\\n ü•ï \\n Â¶ÇÊûúÂÖîÂÖîÁöÑ‰ªìÂ∫ìÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÁöÑËØùÁÇπ‰∏™‚≠êÂñµ~ \\n If Tutu's repository is helpful to you, please give it a ‚≠ê meow~ \\n „ÇÇ„Åó„ÅÜ„Åï„Åé„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅåÂΩπ„Å´Á´ã„Å£„ÅüÂ†¥Âêà„ÅØ„ÄÅ‚≠ê„Çí„ÅΩ„Å°„Å£„Å®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„Å´„ÇÉ„Çì~  \\n\\n üçâ \\n ‰ªª‰Ωï ‚ùìÈóÆÈ¢ò / üí≠ÊÄùËÄÉ /üí°ÊÉ≥Ê≥ï ÈÉΩÊ¨¢ËøéÊèêÂá∫ÔºÅ\\n Any ‚ùìquestion / üí≠thought /üí°idea  is welcome! \\n „Å©„Çì„Å™ ‚ùìË≥™Âïè / üí≠ËÄÉ„Åà /üí°„Ç¢„Ç§„Éá„Ç¢ „Åß„ÇÇÊ≠ìËøé„Åß„ÅôÔºÅ \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÁÆÄ‰ªã\\n\\t\\n\\n\\nËçâËñôÂØß„ÄÖ Âπ≤Â£∞Â∏¶Ê†áÁ≠æÊï∞ÊçÆÈõÜ\\n\\nÊú¨Êï∞ÊçÆÈõÜÂè™Êî∂ÈõÜ‰∫ÜÊ∏∏ÊàèÂÜÖÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂπ∂‰∏çÊòØÂÖ®ÈÉ®ÁöÑÂÆÅÂÆÅÂπ≤Â£∞ËØ≠Èü≥ÔºåÂÖ∂‰∏≠ nene_org.txt ÊòØÊ†áÁ≠æÊñá‰ª∂\\npjsk ÂÖ®ÈÉ®ËßíËâ≤Âπ≤Â£∞Â∏¶Ê†áÁ≠æÊï∞ÊçÆÈõÜÁöÑËØùÂèØ‰ª•Âä†QQÁæ§Ôºö691795641ÔºåÁæ§ÂÖ¨ÂëäÈáåÊúâÁΩëÁõòÂú∞ÂùÄ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÂèÇËÄÉ\\n\\t\\n\\n\\nÂ£∞Ê∫êÂΩíÂ±ûÔºöËçâËñôÂØß„ÄÖ(CV:Machico)-„Äå„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çª„Ç´„Ç§ „Ç´„É©„Éï„É´„Çπ„ÉÜ„Éº„Ç∏ÔºÅ feat. ÂàùÈü≥„Éü„ÇØ„Äç\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTODO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MomoyamaSawa/Voice-KusanagiNene.","first_N":5,"first_N_keywords":["other","text-to-speech","audio-to-audio","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"libritts_r","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/libritts_r","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LibriTTS-R\\n\\t\\n\\n\\n\\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus \\n(http://www.openslr.org/60/) which is a multi-speaker English corpus of approximately \\n585 hours of read English speech at 24kHz sampling rate, published in 2019.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the LibriTTS-R dataset, adapted for the datasets library.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSplits\\n\\t\\n\\nThere are 7 splits (dots replace dashes from the original dataset, to comply with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/libritts_r.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"sd-ml-assignment","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/premai-io/sd-ml-assignment","creator_name":"Prem","creator_url":"https://huggingface.co/premai-io","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tText to Image Dataset for Pixel Art style\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains 100 examples of Images representing different topics all with the same style.\\n","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","arrow","Image"],"keywords_longer_than_N":true},
	{"name":"libritts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/libritts","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LibriTTS\\n\\t\\n\\n\\n\\nLibriTTS is a multi-speaker English corpus of approximately 585 hours of read English speech at 24kHz sampling rate, \\nprepared by Heiga Zen with the assistance of Google Speech and Google Brain team members. The LibriTTS corpus is \\ndesigned for TTS research. It is derived from the original materials (mp3 audio files from LibriVox and text files \\nfrom Project Gutenberg) of the LibriSpeech corpus.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the LibriTTS dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/libritts.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"vlsp2020_vinai_100h","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of VLSP 2020 - VinAI - ASR challenge dataset\\n\\t\\n\\nofficial announcement:\\n\\nti·∫øng vi·ªát: https://institute.vinbigdata.org/events/vinbigdata-chia-se-100-gio-du-lieu-tieng-noi-cho-cong-dong/\\nin eglish: https://institute.vinbigdata.org/en/events/vinbigdata-shares-100-hour-data-for-the-community/\\nVLSP 2020 workshop: https://vlsp.org.vn/vlsp2020\\n\\nofficial download: https://drive.google.com/file/d/1vUSxdORDxk-ePUt-bUVDahpoXiqKchMx/view?usp=sharing\\ncontact:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"infore1_25hours","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore1_25hours","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of InfoRe Technology public dataset ‚Ññ1\\n\\t\\n\\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\\n25h, 14.9k samples, InfoRe paid a contractor to read text\\nofficial download: magnet:?xt=urn:btih:1cbe13fb14a390c852c016a924b4a5e879d85f41&dn=25hours.zip&tr=http%3A%2F%2Foffice.socials.vn%3A8725%2Fannounce\\nmirror: https://files.huylenguyen.com/25hours.zip\\nunzip password: BroughtToYouByInfoRe\\npre-process: none\\nneed to do:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore1_25hours.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DND-Monster-Diffusion","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TravisHudson/DND-Monster-Diffusion","creator_name":"Travis Hudson","creator_url":"https://huggingface.co/TravisHudson","description":"TravisHudson/DND-Monster-Diffusion dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"mls_eng_10k","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng_10k","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls_eng_10k","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng_10k","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls_eng","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for English MLS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls_eng","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for English MLS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"train_video_and_instruction","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ShareGPTVideo/train_video_and_instruction","creator_name":"ShareGPTVideo","creator_url":"https://huggingface.co/ShareGPTVideo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPTVideo Training Data\\n\\t\\n\\nAll dataset and models can be found at ShareGPTVideo.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContents:\\n\\t\\n\\n\\nTrain 300k video frames: contains video frames used for SFT and DPO model, which is a subset of total 900k.\\nActivityNet 50k + vidal 150k + webvid 100k.\\n\\nTrain 600k video frames: contains the rest 600k frames, the total 900k frames are used for pre-training stage. If you just do finetuning using our video QA, you can just download the 300k above.\\n900k composition is 400k‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShareGPTVideo/train_video_and_instruction.","first_N":5,"first_N_keywords":["question-answering","video-text-to-text","English","apache-2.0","Video"],"keywords_longer_than_N":true},
	{"name":"airbnb_embeddings","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MongoDB/airbnb_embeddings","creator_name":"MongoDB","creator_url":"https://huggingface.co/MongoDB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset consists of AirBnB listings with property descriptions, reviews, and other metadata. \\nIt also contains text embeddings of the property descriptions as well as image embeddings of the listing image. The text embeddings were created using OpenAI's text-embedding-3-small model and the image embeddings using OpenAI's clip-vit-base-patch32 model available on Hugging Face. \\nThe text embeddings have 1536 dimensions, while the image embeddings have 512 dimensions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MongoDB/airbnb_embeddings.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","text-to-image","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MediaSpeech","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMediaSpeech\\n\\t\\n\\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\\nBaseline models and WAV version of the dataset can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"libritts_r_tags_tagged_10k_generated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/libritts_r_tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotated LibriTTS-R\\n\\t\\n\\nThis dataset is an annotated version of LibriTTS-R [1]. LibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately 960 hours of read English speech at 24kHz sampling rate, published in 2019. \\nIn the text_description column, it provides natural language annotations on the characteristics of speakers and utterances, that have been generated using the Data-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"synthetic-dataset-1m-dalle3-high-quality-captions","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions","creator_name":"Ben","creator_url":"https://huggingface.co/ProGamerGov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dalle3 1 Million+ High Quality Captions\\n\\t\\n\\nAlt name: Human Preference Synthetic Dataset\\n\\n\\n\\nExample grids for landscapes, cats, creatures, and fantasy are also available.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription:\\n\\t\\n\\nThis dataset comprises of AI-generated images sourced from various websites and individuals, primarily focusing on Dalle 3 content, along with contributions from other AI systems of sufficient quality like Stable Diffusion and Midjourney (MJ v5 and above). As users‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions.","first_N":5,"first_N_keywords":["text-to-image","image-classification","image-to-text","image-text-to-text","other"],"keywords_longer_than_N":true},
	{"name":"synthetic-dataset-1m-dalle3-high-quality-captions","keyword":"image-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions","creator_name":"Ben","creator_url":"https://huggingface.co/ProGamerGov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dalle3 1 Million+ High Quality Captions\\n\\t\\n\\nAlt name: Human Preference Synthetic Dataset\\n\\n\\n\\nExample grids for landscapes, cats, creatures, and fantasy are also available.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription:\\n\\t\\n\\nThis dataset comprises of AI-generated images sourced from various websites and individuals, primarily focusing on Dalle 3 content, along with contributions from other AI systems of sufficient quality like Stable Diffusion and Midjourney (MJ v5 and above). As users‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions.","first_N":5,"first_N_keywords":["text-to-image","image-classification","image-to-text","image-text-to-text","other"],"keywords_longer_than_N":true},
	{"name":"LSVSC","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/LSVSC","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of LSVSC dataset (novel large-scale Vietnamese speech corpus)\\n\\t\\n\\nofficial announcement: https://www.mdpi.com/2079-9292/13/5/977\\nofficial download: https://drive.google.com/drive/folders/1tiPKaIOC7bt6isv5qFqf61O_2jFK8ZOI\\n100h, 57k samples\\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/clean-lsvsc.py\\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\\nusage with HuggingFace:\\n# pip install -q‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/LSVSC.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"StreetView360AtoZ","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/everettshen/StreetView360AtoZ","creator_name":"Everett Shen","creator_url":"https://huggingface.co/everettshen","description":"StreetView 360X is a dataset containing 6342 360 degree equirectangular street view images randomly sampled and downloaded from Google Street View. It is published as part of the paper \\\"StreetView360X: A Location-Conditioned Latent Diffusion Model for Generating Equirectangular 360 Degree Street Views\\\" (Princeton COS Senior Independent Work by Everett Shen). Images are labelled with their capture coordinates and panorama IDs. Scripts for extending the dataset (i.e. fetching additional images)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/everettshen/StreetView360AtoZ.","first_N":5,"first_N_keywords":["text-to-image","image-classification","image-to-text","image-feature-extraction","mit"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ClArTTS","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe present a speech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated. The final ClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nA typical data point comprises the name of the audio file, called‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ClArTTS.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ClArTTS","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe present a speech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated. The final ClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nA typical data point comprises the name of the audio file, called‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ClArTTS.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"pony-speech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-speech","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"pony-speech","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-speech","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"commoncatalog-cc-by","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/common-canvas/commoncatalog-cc-by","creator_name":"CommonCanvas","creator_url":"https://huggingface.co/common-canvas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CommonCatalog CC-BY\\n\\t\\n\\nThis dataset is a large collection of high-resolution Creative Common images (composed of different licenses, see paper Table 1 in the Appendix) collected in 2014 from users of Yahoo Flickr. \\nThe dataset contains images of up to 4k resolution, making this one of the highest resolution captioned image datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe provide captions synthetic captions to approximately 100 million‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/common-canvas/commoncatalog-cc-by.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"Plot2Code","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TencentARC/Plot2Code","creator_name":"ARC Lab, Tencent PCG","creator_url":"https://huggingface.co/TencentARC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlot2Code Benchmark\\n\\t\\n\\nPlot2Code benchmark is now open-sourced at huggingface (ARC Lab) and GitHub. More information can be found in our paper. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy we need Plot2Code?\\n\\t\\n\\n\\nüßê While MLLMs have demonstrated potential in visual contexts, their capabilities in visual coding tasks have not been thoroughly evaluated. Plot2Code offers a platform for comprehensive assessment of these models.\\n\\nü§ó To enable individuals to ascertain the proficiency of AI assistants in generating‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TencentARC/Plot2Code.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-to-image","image-to-text","image-to-image"],"keywords_longer_than_N":true},
	{"name":"midjourney-v6","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CortexLM/midjourney-v6","creator_name":"Cortex Foundation","creator_url":"https://huggingface.co/CortexLM","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMidJourney v6 Dataset by Bittensor Network (NetUID 19)\\n\\t\\n\\nDescription : This dataset was generated by Subnetwork 19 (Bittensor), utilizing the capabilities of MidJourney v6.\\nDisclaimer: Image Attribution and Copyright Notice\\nThe images included in this dataset have been sourced from an API. While every effort has been made to ensure compliance with copyright and intellectual property rights, Cortex Foundation cannot guarantee the absence of any copyright or intellectual property‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CortexLM/midjourney-v6.","first_N":5,"first_N_keywords":["text-to-image","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"lexica_dataset","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vera365/lexica_dataset","creator_name":"Xinyue Shen","creator_url":"https://huggingface.co/vera365","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLexicaDataset\\n\\t\\n\\nLexicaDataset is a large-scale text-to-image prompt dataset shared in [USENIX'24] Prompt Stealing Attacks Against Text-to-Image Generation Models.\\nIt contains 61,467 prompt-image pairs collected from Lexica.\\nAll prompts are curated by real users and images are generated by Stable Diffusion.\\nData collection details can be found in the paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nWe randomly sample 80% of a dataset as the training dataset and the rest 20% as the testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vera365/lexica_dataset.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Recap-DataComp-1B","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCSC-VLAA/Recap-DataComp-1B","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Recap-DataComp-1B\\n\\t\\n\\n\\n\\nRecap-DataComp-1B is a large-scale image-text dataset that has been recaptioned using an advanced LLaVA-1.5-LLaMA3-8B model to enhance the alignment and detail of textual descriptions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nOur paper aims to bridge this community effort, leveraging the powerful and open-sourced LLaMA-3, a GPT-4 level LLM.\\nOur recaptioning pipeline is simple: first, we fine-tune a LLaMA-3-8B powered‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UCSC-VLAA/Recap-DataComp-1B.","first_N":5,"first_N_keywords":["zero-shot-classification","text-retrieval","image-to-text","text-to-image","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ChronoMagic","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BestWishYsh/ChronoMagic","creator_name":"YSH","creator_url":"https://huggingface.co/BestWishYsh","description":"\\n\\n\\n MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators\\n\\n If you like our project, please give us a star ‚≠ê on GitHub for the latest update.  \\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüê≥ ChronoMagic Dataset\\n\\t\\n\\nChronoMagic with 2265 metamorphic time-lapse videos, each accompanied by a detailed caption. We released the subset of ChronoMagic used to train MagicTime. The dataset can be downloaded at HuggingFace Dataset, or you can download it with the following command. Some samples can be found on our Project‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BestWishYsh/ChronoMagic.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"GLOBE","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImportant notice\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t!!! Please use V2 version version as this version has abnormal voice volume issue.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlobe\\n\\t\\n\\nThe full paper can be accessed here: arXiv\\nAn online demo can be accessed here: Github\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbstract\\n\\t\\n\\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to address the limitations of current zero-shot speaker adaptive Text-to-Speech (TTS) systems that exhibit poor generalizability in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"UltraEdit_Region_Based_100k","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BleachNick/UltraEdit_Region_Based_100k","creator_name":"Hans Zhao","creator_url":"https://huggingface.co/BleachNick","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBibtex citation\\n\\t\\n\\n@misc{zhao2024ultraeditinstructionbasedfinegrainedimage,\\n      title={UltraEdit: Instruction-based Fine-Grained Image Editing at Scale}, \\n      author={Haozhe Zhao and Xiaojian Ma and Liang Chen and Shuzheng Si and Rujie Wu and Kaikai An and Peiyu Yu and Minjia Zhang and Qing Li and Baobao Chang},\\n      year={2024},\\n      eprint={2407.05282},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CV},\\n      url={https://arxiv.org/abs/2407.05282}, \\n}\\n\\n","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"BibleMMS","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flux9665/BibleMMS","creator_name":"Florian Lux","creator_url":"https://huggingface.co/Flux9665","description":"The Dataset associated with the Paper \\\"Meta Learning Text-to-Speech Synthesis in over 7000 Languages\\\" by Florian Lux, Sarina Meyer, Lyonel Behringer, Frank Zalkow, Phat Do, Matt Coler, Emanu√´l A. P. Habets and Ngoc Thang Vu (Interspeech 2024).\\nWe generate 2000 spoken utterances per language using the subsets of the eBible dataset [1] that are under free licenses as the text input to the MMS TTS models [2]. \\nThe languages associated with the following ISO-639-3 codes are represented in this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Flux9665/BibleMMS.","first_N":5,"first_N_keywords":["text-to-speech","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"living-room-passes","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nfiniteai/living-room-passes","creator_name":"Nfinite","creator_url":"https://huggingface.co/Nfiniteai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tnfinite-living-room-passes\\n\\t\\n\\nVersion of the release: 1.0.0-alphaRelease date: 2024/06/17\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe nfinite-living-room-passes dataset is a dataset of images from 3D models for objects usually found in the living room space. 500 products are available, across 10500 images.  \\nEach product has been rendered photo-realistically from a 3D model and is also available as a series of images depicting its normal map, its depth map, and some other information.Those‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nfiniteai/living-room-passes.","first_N":5,"first_N_keywords":["depth-estimation","image-classification","image-segmentation","text-to-image","image-to-text"],"keywords_longer_than_N":true},
	{"name":"OpenVid-1M","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nkp37/OpenVid-1M","creator_name":"nkp","creator_url":"https://huggingface.co/nkp37","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper \\\"OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation\\\".\\nOpenVid-1M is a high-quality text-to-video dataset designed for research institutions to enhance video quality, featuring high aesthetics, clarity, and resolution. It can be used for direct training or as a quality tuning complement to other video datasets.\\nAll videos in the OpenVid-1M dataset have resolutions of at least 512√ó512. Furthermore, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nkp37/OpenVid-1M.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"OpenVid-1M","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nkp37/OpenVid-1M","creator_name":"nkp","creator_url":"https://huggingface.co/nkp37","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper \\\"OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation\\\".\\nOpenVid-1M is a high-quality text-to-video dataset designed for research institutions to enhance video quality, featuring high aesthetics, clarity, and resolution. It can be used for direct training or as a quality tuning complement to other video datasets.\\nAll videos in the OpenVid-1M dataset have resolutions of at least 512√ó512. Furthermore, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nkp37/OpenVid-1M.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"conceptual-captions-cc12m-llavanext","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/conceptual-captions-cc12m-llavanext","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for conceptual-captions-cc12m-llavanext\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a data of 21,930,344 synthetic captions for 10,965,172 images from conceptual_12m. In the interest of reproducibility, an archive found here on Huggingface was used (cc12m-wds). The captions were produced using llama3-llava-next-8b inferenced in float16, followed by cleanup and shortening with Meta-Llama-3-8B.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe captions are in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/conceptual-captions-cc12m-llavanext.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Recap-COCO-30K","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCSC-VLAA/Recap-COCO-30K","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLlava recaptioned COCO2014 ValSet.\\n\\t\\n\\nUsed for text-to-image generation evaluaion. More detial can be found in What If We Recaption Billions of Web Images with LLaMA-3?\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\\"image_id\\\" (str): COCO image id.\\n\\\"coco_url\\\" (image): the COCO image url.\\n\\\"caption\\\" (str): the original COCO caption.\\n\\\"recaption\\\" (str): the llava recaptioned COCO caption.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n\\n\\nBibTeX:\\n@article{li2024recapdatacomp,\\n  title={What If We Recaption Billions of Web‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UCSC-VLAA/Recap-COCO-30K.","first_N":5,"first_N_keywords":["text-to-image","cc-by-4.0","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"mls-eng-speaker-descriptions","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of English MLS\\n\\t\\n\\nThis dataset consists in annotations of the English subset of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.\\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-speaker-descriptions","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of English MLS\\n\\t\\n\\nThis dataset consists in annotations of the English subset of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.\\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"libritts_r_filtered","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/libritts_r_filtered","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtered LibriTTS-R\\n\\t\\n\\nThis is a filtered version of LibriTTS-R. It has been filtered based on two sources:\\n\\nLibriTTS-R paper [1], which lists samples for which speech restoration have failed\\nLibriTTS-P [2] list of excluded speakers for which multiple speakers have been detected.\\n\\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately \\n585 hours of read English speech at 24kHz sampling rate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_filtered.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"TexSD","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ilopes/TexSD","creator_name":"Lopes","creator_url":"https://huggingface.co/ilopes","description":"We generate a high-resolution tileable texture dataset by prompting a pre-trained Stable Diffusion model. The dataset consists of 130 classes resulting in more than 10,000 unique textures. More details can be found in our paper.\\nThe generated samples have been curated manually to select only the most relevant textures.\\n\\n","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"pixelprose","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomg-group-umd/pixelprose","creator_name":"Tom Goldstein's Lab at University of Maryland, College Park","creator_url":"https://huggingface.co/tomg-group-umd","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom Pixels to Prose: A Large Dataset of Dense Image Captions\\n\\t\\n\\n[ arXiv paper ]\\nPixelProse is a comprehensive dataset of over 16M (million) synthetically generated captions, \\nleveraging cutting-edge vision-language models (Gemini 1.0 Pro Vision) for detailed and accurate descriptions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Details\\n\\t\\n\\nTotal number of image-caption pairs: 16,896,214 (16.9M)\\n\\n6,538,898 (6.5M) pairs in the split of CommonPool\\n9,066,455 (9.1M) pairs in the split of CC12M\\n1,290,861 (1.3M)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomg-group-umd/pixelprose.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"pixelprose","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestone-horizon/pixelprose","creator_name":"Horizon","creator_url":"https://huggingface.co/lodestone-horizon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom Pixels to Prose: A Large Dataset of Dense Image Captions\\n\\t\\n\\n[[ arXiv paper ]]\\nPixelProse is a comprehensive dataset of over 16M (million) synthetically generated captions, \\nleveraging cutting-edge vision-language models (Gemini 1.0 Pro Vision) for detailed and accurate descriptions.\\n@article{pixelprose24,\\n  title   = {{From Pixels to Prose: A Large Dataset of Dense Image Captions}},\\n  author  = {Vasu Singla and Kaiyu Yue and Sukriti Paul and Reza Shirkavand and Mayuka‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lodestone-horizon/pixelprose.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"coyo-hd-11m-llavanext","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/coyo-hd-11m-llavanext","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for coyo-hd-11m-llavanext\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a data of 22,794,288 synthetic captions for 11,397,144 images from coyo-700m. The \\\"hd\\\" in the title refers to two aspects: high density and high definition. While large alt-text image pair datasets have many images, only a very small proportion of these images are in higher resolutions and have substantial concept density. For example, many of these datasets consist of more than 50% thumbnail sized or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/coyo-hd-11m-llavanext.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"photo-anatomy","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lodestone-horizon/photo-anatomy","creator_name":"Horizon","creator_url":"https://huggingface.co/lodestone-horizon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhoto Anatomy Dataset\\n\\t\\n\\nPulled from Pexels in 2023.\\nImages contain a majority of images of \\\"people holding things\\\".\\nImage filenames may be used as captions, or, the parquet table contains the same values.\\nThis dataset contains the full images.\\nCaptions were created with CogVLM.\\n","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"NSFW-T2I","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zxbsmk/NSFW-T2I","creator_name":"Jun","creator_url":"https://huggingface.co/zxbsmk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction (Version 1)\\n\\t\\n\\nAbout 38k image-text pairs(10k from LAION and 28k from nsfw_detect), and captions are generated by LLaVA-NeXT with prompt \\\"Describe the photo in detail (attributes of person)\\\".\\nThe \\\"txt\\\" column shown in the dataset viewer is originated from LAION, not the captions yielded by LLaVA-NeXT.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCaption Codes\\n\\t\\n\\npretrained = \\\"lmms-lab/llama3-llava-next-8b\\\"\\nmodel_name = \\\"llava_llama3\\\"\\ndevice = \\\"cuda:2\\\"\\ndevice_map = \\\"auto\\\"\\ntokenizer, model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zxbsmk/NSFW-T2I.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"arabic_quranic_asr","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadique5/arabic_quranic_asr","creator_name":"Sadique Abdullah","creator_url":"https://huggingface.co/Sadique5","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nThis dataset contains quran recitations of every ayats or verses. Also contains 10k unique words from quran.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Purpose\\n\\t\\n\\nThis dataset can be used to train ASR models that can be used for teaching beginners to recite quran. It can also be used for training TTS models that produces quran recitations in a way so that beginners can easily learn.\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"AnyWord-3M","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stzhao/AnyWord-3M","creator_name":"steve z","creator_url":"https://huggingface.co/stzhao","description":"Dataset from AnyText: Multilingual Visual Text Generation And Editing.\\nDataset description from Anytext Team:\\nCurrently, there is a relative scarcity of public datasets for text generation tasks, especially those involving non-Latin script languages. To address this, we introduce a large-scale multilingual dataset called AnyWord-3M. The images in this dataset are sourced from Noah-Wukong, LAION-400M, and OCR recognition datasets such as ArT, COCO-Text, RCTW, LSVT, MLT, MTWI, ReCTS, etc. These‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stzhao/AnyWord-3M.","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","1M - 10M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"persian_tts_stt","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SmartGitiCorp/persian_tts_stt","creator_name":"Smart Giti Corporation","creator_url":"https://huggingface.co/SmartGitiCorp","description":"This dataset contains more than 10k records and 15 hours of clear vocal voice aligning with text in csv file.\\n","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"persian_tts_stt","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SmartGitiCorp/persian_tts_stt","creator_name":"Smart Giti Corporation","creator_url":"https://huggingface.co/SmartGitiCorp","description":"This dataset contains more than 10k records and 15 hours of clear vocal voice aligning with text in csv file.\\n","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"svg-stack-labeled","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrOvkill/svg-stack-labeled","creator_name":"Samuel L Meyers","creator_url":"https://huggingface.co/MrOvkill","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSvg Stack - Labeled\\n\\t\\n\\nThis dataset consists of the central storage for all datasets related to the SVG Stack dataset. I found it to be lovely, detailed, and of decent to extremely good quality upon observing many different icons and logos during the labeling process.\\nThis is the central dataset, and is currently UNDER CONSTRUCTION.  Use with caution, and be aware that the format HAS NOT been frozen. I will make a post announcing when I freeze this dataset, as that will also be the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrOvkill/svg-stack-labeled.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"imagenet-1k-vl-enriched","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/visual-layer/imagenet-1k-vl-enriched","creator_name":"Visual Layer","creator_url":"https://huggingface.co/visual-layer","description":"\\n  \\n    Visualize on Visual Layer\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImagenet-1K-VL-Enriched\\n\\t\\n\\nAn enriched version of the ImageNet-1K Dataset with image caption, bounding boxes, and label issues!\\nWith this additional information, the ImageNet-1K dataset can be extended to various tasks such as image retrieval or visual question answering.\\nThe label issues helps to curate a cleaner and leaner dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset consists of 6 columns:\\n\\nimage_id: The original filename of the image‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/visual-layer/imagenet-1k-vl-enriched.","first_N":5,"first_N_keywords":["object-detection","image-classification","text-to-image","image-to-text","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"MiraData","keyword":"text-to-image","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TencentARC/MiraData","creator_name":"ARC Lab, Tencent PCG","creator_url":"https://huggingface.co/TencentARC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions\\n\\t\\n\\n\\nXuan Ju1*, Yiming Gao1*, Zhaoyang Zhang1*#, Ziyang Yuan1,  Xintao Wang1,  Ailing Zeng, Yu Xiong, Qiang Xu,  Ying Shan1 \\n1ARC Lab, Tencent PCG  2The Chinese University of Hong Kong  *Equal Contribution  #Project Lead\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVideo datasets play a crucial role in video generation such as Sora.\\nHowever, existing text-video datasets often fall short when it comes to handling long‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TencentARC/MiraData.","first_N":5,"first_N_keywords":["image-to-video","text-to-image","text-to-video","video-classification","English"],"keywords_longer_than_N":true},
	{"name":"MiraData","keyword":"text-to-video","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TencentARC/MiraData","creator_name":"ARC Lab, Tencent PCG","creator_url":"https://huggingface.co/TencentARC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions\\n\\t\\n\\n\\nXuan Ju1*, Yiming Gao1*, Zhaoyang Zhang1*#, Ziyang Yuan1,  Xintao Wang1,  Ailing Zeng, Yu Xiong, Qiang Xu,  Ying Shan1 \\n1ARC Lab, Tencent PCG  2The Chinese University of Hong Kong  *Equal Contribution  #Project Lead\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVideo datasets play a crucial role in video generation such as Sora.\\nHowever, existing text-video datasets often fall short when it comes to handling long‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TencentARC/MiraData.","first_N":5,"first_N_keywords":["image-to-video","text-to-image","text-to-video","video-classification","English"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"Á≤µË™ûË®àÁÆóË™ûË®ÄÂ≠∏Âü∫Á§éÂª∫Ë®≠ÁµÑ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\\n\\t\\n\\t\\t\\n\\t\\tÂºµÊÇ¶Ê•∑Ë¨õÂè§Ë™ûÈü≥Êï∏ÊìöÈõÜ\\n\\t\\n\\nEnglish\\nÂë¢ÂÄã‰øÇÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„Äã„ÄÅ„ÄäÊ∞¥Êª∏ÂÇ≥„Äã„ÄÅ„ÄäËµ∞ÈÄ≤ÊØõÊæ§Êù±ÁöÑÊúÄÂæåÊ≠≤Êúà„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ„ÄÇÂºµÊÇ¶Ê•∑‰øÇÂª£Â∑ûÊúÄÂá∫ÂêçÂòÖË¨õÂè§‰Ω¨ / Á≤µË™ûË™¨Êõ∏Ëóù‰∫∫„ÄÇ‰Ω¢Âæû‰∏ä‰∏ñÁ¥Ä‰∏ÉÂçÅÂπ¥‰ª£ÈñãÂßãÂ∞±Âñ∫Âª£Êù±ÂêÑÂÄãÊî∂Èü≥ÈõªÂè∞Â∫¶Ë¨õÂè§Ôºå‰Ω¢ÊääËÅ≤‰øÇÂ•ΩÂ§öÂª£Â∑û‰∫∫ÂòÖÂÖ±ÂêåÂõûÊÜ∂„ÄÇÊú¨Êï∏ÊìöÈõÜÊî∂ÈõÜÂòÖ‰øÇ‰Ω¢ÊúÄÁü•ÂêçÂòÖ‰∏âÈÉ®‰ΩúÂìÅ„ÄÇ\\nÊï∏ÊìöÈõÜÁî®ÈÄîÔºö\\n\\nTTSÔºàË™ûÈü≥ÂêàÊàêÔºâË®ìÁ∑¥ÈõÜ\\nASRÔºàË™ûÈü≥Ë≠òÂà•ÔºâË®ìÁ∑¥ÈõÜÊàñÊ∏¨Ë©¶ÈõÜ\\nÂêÑÁ®ÆË™ûË®ÄÂ≠∏„ÄÅÊñáÂ≠∏Á†îÁ©∂\\nÁõ¥Êé•ËÅΩÂöüÊ¨£Ë≥ûËóùË°ìÔºÅ\\n\\nTTS ÊïàÊûúÊºîÁ§∫Ôºöhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tË™¨Êòé\\n\\t\\n\\n\\nÊâÄÊúâÊñáÊú¨ÈÉΩÊ†πÊìö https://jyutping.org/blog/typo/ Âêå https://jyutping.org/blog/particles/ Ë¶èÁØÑÁî®Â≠ó„ÄÇ\\nÊâÄÊúâÊñáÊú¨ÈÉΩ‰ΩøÁî®ÂÖ®ËßíÊ®ôÈªûÔºåÂÜáÂçäËßíÊ®ôÈªû„ÄÇ\\nÊâÄÊúâÊñáÊú¨ÈÉΩÁî®Êº¢Â≠óËΩâÂØ´ÔºåÁÑ°ÈòøÊãâ‰ºØÊï∏Â≠óÁÑ°Ëã±ÊñáÂ≠óÊØç\\nÊâÄÊúâÈü≥È†ªÊ∫êÈÉΩÂ≠òÊîæÂñ∫/sourceÔºåÁÇ∫Êñπ‰æøÁõ¥Êé•Áî®‰ΩúË®ìÁ∑¥Êï∏ÊìöÔºåÂàáÂàÜÂæåÂòÖÈü≥È†ªÈÉΩÊîæÂñ∫ opus/\\nÊâÄÊúâ opus Èü≥È†ªÁöÜÁÇ∫ 48000 Hz Êé°Ê®£Áéá„ÄÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"Á≤µË™ûË®àÁÆóË™ûË®ÄÂ≠∏Âü∫Á§éÂª∫Ë®≠ÁµÑ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\\n\\t\\n\\t\\t\\n\\t\\tÂºµÊÇ¶Ê•∑Ë¨õÂè§Ë™ûÈü≥Êï∏ÊìöÈõÜ\\n\\t\\n\\nEnglish\\nÂë¢ÂÄã‰øÇÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„Äã„ÄÅ„ÄäÊ∞¥Êª∏ÂÇ≥„Äã„ÄÅ„ÄäËµ∞ÈÄ≤ÊØõÊæ§Êù±ÁöÑÊúÄÂæåÊ≠≤Êúà„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ„ÄÇÂºµÊÇ¶Ê•∑‰øÇÂª£Â∑ûÊúÄÂá∫ÂêçÂòÖË¨õÂè§‰Ω¨ / Á≤µË™ûË™¨Êõ∏Ëóù‰∫∫„ÄÇ‰Ω¢Âæû‰∏ä‰∏ñÁ¥Ä‰∏ÉÂçÅÂπ¥‰ª£ÈñãÂßãÂ∞±Âñ∫Âª£Êù±ÂêÑÂÄãÊî∂Èü≥ÈõªÂè∞Â∫¶Ë¨õÂè§Ôºå‰Ω¢ÊääËÅ≤‰øÇÂ•ΩÂ§öÂª£Â∑û‰∫∫ÂòÖÂÖ±ÂêåÂõûÊÜ∂„ÄÇÊú¨Êï∏ÊìöÈõÜÊî∂ÈõÜÂòÖ‰øÇ‰Ω¢ÊúÄÁü•ÂêçÂòÖ‰∏âÈÉ®‰ΩúÂìÅ„ÄÇ\\nÊï∏ÊìöÈõÜÁî®ÈÄîÔºö\\n\\nTTSÔºàË™ûÈü≥ÂêàÊàêÔºâË®ìÁ∑¥ÈõÜ\\nASRÔºàË™ûÈü≥Ë≠òÂà•ÔºâË®ìÁ∑¥ÈõÜÊàñÊ∏¨Ë©¶ÈõÜ\\nÂêÑÁ®ÆË™ûË®ÄÂ≠∏„ÄÅÊñáÂ≠∏Á†îÁ©∂\\nÁõ¥Êé•ËÅΩÂöüÊ¨£Ë≥ûËóùË°ìÔºÅ\\n\\nTTS ÊïàÊûúÊºîÁ§∫Ôºöhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tË™¨Êòé\\n\\t\\n\\n\\nÊâÄÊúâÊñáÊú¨ÈÉΩÊ†πÊìö https://jyutping.org/blog/typo/ Âêå https://jyutping.org/blog/particles/ Ë¶èÁØÑÁî®Â≠ó„ÄÇ\\nÊâÄÊúâÊñáÊú¨ÈÉΩ‰ΩøÁî®ÂÖ®ËßíÊ®ôÈªûÔºåÂÜáÂçäËßíÊ®ôÈªû„ÄÇ\\nÊâÄÊúâÊñáÊú¨ÈÉΩÁî®Êº¢Â≠óËΩâÂØ´ÔºåÁÑ°ÈòøÊãâ‰ºØÊï∏Â≠óÁÑ°Ëã±ÊñáÂ≠óÊØç\\nÊâÄÊúâÈü≥È†ªÊ∫êÈÉΩÂ≠òÊîæÂñ∫/sourceÔºåÁÇ∫Êñπ‰æøÁõ¥Êé•Áî®‰ΩúË®ìÁ∑¥Êï∏ÊìöÔºåÂàáÂàÜÂæåÂòÖÈü≥È†ªÈÉΩÊîæÂñ∫ opus/\\nÊâÄÊúâ opus Èü≥È†ªÁöÜÁÇ∫ 48000 Hz Êé°Ê®£Áéá„ÄÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"e621-2024_index","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NebulaeWis/e621-2024_index","creator_name":"Nebulae","creator_url":"https://huggingface.co/NebulaeWis","description":"Index files of  https://huggingface.co/datasets/boxingscorpionbagel/e621-2024. \\n","first_N":5,"first_N_keywords":["text-to-image","image-classification","English","mit","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"coral-tts","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/coral-tts","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CoRal TTS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of two professional Danish speakers, female and male, recording roughly 17 hours of Danish speech each.\\nThe dataset is part of the CoRal project which is funded by the Danish Innovation Fund.\\nThe text data was selected by the Alexandra Institute (Github repo for the dataset creation) and consists of sentences from sundhed.dk, borger.dk, names of bus stops and stations, manually filtered Reddit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/coral-tts.","first_N":5,"first_N_keywords":["text-to-speech","Danish","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"vintage-photography-450k-high-quality-captions","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SilentAntagonist/vintage-photography-450k-high-quality-captions","creator_name":"John Smith","creator_url":"https://huggingface.co/SilentAntagonist","description":"This is a 450k image datastet focused on photography from the 20th century, and their analog aspect. Many of the images are in high resolution. This dataset currently has 20k images captioned with InternVL2 26B, and is a work in progress (I plan to caption the entire dataset and also have short captions for all of the images, compute is an issue for now).\\n","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","text-to-image","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"table-vqa","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cmarkea/table-vqa","creator_name":"Credit Mutuel Arkea","creator_url":"https://huggingface.co/cmarkea","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThe table-vqa Dataset integrates images of tables from the dataset AFTdb (Arxiv Figure Table Database) curated by cmarkea. \\nThis dataset consists of pairs of table images and corresponding LaTeX source code, with each image linked to an average of ten questions and answers. Half of the Q&A pairs are in English and the other half in French. These questions and answers were generated using Gemini 1.5 Pro and Claude 3.5 sonnet, making the dataset well-suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmarkea/table-vqa.","first_N":5,"first_N_keywords":["text-generation","text-to-image","image-to-text","table-question-answering","visual-question-answering"],"keywords_longer_than_N":true},
	{"name":"doodles-dataset","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/riversnow/doodles-dataset","creator_name":"Aditya Shankar","creator_url":"https://huggingface.co/riversnow","description":"A complete doodles dataset!\\n","first_N":5,"first_N_keywords":["image-classification","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Microcosmos","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pixel-Dust/Microcosmos","creator_name":"Pixel Dust","creator_url":"https://huggingface.co/Pixel-Dust","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMicrocosmos Dataset\\n\\t\\n\\nThis dataset consists of a carefully curated collection of Creative Commons (CC0) images or similar, combined with both synthetic and human-generated captions. It was assembled to facilitate the training of diffusion models with a focus on efficiency and ethical data practices. The dataset was compiled over several months, highlighting the dedication to responsible data collection and management.\\nDataset Details\\nDataset Description\\nMicrocosmos is designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Pixel-Dust/Microcosmos.","first_N":5,"first_N_keywords":["text-to-image","English","cc0-1.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"dreamlip_long_captions","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qidouxiong619/dreamlip_long_captions","creator_name":"Yifei Zhang","creator_url":"https://huggingface.co/qidouxiong619","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DreamLIP-30M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDreamLIP-Long-Captions is a dataset consisting of ~30M image annotations, i.e. detailed long captions. In contrast with the curated style of other synthetic image caption annotations, DreamLIP-30M utilizes pre-trained Multi-modality Large Language Model to obtain detailed descriptions with an average length of 247. More precisely, the detailed descriptions are generated by asking the ShareGPT4V/InstructBLIP/LLava1.5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qidouxiong619/dreamlip_long_captions.","first_N":5,"first_N_keywords":["text-to-image","zero-shot-classification","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"wolof_tts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galsenai/wolof_tts","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","description":"\\n\\t\\n\\t\\t\\n\\t\\tWolof TTS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a Wolof Text To Speech (TTS) dataset collected by Baamtu Datamation as part of the AI4D African language program. \\nThe original dataset is hosted on Zenodo and it contains recordings from two (02) natif Wolof speakers (a male and female voice). Each speaker recored more than 20,000 sentences.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpeaking time:\\n\\t\\n\\n-- Male: 22h 28mn 41s\\n-- Female: 18h 47mn 19s\\n\\nThe text dataset comes from news websites, Wikipedia and self‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/galsenai/wolof_tts.","first_N":5,"first_N_keywords":["text-to-speech","Wolof","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"flickr-megalith-10m-internvl2-multi-caption","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/flickr-megalith-10m-internvl2-multi-caption","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for flickr-megalith-10m-internvl2-multi-caption\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is approximately 57.3 million synthetic captions for the images found in madebyollin/megalith-10m. \\nIt includes the following captions:\\n\\nInternVL2 8B long captions (by CaptionEmporium)\\nInternVL2 8B short captions (by CaptionEmporium)\\nFlorence2 long captions (by aipicasso)\\nFlorence2 short captions (by CaptionEmporium)\\nShareCaptioner long captions (by drawthingsai)\\nShareCaptioner short‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/flickr-megalith-10m-internvl2-multi-caption.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"AI2D-Caption","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhayzala/AI2D-Caption","creator_name":"Abhay Zala","creator_url":"https://huggingface.co/abhayzala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM Planning\\n\\t\\n\\nOfficial implementation of DiagrammerGPT, a novel two-stage text-to-diagram generation framework that leverages the layout guidance capabilities of LLMs to generate more accurate open-domain, open-platform diagrams.\\n  \\nAbhay Zala,\\nHan Lin,\\nJaemin Cho,\\nMohit Bansal\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI2D-Caption Dataset\\n\\t\\n\\nThis dataset is primarily based off the AI2D Dataset (see here).\\nSee Section 4.1 of our paper for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abhayzala/AI2D-Caption.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K<n<10K","arxiv:2310.12128"],"keywords_longer_than_N":true},
	{"name":"Video-Detailed-Caption","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wchai/Video-Detailed-Caption","creator_name":"Wenhao Chai","creator_url":"https://huggingface.co/wchai","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVideo Detailed Caption Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tResources\\n\\t\\n\\n\\nWebsite\\narXiv: Paper\\nGitHub: Code\\nHuggingface: AuroraCap Model\\nHuggingface: VDC Benchmark\\nHuggingface: Trainset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBenchmark Collection and Processing\\n\\t\\n\\nWe building VDC upon Panda-70M, Ego4D, Mixkit, Pixabay, and Pexels. Structured detailed captions construction pipeline. We develop a structured detailed captions construction pipeline to generate extra detailed descriptions from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wchai/Video-Detailed-Caption.","first_N":5,"first_N_keywords":["video-text-to-text","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"blip3-ocr-200m","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salesforce/blip3-ocr-200m","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","description":"\\n\\t\\n\\t\\t\\n\\t\\tBLIP3-OCR-200M Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe BLIP3-OCR-200M dataset is designed to address the limitations of current Vision-Language Models (VLMs) in processing and interpreting text-rich images, such as documents and charts. Traditional image-text datasets often struggle to capture nuanced textual information, which is crucial for tasks requiring complex text comprehension and reasoning. \\n\\n\\t\\n\\t\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nOCR Integration: The dataset incorporates Optical Character‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/blip3-ocr-200m.","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"styles","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rezashkv/styles","creator_name":"Reza Shirkavand","creator_url":"https://huggingface.co/rezashkv","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStyled Image Dataset Generated with FLUX.1-dev and LoRAs from the community\\n\\t\\n\\nAccess the generation scripts here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains 60,000 text-image-pairs. The images are generated by adding trained LoRA weights to the diffusion transformer model black-forest-labs/FLUX.1-dev. The images were created using 6 different style models, with each style having its own set of 10,000 images. Each style includes 10,000 captions sampled from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rezashkv/styles.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"RapBank","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zqning/RapBank","creator_name":"ziqianning","creator_url":"https://huggingface.co/zqning","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RapBank\\n\\t\\n\\n\\n\\nRapBank is the first dataset for rap generation. The rap songs are collected from YouTube, and we provide a meticulously designed pipeline for data processing\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: https://github.com/NZqian/RapBank\\nPaper: https://arxiv.org/abs/2408.15474\\nDemo: https://nzqian.github.io/Freestyler/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStatistics\\n\\t\\n\\nThe RapBank dataset comprises links to a total of 94, 164 songs.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zqning/RapBank.","first_N":5,"first_N_keywords":["text-to-speech","cc-by-sa-4.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"HumanCaption-10M","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHumanCaption-10M\\n\\t\\n\\nHumanCaption-10M: a large, diverse, high-quality dataset of human-related images with natural language descriptions (image to text). The dataset is designed to facilitate research on human-centered tasks. HumanCaption-10M contains approximately 10 million human-related images and their corresponding facial features in natural language descriptions and is the second generation version of FaceCaption-15M \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIllustrations\\n\\t\\n\\n\\nPiplines of constructing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-10M.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"Disney-VideoGeneration-Dataset","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Wild-Heart/Disney-VideoGeneration-Dataset","creator_name":"Wild-Heart","creator_url":"https://huggingface.co/Wild-Heart","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSteamboat Willie - Video Generation Dataset\\n\\t\\n\\n‰∏≠ÊñáÈòÖËØª\\nThis dataset contains 69 videos clipped from Disney's Steamboat Willie.\\n\\nThe length of each video is 6 seconds.\\nThe frame rate of the videos is 30 frames per second.\\nThe video resolution is 640 x 380.\\nAll videos are black and white, not in color.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Format\\n\\t\\n\\n.\\n‚îú‚îÄ‚îÄ README.md\\n‚îú‚îÄ‚îÄ metadata.csv\\n‚îú‚îÄ‚îÄ prompt.txt\\n‚îú‚îÄ‚îÄ videos\\n‚îî‚îÄ‚îÄ videos.txt\\n\\nThe prompt.txt file contains descriptions for each video, each description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Wild-Heart/Disney-VideoGeneration-Dataset.","first_N":5,"first_N_keywords":["text-to-video","image-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"rel_dataset","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m522t/rel_dataset","creator_name":"Mehrshad Taji","creator_url":"https://huggingface.co/m522t","description":"m522t/rel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"danbooru-json","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Disty0/danbooru-json","creator_name":"Disty","creator_url":"https://huggingface.co/Disty0","description":"Saved the JSON responses from Danbooru over a span of a month (September 2024).  \\nStart id: 1End id: 8180000File count: 8141037Folder names: int(id / 10000)File names: id.jsonAccount: None  \\nNote: danbooru-json.tar.gz and danbooru-json.tar is the same file. .gz one is compressed with gzip.  \\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","1M<n<10M","Text"],"keywords_longer_than_N":true},
	{"name":"JA_audio_JA_text_180k_samples","keyword":"text-to-speech","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":"","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Japanese"],"keywords_longer_than_N":true},
	{"name":"JA_audio_JA_text_180k_samples","keyword":"text-to-audio","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":"","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Japanese"],"keywords_longer_than_N":true},
	{"name":"PVIT-3M","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sterzhang/PVIT-3M","creator_name":"Jianshu Zhang","creator_url":"https://huggingface.co/Sterzhang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPVIT-3M\\n\\t\\n\\nThe paper titled \\\"Personalized Visual Instruction Tuning\\\" introduces a novel dataset called PVIT-3M. This dataset is specifically designed for tuning MLLMs in the context of personalized visual instruction tasks. The dataset consists of 3 million image-text pairs that aim to improve MLLMs' abilities to generate responses based on personalized visual inputs, making them more tailored and adaptable to individual user needs and preferences.\\nHere‚Äôs the PVIT-3M statistics:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sterzhang/PVIT-3M.","first_N":5,"first_N_keywords":["visual-question-answering","image-text-to-text","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"diffusion_stage_design_japanese_anime_style","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mintz1104/diffusion_stage_design_japanese_anime_style","creator_name":"Huang","creator_url":"https://huggingface.co/mintz1104","description":"mintz1104/diffusion_stage_design_japanese_anime_style dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","Chinese","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"EGY2K","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahafvii/EGY2K","creator_name":"xx","creator_url":"https://huggingface.co/rahafvii","description":"rahafvii/EGY2K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"EGY2K","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahafvii/EGY2K","creator_name":"xx","creator_url":"https://huggingface.co/rahafvii","description":"rahafvii/EGY2K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"HumanCaption-HQ-311K","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHumanCaption-HQ-311K\\n\\t\\n\\nHumanCaption-HQ-311K: Approximately 311,000 human-related images and their corresponding natural language descriptions.\\nCompared to HumanCaption-10M, this dataset not only includes associated facial language descriptions but also filters out images with higher resolution and employs the powerful visual understanding capabilities of GPT-4V to generate more detailed and accurate text descriptions.\\nThis dataset is used for the second phase of training HumanVLM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/HumanCaption-HQ-311K.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"sft_data","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Share4oReasoning/sft_data","creator_name":"Share4oReasoning","creator_url":"https://huggingface.co/Share4oReasoning","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT4oReasoning Training Data\\n\\t\\n\\nAll dataset and models can be found at Share4oReasoning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContents:\\n\\t\\n\\n\\nSFT instruction: Contains GPT-4o distilled chain-of-thought reasoning data covering wide range of tasks. Together with corresponding short-answer prediction data.\\n\\nImage: contains the zipped image data (see below for details) used for SFT above.\\n\\n[Inference and Instruction for DPO](To be added): uploading now\\nTraining pipeline refer to LLaVA-Reasoner-DPO training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Share4oReasoning/sft_data.","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"thai_handwriting_dataset","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/thai_handwriting_dataset","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThai Handwriting Dataset\\n\\t\\n\\nThis dataset combines two major Thai handwriting datasets:\\n\\nBEST 2019 Thai Handwriting Recognition dataset (train-0000.parquet)\\nThai Handwritten Free Dataset by Wang (train-0001.parquet onwards)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMaintainer\\n\\t\\n\\nkobkrit@iapp.co.th\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBEST 2019 Dataset\\n\\t\\n\\nContains handwritten Thai text images along with their ground truth transcriptions. The images have been processed and standardized for machine‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/thai_handwriting_dataset.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","Thai","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Lappland-the-Decadenza","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland-the-Decadenza","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland-the-Decadenza dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V2","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V2","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImportant notice\\n\\t\\n\\nDifferences between V2 version and the version described in paper:\\n\\nThe V2 version provide audio in 44.1kHz sample rate. (Supersampling)\\nThe V2 versionn removed some samples (~5%) due to the volumn and text aligment issues.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlobe\\n\\t\\n\\nThe full paper can be accessed here: arXiv\\nAn online demo can be accessed here: Github\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbstract\\n\\t\\n\\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V2.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"suno","keyword":"text-to-audio","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/suno","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Suno.ai Music Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata for 659,788 songs generated by artificial intelligence on the suno.com platform, a service that generates music using artificial intelligence. The songs were discovered by search queries with words from the dwyl/english-words word list.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is multilingual with English as the primary language:\\n\\nEnglish (en): Primary language for metadata and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/suno.","first_N":5,"first_N_keywords":["audio-classification","text-to-audio","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"noob-wiki","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Laxhar/noob-wiki","creator_name":"Laxhar Dream Lab","creator_url":"https://huggingface.co/Laxhar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNoob SDXL Wiki\\n\\t\\n\\nThis is the WIKI database for Noob SDXL Models.\\n","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","üá∫üá∏ Region: US","wiki"],"keywords_longer_than_N":false},
	{"name":"anta_women_tts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galsenai/anta_women_tts","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnta Women TTS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a cleaned version of the Wolof TTS dataset by GalsenAI. \\nWe extracted the female voice, denoised it and enhanced it with the Resemble Enhance library. \\nWe also cleaned up the annotations by removing special characters, emojis, Arabic and Russian characters. \\nWe've corrected a few annotation errors, but there are potentially many more to come. \\nSome lines and audios judged not qualitative enough have been removed from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/galsenai/anta_women_tts.","first_N":5,"first_N_keywords":["text-to-speech","Wolof","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ConsisID-preview-Data","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BestWishYsh/ConsisID-preview-Data","creator_name":"YSH","creator_url":"https://huggingface.co/BestWishYsh","description":"\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\ncat videos.tar.part* > videos.tar\\ncat masks.tar.part* > masks.tar\\ntar -xvf bboxes.tar\\ntar -xvf masks.tar\\ntar -xvf videos.tar\\ntar -xvf face_images.tar\\n\\nFor how to process your own data like ConsisID-Preview-Data dataset in the ConsisID paper, please refer to here. (Support Multi-ID)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\n\\nThe current open source data is not the complete set for training ConsisID.\\nThe current 31.9K captions correspond to videos with a single ID, while the remaining‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BestWishYsh/ConsisID-preview-Data.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"open-image-preferences-v1","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/data-is-better-together/open-image-preferences-v1","creator_name":"Data Is Better Together","creator_url":"https://huggingface.co/data-is-better-together","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Image Preferences\\n\\t\\n\\n\\n\\n\\n\\n  \\n      Prompt: Anime-style concept art of a Mayan Quetzalcoatl biomutant, dystopian world, vibrant colors, 4K.\\n      \\n          \\n              \\n              Image 1\\n          \\n          \\n              \\n              Image 2\\n          \\n      \\n  \\n\\n\\n\\n  \\n      Prompt: 8-bit pixel art of a blue knight, green car, and glacier landscape in Norway, fantasy style, colorful and detailed.\\n      \\n          \\n              \\n              Image 1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/data-is-better-together/open-image-preferences-v1.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-231k","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-Speech-231K\\n\\t\\n\\n\\n\\n\\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \\nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-Speech-231K is a comprehensive dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-231K is part of EMOVA-Datasets collection and is used in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"MooreFRCollections","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sawadogosalif/MooreFRCollections","creator_name":"SAWADOGO Salif","creator_url":"https://huggingface.co/sawadogosalif","description":"\\n\\t\\n\\t\\t\\n\\t\\tMooreFRCollections - Jeu de donn√©es bilingue Moor√©-Fran√ßais\\n\\t\\n\\nMooreFRCollections est un projet ouvert d√©di√© √† la cr√©ation d‚Äôun corpus bilingue Moor√©-Fran√ßais pour la recherche et le d√©veloppement de technologies linguistiques adapt√©es au contexte burkinab√©. L‚Äôobjectif est de fournir un outil essentiel pour tester, entra√Æner, et affiner des mod√®les de traduction et d‚Äôautres applications d‚Äôapprentissage automatique. Ce projet met en avant le Moor√©, une langue locale du Burkina Faso.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sawadogosalif/MooreFRCollections.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","translation","text-to-speech","French"],"keywords_longer_than_N":true},
	{"name":"X2I-text-to-image","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yzwang/X2I-text-to-image","creator_name":"Yueze Wang","creator_url":"https://huggingface.co/yzwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX2I Dataset\\n\\t\\n\\n\\nProject Page: https://vectorspacelab.github.io/OmniGen/\\nGithub: https://github.com/VectorSpaceLab/OmniGen\\nPaper: https://arxiv.org/abs/2409.11340\\nModel: https://huggingface.co/Shitao/OmniGen-v1\\n\\nTo achieve robust multi-task processing capabilities, it is essential to train the OmniGen on large-scale and diverse datasets. However, in the field of unified image generation, a readily available dataset has yet to emerge. For this reason, we have curated a large-scale‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yzwang/X2I-text-to-image.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1M<n<10M","arxiv:2409.11340"],"keywords_longer_than_N":true},
	{"name":"X2I-mm-instruction","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yzwang/X2I-mm-instruction","creator_name":"Yueze Wang","creator_url":"https://huggingface.co/yzwang","description":"\\n\\t\\n\\t\\t\\n\\t\\tX2I Dataset\\n\\t\\n\\n\\nProject Page: https://vectorspacelab.github.io/OmniGen/\\nGithub: https://github.com/VectorSpaceLab/OmniGen\\nPaper: https://arxiv.org/abs/2409.11340\\nModel: https://huggingface.co/Shitao/OmniGen-v1\\n\\nTo achieve robust multi-task processing capabilities, it is essential to train the OmniGen on large-scale and diverse datasets. However, in the field of unified image generation, a readily available dataset has yet to emerge. For this reason, we have curated a large-scale‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yzwang/X2I-mm-instruction.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"X2I-subject-driven","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yzwang/X2I-subject-driven","creator_name":"Yueze Wang","creator_url":"https://huggingface.co/yzwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX2I Dataset\\n\\t\\n\\n\\nProject Page: https://vectorspacelab.github.io/OmniGen/\\nGithub: https://github.com/VectorSpaceLab/OmniGen\\nPaper: https://arxiv.org/abs/2409.11340\\nModel: https://huggingface.co/Shitao/OmniGen-v1\\n\\nTo achieve robust multi-task processing capabilities, it is essential to train the OmniGen on large-scale and diverse datasets. However, in the field of unified image generation, a readily available dataset has yet to emerge. For this reason, we have curated a large-scale‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yzwang/X2I-subject-driven.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"mid-space","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mila-ai4h/mid-space","creator_name":"Mila AI4H","creator_url":"https://huggingface.co/mila-ai4h","description":"\\n\\t\\n\\t\\t\\n\\t\\tMID-Space: Aligning Diverse Communities‚Äô Needs to Inclusive Public Spaces\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA new version of the dataset will be released soon, incorporating user identity markers and expanded annotations.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLIVS PAPER \\n\\t\\n\\n\\nClick below to see more:\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe MID-Space dataset is designed to align AI-generated visualizations of urban public spaces with the preferences of diverse and marginalized communities in Montreal. It includes textual prompts, Stable Diffusion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mila-ai4h/mid-space.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"AnyEdit","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bin1117/AnyEdit","creator_name":"QifanYu","creator_url":"https://huggingface.co/Bin1117","description":"\\n\\n\\n\\nCelebrate! AnyEdit resolved the data alignment with the re-uploading process (but the view filter is not working:(, though it has 25 edit types). You can view the validation split for a quick look. You can also refer to anyedit-split dataset to view and download specific data for each editing type.\\n\\n\\t\\t\\n\\t\\tDataset Card for AnyEdit-Dataset\\n\\t\\n\\nInstruction-based image editing aims to modify specific image elements with natural language instructions. However, current models in this domain often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bin1117/AnyEdit.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"cc12m-4mp-realistic","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opendiffusionai/cc12m-4mp-realistic","creator_name":"Open Diffusion AI","creator_url":"https://huggingface.co/opendiffusionai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is a hand-selected subset of our larger attempts to filter the well known CC12M dataset.\\nThis one focuses on large (4 megapixels) images that are real world, high quality images, and the captioning\\nspecifically matches either \\\"A man\\\" or \\\"A woman\\\".\\nNote that I did not have the diskspace/time to go through the ENTIRE set. It was perhaps only from the first 2 million of our\\nCC12M-cleaned subset.\\nIf an effort were made to go through the entire 4mp image set, there‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opendiffusionai/cc12m-4mp-realistic.","first_N":5,"first_N_keywords":["text-to-image","cc-by-sa-4.0","10K - 100K","json","Image"],"keywords_longer_than_N":true},
	{"name":"piper_italiano","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kirys79/piper_italiano","creator_name":"Federico Improta","creator_url":"https://huggingface.co/kirys79","description":"\\n\\t\\n\\t\\t\\n\\t\\tPiper Italiano\\n\\t\\n\\nSto cercando di creare un nuovo checkpoint per PiperTTS in italiano.\\nLa fonte per il traine √® il Multilingual LibriSpeech (MLS) rilasciato sotto licenza Creative Commons\\nQui metter√≤ i dataset estratti dal suddetto blocco dati\\nIl dataset √® nel formato che gradisce PiperTTS come indicato a questo link\\n\\nAurora √® lo speaker 6807\\nLeonardo √® lo speaker 1595 - Probabile voce di Riccardo (modello originale di piper) ma ad una maggiore qualit√†\\n\\n","first_N":5,"first_N_keywords":["text-to-speech","Italian","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"art-museums-pd-440k","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mitsua/art-museums-pd-440k","creator_name":"elanmitsua","creator_url":"https://huggingface.co/Mitsua","description":"\\n\\t\\n\\t\\t\\n\\t\\tArt Museums PD 440K\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is a dataset to train text-to-image or any text and image multimodal models with minimized copyright/licensing concerns.\\nAll images and texts in this dataset are orignally shared under CC0 or public domain, and no pretrained models or any AI models are used to build this dataset except for our ElanMT model to translate English captions to Japanese.\\nElanMT model is trained solely on licensed corpus.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData sources\\n\\t\\n\\nImages and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/art-museums-pd-440k.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"safe-commons-pd-3m","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mitsua/safe-commons-pd-3m","creator_name":"elanmitsua","creator_url":"https://huggingface.co/Mitsua","description":"\\n\\t\\n\\t\\t\\n\\t\\tSafe Commons PD 3M\\n\\t\\n\\n\\nThis is a balanced and safe-to-use public domain / CC0 images dataset.\\nAll images and texts come from Wikimedia Commons and Wikidata with strict filtering.\\nImages license is either Public Domain or CC0 (varies by image).\\nTexts license is either CC0 or CC BY-SA (varies by caption source).\\nNo synthetic data (AI generated images or captions) is in the dataset.\\n\\nTo build this dataset, we tried to avoid any knowledge leaks from existing pre-trained models at the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/safe-commons-pd-3m.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","Japanese","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"open-image-preferences-v1-more-results","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/open-image-preferences-v1-more-results","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\n\\n\\nWe wanted to contribute to the challenge posed by the data-is-better-together community (description below). We collected 170'000 preferences using our API from people all around the world in rougly 3 days (docs.rapidata.ai):\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for image-preferences-results Original\\n\\t\\n\\n\\n\\n\\n\\n  \\n      Prompt: Anime-style concept art of a Mayan Quetzalcoatl biomutant, dystopian world‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/open-image-preferences-v1-more-results.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Preference Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\nThis dataset was collected in ~12 hours using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\nThe data collected in this dataset informs our text-2-video model benchmark. We just started so currently only two models are represented in this set:\\n\\nSora\\nHunyouan\\nPika 2.0\\nRunway ML Alpha\\nLuma Ray 2\\n\\nExplore our latest model rankings on our website.\\nIf you get value from this dataset and would‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences.","first_N":5,"first_N_keywords":["text-to-video","video-classification","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test-HunyuanVideo-anime-images","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/test-HunyuanVideo-anime-images","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTest-HunyuanVideo-Anime-Stills\\n\\t\\n\\nA small dataset of AI-generated anime-themed images designed for general anime text-to-image (T2I) training debug or testing Hunyuan Video. This dataset provides a balanced distribution of subjects and aims to align large pretrained models with anime aesthetics in terms of visual appeal and text faithfulness.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubject Selection\\n\\t\\n\\nThe subject distributions (other than the 50% anime girls) are selected based on the policy outlined in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trojblue/test-HunyuanVideo-anime-images.","first_N":5,"first_N_keywords":["text-to-image","text-to-video","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"test-HunyuanVideo-anime-images","keyword":"text-to-video","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/test-HunyuanVideo-anime-images","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTest-HunyuanVideo-Anime-Stills\\n\\t\\n\\nA small dataset of AI-generated anime-themed images designed for general anime text-to-image (T2I) training debug or testing Hunyuan Video. This dataset provides a balanced distribution of subjects and aims to align large pretrained models with anime aesthetics in terms of visual appeal and text faithfulness.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubject Selection\\n\\t\\n\\nThe subject distributions (other than the 50% anime girls) are selected based on the policy outlined in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trojblue/test-HunyuanVideo-anime-images.","first_N":5,"first_N_keywords":["text-to-image","text-to-video","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"cc3m","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WeiChow/cc3m","creator_name":"zhou wei","creator_url":"https://huggingface.co/WeiChow","description":"This repo is CC3M's unofficial huggingface repo. \\nHowever, for the large picture, we process it as follow and then upload:\\nif pil_image.width > 1024 or pil_image.height > 1024:\\n    pil_image = pil_image.resize((1024, 1024), Image.BICUBIC)\\n\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"test-HunyuanVideo-pixelart-images","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/test-HunyuanVideo-pixelart-images","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttrojblue/test-HunyuanVideo-pixelart-images\\n\\t\\n\\nHey there! üëã Heads up‚Äîthis repository is just a PARTIAL dataset. For the full pixelart-images dataset, make sure to grab both parts:\\n\\nImages Part (this repo)\\nVideo Part\\n\\nThis dataset is a collection of anime-style pixel art images and is perfect for debugging general anime text-to-image (T2I) training or testing Hunyuan Video models. üé®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat's in the Dataset?\\n\\t\\n\\nThis dataset is all about anime-styled pixel art images that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trojblue/test-HunyuanVideo-pixelart-images.","first_N":5,"first_N_keywords":["text-to-image","text-to-video","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"test-HunyuanVideo-pixelart-images","keyword":"text-to-video","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/test-HunyuanVideo-pixelart-images","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttrojblue/test-HunyuanVideo-pixelart-images\\n\\t\\n\\nHey there! üëã Heads up‚Äîthis repository is just a PARTIAL dataset. For the full pixelart-images dataset, make sure to grab both parts:\\n\\nImages Part (this repo)\\nVideo Part\\n\\nThis dataset is a collection of anime-style pixel art images and is perfect for debugging general anime text-to-image (T2I) training or testing Hunyuan Video models. üé®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat's in the Dataset?\\n\\t\\n\\nThis dataset is all about anime-styled pixel art images that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trojblue/test-HunyuanVideo-pixelart-images.","first_N":5,"first_N_keywords":["text-to-image","text-to-video","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"test-HunyuanVideo-pixelart-videos","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/test-HunyuanVideo-pixelart-videos","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttrojblue/test-HunyuanVideo-pixelart-images\\n\\t\\n\\nüëã Heads up‚Äîthis repository is just a PARTIAL dataset. For the full pixelart-images dataset, make sure to grab both parts:\\n\\nImages Part \\nVideo Part (this repo)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat's in the Dataset?\\n\\t\\n\\nThis dataset is all about anime-styled pixel art images that have been carefully selected to make your models shine. Here‚Äôs what makes these images special:\\n\\nRich in detail: Pixelated, yes‚Äîbut still full of life and not overly simplified.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trojblue/test-HunyuanVideo-pixelart-videos.","first_N":5,"first_N_keywords":["text-to-image","text-to-video","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"test-HunyuanVideo-pixelart-videos","keyword":"text-to-video","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/test-HunyuanVideo-pixelart-videos","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttrojblue/test-HunyuanVideo-pixelart-images\\n\\t\\n\\nüëã Heads up‚Äîthis repository is just a PARTIAL dataset. For the full pixelart-images dataset, make sure to grab both parts:\\n\\nImages Part \\nVideo Part (this repo)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat's in the Dataset?\\n\\t\\n\\nThis dataset is all about anime-styled pixel art images that have been carefully selected to make your models shine. Here‚Äôs what makes these images special:\\n\\nRich in detail: Pixelated, yes‚Äîbut still full of life and not overly simplified.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trojblue/test-HunyuanVideo-pixelart-videos.","first_N":5,"first_N_keywords":["text-to-image","text-to-video","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"dpo_data","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Share4oReasoning/dpo_data","creator_name":"Share4oReasoning","creator_url":"https://huggingface.co/Share4oReasoning","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT4oReasoning Training Data DPO\\n\\t\\n\\nAll dataset and models can be found at Share4oReasoning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContents:\\n\\t\\n\\n\\nDPO_preview: Contains model generated CoT judged my outcome reward.\\n\\nImage use same in sft repo: contains the zipped image data (see below for details) used for SFT above.\\n\\n[Inference and Instruction for DPO](To be added): uploading now\\nTraining pipeline refer to LLaVA-Reasoner-DPO training TODO separate readme for setup and train.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSet up:\\n\\t\\n\\ngit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Share4oReasoning/dpo_data.","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"klingai","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/klingai","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KLING AI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 12,782 AI-generated media items (images and videos) created using KLING AI's generative tools. The content includes metadata and original files for various AI generations, encompassing both still images and motion videos created through text-to-image and image-to-video transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en), with prompts and metadata in English.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/klingai.","first_N":5,"first_N_keywords":["text-to-image","image-to-video","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OVO-Bench","keyword":"video-text-to-text","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JoeLeelyf/OVO-Bench","creator_name":"Yifei Li","creator_url":"https://huggingface.co/JoeLeelyf","description":"This dataset was presented in the paper OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?.\\nProject page: https://joeleelyf.github.io/OVO-Bench/\\nCode: https://github.com/JoeLeelyf/OVO-Bench\\nThe repository contains the following file information:\\n","first_N":5,"first_N_keywords":["video-text-to-text","English","cc-by-sa-4.0","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM-eval","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLayoutSAM-eval Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nLayoutSAM-Eval is a comprehensive benchmark for evaluating the quality of Layout-to-Image (L2I) generation models. This benchmark assesses L2I generation quality from two perspectives: region-wise quality (spatial and attribute accuracy) and global-wise quality (visual quality and prompt following). It employs the VLM‚Äôs visual question answering to evaluate spatial and attribute adherence, and utilizes various metrics including IR‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM-eval.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"LayoutSAM","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuiZhang0812/LayoutSAM","creator_name":"HuiZhang","creator_url":"https://huggingface.co/HuiZhang0812","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLayoutSAM Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe LayoutSAM dataset is a large-scale layout dataset derived from the SAM dataset, containing 2.7 million image-text pairs and 10.7 million entities. Each entity is annotated with a spatial position (i.e., bounding box) and a textual description.\\nTraditional layout datasets often exhibit a closed-set and coarse-grained nature, which may limit the model's ability to generate complex attributes such as color, shape, and texture.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuiZhang0812/LayoutSAM.","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MiSide-Japanese","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AkitoP/MiSide-Japanese","creator_name":"L","creator_url":"https://huggingface.co/AkitoP","description":"AkitoP/MiSide-Japanese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Japanese","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"text-2-image-Rich-Human-Feedback","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-image-Rich-Human-Feedback","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\n\\n\\nBuilding upon Google's research Rich Human Feedback for Text-to-Image Generation we have collected over 1.5 million responses from 152'684 individual humans using Rapidata via the Python API. Collection took roughly 5 days. \\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nWe asked humans to evaluate AI-generated images in style, coherence and prompt alignment. For images that contained flaws, participants were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-image-Rich-Human-Feedback.","first_N":5,"first_N_keywords":["text-to-image","text-classification","image-classification","image-to-text","image-segmentation"],"keywords_longer_than_N":true},
	{"name":"EmbodiedEval","keyword":"video-text-to-text","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbodiedEval/EmbodiedEval","creator_name":"EmbodiedEval","creator_url":"https://huggingface.co/EmbodiedEval","description":"This repository contains the dataset of the paper EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents.\\nGithub repository: https://github.com/thunlp/EmbodiedEval\\nProject Page: https://embodiedeval.github.io/\\n","first_N":5,"first_N_keywords":["robotics","video-text-to-text","English","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DualMath-1.1M","keyword":"image-text-to-text","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/URSA-MATH/DualMath-1.1M","creator_name":"URSA-MATH","creator_url":"https://huggingface.co/URSA-MATH","description":"\\n\\t\\n\\t\\t\\n\\t\\tDualMath-1.1M\\n\\t\\n\\nImage data can be downloaded from the following address:\\n\\nMAVIS: https://github.com/ZrrSkywalker/MAVIS, https://drive.google.com/drive/folders/1LGd2JCVHi1Y6IQ7l-5erZ4QRGC4L7Nol.\\nMultimath: https://huggingface.co/datasets/pengshuai-rin/multimath-300k.\\nGeo170k: https://huggingface.co/datasets/Luckyjhg/Geo170K.\\nVarsityTutors: https://huggingface.co/datasets/Math-PUMA/Math-PUMA_Data_Stage2. \\nMathV360K: https://huggingface.co/datasets/Zhiqiang007/MathV360K.\\n\\nThe image data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/URSA-MATH/DualMath-1.1M.","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","Chinese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"FaceCaptionHQ-4M","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M","creator_name":"ddw2AIGROUP-CQUPT","creator_url":"https://huggingface.co/OpenFace-CQUPT","description":"\\n\\t\\n\\t\\t\\n\\t\\tFaceCaptionHQ-4M\\n\\t\\n\\nFaceCaptionHQ-4M contains about 4M facial image-text pairs that cleaned from FaceCaption-15M .  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFigure.1 Illustrations\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFigure.2 Piplines of constructing FaceCaptionHQ-4M. The detailed method can be referred to Face-MakeUp.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNews and Update üî•üî•üî•\\n\\t\\n\\n\\nJan.11, 2025.   ü§óFaceCaptionHQ-4M, is released!üëèüëèüëè\\nJan.11, 2025.   ü§óFaceMaker-V0, is released!üëèüëèüëè\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tü§ó How to Use\\n\\t\\n\\nWe provide a few lines of code to download‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaptionHQ-4M.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"VisualWebInstruct-Recall","keyword":"image-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct-Recall","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is the dataset recalled from Google Search from the seed images.\\n\\n\\t\\n\\t\\t\\n\\t\\tLinks\\n\\t\\n\\nGithub|\\nPaper|\\nWebsite\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{visualwebinstruct,\\n    title={VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search},\\n    author = {Jia, Yiming and Li, Jiachen and Yue, Xiang and Li, Bo and Nie, Ping and Zou, Kai and Chen, Wenhu},\\n    journal={arXiv preprint arXiv:2503.10582},\\n    year={2025}\\n}\\n\\n","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"bam-asr-all","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/bam-asr-all","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Bambara-ASR-All Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \\nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \\nData sources include all publicly available collections of audio with Bambara transcriptions, organized for accessibility and usability.\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Puck-Voice","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Puck-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Puck-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Aoede-Voice","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Aoede-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Aoede-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Tarsier2-Recap-585K","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omni-research/Tarsier2-Recap-585K","creator_name":"omni-research","creator_url":"https://huggingface.co/omni-research","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Tarsier2-Recap-585K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\n‚ú®Tarsier2-Recap-585K‚ú® consists of 585K distinct video clips, lasting for 1972 hours in total, from open-source datasets (e.g. VATEX, TGIF, LSMDC, etc.) and each one with a detailed video description annotated by Tarsier2-7B, which beats GPT-4o in generating detailed and accurate video descriptions for video clips of 5~20 seconds (See the DREAM-1K Leaderboard). Experiments demonstrate its effectiveness in enhancing the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omni-research/Tarsier2-Recap-585K.","first_N":5,"first_N_keywords":["video-text-to-text","English","apache-2.0","Video","arxiv:2501.07888"],"keywords_longer_than_N":true},
	{"name":"awesome-text2video-prompts","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/awesome-text2video-prompts","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Preference Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset contains prompts for video generation for 14 different categories. They were collected with a combination of manual prompting and ChatGPT 4o. We provide one example sora video generation for each video.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCategories and Comments\\n\\t\\n\\n\\nObject Interactions Scenes: Basic scenes with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/awesome-text2video-prompts.","first_N":5,"first_N_keywords":["text-to-video","video-classification","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"kokoro-82M-voices","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ecyht2/kokoro-82M-voices","creator_name":"ecyht2","creator_url":"https://huggingface.co/ecyht2","description":"\\n\\t\\n\\t\\t\\n\\t\\tKokoro-82M Voices\\n\\t\\n\\nThis dataset contains all the voices available in hexgrad/Kokoro-82M.\\nThis dataset provides the voices in 3 different formats.\\n\\nIndividual voices embeddings in different JSON file\\nSingle JSON which contains all the voices in a JSON object.\\nParquet format for usage via datasets\\nThe voices name is the same as the .pth file names shown below.\\n\\nvoices = [\\n    \\\"af\\\",\\n    \\\"af_bella\\\",\\n    \\\"af_nicole\\\",\\n    \\\"af_sarah\\\",\\n    \\\"af_sky\\\",\\n    \\\"am_adam\\\",\\n    \\\"am_michael\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ecyht2/kokoro-82M-voices.","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"gemini-flash-2.0-speech","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"\\n\\t\\n\\t\\t\\n\\t\\tüéôÔ∏è Gemini Flash 2.0 Speech Dataset\\n\\t\\n\\n\\nThis is a high quality synthetic speech dataset generated by Gemini Flash 2.0 via the Multimodel Live API. It contains speech from 2 speakers - Puck (Male) and Kore (Female) in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t„ÄΩÔ∏è Stats\\n\\t\\n\\nTotal number of audio files: 47,256*2 = 94512Total duration: 1023527.20 seconds (284.31 hours)   \\nAverage duration: 10.83 seconds   \\nShortest file: 0.6 secondsLongest file: 92.12 seconds   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüß© Data Composition\\n\\t\\n\\nThe text in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bird-critic-1.0-flash-exp","keyword":"text-to-sql","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/birdsql/bird-critic-1.0-flash-exp","creator_name":"The BIRD Team","creator_url":"https://huggingface.co/birdsql","description":"\\n\\t\\n\\t\\t\\n\\t\\tBIRD-CRITIC-1.0-Flash\\n\\t\\n\\nBIRD-Critic is the first SQL debugging benchmark designed to answer a critical question:\\nCan large language models (LLMs) fix user issues in real-world database applications? Each task in BIRD-CRITIC has been verified by human experts on the following dimensions:\\n\\nReproduction of errors on BIRD env to prevent data leakage.\\nCarefully curate test case functions for each task specifically. \\nSoft EX: This metric can evaluate SELECT-ONLY tasks.\\nSoft EX + Parsing:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/birdsql/bird-critic-1.0-flash-exp.","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"jacob-common-voice-19-zh-TW-curated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jacob-common-voice-19-zh-TW-curated","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/jacob-common-voice-19-zh-TW-curated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chinese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\\n\\t\\n\\t\\t\\n\\t\\tHailuo AI Voices Dataset üé§\\n\\t\\n\\n\\n\\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìä Dataset Overview\\n\\t\\n\\nThe dataset provides a comprehensive collection of voice samples with the following features:\\n\\n\\t\\n\\t\\t\\nFeature\\nDescription\\n\\n\\n\\t\\t\\nAudio Files\\nHigh-quality WAV format recordings\\n\\n\\nTranscription\\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\\n\\t\\n\\t\\t\\n\\t\\tHailuo AI Voices Dataset üé§\\n\\t\\n\\n\\n\\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìä Dataset Overview\\n\\t\\n\\nThe dataset provides a comprehensive collection of voice samples with the following features:\\n\\n\\t\\n\\t\\t\\nFeature\\nDescription\\n\\n\\n\\t\\t\\nAudio Files\\nHigh-quality WAV format recordings\\n\\n\\nTranscription\\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"jl-speech","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jl-speech","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\\n\\t\\n\\t\\t\\n\\t\\tJL Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nJL Speech is a male voice version of the LJ Speech dataset. It contains 13,100 short audio clips of a single speaker reading passages from books. The total audio duration is approximately 24 hours, with audio quality improved to 48 kHz sampling rate.\\nThis dataset is licensed under the CC-BY-4.0 License.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCreation\\n\\t\\n\\nThe JL Speech dataset was created by converting the original LJ Speech dataset to a male‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/jl-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jl-speech","keyword":"text-to-audio","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jl-speech","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\\n\\t\\n\\t\\t\\n\\t\\tJL Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nJL Speech is a male voice version of the LJ Speech dataset. It contains 13,100 short audio clips of a single speaker reading passages from books. The total audio duration is approximately 24 hours, with audio quality improved to 48 kHz sampling rate.\\nThis dataset is licensed under the CC-BY-4.0 License.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCreation\\n\\t\\n\\nThe JL Speech dataset was created by converting the original LJ Speech dataset to a male‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/jl-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PhysBench","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/USC-GVL/PhysBench","creator_name":"USC Geomtry, Vision, and Learning Lab","creator_url":"https://huggingface.co/USC-GVL","description":"\\n  PhysBench \\n\\n\\n    üåê Homepage | ü§ó Dataset | üìë Paper | üíª Code | üî∫ EvalAI\\n\\n\\nThis repo contains evaluation code for the paper \\\"PhysBench: Benchmarking and Enhancing VLMs for Physical World Understanding\\\"\\nIf you like our project, please give us a star ‚≠ê on GitHub for latest update.\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nUnderstanding the physical world is a fundamental challenge in embodied AI, critical for enabling agents to perform complex tasks and operate safely in real-world environments. While‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/USC-GVL/PhysBench.","first_N":5,"first_N_keywords":["video-text-to-text","English","apache-2.0","arxiv:2501.16411","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"LongVA-TPO-10k","keyword":"video-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ruili0/LongVA-TPO-10k","creator_name":"Rui Li","creator_url":"https://huggingface.co/ruili0","description":"\\n \\n \\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\t10kTemporal Preference Optimization Dataset for LongVA\\n\\t\\n\\nLongVA-TPO-10k, introduced by paper Temporal Preference Optimization for Long-form Video Understanding\\n","first_N":5,"first_N_keywords":["video-text-to-text","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-style-likert-scoring","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-style-likert-scoring","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Preference Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~6000 human evaluators were asked to rate AI-generated videos based on their visual appeal, without seeing the prompts used to generate them. The specific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-style-likert-scoring.","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"emojis","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/emojis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Emojis.com\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata for 3,264,372 AI-generated emoji images from Emojis.com. Each entry represents an emoji with associated metadata including prompt text and image URLs.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nslug: Unique identifier for the emoji (string)\\nid: Internal ID (string) \\nnoBackgroundUrl:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/emojis.","first_N":5,"first_N_keywords":["text-to-image","image-classification","multi-class-image-classification","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Punjabi","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Punjabi","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\\n\\t\\n\\t\\t\\n\\t\\tPunjabi Indic TTS Dataset\\n\\t\\n\\nThis dataset is derived from the Indic TTS Database project, specifically using the Punjabi monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nLanguage: Punjabi\\nTotal Duration: ~20 hours (Male: 10 hours, Female: 10 hours)\\nAudio Format: WAV\\nSampling Rate: 48000Hz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Punjabi.","first_N":5,"first_N_keywords":["text-to-speech","pb","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"synthetic-emotions","keyword":"text-to-video","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aadityaubhat/synthetic-emotions","creator_name":"Aaditya Bhat","creator_url":"https://huggingface.co/aadityaubhat","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthetic Emotions Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nSynthetic Emotions is a video dataset of AI-generated human emotions created using OpenAI Sora. It features short (5-sec, 480p, 9:16) videos depicting diverse individuals expressing emotions like happiness, sadness, anger, fear, surprise, and more.\\nThis dataset is ideal for emotion recognition, facial expression analysis, affective computing, and AI-human interaction research.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nTotal Videos: 100\\nVideo Format:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aadityaubhat/synthetic-emotions.","first_N":5,"first_N_keywords":["video-classification","text-to-video","mit","< 1K","Text"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-alignment-likert-scoring","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-alignment-likert-scoring","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Prompt Alignment Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~6000 human evaluators were asked to evaluate AI-generated videos based on how well the generated video matches the prompt. The specific question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-alignment-likert-scoring.","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-physics-likert-scoring","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-physics-likert-scoring","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Physics Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~6000 human evaluators were asked to rate AI-generated videos based on if gravity and colisions make sense, without seeing the prompts used to generate them.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-physics-likert-scoring.","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"EgoNormia","keyword":"video-text-to-text","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/open-social-world/EgoNormia","creator_name":"Open Social World","creator_url":"https://huggingface.co/open-social-world","description":"\\n                EgoNormia: Benchmarking Physical Social Norm Understanding      \\n\\n    MohammadHossein Rezaei*,¬†\\n    Yicheng Fu*,¬†\\n    Phil Cuvin*,¬†\\n    Caleb Ziems,¬†\\n    Yanzhe Zhang,¬†\\n    Hao Zhu,¬†\\n    Diyi Yang,¬†\\n\\n\\n\\n    üåéWebsite |\\n    ü§ó Dataset |\\n    üìÑ arXiv |\\n    üìÑ HF Paper\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEgoNormia\\n\\t\\n\\nEgoNormia is a challenging QA benchmark that tests VLMs' ability to reason over norms in context.\\nThe datset consists of 1,853 physically grounded egocentric \\ninteraction clips from Ego4D‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/open-social-world/EgoNormia.","first_N":5,"first_N_keywords":["visual-question-answering","video-text-to-text","question-answering","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"laion-coco-13m-molmo-d-7b","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaptionEmporium/laion-coco-13m-molmo-d-7b","creator_name":"Caption Emporium","creator_url":"https://huggingface.co/CaptionEmporium","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for laion-coco-13m-molmo-d-7b\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is 41,409,699 new synthetic captions for the 13,803,233 images found in laion/laion-coco. It includes the original captions from that repository as well as new captions. The dataset was filtered to images >= 512px on the short edge.\\nThe long captions were produced using allenai/Molmo-7B-D-0924. Medium and short captions were produced from these captions using allenai/Llama-3.1-Tulu-3-8B-DPO. The dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaptionEmporium/laion-coco-13m-molmo-d-7b.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","other","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-luma-ray2","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-luma-ray2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Luma Ray2 Human Preference\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~45'000 human annotations were collected to evaluate Luma's Ray 2 video generation model on our benchmark. The up to date benchmark can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-luma-ray2.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-human-preferences-luma-ray2","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-luma-ray2","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Luma Ray2 Human Preference\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~45'000 human annotations were collected to evaluate Luma's Ray 2 video generation model on our benchmark. The up to date benchmark can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-human-preferences-luma-ray2.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-aligned-words","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-aligned-words","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Word for Word Alignment Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~1500 human evaluators were asked to evaluate AI-generated videos based on what part of the prompt did not align the video. The specific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-aligned-words.","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sora-video-generation-time-flow","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/sora-video-generation-time-flow","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Time flow Annotation Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~1 hour using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~3700 human evaluators were asked to evaluate AI-generated videos based on how time flows in the video. The specific question posed was: \\\"How‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/sora-video-generation-time-flow.","first_N":5,"first_N_keywords":["video-classification","text-to-video","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"text-2-video-Rich-Human-Feedback","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-Rich-Human-Feedback","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Rich Human Feedback Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~4 hours total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~22'000 human annotations were collected to evaluate AI-generated videos (using Sora) in 5 different categories. \\n\\nPrompt - Video‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-Rich-Human-Feedback.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"text-2-video-Rich-Human-Feedback","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rapidata/text-2-video-Rich-Human-Feedback","creator_name":"Rapidata","creator_url":"https://huggingface.co/Rapidata","description":"\\n\\t\\n\\t\\t\\n\\t\\tRapidata Video Generation Rich Human Feedback Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIf you get value from this dataset and would like to see more in the future, please consider liking it.\\n\\n\\nThis dataset was collected in ~4 hours total using the Rapidata Python API, accessible to anyone and ideal for large scale data annotation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nIn this dataset, ~22'000 human annotations were collected to evaluate AI-generated videos (using Sora) in 5 different categories. \\n\\nPrompt - Video‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/text-2-video-Rich-Human-Feedback.","first_N":5,"first_N_keywords":["video-classification","text-to-video","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"odoo-sql-query-dataset","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VPCSinfo/odoo-sql-query-dataset","creator_name":"Vinay Rana","creator_url":"https://huggingface.co/VPCSinfo","description":"\\n\\t\\n\\t\\t\\n\\t\\tOdoo SQL Query Dataset\\n\\t\\n\\nThis dataset contains natural language to SQL query pairs specifically for Odoo 17.0 Community Edition. It's designed to help train and fine-tune language models for generating accurate SQL queries for Odoo databases.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset consists of 6815 carefully curated examples of natural language questions paired with their corresponding SQL queries for Odoo databases. Each example includes detailed instructions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VPCSinfo/odoo-sql-query-dataset.","first_N":5,"first_N_keywords":["text-generation","language-modeling","text-simplification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"fastcup-highlights","keyword":"video-text-to-text","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/fastcup-highlights","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Fastcup.net Highlights\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 85,488 video clips from the gaming platform Fastcup.net, with 78,143 clips from Counter-Strike 2 and 7,345 clips from Counter-Strike: Global Offensive. The clips showcase gameplay highlights and include detailed metadata such as player statistics, weapon information, and engagement metrics. The total size of raw video content is approximately 34 TB.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fastcup-highlights.","first_N":5,"first_N_keywords":["video-classification","video-text-to-text","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"TextAtlas5M","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CSU-JPG/TextAtlas5M","creator_name":"Jinpeng Group","creator_url":"https://huggingface.co/CSU-JPG","description":"\\n\\t\\n\\t\\t\\n\\t\\tTextAtlas5M\\n\\t\\n\\nThis dataset is a training set for TextAtlas.\\nPaper: https://huggingface.co/papers/2502.07870\\n(All the data in this repo is being uploaded, will meet you soon. :>)\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset subsets\\n\\t\\n\\nSubsets in this dataset are CleanTextSynth, PPT2Details, PPT2Structured,LongWordsSubset-A,LongWordsSubset-M,Cover Book,Paper2Text,TextVisionBlend,StyledTextSynth and TextScenesHQ. The dataset features are as follows: \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Features\\n\\t\\n\\n\\nimage (img): The GT image.\\nannotation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CSU-JPG/TextAtlas5M.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"TextAtlasEval","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CSU-JPG/TextAtlasEval","creator_name":"Jinpeng Group","creator_url":"https://huggingface.co/CSU-JPG","description":"This dataset is a evaluation set for TextAtlas, described in the paper TextAtlas5M: A Large-scale Dataset for Dense Text Image Generation.\\n\\n\\t\\n\\t\\t\\n\\t\\tEvaluation\\n\\t\\n\\nOur evaluation scripts are now available on github !\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset subsets\\n\\t\\n\\nSubsets in this dataset are styledtextsynth, textsceneshq and textvisionblend. The dataset features are as follows: \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Features\\n\\t\\n\\n\\nimage (img): The GT image.\\nannotation (string): The input prompt used to generate the text.\\nimage_path‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CSU-JPG/TextAtlasEval.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\\n\\t\\n\\t\\t\\n\\t\\tHailuo AI Jokes Dataset üé§\\n\\t\\n\\n\\n\\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüéôÔ∏è Dataset Content\\n\\t\\n\\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\\n\\t\\n\\t\\t\\n\\t\\tHailuo AI Jokes Dataset üé§\\n\\t\\n\\n\\n\\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüéôÔ∏è Dataset Content\\n\\t\\n\\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"Audio-FLAN-Dataset","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tAudio-FLAN Dataset (Paper)\\n\\t\\n\\n(the FULL audio files and jsonl files are still updating)\\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \\n\\n\\t\\n\\t\\t\\n\\t\\t1. Dataset Structure\\n\\t\\n\\nThe Audio-FLAN-Dataset has the following directory structure:\\nAudio-FLAN-Dataset/\\n‚îú‚îÄ‚îÄ audio_files/\\n‚îÇ   ‚îú‚îÄ‚îÄ audio/\\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 177_TAU_Urban_Acoustic_Scenes_2022/\\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 179_Audioset_for_Audio_Inpainting/\\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\\n‚îÇ   ‚îú‚îÄ‚îÄ music/\\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Audio-FLAN-Dataset","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tAudio-FLAN Dataset (Paper)\\n\\t\\n\\n(the FULL audio files and jsonl files are still updating)\\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \\n\\n\\t\\n\\t\\t\\n\\t\\t1. Dataset Structure\\n\\t\\n\\nThe Audio-FLAN-Dataset has the following directory structure:\\nAudio-FLAN-Dataset/\\n‚îú‚îÄ‚îÄ audio_files/\\n‚îÇ   ‚îú‚îÄ‚îÄ audio/\\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 177_TAU_Urban_Acoustic_Scenes_2022/\\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 179_Audioset_for_Audio_Inpainting/\\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\\n‚îÇ   ‚îú‚îÄ‚îÄ music/\\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"qirimtatar-tts","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/qirimtatar-tts","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":" \\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOpen Source Crimean Tatar Text-to-Speech datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tVoices\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMale\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tAbibullah\\n\\t\\n\\n\\nQuality: high\\nDuration: 2h + 50m\\nAudio formats: OPUS\\nFrequency: 48000 Hz\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tArslan\\n\\t\\n\\n\\nQuality: high\\nDuration: 40m + 40m\\nAudio formats: OPUS\\nFrequency: 48000 Hz\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFemale\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSevil\\n\\t\\n\\n\\nQuality:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/qirimtatar-tts.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"DeepFashion-MultiModal-Parts2Whole","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LIAGM/DeepFashion-MultiModal-Parts2Whole","creator_name":"Yu-Ju Tsai","creator_url":"https://huggingface.co/LIAGM","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepFashion MultiModal Parts2Whole\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis human image dataset comprising about 41,500 reference-target pairs. Each pair in this dataset includes multiple reference images, which encompass human pose images (e.g., OpenPose, Human Parsing, DensePose), various aspects of human appearance (e.g., hair, face, clothes, shoes) with their short textual labels, and a target image featuring the same individual (ID) in the same outfit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIAGM/DeepFashion-MultiModal-Parts2Whole.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Lux-Japanese-Speech-Corpus","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus","creator_name":"KohnoseLami","creator_url":"https://huggingface.co/Lami","description":"\\n\\t\\n\\t\\t\\n\\t\\tLux Japanese Speech Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tÊ¶ÇË¶Å\\n\\t\\n\\nLux Japanese Speech Corpus „ÅØ„ÄÅ„Ç™„É™„Ç∏„Éä„É´„Ç≠„É£„É©„ÇØ„Çø„Éº„ÄåLux („É´„ÇØ„Çπ)„Äç„Å´„Çà„ÇãÊó•Êú¨Ë™û„ÅÆ„ÉÜ„Ç≠„Çπ„ÉàË™≠„Åø‰∏ä„ÅíÈü≥Â£∞„ÇíÂèéÈå≤„Åó„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ2Á®ÆÈ°û„ÅÆÈü≥Â£∞„Éï„Ç°„Ç§„É´„ÅßÊßãÊàê„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\nraw: Âä†Â∑•Ââç„ÅÆ 96kHz/16bit „ÅÆ WAV „Éï„Ç°„Ç§„É´\\ncleaned: „Éé„Ç§„Ç∫Èô§Âéª„Å™„Å©„ÅÆÂá¶ÁêÜ„ÇíÊñΩ„Åó„Åü 96kHz/16bit „ÅÆ WAV „Éï„Ç°„Ç§„É´\\n\\nÂêÑÈü≥Â£∞„Éï„Ç°„Ç§„É´„Å´ÂØæÂøú„Åô„Çã„Éà„É©„É≥„Çπ„ÇØ„É™„Éó„Ç∑„Éß„É≥ÔºàË™≠„Åø‰∏ä„Åí„ÅüÊñáÁ´†Ôºâ„ÅØ„ÄÅmetadata.csv „Å´Ë®òÈå≤„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Éá„Éº„Çø„Çª„ÉÉ„ÉàÂÖ®‰Ωì„ÅÆ„É°„ÇøÊÉÖÂ†±„ÅØ dataset_infos.json „ÅßÁÆ°ÁêÜ„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\t„Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÈÄ†\\n\\t\\n\\n‰ª•‰∏ã„ÅØ„ÄÅ„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅÆÊé®Â•®„Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÈÄ†„ÅÆ‰æã„Åß„Åô„ÄÇ\\nLux-Japanese-Speech-Corpus/\\n‚îú‚îÄ‚îÄ .gitattributes           # Git„ÅÆ„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„Éï„Ç°„Ç§„É´\\n‚îú‚îÄ‚îÄ README.md‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-4.0","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"ViDoSeek","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/autumncc/ViDoSeek","creator_name":"QiuchenWang","creator_url":"https://huggingface.co/autumncc","description":"\\n\\t\\n\\t\\t\\n\\t\\tüöÄOverview\\n\\t\\n\\nThis is the Repo for ViDoSeek, a benchmark specifically designed for visually rich document retrieval-reason-answer, fully suited for evaluation of RAG within large document corpus. \\n\\nThe paper is available at https://arxiv.org/abs/2502.18017.\\nViDoRAG Project: https://github.com/Alibaba-NLP/ViDoRAG\\n\\nViDoSeek sets itself apart with its heightened difficulty level, attributed to the multi-document context and the intricate nature of its content types, particularly the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/autumncc/ViDoSeek.","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","apache-2.0","arxiv:2502.18017"],"keywords_longer_than_N":true},
	{"name":"StoryFrames","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ingoziegler/StoryFrames","creator_name":"Ingo Ziegler","creator_url":"https://huggingface.co/ingoziegler","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe StoryFrames Dataset\\n\\t\\n\\nStoryFrames is a human-annotated dataset created to enhance a model's capability of understanding and reasoning over sequences of images.\\nIt is specifically designed for tasks like generating a description for the next scene in a story based on previous visual and textual information.\\nThe dataset repurposes the StoryBench dataset, a video dataset originally designed to predict future frames of a video.\\nStoryFrames subsamples frames from those videos and pairs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ingoziegler/StoryFrames.","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","text-to-image","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"HAIC","keyword":"video-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KuaishouHAIC/HAIC","creator_name":"KuaishouHAIC","creator_url":"https://huggingface.co/KuaishouHAIC","description":"\\n\\t\\n\\t\\t\\n\\t\\tHAIC: Human Action and Interaction Comprehension Dataset\\n\\t\\n\\nFrom the paper: \\\"HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models\\\"\\nRead the Paper\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nHAICBench is a comprehensive video dataset featuring manually annotated, fine-grained human captions that features:\\n\\nMultiple Human Subjects: Captions detail interactions and activities involving more than one person, capturing the complexity of human‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KuaishouHAIC/HAIC.","first_N":5,"first_N_keywords":["video-text-to-text","English","Chinese","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"VideoUFO","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VideoUFO/VideoUFO","creator_name":"VideoUFO","creator_url":"https://huggingface.co/VideoUFO","description":"\\n\\t\\n\\t\\t\\n\\t\\tNews\\n\\t\\n\\n‚ú® Ranked Top 1 in the Hugging Face Dataset Trending List for text-to-video generation on March 7, 2025.\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the dataset proposed in our paper VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation\\nVideoUFO is the first dataset curated in alignment with real-world users‚Äô focused topics for text-to-video generation. Specifically, the dataset comprises over 1.09 million video clips spanning 1,291 topics. Here, we select the top 20 most‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VideoUFO/VideoUFO.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"open-sora-pexels-45k","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpcai-tech/open-sora-pexels-45k","creator_name":"HPC-AI Technology","creator_url":"https://huggingface.co/hpcai-tech","description":"\\n\\t\\n\\t\\t\\n\\t\\topen-sora-pexels-45k\\n\\t\\n\\nThis dataset contains 45k high-quality videos from Pexels. The videos are filtered out from about 400K videos based on different kinds of scores.\\nPexels.com is a free stock photo and video platform that provides high-quality, royalty-free images and videos for personal and commercial use. All content on Pexels is licensed under the Pexels License, allowing users to download, modify, and use the media without attribution or copyright concerns.\\nThere are three csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hpcai-tech/open-sora-pexels-45k.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"gretel-synthetic-text-to-sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/gretel-synthetic-text-to-sql","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\tFork of gretelai/synthetic_text_to_sql\\n\\t\\n\\nThe gretelai/synthetic_text_to_sql dataset is a large, Apache 2.0 licensed, synthetic Text-to-SQL dataset consisting of 105,851 high-quality records across 100 diverse domains, designed for training language models. It includes comprehensive SQL tasks with varying complexities, database contexts, natural language explanations, and contextual tags, outperforming existing datasets in SQL correctness and standards compliance.\\n","first_N":5,"first_N_keywords":["question-answering","table-question-answering","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Corinth_dataset","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OlameMend/Corinth_dataset","creator_name":"leo","creator_url":"https://huggingface.co/OlameMend","description":"OlameMend/Corinth_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"danbooru2024-captions-1ktar","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/danbooru2024-captions-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\\n\\t\\n\\t\\t\\n\\t\\tDanbooru 2024 captions only in 1k tar\\n\\t\\n\\n\\nRaw captions jointed by 7.62M unpublished extended dataset from KBlueLeaf/danbooru2023-metadata-database and 0.48M generated dataset via Minthy/ToriiGate-v0.4-7B in exl2-8bpw mode. There are 8.13M in total.\\n\\npython convert_meta_to_tar.py\\nReading source JSON\\nKeys count: 8136011\\nmax id: 8360499\\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2024-captions-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"ShahNegar","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sadrasabouri/ShahNegar","creator_name":"Sadra Sabouri","creator_url":"https://huggingface.co/sadrasabouri","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShahNegar (A Plotted version of The Shahnameh)\\n\\t\\n\\nThis dataset is a plotted version of Ferdowsi's Shahnameh (which is a highly-regarded ancient set of Farsi poems) generated using DALL-E mini (aka craiyon). You can use this dataset using the code below: \\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"sadrasabouri/ShahNegar\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains more than 30K images with their corresponding text from the Shahnameh. For each Shahnameh‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sadrasabouri/ShahNegar.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","image-captioning","machine-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"nouns","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m1guelpf/nouns","creator_name":"Miguel Piedrafita","creator_url":"https://huggingface.co/m1guelpf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Nouns auto-captioned\\n\\t\\n\\nDataset used to train Nouns text to image model\\nAutomatically generated captions for Nouns from their attributes, colors and items. Help on the captioning script appreciated!\\nFor each row the dataset contains image and text keys. image is a varying size PIL jpeg, and text is the accompanying text caption. Only a train split is provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use this dataset, please cite it as:\\n@misc{piedrafita2022nouns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m1guelpf/nouns.","first_N":5,"first_N_keywords":["text-to-image","machine-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"skateboarding-tricks","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vogloblinsky/skateboarding-tricks","creator_name":"Ogloblinsky","creator_url":"https://huggingface.co/vogloblinsky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Skateboarding tricks\\n\\t\\n\\nDataset used to train Text to skateboarding image model.\\nFor each row the dataset contains image and text keys.\\nimage is a varying size PIL jpeg, and text is the accompanying text caption.\\n","first_N":5,"first_N_keywords":["text-to-image","machine-generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-turkish-subset","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mcemilg/laion2B-multi-turkish-subset","creator_name":"Cemil Guney","creator_url":"https://huggingface.co/mcemilg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for laion2B-multi-turkish-subset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLAION-5B is a large scale openly accessible image-text dataset contains text from multiple languages. This is a Turkish subset data of laion/laion2B-multi. It's compatible to be used with image2dataset to fetch the images at scale.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mcemilg/laion2B-multi-turkish-subset.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"bible_tts_hausa","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vpetukhov/bible_tts_hausa","creator_name":"Viktor Petukhov","creator_url":"https://huggingface.co/vpetukhov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BibleTTS Hausa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBibleTTS is a large high-quality open Text-to-Speech dataset with up to 80 hours of single speaker, studio quality 48kHz recordings.\\nThis is a Hausa part of the dataset. Aligned hours: 86.6, aligned verses: 40,603.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nHausa\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\naudio: audio path\\nsentence: transcription of the audio\\nlocale: always set to ha\\nbook: 3-char book encoding\\nverse:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vpetukhov/bible_tts_hausa.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Mroue","keyword":"text-to-image","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gr3en/Mroue","creator_name":"Walter Maiorino","creator_url":"https://huggingface.co/Gr3en","description":"Gr3en/Mroue dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"fashion-captions-de","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jinaai/fashion-captions-de","creator_name":"Jina AI","creator_url":"https://huggingface.co/jinaai","description":"\\n\\n\\n\\n\\n\\n\\nThe data offered by Jina AI, Finetuner team.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset is a German-language dataset based on the Fashion12K dataset, which originally contains both English and German text descriptions for each item.\\nThis dataset was used to to finetuner CLIP using the Finetuner tool.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFine-tuning\\n\\t\\n\\nPlease refer to our documentation: Multilingual Text-to-Image Search with MultilingualCLIP\\nand blog Improving Search Quality for Non-English Queries with Fine-tuned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jinaai/fashion-captions-de.","first_N":5,"first_N_keywords":["text-to-image","monolingual","original","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"microsoft-fluentui-emoji-512-whitebg","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Norod78/microsoft-fluentui-emoji-512-whitebg","creator_name":"Doron Adler","creator_url":"https://huggingface.co/Norod78","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"microsoft-fluentui-emoji-512-whitebg\\\"\\n\\t\\n\\nsvg and their file names were converted to images and text from Microsoft's fluentui-emoji repo\\n","first_N":5,"first_N_keywords":["unconditional-image-generation","text-to-image","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"microsoft-fluentui-emoji-768","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Norod78/microsoft-fluentui-emoji-768","creator_name":"Doron Adler","creator_url":"https://huggingface.co/Norod78","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"microsoft-fluentui-emoji-768\\\"\\n\\t\\n\\nsvg and their file names were converted to images and text from Microsoft's fluentui-emoji repo\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Umamusume-voice-text-pairs","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Plachta/Umamusume-voice-text-pairs","creator_name":"ElderFrog","creator_url":"https://huggingface.co/Plachta","description":"Plachta/Umamusume-voice-text-pairs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"textures-color-1k","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dream-textures/textures-color-1k","creator_name":"Dream Textures","creator_url":"https://huggingface.co/dream-textures","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttextures-color-1k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe textures-color-1k dataset is an image dataset of 1000+ color image textures in 512x512 resolution with associated text descriptions.\\nThe dataset was created for training/fine-tuning diffusion models on texture generation tasks.\\nIt contains a combination of CC0 procedural and photoscanned PBR materials from ambientCG.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text descriptions are in English, and created by joining the tags of each material‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dream-textures/textures-color-1k.","first_N":5,"first_N_keywords":["text-to-image","English","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"cifar_stable_diffusion","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MatthewWaller/cifar_stable_diffusion","creator_name":"Matthew Waller","creator_url":"https://huggingface.co/MatthewWaller","description":"MatthewWaller/cifar_stable_diffusion dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"regularization-architecture","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-architecture","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArchitecture Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of architecture for the Stable Diffusion 1.5 to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"regularization-castle","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-castle","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCastle Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of castles for the Stable Diffusion 1.5 to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"regularization-horse","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-horse","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHorse Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of horses for the Stable Diffusion 1.5 to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","text","Image","Text"],"keywords_longer_than_N":true},
	{"name":"regularization-creature","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-creature","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCreature Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of creatures for the Stable Diffusion 1.5 to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"regularization-forest","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-forest","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tForest Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of forests for the Stable Diffusion 1.5 model to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","text","Image","Text"],"keywords_longer_than_N":true},
	{"name":"regularization-space","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-space","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpace Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of space for the Stable Diffusion 1.5 to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","text","Image","Text"],"keywords_longer_than_N":true},
	{"name":"regularization-tiger","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-tiger","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTiger Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of tigers for the Stable Diffusion 1.5 to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"regularization-landscape","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-landscape","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLandscape Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of landscapes for the Stable Diffusion 1.5 to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","text","Image","Text"],"keywords_longer_than_N":true},
	{"name":"regularization-man","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-man","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMan Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of men for the Stable Diffusion 1.5 to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","text","Image","Text"],"keywords_longer_than_N":true},
	{"name":"regularization-woman","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3ee/regularization-woman","creator_name":"3ee Games","creator_url":"https://huggingface.co/3ee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWoman Regularization Images\\n\\t\\n\\nA collection of regularization & class instance datasets of women for the Stable Diffusion 1.5 to use for DreamBooth prior preservation loss training.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","text","Image","Text"],"keywords_longer_than_N":true},
	{"name":"hungarian-single-speaker-tts","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts","creator_name":"KTH","creator_url":"https://huggingface.co/KTH","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CSS10 Hungarian: Single Speaker Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe corpus consists of a single speaker, with 4515 segments extracted\\nfrom a single LibriVox audiobook.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe audio is in Hungarian.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[Needs More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts.","first_N":5,"first_N_keywords":["text-to-speech","other","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Bored_Ape_NFT_text","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vessl/Bored_Ape_NFT_text","creator_name":"VESSL AI","creator_url":"https://huggingface.co/vessl","description":"\\n\\t\\n\\t\\t\\n\\t\\tDisclaimer\\n\\t\\n\\nAll rights belong to their owners. Models and datasets can be removed from the site at the request of the copyright holder.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"VESSL/Bored_Ape_NFT_text\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Field\\n\\t\\n\\nimage = binary image file and path \\ntext = auto generated prompt for image\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation & Information\\n\\t\\n\\n@InProceedings{VESSL,    author={Jinpil Choi}    year=2023}\\n\\n\\t\\n\\t\\t\\n\\t\\tProjects‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vessl/Bored_Ape_NFT_text.","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"boudoir-dataset","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/soymia/boudoir-dataset","creator_name":"Milton Arango","creator_url":"https://huggingface.co/soymia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"boudoir-dataset\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nImages scrapped from selected Galleries on Behance.\\n","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"galactic-animation","keyword":"text-to-image","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexZheng/galactic-animation","creator_name":"Alex Zheng","creator_url":"https://huggingface.co/AlexZheng","description":"Dataset to make the galactic-diffusion\\nnum: 133\\nsource: Entergalactic on Netflix\\nincluding: male, female, male and female, indoor scene, outdoor scene","first_N":5,"first_N_keywords":["text-to-image","afl-3.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"common_voice_11_clean_tokenized","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anforsm/common_voice_11_clean_tokenized","creator_name":"Anton Forsman","creator_url":"https://huggingface.co/anforsm","description":"A cleaned and tokenized version of the English data from Mozilla Common Voice 11 dataset.\\nCleaning steps:\\n\\nFiltered on samples with >2 upvotes and <1 downvotes]\\nRemoved non voice audio at start and end through pytorch VAD\\n\\nTokenization:\\n\\nAudio tokenized through EnCodec by Meta\\nUsing 24khz pre-trained model, and target bandwidth of 1.5\\nRepresented in text as audio_token_0 - audio_token_1023\\n\\n\\nPrompts constructed as \\\"text: <common voice transcript>\\\\naudio: <audio tokens>\\\"\\nPrompts tokenized with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anforsm/common_voice_11_clean_tokenized.","first_N":5,"first_N_keywords":["text-to-speech","text-generation","English","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"minercraft","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/keras-dreambooth/minercraft","creator_name":"Keras Dreambooth Event","creator_url":"https://huggingface.co/keras-dreambooth","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset was used to fine-tune this model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo\\n\\t\\n\\nYou can try with this demo\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended uses & limitations\\n\\t\\n\\nA lot of image is belonging to landscape in Minecraft world\\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"rabbit-toy","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/keras-dreambooth/rabbit-toy","creator_name":"Keras Dreambooth Event","creator_url":"https://huggingface.co/keras-dreambooth","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset was used to fine-tune this model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo\\n\\t\\n\\nYou can try with this demo\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended uses & limitations\\n\\t\\n\\nImage of mother rabbit toy\\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"hokusai-style","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/keras-dreambooth/hokusai-style","creator_name":"Keras Dreambooth Event","creator_url":"https://huggingface.co/keras-dreambooth","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset was used to fine-tune this model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo\\n\\t\\n\\nYou can try with this demo\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended uses & limitations\\n\\t\\n\\nImage of Hokusai artist\\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"akita-inu","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/keras-dreambooth/akita-inu","creator_name":"Keras Dreambooth Event","creator_url":"https://huggingface.co/keras-dreambooth","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset was used to fine-tune this model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo\\n\\t\\n\\nYou can try with this demo\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended uses & limitations\\n\\t\\n\\nImage of Akita dog - A famous and cute dog of Japan\\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"indian-foods-dataset","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bharat-raghunathan/indian-foods-dataset","creator_name":"Bharat Raghunathan","creator_url":"https://huggingface.co/bharat-raghunathan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indian Foods Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a multi-category(multi-class classification) related Indian food dataset showcasing The-massive-Indian-Food-Dataset. \\nThis card has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n{\\n  \\\"image\\\": \\\"Image(decode=True, id=None)\\\",\\n  \\\"target\\\": \\\"ClassLabel(names=['biryani'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bharat-raghunathan/indian-foods-dataset.","first_N":5,"first_N_keywords":["image-classification","text-to-image","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"peanuts-flan-t5-xl","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/afmck/peanuts-flan-t5-xl","creator_name":"Alex McKinney","creator_url":"https://huggingface.co/afmck","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPeanut Comic Strip Dataset (Snoopy & Co.)\\n\\t\\n\\n\\nThis is a dataset Peanuts comic strips from 1950/10/02 to 2000/02/13.\\nThere are 77,456 panels extracted from 17,816 comic strips. \\nThe dataset size is approximately 4.4G.\\nEach row in the dataset contains the following fields:\\n\\nimage: PIL.Image containing the extracted panel.\\npanel_name: unique identifier for the row.\\ncharacters: tuple[str, ...] of characters included in the comic strip the panel is part of.\\nthemes: tuple[str, ...] of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/afmck/peanuts-flan-t5-xl.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"milly-images","keyword":"text-to-image","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/spongus/milly-images","creator_name":"spongussss","creator_url":"https://huggingface.co/spongus","description":"A collection of images from a very silly cat, these are all from @fatfatmillycat in twitter. Intended to be used with stable-diffusion-v1-4\\n","first_N":5,"first_N_keywords":["text-to-image","image-classification","image-segmentation","English","unlicense"],"keywords_longer_than_N":true},
	{"name":"GameplayCaptions","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asgaardlab/GameplayCaptions","creator_name":"Analytics of Software, Games and Repository Data (ASGAARD) Lab","creator_url":"https://huggingface.co/asgaardlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Gameplay Captions\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"riffusion-musiccaps-dataset","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hyeon2/riffusion-musiccaps-dataset","creator_name":"Cho Hyeon Min","creator_url":"https://huggingface.co/Hyeon2","description":"riffusion manipulated google/MusicCaps\\n","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"riffusion_musiccaps_datasets_768","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hyeon2/riffusion_musiccaps_datasets_768","creator_name":"Cho Hyeon Min","creator_url":"https://huggingface.co/Hyeon2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"riffusion-musiccaps-datasets-768\\\"\\n\\t\\n\\nConverted google/musicCaps to spectograms with audio_to_spectrum with riffusion cli.\\nRandom 7.68 sec for each music in musicCaps.\\nMore Information needed\\n","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"sql-create-context-copy","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/sql-create-context-copy","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFork of b-mc2/sql-create-context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/sql-create-context-copy.","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"GMaSC","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/GMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGMaSC: GEC Barton Hill Malayalam Speech Corpus\\n\\t\\n\\nGMaSC is a Malayalam text and speech corpus created by the Government Engineering College Barton Hill with an emphasis on Malayalam-accented English. The corpus contains 2,000 text-audio pairs of Malayalam sentences spoken by 2 speakers, totalling in approximately 139 minutes of audio. Each sentences has at least one English word common in Malayalam speech.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of 2,000 instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/GMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"medium","keyword":"text-to-video","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TempoFunk/medium","creator_name":"TempoFunk","creator_url":"https://huggingface.co/TempoFunk","description":"curr. size: 53,081 videos\\ngoal (todo): 100,000+\\n","first_N":5,"first_N_keywords":["text-to-video","English","agpl-3.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"midjourney-kaggle-clean","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanng/midjourney-kaggle-clean","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmidjourney-v5-202304-clean\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÁÆÄ‰ªã Brief Introduction\\n\\t\\n\\nÈùûÂÆòÊñπÁöÑÔºåÂØπKaggle (Midjourney User Prompts & Generated Images (250k))[https://www.kaggle.com/datasets/succinctlyai/midjourney-texttoimage?select=general-01_2022_06_20.json] ‰∏äÁöÑÊï∞ÊçÆÈõÜËøõË°å‰∫ÜÊ∏ÖÁêÜÔºå‰∏ÄÂÖ±Êúâ 248,167ÂØπ„ÄÇ\\nUnofficially, a cleanup of the dataset on Kaggle (Midjourney User Prompts & Generated Images (250k))[https://www.kaggle.com/datasets/succinctlyai/midjourney-texttoimage?select=general-01_2022_06_20.json] yielded 248,167 pairs.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wanng/midjourney-kaggle-clean.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"sample_controlnet_dataset","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SaffalPoosh/sample_controlnet_dataset","creator_name":"Talha Yousuf","creator_url":"https://huggingface.co/SaffalPoosh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tControlNet training\\n\\t\\n\\nthis dataset is subset of fill_50k dataset just to test the finetuning logic.\\n\\nTODO:\\n\\n\\n add text data\\n\\n","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"ParsiGoo","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kamtera/ParsiGoo","creator_name":"Flincer","creator_url":"https://huggingface.co/Kamtera","description":"A Persian multispeaker dataset for text-to-speech purposes.","first_N":5,"first_N_keywords":["text-to-speech","other","monolingual","original","Persian"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/felixsaaro/test","creator_name":"Felix S","creator_url":"https://huggingface.co/felixsaaro","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"test\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"FETV","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lyx97/FETV","creator_name":"Yuanxin Liu","creator_url":"https://huggingface.co/lyx97","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFETV\\n\\t\\n\\nFETV is a benchmark for Fine-grained Evaluation of open-domain Text-to-Video generation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nFETV consist of a diverse set of text prompts, categorized based on three orthogonal aspects: major content, attribute control, and prompt complexity.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAll FETV data are all available in the file fetv_data.json. Each line is a data instance, which is formatted as:\\n{\\n  \\\"video_id\\\": \\\"1006807024\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyx97/FETV.","first_N":5,"first_N_keywords":["text-to-video","English","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"anime-synthetics","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mirav/anime-synthetics","creator_name":"Mira","creator_url":"https://huggingface.co/mirav","description":"Mostly unfiltered anime-style images generated by various text to image models, collected from various sources (some were submitted for inclusion by their creators).\\nIncludes a subset of p1atdev/niji-v5, albeit captioned differently than the source. \\nContains 2224 image & caption pairs.\\nAs it is unfiltered, some adult content may be included.\\nCaptions may not be completely accurate.\\nIf you wish to submit content, do it as a pull request.\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-image","image-to-text","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"whisperspeech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/collabora/whisperspeech","creator_name":"Collabora","creator_url":"https://huggingface.co/collabora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe WhisperSpeech Dataset\\n\\t\\n\\nThis dataset contains data to train SPEAR TTS-like text-to-speech models that utilized semantic tokens derived from the OpenAI Whisper\\nspeech recognition model.\\nWe currently provide semantic and acoustic tokens for the LibriLight and LibriTTS datasets (English only).\\nAcoustic tokens:\\n\\n24kHz EnCodec 6kbps (8 quantizers)\\n\\nSemantic tokens:\\n\\nWhisper tiny VQ bottleneck trained on a subset of LibriLight\\n\\nAvailable LibriLight subsets:\\n\\nsmall/medium/large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/collabora/whisperspeech.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"spider-schema","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-schema","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Schema\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset contains the 166 databases used in the Spider dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-schema.","first_N":5,"first_N_keywords":["spider","English","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"spider-context-instruct","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-instruct.","first_N":5,"first_N_keywords":["spider","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"DreamEditBench","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tianleliphoebe/DreamEditBench","creator_name":"Tianle LI","creator_url":"https://huggingface.co/tianleliphoebe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDreamEditBench for Subject Replacement task and Subject Addition task.\\n\\t\\n\\nThe goal of subject replacement is to replace a subject from a source image with a customized subject. In contrast, the aim of the subject addition task is to add a customized\\nsubject to a desired position in the source image. To standardize the evaluation of the two proposed tasks, we curate a new benchmark, i.e. DreamEditBench, consisting of 22 subjects in alignment with DreamBooth with 20 images for each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tianleliphoebe/DreamEditBench.","first_N":5,"first_N_keywords":["image-to-image","text-to-image","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"spider-context-validation","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate spider-fine-tuned LLMs with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation.","first_N":5,"first_N_keywords":["spider","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"cleanvid-15m_map","keyword":"text-to-video","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shinonomelab/cleanvid-15m_map","creator_name":"Shinonome AI Lab","creator_url":"https://huggingface.co/shinonomelab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCleanVid Map (15M) üé•\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTempoFunk Video Generation Project\\n\\t\\n\\nCleanVid-15M is a large-scale dataset of videos with multiple metadata entries such as:\\n\\nTextual Descriptions üìÉ\\nRecording Equipment üìπ\\nCategories üî†\\nFramerate üéûÔ∏è\\nAspect Ratio üì∫\\n\\nCleanVid aim is to improve the quality of WebVid-10M dataset by adding more data and cleaning the dataset by dewatermarking the videos in it.\\nThis dataset includes only the map with the urls and metadata, with 3,694,510 more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shinonomelab/cleanvid-15m_map.","first_N":5,"first_N_keywords":["text-to-video","video-classification","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"fictional_characters_raw_data_without_images","keyword":"text-to-image","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gryffindor-ISWS/fictional_characters_raw_data_without_images","creator_name":"gryffindor","creator_url":"https://huggingface.co/gryffindor-ISWS","description":"gryffindor-ISWS/fictional_characters_raw_data_without_images dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","gpl-3.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MusicCaps-ru","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/MusicCaps-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMusicCaps-ru\\n\\t\\n\\nTranslated version of google/MusicCaps into Russian.\\n","first_N":5,"first_N_keywords":["text-to-speech","translated","Russian","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"audiocaps-ru","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/audiocaps-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taudiocaps-ru\\n\\t\\n\\nTranslated version of d0rj/audiocaps into Russian.\\n","first_N":5,"first_N_keywords":["text-to-speech","translated","monolingual","d0rj/audiocaps","Russian"],"keywords_longer_than_N":true},
	{"name":"laion_mi","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/antoniaaa/laion_mi","creator_name":"Antoni Kowalczuk","creator_url":"https://huggingface.co/antoniaaa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"LAION-mi\\\"\\n\\t\\n\\nThis is a dataset from Towards More Realistic Membership Inference Attacks on Large Diffusion Models, link.\\nWe provide a robust evaluation setup for membership inference attacks on a state-of-the-art Stable Diffusion model and publish the corresponding dataset along with the proposed setup.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCiting\\n\\t\\n\\nIf you find our work useful in your research, please cite as \\n@misc{dubi≈Ñski2023realistic,\\n      title={Towards More Realistic Membership‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/antoniaaa/laion_mi.","first_N":5,"first_N_keywords":["text-to-image","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"spider-natsql-skeleton-context-instruct","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct.","first_N":5,"first_N_keywords":["spider","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"the-mc-speech-dataset","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset","creator_name":"Mateusz Czy≈ºnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This is public domain speech dataset consisting of 24018 short audio clips of a single speaker reading sentences in Polish. A transcription is provided for each clip. Clips have total length of more than 22 hours.\\nTexts are in public domain. The audio was recorded in 2021-22 as a part of my master's thesis and is in public domain.\\nIf you use this dataset, please cite:\\n@masterthesis{mcspeech,\\n  title={Analiza por√≥wnawcza korpus√≥w nagra≈Ñ mowy dla cel√≥w syntezy mowy w jƒôzyku polskim}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Polish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"tartakovsky-style","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/szymonrucinski/tartakovsky-style","creator_name":"Szymon Ruci≈Ñski","creator_url":"https://huggingface.co/szymonrucinski","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tartakovsky-style\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["text-to-image","apache-2.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"generated-data-fictional-characters-without-images","keyword":"text-to-image","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gryffindor-ISWS/generated-data-fictional-characters-without-images","creator_name":"gryffindor","creator_url":"https://huggingface.co/gryffindor-ISWS","description":"gryffindor-ISWS/generated-data-fictional-characters-without-images dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","gpl-3.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"generated-data-fictional-characters-with-images","keyword":"text-to-image","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gryffindor-ISWS/generated-data-fictional-characters-with-images","creator_name":"gryffindor","creator_url":"https://huggingface.co/gryffindor-ISWS","description":"gryffindor-ISWS/generated-data-fictional-characters-with-images dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","gpl-3.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"spider-natsql-context-validation","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate LLMs on the Spider dev dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation.","first_N":5,"first_N_keywords":["spider","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"edited_common_voice","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lunarlist/edited_common_voice","creator_name":"taetiya taechamatavorn","creator_url":"https://huggingface.co/lunarlist","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"edited_common_voice\\\"\\n\\t\\n\\nMore Information needed\\nThis dataset is a Thai TTS dataset that use the voice from Common Voice dataset and modify the voice to not to sound like the original.\\nMedium: Text-To-Speech ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Tacotron2\\n","first_N":5,"first_N_keywords":["text-to-speech","Thai","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"spider-natsql-context-instruct","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct.","first_N":5,"first_N_keywords":["spider","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"stable-diffusion-2-1-without-images","keyword":"text-to-image","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gryffindor-ISWS/stable-diffusion-2-1-without-images","creator_name":"gryffindor","creator_url":"https://huggingface.co/gryffindor-ISWS","description":"gryffindor-ISWS/stable-diffusion-2-1-without-images dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","gpl-3.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"spider-skeleton-context-instruct","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Skeleton Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct.","first_N":5,"first_N_keywords":["spider","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MissingKeys","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RyokoExtra/MissingKeys","creator_name":"RyokoAI Extra","creator_url":"https://huggingface.co/RyokoExtra","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MissingKeys\\n\\t\\n\\nNOTE: This contains old data before 10/04/24. The uploader has moved to here!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMissingKeys is a raw dataset archive of the misskey.io network.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.\\n\\ntext-classification\\ntext-generation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nPrimarily japanese, however there‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RyokoExtra/MissingKeys.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-image","text-to-video","Japanese"],"keywords_longer_than_N":true},
	{"name":"MissingKeys","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RyokoExtra/MissingKeys","creator_name":"RyokoAI Extra","creator_url":"https://huggingface.co/RyokoExtra","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MissingKeys\\n\\t\\n\\nNOTE: This contains old data before 10/04/24. The uploader has moved to here!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMissingKeys is a raw dataset archive of the misskey.io network.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.\\n\\ntext-classification\\ntext-generation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nPrimarily japanese, however there‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RyokoExtra/MissingKeys.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-image","text-to-video","Japanese"],"keywords_longer_than_N":true},
	{"name":"artelingo-dummy","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssef101/artelingo-dummy","creator_name":"mohamed","creator_url":"https://huggingface.co/youssef101","description":"ArtELingo is a benchmark and dataset introduced in a research paper aimed at promoting work on diversity across languages and cultures. It is an extension of ArtEmis, which is a collection of 80,000 artworks from WikiArt with 450,000 emotion labels and English-only captions. ArtELingo expands this dataset by adding 790,000 annotations in Arabic and Chinese. The purpose of these additional annotations is to evaluate the performance of \\\"cultural-transfer\\\" in AI systems.\\nThe dataset in ArtELingo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssef101/artelingo-dummy.","first_N":5,"first_N_keywords":["image-to-text","text-classification","image-classification","text-to-image","text-generation"],"keywords_longer_than_N":true},
	{"name":"JapaneseGoblin","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RyokoExtra/JapaneseGoblin","creator_name":"RyokoAI Extra","creator_url":"https://huggingface.co/RyokoExtra","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for JapaneseGoblin\\n\\t\\n\\nWE ARE THE JAPANESE GOBLIN!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nJapaneseGoblin is a dump of en.touhouwiki.net wiki.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.\\n\\ntext-classification\\ntext-generation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nPrimarily english, however there are also japanese as well.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RyokoExtra/JapaneseGoblin.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-image","text-to-video","Japanese"],"keywords_longer_than_N":true},
	{"name":"JapaneseGoblin","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RyokoExtra/JapaneseGoblin","creator_name":"RyokoAI Extra","creator_url":"https://huggingface.co/RyokoExtra","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for JapaneseGoblin\\n\\t\\n\\nWE ARE THE JAPANESE GOBLIN!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nJapaneseGoblin is a dump of en.touhouwiki.net wiki.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.\\n\\ntext-classification\\ntext-generation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nPrimarily english, however there are also japanese as well.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RyokoExtra/JapaneseGoblin.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-image","text-to-video","Japanese"],"keywords_longer_than_N":true},
	{"name":"midjourney-v5-202304","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JohnTeddy3/midjourney-v5-202304","creator_name":"JohnTeddy3","creator_url":"https://huggingface.co/JohnTeddy3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmidjourney-v5-202304-clean\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÁÆÄ‰ªã Brief Introduction\\n\\t\\n\\nËΩ¨ËΩΩËá™wanng/midjourney-v5-202304-clean\\nÈùûÂÆòÊñπÁöÑÔºåÁà¨ÂèñËá™midjourney v5ÁöÑ2023Âπ¥4ÊúàÁöÑÊï∞ÊçÆÔºå‰∏ÄÂÖ±1701420Êù°„ÄÇ\\nUnofficial, crawled from midjourney v5 for April 2023, 1,701,420 pairs in total.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ Dataset Information\\n\\t\\n\\nÂéüÂßãÈ°πÁõÆÂú∞ÂùÄÔºöhttps://huggingface.co/datasets/tarungupta83/MidJourney_v5_Prompt_dataset\\nÊàëÂÅö‰∫Ü‰∏Ä‰∫õÊ∏ÖÊ¥óÔºåÊ∏ÖÁêÜÂá∫‰∫Ü‰∏§‰∏™Êñá‰ª∂Ôºö\\n\\nori_prompts_df.parquet Ôºà1,255,812ÂØπÔºåmidjourneyÁöÑÂõõÊ†ºÂõæÔºâ\\n\\nupscaled_prompts_df.parquet Ôºà445,608ÂØπÔºå‰ΩøÁî®‰∫ÜÈ´òÊ∏ÖÊåá‰ª§ÁöÑÂõæÔºåËøôÊÑèÂë≥ÁùÄËøô‰∏™ÂõæÊõ¥ÂèóÊ¨¢Ëøé„ÄÇÔºâ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JohnTeddy3/midjourney-v5-202304.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech-Synthesizer-TTS","keyword":"text-to-speech","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","Spanish Sign Language","unlicense","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech-Synthesizer-TTS","keyword":"text-to-speech","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","Spanish Sign Language","unlicense","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"VietBibleVox","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ntt123/VietBibleVox","creator_name":"Th√¥ng Nguy·ªÖn","creator_url":"https://huggingface.co/ntt123","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVietBibleVox Dataset\\n\\t\\n\\nThe VietBibleVox Dataset is based on the data extracted from open.bible specifically for the Vietnamese language. As the original data is provided under the cc-by-sa-4.0 license, this derived dataset is also licensed under cc-by-sa-4.0.\\nThe dataset comprises 29,185 pairs of (verse, audio clip), with each verse from the Bible read in Vietnamese by a male voice.\\n\\nThe verses are the original texts and may not be directly usable for training text-to-speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ntt123/VietBibleVox.","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","cc-by-sa-4.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"hdvila-100M","keyword":"text-to-video","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TempoFunk/hdvila-100M","creator_name":"TempoFunk","creator_url":"https://huggingface.co/TempoFunk","description":"TempoFunk/hdvila-100M dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-video","text-to-image","video-classification","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"hdvila-100M","keyword":"text-to-image","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TempoFunk/hdvila-100M","creator_name":"TempoFunk","creator_url":"https://huggingface.co/TempoFunk","description":"TempoFunk/hdvila-100M dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-video","text-to-image","video-classification","image-classification","English"],"keywords_longer_than_N":true},
	{"name":"pusheen","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qillura/pusheen","creator_name":"Jason","creator_url":"https://huggingface.co/qillura","description":"qillura/pusheen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","cc0-1.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/metaltiger775/test","creator_name":"metaltiger775","creator_url":"https://huggingface.co/metaltiger775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHello!\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"minispider","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ravidborse/minispider","creator_name":"Ravikiran Borse","creator_url":"https://huggingface.co/ravidborse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ravidborse/minispider.","first_N":5,"first_N_keywords":["text2text-generation","expert-generated","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"spider-context-validation-ranked-schema","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRanked Schema by ChatGPT\\n\\t\\n\\nThe database context used here is generated from ChatGPT after telling it to reorder the schema with the most relevant columns in the beginning of the db_info.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema.","first_N":5,"first_N_keywords":["spider","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"text2food-mmc4","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tum-nlp/text2food-mmc4","creator_name":"Natural Language Processing @ TUM","creator_url":"https://huggingface.co/tum-nlp","description":"This dataset is filtered version of MMC4 Multimodal-C4 core fewer-faces dataset . It contains 144 474 pair of food image url and image caption.\\nAll the code and model in the repository.\\n","first_N":5,"first_N_keywords":["text-to-image","English","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"AlbanianSpeech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Yakidev/AlbanianSpeech","creator_name":"Trust Oriakhi","creator_url":"https://huggingface.co/Yakidev","description":"Yakidev/AlbanianSpeech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Albanian","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-Vietnamese-subset","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/imthanhlv/laion2B-multi-Vietnamese-subset","creator_name":"Th√†nh L√™","creator_url":"https://huggingface.co/imthanhlv","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LAION-2B-multi Vietnamese subset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFilter the Vietnamese subset from Laion2B-multi\\nTo get the subset of your language, check out this notebook\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-text","Vietnamese","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"LAION-EO","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mikonvergence/LAION-EO","creator_name":"Mikolaj Czerkawski","creator_url":"https://huggingface.co/mikonvergence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LAION-EO\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a subset of LAION-5B containing images that are likely to be satellite images. The procedure of acquiring and filtering the dataset has been described in https://arxiv.org/abs/2309.15535.\\n\\n\\t\\n\\t\\t\\nVersion\\nNumber of Samples\\n\\n\\n\\t\\t\\n0\\n24,933\\n\\n\\n1\\n112,985\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach version of the dataset contains a .csv file with metadata with urls to images, which can be easily filtered. Note‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mikonvergence/LAION-EO.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","100K<n<1M","Image"],"keywords_longer_than_N":true},
	{"name":"Scenery_of_japan","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JapanDegitalMaterial/Scenery_of_japan","creator_name":"Japan Degital Material","creator_url":"https://huggingface.co/JapanDegitalMaterial","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScenery of japan.\\n\\t\\n\\nThis is a dataset to train text-to-image or other models without any copyright issue.\\nAll materials used in this dataset are CC0 (Public domain /P.D.).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JapanDegitalMaterial/Scenery_of_japan.","first_N":5,"first_N_keywords":["text-to-image","English","Japanese","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Texture_images","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JapanDegitalMaterial/Texture_images","creator_name":"Japan Degital Material","creator_url":"https://huggingface.co/JapanDegitalMaterial","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTextuer images\\n\\t\\n\\nThis is a dataset to train text-to-image or other models without any copyright issue.\\nAll materials used in this dataset are CC0 (Public domain /P.D.).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JapanDegitalMaterial/Texture_images.","first_N":5,"first_N_keywords":["text-to-image","English","Japanese","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Places_in_Japan","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JapanDegitalMaterial/Places_in_Japan","creator_name":"Japan Degital Material","creator_url":"https://huggingface.co/JapanDegitalMaterial","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlaces in japan.\\n\\t\\n\\nThis is a dataset to train text-to-image or other models without any copyright issue.\\nAll materials used in this dataset are CC0 (Public domain /P.D.).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JapanDegitalMaterial/Places_in_Japan.","first_N":5,"first_N_keywords":["text-to-image","English","Japanese","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"pythia_img_beta","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GeneticApple/pythia_img_beta","creator_name":"Genetic Apple","creator_url":"https://huggingface.co/GeneticApple","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"pythia_img_beta\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"nota","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nota","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Nota\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis data was created by the public institution Nota, which is part of the Danish Ministry of Culture. Nota has a library audiobooks and audiomagazines for people with reading or sight disabilities. Nota also produces a number of audiobooks and audiomagazines themselves.  \\nThe dataset consists of audio and associated transcriptions from Nota's audiomagazines \\\"Inspiration\\\" and \\\"Radio/TV\\\". All files related to one reading of one‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nota.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"nst-da","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nst-da","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NST-da\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an upload of the NST Danish ASR Database (16 kHz) ‚Äì reorganized.\\nThe training and test splits are the original ones.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTraining automatic speech recognition is the intended task for this dataset. No leaderboard is active at this point.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is available in Danish (da).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nst-da.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"VoxCelebSpoof","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MattyB95/VoxCelebSpoof","creator_name":"Matthew Boakes","creator_url":"https://huggingface.co/MattyB95","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVoxCelebSpoof\\n\\t\\n\\nVoxCelebSpoof is a dataset related to detecting spoofing attacks on automatic speaker verification systems. This dataset is part of a broader effort to improve the security of voice biometric systems against various types of spoofing attacks, such as replay attacks, voice synthesis, and voice conversion.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe VoxCelebSpoof dataset includes a range of audio samples from different types of synthesis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MattyB95/VoxCelebSpoof.","first_N":5,"first_N_keywords":["audio-classification","text-to-speech","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"sql-parsed","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/sql-parsed","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-parsed dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"sixuxar_yijiri_mak7","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anzorq/sixuxar_yijiri_mak7","creator_name":"AQ","creator_url":"https://huggingface.co/anzorq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Info\\n\\t\\n\\nThis dataset consists of paired audio and text data sourced from the following book:\\n\\nTitle: –ö—ä—ç—Ä–º–æ–∫—ä—É—ç –ú. –©–∏—Ö—É—Ö—ç—Ä –∏–¥–∂—ã—Ä–∏ –º—ç–∫I. –Ø–ø—ç —Ç—Ö—ã–ª—ä.\\nPublication: –ù–∞–ª—å—á–∏–∫: –≠–ª—å–±—Ä—É—Å, 1999\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAudio Specifications\\n\\t\\n\\n\\nSample Rate: 16,000 Hz\\nTotal Length: 10:36:40\\nSource: adigabook.ru\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcessing Information\\n\\t\\n\\nAudio-text pairs for this dataset were extracted and aligned using META AI's forced alignment algorithm.\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kabardian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for VibraVox\\n\\t\\n\\n\\n  \\n\\n\\n\\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\\nwhich has exactly the same architecture.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDATASET SUMMARY\\n\\t\\n\\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\\nThis dataset can be used for various audio machine learning tasks :\\n\\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"commoncatalog-cc-by-sa","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/common-canvas/commoncatalog-cc-by-sa","creator_name":"CommonCanvas","creator_url":"https://huggingface.co/common-canvas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CommonCatalog CC-BY-SA\\n\\t\\n\\nThis dataset is a large collection of high-resolution Creative Common images (composed of different licenses, see paper Table 1 in the Appendix) collected in 2014 from users of Yahoo Flickr. \\nThe dataset contains images of up to 4k resolution, making this one of the highest resolution captioned image datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe provide captions synthetic captions to approximately 100‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/common-canvas/commoncatalog-cc-by-sa.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-sa-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"irish-traditional-tunes","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hdparmar/irish-traditional-tunes","creator_name":"Harshdeep Parmar","creator_url":"https://huggingface.co/hdparmar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"irish-traditional-tunes\\\"\\n\\t\\n\\nMore Information needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"irish-tunes-spectrograms\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Dataset Description\\n\\t\\n\\n  Dataset is used for the following project\\n\\nHomepage: Trad-fusion\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1.1 Dataset Summary\\n\\t\\n\\nThis dataset contains 9604 Mel spectrograms that represent Traditional Irish Music. \\nThis dataset is smaller compared to hdparmar/irish-tunes-spectrogram, to reduce the training time and increase the possibilty to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hdparmar/irish-traditional-tunes.","first_N":5,"first_N_keywords":["text-to-image","text-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"irish-traditional-tunes","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hdparmar/irish-traditional-tunes","creator_name":"Harshdeep Parmar","creator_url":"https://huggingface.co/hdparmar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"irish-traditional-tunes\\\"\\n\\t\\n\\nMore Information needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"irish-tunes-spectrograms\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Dataset Description\\n\\t\\n\\n  Dataset is used for the following project\\n\\nHomepage: Trad-fusion\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1.1 Dataset Summary\\n\\t\\n\\nThis dataset contains 9604 Mel spectrograms that represent Traditional Irish Music. \\nThis dataset is smaller compared to hdparmar/irish-tunes-spectrogram, to reduce the training time and increase the possibilty to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hdparmar/irish-traditional-tunes.","first_N":5,"first_N_keywords":["text-to-image","text-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MCC-250","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AIML-TUDA/MCC-250","creator_name":"Artificial Intelligence & Machine Learning Lab at TU Darmstadt","creator_url":"https://huggingface.co/AIML-TUDA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultimodal Concept Conjunction 250\\n\\t\\n\\nIn our paper MultiFusion: Fusing Pre-Trained Models for\\nMulti-Lingual, Multi-Modal Image Generation we propose the MCC-250 benchmark to evaluate generative image composition capablities for multimodal inputs. \\nMCC-250 is built on a subset of CC-500 which contains 500 text-only prompts of the pattern \\\"a red apple and a yellow banana\\\", textually\\ndescribing two objects with respective attributes.\\nWith MCC-250, we provide a set of reference images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIML-TUDA/MCC-250.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Openclipart-Oldstyle","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuajewell/Openclipart-Oldstyle","creator_name":"Joshua Jewell","creator_url":"https://huggingface.co/joshuajewell","description":"Dataset Card for 16th Century(?) Black and White Style\\n\\nDataset used to train/finetune a black and white print style\\nCaptions are generated by hand with the assistance of BLIP.\\nImages were sourced from:\\n  https://openclipart.org/artist/j4p4n\\n  https://openclipart.org/artist/johnny_automatic\\n  https://openclipart.org/artist/SnipsAndClips\\nText file filenames correspond image file filenames as captions.\\n","first_N":5,"first_N_keywords":["text-to-image","human generated","other","monolingual","https://openclipart.org/artist/j4p4n"],"keywords_longer_than_N":true},
	{"name":"32000-BlackSharpie","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuajewell/32000-BlackSharpie","creator_name":"Joshua Jewell","creator_url":"https://huggingface.co/joshuajewell","description":"Dataset Card for a Black and White Sharpie Style\\n\\nDataset used to train/finetune a black and white sharpie style\\nCaptions are generated by hand with the assistance of BLIP.\\nImages were hand drawn.\\nText file filenames correspond image file filenames as captions.\\n","first_N":5,"first_N_keywords":["text-to-image","human generated","other","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"sql-create-context-id","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detakarang/sql-create-context-id","creator_name":"Gede Putra Nugraha","creator_url":"https://huggingface.co/detakarang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a fork from sql-create-context \\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detakarang/sql-create-context-id.","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","Indonesian","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Rhulk_pt-br","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/satierf/Rhulk_pt-br","creator_name":"thiago freitas pimenta","creator_url":"https://huggingface.co/satierf","description":"satierf/Rhulk_pt-br dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"civitai-stable-diffusion-2.5m","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hanruijiang/civitai-stable-diffusion-2.5m","creator_name":"Han Ruijiang","creator_url":"https://huggingface.co/hanruijiang","description":"inspired by thefcraft/civitai-stable-diffusion-337k.\\ncollected using civitai api to get all prompts.\\n","first_N":5,"first_N_keywords":["text-generation","text-to-image","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"hoshino_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/hoshino_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of hoshino (Blue Archive)\\n\\t\\n\\nThis is the dataset of hoshino (Blue Archive), containing 150 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n150\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n420\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n477\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/hoshino_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","n<1K","Image","Text"],"keywords_longer_than_N":true},
	{"name":"momoi_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/momoi_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of momoi (Blue Archive)\\n\\t\\n\\nThis is the dataset of momoi (Blue Archive), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n560\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n668\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/momoi_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"kokona_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/kokona_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of kokona (Blue Archive)\\n\\t\\n\\nThis is the dataset of kokona (Blue Archive), containing 150 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n150\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n416\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n505\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/kokona_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"iroha_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/iroha_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of iroha (Blue Archive)\\n\\t\\n\\nThis is the dataset of iroha (Blue Archive), containing 150 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n150\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n416\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n482\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/iroha_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"midori_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/midori_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of midori (Blue Archive)\\n\\t\\n\\nThis is the dataset of midori (Blue Archive), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n556\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n676\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/midori_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"mari_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/mari_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of mari (Blue Archive)\\n\\t\\n\\nThis is the dataset of mari (Blue Archive), containing 150 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n150\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n409\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n475\\nDownload\\n3-stage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/mari_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"unicorn_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/unicorn_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of unicorn (Azur Lane)\\n\\t\\n\\nThis is the dataset of unicorn (Azur Lane), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n522\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n597\\nDownload\\n3-stage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/unicorn_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"laffey_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/laffey_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of laffey (Azur Lane)\\n\\t\\n\\nThis is the dataset of laffey (Azur Lane), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n516\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n581\\nDownload\\n3-stage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/laffey_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"serina_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/serina_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of serina (Blue Archive)\\n\\t\\n\\nThis is the dataset of serina (Blue Archive), containing 194 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n194\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n528\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n611\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/serina_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"le_malin_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/le_malin_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of le_malin (Azur Lane)\\n\\t\\n\\nThis is the dataset of le_malin (Azur Lane), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n530\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n598\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/le_malin_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"nagato_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/nagato_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of nagato (Azur Lane)\\n\\t\\n\\nThis is the dataset of nagato (Azur Lane), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n520\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n584\\nDownload\\n3-stage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/nagato_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"shimakaze_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/shimakaze_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of shimakaze (Azur Lane)\\n\\t\\n\\nThis is the dataset of shimakaze (Azur Lane), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n555\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n602\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/shimakaze_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"yoshimi_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/yoshimi_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of yoshimi (Blue Archive)\\n\\t\\n\\nThis is the dataset of yoshimi (Blue Archive), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n564\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n660\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/yoshimi_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"tsurugi_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/tsurugi_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of tsurugi (Blue Archive)\\n\\t\\n\\nThis is the dataset of tsurugi (Blue Archive), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\nraw-stage3\\n531\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n667\\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/tsurugi_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"google-chilean-spanish","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-chilean-spanish","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tamil Speech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 7 hours of transcribed high-quality audio of Chilean Spanish sentences recorded by 31 volunteers. The dataset is intended for speech technologies. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-chilean-spanish.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Spanish","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"google-chilean-spanish","keyword":"text-to-audio","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-chilean-spanish","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tamil Speech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 7 hours of transcribed high-quality audio of Chilean Spanish sentences recorded by 31 volunteers. The dataset is intended for speech technologies. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-chilean-spanish.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Spanish","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ch_en_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/ch_en_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of ch'en (Arknights)\\n\\t\\n\\nThis is the dataset of ch'en (Arknights), containing 200 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization).(LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n200\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n490\\nDownload\\n3-stage cropped raw data with meta information.\\n\\n\\nraw-stage3-eyes\\n605\\nDownload\\n3-stage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/ch_en_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"factorio-blueprint-visualizations","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/piebro/factorio-blueprint-visualizations","creator_name":"Piet","creator_url":"https://huggingface.co/piebro","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a collection of visualizations of Factorio Blueprints using this Factorio Visualization Tool: https://github.com/piebro/factorio-blueprint-visualizer. The Blueprints are collected from https://www.factorio.school/.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExamples\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\\"svg_original\\\": The svg downloaded like this from the website\\n\\\"svg_rect\\\": The svg reshaped to a rect and a slightly bigger border\\n\\\"png_1024x1024\\\": The svg_rect images‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/piebro/factorio-blueprint-visualizations.","first_N":5,"first_N_keywords":["text-to-image","cc0-1.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"openslr-slr69-ca-trimmed-denoised","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for openslr-slr69-ca-denoised\\n\\t\\n\\nThis is a post-processed version of the Catalan subset belonging to the Open Speech and Language Resources (OpenSLR) speech dataset. \\nSpecifically the subset OpenSLR-69. \\nThe original HFü§ó SLR-69 dataset is located here.\\nSame license is maintained: Attribution-ShareAlike 4.0 International.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe processed the data of the Catalan OpenSLR with the following recipe:\\n\\nTrimming:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised.","first_N":5,"first_N_keywords":["text-to-speech","no-annotation","crowdsourced","monolingual","openslr"],"keywords_longer_than_N":true},
	{"name":"yato_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/yato_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of yato (Arknights)\\n\\t\\n\\nThis is the dataset of yato (Arknights), containing 90 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n90\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n227\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/yato_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"ranger_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/ranger_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of ranger (Azur Lane)\\n\\t\\n\\nThis is the dataset of ranger (Azur Lane), containing 45 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n45\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n120\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/ranger_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"durin_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/durin_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of durin (Arknights)\\n\\t\\n\\nThis is the dataset of durin (Arknights), containing 55 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n55\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n133\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/durin_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"fang_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/fang_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of fang (Arknights)\\n\\t\\n\\nThis is the dataset of fang (Arknights), containing 61 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n61\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n146\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/fang_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"MuLMS-Img","keyword":"text-to-image","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Timbrt/MuLMS-Img","creator_name":"Tim Tarsi","creator_url":"https://huggingface.co/Timbrt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMulti Layer Materials Science Image Corpus\\n\\t\\n\\nThis repository contains companion material for the following publication:\\n\\nTim Tarsi, Heike Adel, Jan Hendrik Metzen, Dan Zhang, Matteo Finco, Annemarie Friedrich. SciOL and MuLMS-Img: Introducing A Large-Scale Multimodal Scientific Dataset and Models for Image-Text Tasks in the Scientific Domain. WACV 2024.\\n\\nPlease cite this paper if using the dataset, and direct any questions regarding the dataset\\nto Tim Tarsi\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Timbrt/MuLMS-Img.","first_N":5,"first_N_keywords":["image-classification","text-to-image","object-detection","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"cardigan_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/cardigan_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of cardigan (Arknights)\\n\\t\\n\\nThis is the dataset of cardigan (Arknights), containing 85 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n85\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n207\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/cardigan_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"kroos_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/kroos_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of kroos (Arknights)\\n\\t\\n\\nThis is the dataset of kroos (Arknights), containing 196 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n196\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n497\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/kroos_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"adnachiel_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/adnachiel_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of adnachiel (Arknights)\\n\\t\\n\\nThis is the dataset of adnachiel (Arknights), containing 19 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n19\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n45\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/adnachiel_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"hibiscus_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/hibiscus_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of hibiscus (Arknights)\\n\\t\\n\\nThis is the dataset of hibiscus (Arknights), containing 99 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n99\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n247\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/hibiscus_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"meteor_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/meteor_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of meteor (Arknights)\\n\\t\\n\\nThis is the dataset of meteor (Arknights), containing 161 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n161\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n409\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/meteor_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"4catac","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/4catac","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 4catac\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n4catac: examples of phonetic transcription in 4  Catalan accents is a dataset of phonetic transcriptions in four Catalan accents: Balearic, Central, North-Western and Valencian. \\nIt consists of 160 sentences transcribed using IPA, following the recommendations of the Institut d'Estudis Catalans.\\nThese sentences are the same for the four accents but may have small morphological adaptations to make them more natural for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/4catac.","first_N":5,"first_N_keywords":["text-to-speech","expert-generated","expert-generated","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"festcat_trimmed_denoised","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/festcat_trimmed_denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for festcat_trimmed_denoised\\n\\t\\n\\nThis is a post-processed version of the Catalan Festcat speech dataset. \\nThe original data can be found here.\\nSame license is maintained: Creative Commons Attribution-ShareAlike 3.0 Spain License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe processed the data of the Catalan Festcat with the following recipe:\\n\\nTrimming: Long silences from the start and the end of clips have been removed.\\npy-webrtcvad -> Python‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/festcat_trimmed_denoised.","first_N":5,"first_N_keywords":["text-to-speech","no-annotation","crowdsourced","monolingual","openslr"],"keywords_longer_than_N":true},
	{"name":"universal_bulin_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/universal_bulin_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of universal_bulin (Azur Lane)\\n\\t\\n\\nThis is the dataset of universal_bulin (Azur Lane), containing 14 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n14\\nDownloadRaw data with meta information.\\n\\n\\nraw-stage3\\n35\\nDownload\\n3-stage cropped raw‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/universal_bulin_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"vanilla_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/vanilla_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of vanilla (Arknights)\\n\\t\\n\\nThis is the dataset of vanilla (Arknights), containing 30 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n30\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n65\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/vanilla_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"cassin_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/cassin_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of cassin (Azur Lane)\\n\\t\\n\\nThis is the dataset of cassin (Azur Lane), containing 40 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n40\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n108\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/cassin_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"airi_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/airi_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of airi (Blue Archive)\\n\\t\\n\\nThis is the dataset of airi (Blue Archive), containing 79 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n79\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n212\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/airi_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"downes_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/downes_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of downes (Azur Lane)\\n\\t\\n\\nThis is the dataset of downes (Azur Lane), containing 15 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n15\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n41\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/downes_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"maury_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/maury_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of maury (Azur Lane)\\n\\t\\n\\nThis is the dataset of maury (Azur Lane), containing 18 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n18\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n45\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/maury_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"charles_ausburne_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/charles_ausburne_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of charles_ausburne (Azur Lane)\\n\\t\\n\\nThis is the dataset of charles_ausburne (Azur Lane), containing 12 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n12\\nDownloadRaw data with meta information.\\n\\n\\nraw-stage3\\n30\\nDownload\\n3-stage cropped‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/charles_ausburne_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"foote_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/foote_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of foote (Azur Lane)\\n\\t\\n\\nThis is the dataset of foote (Azur Lane), containing 26 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n26\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n69\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/foote_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"plume_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/plume_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of plume (Arknights)\\n\\t\\n\\nThis is the dataset of plume (Arknights), containing 131 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n131\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n335\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/plume_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"sims_azurlane","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/sims_azurlane","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of sims (Azur Lane)\\n\\t\\n\\nThis is the dataset of sims (Azur Lane), containing 68 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n68\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n181\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/sims_azurlane.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"melantha_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/melantha_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of melantha (Arknights)\\n\\t\\n\\nThis is the dataset of melantha (Arknights), containing 166 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n166\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n384\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/melantha_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"beagle_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/beagle_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of beagle (Arknights)\\n\\t\\n\\nThis is the dataset of beagle (Arknights), containing 35 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n35\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n77\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/beagle_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"lava_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/lava_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of lava (Arknights)\\n\\t\\n\\nThis is the dataset of lava (Arknights), containing 63 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n63\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n156\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/lava_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"ansel_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/ansel_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of ansel (Arknights)\\n\\t\\n\\nThis is the dataset of ansel (Arknights), containing 140 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n140\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n319\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/ansel_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"orchid_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/orchid_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of orchid (Arknights)\\n\\t\\n\\nThis is the dataset of orchid (Arknights), containing 32 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n32\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n76\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/orchid_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"haze_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/haze_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of haze (Arknights)\\n\\t\\n\\nThis is the dataset of haze (Arknights), containing 73 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n73\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n163\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/haze_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"jessica_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/jessica_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of jessica (Arknights)\\n\\t\\n\\nThis is the dataset of jessica (Arknights), containing 307 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n307\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n746\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/jessica_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"shirayuki_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/shirayuki_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of shirayuki (Arknights)\\n\\t\\n\\nThis is the dataset of shirayuki (Arknights), containing 58 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n58\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n151\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/shirayuki_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"courier_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/courier_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of courier (Arknights)\\n\\t\\n\\nThis is the dataset of courier (Arknights), containing 34 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n34\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n91\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/courier_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"scavenger_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/scavenger_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of scavenger (Arknights)\\n\\t\\n\\nThis is the dataset of scavenger (Arknights), containing 30 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n30\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n80\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/scavenger_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"akane_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/akane_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of akane (Blue Archive)\\n\\t\\n\\nThis is the dataset of akane (Blue Archive), containing 498 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n498\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n1352\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/akane_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","n<1K","Image","Text"],"keywords_longer_than_N":true},
	{"name":"akari_bluearchive","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/akari_bluearchive","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of akari (Blue Archive)\\n\\t\\n\\nThis is the dataset of akari (Blue Archive), containing 57 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n57\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n160\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/akari_bluearchive.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"meme-imgflip-small-test-dataset","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SassyRong/meme-imgflip-small-test-dataset","creator_name":"SassyRong","creator_url":"https://huggingface.co/SassyRong","description":"SassyRong/meme-imgflip-small-test-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","cc0-1.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"vigna_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/vigna_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of vigna (Arknights)\\n\\t\\n\\nThis is the dataset of vigna (Arknights), containing 210 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n210\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n570\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/vigna_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"bubble_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/bubble_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of bubble (Arknights)\\n\\t\\n\\nThis is the dataset of bubble (Arknights), containing 15 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n15\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n35\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/bubble_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"jackie_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/jackie_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of jackie (Arknights)\\n\\t\\n\\nThis is the dataset of jackie (Arknights), containing 26 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n26\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n70\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/jackie_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"frost_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/frost_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of frost (Arknights)\\n\\t\\n\\nThis is the dataset of frost (Arknights), containing 74 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n74\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n182\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/frost_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"pudding_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/pudding_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of pudding (Arknights)\\n\\t\\n\\nThis is the dataset of pudding (Arknights), containing 20 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n20\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n52\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/pudding_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"rockrock_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/rockrock_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of rockrock (Arknights)\\n\\t\\n\\nThis is the dataset of rockrock (Arknights), containing 48 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n48\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n132\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/rockrock_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"highmore_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/highmore_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of highmore (Arknights)\\n\\t\\n\\nThis is the dataset of highmore (Arknights), containing 48 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n48\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n133\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/highmore_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"lunacub_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/lunacub_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of lunacub (Arknights)\\n\\t\\n\\nThis is the dataset of lunacub (Arknights), containing 38 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n38\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n104\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/lunacub_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"vigil_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/vigil_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of vigil (Arknights)\\n\\t\\n\\nThis is the dataset of vigil (Arknights), containing 16 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n16\\nDownload\\nRaw data with meta information.\\nraw-stage3\\n41\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/vigil_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"firewhistle_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/firewhistle_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of firewhistle (Arknights)\\n\\t\\n\\nThis is the dataset of firewhistle (Arknights), containing 15 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n15\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n41\\nDownload\\n3-stage cropped raw data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/firewhistle_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"paprika_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/paprika_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of paprika (Arknights)\\n\\t\\n\\nThis is the dataset of paprika (Arknights), containing 13 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n13\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n33\\nDownload\\n3-stage cropped raw data with meta‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/paprika_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"stainless_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/stainless_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of stainless (Arknights)\\n\\t\\n\\nThis is the dataset of stainless (Arknights), containing 17 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n17\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n39\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/stainless_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"qanipalaat_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/qanipalaat_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of qanipalaat (Arknights)\\n\\t\\n\\nThis is the dataset of qanipalaat (Arknights), containing 15 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n15\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n34\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/qanipalaat_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"chongyue_arknights","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AppleHarem/chongyue_arknights","creator_name":"AppleHarem","creator_url":"https://huggingface.co/AppleHarem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset of chongyue (Arknights)\\n\\t\\n\\nThis is the dataset of chongyue (Arknights), containing 17 images and their tags.\\nImages are crawled from many sites (e.g. danbooru, pixiv, zerochan ...), the auto-crawling system is powered by DeepGHS Team(huggingface organization). \\nThis is a WebUI contains crawlers and other thing: (LittleAppleWebUI)\\n\\n\\t\\n\\t\\t\\nName\\nImages\\nDownload\\nDescription\\n\\n\\n\\t\\t\\nraw\\n17\\nDownload\\nRaw data with meta information.\\n\\n\\nraw-stage3\\n41\\nDownload\\n3-stage cropped raw data with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AppleHarem/chongyue_arknights.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"common-voice-filtered","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/common-voice-filtered","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommon Voice Filtered\\n\\t\\n\\nA filtered subset of the Common Voice dataset. Currently, this dataset only includes a small subset of English speech.\\nWe only include speech ranked above 3.75 (75%) on the MOS metric, as calculated by the UTMOS system. Approximately 7% of audio qualified for inclusion in this filtered dataset.\\nThis data is not final. Processing the whole Common Voice dataset would require a significant amount of compute, this is just a small sample/MVP of the project.\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/styletts2-community/common-voice-filtered.","first_N":5,"first_N_keywords":["text-to-speech","cc-by-sa-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"presto-athena-txt-2-sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cnatale/presto-athena-txt-2-sql","creator_name":"Chris Natale","creator_url":"https://huggingface.co/cnatale","description":"I created this dataset using sqlglot to auto-convert the Spider and Wikisql datasets to Presto syntax, along with running some regex's for additional cleanup.\\nAn example use case is fine-tuning an existing model to respond with Presto/Athena text-to-sql, if it performs well at standard SQL syntax used by the major text to sql training datasets.\\nExample of fine-tuning using this dataset (in this case for Mystral 7b Instruct):\\nimport json\\nimport pandas as pd\\nfrom datasets import Dataset\\n\\ndef‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cnatale/presto-athena-txt-2-sql.","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"stable-diffusion-prompts-uncensored","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/stable-diffusion-prompts-uncensored","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"stable-diffusion-prompts-uncensored\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tNot SAFE for public - Definately Unfiltered\\n\\t\\n\\nThis dataset comes from prompts shared from images' metadata on Civitai. Not for the faint of heart. \\nThanks to Civitai.com for all the models, building a playground, allowing fine tuning of models, and generally being a good influence on model building and generation.\\nThe purpose of this dataset is to allow for analysis of prompts and feature analysis in prompts and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jtatman/stable-diffusion-prompts-uncensored.","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Derm-T2IM-Dataset","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MAli-Farooq/Derm-T2IM-Dataset","creator_name":"Muhammad Ali Farooq","creator_url":"https://huggingface.co/MAli-Farooq","description":"\\nThe Dataset6K folder consist of two sub folders which includes Benign and Malignant data samples each having 3k data samples.\\n\\nThe Smart transformation folder consist of three subfolders which inlcudes tiny benign mole, large malignant moles and multiple moles each having advanced skin lesion augmentation results.\\n\\nIf you need to generate more data using Derm-T2IM model it can done by uploading the Derm-T2IM model on stable diffusion GUI which can be cloned from below Github Repo.\\nLink:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAli-Farooq/Derm-T2IM-Dataset.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"yandere2023","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nyanko7/yandere2023","creator_name":"Nyanko","creator_url":"https://huggingface.co/nyanko7","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYandere2023: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset\\n\\t\\n\\n\\n\\nYandere2023 is a comprehensive anime image dataset with over 1.2 million high-quality images sourced from various materials, including key frames, manga scans, artbooks, and more. While the average number of tags per image is relatively low, the dataset boasts a diverse collection of images with exceptional quality.\\n\\nShared by: Nyanko Devs\\nLanguage(s): English, Japanese\\nLicense: MIT\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyanko7/yandere2023.","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"AISHELL-3","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISHELL/AISHELL-3","creator_name":"aishelltech","creator_url":"https://huggingface.co/AISHELL","description":"AISHELL-3 is a large-scale and high-fidelity multi-speaker Mandarin speech corpus published by Beijing Shell Shell Technology Co.,Ltd. It can be used to train multi-speaker Text-to-Speech (TTS) systems.The corpus contains roughly 85 hours of emotion-neutral recordings spoken by 218 native Chinese mandarin speakers and total 88035 utterances. Their auxiliary attributes such as gender, age group and native accents are explicitly marked and provided in the corpus. Accordingly, transcripts in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AISHELL/AISHELL-3.","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"OmniVid","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vivym/OmniVid","creator_name":"Ming Yang","creator_url":"https://huggingface.co/vivym","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOmniVid\\n\\t\\n\\nYoutube Video: 24,037,110\\n","first_N":5,"first_N_keywords":["text-to-video","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MultiCaRe_Dataset","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset","creator_name":"Mauro Nievas Offidani","creator_url":"https://huggingface.co/mauro-nievoff","description":"The dataset contains multi-modal data from over 75,000 open access and de-identified case reports, including metadata, clinical cases, image captions and more than 130,000 images. Images and clinical cases belong to different medical specialties, such as oncology, cardiology, surgery and pathology. The structure of the dataset allows to easily map images with their corresponding article metadata, clinical case, captions and image labels. Details of the data structure can be found in the file‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mauro-nievoff/MultiCaRe_Dataset.","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"itaku","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/itaku","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Itaku.ee\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata for 924,723 artwork posts from Itaku.ee, an art-sharing and commissioning platform. The total uncompressed size of the original media files (not included in dataset) is 1,900,129.40 MB. The dataset includes only metadata such as titles, descriptions, tags, and other post information.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en), with titles, descriptions and tags in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/itaku.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"wiki-en-in-neerja-speech","keyword":"text-to-audio","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"This dataset contains 10K audio samples generated using Microsoft Edge Text-to-Speech via EdgeTTS. \\n\\nTotal samples: 10K\\nAudio format: MP3\\nSample rate: 24kHz\\nTotal duration: 95735.86 seconds (26.59 hours)\\nAverage duration: 9.57 seconds\\nLanguages included: English\\nVoices used: en-IN-NeerjaExpressiveNeural\\n\\nInput sentences were randomly sampled from Wikipedia, provided by the Wikimedia Foundation under the GNU Free Documentation License (GFDL) and the Creative Commons Attribution-Share-Alike 3.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SpeechBrown","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-lab/SpeechBrown","creator_name":"LLM-Lab-Org  @QCRI","creator_url":"https://huggingface.co/llm-lab","description":" \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpeech Brown is a comprehensive, synthetic, and diverse paired speech-text dataset in 15 categories, covering a wide range of topics from fiction to religion. This dataset consists of over 55,000 sentence-level samples.  \\nTo train the CLASP model, we created this dataset based on the Brown Corpus. The synthetic speech was generated using the NVIDIA Tacotron 2 text-to-speech model.  \\nFor more information about our proposed model, please refer to this paper. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llm-lab/SpeechBrown.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"ecom-prod-demo","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ariwala99/ecom-prod-demo","creator_name":"Pratham Ariwala","creator_url":"https://huggingface.co/ariwala99","description":"ariwala99/ecom-prod-demo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ImageDataset","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bk1832004/ImageDataset","creator_name":"Bharath Krishna","creator_url":"https://huggingface.co/bk1832004","description":"bk1832004/ImageDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"CVPR-2021-Accepted-Papers","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DeepNLP/CVPR-2021-Accepted-Papers","creator_name":"DeepNLP","creator_url":"https://huggingface.co/DeepNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tCVPR 2021 Accepted Paper Meta Info Dataset\\n\\t\\n\\nThis dataset is collect from the CVPR 2021 Open Access website (https://openaccess.thecvf.com/CVPR2021) as well as the arxiv website DeepNLP paper arxiv (http://www.deepnlp.org/content/paper/cvpr2021). For researchers who are interested in doing analysis of CVPR 2021 accepted papers and potential trends, you can use the already cleaned up json files. Each row contains the meta information of a paper in the CVPR 2021 conference. To explore‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DeepNLP/CVPR-2021-Accepted-Papers.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ScImage","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/casszhao/ScImage","creator_name":"casszhao","creator_url":"https://huggingface.co/casszhao","description":"The prompt for ICLR2025 paper \\nScImage: HOW GOOD ARE MULTIMODAL LARGE LANGUAGE MODELS AT SCIENTIFIC TEXT-TO-IMAGE GENERATION?\\nThe prompt template and the object list will be added soon.\\n@inproceedings{\\nscimage2025,\\ntitle={ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?},\\nauthor={Zhang, Leixin and Cheng, Yinjie and Zhai, Weihe and Eger, Steffen and Belouadi, Jonas and Moafian, Fahimeh and Zhao, Zhixue},\\nbooktitle={The Thirteenth International‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/casszhao/ScImage.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"ScImage","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/casszhao/ScImage","creator_name":"casszhao","creator_url":"https://huggingface.co/casszhao","description":"The prompt for ICLR2025 paper \\nScImage: HOW GOOD ARE MULTIMODAL LARGE LANGUAGE MODELS AT SCIENTIFIC TEXT-TO-IMAGE GENERATION?\\nThe prompt template and the object list will be added soon.\\n@inproceedings{\\nscimage2025,\\ntitle={ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?},\\nauthor={Zhang, Leixin and Cheng, Yinjie and Zhai, Weihe and Eger, Steffen and Belouadi, Jonas and Moafian, Fahimeh and Zhao, Zhixue},\\nbooktitle={The Thirteenth International‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/casszhao/ScImage.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Images-for-examples","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felguk/Images-for-examples","creator_name":"Alex Felguk","creator_url":"https://huggingface.co/Felguk","description":"Yes this is example of images for image generator gr.Examples\\nThere are three of them for now but I will add many images soon.\\nSub me\\n","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"TOSD","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tamazight-NLP/TOSD","creator_name":"Tamazight NLP","creator_url":"https://huggingface.co/Tamazight-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Tamazight Open Speech Dataset\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tamazight-NLP/TOSD.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Standard Moroccan Tamazight","ber","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"XTD-10","keyword":"image-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Haon-Chen/XTD-10","creator_name":"Haonan Chen","creator_url":"https://huggingface.co/Haon-Chen","description":"\\n\\t\\n\\t\\t\\n\\t\\tXTD Multimodal Multilingual Data With Instruction\\n\\t\\n\\nThis dataset contains datasets (with English instruction) used for evaluating the multilingual capability of a multimodal embedding model, including seven languages:\\n\\nit, es, ru, zh, pl, tr, ko\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Usage\\n\\t\\n\\n\\nThe instruction on the query side is: \\\"Retrieve an image of this caption.\\\"\\nThe instruction on the document side is: \\\"Represent the given image.\\\"\\nEach example contains a query and a set of targets. The first one in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Haon-Chen/XTD-10.","first_N":5,"first_N_keywords":["image-text-to-text","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"contrabandistas_outfit","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jtorregrosa/contrabandistas_outfit","creator_name":"Jorge Torregrosa Lloret","creator_url":"https://huggingface.co/jtorregrosa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContrabandistas Outfit Dataset\\n\\t\\n\\nThis dataset provides a collection of labeled images featuring individuals wearing the traditional Contrabandista outfit, typically worn by participants in the Comparsa Contrabandistas in San Vicente del Raspeig. These images are annotated with labels detailing the pose, orientation, background, and outfit specifics, offering a detailed visual reference for this culturally significant attire.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nTotal Images: 27\\nFile‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jtorregrosa/contrabandistas_outfit.","first_N":5,"first_N_keywords":["text-to-image","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"diffusion-models-hf-hub","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DeFactOfficial/diffusion-models-hf-hub","creator_name":"Sam Rahimi","creator_url":"https://huggingface.co/DeFactOfficial","description":"DeFactOfficial/diffusion-models-hf-hub dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","image-to-image","text-generation","mit","Image"],"keywords_longer_than_N":true},
	{"name":"watercolour2k","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jtorregrosa/watercolour2k","creator_name":"Jorge Torregrosa Lloret","creator_url":"https://huggingface.co/jtorregrosa","description":"jtorregrosa/watercolour2k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","mit","10K<n<100K","Image","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"prl_crimson_maiden_style","keyword":"text-to-image","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paralaif/prl_crimson_maiden_style","creator_name":"paralaif","creator_url":"https://huggingface.co/paralaif","description":"\\n\\t\\n\\t\\t\\n\\t\\tprl_crimson_maiden_style Dataset\\n\\t\\n\\nThis dataset is used to train my lora Crimson Maiden from Civitai.\\n","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"myanmar-written-corpus","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/myanmar-written-corpus","creator_name":"WYC","creator_url":"https://huggingface.co/freococo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMyanmar Written Corpus\\n\\t\\n\\nThe Myanmar Written Corpus is a comprehensive collection of high-quality written Myanmar text, designed to address the lack of large-scale, openly accessible resources for Myanmar Natural Language Processing (NLP). It is tailored to support various tasks such as text-to-speech (TTS), automatic speech recognition (ASR), translation, text generation, and more.\\nThis dataset serves as a critical resource for researchers and developers aiming to advance Myanmar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/myanmar-written-corpus.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-speech","Burmese","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"libritts-r-mimi","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jkeisling/libritts-r-mimi","creator_name":"Jacob Keisling","creator_url":"https://huggingface.co/jkeisling","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLibriTTS-R Mimi encoding\\n\\t\\n\\nThis dataset converts all audio in the dev.clean, test.clean, train.100 and train.360 splits of the LibriTTS-R dataset from waveforms to tokens in Kyutai's Mimi neural codec.\\nThese tokens are intended as targets for DualAR audio models, but also allow you to simply download all audio in ~50-100x less space, if you're comfortable decoding later on with rustymimi or Transformers.\\nThis does NOT contain the original audio, please use the regular LibriTTS-R‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jkeisling/libritts-r-mimi.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"e621_2024-latents-sdxl-1ktar","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/e621_2024-latents-sdxl-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\\n\\t\\n\\t\\t\\n\\t\\tE621 2024 SDXL VAE latents in 1k tar\\n\\t\\n\\n\\nDedicated dataset to align both NebulaeWis/e621-2024-webp-4Mpixel and deepghs/e621_newest-webp-4Mpixel. \\\"4MP-Focus\\\" for average raw image resolution. \\nLatents are ARB with maximum size of 1024x1024 as the recommended setting in kohyas. Major reason is to make sure I can finetune with RTX 3090. VRAM usage will raise drastically after 1024.\\nGenerated from prepare_buckets_latents_v2.py, modified from prepare_buckets_latents.py.\\nUsed for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/e621_2024-latents-sdxl-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"danbooru2025-metadata","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/danbooru2025-metadata","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Danbooru 2025 Metadata\\n\\t\\n\\nLatest Post ID: 8,877,698 (as of February 18, 2025)\\nThis repository provides a comprehensive, up-to-date metadata dump for Danbooru. The metadata was freshly scraped starting January 2, 2025, featuring more extensive tag annotations for older posts, fewer errors, and fewer unlabeled AI-generated images compared to previous scrapes.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nOverview\\nDanbooru is a well-known imageboard focusing on anime-style artwork, hosting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trojblue/danbooru2025-metadata.","first_N":5,"first_N_keywords":["text-to-image","image-classification","English","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"SIWIS_French_Speech_Synthesis_Database","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database","creator_name":"Anthonny Olime","creator_url":"https://huggingface.co/Aviv-anthonnyolime","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIWIS French Speech Synthesis Database\\n\\t\\n\\nThis README provides a concise description of the dataset, including its structure, file naming conventions, and known labeling issues. Additionally, suggestions for potential improvements are outlined in the TODO section.  \\nThe dataset is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting its use for any purpose.  \\nFor more details about the database design and recording process, please‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","French","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dataset_for_STT_TTSmodels","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/dataset_for_STT_TTSmodels","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/dataset_for_STT_TTSmodels dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"waikato_aerial_2017_sd_ft","keyword":"text-to-image","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dushj98/waikato_aerial_2017_sd_ft","creator_name":"Dinushi Jayasinghe","creator_url":"https://huggingface.co/dushj98","description":"This is a re-upload of a random sample of 260 images + curresponding blip captions obtained from the original waikato_aerial_imagery_2017 classification dataset residing at https://datasets.cms.waikato.ac.nz/taiao/waikato_aerial_imagery_2017/ under the same license. You can find additional dataset information using the provided URL.  \\nThe BLIP model used for captioning: Salesforce/blip-image-captioning-large  \\nThe images belong to 13 unique categories and each caption contains a unique token‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dushj98/waikato_aerial_2017_sd_ft.","first_N":5,"first_N_keywords":["text-to-image","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"natasha_sova_ai","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/intexcp/natasha_sova_ai","creator_name":"Ivan","creator_url":"https://huggingface.co/intexcp","description":"This is a saved natasha dataset from SOVA AI\\n","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","1B<n<10B","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"ruslan_sova_ai","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/intexcp/ruslan_sova_ai","creator_name":"Ivan","creator_url":"https://huggingface.co/intexcp","description":"This is a saved ruslan dataset from SOVA AI\\n","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"Step-Video-T2V-Eval","keyword":"text-to-video","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stepfun-ai/Step-Video-T2V-Eval","creator_name":"StepFun","creator_url":"https://huggingface.co/stepfun-ai","description":"This dataset contains the data of the paper Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model.\\nCode: https://github.com/stepfun-ai/Step-Video-T2V\\nProject page: https://yuewen.cn/videos\\n","first_N":5,"first_N_keywords":["text-to-video","mit","< 1K","Video","Datasets"],"keywords_longer_than_N":true},
	{"name":"HumanEval-V-Benchmark","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HumanEval-V/HumanEval-V-Benchmark","creator_name":"HumanEval-V","creator_url":"https://huggingface.co/HumanEval-V","description":"\\n\\t\\n\\t\\t\\n\\t\\tHumanEval-V: Benchmarking High-Level Visual Reasoning with Complex Diagrams in Coding Tasks\\n\\t\\n\\n\\n    üìÑ Paper  ‚Ä¢\\n    üè† Home Page ‚Ä¢\\n    üíª GitHub Repository  ‚Ä¢\\n    üèÜ Leaderboard ‚Ä¢\\n    ü§ó Dataset Viewer \\n\\n\\nHumanEval-V is a novel benchmark designed to evaluate the diagram understanding and reasoning capabilities of Large Multimodal Models (LMMs) in programming contexts. Unlike existing benchmarks, HumanEval-V focuses on coding tasks that require sophisticated visual reasoning over‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HumanEval-V/HumanEval-V-Benchmark.","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-to-audio","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"video-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"ChronoMagic","keyword":"text-to-video","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/buraska/ChronoMagic","creator_name":"vadim zolotarenko","creator_url":"https://huggingface.co/buraska","description":"\\n\\n\\n MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators\\n\\n If you like our project, please give us a star ‚≠ê on GitHub for the latest update.  \\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüê≥ ChronoMagic Dataset\\n\\t\\n\\nChronoMagic with 2265 metamorphic time-lapse videos, each accompanied by a detailed caption. We released the subset of ChronoMagic used to train MagicTime. The dataset can be downloaded at HuggingFace Dataset, or you can download it with the following command. Some samples can be found on our Project‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/buraska/ChronoMagic.","first_N":5,"first_N_keywords":["text-to-video","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"tts-test2","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deniskaanalpay/tts-test2","creator_name":"denis kaan alpay","creator_url":"https://huggingface.co/deniskaanalpay","description":"deniskaanalpay/tts-test2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Turkish","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"RSTeller_metadata","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SlytherinGe/RSTeller_metadata","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","description":"\\n\\t\\n\\t\\t\\n\\t\\tMetadata for RSTeller\\n\\t\\n\\nThis dataset contains the necessary metadata for the dataset SlytherinGe/RSTeller.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThe metadata table provides detailed information for the RSTeller dataset, with the following columns:\\n\\npatch_id: The primary key of the table, corresponding to the \\\"__key__\\\" or the \\\"patch_id\\\" field in the JSON of the RSTeller dataset.\\n\\npatch_lat and patch_lon: The latitude and longitude coordinates of the patch center in WGS84‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller_metadata.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","zero-shot-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"RSTeller","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SlytherinGe/RSTeller","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","description":"\\n\\t\\n\\t\\t\\n\\t\\t‚ö†Ô∏è Usage Warning\\n\\t\\n\\nThis is the latest version of RSTeller, updated on 2025-01-28. Users who accessed this dataset before this date can find the legacy version, which is preserved for reference. Additionally, we have released the metadata for this dataset.\\nFor the details and the usage of the dataset, please refer to our github page.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find the dataset and our paper useful, please consider citing our paper:\\n@misc{ge2025rstellerscalingvisuallanguage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","zero-shot-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"my_dataset_2","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kashif314/my_dataset_2","creator_name":"kashif","creator_url":"https://huggingface.co/kashif314","description":"kashif314/my_dataset_2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Urdu","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"danbooru2023-captions-1ktar","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/danbooru2023-captions-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\\n\\t\\n\\t\\t\\n\\t\\tDanbooru 2023 captions only in 1k tar\\n\\t\\n\\n\\nRaw captions jointed by unpublished extended dataset from KBlueLeaf/danbooru2023-metadata-database\\n\\nIt aligns to nyanko7/danbooru2023. There are around 200k missing for the 2024 version, I'll try to use Minthy/ToriiGate-v0.4-7B to fill in the rest.\\n\\nmeta_cap.json has been provided in compressed format if you want to train with kohyas triner. Currently I'm trying to merge this with my 2024 version.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCore logic\\n\\t\\n\\n\\nThe script building‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2023-captions-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"sTinyStories","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/sTinyStories","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\\n\\t\\n\\t\\t\\n\\t\\tsTinyStories\\n\\t\\n\\nA spoken version of TinyStories Synthesized with LJ voice using FastSpeech2.\\nThe dataset was synthesized to boost the training of Speech Language Models as detailed in the paper \\\"Slamming: Training a Speech Language Model on One GPU in a Day\\\".\\nIt was first suggested by Cuervo et. al 2024.\\nWe refer you to the SlamKit codebase to see how you can train a SpeechLM with this dataset.\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets importload_dataset\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slprl/sTinyStories.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"M2RAG","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/whalezzz/M2RAG","creator_name":"Tianshuo Zhou","creator_url":"https://huggingface.co/whalezzz","description":"\\n\\t\\n\\t\\t\\n\\t\\tData statices of M2RAG\\n\\t\\n\\nClick the links below to view our paper and Github project.\\n\\nIf you find this work useful, please cite our paper  and give us a shining star üåü in Github \\n@misc{liu2025benchmarkingretrievalaugmentedgenerationmultimodal,\\n      title={Benchmarking Retrieval-Augmented Generation in Multi-Modal Contexts}, \\n      author={Zhenghao Liu and Xingsheng Zhu and Tianshuo Zhou and Xinyi Zhang and Xiaoyuan Yi and Yukun Yan and Yu Gu and Ge Yu and Maosong Sun}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/whalezzz/M2RAG.","first_N":5,"first_N_keywords":["text-to-image","visual-question-answering","English","mit","Image"],"keywords_longer_than_N":true},
	{"name":"ABC-Pretraining-Data","keyword":"image-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/ABC-Pretraining-Data","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tABC Pretraining Data\\n\\t\\n\\n\\nThis the the pretraining data for ABC. This dataset is derived from Google's Conceptual Captions dataset.\\nThe each item in the dataset contain a URL where the corresponding image can be downloaded. Full dataaset is ~300 GB of images.\\n\\n\\t\\n\\t\\t\\n\\t\\tPaper and Website\\n\\t\\n\\nFor more information, please refer to Website.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{schneider2025abcachievingbettercontrol,\\n      title={ABC: Achieving Better Control of Multimodal Embeddings using VLMs}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/ABC-Pretraining-Data.","first_N":5,"first_N_keywords":["visual-question-answering","image-text-to-text","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ABC-VG-Instruct","keyword":"image-text-to-text","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/ABC-VG-Instruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tVG Instruct\\n\\t\\n\\nThis is the instruction finetuning dataset for ABC: Achieving better control of multimodal embeddings using VLMs.\\nEach element in this dataset contains 4 instruction-captions pairs for images in the visual genome dataset, corresponding to different bounding boxes in the image.\\nWe use this dataset to train an embedding model that can use instruction to embeds specific aspects of a scene.\\n\\nCombined with our pretraining step, this results in a model that can create high‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/ABC-VG-Instruct.","first_N":5,"first_N_keywords":["image-text-to-text","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-crh-abibullah","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/tts-crh-abibullah","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":" \\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOpen Source Crimean Tatar Text-to-Speech datasets\\n\\t\\n\\nThis is subset of Abibullah voice with train/test splits.\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tStatistics\\n\\t\\n\\n\\nQuality: high\\nDuration: 2h50m\\nFrequency: 48 kHz\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCite this work\\n\\t\\n\\n@misc {smoliakov_2025,\\n    author       = { {Smoliakov} },\\n    title        = { qirimtatar-tts (Revision c2ceec6)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-abibullah.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-crh-sevil","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/tts-crh-sevil","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":" \\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOpen Source Crimean Tatar Text-to-Speech datasets\\n\\t\\n\\nThis is subset of Sevil voice with train/test splits.\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tStatistics\\n\\t\\n\\n\\nQuality: high\\nDuration: 2h29m\\nFrequency: 48 kHz\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCite this work\\n\\t\\n\\n@misc {smoliakov_2025,\\n    author       = { {Smoliakov} },\\n    title        = { qirimtatar-tts (Revision c2ceec6) }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-sevil.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-crh-arslan","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/tts-crh-arslan","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":" \\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOpen Source Crimean Tatar Text-to-Speech datasets\\n\\t\\n\\nThis is subset of Arslan voice with train/test splits.\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tStatistics\\n\\t\\n\\n\\nQuality: high\\nDuration: 1h20m\\nFrequency: 48 kHz\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCite this work\\n\\t\\n\\n@misc {smoliakov_2025,\\n    author       = { {Smoliakov} },\\n    title        = { qirimtatar-tts (Revision c2ceec6) }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-arslan.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-tetiana","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-tetiana","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCite this work\\n\\t\\n\\n@misc {smoliakov_2025,\\n    author       = { {Smoliakov} },\\n    title        = { opentts-uk (Revision 32abc9c) },\\n    year         = 2025,\\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-tetiana.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-mykyta","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-mykyta","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCite this work\\n\\t\\n\\n@misc {smoliakov_2025,\\n    author       = { {Smoliakov} },\\n    title        = { opentts-uk (Revision 32abc9c) },\\n    year         = 2025,\\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-mykyta.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"GenVerse","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/GenVerse","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"TaiMingLu/GenVerse dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"syntetic_necoarc_rus","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kostya165/syntetic_necoarc_rus","creator_name":"pleroma_cascade","creator_url":"https://huggingface.co/Kostya165","description":"\\n\\t\\n\\t\\t\\n\\t\\t–û–ø–∏—Å–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\\n\\t\\n\\n–≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏, –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ RVC (Retrieval-based Voice Conversion) NecoArc. –î–∞—Ç–∞—Å–µ—Ç –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π —Å–∏–Ω—Ç–µ–∑–∞ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\\n–Ø –Ω–µ –æ—Å–∏–ª–∏–ª —Ñ–∞–π–Ω—Ç—é–Ω TTS –º–æ–¥–µ–ª–∏ –ª–µ–≥–∫–æ–≤–µ—Å–Ω–æ–π , —Ç–∞–∫ —á—Ç–æ –µ—Å–ª–∏ —Å–º–æ–∂–µ—Ç–µ —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –±—É–¥—É –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω –∑–∞ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å\\n\\n–Ø–∑—ã–∫: –†—É—Å—Å–∫–∏–π\\n–õ–∏—Ü–µ–Ω–∑–∏—è: MIT\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\\n\\t\\n\\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø–æ–ª—è:\\n\\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kostya165/syntetic_necoarc_rus.","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Emilia-YODAS","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrfakename/Emilia-YODAS","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"siglip-recursion-ffhq-thumbnails","keyword":"text-to-image","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hibana2077/siglip-recursion-ffhq-thumbnails","creator_name":"XUAN-HAO LI","creator_url":"https://huggingface.co/hibana2077","description":"\\n\\t\\n\\t\\t\\n\\t\\tSIGLIP-Recursion-FFHQ-ThumbNail\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLabels\\n\\t\\n\\n‚Ä¢\\tsmileÔºösmiling, no smile\\n‚Ä¢\\tpitchÔºödownward, neutral, upward\\n‚Ä¢\\trollÔºötilted, neutral\\n‚Ä¢\\tyawÔºöturned left, frontal, turned right\\n‚Ä¢\\tgenderÔºömale, female\\n‚Ä¢\\tageÔºöadult, baby, child, teenager, senior\\n‚Ä¢\\tfacialHairÔºömoustache, beard, sideburns, none\\n‚Ä¢\\tglassesÔºöNoGlasses, SwimmingGoggles, Sunglasses, ReadingGlasses\\n‚Ä¢\\temotionÔºöhappiness, sadness, surprise, contempt, disgust, neutral, anger, fear\\n‚Ä¢\\tblurÔºöhigh, medium, low\\n‚Ä¢\\texposureÔºögoodExposure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hibana2077/siglip-recursion-ffhq-thumbnails.","first_N":5,"first_N_keywords":["text-to-image","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"SyntheticFurGroundtruth","keyword":"text-to-image","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BXYMartin/SyntheticFurGroundtruth","creator_name":"Martin Bai","creator_url":"https://huggingface.co/BXYMartin","description":"\\n\\t\\n\\t\\t\\n\\t\\tProcessed Synthetic Fur Dataset\\n\\t\\n\\nThis dataset is part of the dataset located here https://github.com/google-research-datasets/synthetic-fur, with modifications to keep only the ground truth samples and add correponding description ending in *.txt.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nContains high-quality synthetic rendered fur in static and moving scenes, with different lightning conditions.\\n","first_N":5,"first_N_keywords":["text-to-image","image-to-image","apache-2.0","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"ECG-Grounding","keyword":"image-text-to-text","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LANSG/ECG-Grounding","creator_name":"LAN XIANG","creator_url":"https://huggingface.co/LANSG","description":"\\n\\t\\n\\t\\t\\n\\t\\tECG-Grounding dataset\\n\\t\\n\\nECG-Grounding provides more accurate, holistic, and evidence-driven interpretations with diagnoses grounded in measurable ECG features.¬†Currently, it contains 30,000 instruction pairs annotated with heartbeat-level physiological features. This is the first high-granularity ECG grounding dataset, enabling evidence-based diagnosis and improving the trustworthiness of medical AI. We will continue to release more ECG-Grounding data and associated beat-level‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LANSG/ECG-Grounding.","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true}
]
;
