var data_for_speech_recognition = 
[
	{"name":"pseudostreaming-malaya-speech-stt","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mesolitica/pseudostreaming-malaya-speech-stt","creator_name":"Mesolitica","creator_url":"https://huggingface.co/mesolitica","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPseudostreaming Malaya-Speech STT\\n\\t\\n\\nOriginal dataset at https://github.com/mesolitica/malaysian-dataset/tree/master/speech-to-text-semisupervised/pseudolabel-malaya-speech-stt\\nWe use https://huggingface.co/mesolitica/conformer-medium-mixed to generate pseudostreaming dataset, source code at https://github.com/mesolitica/malaysian-dataset/tree/master/speech-to-text-semisupervised/pseudostreaming-malaya-speech-stt\\nTotal 8667.802379812754 hours.\\ndata format from processed.jsonl,\\n[… See the full description on the dataset page: https://huggingface.co/datasets/mesolitica/pseudostreaming-malaya-speech-stt."},
	{"name":"pseudostreaming-malaysian-youtube-whisper-large-v3","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mesolitica/pseudostreaming-malaysian-youtube-whisper-large-v3","creator_name":"Mesolitica","creator_url":"https://huggingface.co/mesolitica","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPseudostreaming Malaysian Youtube videos using Whisper Large V3\\n\\t\\n\\nOriginal dataset at https://huggingface.co/datasets/mesolitica/pseudolabel-malaysian-youtube-whisper-large-v3\\nWe use https://huggingface.co/mesolitica/conformer-medium-mixed to generate pseudostreaming dataset, source code at https://github.com/mesolitica/malaysian-dataset/tree/master/speech-to-text-semisupervised/pseudostreaming-whisper\\nTotal 40486.589364839296 hours.\\ndata format from processed.jsonl,\\n[\\n  {… See the full description on the dataset page: https://huggingface.co/datasets/mesolitica/pseudostreaming-malaysian-youtube-whisper-large-v3."},
	{"name":"Indic-subtitler-audio_evals","keyword":"automatic-speech-recognition","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals","creator_name":"Kurian Benoy","creator_url":"https://huggingface.co/kurianbenoy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic_audio_evals\\n\\t\\n\\nAs part of this project. We are evaluating our performance of various ASR models as well\\nin a benchmarking dataset, we have created in various languages. This benchmarking dataset\\nis more alligned to real-world use-cases rather than having any academic datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout Dataset\\n\\t\\n\\n\\nDataset Link in HuggingFace: kurianbenoy/Indic-subtitler-audio_evals\\n\\nThis dataset contains audio file in .wav format and video file in .mp4. The respective groundtruth… See the full description on the dataset page: https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals."},
	{"name":"tts-rj-hi-karya","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/tts-rj-hi-karya","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRajasthani Hindi Speech Dataset\\n\\t\\n\\n\\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. They had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426872 recordings in this dataset. They had roughly 58 male participants and 40 female participants.\\n\\nPoint to Note:\\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the… See the full description on the dataset page: https://huggingface.co/datasets/1rsh/tts-rj-hi-karya."},
	{"name":"speech-rj-hi","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/speech-rj-hi","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRajasthani Hindi Speech Dataset\\n\\t\\n\\n\\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. We had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426873 recordings in this dataset. We had roughly 58 male participants and 40 female participants.\\n\\nPoint to Note:\\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences… See the full description on the dataset page: https://huggingface.co/datasets/severo/speech-rj-hi."},
	{"name":"fpt_fosd","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/fpt_fosd","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of FPT Open Speech Dataset (FOSD)\\n\\t\\n\\nreleased publicly in 2018 by FPT Corporation\\n100h, 25.9k samples\\nofficial link (dead): https://fpt.ai/fpt-open-speech-data/\\nmirror: https://data.mendeley.com/datasets/k9sxg2twv4/4\\nDOI: 10.17632/k9sxg2twv4.4\\npre-process:\\n\\nremove non-sense strings: -N \\\\r\\\\n\\nremove 4 files because missing transcription:\\nSet001_V0.1_008210.mp3\\nSet001_V0.1_010753.mp3\\nSet001_V0.1_011477.mp3\\nSet001_V0.1_011841.mp3\\n\\n\\n\\nneed to do: check misspelling\\nusage… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/fpt_fosd."},
	{"name":"infore2_audiobooks","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore2_audiobooks","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of InfoRe Technology public dataset №2\\n\\t\\n\\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\\n415h, 315k samples, vietnamese audiobooks of chinese wǔxiá 武俠 & xiānxiá 仙俠\\nbộ dữ liệu bóc ra từ YouTube đọc truyện võ hiệp & tiên hiệp, áp dụng kĩ thuật đối chiếu văn bản để dán nhãn tự động\\nofficial download:… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore2_audiobooks."},
	{"name":"nst-da-norm","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NST-da Normalized\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): da\\nLicense: cc0-1.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses… See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm."},
	{"name":"medical","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/offbeatPickle/medical","creator_name":"Samhita Marri","creator_url":"https://huggingface.co/offbeatPickle","description":"offbeatPickle/medical dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sebut-perkataan","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mesolitica/sebut-perkataan","creator_name":"Mesolitica","creator_url":"https://huggingface.co/mesolitica","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSebut Perkataan\\n\\t\\n\\n\\nsebut-perkataan-man voice by Husein Zolkepli\\ntolong-sebut voice by Khalil Nooh\\nsebut-perkataan-woman voice by Mas Aisyah Ahmad\\nRecorded using low-end tech microphones.\\n\\n"},
	{"name":"luna-speech-dataset","keyword":"automatic-speech-recognition","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/luna-speech-dataset","creator_name":"Mateusz Czyżnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This speech dataset consists of 10385 short audio clips of multiple speakers conversing in Polish. A transcription is provided for each clip, also gender of speaker is provided for part of the dataset. Clips have total length of almost 10 hours.\\nThis dataset was created from LUNA dataset of human-human and human-computer dialogues on the topic of public transport. The postprocessing consisted of extracting segments with human speech together with their transcripts. If you are interested in the… See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/luna-speech-dataset."},
	{"name":"asr-farsi-youtube-chunked-30-seconds","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/asr-farsi-youtube-chunked-30-seconds","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow To Use\\n\\t\\n\\nfrom datasets import load_dataset\\ntrain = load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='train+val')\\ntest =load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='test')\\n\\n+300 Hours ASR dataset generated from this kaggle dataset\\n"},
	{"name":"Hokchia","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yjhuang01/Hokchia","creator_name":"Yijun Huang","creator_url":"https://huggingface.co/yjhuang01","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHokchia Audio Dataset\\n\\t\\n\\nHokchia, or the Fuqing dialect, is a branch of Eastern Min Chinese spoken mainly in the Fuqing City of Fujian province, China. Unlike Hokkien, which is more widely recognized and spoken in various parts of Southeast Asia, Hokchia maintains its unique linguistic characteristics and is primarily used within the Fuqing community and its diaspora. This dialect is known for its distinct pronunciation, vocabulary, and grammatical structures compared to other Min… See the full description on the dataset page: https://huggingface.co/datasets/yjhuang01/Hokchia."},
	{"name":"Fleurs-Kn","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RaviNaik/Fleurs-Kn","creator_name":"Ravi Naik","creator_url":"https://huggingface.co/RaviNaik","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Sample:\\n\\t\\n\\n{'id': 1053,\\n 'num_samples': 226560,\\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\\n 'audio': {'path': 'train/10000267636955490843.wav',\\n  'array': array([ 0.        ,  0.… See the full description on the dataset page: https://huggingface.co/datasets/RaviNaik/Fleurs-Kn."},
	{"name":"Fleurs-Kn","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn","creator_name":"Kannada LLM Labs","creator_url":"https://huggingface.co/Kannada-LLM-Labs","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Sample:\\n\\t\\n\\n{'id': 1053,\\n 'num_samples': 226560,\\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\\n 'audio': {'path': 'train/10000267636955490843.wav',\\n  'array': array([ 0.        ,  0.… See the full description on the dataset page: https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn."},
	{"name":"Fleurs-Kn","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn","creator_name":"Indic-LLM-Labs","creator_url":"https://huggingface.co/Indic-LLM-Labs","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Sample:\\n\\t\\n\\n{'id': 1053,\\n 'num_samples': 226560,\\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\\n 'audio': {'path': 'train/10000267636955490843.wav',\\n  'array': array([ 0.        ,  0.… See the full description on the dataset page: https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn."},
	{"name":"movieAudio","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shaggysus/movieAudio","creator_name":"Sandun de silva","creator_url":"https://huggingface.co/shaggysus","description":"shaggysus/movieAudio dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"assamese_speech_corpus","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/madhabpaul/assamese_speech_corpus","creator_name":"Madhab Paul","creator_url":"https://huggingface.co/madhabpaul","description":"madhabpaul/assamese_speech_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"twi_dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d3vnerd/twi_dataset","creator_name":"jeffery crentsil","creator_url":"https://huggingface.co/d3vnerd","description":"d3vnerd/twi_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"bhojpuri","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
	{"name":"bhojpuri","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
	{"name":"jalandhary_asr","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirfan899/jalandhary_asr","creator_name":"Muhammad Irfan","creator_url":"https://huggingface.co/mirfan899","description":"Jalandhary dataset is created using whisper model for STT and TTS. Some audios are ommited due to issues while trimming them. If there are some isues \\nin the dataset or audio not matching the text you can start a discussion or ping me to correcting it. \\n"},
	{"name":"librispeech_asr_test_clean_word_timestamp","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/olympusmons/librispeech_asr_test_clean_word_timestamp","creator_name":"ML","creator_url":"https://huggingface.co/olympusmons","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWord-level timestamp annotated Librispeech ASR test set\\n\\t\\n\\nThis dataset contains word-level timestamp information for the Librispeech ASR test (clean) dataset.\\nIt contains 2620 short files that have been force-aligned with its text to get reasonably accurate word-level timestamp information.\\nSuitable for use in timestamp benchmarking of ASR models or audio dataset preprocessing.\\nTo request access to more datasets like this, please fill out this form:… See the full description on the dataset page: https://huggingface.co/datasets/olympusmons/librispeech_asr_test_clean_word_timestamp."},
	{"name":"cv-corpus-17.0-zh-CN-client_id-grouped","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcv-corpus-17.0-zh-CN-client_id-grouped\\n\\t\\n\\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nThe dataset is derived from the Common Voice dataset.\\nThe original dataset is available at Common Voice Dataset.\\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\\nEach group is filtered to include only client IDs with a minimum of 30 samples and a… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped."},
	{"name":"cv-corpus-17.0-zh-TW-client_id-grouped","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcv-corpus-17.0-zh-TW-client_id-grouped\\n\\t\\n\\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nThe dataset is derived from the Common Voice dataset.\\nThe original dataset is available at Common Voice Dataset.\\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\\nEach group is filtered to include only client IDs with a minimum of 30 samples and a… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped."},
	{"name":"cv-corpus-17.0-ja-client_id-grouped","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcv-corpus-17.0-ja-client_id-grouped\\n\\t\\n\\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nThe dataset is derived from the Common Voice dataset.\\nThe original dataset is available at Common Voice Dataset.\\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\\nEach group is filtered to include only client IDs with a minimum of 30 samples and a… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped."},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of 10K hours of English MLS\\n\\t\\n\\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated."},
	{"name":"pwr-azon-speech-dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/pwr-azon-speech-dataset","creator_name":"Mateusz Czyżnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This speech dataset consists of 15332 short audio clips of multiple speakers speaking in Polish. Transcription is provided for 14491 audio clips (train split), and it is missing for 841 audio clips (unsup split). Gender of speaker is provided for the whole dataset. Clips have total length of almost 31 hours.\\nThis dataset was created from Korpus nagrań próbek mowy do celów budowy modeli akustycznych dla automatycznego rozpoznawania mowy w języku polskim. The dataset was repackaged into easier… See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/pwr-azon-speech-dataset."},
	{"name":"px-corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bastiendechamps/px-corpus","creator_name":"Bastien Dechamps","creator_url":"https://huggingface.co/bastiendechamps","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPxCorpus : A Spoken Drug Prescription Dataset in French\\n\\t\\n\\nPxCorpus is to the best of our knowledge, the first spoken medical drug prescriptions corpus to be distributed. \\nIt contains 4 hours of transcribed and annotated dialogues of drug prescriptions in \\nFrench acquired through an experiment with 55 participants experts and non-experts  in drug prescriptions.\\nThe automatic transcriptions were verified by human effort and aligned with \\nsemantic labels to allow training of NLP… See the full description on the dataset page: https://huggingface.co/datasets/bastiendechamps/px-corpus."},
	{"name":"MEDISCO","keyword":"automatic-speech-recognition","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrqorib/MEDISCO","creator_name":"Reza Qorib","creator_url":"https://huggingface.co/mrqorib","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuilding MEDISCO: Indonesian Speech Corpus for Medical Domain\\n\\t\\n\\nThe dataset was published in the following paper:\\n\\nBuilding MEDISCO: Indonesian Speech Corpus for Medical Domain (PDF | IEEEXplore) \\nMuhammad Reza Qorib and Mirna Adriani \\n2018 International Conference on Asian Language Processing (IALP)\\n\\nPlease look for the raw files (inside the \\\"Files and versions\\\" tab) as the dataset viewer parsed by Huggingface does not show the text transcript.\\nPlease direct any questions to… See the full description on the dataset page: https://huggingface.co/datasets/mrqorib/MEDISCO."},
	{"name":"FLEURS-GA-EN","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThis is the Irish-to-English portion of the FLEURS dataset.\\nFleurs is the speech version of the FLoRes machine translation benchmark.\\nThe Irish portion consists of 3991 utterances, which correspond to approximately 16 hours and 45 minutes (16:45:17) of audio data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['id', 'audio', 'text_ga', 'text_en'],\\n        num_rows: 3991\\n    })\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN."},
	{"name":"SpokenWords-GA-EN-MTed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis is the Irish portion of the Spoken Words dataset (available at MLCommons/ml_spoken_words),\\nwith merged splits “train”, “validation”, and “test”, augmented with machine translation.\\nThe Irish sentences are automatically translated into English using Google Translation API.\\nThe dataset includes approximately 3 hours and 2 minutes of audio (03:02:02), spoken by multiple narrators.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features: ['keyword'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed."},
	{"name":"Living-Audio-Irish","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Living-Audio-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nLiving Audio Irish speech corpus. This version is based on the Irish dataset on Kaggle.\\nThe original dataset with audio in more languages is available on GitHub as part of the Idlak project.\\nThe details of the Irish portion of the Living Audio dataset are as follows:\\n\\n\\t\\n\\t\\t\\nSpeaker\\nLanguage\\nAccent\\nGender\\nTotal duration(mm:ss)\\nSample rate (Hz)\\n\\n\\n\\t\\t\\nCLL\\nIrish (ga)\\nNon-native (ie)\\nMan\\n61:56\\n48,000\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features:… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Living-Audio-Irish."},
	{"name":"BanglaEnglishMixedAsrDataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akhikhan123/BanglaEnglishMixedAsrDataset","creator_name":"Fatema Tuz Zohra Akhi","creator_url":"https://huggingface.co/akhikhan123","description":"akhikhan123/BanglaEnglishMixedAsrDataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"chuvash_voice","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexantonov/chuvash_voice","creator_name":"Alexander Antonov","creator_url":"https://huggingface.co/alexantonov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use\\n\\t\\n\\nWe recommend using our dataset in conjunction with the Common Voice Corpus. We have attempted to maintain a consistent structure.\\nfrom datasets import load_dataset, DatasetDict, concatenate_datasets, Audio\\n\\ncomm_voice = DatasetDict()\\ncomm_voice[\\\"train\\\"] = load_dataset(\\\"mozilla-foundation/common_voice_17_0\\\", \\\"cv\\\", split=\\\"train+validation\\\", use_auth_token=True)\\ncomm_voice[\\\"test\\\"] = load_dataset(\\\"mozilla-foundation/common_voice_17_0\\\", \\\"cv\\\", split=\\\"test\\\"… See the full description on the dataset page: https://huggingface.co/datasets/alexantonov/chuvash_voice."},
	{"name":"arabic_speech_corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Arabic Speech Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton. The corpus was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe… See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus."},
	{"name":"tele_con_ciencia","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/tele_con_ciencia","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tele_con_ciencia\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAccording to the Facebook page of Tele con Ciencia:\\n\\\"Nuestra misión es la comunicación pública de la ciencia y la tecnología mexicana. El objetivo, \\nla participación activa de todos los mexicanos en las áreas del descubrimiento científico y el \\ndesarrollo tecnológico.\\\"\\n\\\"Our mission is to spread the achievements of the Mexican Science and Technology. The main goal\\nis to promote the active participation of mexican… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/tele_con_ciencia."},
	{"name":"librivox_spanish","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/librivox_spanish","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for librivox_spanish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLibrivox is a non-commercial, non-profit and ad-free project that is dedicated to make all books in the public domain available, for free, in audio format on the internet. According to this, we downloaded 300 titles in Spanish to create the LIBRIVOX SPANISH CORPUS.\\nThe LIBRIVOX SPANISH CORPUS has a duration of 73 hours and it is constituted by audio files between 3 and 10 seconds long, manually segmented.… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/librivox_spanish."},
	{"name":"voxforge_spanish","keyword":"automatic-speech-recognition","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/voxforge_spanish","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for voxforge_spanish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nVoxForge was set up to collect transcribed speech for use with Free and Open Source Speech Recognition Engines (on Linux, Windows and Mac). They promise they will make available all submitted audio files under the GPL license, and then 'compile' them into acoustic models for use with Open Source speech recognition engines such as CMU Sphinx, ISIP, Julius and HTK. According to this, we downloaded the Spanish… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/voxforge_spanish."},
	{"name":"shrutilipi","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of 10K hours of English MLS\\n\\t\\n\\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K… See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated."},
	{"name":"vais1000","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vais1000","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of VAIS-1000\\n\\t\\n\\nofficial announcement: https://vais.vn/vi/tai-ve/hts_for_vietnamese (dead)\\nmirror: https://github.com/undertheseanlp/text_to_speech/tree/run/data/vais1000/raw\\nsmall only 1h40min audio - 1 speaker (female northern accent) - 1k samples\\npre-process: none\\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\\nusage with HuggingFace:\\n# pip install -q \\\"datasets[audio]\\\"\\nfrom datasets import load_dataset\\nfrom torch.utils.data import… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vais1000."},
	{"name":"Tatoeba-Speech-Irish","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nSynthetic audio dataset, created using Azure text-to-speech service.\\nThe bilingual text is a portion of the Tatoeba dataset, consisting of 1,983 text segments.\\nThe dataset consists of two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\\nThe speech data comprises approximately 2 hours and 39 minutes (02:39:31) spread across 3,966 utterances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features: ['audio'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish."},
	{"name":"Wikimedia-Speech-Irish","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nSynthetic audio dataset, created using Azure text-to-speech service.\\nThe bilingual text is a portion of the Wikimedia dataset, consisting of 7,545 text segments.\\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\\nThe speech data comprises approximately 34 hours and 23 minutes (34:23:12) spread across 15,090 utterances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features: ['audio'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish."},
	{"name":"parler-tts_mls_eng_10k_snac_token_old","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blanchon/parler-tts_mls_eng_10k_snac_token_old","creator_name":"Julien BLANCHON","creator_url":"https://huggingface.co/blanchon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/blanchon/parler-tts_mls_eng_10k_snac_token_old."},
	{"name":"gujarati-f-openslr","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/gujarati-f-openslr","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGujarati OpenSLR Female\\n\\t\\n\\nInterspeech data downloaded from https://www.openslr.org/resources/78/gu_in_female.zip\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nGujarati Data (Most of the entries are <30 seconds and hence Whisper Models can be used for accurate timestamp prediction)\\nAlso, the audio seems to have been spoken by a single female.\\n\\n"},
	{"name":"mixed_shona_dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kittech/mixed_shona_dataset","creator_name":"Bright Chirindo","creator_url":"https://huggingface.co/Kittech","description":"Kittech/mixed_shona_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"kikongo-bible-asr","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/kikongo-bible-asr","creator_name":"NIONGOLO Chrys Fé-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKikongo Bible ASR\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/kikongo-bible-asr."},
	{"name":"killkan","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ctaguchi/killkan","creator_name":"Chihiro Taguchi","creator_url":"https://huggingface.co/ctaguchi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKillkan: Speech Recognition dataset for Kichwa\\n\\t\\n\\nKillkan (Kichwa uyachkata payllatak killkak anta) is the first automatic speech recognition (ASR) dataset for the Kichwa language.\\nSee also our paper (https://arxiv.org/abs/2404.15501).\\n"},
	{"name":"ewe_bible_v1","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEwe bible for Text-to-Speech\\n\\t\\n\\n"},
	{"name":"twi_bible_v1","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTwi Text-to-Speech\\n\\t\\n\\n"},
	{"name":"ewe_bible_v2_tts","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tText-to-Speech\\n\\t\\n\\n"},
	{"name":"twi_bible_v2_tts","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tText-to-Speech Dataset\\n\\t\\n\\n"},
	{"name":"EUbookshop-Speech-Irish","keyword":"automatic-speech-recognition","license":"European Union Public License 1.1","license_url":"https://choosealicense.com/licenses/eupl-1.1/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nSynthetic audio dataset, created using Azure text-to-speech service.\\nThe bilingual text is a portion of the EUbookshop dataset, consisting of 33,634 text segments.\\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\\nThe speech data comprises approximately 159 hours and 45 minutes (159:45:05) spread across 67,268 utterances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset({\\n    features: ['audio'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish."},
	{"name":"mother_tongue_dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MothersTongue/mother_tongue_dataset","creator_name":"Patronela  Tiwaringe ","creator_url":"https://huggingface.co/MothersTongue","description":"MothersTongue/mother_tongue_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de Mécanique des Structures et des Systèmes Couplés","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\\nIt is not intended for training.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnhancement procedure\\n\\t\\n\\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRessources\\n\\t\\n\\nResults for speech-to-phoneme… See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN."},
	{"name":"fleurs_clean","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
	{"name":"ESLTTS","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/ESLTTS","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tESLTTS\\n\\t\\n\\nThe full paper can be accessed here: arXiv, IEEE Xplore.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Access\\n\\t\\n\\nYou can access this dataset through Huggingface or Google Driver or IEEE Dataport.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbstract\\n\\t\\n\\nWith the progress made in speaker-adaptive TTS approaches, advanced approaches have shown a remarkable capacity to reproduce the speaker’s voice in the commonly used TTS datasets. However, mimicking voices characterized by substantial accents, such as non-native English speakers… See the full description on the dataset page: https://huggingface.co/datasets/MushanW/ESLTTS."},
	{"name":"fleurs_clean","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
	{"name":"Clapping_Sound_Dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/Clapping_Sound_Dataset","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/Clapping_Sound_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sampleDental","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/srirama/sampleDental","creator_name":"srirama","creator_url":"https://huggingface.co/srirama","description":"srirama/sampleDental dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Speech-MASSIVE_vie","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/Speech-MASSIVE_vie","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVietnamse subset of the Speech-MASSIVE dataset\\n\\t\\n\\nextracted from:\\n\\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE\\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE-test\\n\\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-speechmassive.py\\n"},
	{"name":"ASCEND-phoneme","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/katyayego/ASCEND-phoneme","creator_name":"Katya Yegorova","creator_url":"https://huggingface.co/katyayego","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a modified version of the ASCEND dataset which consists of spontaneous Mandarin-English code-switched speech. The ASCEND dataset was published by Lovenia et al. (2022) (Check here for the dataset and here for the paper). \\nThis dataset adds a phonetic transcription column to the dataset using the eSpeak backend from the phonemizer library created by Bernard et al. (2021) (Check it out here).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tthe following documentation is a modified… See the full description on the dataset page: https://huggingface.co/datasets/katyayego/ASCEND-phoneme."},
	{"name":"BibleMMS_vie","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/BibleMMS_vie","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVietnamse subset of the BibleMMS dataset\\n\\t\\n\\nextracted from: https://huggingface.co/datasets/Flux9665/BibleMMS\\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-biblemms.py\\n"},
	{"name":"yogera_runyankore_ailab","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shawal777/yogera_runyankore_ailab","creator_name":"Shawal Mbalire","creator_url":"https://huggingface.co/Shawal777","description":"Shawal777/yogera_runyankore_ailab dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"VietMed_unlabeled","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) unlabeled set\\n\\t\\n\\nofficial announcement: https://arxiv.org/abs/2404.05659\\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\\nthis repo contains the unlabeled set: 966h - 230k samples\\ni also gather the metadata: see info.csv\\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-unlabeled.py\\nneed to do: check misspelling, restore foreign words phonetised… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled."},
	{"name":"VietMed_labeled","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_labeled","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) labeled set\\n\\t\\n\\nofficial announcement: https://arxiv.org/abs/2404.05659\\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\\nthis repo contains the labeled set: 9.2k samples\\ni also gather the metadata: see info.csv\\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-labeled.py\\nneed to do: check misspelling, restore foreign words phonetised to vietnamese… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_labeled."},
	{"name":"stock_market_asx_audio","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sdeering/stock_market_asx_audio","creator_name":"Sam","creator_url":"https://huggingface.co/sdeering","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Stock Market ASX Audio\\n\\t\\n\\nContains audios for every listed company on the Australian Stock Exchange (ASX). The dataset contains 2329 audio files of people saying the name of the company.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nsentence_id (string): An id for the sentence used for the recording.\\nvoice_id (string): An id for which client (voice) made the recording.\\naudio (dict): A dictionary containing the path to the downloaded audio file.\\nsentence (string): The sentence the… See the full description on the dataset page: https://huggingface.co/datasets/sdeering/stock_market_asx_audio."},
	{"name":"Libriheavy-HQ","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Libriheavy-HQ\\n\\t\\n\\n\\n\\nLibriheavy: a 50,000 hours ASR corpus with punctuation casing \\nand context. Libriheavy is a labeled version of Libri-Light.\\nLibriheavy-HQ replaces the default Libri-Light audio files with the highest quality available versions from librivox \\nwithout re-encoding them. \\nIn most cases, this consists an upgrade of the source audio from a 64kbps .mp3 to a 128kbps .mp3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the Libriheavy-HQ dataset, adapted for the datasets… See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ."},
	{"name":"librivox-tracks","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
	{"name":"uz-data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uz-data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uz-data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"UZ_voice","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/UZ_voice","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/UZ_voice dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"STT_uz","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/STT_uz","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"The dataset is organized into the following directories and files:\\naudio/\\nother/: Contains .tar archives like uz_other_0.taruz_other_1.tar\\ntrain/: Contains .tar archives like uz_train_0.tar.\\nvalidated/: Contains .tar archives like uz_validated_0.tar, uz_validated_1.tar, and uz_validated_2.tar.\\ntest/: Contains individual .wav files.\\ntranscription/: Contains .tsv files including:\\nother.tsv\\ntrain.tsv\\nvalidated.tsv\\ntest.tsv\\nThe .tsv files have two columns: file_name and transcription. Each entry… See the full description on the dataset page: https://huggingface.co/datasets/Beehzod/STT_uz."},
	{"name":"uzbek_stt_data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uzbek_stt_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uzbek_stt_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"raw-speech-whispervq-v1","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/homebrewltd/raw-speech-whispervq-v1","creator_name":"Menlo Research","creator_url":"https://huggingface.co/homebrewltd","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset contains over 2,4M English ASR samples, using:\\n\\nThe a training set of parler-tts/mls_eng_10k\\nTokenized using WhisperVQ.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset, Audio\\n# Load Instruction Speech dataset\\n\\ndataset = load_dataset(\\\"homebrewltd/raw-speech-whispervq-v1\\\",split='train')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Fields\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nField\\nType\\nDescription\\n\\n\\n\\t\\t\\ntokens\\nsequence\\nTokenized using Encodec\\n\\n\\ntext\\nsequence\\nConverted audio tokens… See the full description on the dataset page: https://huggingface.co/datasets/homebrewltd/raw-speech-whispervq-v1."},
	{"name":"new_data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/new_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/new_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"yogera_runyankore_ailab_4_0_1","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shawal777/yogera_runyankore_ailab_4_0_1","creator_name":"Shawal Mbalire","creator_url":"https://huggingface.co/Shawal777","description":"Shawal777/yogera_runyankore_ailab_4_0_1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Saudilang-Code-Switch-Corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus","creator_name":"SDAIA NCAI","creator_url":"https://huggingface.co/SDAIANCAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCC - Saudilang Code-Switch Corpus\\n\\t\\n\\nThe National Center for Artificial Intelligence at the Saudi Data and Artificial Intelligence Authority (SDAIA), published the \\\"SCC\\\" dataset, which stands for \\\"Saudilang Code-Switch Corpus”.\\nThis dataset contains a transcription of general conversations taken from a YouTube podcast \\\"Thmanyah\\\" that has been transcribed by the National Center for Artificial Intelligence in SDAIA. The data features three episodes covering different domains:… See the full description on the dataset page: https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus."},
	{"name":"myanmar-speech-dataset-openslr-80","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMyanmar Speech Dataset (OpenSLR-80)\\n\\t\\n\\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual OpenSLR dataset. \\nFor the complete multilingual dataset and additional information, please visit the original dataset repository \\nof OpenSLR Hugging Face page.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Source\\n\\t\\n\\nOpenSLR is a site devoted to hosting speech and language resources, such as… See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80."},
	{"name":"SBCSAE","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dklement/SBCSAE","creator_name":"Dominik Klement","creator_url":"https://huggingface.co/dklement","description":"A detailed dataset description (including description, audio samples, and statistics) is provided here: https://domklement.github.io/sbcsae/\\nIf you use the dataset, please, do not forget to cite our work:\\n@inproceedings{maciejewski24_interspeech,\\n  title     = {Evaluating the Santa Barbara Corpus: Challenges of the Breadth of Conversational Spoken Language},\\n  author    = {Matthew Maciejewski and Dominik Klement and Ruizhe Huang and Matthew Wiesner and Sanjeev Khudanpur},\\n  year      = {2024}… See the full description on the dataset page: https://huggingface.co/datasets/dklement/SBCSAE."},
	{"name":"ksponspeech-eval","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yfyeung/ksponspeech-eval","creator_name":"Yifan Yang","creator_url":"https://huggingface.co/yfyeung","description":"paper link: https://www.mdpi.com/846876\\n"},
	{"name":"inbrowser-proctor-dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset","creator_name":"Aayush Man Shrestha","creator_url":"https://huggingface.co/lord-reso","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Inbrowser Proctor Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject Description\\n\\t\\n\\nInbrowser Proctoring is an online browser proctoring application designed to supervise exams and prevent cheating in real-time. Utilizing a combination of video, audio, and screen recording technologies, along with advanced AI algorithms, the system closely monitors test-takers to identify suspicious behaviors and activities. By analyzing audio and visual data, it can detect anomalies that may indicate… See the full description on the dataset page: https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset."},
	{"name":"enwaucymraeg","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/enwaucymraeg","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"The training and development set sentences are taken from CoVoST and have been compared to all validated sentences in the Welsh Common Voice data to ensure none of the already recorded sentences will be used here. Then all sentences containing personal names have been extracted and replaced with a randomly generated name using the Faker library and a custom Welsh names list. The sentences were then recorded by 26 volunteers from North-West Wales, 15 women, 10 men and one non-binary person.… See the full description on the dataset page: https://huggingface.co/datasets/wanasash/enwaucymraeg."},
	{"name":"TIE_shorts","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raianand/TIE_shorts","creator_name":"Anand Rai","creator_url":"https://huggingface.co/raianand","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TIE_Shorts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTIE_shorts is a derived version of the Technical Indian English (TIE) dataset, a large-scale speech dataset (~ 8K hours) originally consisting of approximately 750 GB of content \\nsourced from the NPTEL platform. The original TIE dataset contains around 9.8K technical lectures in English delivered by instructors from various regions across India, \\nwith each lecture averaging about 50 minutes. These lectures cover a wide… See the full description on the dataset page: https://huggingface.co/datasets/raianand/TIE_shorts."},
	{"name":"indicvoices_hi_tagged_transcripts","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_hi_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions… See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts."},
	{"name":"toy_corpus_asr_ca","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_ca","creator_name":"Carlos Daniel Hernández Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\\n"},
	{"name":"librispeech_asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pavanyellow/librispeech_asr","creator_name":"Pavan Katta","creator_url":"https://huggingface.co/pavanyellow","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for librispeech_asr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLibriSpeech ASR 2s Splits Dataset\\n\\t\\n\\nVersion of LibriSpeech ASR corpus split into 2s clips.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the dataset from the Hub\\ndataset = load_dataset(\\\"pavanyellow/librispeech_asr\\\")\\n\\n# Or load a specific split\\ndataset = load_dataset(\\\"pavanyellow/librispeech_asr\\\", split=\\\"train\\\")\\n\\n# Access the data\\nfor example in dataset['train'][:5]:\\n   audio = example['audio']\\n   text =… See the full description on the dataset page: https://huggingface.co/datasets/pavanyellow/librispeech_asr."},
	{"name":"bengali_regional_dataset_refine","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sha1779/bengali_regional_dataset_refine","creator_name":"Md sazzad hossain","creator_url":"https://huggingface.co/sha1779","description":"This is the dataset of  ভাষা-বিচিত্রা: ASR for Regional Dialects competition.\\nhere i preprocessed and make train and eval split.\\nthis dataset consist of 10 dialact named 'barishal', 'chittagong', 'habiganj', 'kishoreganj', 'narail',\\n       'narsingdi', 'rangpur', 'sandwip', 'sylhet', 'tangail'.\\nbarishal district has 796 samples\\nchittagong district has 1406 samples\\nhabiganj district has 940 samples\\nkishoreganj district has 1638 samples\\nnarail district has 1488 samples\\nnarsingdi district has… See the full description on the dataset page: https://huggingface.co/datasets/sha1779/bengali_regional_dataset_refine."},
	{"name":"STT-v1","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FILM6912/STT-v1","creator_name":"FILM","creator_url":"https://huggingface.co/FILM6912","description":"FILM6912/STT-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"BERSt","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chocobearz/BERSt","creator_name":"Paige Tuttosi","creator_url":"https://huggingface.co/chocobearz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBERSt Dataset\\n\\t\\n\\nWe release the BERSt Dataset for various speech recognition tasks including Automatic Speech Recognition (ASR) and Speech Emotion Recogniton (SER)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n\\n4526 single phrase recordings (~3.75h)\\n98 professional actors\\n19 phone positions\\n7 emotion classes\\n3 vocal intensity levels\\nvaried regional and non-native English accents\\nnonsense phrases covering all English Phonemes\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData collection\\n\\t\\n\\nThe BERSt dataset represents data collected in… See the full description on the dataset page: https://huggingface.co/datasets/chocobearz/BERSt."},
	{"name":"picovoice-wake-word-benchmark","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark","creator_name":"Adam Jones","creator_url":"https://huggingface.co/domdomegg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPicovoice Wake Word Benchmark Dataset\\n\\t\\n\\nThis dataset contains a collection of wake word recordings used for benchmarking wake word detection systems. The dataset has been reformatted from the original Picovoice Wake Word Benchmark repository for easier use with Hugging Face's ecosystem.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains over 300 recordings of six different wake words from more than 50 distinct speakers. These recordings were originally used to benchmark… See the full description on the dataset page: https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark."},
	{"name":"ami-disfluent","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/ami-disfluent","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/ami-disfluent dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"audio-data","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinTelecmi/audio-data","creator_name":"Sachin Mohanty","creator_url":"https://huggingface.co/SachinTelecmi","description":"SachinTelecmi/audio-data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"zeroth-STT-Ko","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\\n\\t\\n\\t\\t\\n\\t\\tZeroth-STT-Ko Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset combines the following publicly available Korean language datasets:\\nJunhoee/STT_Korean_Dataset_80000\\nand\\nZeroth-Korean Dataset (from Project: Zeroth, by GoodAtlas and Gridspace)\\nThis provides over 102K rows of data (sentences) in total.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0… See the full description on the dataset page: https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko."},
	{"name":"kinh-phap-hoa-ke-trom-huong","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"Normalized using https://github.com/oysterlanguage/emiliapipex\\n@article{emilia,\\n      title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},\\n      author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},\\n      journal={arXiv},\\n      volume={abs/2407.05361}… See the full description on the dataset page: https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong."},
	{"name":"STT-v2","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FILM6912/STT-v2","creator_name":"FILM","creator_url":"https://huggingface.co/FILM6912","description":"FILM6912/STT-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sinhala-bank-speech","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech","creator_name":"Ishan Sugathadasa","creator_url":"https://huggingface.co/IshanSuga","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nThis dataset contains 100 audio files in the format .wav. \\nThe domain of this dataset is Banking.Only Language is Sinhalese(Sinhala,si)\\nTotal Duration: 700.283 seconds.\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More… See the full description on the dataset page: https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech."},
	{"name":"KikuyuASR_trainingdataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CGIAR/KikuyuASR_trainingdataset","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","description":"This dataset is obtained as part of AIEP prject by Digital Green and Karya from the extension workers, lead farmers and farmers.\\nProcess of collection of data:\\nSelected users were given the option of doing a task and getting paid for it.\\nThe users were supposed to record the sentence as it appeared on the screen.\\nThe audio file thus obtained was validated matched with the sentences to fine tune the model.\\nAlso available are the python script that helps in processing and splitting the data into… See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/KikuyuASR_trainingdataset."},
	{"name":"emova-sft-4m","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-4m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-4M\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-4M is a comprehensive dataset curated for omni-modal instruction tuning, including textual, visual, and audio interactions. This dataset is created by gathering open-sourced multi-modal instruction datasets and synthesizing high-quality omni-modal conversation data to enhance user experience. This dataset is… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-4m."},
	{"name":"composite_corpus_eu_v2.1","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/composite_corpus_eu_v2.1","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComposite dataset for Basque made from public available data\\n\\t\\n\\nThis dataset is composed of the following public available data:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTrain split:\\n\\t\\n\\nThe train split is composed of the following datasets combined:\\n\\nmozilla-foundation/common_voice_18_0/eu: \\\"validated\\\" split removing \\\"test_cv\\\" and \\\"dev_cv\\\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\\ngttsehu/basque_parliament_1/eu: \\\"train_clean\\\" split removing some of… See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_eu_v2.1."},
	{"name":"jeli-asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \\nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \\nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \\nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \\nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \\nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\\n"},
	{"name":"wolof-audio-data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galsenai/wolof-audio-data","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWolof Audio Dataset\\n\\t\\n\\nThe Wolof Audio Dataset is a collection of audio recordings and their corresponding transcriptions in Wolof. This dataset is designed to support the development of Automatic Speech Recognition (ASR) models for the Wolof language. It was created by combining four existing datasets:\\n\\nALFFA: Available at serge-wilson/wolof_speech_transcription\\nFLEURS: Available at vonewman/fleurs-wolof-dataset\\nUrban Bus Wolof Speech Dataset: Available at vonewman/urban-bus-wolof… See the full description on the dataset page: https://huggingface.co/datasets/galsenai/wolof-audio-data."},
	{"name":"CanaryAura","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nkazi/CanaryAura","creator_name":"Nazmul Kazi","creator_url":"https://huggingface.co/nkazi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Canary Aura\\\"\\n\\t\\n\\nThis is a dataset for...\\n"},
	{"name":"lleisiau-arfor","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cymen-arfor/lleisiau-arfor","creator_name":"Prosiect Arfor Cymen","creator_url":"https://huggingface.co/cymen-arfor","description":"See below for English\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLleisiau ARFOR\\n\\t\\n\\nCafodd y set ddata hon ei chreu gan Cymen fel rhan o brosiect a ariannwyd gan ARFOR ar y cyd â’r Uned Technolegau Iaith ym Mhrifysgol Bangor.   \\nNod y prosiect oedd casglu llawer iawn o ddata llafar Cymraeg o ansawdd uchel, ynghyd â’u trawsgrifiadau cyfatebol, gan ganolbwyntio’n benodol ar iaith anffurfiol, sgyrsiol a digymell o ardal Arfor. Bydd y set ddata sy’n deillio ohoni wedyn yn cael ei defnyddio i wella technoleg adnabod llais yng… See the full description on the dataset page: https://huggingface.co/datasets/cymen-arfor/lleisiau-arfor."},
	{"name":"twi_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\\n\\t\\n\\t\\t\\n\\t\\tTwi Multispeaker Audio Transcribed Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Twi Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Asante Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: The dataset is derived from the Financial Inclusion… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed."},
	{"name":"akuapem_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\\n\\t\\n\\t\\t\\n\\t\\tAkuapem Multispeaker Audio Transcribed Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Akuapem Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Akuapem Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: The dataset is derived from the Financial… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed."},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","description":"\\n\\t\\n\\t\\t\\n\\t\\tTamazight-Arabic Speech Recognition Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\\n\\n\\t\\n\\t\\t\\n\\t\\tQuick Start\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text."},
	{"name":"fante_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\\n\\t\\n\\t\\t\\n\\t\\tFante Multispeaker Audio Transcribed Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Fante Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Fante, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: The dataset is derived from the Financial Inclusion Speech… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed."},
	{"name":"ChFT","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tzyll/ChFT","creator_name":"Zhiyuan Tang","creator_url":"https://huggingface.co/tzyll","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ChFT\\n\\t\\n\\n\\n\\nThis dataset is published with the paper Full-text Error Correction for Chinese Speech Recognition with Large Language Model in ICASSP 2025.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources… See the full description on the dataset page: https://huggingface.co/datasets/tzyll/ChFT."},
	{"name":"speakeroverlap_multiseg","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zbrunner/speakeroverlap_multiseg","creator_name":"Zoe Brunner","creator_url":"https://huggingface.co/zbrunner","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiSeg Dataset for ASR Hallucinations\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nMultiSeg is a perturbed and altered version of the TEDLIUM3 dataset, specifically created for evaluating the robustness of Automatic Speech Recognition (ASR) systems. This dataset is derived from the 'speakeroverlap' subset, which consists of held-back training data from TEDLIUM3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe primary purpose of the MultiSeg dataset is to:\\n\\nElicit hallucinations from ASR systems\\nEvaluate ASR… See the full description on the dataset page: https://huggingface.co/datasets/zbrunner/speakeroverlap_multiseg."},
	{"name":"mosel","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description, Collection, and Source\\n\\t\\n\\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large… See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel."},
	{"name":"indicvoices_pa_tagged_transcripts","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_pa_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions… See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts."},
	{"name":"indicvoices_mr_tagged_transcripts","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_mr_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions… See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts."},
	{"name":"indicvoices_bn_tagged_transcripts","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_bn_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions… See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts."},
	{"name":"KikuyuASR_trainingdataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DigiGreen/KikuyuASR_trainingdataset","creator_name":"Digital Green","creator_url":"https://huggingface.co/DigiGreen","description":"This dataset is obtained as part of AIEP prject by Digital Green and Karya from the extension workers, lead farmers and farmers.\\nProcess of collection of data:\\nSelected users were given the option of doing a task and getting paid for it.\\nThe users were supposed to record the sentence as it appeared on the screen.\\nThe audio file thus obtained was validated matched with the sentences to fine tune the model.\\nAlso available are the python script that helps in processing and splitting the data into… See the full description on the dataset page: https://huggingface.co/datasets/DigiGreen/KikuyuASR_trainingdataset."},
	{"name":"znanio-audios","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/znanio-audios","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Znanio.ru Educational Audio\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 3,417 educational audio files from the znanio.ru platform, a resource for teachers, educators, students, and parents providing diverse educational content. Znanio.ru has been a pioneer in educational technologies and distance learning in the Russian-speaking internet since 2009.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian, with potential multilingual content:… See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/znanio-audios."},
	{"name":"test_4","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
	{"name":"test_4","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
	{"name":"mabama-data","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aztro/mabama-data","creator_name":"Jose Omar Vieyra","creator_url":"https://huggingface.co/aztro","description":"aztro/mabama-data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\\n\\t\\n\\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\\n\\nDataset Summary\\nDataset composition\\nSources\\nContent Types\\nLanguages and Dialects\\n\\n\\nExample use (python)\\nLicense\\nCitations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on… See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented."},
	{"name":"emova-alignment-7m","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-Alignment-7M\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-Alignment-7M is a comprehensive dataset curated for omni-modal pre-training, including vision-language and speech-language alignment. \\nThis dataset is created using open-sourced image-text pre-training datasets, OCR datasets, and 2,000 hours of ASR and TTS data. \\nThis dataset is part of the EMOVA-Datasets… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m."},
	{"name":"wolof-audio-data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vonewman/wolof-audio-data","creator_name":"Abdoulaye Diallo","creator_url":"https://huggingface.co/vonewman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWolof Audio Dataset\\n\\t\\n\\nThe Wolof Audio Dataset is a collection of audio recordings and their corresponding transcriptions in Wolof. This dataset is designed to support the development of Automatic Speech Recognition (ASR) models for the Wolof language. It was created by combining three existing datasets:\\n\\nALFFA: Available at serge-wilson/wolof_speech_transcription\\nFLEURS: Available at vonewman/fleurs-wolof-dataset\\nUrban Bus Wolof Speech Dataset: Available at… See the full description on the dataset page: https://huggingface.co/datasets/vonewman/wolof-audio-data."},
	{"name":"emova-asr-tts-eval","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-ASR-TTS-Eval\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-ASR-TTS-Eval is a dataset designed for evaluating the ASR and TTS performance of Omni-modal LLMs. It is derived from the test-clean set of the LibriSpeech dataset. This dataset is part of the EMOVA-Datasets collection. We extract the speech units using the EMOVA Speech Tokenizer.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThis… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval."},
	{"name":"pashto_speech_2k","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_2k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\\n\\t\\n\\t\\t\\n\\t\\tPashto Synthetic Speech Dataset (2k)\\n\\t\\n\\nThis dataset contains 4000 synthetic speech recordings in the Pashto language,\\nwith 2000 male voice recordings and 2000 female voice recordings.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nDataset Size: 2000 sentences\\nTotal Recordings: 4000 audio files (2000 male + 2000 female)\\nAudio Format: WAV, 44.1kHz, 16-bit PCM\\nSampling Rate: 44.1kHz (44100 Hz)\\nVoices: \\nMale: ps-AF-GulNawazNeural\\nFemale: ps-AF-LatifaNeural\\n\\n\\nTotal Audio Duration: \\nMale: 0.00 seconds… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_2k."},
	{"name":"prueba_parquet","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/prueba_parquet","creator_name":"Carlos Daniel Hernández Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with parquet files only.\\n"},
	{"name":"ga_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\\n\\t\\n\\t\\t\\n\\t\\tGa Multispeaker Audio Transcribed Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Ga Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Ga, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: The dataset is derived from the Financial Inclusion Speech Dataset… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed."},
	{"name":"alphanumeric-audio-dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset","creator_name":"Sakshee Patil","creator_url":"https://huggingface.co/sakshee05","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpeech Recognition Bias Reduction Project\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExecutive Summary\\n\\t\\n\\nWelcome to the Speech Recognition Bias Reduction Project. It aims to create a more inclusive and representative dataset for improving automated speech recognition systems. This project addresses the challenges faced by speakers with non-native English accents, particularly when interacting with automated voice systems that struggle to interpret alphanumeric information such as names, phone numbers, and… See the full description on the dataset page: https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset."},
	{"name":"bot_stt","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/bot_stt","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/bot_stt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Google_Myanmar_ASR","keyword":"speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/Google_Myanmar_ASR","creator_name":"WYC","creator_url":"https://huggingface.co/freococo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoogle Myanmar ASR Dataset\\n\\t\\n\\nThis dataset is a processed and organized version of the original OpenSLR-80 Burmese Speech Corpus. It has been carefully structured for ASR tasks with additional preprocessing steps to enhance usability and consistency.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Google Myanmar ASR Dataset is based on the Burmese Speech Corpus, originally published by Google. It consists of audio files and their corresponding transcriptions. The dataset is primarily aimed… See the full description on the dataset page: https://huggingface.co/datasets/freococo/Google_Myanmar_ASR."},
	{"name":"emova-sft-speech-eval","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-Speech-Eval\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-Speech-Eval is an evaluation dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-Eval is part of EMOVA-Datasets collection, and the training… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval."},
	{"name":"Google_Myanmar_ASR","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/Google_Myanmar_ASR","creator_name":"WYC","creator_url":"https://huggingface.co/freococo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoogle Myanmar ASR Dataset\\n\\t\\n\\nThis dataset is a processed and organized version of the original OpenSLR-80 Burmese Speech Corpus. It has been carefully structured for ASR tasks with additional preprocessing steps to enhance usability and consistency.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Google Myanmar ASR Dataset is based on the Burmese Speech Corpus, originally published by Google. It consists of audio files and their corresponding transcriptions. The dataset is primarily aimed… See the full description on the dataset page: https://huggingface.co/datasets/freococo/Google_Myanmar_ASR."},
	{"name":"zeroth-korean","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/zeroth-korean","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZeroth-Korean\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZeroth-Korean\\n\\t\\n\\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\\nZeroth project introduces free Korean speech corpus and aims to make… See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/zeroth-korean."},
	{"name":"common_voice_11_0","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0","creator_name":"Mozilla Foundation","creator_url":"https://huggingface.co/mozilla-foundation","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Common Voice Corpus 11.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \\nMany of the 24210 recorded hours in the dataset also include demographic metadata like age, sex, and accent \\nthat can help improve the accuracy of speech recognition engines.\\nThe dataset currently consists of 16413 validated hours in 100 languages, but more voices and languages are always added. \\nTake a look at the Languages page to… See the full description on the dataset page: https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0."},
	{"name":"linto-dataset-audio-ar-tn","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\\n\\t\\n\\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\\n(linagora/linto-asr-ar-tn).\\n\\nDataset Summary\\nDataset composition\\nSources\\nData Table\\nData sources\\nContent Types\\nLanguages and Dialects\\n\\n\\nExample use (python)\\nLicense\\nCitations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LinTO DataSet Audio for Arabic Tunisian is a… See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn."},
	{"name":"ASCEND","keyword":"speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/ASCEND","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASCEND\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.… See the full description on the dataset page: https://huggingface.co/datasets/CAiRE/ASCEND."},
	{"name":"CommonVoices20_ro","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","description":"\\n\\t\\n\\t\\t\\n\\t\\tCommon Voices Corpus 20.0 (Romanian)\\n\\t\\n\\n\\nCommon Voices is an open-source dataset of speech recordings created by \\nMozilla to improve speech recognition technologies. \\nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\\n\\n\\n\\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \\nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \\nessential… See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro."},
	{"name":"ASCEND","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/ASCEND","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASCEND\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.… See the full description on the dataset page: https://huggingface.co/datasets/CAiRE/ASCEND."},
	{"name":"multilingual_librispeech","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiLingual LibriSpeech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.… See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech."},
	{"name":"voxpopuli","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/voxpopuli","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation."},
	{"name":"ami","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edinburghcstr/ami","creator_name":"University of Edingburgh - Centre For Speech Technology Research","creator_url":"https://huggingface.co/edinburghcstr","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\\nnon-native speakers. \\\\n"},
	{"name":"sova_rudevices","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bond005/sova_rudevices","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for sova_rudevices\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSOVA Dataset is free public STT/ASR dataset. It consists of several parts, one of them is SOVA RuDevices. This part is an acoustic corpus of approximately 100 hours of 16kHz Russian live speech with manual annotating, prepared by SOVA.ai team.\\nAuthors do not divide the dataset into train, validation and test subsets. Therefore, I was compelled to prepare this splitting. The training subset includes more than 82 hours… See the full description on the dataset page: https://huggingface.co/datasets/bond005/sova_rudevices."},
	{"name":"IMaSC","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/IMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIMaSC: ICFOSS Malayalam Speech Corpus\\n\\t\\n\\nIMaSC is a Malayalam text and speech corpus made available by ICFOSS for the purpose of developing speech technology for Malayalam, particularly text-to-speech. The corpus contains 34,473 text-audio pairs of Malayalam sentences spoken by 8 speakers, totalling in approximately 50 hours of audio.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of 34,473 instances with fields text, speaker, and audio. The audio is mono, sampled at 16kH.… See the full description on the dataset page: https://huggingface.co/datasets/thennal/IMaSC."},
	{"name":"quran-data","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ashraf-ali/quran-data","creator_name":"Ashraf Ali","creator_url":"https://huggingface.co/ashraf-ali","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Quran audio\\n\\t\\n\\nContent \\n\\n7 Imam Full Quran Recitation: 7*6236 wav file\\ncsv contains the Text info for 11k subset short wav file\\n\\n\\nTarteel.io user dataset ~25k wav\\ncsv contains the Text info for 18k subset of the accepted user quality\\n\\n\\n\\n"},
	{"name":"everyayah","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tarteel-ai/everyayah","creator_name":"Tarteel AI","creator_url":"https://huggingface.co/tarteel-ai","description":"﷽\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tarteel AI's EveryAyah Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe audio is in Arabic.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA typical data point comprises the audio file audio, and its transcription called text.\\nThe duration… See the full description on the dataset page: https://huggingface.co/datasets/tarteel-ai/everyayah."},
	{"name":"km-speech-corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seanghay/km-speech-corpus","creator_name":"seanghay","creator_url":"https://huggingface.co/seanghay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"km-speech-corpus\\\"\\n\\t\\n\\nsampling_rate: 16000\\nmean_seconds: 2.5068187111021882\\nmax_seconds: 19.392\\nmin_seconds: 0.448\\ntotal_seconds: 37459.392\\ntotal_hrs: 10.405386666666667\\n\\n"},
	{"name":"tarteel-ai-everyayah-Quran","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran","creator_name":"Mohamed Salama","creator_url":"https://huggingface.co/Salama1429","description":"﷽\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tarteel AI's EveryAyah Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to download\\n\\t\\n\\n!pip install -q datasets\\n\\nfrom datasets import load_dataset\\ndataset =load_dataset(\\\"Salama1429/tarteel-ai-everyayah-Quran\\\", verification_mode=\\\"no_checks\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages… See the full description on the dataset page: https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran."},
	{"name":"japanese-anime-speech","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joujiboi/japanese-anime-speech","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJapanese Anime Speech Dataset\\n\\t\\n\\n日本語はこちら\\njapanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.\\nThe goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre… See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech."},
	{"name":"MSC","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smcproject/MSC","creator_name":"Swathanthra Malayalam Computing","creator_url":"https://huggingface.co/smcproject","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [msc]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n1541 speech samples\\n75 speech contributors\\n1:38:16 hours of speech\\n482 unique sentences\\n1400 unique words\\n553 unique syllables\\n48 unique phonemes\\n\\nFor more detailed analysis see the python notebook provided here\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nAutomatic Speech Recognition system development, gender and age identification of speakers\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMalayalam\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure… See the full description on the dataset page: https://huggingface.co/datasets/smcproject/MSC."},
	{"name":"librispeech-alignments","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gilkeyio/librispeech-alignments","creator_name":"Kim Gilkey","creator_url":"https://huggingface.co/gilkeyio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Librispeech Alignments\\n\\t\\n\\nLibrispeech with alignments generated by the Montreal Forced Aligner. The original alignments in TextGrid format can be found here\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLibrispeech is a corpus of read English speech, designed for training and evaluating automatic speech recognition (ASR) systems. The dataset contains 1000 hours of 16kHz read English speech derived from audiobooks.\\nThe Montreal Forced Aligner… See the full description on the dataset page: https://huggingface.co/datasets/gilkeyio/librispeech-alignments."},
	{"name":"speechocean762","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mispeech/speechocean762","creator_name":"Xiaomi Dasheng Team","creator_url":"https://huggingface.co/mispeech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tspeechocean762: A non-native English corpus for pronunciation scoring task\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nPronunciation scoring is a crucial technology in computer-assisted language learning (CALL) systems. The pronunciation quality scores might be given at phoneme-level, word-level, and sentence-level for a typical pronunciation scoring task.\\nThis corpus aims to provide a free public dataset for the pronunciation scoring task.\\nKey features:\\n\\nIt is available for free download for… See the full description on the dataset page: https://huggingface.co/datasets/mispeech/speechocean762."},
	{"name":"librivox-tracks","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
	{"name":"openslr63","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/openslr63","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSLR63: Crowdsourced high-quality Malayalam multi-speaker speech data set\\n\\t\\n\\nThis data set contains transcribed high-quality audio of Malayalam sentences recorded by volunteers. The data set consists of wave files, and a TSV file (line_index.tsv). The file line_index.tsv contains a anonymized FileID and the transcription of audio in the file.\\nThe data set has been manually quality checked, but there might still be errors.\\nPlease report any issues in the following issue tracker on… See the full description on the dataset page: https://huggingface.co/datasets/vrclc/openslr63."},
	{"name":"uzbekvoice-filtered","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered","creator_name":"Dovron Sherbaev","creator_url":"https://huggingface.co/DavronSherbaev","description":"This is heavy filtered version of the dataset with additional information.\\nThis dataset does not contain original Mozilla Common Voice audios or texts\\nWe filtered the dataset using number approaches:\\n\\nVAD + Noise detection. Audios which lacked voice activity and produced no sound after denoiser were removed\\nReading Speed. Audios with outlier speeds (approximately 5-10%), as they didnt match natural speed or were too noisy\\nAutomatic STT validation. We trained the model using subset of valid… See the full description on the dataset page: https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered."},
	{"name":"SUBAK.KO","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO","creator_name":"SUST CSE Speech Processing Lab","creator_url":"https://huggingface.co/SUST-CSE-Speech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SUBAK.KO\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSUBAK.KO (সুবাক্য), a publicly available annotated Bangladeshi standard Bangla speech corpus, is compiled for automatic speech recognition research. \\nThis corpus contains 241 hours of high-quality speech data, including 229 hours of read speech data and 12 hours of broadcast speech data. \\nThe read speech segment is recorded in a noise-proof studio environment from 33 male and 28 female native Bangladeshi Bangla speakers… See the full description on the dataset page: https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO."},
	{"name":"vlsp2020_vinai_100h","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of VLSP 2020 - VinAI - ASR challenge dataset\\n\\t\\n\\nofficial announcement:\\n\\ntiếng việt: https://institute.vinbigdata.org/events/vinbigdata-chia-se-100-gio-du-lieu-tieng-noi-cho-cong-dong/\\nin eglish: https://institute.vinbigdata.org/en/events/vinbigdata-shares-100-hour-data-for-the-community/\\nVLSP 2020 workshop: https://vlsp.org.vn/vlsp2020\\n\\nofficial download: https://drive.google.com/file/d/1vUSxdORDxk-ePUt-bUVDahpoXiqKchMx/view?usp=sharing\\ncontact:… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h."},
	{"name":"infore1_25hours","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore1_25hours","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of InfoRe Technology public dataset №1\\n\\t\\n\\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\\n25h, 14.9k samples, InfoRe paid a contractor to read text\\nofficial download: magnet:?xt=urn:btih:1cbe13fb14a390c852c016a924b4a5e879d85f41&dn=25hours.zip&tr=http%3A%2F%2Foffice.socials.vn%3A8725%2Fannounce\\nmirror: https://files.huylenguyen.com/25hours.zip\\nunzip password: BroughtToYouByInfoRe\\npre-process: none\\nneed to do:… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore1_25hours."},
	{"name":"SUBAK.KO","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO","creator_name":"SUST CSE Speech Processing Lab","creator_url":"https://huggingface.co/SUST-CSE-Speech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SUBAK.KO\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSUBAK.KO (সুবাক্য), a publicly available annotated Bangladeshi standard Bangla speech corpus, is compiled for automatic speech recognition research. \\nThis corpus contains 241 hours of high-quality speech data, including 229 hours of read speech data and 12 hours of broadcast speech data. \\nThe read speech segment is recorded in a noise-proof studio environment from 33 male and 28 female native Bangladeshi Bangla speakers… See the full description on the dataset page: https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO."},
	{"name":"mls_eng_10k","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng_10k","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng_10k."},
	{"name":"mls_eng","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for English MLS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng."},
	{"name":"MediaSpeech","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMediaSpeech\\n\\t\\n\\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\\nBaseline models and WAV version of the dataset can be… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech."},
	{"name":"LSVSC","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/LSVSC","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tunofficial mirror of LSVSC dataset (novel large-scale Vietnamese speech corpus)\\n\\t\\n\\nofficial announcement: https://www.mdpi.com/2079-9292/13/5/977\\nofficial download: https://drive.google.com/drive/folders/1tiPKaIOC7bt6isv5qFqf61O_2jFK8ZOI\\n100h, 57k samples\\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/clean-lsvsc.py\\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\\nusage with HuggingFace:\\n# pip install -q… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/LSVSC."},
	{"name":"cv-corpus-1.0-en-client_id-grouped","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcv-corpus-1.0-en-client_id-grouped\\n\\t\\n\\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nThe dataset is derived from the Common Voice dataset.\\nThe original dataset is available at Common Voice Dataset.\\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\\nEach group is filtered to include only client IDs with a minimum of 60 samples and a… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped."},
	{"name":"profanity-speech-suroboyoan","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jaal047/profanity-speech-suroboyoan","creator_name":"Rijal Akhdan Khirulah","creator_url":"https://huggingface.co/Jaal047","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Audio Perkataan Vulgar Bahasa Jawa Dialek Surabaya\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDeskripsi\\n\\t\\n\\nDataset ini berisi audio rekaman percakapan dalam bahasa Jawa dialek Surabaya yang mengandung perkataan vulgar. Setiap rekaman dilengkapi dengan transkripsi teks yang sesuai.Dataset ini dibuat sebagai bagian dari penelitian skripsi saya dengan tujuan untuk mendukung analisis dan pengembangan dalam bidang deteksi perkataan vulgar dalam bahasa Jawa dialek Surabaya menggunakan teknologi… See the full description on the dataset page: https://huggingface.co/datasets/Jaal047/profanity-speech-suroboyoan."},
	{"name":"GLOBE","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImportant notice\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t!!! Please use V2 version version as this version has abnormal voice volume issue.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlobe\\n\\t\\n\\nThe full paper can be accessed here: arXiv\\nAn online demo can be accessed here: Github\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbstract\\n\\t\\n\\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to address the limitations of current zero-shot speaker adaptive Text-to-Speech (TTS) systems that exhibit poor generalizability in… See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE."},
	{"name":"mls-eng-speaker-descriptions","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of English MLS\\n\\t\\n\\nThis dataset consists in annotations of the English subset of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.\\nThis… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions."},
	{"name":"libritts_r_filtered","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/libritts_r_filtered","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtered LibriTTS-R\\n\\t\\n\\nThis is a filtered version of LibriTTS-R. It has been filtered based on two sources:\\n\\nLibriTTS-R paper [1], which lists samples for which speech restoration have failed\\nLibriTTS-P [2] list of excluded speakers for which multiple speakers have been detected.\\n\\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately \\n585 hours of read English speech at 24kHz sampling rate… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_filtered."},
	{"name":"arabic_quranic_asr","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadique5/arabic_quranic_asr","creator_name":"Sadique Abdullah","creator_url":"https://huggingface.co/Sadique5","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nThis dataset contains quran recitations of every ayats or verses. Also contains 10k unique words from quran.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Purpose\\n\\t\\n\\nThis dataset can be used to train ASR models that can be used for teaching beginners to recite quran. It can also be used for training TTS models that produces quran recitations in a way so that beginners can easily learn.\\n"},
	{"name":"darija_speech_to_text","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adiren7/darija_speech_to_text","creator_name":"Adil Oubaibou","creator_url":"https://huggingface.co/adiren7","description":"adiren7/darija_speech_to_text dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"zoengjyutgaai","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"粵語計算語言學基礎建設組 (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\\n\\t\\n\\t\\t\\n\\t\\t張悦楷講古語音數據集\\n\\t\\n\\nEnglish\\n呢個係張悦楷講《三國演義》、《水滸傳》、《走進毛澤東的最後歲月》語音數據集。張悦楷係廣州最出名嘅講古佬 / 粵語説書藝人。佢從上世紀七十年代開始就喺廣東各個收音電台度講古，佢把聲係好多廣州人嘅共同回憶。本數據集收集嘅係佢最知名嘅三部作品。\\n數據集用途：\\n\\nTTS（語音合成）訓練集\\nASR（語音識別）訓練集或測試集\\n各種語言學、文學研究\\n直接聽嚟欣賞藝術！\\n\\nTTS 效果演示：https://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t説明\\n\\t\\n\\n\\n所有文本都根據 https://jyutping.org/blog/typo/ 同 https://jyutping.org/blog/particles/ 規範用字。\\n所有文本都使用全角標點，冇半角標點。\\n所有文本都用漢字轉寫，無阿拉伯數字無英文字母\\n所有音頻源都存放喺/source，為方便直接用作訓練數據，切分後嘅音頻都放喺 opus/\\n所有 opus 音頻皆為 48000 Hz 採樣率。… See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai."},
	{"name":"composite_corpus_eu_v2.1","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1","creator_name":"Asier Herranz","creator_url":"https://huggingface.co/asierhv","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComposite dataset for Basque made from public available data\\n\\t\\n\\nThis dataset is composed of the following public available data:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTrain split:\\n\\t\\n\\nThe train split is composed of the following datasets combined:\\n\\nmozilla-foundation/common_voice_18_0/eu: \\\"validated\\\" split removing \\\"test_cv\\\" and \\\"dev_cv\\\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\\ngttsehu/basque_parliament_1/eu: \\\"train_clean\\\" split removing some of… See the full description on the dataset page: https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1."},
	{"name":"Ar-En-Code-Switching-Textual-Dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDAIANCAI/Ar-En-Code-Switching-Textual-Dataset","creator_name":"SDAIA NCAI","creator_url":"https://huggingface.co/SDAIANCAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArE-CSTD: Arabic-English Code-Switching Textual Dataset\\n\\t\\n\\nThe National Center for Artificial Intelligence at the Saudi Data and Artificial Intelligence Authority (SDAIA), published the \\\"ArE-CSTD\\\" dataset, which stands for \\\"Arabic-English Code-Switching Textual Dataset”.\\nThis dataset contains 330K dialectical Arabic-English code-swithing sentences generated by the large language model GPT-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTXT Files\\n\\t\\n\\nThere are 6 txt files. 2 files for Modern Standard Arabic(MSA)… See the full description on the dataset page: https://huggingface.co/datasets/SDAIANCAI/Ar-En-Code-Switching-Textual-Dataset."},
	{"name":"parlament_parla_v3","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/parlament_parla_v3","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ParlamentParla v3 - Speech Corpus of Catalan Parliamentary Sessions\\n\\t\\n\\nA speech corpus composed of Catalan Parliamentary Sessions.The v3 and last version of the corpus includes both clean and other quality segments, divided into short segments (less than 30 seconds) and long segments (more than 30 seconds). The total dataset encompasses 1059h 48m 04s of speech, including 945h 51m 06s for the short segments and 113h 56m 58s for the long segments, with a total of… See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/parlament_parla_v3."},
	{"name":"Tuda-De","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/uhhlt/Tuda-De","creator_name":"LT Group at UHH","creator_url":"https://huggingface.co/uhhlt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen speech data for German speech recognition\\n\\t\\n\\nLanguage Technology, Universität Hamburg, Germany\\nhttps://www.inf.uni-hamburg.de/en/inst/ab/lt (formerly TU-Darmstadt)\\nhttps://www.lt.tu-darmstadt.de\\nTelecooperation labs, TU-Darmstadt, Germany\\nhttps://www.tk.informatik.tu-darmstadt.de\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral information\\n\\t\\n\\n\\nThe speech data was collected in a controlled environment (same room, same microphone distances, etc. )\\nDistance between speakers and the microphones is about 1… See the full description on the dataset page: https://huggingface.co/datasets/uhhlt/Tuda-De."},
	{"name":"uzbek_speech_data","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uzbek_speech_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uzbek_speech_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SUMM-RE","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/SUMM-RE","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"Note: if the data viewer is not working, use the \\\"example\\\" subset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSUMM-RE\\n\\t\\n\\nThe SUMM-RE dataset is a collection of transcripts of French conversations, aligned with the audio signal.\\nIt is a corpus of meeting-style conversations in French created for the purpose of the SUMM-RE project (ANR-20-CE23-0017). \\nThe full dataset is described in Hunter et al. (2024): \\\"SUMM-RE: A corpus of French meeting-style conversations\\\".\\n\\nCreated by: Recording and manual correction of the corpus was… See the full description on the dataset page: https://huggingface.co/datasets/linagora/SUMM-RE."},
	{"name":"kurdishted","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aranemini/kurdishted","creator_name":"Aran Emini","creator_url":"https://huggingface.co/aranemini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKurdish TED (KUTED)\\n\\t\\n\\nKurdish TED (KUTED) is the first Speech-to-Text-Translation (S2TT) dataset for Central Kurdish language derived from TED Talks and TEDx. \\nThe corpus consists of 91,000 pairs, encompassing 170 hours of English audio, 1.65 million English tokens, and 1.40 million Central Kurdish tokens.\\nThis dataset is evaluated on speech E2E S2TT, Cascaded S2TT and T2TT tasks. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nKurdish TED can be used for the following tasks:\\n\\nSpeech-to-Text-Translation… See the full description on the dataset page: https://huggingface.co/datasets/aranemini/kurdishted."},
	{"name":"JA_audio_JA_text_180k_samples","keyword":"automatic-speech-recognition","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":""},
	{"name":"BinauralLibriSpeech","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\\nThe dataset has annotations of the source direction as well as microphone array geometry. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nLanguage(s) (NLP): English\\nLicense: [More Information Needed]… See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech."},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"automatic-speech-recognition","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Galgame_Speech_ASR_16kHz\\n\\t\\n\\n\\nThe following rules (in the original repository) must be followed:\\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\\nEnglish:\\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset cannot be… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz."},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"automatic-speech-recognition","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Galgame_Speech_SER_16kHz\\n\\t\\n\\n\\nThe following rules (in the original repository) must be followed:\\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\\nEnglish:\\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset cannot be… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz."},
	{"name":"GLOBE_V2","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V2","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImportant notice\\n\\t\\n\\nDifferences between V2 version and the version described in paper:\\n\\nThe V2 version provide audio in 44.1kHz sample rate. (Supersampling)\\nThe V2 versionn removed some samples (~5%) due to the volumn and text aligment issues.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlobe\\n\\t\\n\\nThe full paper can be accessed here: arXiv\\nAn online demo can be accessed here: Github\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbstract\\n\\t\\n\\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to… See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V2."},
	{"name":"emova-sft-speech-231k","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-Speech-231K\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-Speech-231K is a comprehensive dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-231K is part of EMOVA-Datasets collection and is used in… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k."},
	{"name":"belebele-fleurs","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
	{"name":"2M-Belebele","keyword":"speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
	{"name":"sib-fleurs","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
	{"name":"2M-Belebele","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
	{"name":"commonvoice-12.0-arabic-voice-converted","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted","creator_name":"Modar M. Alfadly","creator_url":"https://huggingface.co/xmodar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Voice Converted Arabic Common Voice 12.0\\n\\t\\n\\nThis dataset is derived from the Common Voice Arabic Corpus 12.0 and includes automatically diacritized transcriptions and phoneme representations for the original augmented audio data. The recordings feature Arabic text read aloud by users, where the text was initially undiacritized, allowing for potential reading errors. The diacritization and phonemes were generated automatically, resulting in a dataset that is… See the full description on the dataset page: https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted."},
	{"name":"darija-speech-to-text","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/darija-speech-to-text","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpeech To Text Darija dataset\\n\\t\\n\\nReupload of adiren7/darija_speech_to_text\\n"},
	{"name":"2M-Flores-ASL","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Flores-ASL","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Flores\\n\\t\\n\\nAs part of the 2M-Belebele project, we have produced video recodings of ASL signing for all the dev and devtest \\nsentences in the original flores200 dataset.\\nTo obtain ASL sign recordings, we provide translators of ASL and native signers with the English text version of the sentences to be recorded.\\nThe interpreters are then asked to translate these sentences into ASL, create glosses for all sentences, and record their interpretations into ASL one sentence at a time.… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Flores-ASL."},
	{"name":"wikitongues-darija","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/wikitongues-darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikitongues-Darija\\n\\t\\n\\nThis is a small test dataset for Automatic Speech Recognition in Darija language, built from 2 captioned videos of the WikiTongues project:\\n\\nnawal\\nanass\\n\\nProcess:\\n\\neach webm video has been converted to monochannel 16khz wav files with ffmpeg :\\n\\nffmpeg -i WIKITONGUES-_Nawal_speaking_Moroccan_Arabic.webm.1080p.vp9.webm -ar 16000 -ac 1 nawal.wav\\n\\n\\neach audio has been cut in samples of less than 30 seconds audio according to the captions timestamps. The script may… See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/wikitongues-darija."},
	{"name":"commonvoice_17_tr_fixed","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ysdede/commonvoice_17_tr_fixed","creator_name":"Yunus Dede","creator_url":"https://huggingface.co/ysdede","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImproving CommonVoice 17 Turkish Dataset\\n\\t\\n\\nI recently worked on enhancing the Mozilla CommonVoice 17 Turkish dataset to create a higher quality training set for speech recognition models.Here's an overview of my process and findings.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInitial Analysis and Split Organization\\n\\t\\n\\nMy first step was analyzing the dataset organization to understand its structure.Through analysis of filename stems as unique keys, I revealed and documented an important aspect of CommonVoice's… See the full description on the dataset page: https://huggingface.co/datasets/ysdede/commonvoice_17_tr_fixed."},
	{"name":"bam-asr-all","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/bam-asr-all","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Bambara-ASR-All Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \\nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \\nData sources include all publicly available collections of audio with Bambara transcriptions, organized for accessibility and usability.\\n"},
	{"name":"gemini-flash-2.0-speech","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"\\n\\t\\n\\t\\t\\n\\t\\t🎙️ Gemini Flash 2.0 Speech Dataset\\n\\t\\n\\n\\nThis is a high quality synthetic speech dataset generated by Gemini Flash 2.0 via the Multimodel Live API. It contains speech from 2 speakers - Puck (Male) and Kore (Female) in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t〽️ Stats\\n\\t\\n\\nTotal number of audio files: 47,256*2 = 94512Total duration: 1023527.20 seconds (284.31 hours)   \\nAverage duration: 10.83 seconds   \\nShortest file: 0.6 secondsLongest file: 92.12 seconds   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t🧩 Data Composition\\n\\t\\n\\nThe text in the… See the full description on the dataset page: https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech."},
	{"name":"Turkish_Speech_Corpus","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Turkish_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\\n\\t\\n\\t\\t\\n\\t\\tTurkish Speech Corpus (TSC)\\n\\t\\n\\nThis repository presents an open-source Turkish Speech Corpus, introduced in \\\"Multilingual Speech Recognition for Turkic Languages\\\". The corpus contains 218.2 hours of transcribed speech with 186,171 utterances and is the largest publicly available Turkish dataset of its kind at that time. \\nPaper: Multilingual Speech Recognition for Turkic Languages.  \\nGitHub Repository: https://github.com/IS2AI/TurkicASR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@Article{info14020074… See the full description on the dataset page: https://huggingface.co/datasets/issai/Turkish_Speech_Corpus."},
	{"name":"jacob-common-voice-19-zh-TW-curated","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jacob-common-voice-19-zh-TW-curated","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/jacob-common-voice-19-zh-TW-curated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"hailuo-ai-voices","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\\n\\t\\n\\t\\t\\n\\t\\tHailuo AI Voices Dataset 🎤\\n\\t\\n\\n\\n\\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📊 Dataset Overview\\n\\t\\n\\nThe dataset provides a comprehensive collection of voice samples with the following features:\\n\\n\\t\\n\\t\\t\\nFeature\\nDescription\\n\\n\\n\\t\\t\\nAudio Files\\nHigh-quality WAV format recordings\\n\\n\\nTranscription\\nAccurate transcriptions of each… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices."},
	{"name":"jl-speech","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jl-speech","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\\n\\t\\n\\t\\t\\n\\t\\tJL Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nJL Speech is a male voice version of the LJ Speech dataset. It contains 13,100 short audio clips of a single speaker reading passages from books. The total audio duration is approximately 24 hours, with audio quality improved to 48 kHz sampling rate.\\nThis dataset is licensed under the CC-BY-4.0 License.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCreation\\n\\t\\n\\nThe JL Speech dataset was created by converting the original LJ Speech dataset to a male… See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/jl-speech."},
	{"name":"uzbek-speech-corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murodbek/uzbek-speech-corpus","creator_name":"Abror Shopulatov","creator_url":"https://huggingface.co/murodbek","description":"\\n\\t\\n\\t\\t\\n\\t\\tUzbek Speech Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Uzbek speech corpus (USC) has been developed in collaboration between ISSAI and the Image and Speech Processing Laboratory in the Department of Computer Systems of the Tashkent University of Information Technologies. The USC comprises 958 different speakers with a total of 105 hours of transcribed audio recordings. To ensure high quality, the USC has been manually checked by native speakers. The USC is primarily designed for… See the full description on the dataset page: https://huggingface.co/datasets/murodbek/uzbek-speech-corpus."},
	{"name":"hailuo-ai-jokes","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\\n\\t\\n\\t\\t\\n\\t\\tHailuo AI Jokes Dataset 🎤\\n\\t\\n\\n\\n\\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎙️ Dataset Content\\n\\t\\n\\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes."},
	{"name":"Audio-FLAN-Dataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tAudio-FLAN Dataset (Paper)\\n\\t\\n\\n(the FULL audio files and jsonl files are still updating)\\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \\n\\n\\t\\n\\t\\t\\n\\t\\t1. Dataset Structure\\n\\t\\n\\nThe Audio-FLAN-Dataset has the following directory structure:\\nAudio-FLAN-Dataset/\\n├── audio_files/\\n│   ├── audio/\\n│   │   └── 177_TAU_Urban_Acoustic_Scenes_2022/\\n│   │   └── 179_Audioset_for_Audio_Inpainting/\\n│   │   └── ...\\n│   ├── music/\\n│   │   └──… See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset."},
	{"name":"cv10-uk-testset-clean","keyword":"automatic-speech-recognition","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/cv10-uk-testset-clean","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe cleaned Common Voice 10 (test set) that has been checked by a human for Ukrainian 🇺🇦\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains the archive of Common Voice 10 (test set) with checked Ukrainian transcriptions and audios.\\nAll audios have been checked by a human to be sure that they are correct. \\nThis archive is used to test all ASR models listed here: https://github.com/egorsmkv/speech-recognition-uk\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech… See the full description on the dataset page: https://huggingface.co/datasets/Yehor/cv10-uk-testset-clean."},
	{"name":"Lux-Japanese-Speech-Corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus","creator_name":"KohnoseLami","creator_url":"https://huggingface.co/Lami","description":"\\n\\t\\n\\t\\t\\n\\t\\tLux Japanese Speech Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t概要\\n\\t\\n\\nLux Japanese Speech Corpus は、オリジナルキャラクター「Lux (ルクス)」による日本語のテキスト読み上げ音声を収録したデータセットです。このデータセットは、以下の2種類の音声ファイルで構成されています。\\n\\nraw: 加工前の 96kHz/16bit の WAV ファイル\\ncleaned: ノイズ除去などの処理を施した 96kHz/16bit の WAV ファイル\\n\\n各音声ファイルに対応するトランスクリプション（読み上げた文章）は、metadata.csv に記録しています。データセット全体のメタ情報は dataset_infos.json で管理されています。\\n\\n\\t\\n\\t\\t\\n\\t\\tディレクトリ構造\\n\\t\\n\\n以下は、このリポジトリの推奨ディレクトリ構造の例です。\\nLux-Japanese-Speech-Corpus/\\n├── .gitattributes           # Gitのカスタマイズファイル\\n├── README.md… See the full description on the dataset page: https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus."},
	{"name":"NPSC_test","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/NPSC_test","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NBAiLab/NPSC\\n\\t\\n\\nThe Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Språkbanken at the National Library in Norway. \\nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokmål or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant… See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/NPSC_test."},
	{"name":"sharif_emotional_speech_dataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset","creator_name":"Paria Jamshid Lou","creator_url":"https://huggingface.co/pariajm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSharif Emotional Speech Dataset (ShEMO)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset includes 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data extracted from online Persian radio plays. The ShEMO covers speech samples of 87 native-Persian speakers for five basic emotions including anger, fear, happiness, sadness and surprise, as well as neutral state. Twelve annotators label the underlying emotional state of utterances and majority voting is used… See the full description on the dataset page: https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset."},
	{"name":"ascend","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/filwsyl/ascend","creator_name":"jianyuan.zengjy","creator_url":"https://huggingface.co/filwsyl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASCEND\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.… See the full description on the dataset page: https://huggingface.co/datasets/filwsyl/ascend."},
	{"name":"openstt-uk","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/openstt-uk","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Speech-to-Text corpus for 🇺🇦 Ukrainian\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset has transcriptions with other metadata for the VOA Ukrainian dataset (~398h).\\n\\n\\t\\n\\t\\t\\n\\t\\tCite this work\\n\\t\\n\\n@misc {smoliakov_2025,\\n    author       = { {Smoliakov} },\\n    title        = { openstt-uk (Revision 88d95da) },\\n    year         = 2025… See the full description on the dataset page: https://huggingface.co/datasets/Yehor/openstt-uk."},
	{"name":"librispeech_asr_dummy","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy","creator_name":"Sanchit Gandhi","creator_url":"https://huggingface.co/sanchit-gandhi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for librispeech_asr_dummy\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a truncated version of the LibriSpeech dataset. It contains 20 samples from each of the splits. To view the full dataset, visit: https://huggingface.co/datasets/librispeech_asr\\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been… See the full description on the dataset page: https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy."},
	{"name":"toy_corpus_asr_es","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_es","creator_name":"Carlos Daniel Hernández Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\\n"},
	{"name":"nst","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jzju/nst","creator_name":"Johan Ju","creator_url":"https://huggingface.co/jzju","description":"Homepage: https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-56\\nUsed lydfiler_16_1.tar.gz and metadata_se_csv.zip\\n"},
	{"name":"ciempiess_test","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_test","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"The CIEMPIESS TEST Corpus is a gender balanced corpus destined to test acoustic models for the speech recognition task. The corpus was manually transcribed and it contains audio recordings from 10 male and 10 female speakers. The CIEMPIESS TEST is one of the three corpora included at the LDC's \\\\\\\"CIEMPIESS Experimentation\\\\\\\" (LDC2019S07)."},
	{"name":"samromur_children","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_children","creator_name":"Language and Voice Laboratory (Reykjavík University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"The Samrómur Children corpus contains more than 137000 validated speech-recordings uttered by Icelandic children."},
	{"name":"xbmu_amdo31","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/syzym/xbmu_amdo31","creator_name":"Senyan Li","creator_url":"https://huggingface.co/syzym","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [XBMU-AMDO31]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXBMU-AMDO31 dataset is a speech recognition corpus of Amdo Tibetan dialect. The open source corpus contains 31 hours of speech data and resources related to build speech recognition systems, including transcribed texts and a Tibetan pronunciation dictionary.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nautomatic-speech-recognition: The dataset can be used to train a model for Amdo Tibetan Automatic Speech… See the full description on the dataset page: https://huggingface.co/datasets/syzym/xbmu_amdo31."},
	{"name":"raddromur_asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr","creator_name":"Language and Voice Laboratory (Reykjavík University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for raddromur_asr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Raddrómur Icelandic Speech 22.09\\\" (\\\"Raddrómur Corpus\\\" for short) is an Icelandic corpus created by the Language and Voice Laboratory (LVL) at Reykjavík University (RU) in 2022. It is made out of radio podcasts mostly taken from RÚV (ruv.is).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample Usage\\n\\t\\n\\nThe Raddrómur Corpus counts with the train split only. To load the training split pass its name as a config name:\\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr."},
	{"name":"bible_tts_hausa","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vpetukhov/bible_tts_hausa","creator_name":"Viktor Petukhov","creator_url":"https://huggingface.co/vpetukhov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BibleTTS Hausa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBibleTTS is a large high-quality open Text-to-Speech dataset with up to 80 hours of single speaker, studio quality 48kHz recordings.\\nThis is a Hausa part of the dataset. Aligned hours: 86.6, aligned verses: 40,603.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nHausa\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\naudio: audio path\\nsentence: transcription of the audio\\nlocale: always set to ha\\nbook: 3-char book encoding\\nverse:… See the full description on the dataset page: https://huggingface.co/datasets/vpetukhov/bible_tts_hausa."},
	{"name":"libris_clean_100","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for librispeech_asr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for… See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100."},
	{"name":"msc","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/msc","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSMC Malayalam Speech Corpus\\n\\t\\n\\nMalayalam Speech Corpus (MSC) is a repository of curated speech samples collected using MSC web application, released by Swathanthra Malayalam Computing. \\nThe official blog post and source data can be found at https://blog.smc.org.in/malayalam-speech-corpus/.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe first version of Malayalam Speech Corpus contains 1541 speech samples from 75 contributors amounting to 1:38:16 hours of speech. It has 482 unique sentences… See the full description on the dataset page: https://huggingface.co/datasets/thennal/msc."},
	{"name":"ulca_ml","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/ulca_ml","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tULCA ASR Dataset Malayalam Speech Corpus\\n\\t\\n\\nThe labelled Malayalam speech subcorpus from the larger ULCA ASR Corpus.\\nThe speech is taken from news broadcasts, and is largely composed of short soundbites with some longer outliers.\\n"},
	{"name":"Umamusume-voice-text-pairs","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Plachta/Umamusume-voice-text-pairs","creator_name":"ElderFrog","creator_url":"https://huggingface.co/Plachta","description":"Plachta/Umamusume-voice-text-pairs dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"gos-demo","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bartelds/gos-demo","creator_name":"Martijn Bartelds","creator_url":"https://huggingface.co/bartelds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGronings transcribed speech\\n\\t\\n\\nDemonstration dataset with Gronings transcribed speech based on the dataset released by San et al. (2021).\\nFor more information see the corresponding ASRU 2021 paper.\\n"},
	{"name":"cm.trial","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/taqwa92/cm.trial","creator_name":"taqwa mohamed","creator_url":"https://huggingface.co/taqwa92","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Common Voice Corpus 11.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \\nMany of the 24210 recorded hours in the dataset also include demographic metadata like age, sex, and accent \\nthat can help improve the accuracy of speech recognition engines.\\nThe dataset currently consists of 16413 validated hours in 100 languages, but more voices and languages are always added. \\nTake a look at the Languages… See the full description on the dataset page: https://huggingface.co/datasets/taqwa92/cm.trial."},
	{"name":"atco2_only_augmented","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/luigisaetta/atco2_only_augmented","creator_name":"LuigiSaetta","creator_url":"https://huggingface.co/luigisaetta","description":"luigisaetta/atco2_only_augmented dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"latvian-text","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RaivisDejus/latvian-text","creator_name":"Raivis Dejus","creator_url":"https://huggingface.co/RaivisDejus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLatvian text dataset\\n\\t\\n\\nData set of latvian language texts. Intended for use in AI tool development, like speech recognition or spellcheckers\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData sources used\\n\\t\\n\\n\\nLatvian Wikisource articles - https://wikisource.org/wiki/Category:Latvian\\nLiterary works of Rainis - https://repository.clarin.lv/repository/xmlui/handle/20.500.12574/41\\nLatvian Wikipedia articles - https://huggingface.co/datasets/joelito/EU_Wikipedias\\nEuropean Parliament Proceedings Parallel Corpus -… See the full description on the dataset page: https://huggingface.co/datasets/RaivisDejus/latvian-text."},
	{"name":"banc-trawsgrifiadau-bangor","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prvInSpace/banc-trawsgrifiadau-bangor","creator_name":"Preben Vangberg","creator_url":"https://huggingface.co/prvInSpace","description":"Huggingface Dataset version of Banc Trawsgrifiadau Bangor"},
	{"name":"or_in_dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ranjit/or_in_dataset","creator_name":"Ranjit Patro","creator_url":"https://huggingface.co/Ranjit","description":"Ranjit/or_in_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ami-ihm","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distil-whisper/ami-ihm","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\\nnon-native speakers. \\\\n"},
	{"name":"ami-sdm","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distil-whisper/ami-sdm","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\\nnon-native speakers. \\\\n"},
	{"name":"snips_slu_v1.0","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MWilinski/snips_slu_v1.0","creator_name":"Michał Wiliński","creator_url":"https://huggingface.co/MWilinski","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SNIPS SLU v1.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains SNIPS SLU Speech Recognition Dataset, available here.\\nIt contains recordings of commands for smart home appliances in English, with info about demographics of the speaker.\\n"},
	{"name":"test","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gogogogo-1/test","creator_name":"mhj","creator_url":"https://huggingface.co/gogogogo-1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Common Voice Corpus 10.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \\nMany of the 20817 recorded hours in the dataset also include demographic metadata like age, sex, and accent \\nthat can help improve the accuracy of speech recognition engines.\\nThe dataset currently consists of 15234 validated hours in 96 languages, but more voices and languages are always added. \\nTake a look at the Languages page… See the full description on the dataset page: https://huggingface.co/datasets/gogogogo-1/test."},
	{"name":"quantized-librispeech-train-360","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theblackcat102/quantized-librispeech-train-360","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"theblackcat102/quantized-librispeech-train-360 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"quantized-common-voice-en","keyword":"automatic-speech-recognition","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theblackcat102/quantized-common-voice-en","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"theblackcat102/quantized-common-voice-en dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"common-voice-en-revoice","keyword":"automatic-speech-recognition","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theblackcat102/common-voice-en-revoice","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"theblackcat102/common-voice-en-revoice dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"GMaSC","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/GMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGMaSC: GEC Barton Hill Malayalam Speech Corpus\\n\\t\\n\\nGMaSC is a Malayalam text and speech corpus created by the Government Engineering College Barton Hill with an emphasis on Malayalam-accented English. The corpus contains 2,000 text-audio pairs of Malayalam sentences spoken by 2 speakers, totalling in approximately 139 minutes of audio. Each sentences has at least one English word common in Malayalam speech.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of 2,000 instances… See the full description on the dataset page: https://huggingface.co/datasets/thennal/GMaSC."},
	{"name":"audio_letters_eo","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xekri/audio_letters_eo","creator_name":"Xekri Dragon","creator_url":"https://huggingface.co/xekri","description":"Audio files sampled at 48000Hz of an American male pronouncing the names of the Esperanto letters in three ways. Retroflex-r and trilled-r are included.\\n"},
	{"name":"librispeech_asr_individual","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Splend1dchan/librispeech_asr_individual","creator_name":"許湛然","creator_url":"https://huggingface.co/Splend1dchan","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87"},
	{"name":"amis_voice","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caasih/amis_voice","creator_name":"Isaac Huang","creator_url":"https://huggingface.co/caasih","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tamis_voice\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttest data\\n\\t\\n\\n\\nDr. Safulo Kacaw Lalanges introduces himself in Amis (Pangcah) Language: YouTube, WAV\\n\\n"},
	{"name":"the-mc-speech-dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset","creator_name":"Mateusz Czyżnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This is public domain speech dataset consisting of 24018 short audio clips of a single speaker reading sentences in Polish. A transcription is provided for each clip. Clips have total length of more than 22 hours.\\nTexts are in public domain. The audio was recorded in 2021-22 as a part of my master's thesis and is in public domain.\\nIf you use this dataset, please cite:\\n@masterthesis{mcspeech,\\n  title={Analiza porównawcza korpusów nagrań mowy dla celów syntezy mowy w języku polskim}… See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset."},
	{"name":"samromur_synthetic","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_synthetic","creator_name":"Language and Voice Laboratory (Reykjavík University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"Samrómur Synthetic consists of 72 hours of synthetized speech in Icelandic."},
	{"name":"ciempiess_light","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_light","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_light\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS LIGHT is a Radio Corpus designed to create acoustic models for automatic speech recognition and it is made up by recordings of spontaneous conversations in Mexican Spanish between a radio moderator and his guests. It is an enhanced version of the CIEMPIESS Corpus (LDC item LDC2015S07).\\nCIEMPIESS LIGHT is \\\"light\\\" because it doesn't include much of the files of the first version of CIEMPIESS and it is… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_light."},
	{"name":"ciempiess_balance","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_balance","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_balance\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS BALANCE Corpus is designed to match with the CIEMPIESS LIGHT Corpus (LDC2017S23). So, \\\"Balance\\\" means that if the CIEMPIESS BALANCE is combined with the CIEMPIESS LIGHT, one will get a gender balanced corpus. To appreciate this, one need to know that the CIEMPIESS LIGHT is by itself, a gender unbalanced corpus of approximately 25% of female speakers and 75% of male speakers. So, the CIEMPIESS BALANCE… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_balance."},
	{"name":"ciempiess_fem","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_fem","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_fem\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSince the publication of the CIEMPIESS Corpus (LDC2015S07) in 2015 we have noticed that there is a lack of female speakers in the sources where we traditionally take audio to create new CIEMPIESS datasets. That is why we decided to create a corpus that helps to balance future gender unbalanced datasets.\\nThe CIEMPIESS FEM Corpus was created by recordings and human transcripts of 21 different women. 16 of these women… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_fem."},
	{"name":"ciempiess_complementary","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_complementary","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_complementary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS COMPLEMENTARY is a phonetically balanced corpus of isolated Spanish words spoken by people of Central Mexico. It was designed to solve one particular issue when training automatic speech recognition (ASR) systems in the Spanish of Central Mexico. This problem appears when someone collects some training data, but the system complains because it does not find enough instances of one or more… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_complementary."},
	{"name":"bengali_asr_corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parambharat/bengali_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","description":"The corpus contains roughly 500 hours of audio and transcripts in Bangla language. \\nThe transcripts have beed de-duplicated using exact match deduplication and audio has be converted to 16000 samples"},
	{"name":"nb_samtale","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sprakbanken/nb_samtale","creator_name":"Nasjonalbiblioteket Språkbanken","creator_url":"https://huggingface.co/Sprakbanken","description":"NB Samtale is a speech corpus made by the Language Bank at the National Library of Norway.\\nThe corpus contains orthographically transcribed speech from podcasts and recordings of live events at the National Library.\\nThe corpus is intended as an open source dataset for Automatic Speech Recognition (ASR) development,\\nand is specifically aimed at improving ASR systems’ handle on conversational speech."},
	{"name":"red_ace_asr_error_detection_and_correction","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/red_ace_asr_error_detection_and_correction","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRED-ACE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset can be used to train and evaluate ASR Error Detection or Correction models. It was introduced in the RED-ACE paper (Gekhman et al, 2022).\\nThe dataset contains ASR outputs on the LibriSpeech corpus (Panayotov et al., 2015) with annotated transcription errors.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe LibriSpeech corpus was decoded using Google Cloud Speech-to-Text API, with the default and video models.\\nThe word-level confidence was… See the full description on the dataset page: https://huggingface.co/datasets/google/red_ace_asr_error_detection_and_correction."},
	{"name":"samromur_children_test","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ericwang/samromur_children_test","creator_name":"Zhiyong Wang","creator_url":"https://huggingface.co/Ericwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for samromur_children\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Samrómur Children Corpus consists of audio recordings and metadata files containing prompts read by the participants. It contains more than 137000 validated speech-recordings uttered by Icelandic children.\\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab (LVL) at the Reykjavik University, in cooperation with Almannarómur, Center for Language Technology. The recording… See the full description on the dataset page: https://huggingface.co/datasets/Ericwang/samromur_children_test."},
	{"name":"ami-ihm-timestamped","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distil-whisper/ami-ihm-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\\nnon-native speakers. \\\\n"},
	{"name":"ami-sdm-timestamped","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distil-whisper/ami-sdm-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\\nnon-native speakers. \\\\n"},
	{"name":"common_voice_13_0_dv_preprocessed","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ferno22/common_voice_13_0_dv_preprocessed","creator_name":"Ant","creator_url":"https://huggingface.co/ferno22","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Common Voice Corpus 13.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \\nMany of the 27141 recorded hours in the dataset also include demographic metadata like age, sex, and accent \\nthat can help improve the accuracy of speech recognition engines.\\nThe dataset currently consists of 17689 validated hours in 108 languages, but more voices and languages are always added. \\nTake a look at the Languages… See the full description on the dataset page: https://huggingface.co/datasets/ferno22/common_voice_13_0_dv_preprocessed."},
	{"name":"common_voice_13_0_dv_preprocessed","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fmagot01/common_voice_13_0_dv_preprocessed","creator_name":"Francisco Magot","creator_url":"https://huggingface.co/fmagot01","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Common Voice Corpus 13.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \\nMany of the 27141 recorded hours in the dataset also include demographic metadata like age, sex, and accent \\nthat can help improve the accuracy of speech recognition engines.\\nThe dataset currently consists of 17689 validated hours in 108 languages, but more voices and languages are always added. \\nTake a look at the Languages… See the full description on the dataset page: https://huggingface.co/datasets/fmagot01/common_voice_13_0_dv_preprocessed."},
	{"name":"common_voice_13_0_dv_preprocessed","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ssahir/common_voice_13_0_dv_preprocessed","creator_name":"Saad Sahir","creator_url":"https://huggingface.co/ssahir","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Common Voice Corpus 13.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \\nMany of the 27141 recorded hours in the dataset also include demographic metadata like age, sex, and accent \\nthat can help improve the accuracy of speech recognition engines.\\nThe dataset currently consists of 17689 validated hours in 108 languages, but more voices and languages are always added. \\nTake a look at the Languages… See the full description on the dataset page: https://huggingface.co/datasets/ssahir/common_voice_13_0_dv_preprocessed."},
	{"name":"nota","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nota","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Nota\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis data was created by the public institution Nota, which is part of the Danish Ministry of Culture. Nota has a library audiobooks and audiomagazines for people with reading or sight disabilities. Nota also produces a number of audiobooks and audiomagazines themselves.  \\nThe dataset consists of audio and associated transcriptions from Nota's audiomagazines \\\"Inspiration\\\" and \\\"Radio/TV\\\". All files related to one reading of one… See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nota."},
	{"name":"nst-da","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nst-da","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NST-da\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an upload of the NST Danish ASR Database (16 kHz) – reorganized.\\nThe training and test splits are the original ones.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTraining automatic speech recognition is the intended task for this dataset. No leaderboard is active at this point.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is available in Danish (da).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances… See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nst-da."},
	{"name":"speech-mendeley-pa","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aipanjab/speech-mendeley-pa","creator_name":"AI Panjab","creator_url":"https://huggingface.co/aipanjab","description":"\\n\\t\\n\\t\\t\\n\\t\\tCredit - https://data.mendeley.com/datasets/sdbc8f5b77/2\\n\\t\\n\\n"},
	{"name":"sixuxar_yijiri_mak7","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anzorq/sixuxar_yijiri_mak7","creator_name":"AQ","creator_url":"https://huggingface.co/anzorq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Info\\n\\t\\n\\nThis dataset consists of paired audio and text data sourced from the following book:\\n\\nTitle: Къэрмокъуэ М. Щихухэр иджыри мэкI. Япэ тхылъ.\\nPublication: Нальчик: Эльбрус, 1999\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAudio Specifications\\n\\t\\n\\n\\nSample Rate: 16,000 Hz\\nTotal Length: 10:36:40\\nSource: adigabook.ru\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcessing Information\\n\\t\\n\\nAudio-text pairs for this dataset were extracted and aligned using META AI's forced alignment algorithm.\\n"},
	{"name":"medical_asr_recording_dataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hani89/medical_asr_recording_dataset","creator_name":"Hani. M","creator_url":"https://huggingface.co/Hani89","description":"Data Source\\nKaggle Medical Speech, Transcription, and Intent\\nContext\\n\\n8.5 hours of audio utterances paired with text for common medical symptoms.\\n\\nContent\\n\\nThis data contains thousands of audio utterances for common medical symptoms like “knee pain” or “headache,” totaling more than 8 hours in aggregate. Each utterance was created by individual human contributors based on a given symptom. These audio snippets can be used to train conversational agents in the medical field.\\nThis Figure Eight… See the full description on the dataset page: https://huggingface.co/datasets/Hani89/medical_asr_recording_dataset."},
	{"name":"Medical_Interview","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SandO114/Medical_Interview","creator_name":"Heyang Liu","creator_url":"https://huggingface.co/SandO114","description":"The dataset was re-organized and used in the following paper. Please cite if you adopted the corpus in your work.\\n@inproceedings{liu2024post,\\n  title={Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview},\\n  author={Liu, Heyang and Wang, Yanfeng and Wang, Yu},\\n  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},\\n  pages={12917--12926},\\n  year={2024}\\n}\\n\\n"},
	{"name":"vibravox","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de Mécanique des Structures et des Systèmes Couplés","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for VibraVox\\n\\t\\n\\n\\n  \\n\\n\\n\\n👀 While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\\nwhich has exactly the same architecture.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDATASET SUMMARY\\n\\t\\n\\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\\nThis dataset can be used for various audio machine learning tasks :\\n\\nAutomatic Speech Recognition (ASR) (Speech-to-Text… See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox."},
	{"name":"LatinAccents","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jstack32/LatinAccents","creator_name":"Joey Stack","creator_url":"https://huggingface.co/jstack32","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/jstack32/LatinAccents."},
	{"name":"simsamu","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/medkit/simsamu","creator_name":"medkit","creator_url":"https://huggingface.co/medkit","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSimsamu dataset\\n\\t\\n\\nThis repository contains recordings of simulated medical dispatch dialogs in the\\nfrench language, annotated for diarization and transcription. It is published\\nunder the MIT license.\\nThese dialogs were recorded as part of the training of emergency medicine\\ninterns, which consisted in simulating a medical dispatch call where the interns\\ntook turns playing the caller and the regulating doctor. \\nEach situation was decided randomly in advance, blind to who was playing… See the full description on the dataset page: https://huggingface.co/datasets/medkit/simsamu."},
	{"name":"auto-pale","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeio/auto-pale","creator_name":"zeionara","creator_url":"https://huggingface.co/zeio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for pale\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nThis dataset contains league of legends champions' quotes parsed from fandom.\\nSee dataset usage example at google colab.\\nThe dataset is available in the following configurations:\\n\\nvanilla - all data pulled from the website without significant modifications apart from the web page structure parsing;\\nquotes - truncated version of the corpus, which does't contain sound effects;\\nannotated - an extended version of the full… See the full description on the dataset page: https://huggingface.co/datasets/zeio/auto-pale."},
	{"name":"imasc_slr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/imasc_slr","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"Clone of : thennal/IMaSC\\n"},
	{"name":"Vibravox_dummy","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"Éric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"speechocean762","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seba3y/speechocean762","creator_name":"Elsebaiy mohamed","creator_url":"https://huggingface.co/seba3y","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tspeechocean762: A non-native English corpus for pronunciation scoring task\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use?\\n\\t\\n\\nyou can load data using\\nspeechocean762_dataset = load_dataset('seba3y/speechocean762')\\n\\n>> speechocean762_dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['spk', 'age', 'gender', 'utt_name', 'audio', 'utt_text', 'utt_accuracy', 'utt_completeness', 'utt_fluency', 'utt_prosodic', 'utt_total', 'words', 'words_accuracy', 'words_stress', 'words_total', 'phones'… See the full description on the dataset page: https://huggingface.co/datasets/seba3y/speechocean762."},
	{"name":"work","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gustav114514/work","creator_name":"Ryohei Kasai","creator_url":"https://huggingface.co/Gustav114514","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFine-tuned XLSR-53 large model for speech recognition in Japanese\\n\\t\\n\\nFine-tuned facebook/wav2vec2-large-xlsr-53 on Japanese using the train and validation splits of Common Voice 6.1, CSS10 and JSUT.\\nWhen using this model, make sure that your speech input is sampled at 16kHz.\\nThis model has been fine-tuned thanks to the GPU credits generously given by the OVHcloud :)\\nThe script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage… See the full description on the dataset page: https://huggingface.co/datasets/Gustav114514/work."},
	{"name":"escagleu-64k","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/escagleu-64k","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for escagleu-64K corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nescagleu-64k is a parallel corpus comprising 64091 sentences translated among Spanish, Catalan, Valencian Catalan, Galician, and Basque.\\nThe original sentences are in Spanish and come from the Spanish Common Voice Corpus.\\nWe prepared this corpus with the aim of creating a parallel speech dataset among these languages using the Common Voice platform between the frame of the… See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/escagleu-64k."},
	{"name":"RSL_Maran","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran."},
	{"name":"wiki-en-in-neerja-speech","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"This dataset contains 10K audio samples generated using Microsoft Edge Text-to-Speech via EdgeTTS. \\n\\nTotal samples: 10K\\nAudio format: MP3\\nSample rate: 24kHz\\nTotal duration: 95735.86 seconds (26.59 hours)\\nAverage duration: 9.57 seconds\\nLanguages included: English\\nVoices used: en-IN-NeerjaExpressiveNeural\\n\\nInput sentences were randomly sampled from Wikipedia, provided by the Wikimedia Foundation under the GNU Free Documentation License (GFDL) and the Creative Commons Attribution-Share-Alike 3.0… See the full description on the dataset page: https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech."},
	{"name":"Zeroth-STT-Korean","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/o0dimplz0o/Zeroth-STT-Korean","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\\n\\t\\n\\t\\t\\n\\t\\tZeroth-STT-Korean Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis is a shuffled version of the Zeroth-STT-Ko dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0 license.\\nJunhoee/STT_Korean_Dataset_80000 Dataset, created by [Junhoee], 2024.\\nAvailable at https://huggingface.co/datasets/Junhoee/STT_Korean_Dataset_80000\\n"},
	{"name":"TOSD","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tamazight-NLP/TOSD","creator_name":"Tamazight NLP","creator_url":"https://huggingface.co/Tamazight-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Tamazight Open Speech Dataset\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/Tamazight-NLP/TOSD."},
	{"name":"farsi-asr-dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/farsi-asr/farsi-asr-dataset","creator_name":"Farsi ASR","creator_url":"https://huggingface.co/farsi-asr","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tFarsi ASR Dataset\\n\\t\\n\\nThe largest open-source Persian Automatic Speech Recognition (ASR) dataset, collected from various sources. The codes associated with the collection of this dataset is also available in the Farsi ASR Dataset GitHub repository.\\n"},
	{"name":"semi-Voxpopuli","keyword":"speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli","creator_name":"Jagadeesh Rachapudi","creator_url":"https://huggingface.co/Jagadeesh9580","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVoxPopuli Multilingual Audio Dataset\\n\\t\\n\\nThis dataset contains audio recordings in English (EN), Polish (PL), and Swedish (SV) languages. It is derived from the VoxPopuli dataset and tailored for multilingual language processing tasks.\\nThe dataset includes audio clips and corresponding metadata to support research and development in multilingual audio processing.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Files\\n\\t\\n\\nThe dataset includes the following files:\\n\\ndata.csv: Contains metadata about the audio files… See the full description on the dataset page: https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli."},
	{"name":"common_voice_19_0_zh-TW","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/common_voice_19_0_zh-TW","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommon Voice Corpus 19.0 Chinese (Taiwan)\\n\\t\\n\\nThe test set is the same as the original test set, while validated_without_test includes all validated examples except those with sentence IDs that appear in the test set.\\n\\nvalidated_without_test has about 50,000 examples in total, equivalent to approximately 44 hours, and is intended for use as the training set.\\ntest has about 5,000 examples, which is approximately 5 hours.\\n\\n"},
	{"name":"SIWIS_French_Speech_Synthesis_Database","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database","creator_name":"Anthonny Olime","creator_url":"https://huggingface.co/Aviv-anthonnyolime","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIWIS French Speech Synthesis Database\\n\\t\\n\\nThis README provides a concise description of the dataset, including its structure, file naming conventions, and known labeling issues. Additionally, suggestions for potential improvements are outlined in the TODO section.  \\nThe dataset is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting its use for any purpose.  \\nFor more details about the database design and recording process, please… See the full description on the dataset page: https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database."},
	{"name":"Uzbek_Speech_Corpus","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\\n\\t\\n\\t\\t\\n\\t\\tUzbek Speech Corpus (USC)\\n\\t\\n\\nPaper: USC: An Open-Source Uzbek Speech Corpus and Initial Speech Recognition Experiments\\nSummary: This repository contains dataset for reproducing the results presented in the paper \\\"USC: An Open-Source Uzbek Speech Corpus\\\". USC is a freely available, manually checked speech corpus comprising 958 speakers and 105 hours of transcribed audio recordings. \\nDataset Summary:\\n\\n\\t\\n\\t\\t\\nFeature\\nDescription\\n\\n\\n\\t\\t\\nLanguage\\nUzbek\\n\\n\\nSize\\n105 hours of audio\\n\\n\\nNumber of… See the full description on the dataset page: https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus."},
	{"name":"Multilingual_Speech_Dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Speech Dataset\\n\\t\\n\\nPaper: A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\\nRepository: https://github.com/IS2AI/MultilingualASR\\nDescription: This repository provides the dataset used in the paper \\\"A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\\\". The paper focuses on training a single end-to-end (E2E) ASR model for Kazakh, Russian, and English, comparing monolingual and multilingual approaches… See the full description on the dataset page: https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset."},
	{"name":"Kazakh_Speech_Corpus_2","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\\n\\t\\n\\t\\t\\n\\t\\tKazakh Speech Corpus 2 (KSC2)\\n\\t\\n\\nThis dataset card describes the KSC2, an industrial-scale, open-source speech corpus for the Kazakh language.\\nPaper: KSC2: An Industrial-Scale Open-Source Kazakh Speech Corpus\\nSummary: KSC2 corpus subsumes the previously introduced two corpora: Kazakh Speech Corpus and Kazakh Text-To-Speech 2, and supplements additional data from other sources like tv programs, radio, senate, and podcasts. In total, KSC2 contains around 1.2k hours of high-quality… See the full description on the dataset page: https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2."},
	{"name":"real-world-noise-through-zoom","keyword":"automatic-speech-recognition","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KoelLabs/real-world-noise-through-zoom","creator_name":"Koel Labs","creator_url":"https://huggingface.co/KoelLabs","description":"\\n\\t\\n\\t\\t\\n\\t\\tReal-World Noise Through Zoom (RWNTZ)\\n\\t\\n\\n\\n5 different real world noise settings (bedroom, crowded room, background music, rain, road with cars)\\n2 different speakers\\nvarious microphone distances (6 inches, 24 inches)\\n32 total samples with different phrases\\nrecorded through Zoom to simulate real-world linguistic fieldwork scenarios\\nmanually verified word level transcriptions\\ng2p phoneme trancriptions\\naudio to phoneme trancriptions with a variety of Wav2Vec2 based models\\n\\n"},
	{"name":"whisper-internal-test","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulus/whisper-internal-test","creator_name":"Minseok Lee","creator_url":"https://huggingface.co/neulus","description":"Original datasets can be found in shb777/gemini-flash-2.0-speech.\\nFor personal testing purposes.\\n"},
	{"name":"V1Q","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
	{"name":"Tamazight-ASR-Dataset-v2","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2","creator_name":"Soufiane Dahimi","creator_url":"https://huggingface.co/SoufianeDahimi","description":"\\n\\t\\n\\t\\t\\n\\t\\tTamazight-Arabic Speech Recognition Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains speech segments in Tamazight (specifically focusing on the Tachelhit dialect) paired with their corresponding Arabic transcriptions. It is designed to support the development of automatic speech recognition (ASR) systems for the Tamazight language, particularly for translation into Modern Standard Arabic.\\nThis is an actively growing dataset, with regular updates and new data points being… See the full description on the dataset page: https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2."},
	{"name":"sTinyStories","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/sTinyStories","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\\n\\t\\n\\t\\t\\n\\t\\tsTinyStories\\n\\t\\n\\nA spoken version of TinyStories Synthesized with LJ voice using FastSpeech2.\\nThe dataset was synthesized to boost the training of Speech Language Models as detailed in the paper \\\"Slamming: Training a Speech Language Model on One GPU in a Day\\\".\\nIt was first suggested by Cuervo et. al 2024.\\nWe refer you to the SlamKit codebase to see how you can train a SpeechLM with this dataset.\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets importload_dataset\\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/slprl/sTinyStories."},
	{"name":"ScreenTalk-XS","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataLabX/ScreenTalk-XS","creator_name":"DataLabX","creator_url":"https://huggingface.co/DataLabX","description":"\\n\\t\\n\\t\\t\\n\\t\\t🎬 ScreenTalk-XS: Sample Speech Dataset from Screen Content 🖥️\\n\\t\\n\\n  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📢 What is ScreenTalk-XS?\\n\\t\\n\\nScreenTalk-XS is a high-quality transcribed speech dataset containing 10k speech samples from diverse screen content.It is designed for automatic speech recognition (ASR), natural language processing (NLP), and conversational AI research.  \\n✅ This dataset is freely available for research and educational use.🔹 If you need a larger dataset with more diverse speech samples… See the full description on the dataset page: https://huggingface.co/datasets/DataLabX/ScreenTalk-XS."},
	{"name":"voice-of-america","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/voice-of-america","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\\n\\t\\n\\t\\t\\n\\t\\tVoice of America for  🇺🇦 Ukrainian\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCommunity\\n\\t\\n\\n\\nDiscord: https://bit.ly/discord-uds\\nSpeech Recognition: https://t.me/speech_recognition_uk\\nSpeech Synthesis: https://t.me/speech_synthesis_uk\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tStatistics\\n\\t\\n\\nDuration: 390.99 hours\\n\\nmean: 4.315471\\nstd: 3.63682\\nmin: 0.2995625\\n25%: 1.82\\n50%: 3.42\\n75%: 5.628\\nmax: 29.98\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCite this work\\n\\t\\n\\n@misc {smoliakov_2025,\\n    author       = { {Smoliakov} },\\n    title        = { opentts-uk (Revision 32abc9c) },\\n    year… See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/voice-of-america."},
	{"name":"nepali_speech_to_text","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text","creator_name":"Pujan Paudel","creator_url":"https://huggingface.co/pujanpaudel","description":"\\n\\t\\n\\t\\t\\n\\t\\tNepali Speech-to-Text Dataset\\n\\t\\n\\nThis repository contains a dataset for Automatic Speech Recognition (ASR) in the Nepali language. The dataset is designed for supervised learning tasks and includes audio files along with their corresponding transcriptions. The audio samples have been collected from various open-source platforms and other publicly available sources on the internet.  \\nEach audio file has an average length of 15 seconds and has been converted into a consistent WAV format… See the full description on the dataset page: https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text."},
	{"name":"air-traffic-dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mehmedadymn/air-traffic-dataset","creator_name":"adıyaman","creator_url":"https://huggingface.co/mehmedadymn","description":"\\n\\t\\n\\t\\t\\n\\t\\tATC Veri Kümesi - Whisper Modeli ile İnce Ayar\\n\\t\\n\\nBu veri kümesi, OpenAI'nin Whisper modelini, Hava Trafik Kontrolü (ATC) iletişimlerinde transkripsiyon doğruluğunu artırmak amacıyla ince ayar yapmak için oluşturulmuştur. Veri kümesi, iki ana kaynaktan alınan transkripsiyonlar ve karşılık gelen ses dosyalarını içermektedir: ATCO2 ve UWB-ATCC korpusu, özellikle havacılıkla ilgili iletişimler için seçilmiştir. Veri kümesi, Otomatik Konuşma Tanıma (ASR) projelerinde kullanılmak üzere… See the full description on the dataset page: https://huggingface.co/datasets/mehmedadymn/air-traffic-dataset."},
	{"name":"YouTube_Video_Transkriptleri_TR","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anilosan15/YouTube_Video_Transkriptleri_TR","creator_name":"Hüseyin Anıl Çakmak","creator_url":"https://huggingface.co/Anilosan15","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of nearly 5 hours of video from over 40 Creative Commons-licensed videos on YouTube. The videos contain the voices of more than 100 different people. The audio files have been resampled to 16 kHz. The videos have been divided into chunks of up to 25 seconds. This dataset is intended for developing Turkish STT (Speech-to-Text) models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDatasets Preparetion\\n\\t\\n\\nThe audio files and transcript data were scraped from YouTube. The scraped… See the full description on the dataset page: https://huggingface.co/datasets/Anilosan15/YouTube_Video_Transkriptleri_TR."},
	{"name":"Emilia-YODAS","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrfakename/Emilia-YODAS","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\\n"},
	{"name":"common-voice-20-mn-normalized","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized","creator_name":"Ankhbayasgalan Davaadorj","creator_url":"https://huggingface.co/warmestman","description":"\\n\\t\\n\\t\\t\\n\\t\\tCommon Voice 20.0 Mongolian Dataset\\n\\t\\n\\nThis dataset is a subset of Mozilla's Common Voice project, containing Mongolian speech data. It's part of Common Voice 20.0 release.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio clips in .mp3 format\\nTranscriptions for each audio clip\\nTrain/test/dev splits\\nAdditional metadata including speaker demographics\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nThis dataset can be used for:\\n\\nSpeech Recognition\\nVoice Analysis\\nLinguistic Research\\nSpeech Processing… See the full description on the dataset page: https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized."},
	{"name":"common-voice-corpus-20","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hataphu/common-voice-corpus-20","creator_name":"Ha Van Tan","creator_url":"https://huggingface.co/hataphu","description":"hataphu/common-voice-corpus-20 dataset hosted on Hugging Face and contributed by the HF Datasets community"}
]
;
