const data_for_modality_speech = 
[
	{"name":"pashto_speech_20k","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_20k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (20k)\n\t\n\nThis dataset contains 40000 synthetic speech recordings in the Pashto language,\nwith 20000 male voice recordings and 20000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 20000 sentences\nTotal Recordings: 40000 audio files (20000 male + 20000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_20k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_20k","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_20k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (20k)\n\t\n\nThis dataset contains 40000 synthetic speech recordings in the Pashto language,\nwith 20000 male voice recordings and 20000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 20000 sentences\nTotal Recordings: 40000 audio files (20000 male + 20000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_20k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"TurkicTTS-Chuvash","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tTurkic_TTS-Chuvash\n\t\n\n[Original repository] \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkic_TTS-Chuvash is a speech dataset sourced from the Turkic_TTS GitHub repository. The dataset comprises recordings of text extracted from news articles on chuvash.org and list of digits, all read by a single female speaker at a rapid tempo. The dataset is intended for text-to-speech (TTS) research and development in the Chuvash language. The license and citation information presented in this dataset card has… See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Chuvash","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TurkicTTS-Chuvash","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tTurkic_TTS-Chuvash\n\t\n\n[Original repository] \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkic_TTS-Chuvash is a speech dataset sourced from the Turkic_TTS GitHub repository. The dataset comprises recordings of text extracted from news articles on chuvash.org and list of digits, all read by a single female speaker at a rapid tempo. The dataset is intended for text-to-speech (TTS) research and development in the Chuvash language. The license and citation information presented in this dataset card has… See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Chuvash","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TurkicTTS-Chuvash","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tTurkic_TTS-Chuvash\n\t\n\n[Original repository] \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkic_TTS-Chuvash is a speech dataset sourced from the Turkic_TTS GitHub repository. The dataset comprises recordings of text extracted from news articles on chuvash.org and list of digits, all read by a single female speaker at a rapid tempo. The dataset is intended for text-to-speech (TTS) research and development in the Chuvash language. The license and citation information presented in this dataset card has… See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Chuvash","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"prueba_parquet","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/prueba_parquet","creator_name":"Carlos Daniel Hernández Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with parquet files only.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"Corinth_dataset","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OlameMend/Corinth_dataset","creator_name":"leo","creator_url":"https://huggingface.co/OlameMend","description":"OlameMend/Corinth_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ga_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tGa Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ga Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Ga, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech Dataset… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Irish","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ga_multispeaker_audio_transcribed","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tGa Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ga Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Ga, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech Dataset… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Irish","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"multiCHILDES","keyword":"linguistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"Iñigo Parra","creator_url":"https://huggingface.co/IParraMartin","description":"\n\t\n\t\t\n\t\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: CHILDES corpus\nLanguages: 19 languages\nText Type: Child-directed speech\nTask: Text Generation, Language Modeling\nData Processing: The dataset… See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES.","first_N":5,"first_N_keywords":["text-generation","English","Basque","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"common-voice-corpus-20","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hataphu/common-voice-corpus-20","creator_name":"Ha Van Tan","creator_url":"https://huggingface.co/hataphu","description":"hataphu/common-voice-corpus-20 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"CADE","keyword":"hate-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aequa-tech/CADE","creator_name":"aequa-tech","creator_url":"https://huggingface.co/aequa-tech","description":"\n\t\n\t\t\n\t\tThe Canceling Attitudes Detection (CADE) Dataset\n\t\n\nCADE is a dataset created in the context of the research That is Unacceptable: the Moral Foundations of Canceling. Here you can find the abstract.\nCanceling is a morally-driven phenomenon that hinders the development of safe social media platforms and contributes to ideological polarization. To address this issue we present the Canceling Attitudes Detection (CADE) dataset, an annotated corpus of canceling incidents aimed at exploring… See the full description on the dataset page: https://huggingface.co/datasets/aequa-tech/CADE.","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"twi_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Twi Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Asante Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"twi_multispeaker_audio_transcribed","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Twi Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Asante Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"akuapem_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tAkuapem Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Akuapem Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Akuapem Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"akuapem_multispeaker_audio_transcribed","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tAkuapem Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Akuapem Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Akuapem Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"fante_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tFante Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Fante Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Fante, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Fanti","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"fante_multispeaker_audio_transcribed","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tFante Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Fante Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Fante, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Fanti","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MiscSpeech-ja","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rakuto/MiscSpeech-ja","creator_name":"rakuto","creator_url":"https://huggingface.co/Rakuto","description":"\n\t\n\t\t\n\t\tMiscSpeech-ja\n\t\n\nThis dataset comprises audio and corresponding transcripts collected from a diverse range of YouTube videos and Podcasts. \n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MiscSpeech-ja","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rakuto/MiscSpeech-ja","creator_name":"rakuto","creator_url":"https://huggingface.co/Rakuto","description":"\n\t\n\t\t\n\t\tMiscSpeech-ja\n\t\n\nThis dataset comprises audio and corresponding transcripts collected from a diverse range of YouTube videos and Podcasts. \n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"nigerian_accented_english_dataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Accent English Speech Data 1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Accent Speech Data is a comprehensive dataset of about 8 hours of audio recordings featuring speakers from various regions of Nigeria, \ncapturing the rich diversity of Nigerian accents. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for researchers and developers working on Automatic Speech… See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","English"],"keywords_longer_than_N":true},
	{"name":"nigerian_accented_english_dataset","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Accent English Speech Data 1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Accent Speech Data is a comprehensive dataset of about 8 hours of audio recordings featuring speakers from various regions of Nigeria, \ncapturing the rich diversity of Nigerian accents. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for researchers and developers working on Automatic Speech… See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","English"],"keywords_longer_than_N":true},
	{"name":"audiotest","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Andy2505/audiotest","creator_name":"Andy2505","creator_url":"https://huggingface.co/Andy2505","description":"An audio dataset for test.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"DailyTalkContiguous-ja","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rakuto/DailyTalkContiguous-ja","creator_name":"rakuto","creator_url":"https://huggingface.co/Rakuto","description":"\n\t\n\t\t\n\t\tDailyTalkContiguous-ja: Spoken Dialogue Dataset in Japanese\n\t\n\nDailyTalkContiguous-ja is a synthetic multi-turn Japanese conversational speech dataset in which DailyTalk [Keon Lee etal., 2022]\ntranslated by Gemma-3-27B and speech data is synthesized by TTS engine Zyphra/Zonos-v0.1-transformer.\nFor each speaker in covnersation, different voice is randomly asssigned from voice dataset with five voices in total.\nAs like with kyutai/DailyTalkContiguous, rather than having separate files… See the full description on the dataset page: https://huggingface.co/datasets/Rakuto/DailyTalkContiguous-ja.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc-by-sa-4.0","arxiv:2207.01063","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"emotion-prompts","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/caster97/emotion-prompts","creator_name":"caster97","creator_url":"https://huggingface.co/caster97","description":"\n\t\n\t\t\n\t\tEmotion Prompts Dataset\n\t\n\nThis dataset contains simple textual prompts designed for eliciting or detecting emotional tones in generated speech or text. It is useful for training or evaluating emotion-conditioned models such as TTS (text-to-speech) or dialogue systems.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nDifficulty: Describes prompt complexity (Simple, Moderate, Complex).\nPrompt: A text prompt with an {emotion} placeholder.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo use this dataset with the Hugging Face Datasets… See the full description on the dataset page: https://huggingface.co/datasets/caster97/emotion-prompts.","first_N":5,"first_N_keywords":["text-to-speech","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"emotion-prompts","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/caster97/emotion-prompts","creator_name":"caster97","creator_url":"https://huggingface.co/caster97","description":"\n\t\n\t\t\n\t\tEmotion Prompts Dataset\n\t\n\nThis dataset contains simple textual prompts designed for eliciting or detecting emotional tones in generated speech or text. It is useful for training or evaluating emotion-conditioned models such as TTS (text-to-speech) or dialogue systems.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nDifficulty: Describes prompt complexity (Simple, Moderate, Complex).\nPrompt: A text prompt with an {emotion} placeholder.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo use this dataset with the Hugging Face Datasets… See the full description on the dataset page: https://huggingface.co/datasets/caster97/emotion-prompts.","first_N":5,"first_N_keywords":["text-to-speech","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"conrad-lynk-voice-pack-test","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-test","creator_name":"Bland AI","creator_url":"https://huggingface.co/BlandAIOrg","description":"\n\t\n\t\t\n\t\tConrad Lynk Voice Pack\n\t\n\nA high-quality voice dataset featuring Conrad Lynk, an AI assistant for real estate professionals.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Files: 144 audio samples\nFormat: WAV audio with text transcripts\nLanguage: English\nDomain: Real estate conversations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"BlandAIOrg/conrad-lynk-voice-pack\")\n\n# Access audio and text\nfor item in dataset['train']:\n    audio = item['audio']… See the full description on the dataset page: https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-test.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"conrad-lynk-voice-pack-test","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-test","creator_name":"Bland AI","creator_url":"https://huggingface.co/BlandAIOrg","description":"\n\t\n\t\t\n\t\tConrad Lynk Voice Pack\n\t\n\nA high-quality voice dataset featuring Conrad Lynk, an AI assistant for real estate professionals.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Files: 144 audio samples\nFormat: WAV audio with text transcripts\nLanguage: English\nDomain: Real estate conversations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"BlandAIOrg/conrad-lynk-voice-pack\")\n\n# Access audio and text\nfor item in dataset['train']:\n    audio = item['audio']… See the full description on the dataset page: https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-test.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"conrad-lynk-voice-pack-enhanced","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-enhanced","creator_name":"Bland AI","creator_url":"https://huggingface.co/BlandAIOrg","description":"\n\t\n\t\t\n\t\tConrad Lynk Voice Pack (Enhanced)\n\t\n\nA high-quality voice dataset featuring Conrad Lynk, an AI assistant for real estate professionals. This enhanced version includes speaker identification and detailed audio metadata.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Files: 144 audio samples\nSpeaker: Conrad Lynk (AI assistant)\nFormat: WAV audio with text transcripts\nLanguage: English\nDomain: Real estate conversations\nSample Rate: 48 kHz\nChannels: Mono\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach row contains:… See the full description on the dataset page: https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-enhanced.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"conrad-lynk-voice-pack-enhanced","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-enhanced","creator_name":"Bland AI","creator_url":"https://huggingface.co/BlandAIOrg","description":"\n\t\n\t\t\n\t\tConrad Lynk Voice Pack (Enhanced)\n\t\n\nA high-quality voice dataset featuring Conrad Lynk, an AI assistant for real estate professionals. This enhanced version includes speaker identification and detailed audio metadata.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Files: 144 audio samples\nSpeaker: Conrad Lynk (AI assistant)\nFormat: WAV audio with text transcripts\nLanguage: English\nDomain: Real estate conversations\nSample Rate: 48 kHz\nChannels: Mono\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach row contains:… See the full description on the dataset page: https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-enhanced.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"YouTube-Cantonese","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OrcinusOrca/YouTube-Cantonese","creator_name":"Orca","creator_url":"https://huggingface.co/OrcinusOrca","description":"\n\t\n\t\t\n\t\tCantonese Audio Dataset from YouTube\n\t\n\nThis dataset contains Cantonese audio segments extracted from various YouTube channels, along with corresponding transcription metadata. The data is intended for training automatic speech recognition (ASR) models.\n\n\t\n\t\t\n\t\tData Source and Processing\n\t\n\nThe data was obtained through the following process:\n\nDownload: Audio (.m4a) and available Cantonese subtitles (.srt for zh-TW, zh-HK, zh-Hant) were downloaded from selected YouTube channels. This… See the full description on the dataset page: https://huggingface.co/datasets/OrcinusOrca/YouTube-Cantonese.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","Yue Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"animespeech-orpheus-prep-800","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/taresh18/animespeech-orpheus-prep-800","creator_name":"Taresh Rajput","creator_url":"https://huggingface.co/taresh18","description":"Preprocessed dataset in Orpheus TTS FT format corresponding to voices [\"107\", \"125\", \"145\", \"16\", \"163\", \"179\", \"180\", \"183\", \"185\", \"187\"] from ShoukanLabs/AniSpeech\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"animespeech-orpheus-prep-800","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/taresh18/animespeech-orpheus-prep-800","creator_name":"Taresh Rajput","creator_url":"https://huggingface.co/taresh18","description":"Preprocessed dataset in Orpheus TTS FT format corresponding to voices [\"107\", \"125\", \"145\", \"16\", \"163\", \"179\", \"180\", \"183\", \"185\", \"187\"] from ShoukanLabs/AniSpeech\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_5_10","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 252\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise… See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_5_10","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 252\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise… See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Ranjan-Hindi33min","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BBSRguy/Ranjan-Hindi33min","creator_name":"Rashmi Ranjan Dash","creator_url":"https://huggingface.co/BBSRguy","description":"\n\t\n\t\t\n\t\tRanjan-Hindi33min\n\t\n\nOwner: @BBSRguyCreated: 2025-06-03Year: 2025Language: Hindi 🇮🇳Region Focus: Odisha, IndiaSample Rate Variants: 16 kHz, 24 kHz, 32 kHzTotal Files: 29 pairs (speech + text)Duration: Approximately 33 minutes of speech  \n\n\n\t\n\t\t\n\t\n\t\n\t\t📜 Description\n\t\n\nRanjan-Hindi33min is a meticulously curated dataset comprising high-quality Hindi speech samples and their corresponding textual transcriptions. This dataset is designed to support various speech processing tasks… See the full description on the dataset page: https://huggingface.co/datasets/BBSRguy/Ranjan-Hindi33min.","first_N":5,"first_N_keywords":["text-to-speech","Hindi","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"stereotypes","keyword":"hate-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aequa-tech/stereotypes","creator_name":"aequa-tech","creator_url":"https://huggingface.co/aequa-tech","description":"aequa-tech/stereotypes dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","text2text-generation","Italian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"2hr_myanmar_asr_raw_audio","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t🇲🇲 Raw 2-Hour Burmese ASR Audio Dataset\n\t\n\nA ~2-hour Burmese (Myanmar language) ASR dataset featuring 1,612 audio clips with aligned transcripts, curated from official public-service educational broadcasts by FOEIM Academy — a civic media arm of FOEIM.ORG, operating under the Myanmar National Unity Government (NUG).\nThis dataset is MIT-licensed as a public good — a shared asset for the Burmese-speaking world. It serves speech technology, education, and cultural preservation efforts… See the full description on the dataset page: https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"2hr_myanmar_asr_raw_audio","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t🇲🇲 Raw 2-Hour Burmese ASR Audio Dataset\n\t\n\nA ~2-hour Burmese (Myanmar language) ASR dataset featuring 1,612 audio clips with aligned transcripts, curated from official public-service educational broadcasts by FOEIM Academy — a civic media arm of FOEIM.ORG, operating under the Myanmar National Unity Government (NUG).\nThis dataset is MIT-licensed as a public good — a shared asset for the Burmese-speaking world. It serves speech technology, education, and cultural preservation efforts… See the full description on the dataset page: https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"FeruzaSpeechDualText","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickoo004/FeruzaSpeechDualText","creator_name":"Nicholas","creator_url":"https://huggingface.co/nickoo004","description":"nickoo004/FeruzaSpeechDualText dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"process_dataset_mini","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doublesizebed/process_dataset_mini","creator_name":"chong","creator_url":"https://huggingface.co/doublesizebed","description":"doublesizebed/process_dataset_mini dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Malay","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/audiobooks","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"170 hours of aligned audiobooks taken from tatkniga.ru. There are 4 speakers with 17+ hours of audio and 20 speakers in total. All the books are in free access and most of them in public domain.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/audiobooks","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"170 hours of aligned audiobooks taken from tatkniga.ru. There are 4 speakers with 17+ hours of audio and 20 speakers in total. All the books are in free access and most of them in public domain.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/audiobooks","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"170 hours of aligned audiobooks taken from tatkniga.ru. There are 4 speakers with 17+ hours of audio and 20 speakers in total. All the books are in free access and most of them in public domain.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Children_Counsel","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ironDong/Children_Counsel","creator_name":"sindongwoo","creator_url":"https://huggingface.co/ironDong","description":"\n\t\n\t\t\n\t\t아동·청소년 상담 데이터셋 (Children Counseling Dataset)\n\t\n\nThis dataset contains counseling data for children and adolescents, including both audio recordings and transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n\naudio/: Contains the audio recordings of counseling sessions in MP3 format\ndata/: Contains JSON files with transcriptions and metadata for each session\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nTraining speech recognition models for counseling… See the full description on the dataset page: https://huggingface.co/datasets/ironDong/Children_Counsel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ljs-mos-120","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stefantaubert/ljs-mos-120","creator_name":"Stefan Taubert","creator_url":"https://huggingface.co/stefantaubert","description":"\n\t\n\t\t\n\t\tLJS-MOS-120: Human MOS Ratings for 120 Samples of the LJ Speech Dataset\n\t\n\nLJS-MOS-120 provides Mean Opinion Score (MOS) ratings for 120 text-to-speech (TTS) samples based on the LJ Speech dataset. Each sample was rated by human annotators for intelligibility and naturalness across four experimental TTS conditions. The dataset follows the Tidy data format, with one row per rating per dimension.\nRatings were collected via Amazon Mechanical Turk (MTurk) in 2022. Each entry includes the… See the full description on the dataset page: https://huggingface.co/datasets/stefantaubert/ljs-mos-120.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ljs-mos-120","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stefantaubert/ljs-mos-120","creator_name":"Stefan Taubert","creator_url":"https://huggingface.co/stefantaubert","description":"\n\t\n\t\t\n\t\tLJS-MOS-120: Human MOS Ratings for 120 Samples of the LJ Speech Dataset\n\t\n\nLJS-MOS-120 provides Mean Opinion Score (MOS) ratings for 120 text-to-speech (TTS) samples based on the LJ Speech dataset. Each sample was rated by human annotators for intelligibility and naturalness across four experimental TTS conditions. The dataset follows the Tidy data format, with one row per rating per dimension.\nRatings were collected via Amazon Mechanical Turk (MTurk) in 2022. Each entry includes the… See the full description on the dataset page: https://huggingface.co/datasets/stefantaubert/ljs-mos-120.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ljs-mos-120","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stefantaubert/ljs-mos-120","creator_name":"Stefan Taubert","creator_url":"https://huggingface.co/stefantaubert","description":"\n\t\n\t\t\n\t\tLJS-MOS-120: Human MOS Ratings for 120 Samples of the LJ Speech Dataset\n\t\n\nLJS-MOS-120 provides Mean Opinion Score (MOS) ratings for 120 text-to-speech (TTS) samples based on the LJ Speech dataset. Each sample was rated by human annotators for intelligibility and naturalness across four experimental TTS conditions. The dataset follows the Tidy data format, with one row per rating per dimension.\nRatings were collected via Amazon Mechanical Turk (MTurk) in 2022. Each entry includes the… See the full description on the dataset page: https://huggingface.co/datasets/stefantaubert/ljs-mos-120.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"malay-tts-tags","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doublesizebed/malay-tts-tags","creator_name":"chong","creator_url":"https://huggingface.co/doublesizebed","description":"doublesizebed/malay-tts-tags dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Malay","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CBD","keyword":"hate-speech-detection","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CBD","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CBD\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPolish Tweets annotated for cyberbullying detection.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWritten, Social\n\n\nReference\nhttp://2019.poleval.pl/files/poleval2019.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CBD\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more… See the full description on the dataset page: https://huggingface.co/datasets/mteb/CBD.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CEDRClassification","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CEDRClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CEDRClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClassification of sentences by emotions, labeled into 5 categories (joy, sadness, surprise, fear, and anger).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Social, Blog, Written\n\nReference\nhttps://www.sciencedirect.com/science/article/pii/S1877050921013247\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/CEDRClassification.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"CSFDSKMovieReviewSentimentClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CSFDSKMovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CSFDSKMovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset contains 30k user reviews from csfd.cz in Slovak.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2304.01922\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CSFDSKMovieReviewSentimentClassification\"])\nevaluator = mteb.MTEB(task)… See the full description on the dataset page: https://huggingface.co/datasets/mteb/CSFDSKMovieReviewSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"BengaliHateSpeechClassification","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BengaliHateSpeechClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/bn_hate_speech\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following… See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CSFDCZMovieReviewSentimentClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/CSFDCZMovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  CSFDCZMovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset contains 30k user reviews from csfd.cz in Czech.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2304.01922\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"CSFDCZMovieReviewSentimentClassification\"])\nevaluator = mteb.MTEB(task)… See the full description on the dataset page: https://huggingface.co/datasets/mteb/CSFDCZMovieReviewSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"HebrewSentimentAnalysis","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HebrewSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHebrewSentiment is a data set consists of 12,804 user comments to posts on the official Facebook page of Israel’s president, Mr. Reuven Rivlin. In October 2015, we used the open software application Netvizz (Rieder, 2013) to scrape all the comments to all of the president’s posts in the period of June – August 2014, the first three months of Rivlin’s presidency.2 While the president’s posts aimed at reconciling… See the full description on the dataset page: https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KorHateClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorHateClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset was created to provide the first human-labeled Korean corpus for\n        toxic speech detection from a Korean online entertainment news aggregator. Recently,\n        two young Korean celebrities suffered from a series of tragic incidents that led to two\n        major Korean web portals to close the comments section on their platform. However, this only\n        serves as a temporary solution, and the… See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorHateClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KorHateSpeechMLClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorHateSpeechMLClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorHateSpeechMLClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    The Korean Multi-label Hate Speech Dataset, K-MHaS, consists of 109,692 utterances from Korean online news comments,\n    labelled with 8 fine-grained hate speech classes (labels: Politics, Origin, Physical, Age, Gender, Religion, Race, Profanity)\n    or Not Hate Speech class. Each utterance provides from a single to four labels that can handles Korean language patterns effectively.\n    For more details… See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorHateSpeechMLClassification.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"jvsu_asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/irasalsabila/jvsu_asr","creator_name":"Ira Salsabila","creator_url":"https://huggingface.co/irasalsabila","description":"\n\t\n\t\t\n\t\tJavanese and Sundanese ASR Subset\n\t\n\nThis dataset provides curated subsets of the OpenSLR SLR35 (Javanese) and SLR36 (Sundanese) speech corpora. Each sample contains a reference transcript along with speaker ID and original archive source.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach language has its own configuration:\n\njavanese\nsundanese\n\nFor each config, we provide:\n\ntrain\ntest\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nfilename — the audio file name (without extension)\nuserid — speaker/user identifier\nlabel —… See the full description on the dataset page: https://huggingface.co/datasets/irasalsabila/jvsu_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","original","Javanese","Sundanese"],"keywords_longer_than_N":true},
	{"name":"NaijaSenti","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NaijaSenti","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NaijaSenti\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNaijaSenti is the first large-scale human-annotated Twitter sentiment dataset for the four most widely spoken languages in Nigeria — Hausa, Igbo, Nigerian-Pidgin, and Yorùbá — consisting of around 30,000 annotated tweets per language, including a significant fraction of code-mixed tweets.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://github.com/hausanlp/NaijaSenti\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NaijaSenti.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"PolEmo2.0-IN","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PolEmo2.0-IN","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PolEmo2.0-IN\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA collection of Polish online reviews from four domains: medicine, hotels, products and school. The PolEmo2.0-IN task is to predict the sentiment of in-domain (medicine and hotels) reviews.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nWritten, Social\n\n\nReference\nhttps://aclanthology.org/K19-1092.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport… See the full description on the dataset page: https://huggingface.co/datasets/mteb/PolEmo2.0-IN.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_2k","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_2k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset (2k)\n\t\n\nThis dataset contains 4000 synthetic speech recordings in the Pashto language,\nwith 2000 male voice recordings and 2000 female voice recordings.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 2000 sentences\nTotal Recordings: 4000 audio files (2000 male + 2000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM\nSampling Rate: 44.1kHz (44100 Hz)\nVoices: \nMale: ps-AF-GulNawazNeural\nFemale: ps-AF-LatifaNeural\n\n\nTotal Audio Duration: \nMale: 0.00 seconds… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_2k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_2k","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_2k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset (2k)\n\t\n\nThis dataset contains 4000 synthetic speech recordings in the Pashto language,\nwith 2000 male voice recordings and 2000 female voice recordings.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 2000 sentences\nTotal Recordings: 4000 audio files (2000 male + 2000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM\nSampling Rate: 44.1kHz (44100 Hz)\nVoices: \nMale: ps-AF-GulNawazNeural\nFemale: ps-AF-LatifaNeural\n\n\nTotal Audio Duration: \nMale: 0.00 seconds… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_2k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"SASRBench-v1","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mjwong/SASRBench-v1","creator_name":"Ming Jie Wong","creator_url":"https://huggingface.co/mjwong","description":"\n\t\n\t\t\n\t\tSASRBench-v1: Singlish ASR Benchmark V1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSASRBench-v1 is a benchmark dataset for evaluating Automatic Speech Recognition (ASR) performance on Singlish. It is derived exclusively from the Part 3 Same Room Environment Close-talk Mic recordings of IMDA's NSC Corpus.\n\n\t\n\t\t\n\t\tDataset Derivation\n\t\n\nFrom the Part 3 Same Room Environment Close-talk Mic recordings, audio segments were extracted with the following criteria:\n\nMinimum Word Count: 10 words  \nMaximum… See the full description on the dataset page: https://huggingface.co/datasets/mjwong/SASRBench-v1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"whisper_asr_traindata","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sarannair/whisper_asr_traindata","creator_name":"Saran Nair","creator_url":"https://huggingface.co/sarannair","description":"\n\t\n\t\t\n\t\tEnglish Accent Audio-transcript Dataset.\n\t\n\nAudio is extracted from movies, shows, speeches, talks to capture diverse accents - mainly scottish and indian\nThis dataset contains 30-second audio clips with aligned transcript text. \n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach entry includes:\n\naudio: 30-second speech segment\ntext: Corresponding transcript\nstart_time / end_time: Segment timestamps\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nLicensed under CC-BY-4.0.\n","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_3k","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_3k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (3k)\n\t\n\nThis dataset contains 6000 synthetic speech recordings in the Pashto language,\nwith 3000 male voice recordings and 3000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 3000 sentences\nTotal Recordings: 6000 audio files (3000 male + 3000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz (44100… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_3k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_3k","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_3k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (3k)\n\t\n\nThis dataset contains 6000 synthetic speech recordings in the Pashto language,\nwith 3000 male voice recordings and 3000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 3000 sentences\nTotal Recordings: 6000 audio files (3000 male + 3000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz (44100… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_3k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"lleisiau-arfor","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cymen-arfor/lleisiau-arfor","creator_name":"Prosiect Arfor Cymen","creator_url":"https://huggingface.co/cymen-arfor","description":"See below for English\n\n\t\n\t\t\n\t\tLleisiau ARFOR\n\t\n\nCafodd y set ddata hon ei chreu gan Cymen fel rhan o brosiect a ariannwyd gan ARFOR ar y cyd â’r Uned Technolegau Iaith ym Mhrifysgol Bangor.   \nNod y prosiect oedd casglu llawer iawn o ddata llafar Cymraeg o ansawdd uchel, ynghyd â’u trawsgrifiadau cyfatebol, gan ganolbwyntio’n benodol ar iaith anffurfiol, sgyrsiol a digymell o ardal Arfor. Bydd y set ddata sy’n deillio ohoni wedyn yn cael ei defnyddio i wella technoleg adnabod llais yng Nghymru… See the full description on the dataset page: https://huggingface.co/datasets/cymen-arfor/lleisiau-arfor.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Welsh","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Sentiment-Reasoning","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","description":"\n\t\n\t\t\n\t\tSentiment Reasoning for Healthcare\n\t\n\nACL 2025 (Oral)\nKhai-Nguyen Nguyen*, Khai Le-Duc*, Bach Phan Tat, Duy Le, Long Vo-Dang, Truong-Son Hy\n\n*Equal contribution\n\n\nPlease press ⭐ button and/or cite papers if you feel helpful.\n\n\n  \n\nSentiment Reasoning pipeline\n\n\nAbstract:\nTransparency in AI healthcare decision-making is crucial. By incorporating rationales to explain reason for each predicted label, users could understand Large Language Models (LLMs)’s reasoning to make better decision.… See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning.","first_N":5,"first_N_keywords":["text-generation","text-classification","audio-classification","automatic-speech-recognition","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"NewsLensSync","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sparklessszzz/NewsLensSync","creator_name":"Akshaya","creator_url":"https://huggingface.co/sparklessszzz","description":"sparklessszzz/NewsLensSync dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","summarization","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_ru","keyword":"speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/common_voice_21_ru","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nНабор данных validated.tsv отфильтрованный по down_votes = 0\n\n\t\n\t\t\n\t\t📊 Статистика датасета\n\t\n\n\n\t\n\t\t\n\t\tИнформация по сплитам\n\t\n\n\n\t\n\t\t\n\t\t🔹 Тренировочный набор (train)\n\t\n\n\n\t\n\t\t\nМетрика\nЗначение\n\n\n\t\t\nКоличество семплов\n93,531\n\n\nОбщая продолжительность\n132.25 часов (476,089.70 секунд)\n\n\nСредняя продолжительность семпла\n5.09 секунд\n\n\n\t\n\n\n\t\n\t\t\n\t\t🔹 Валидационный набор (validate)\n\t\n\n\n\t\n\t\t\nМетрика\nЗначение\n\n\n\t\t\nКоличество семплов\n38,836\n\n\nОбщая продолжительность\n55.21… See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/common_voice_21_ru.","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","Russian","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"HAL-9000-Speech","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/campwill/HAL-9000-Speech","creator_name":"William Campbell","creator_url":"https://huggingface.co/campwill","description":"\n\t\n\t\t\n\t\tHAL 9000 Speech Dataset\n\t\n\nThis repository contains audio recordings of dialogue from HAL 9000, the AI character from 2001: A Space Odyssey. The full dataset contains most, but not all audio recordings of HAL 9000 from the film. The dataset is not cleaned, as background noise and variations in his voice are prevalent.  \nThe dataset can be formatted into the LJSpeech structure to ensure compatibility with most text-to-speech (TTS) models and training pipelines, such as Piper.… See the full description on the dataset page: https://huggingface.co/datasets/campwill/HAL-9000-Speech.","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"rudevices","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/rudevices","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\t📊 Сводная статистика аудио-датасетов\n\t\n\n\n\t\n\t\t\n\t\t📈 Общая статистика по всем датасетам\n\t\n\n\n\t\n\t\t\nМетрика\nЗначение\n\n\n\t\t\nВсего датасетов/сабсетов\n2\n\n\nВсего семплов\n296,394\n\n\nОбщая продолжительность\n369.14 часов (1328901.86 секунд)\n\n\nСредняя продолжительность семпла\n4.48 секунд\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tРаспределение объема данных по датасетам\n\t\n\nru_audiobooks_devices ███████████████████████████ 68.5%\nrudevices_audio_records ████████████ 31.5%\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tДатасет: rudevices_audio_records… See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rudevices.","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","100K - 1M","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"KinyaWhisperDataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/benax-rw/KinyaWhisperDataset","creator_name":"Benax Labs","creator_url":"https://huggingface.co/benax-rw","description":"\n\t\n\t\t\n\t\tKinyarwanda Spoken Words Dataset\n\t\n\nThis dataset contains 102 short audio samples of spoken Kinyarwanda words, each labeled with its corresponding transcription. It is designed for training, evaluating, and experimenting with Automatic Speech Recognition (ASR) models in low-resource settings.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudio/: Contains 102 .wav files (mono, 16kHz)\ntranscripts.txt: Tab-separated transcription file (e.g., 001.wav\\tmuraho)\nmanifest.jsonl: JSONL file with audio paths and text… See the full description on the dataset page: https://huggingface.co/datasets/benax-rw/KinyaWhisperDataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kinyarwanda","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"benchmark_eseu_testsets","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/benchmark_eseu_testsets","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tBenchmark Test-sets for evaluations on Spanish and Basque\n\t\n\nThis test-sets are a reduced version of public available datasets. The datasets are balanced with more or less the same amount of hours in each dataset, for equal evaluation tasks.\n\n\t\n\t\t\n\t\tTest splits:\n\t\n\n\nmozilla-foundation/common_voice_18_0/es: a small split made from the official \"test\" split for spanish.\nmozilla-foundation/common_voice_18_0/eu: a small split made from the official \"test\" split for basque.\nopenslr/es: a… See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/benchmark_eseu_testsets.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","Spanish","cc-by-4.0","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_5k","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_5k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (5k)\n\t\n\nThis dataset contains 10000 synthetic speech recordings in the Pashto language,\nwith 5000 male voice recordings and 5000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 5000 sentences\nTotal Recordings: 10000 audio files (5000 male + 5000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz (24000 Hz)… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_5k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_5k","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_5k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (5k)\n\t\n\nThis dataset contains 10000 synthetic speech recordings in the Pashto language,\nwith 5000 male voice recordings and 5000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 5000 sentences\nTotal Recordings: 10000 audio files (5000 male + 5000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz (24000 Hz)… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_5k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"odia-english-ASR","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mohan-diffuser/odia-english-ASR","creator_name":"Mohan Dash","creator_url":"https://huggingface.co/Mohan-diffuser","description":"Mohan-diffuser/odia-english-ASR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Oriya","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mualem-recitations-original","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/obadx/mualem-recitations-original","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","description":"\n\t\n\t\t\n\t\tالمصاحف القرآنية\n\t\n\nمصاحف مجمعمة من القراء المتقنين لبناء نماذج ذكاء اصطناعي لخدمة القرآن الكريم. أنظر هنا لأكواد بناء قاعدة التلاوات القرآنية\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tالبيانات الوصفية للمصاحف\n\t\n\nds = load_dataset('obadx/mualem-recitations-original', name='moshaf_metadata')['train']\n\n\n\t\n\t\n\t\n\t\tوصف أوجه حفص\n\t\n\n\n\t\n\t\t\nAttribute Name\nArabic Name\nValues\nDefault Value\nMore Info\n\n\n\t\t\nrewaya\nالرواية\n- hafs (حفص)\n\nThe type of the quran Rewaya.\n\n\nrecitation_speed\nسرعة التلاوة\n- mujawad (مجود)-… See the full description on the dataset page: https://huggingface.co/datasets/obadx/mualem-recitations-original.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"mualem-recitations-original","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/obadx/mualem-recitations-original","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","description":"\n\t\n\t\t\n\t\tالمصاحف القرآنية\n\t\n\nمصاحف مجمعمة من القراء المتقنين لبناء نماذج ذكاء اصطناعي لخدمة القرآن الكريم. أنظر هنا لأكواد بناء قاعدة التلاوات القرآنية\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tالبيانات الوصفية للمصاحف\n\t\n\nds = load_dataset('obadx/mualem-recitations-original', name='moshaf_metadata')['train']\n\n\n\t\n\t\n\t\n\t\tوصف أوجه حفص\n\t\n\n\n\t\n\t\t\nAttribute Name\nArabic Name\nValues\nDefault Value\nMore Info\n\n\n\t\t\nrewaya\nالرواية\n- hafs (حفص)\n\nThe type of the quran Rewaya.\n\n\nrecitation_speed\nسرعة التلاوة\n- mujawad (مجود)-… See the full description on the dataset page: https://huggingface.co/datasets/obadx/mualem-recitations-original.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"hausa_voice_dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mide7x/hausa_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Voice Dataset\nDescription: This dataset contains Hausa language audio samples from Common Voice. The dataset includes audio files and their corresponding transcriptions, designed for text-to-speech (TTS) and automatic speech recognition (ASR) research and applications.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train\n\nDataset Info:\n\nFeatures:\naudio: Audio file (mono… See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","keyword-spotting","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"hi_luna_synthetic_audio_v1","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ThomasTheMaker/hi_luna_synthetic_audio_v1","creator_name":"Thomas Nguyen","creator_url":"https://huggingface.co/ThomasTheMaker","description":"300k audio files synthetically generated by VITS using https://github.com/dscripka/synthetic_speech_dataset_generation?tab=readme-ov-file\n\nCommand used\npython generate_clips.py \\\n    --model VITS \\\n    --enable_gpu \\\n    --text \"Hey, Luna\" \\\n    --N 300000 \\\n    --max_per_speaker 1 \\\n    --output_dir /luna_audio\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","apache-2.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"hausa_long_voice_dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_long_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Long Voice Dataset\nDescription: This dataset contains merged Hausa language audio samples from Common Voice. Audio files from the same speaker have been concatenated to create longer audio samples with their corresponding transcriptions, designed for text-to-speech (TTS) training where longer sequences are beneficial.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train… See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"zuhri","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/humair025/zuhri","creator_name":"Humair M","creator_url":"https://huggingface.co/humair025","description":"\n\t\n\t\t\n\t\tZuhri — Urdu G2P Dataset\n\t\n\nZuhri is a comprehensive and manually verified Urdu Grapheme-to-Phoneme (G2P) dataset. It is designed to aid research and development in areas such as speech synthesis, pronunciation modeling, and computational linguistics, specifically for the Urdu language.\nThis dataset provides accurate phoneme transcriptions and IPA representations, making it ideal for use in building high-quality TTS (Text-to-Speech), ASR (Automatic Speech Recognition), and other… See the full description on the dataset page: https://huggingface.co/datasets/humair025/zuhri.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","Urdu","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SynStard-1000","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cksqs/SynStard-1000","creator_name":"Pu Yu","creator_url":"https://huggingface.co/cksqs","description":"\n\t\n\t\t\n\t\tSynStard-1000\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSynStard-1000 is a 1,000-hour synthetic dataset for training and evaluating end-to-end speech-to-speech translation (S2ST) models. It is built from English-Chinese parallel texts in the WMT News Commentary v18 corpus and contains approximately 390,000 sentence pairs with paired synthetic speech.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n.\n├── map/\n│   └── all.tsv\n│── text/\n│   ├── en/\n│   │   ├── en.txt\n│   │   ├── en_1.txt\n│   │   ├── ...\n│   │   ├──… See the full description on the dataset page: https://huggingface.co/datasets/cksqs/SynStard-1000.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"bigbench_jsonl","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl","creator_name":"NJUDeepEngine","creator_url":"https://huggingface.co/NJUDeepEngine","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyond… See the full description on the dataset page: https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"AfriSentiClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AfriSentiClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AfriSentiClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAfriSenti is the largest sentiment analysis dataset for under-represented African languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://arxiv.org/abs/2302.08956\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AfriSentiClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel… See the full description on the dataset page: https://huggingface.co/datasets/mteb/AfriSentiClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"AngryTweetsClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AngryTweetsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AngryTweetsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA sentiment dataset with 3 classes (positiv, negativ, neutral) for Danish tweets\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://aclanthology.org/2021.nodalida-main.53/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AngryTweetsClassification\"])\nevaluator = mteb.MTEB(task)… See the full description on the dataset page: https://huggingface.co/datasets/mteb/AngryTweetsClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"BengaliSentimentAnalysis","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BengaliSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\ndataset contains 3307 Negative reviews and 8500 Positive reviews collected and manually annotated from Youtube Bengali drama.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\nReference\nhttps://data.mendeley.com/datasets/p6zc7krs37/4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"BulgarianStoreReviewSentimentClassfication","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BulgarianStoreReviewSentimentClassfication\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBulgarian online store review dataset for sentiment classification.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://doi.org/10.7910/DVN/TXIK9P\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BulgarianStoreReviewSentimentClassfication\"])\nevaluator =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"EstonianValenceClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/EstonianValenceClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  EstonianValenceClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDataset containing annotated Estonian news data from the Postimees and Õhtuleht newspapers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReferencehttps://figshare.com/articles/dataset/Estonian_Valence_Corpus_Eesti_valentsikorpus/24517054\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/EstonianValenceClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"FilipinoShopeeReviewsClassification","keyword":"hate-speech-detection","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FilipinoShopeeReviewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FilipinoShopeeReviewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Shopee reviews tl 15 dataset is constructed by randomly taking 2100 training samples and 450 samples for testing and validation for each review star from 1 to 5. In total, there are 10500 training samples and 2250 each in validation and testing samples.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://uijrt.com/articles/v4/i8/UIJRTV4I80009.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to… See the full description on the dataset page: https://huggingface.co/datasets/mteb/FilipinoShopeeReviewsClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"FinToxicityClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/FinToxicityClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FinToxicityClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    This dataset is a DeepL -based machine translated version of the Jigsaw toxicity dataset for Finnish. The dataset is originally from a Kaggle competition https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data.\n    The original dataset poses a multi-label text classification problem and includes the labels identity_attack, insult, obscene, severe_toxicity, threat and toxicity.\n    Here… See the full description on the dataset page: https://huggingface.co/datasets/mteb/FinToxicityClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GeoreviewClassification","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GeoreviewClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GeoreviewClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nReview classification (5-point scale) based on Yandex Georeview dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/yandex/geo-reviews-dataset-2023\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeoreviewClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeoreviewClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"GeorgianSentimentClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/GeorgianSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  GeorgianSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGoergian Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://aclanthology.org/2022.lrec-1.173\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeorgianSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)… See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeorgianSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"JavaneseIMDBClassification","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JavaneseIMDBClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JavaneseIMDBClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLarge Movie Review Dataset translated to Javanese. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/w11wo/nlp-datasets#javanese-imdb\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following… See the full description on the dataset page: https://huggingface.co/datasets/mteb/JavaneseIMDBClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KorFin","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KorFin","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KorFin\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe KorFin-ASC is an extension of KorFin-ABSA, which is a financial sentiment analysis dataset including 8818 samples with (aspect, polarity) pairs annotated. The samples were collected from KLUE-TC and analyst reports from Naver Finance.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written, Financial\n\n\nReference\nhttps://huggingface.co/datasets/amphora/korfin-asc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an… See the full description on the dataset page: https://huggingface.co/datasets/mteb/KorFin.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"KurdishSentimentClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/KurdishSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  KurdishSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nKurdish Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://link.springer.com/article/10.1007/s10579-023-09716-6\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"KurdishSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/KurdishSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"LccSentimentClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/LccSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  LccSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe leipzig corpora collection, annotated for sentiment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://github.com/fnielsen/lcc-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LccSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/LccSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MovieReviewSentimentClassification","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Allociné dataset is a French-language dataset for sentiment analysis that contains movie reviews produced by the online community of the Allociné.fr website.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using… See the full description on the dataset page: https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018Retrieval","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NanoFiQA2018Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of the Financial Opinion Mining and Question Answering dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Social\n\n\nReferencehttps://sites.google.com/view/fiqa/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoFiQA2018Retrieval\"])\nevaluator = mteb.MTEB(task)… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval.","first_N":5,"first_N_keywords":["text-retrieval","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"test_hf_dataset","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/guynich/test_hf_dataset","creator_name":"Guy Nicholson","creator_url":"https://huggingface.co/guynich","description":"\n\t\n\t\t\n\t\ttest_hf_dataset\n\t\n\nThis dataset was created to document how to create an audio dataset and upload\nit to HuggingFace see GitHub repo.\nNext step: add more documentation.\ne.g.:\n\ncontents of the dataset\ncontext for how the dataset should be used, e.g.: datasets package\nexisting dataset cards, such as the ELI5 dataset card, show common conventions\n\n\n\t\n\t\t\n\t\n\t\n\t\tExample usage of dataset\n\t\n\nExample of transcription.\nFirst install extra dependencies, typically within virtual environment.… See the full description on the dataset page: https://huggingface.co/datasets/guynich/test_hf_dataset.","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"NusaX-senti","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NusaX-senti","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NusaX-senti\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak. NusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NusaX-senti.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"PoemSentimentClassification","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PoemSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PoemSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPoem Sentiment is a sentiment dataset of poem verses from Project Gutenberg.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2011.02686\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PoemSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/PoemSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"PolEmo2.0-OUT","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PolEmo2.0-OUT","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PolEmo2.0-OUT\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA collection of Polish online reviews from four domains: medicine, hotels, products and school. The PolEmo2.0-OUT task is to predict the sentiment of out-of-domain (products and school) reviews using models train on reviews from medicine and hotels domains.\n\n\t\n\t\t\n\n\nTask category\nt2c\n\n\nDomains\nWritten, Social\n\n\nReference\nhttps://aclanthology.org/K19-1092.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an… See the full description on the dataset page: https://huggingface.co/datasets/mteb/PolEmo2.0-OUT.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian\n\t\n\nThis is a dataset with Russian audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian\", split=\"train\")\nprint(dataset[0])\n\n","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian\n\t\n\nThis is a dataset with Russian audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian\", split=\"train\")\nprint(dataset[0])\n\n","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"mls-eng-128kb","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ntt123/mls-eng-128kb","creator_name":"Thông Nguyễn","creator_url":"https://huggingface.co/ntt123","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese… See the full description on the dataset page: https://huggingface.co/datasets/ntt123/mls-eng-128kb.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-128kb","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ntt123/mls-eng-128kb","creator_name":"Thông Nguyễn","creator_url":"https://huggingface.co/ntt123","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese… See the full description on the dataset page: https://huggingface.co/datasets/ntt123/mls-eng-128kb.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"vocsim","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anonymous-submission000/vocsim","creator_name":"Anonymous","creator_url":"https://huggingface.co/anonymous-submission000","description":"\n\t\n\t\t\n\t\tVocSim: Zero-Shot Audio Similarity Benchmark\n\t\n\n\n\n\n\nVocSim evaluates how well neural audio embeddings generalize for zero-shot audio similarity. It tests recognizing fine-grained acoustic similarity without specific similarity training.\n\n\n\t\t\n\t\tKey Features\n\t\n\n\nDiverse Sources: Human speech (phones, words, utterances), birdsong, otter calls, environmental sounds.\nVaried Conditions: Spans clean to noisy recordings, short (<100ms) to long durations, few to many classes per subset.… See the full description on the dataset page: https://huggingface.co/datasets/anonymous-submission000/vocsim.","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"gigaspeech2_vie","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/gigaspeech2_vie","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tVietnamse subset of the Gigaspeech2 dataset\n\t\n\nextracted from: https://huggingface.co/datasets/speechcolab/gigaspeech2\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"linguistic_sq","keyword":"linguistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LTS-VVE/linguistic_sq","creator_name":"LTS","creator_url":"https://huggingface.co/LTS-VVE","description":"\n\t\n\t\t\n\t\tPhysics and Math Problems Dataset\n\t\n\nThis repository contains a dataset of 3,200 enteries of different Albanian linguistics to improve Albanian queries further by introducing Albanian language rules and literature. The dataset is designed to support various NLP tasks and educational applications.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nProblems: 3,200\nLanguage: Albanian\nTopics:\nletërsi shqiptare: 47\npoezi shqiptare: 45\nproza shqiptare: 48\ndrama shqiptare: 46\nautorë shqiptarë: 48\nveprat kryesore… See the full description on the dataset page: https://huggingface.co/datasets/LTS-VVE/linguistic_sq.","first_N":5,"first_N_keywords":["question-answering","Albanian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"YouTube-English","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OrcinusOrca/YouTube-English","creator_name":"Orca","creator_url":"https://huggingface.co/OrcinusOrca","description":"\n\t\n\t\t\n\t\tEnglish Audio Dataset from YouTube\n\t\n\nThis dataset contains English audio segments extracted from various YouTube channels, along with corresponding transcription metadata. The data is intended for training automatic speech recognition (ASR) models.\n\n\t\n\t\t\n\t\tData Source and Processing\n\t\n\nThe data was obtained through the following process:\n\nDownload: Audio (.m4a) and available English subtitles (.srt for en, en.j3PyPqV-e1s) were downloaded from selected YouTube channels. This raw data… See the full description on the dataset page: https://huggingface.co/datasets/OrcinusOrca/YouTube-English.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"TatSC_ASR","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/TatSC_ASR","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\n\t\n\t\t\n\t\tTatar Speech Corpus ASR\n\t\n\n[Original repository] [Original site]\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTatar Speech Corpus ASR is a speech dataset sourced from this GitHub repository. TatSC contains 269.1 hours of transcribed speech with 271,914 utterances. It is the first open-source Tatar speech corpus covering both crowdsourced and audiobooks data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains a single set of recordings, though they come from two different sources:\n\nCrowdsourced… See the full description on the dataset page: https://huggingface.co/datasets/yasalma/TatSC_ASR.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"TatSC_ASR","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/TatSC_ASR","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\n\t\n\t\t\n\t\tTatar Speech Corpus ASR\n\t\n\n[Original repository] [Original site]\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTatar Speech Corpus ASR is a speech dataset sourced from this GitHub repository. TatSC contains 269.1 hours of transcribed speech with 271,914 utterances. It is the first open-source Tatar speech corpus covering both crowdsourced and audiobooks data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains a single set of recordings, though they come from two different sources:\n\nCrowdsourced… See the full description on the dataset page: https://huggingface.co/datasets/yasalma/TatSC_ASR.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"lomwe-speech-text","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/lomwe-speech-text","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tLomwe Speech-Text Parallel Dataset\n\t\n\nThis dataset is a collection of aligned audio-text pairs in Lomwe, extracted from the CMU Wilderness dataset. It is useful for tasks such as:\n\nSpeech recognition (ASR)\nText-to-speech (TTS)\nLanguage modeling for low-resource languages\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry in the dataset contains:\n\naudio: A .wav file sampled at 16kHz\ntext: A transcription of the spoken audio in Lomwe (digits removed)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\t\n\t\t\naudio\ntext… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/lomwe-speech-text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","audio-intent-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"lomwe-speech-text","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/lomwe-speech-text","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tLomwe Speech-Text Parallel Dataset\n\t\n\nThis dataset is a collection of aligned audio-text pairs in Lomwe, extracted from the CMU Wilderness dataset. It is useful for tasks such as:\n\nSpeech recognition (ASR)\nText-to-speech (TTS)\nLanguage modeling for low-resource languages\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry in the dataset contains:\n\naudio: A .wav file sampled at 16kHz\ntext: A transcription of the spoken audio in Lomwe (digits removed)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\t\n\t\t\naudio\ntext… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/lomwe-speech-text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","audio-intent-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"tat_hackathon_asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/tat_hackathon_asr","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\n\t\n\t\t\n\t\tHackathon Tatar ASR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHackathon Tatar ASR is a speech dataset distributed during the \"Татар.Бу Хакатон\" (Tatar.Bu Hackathon) held in Tatarstan in May 2024. This dataset likely consists of newly collected crowdsourced recordings created after the last release of TatSC (Tatar Speech Corpus), although some intersections with TatSC might be present. While TatSC contains 269.1 hours of transcribed speech with 271,914 utterances, this hackathon dataset comprises… See the full description on the dataset page: https://huggingface.co/datasets/yasalma/tat_hackathon_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"tat_hackathon_asr","keyword":"speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/tat_hackathon_asr","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\n\t\n\t\t\n\t\tHackathon Tatar ASR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHackathon Tatar ASR is a speech dataset distributed during the \"Татар.Бу Хакатон\" (Tatar.Bu Hackathon) held in Tatarstan in May 2024. This dataset likely consists of newly collected crowdsourced recordings created after the last release of TatSC (Tatar Speech Corpus), although some intersections with TatSC might be present. While TatSC contains 269.1 hours of transcribed speech with 271,914 utterances, this hackathon dataset comprises… See the full description on the dataset page: https://huggingface.co/datasets/yasalma/tat_hackathon_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian_backup","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_backup","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Backup\n\t\n\nThis is a backup dataset with Russian audio data, split into train_0 to train_49 for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\n\n\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian_backup\", split=\"train_0\")  # Or any train_X… See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_backup.","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian_backup","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_backup","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Backup\n\t\n\nThis is a backup dataset with Russian audio data, split into train_0 to train_49 for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\n\n\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian_backup\", split=\"train_0\")  # Or any train_X… See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_backup.","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"ciempiess_light","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_light","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_light\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIEMPIESS LIGHT is a Radio Corpus designed to create acoustic models for automatic speech recognition and it is made up by recordings of spontaneous conversations in Mexican Spanish between a radio moderator and his guests. It is an enhanced version of the CIEMPIESS Corpus (LDC item LDC2015S07).\nCIEMPIESS LIGHT is \"light\" because it doesn't include much of the files of the first version of CIEMPIESS and it is \"enhanced\"… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_light.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"messaih","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirix/messaih","creator_name":"Ed Moman","creator_url":"https://huggingface.co/mirix","description":"DATASET DESCRIPTION\nThe messAIh dataset is a fork of CMU MOSEI.\nUnlike its parent, MESSAIH is indended for unimodal model development and focusses exclusively on audio classification, more specifically, Speech Emotion Recognition (SER).\nOf course, it can be used for bimodal classification by transcribing each audio track.\nMESSAIH currently contains 13,234 speech samples annotated according to the CMU MOSEI scheme:\n\nEach sentence is annotated for sentiment on a [-3,3] Likert scale of:\n[−3:… See the full description on the dataset page: https://huggingface.co/datasets/mirix/messaih.","first_N":5,"first_N_keywords":["audio-classification","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"nst-da","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nst-da","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is an upload of the NST Danish ASR Database (16 kHz) – reorganized.\nThe training and test splits are the original ones.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTraining automatic speech recognition is the intended task for this dataset. No leaderboard is active at this point.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is available in Danish (da).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\nSize of downloaded… See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nst-da.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"nst-da","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nst-da","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is an upload of the NST Danish ASR Database (16 kHz) – reorganized.\nThe training and test splits are the original ones.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTraining automatic speech recognition is the intended task for this dataset. No leaderboard is active at this point.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is available in Danish (da).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\nSize of downloaded… See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nst-da.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"speech-mendeley-pa","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aipanjab/speech-mendeley-pa","creator_name":"AI Panjab","creator_url":"https://huggingface.co/aipanjab","description":"\n\t\n\t\t\n\t\tCredit - https://data.mendeley.com/datasets/sdbc8f5b77/2\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Panjabi","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"VoxCelebSpoof","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MattyB95/VoxCelebSpoof","creator_name":"Matthew Boakes","creator_url":"https://huggingface.co/MattyB95","description":"\n\t\n\t\t\n\t\n\t\n\t\tVoxCelebSpoof\n\t\n\nVoxCelebSpoof is a dataset related to detecting spoofing attacks on automatic speaker verification systems. This dataset is part of a broader effort to improve the security of voice biometric systems against various types of spoofing attacks, such as replay attacks, voice synthesis, and voice conversion.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe VoxCelebSpoof dataset includes a range of audio samples from different types of synthesis… See the full description on the dataset page: https://huggingface.co/datasets/MattyB95/VoxCelebSpoof.","first_N":5,"first_N_keywords":["audio-classification","text-to-speech","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"sixuxar_yijiri_mak7","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anzorq/sixuxar_yijiri_mak7","creator_name":"AQ","creator_url":"https://huggingface.co/anzorq","description":"\n\t\n\t\t\n\t\tDataset Info\n\t\n\nThis dataset consists of paired audio and text data sourced from the following book:\n\nTitle: Къэрмокъуэ М. Щихухэр иджыри мэкI. Япэ тхылъ.\nPublication: Нальчик: Эльбрус, 1999\n\n\n\t\n\t\t\n\t\tAudio Specifications\n\t\n\n\nSample Rate: 16,000 Hz\nTotal Length: 10:36:40\nSource: adigabook.ru\n\n\n\t\n\t\t\n\t\tProcessing Information\n\t\n\nAudio-text pairs for this dataset were extracted and aligned using META AI's forced alignment algorithm.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kabardian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sixuxar_yijiri_mak7","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anzorq/sixuxar_yijiri_mak7","creator_name":"AQ","creator_url":"https://huggingface.co/anzorq","description":"\n\t\n\t\t\n\t\tDataset Info\n\t\n\nThis dataset consists of paired audio and text data sourced from the following book:\n\nTitle: Къэрмокъуэ М. Щихухэр иджыри мэкI. Япэ тхылъ.\nPublication: Нальчик: Эльбрус, 1999\n\n\n\t\n\t\t\n\t\tAudio Specifications\n\t\n\n\nSample Rate: 16,000 Hz\nTotal Length: 10:36:40\nSource: adigabook.ru\n\n\n\t\n\t\t\n\t\tProcessing Information\n\t\n\nAudio-text pairs for this dataset were extracted and aligned using META AI's forced alignment algorithm.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kabardian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"medical_asr_recording_dataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hani89/medical_asr_recording_dataset","creator_name":"Hani. M","creator_url":"https://huggingface.co/Hani89","description":"Data Source\nKaggle Medical Speech, Transcription, and Intent\nContext\n\n8.5 hours of audio utterances paired with text for common medical symptoms.\n\nContent\n\nThis data contains thousands of audio utterances for common medical symptoms like “knee pain” or “headache,” totaling more than 8 hours in aggregate. Each utterance was created by individual human contributors based on a given symptom. These audio snippets can be used to train conversational agents in the medical field.\nThis Figure Eight… See the full description on the dataset page: https://huggingface.co/datasets/Hani89/medical_asr_recording_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"speechocean762","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seba3y/speechocean762","creator_name":"Elsebaiy mohamed","creator_url":"https://huggingface.co/seba3y","description":"\n\t\n\t\t\n\t\tspeechocean762: A non-native English corpus for pronunciation scoring task\n\t\n\n\n\t\n\t\t\n\t\tHow to use?\n\t\n\nyou can load data using\nspeechocean762_dataset = load_dataset('seba3y/speechocean762')\n\n>> speechocean762_dataset\nDatasetDict({\n    train: Dataset({\n        features: ['spk', 'age', 'gender', 'utt_name', 'audio', 'utt_text', 'utt_accuracy', 'utt_completeness', 'utt_fluency', 'utt_prosodic', 'utt_total', 'words', 'words_accuracy', 'words_stress', 'words_total', 'phones'… See the full description on the dataset page: https://huggingface.co/datasets/seba3y/speechocean762.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"openslr-slr69-ca-trimmed-denoised","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for openslr-slr69-ca-denoised\n\t\n\nThis is a post-processed version of the Catalan subset belonging to the Open Speech and Language Resources (OpenSLR) speech dataset. \nSpecifically the subset OpenSLR-69. \nThe original HF🤗 SLR-69 dataset is located here.\nSame license is maintained: Attribution-ShareAlike 4.0 International.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe processed the data of the Catalan OpenSLR with the following recipe:\n\nTrimming: Long… See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised.","first_N":5,"first_N_keywords":["text-to-speech","no-annotation","crowdsourced","monolingual","openslr"],"keywords_longer_than_N":true},
	{"name":"ciempiess_balance","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_balance","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_balance\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIEMPIESS BALANCE Corpus is designed to match with the CIEMPIESS LIGHT Corpus (LDC2017S23). So, \"Balance\" means that if the CIEMPIESS BALANCE is combined with the CIEMPIESS LIGHT, one will get a gender balanced corpus. To appreciate this, one need to know that the CIEMPIESS LIGHT is by itself, a gender unbalanced corpus of approximately 25% of female speakers and 75% of male speakers. So, the CIEMPIESS BALANCE is a… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_balance.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"uzbekvoice-filtered","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered","creator_name":"Dovron Sherbaev","creator_url":"https://huggingface.co/DavronSherbaev","description":"This is heavy filtered version of the dataset with additional information.\nThis dataset does not contain original Mozilla Common Voice audios or texts\nWe filtered the dataset using number approaches:\n\nVAD + Noise detection. Audios which lacked voice activity and produced no sound after denoiser were removed\nReading Speed. Audios with outlier speeds (approximately 5-10%), as they didnt match natural speed or were too noisy\nAutomatic STT validation. We trained the model using subset of valid… See the full description on the dataset page: https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Medical_Interview","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SandO114/Medical_Interview","creator_name":"Heyang Liu","creator_url":"https://huggingface.co/SandO114","description":"The dataset was re-organized and used in the following paper. Please cite if you adopted the corpus in your work.\n@inproceedings{liu2024post,\n  title={Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview},\n  author={Liu, Heyang and Wang, Yanfeng and Wang, Yu},\n  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},\n  pages={12917--12926},\n  year={2024}\n}\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de Mécanique des Structures et des Systèmes Couplés","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\n👀 While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Text… See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de Mécanique des Structures et des Systèmes Couplés","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\n👀 While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Text… See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"LatinAccents","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jstack32/LatinAccents","creator_name":"Joey Stack","creator_url":"https://huggingface.co/jstack32","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/jstack32/LatinAccents.","first_N":5,"first_N_keywords":["automatic-speech-recognition","extended|common_voice","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ciempiess_fem","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_fem","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_fem\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSince the publication of the CIEMPIESS Corpus (LDC2015S07) in 2015 we have noticed that there is a lack of female speakers in the sources where we traditionally take audio to create new CIEMPIESS datasets. That is why we decided to create a corpus that helps to balance future gender unbalanced datasets.\nThe CIEMPIESS FEM Corpus was created by recordings and human transcripts of 21 different women. 16 of these women are… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_fem.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ciempiess_complementary","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_complementary","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for ciempiess_complementary\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIEMPIESS COMPLEMENTARY is a phonetically balanced corpus of isolated Spanish words spoken by people of Central Mexico. It was designed to solve one particular issue when training automatic speech recognition (ASR) systems in the Spanish of Central Mexico. This problem appears when someone collects some training data, but the system complains because it does not find enough instances of one or more particular… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_complementary.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"4catac","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/4catac","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for 4catac\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n4catac: examples of phonetic transcription in 4  Catalan accents is a dataset of phonetic transcriptions in four Catalan accents: Balearic, Central, North-Western and Valencian. \nIt consists of 160 sentences transcribed using IPA, following the recommendations of the Institut d'Estudis Catalans.\nThese sentences are the same for the four accents but may have small morphological adaptations to make them more natural for the accent.… See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/4catac.","first_N":5,"first_N_keywords":["text-to-speech","expert-generated","expert-generated","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"festcat_trimmed_denoised","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/festcat_trimmed_denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for festcat_trimmed_denoised\n\t\n\nThis is a post-processed version of the Catalan Festcat speech dataset. \nThe original data can be found here.\nSame license is maintained: Creative Commons Attribution-ShareAlike 3.0 Spain License.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nWe processed the data of the Catalan Festcat with the following recipe:\n\nTrimming: Long silences from the start and the end of clips have been removed.\npy-webrtcvad -> Python interface to… See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/festcat_trimmed_denoised.","first_N":5,"first_N_keywords":["text-to-speech","no-annotation","crowdsourced","monolingual","openslr"],"keywords_longer_than_N":true},
	{"name":"nst-da-norm","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da Normalized\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): da\nLicense: cc0-1.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use… See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"nst-da-norm","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da Normalized\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): da\nLicense: cc0-1.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use… See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"sayoko-tts-corpus","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bandad/sayoko-tts-corpus","creator_name":"kai washizaki","creator_url":"https://huggingface.co/bandad","description":"\n\t\n\t\t\n\t\tサヨ子 音声コーパス\n\t\n\n\n\t\n\t\t\n\t\tダウンロード方法\n\t\n\nデータセットを圧縮したzipファイルを、gdriveに置いています。\nまた、以下のスクリプトで、huggingface hubからダウンロードも可能です。\n# pip install --upgrade huggingface_hub\nfrom huggingface_hub import snapshot_download\n\nsnapshot_download(repo_id=\"bandad/sayoko-tts-corpus\", repo_type=\"dataset\", revision=\"main\", local_dir=\"./sayoko-tts-corpus\")\n\n\n\t\n\t\t\n\t\t概要\n\t\n\n81歳の女性の音声コーパスです。… See the full description on the dataset page: https://huggingface.co/datasets/bandad/sayoko-tts-corpus.","first_N":5,"first_N_keywords":["text-to-speech","Japanese","cc-by-4.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"bengali_asr_corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parambharat/bengali_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","description":"The corpus contains roughly 500 hours of audio and transcripts in Bangla language. \nThe transcripts have beed de-duplicated using exact match deduplication and audio has be converted to 16000 samples","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"Voice-KusanagiNene","keyword":"text-to-speech","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MomoyamaSawa/Voice-KusanagiNene","creator_name":"うさぎ","creator_url":"https://huggingface.co/MomoyamaSawa","description":"\n  \n\n 🥕 \n 如果兔兔的仓库对你有帮助的话点个⭐喵~ \n If Tutu's repository is helpful to you, please give it a ⭐ meow~ \n もしうさぎのリポジトリが役に立った場合は、⭐をぽちっとしてくださいにゃん~  \n\n 🍉 \n 任何 ❓问题 / 💭思考 /💡想法 都欢迎提出！\n Any ❓question / 💭thought /💡idea  is welcome! \n どんな ❓質問 / 💭考え /💡アイデア でも歓迎です！ \n\n\n\n\t\n\t\t\n\t\n\t\n\t\t简介\n\t\n\n\n草薙寧々 干声带标签数据集\n\n本数据集只收集了游戏内的一部分，并不是全部的宁宁干声语音，其中 nene_org.txt 是标签文件\npjsk 全部角色干声带标签数据集的话可以加QQ群：691795641，群公告里有网盘地址\n\n\t\n\t\n\t\n\t\t参考\n\t\n\n\n声源归属：草薙寧々(CV:Machico)-「プロジェクトセカイ カラフルステージ！ feat. 初音ミク」\n\t\n\t\t\n\t\tTODO\n\t\n\n\n（长期）补全宁宁语音，规范数据集格式。\n\n","first_N":5,"first_N_keywords":["other","text-to-speech","audio-to-audio","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"medical","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/offbeatPickle/medical","creator_name":"Samhita Marri","creator_url":"https://huggingface.co/offbeatPickle","description":"offbeatPickle/medical dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","m","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"sebut-perkataan","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mesolitica/sebut-perkataan","creator_name":"Mesolitica","creator_url":"https://huggingface.co/mesolitica","description":"\n\t\n\t\t\n\t\tSebut Perkataan\n\t\n\n\nsebut-perkataan-man voice by Husein Zolkepli\ntolong-sebut voice by Khalil Nooh\nsebut-perkataan-woman voice by Mas Aisyah Ahmad\nRecorded using low-end tech microphones.\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malay","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"VietBibleVox","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ntt123/VietBibleVox","creator_name":"Thông Nguyễn","creator_url":"https://huggingface.co/ntt123","description":"\n\t\n\t\t\n\t\n\t\n\t\tVietBibleVox Dataset\n\t\n\nThe VietBibleVox Dataset is based on the data extracted from open.bible specifically for the Vietnamese language. As the original data is provided under the cc-by-sa-4.0 license, this derived dataset is also licensed under cc-by-sa-4.0.\nThe dataset comprises 29,185 pairs of (verse, audio clip), with each verse from the Bible read in Vietnamese by a male voice.\n\nThe verses are the original texts and may not be directly usable for training text-to-speech… See the full description on the dataset page: https://huggingface.co/datasets/ntt123/VietBibleVox.","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","cc-by-sa-4.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"simsamu","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/medkit/simsamu","creator_name":"medkit","creator_url":"https://huggingface.co/medkit","description":"\n\t\n\t\t\n\t\tSimsamu dataset\n\t\n\nThis repository contains recordings of simulated medical dispatch dialogs in the\nfrench language, annotated for diarization and transcription. It is published\nunder the MIT license.\nThese dialogs were recorded as part of the training of emergency medicine\ninterns, which consisted in simulating a medical dispatch call where the interns\ntook turns playing the caller and the regulating doctor. \nEach situation was decided randomly in advance, blind to who was playing the… See the full description on the dataset page: https://huggingface.co/datasets/medkit/simsamu.","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"VietMed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leduckhai/VietMed","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","description":"\n\t\n\t\t\n\t\tVietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain (LREC-COLING 2024, Oral)\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nWe introduced a Vietnamese speech recognition dataset in the medical domain comprising 16h of labeled medical speech, 1000h of unlabeled medical speech and 1200h of unlabeled general-domain speech. \nTo our best knowledge, VietMed is by far the world’s largest public medical speech recognition dataset in 7 aspects:\ntotal duration… See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/VietMed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"auto-pale","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeio/auto-pale","creator_name":"zeionara","creator_url":"https://huggingface.co/zeio","description":"\n\t\n\t\t\n\t\tDataset card for pale\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nThis dataset contains league of legends champions' quotes parsed from fandom.\nSee dataset usage example at google colab.\nThe dataset is available in the following configurations:\n\nvanilla - all data pulled from the website without significant modifications apart from the web page structure parsing;\nquotes - truncated version of the corpus, which does't contain sound effects;\nannotated - an extended version of the full configuration… See the full description on the dataset page: https://huggingface.co/datasets/zeio/auto-pale.","first_N":5,"first_N_keywords":["text-generation","text-classification","automatic-speech-recognition","crowdsourced","English"],"keywords_longer_than_N":true},
	{"name":"common-voice-filtered","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/common-voice-filtered","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"\n\t\n\t\t\n\t\tCommon Voice Filtered\n\t\n\nA filtered subset of the Common Voice dataset. Currently, this dataset only includes a small subset of English speech.\nWe only include speech ranked above 3.75 (75%) on the MOS metric, as calculated by the UTMOS system. Approximately 7% of audio qualified for inclusion in this filtered dataset.\nThis data is not final. Processing the whole Common Voice dataset would require a significant amount of compute, this is just a small sample/MVP of the project.\nThe code… See the full description on the dataset page: https://huggingface.co/datasets/styletts2-community/common-voice-filtered.","first_N":5,"first_N_keywords":["text-to-speech","cc-by-sa-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","description":"\n\t\n\t\t\n\t\tAniSpeech Dataset\n\t\n\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\n\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\n\n\n\n\t\n\t\t\n\t\tANNOUNCMENTS:\n\t\n\n\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker splits… See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","description":"\n\t\n\t\t\n\t\tAniSpeech Dataset\n\t\n\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\n\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\n\n\n\n\t\n\t\t\n\t\tANNOUNCMENTS:\n\t\n\n\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker splits… See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","description":"\n\t\n\t\t\n\t\tAniSpeech Dataset\n\t\n\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\n\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\n\n\n\n\t\n\t\t\n\t\tANNOUNCMENTS:\n\t\n\n\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker splits… See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"PolishCyberbullyingDataset","keyword":"hate-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ptaszynski/PolishCyberbullyingDataset","creator_name":"Michal Ptaszynski","creator_url":"https://huggingface.co/ptaszynski","description":"\n\t\n\t\t\n\t\tExpert-annotated dataset to study cyberbullying in Polish language\n\t\n\nThis the first publically available expert-annotated dataset containing annotations of cyberbullying and hate-speech in Polish language.\nPlease, read the paper about the dataset for all necessary details.\n\n\t\n\t\t\n\t\tModel\n\t\n\nThe classification model which achieved the highest classification results for the dataset is also released under the following URL.\nPolbert-CB - Polish BERT trained for Automatic Cyberbullying… See the full description on the dataset page: https://huggingface.co/datasets/ptaszynski/PolishCyberbullyingDataset.","first_N":5,"first_N_keywords":["Polish","cc-by-4.0","10K - 100K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"TuPY_dataset_multilabel","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\nThis repository is organized as follows:\nroot.\n    ├── annotations   : classification given by annotators\n    ├── raw corpus    : dataset before… See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPY_dataset_binary","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\nThis repository is organized as follows:\nroot.\n    ├── annotations   : classification given by annotators\n    ├── raw corpus    : dataset before… See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPy-Dataset","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) \nand natural language processing (NLP) techniques. TuPy is comprised of 10,000 (ten thousand) unpublished, annotated, and anonymized documents collected \non Twitter (currently known as X) in 2023. \nThis repository is organized as follows:\nroot.\n    ├── binary     : binary… See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","Brazilian-Portuguese","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPyE-Dataset","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Expanded Dataset (TuPyE)\n\t\n\nTuPyE, an enhanced iteration of TuPy, encompasses a compilation of 43,668 meticulously annotated documents specifically \nselected for the purpose of hate speech detection within diverse social network contexts. \nThis augmented dataset integrates supplementary annotations and amalgamates with datasets sourced from \nFortuna et al. (2019), \nLeite et al. (2020), \nand Vargas et al. (2022),\ncomplemented by an infusion of 10,000 original… See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"openslr63","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/openslr63","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\n\t\n\t\t\n\t\tSLR63: Crowdsourced high-quality Malayalam multi-speaker speech data set\n\t\n\nThis data set contains transcribed high-quality audio of Malayalam sentences recorded by volunteers. The data set consists of wave files, and a TSV file (line_index.tsv). The file line_index.tsv contains a anonymized FileID and the transcription of audio in the file.\nThe data set has been manually quality checked, but there might still be errors.\nPlease report any issues in the following issue tracker on… See the full description on the dataset page: https://huggingface.co/datasets/vrclc/openslr63.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Malayalam","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"openslr63","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/openslr63","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\n\t\n\t\t\n\t\tSLR63: Crowdsourced high-quality Malayalam multi-speaker speech data set\n\t\n\nThis data set contains transcribed high-quality audio of Malayalam sentences recorded by volunteers. The data set consists of wave files, and a TSV file (line_index.tsv). The file line_index.tsv contains a anonymized FileID and the transcription of audio in the file.\nThe data set has been manually quality checked, but there might still be errors.\nPlease report any issues in the following issue tracker on… See the full description on the dataset page: https://huggingface.co/datasets/vrclc/openslr63.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Malayalam","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hyvoxpopuli","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Edmon02/hyvoxpopuli","creator_name":"Edmon Sahakyan","creator_url":"https://huggingface.co/Edmon02","description":"\n\t\n\t\t\n\t\tHyVoxPopuli Dataset\n\t\n\nThe HyVoxPopuli dataset is the Armenian language subset of the Facebook VoxPopuli dataset. The name \"HyVoxPopuli\" comes from combining \"hy\" (the ISO 639-1 language code for Armenian) with \"VoxPopuli\" (the original dataset name). It is a high-quality collection of Armenian speech recordings with expert-validated transcriptions, carefully extracted and processed from the original VoxPopuli dataset (https://github.com/facebookresearch/voxpopuli).\nThis dataset is… See the full description on the dataset page: https://huggingface.co/datasets/Edmon02/hyvoxpopuli.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Armenian","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"hyvoxpopuli","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Edmon02/hyvoxpopuli","creator_name":"Edmon Sahakyan","creator_url":"https://huggingface.co/Edmon02","description":"\n\t\n\t\t\n\t\tHyVoxPopuli Dataset\n\t\n\nThe HyVoxPopuli dataset is the Armenian language subset of the Facebook VoxPopuli dataset. The name \"HyVoxPopuli\" comes from combining \"hy\" (the ISO 639-1 language code for Armenian) with \"VoxPopuli\" (the original dataset name). It is a high-quality collection of Armenian speech recordings with expert-validated transcriptions, carefully extracted and processed from the original VoxPopuli dataset (https://github.com/facebookresearch/voxpopuli).\nThis dataset is… See the full description on the dataset page: https://huggingface.co/datasets/Edmon02/hyvoxpopuli.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Armenian","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"SUBAK.KO","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO","creator_name":"SUST CSE Speech Processing Lab","creator_url":"https://huggingface.co/SUST-CSE-Speech","description":"\n\t\n\t\t\n\t\tDataset Card for SUBAK.KO\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBAK.KO (সুবাক্য), a publicly available annotated Bangladeshi standard Bangla speech corpus, is compiled for automatic speech recognition research. \nThis corpus contains 241 hours of high-quality speech data, including 229 hours of read speech data and 12 hours of broadcast speech data. \nThe read speech segment is recorded in a noise-proof studio environment from 33 male and 28 female native Bangladeshi Bangla speakers… See the full description on the dataset page: https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SUBAK.KO","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO","creator_name":"SUST CSE Speech Processing Lab","creator_url":"https://huggingface.co/SUST-CSE-Speech","description":"\n\t\n\t\t\n\t\tDataset Card for SUBAK.KO\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBAK.KO (সুবাক্য), a publicly available annotated Bangladeshi standard Bangla speech corpus, is compiled for automatic speech recognition research. \nThis corpus contains 241 hours of high-quality speech data, including 229 hours of read speech data and 12 hours of broadcast speech data. \nThe read speech segment is recorded in a noise-proof studio environment from 33 male and 28 female native Bangladeshi Bangla speakers… See the full description on the dataset page: https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"libritts_r","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/libritts_r","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\n\t\n\t\t\n\t\tDataset Card for LibriTTS-R\n\t\n\n\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus \n(http://www.openslr.org/60/) which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate, published in 2019.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the LibriTTS-R dataset, adapted for the datasets library.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThere are 7 splits (dots replace dashes from the original dataset, to comply with hf naming… See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/libritts_r.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"nb_samtale","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sprakbanken/nb_samtale","creator_name":"Nasjonalbiblioteket Språkbanken","creator_url":"https://huggingface.co/Sprakbanken","description":"NB Samtale is a speech corpus made by the Language Bank at the National Library of Norway.\nThe corpus contains orthographically transcribed speech from podcasts and recordings of live events at the National Library.\nThe corpus is intended as an open source dataset for Automatic Speech Recognition (ASR) development,\nand is specifically aimed at improving ASR systems’ handle on conversational speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Norwegian Bokmål","Norwegian Nynorsk","Norwegian","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"nb_samtale","keyword":"speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sprakbanken/nb_samtale","creator_name":"Nasjonalbiblioteket Språkbanken","creator_url":"https://huggingface.co/Sprakbanken","description":"NB Samtale is a speech corpus made by the Language Bank at the National Library of Norway.\nThe corpus contains orthographically transcribed speech from podcasts and recordings of live events at the National Library.\nThe corpus is intended as an open source dataset for Automatic Speech Recognition (ASR) development,\nand is specifically aimed at improving ASR systems’ handle on conversational speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Norwegian Bokmål","Norwegian Nynorsk","Norwegian","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"red_ace_asr_error_detection_and_correction","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/red_ace_asr_error_detection_and_correction","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tRED-ACE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset can be used to train and evaluate ASR Error Detection or Correction models. It was introduced in the RED-ACE paper (Gekhman et al, 2022).\nThe dataset contains ASR outputs on the LibriSpeech corpus (Panayotov et al., 2015) with annotated transcription errors.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThe LibriSpeech corpus was decoded using Google Cloud Speech-to-Text API, with the default and video models.\nThe word-level confidence was enabled… See the full description on the dataset page: https://huggingface.co/datasets/google/red_ace_asr_error_detection_and_correction.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"tts-rj-hi-karya","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/tts-rj-hi-karya","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. They had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426872 recordings in this dataset. They had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences… See the full description on the dataset page: https://huggingface.co/datasets/1rsh/tts-rj-hi-karya.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"tts-rj-hi-karya","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/tts-rj-hi-karya","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. They had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426872 recordings in this dataset. They had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences… See the full description on the dataset page: https://huggingface.co/datasets/1rsh/tts-rj-hi-karya.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"speech-rj-hi","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/speech-rj-hi","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. We had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426873 recordings in this dataset. We had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences, we… See the full description on the dataset page: https://huggingface.co/datasets/severo/speech-rj-hi.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"speech-rj-hi","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/speech-rj-hi","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. We had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426873 recordings in this dataset. We had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences, we… See the full description on the dataset page: https://huggingface.co/datasets/severo/speech-rj-hi.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"vlsp2020_vinai_100h","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VLSP 2020 - VinAI - ASR challenge dataset\n\t\n\nofficial announcement:\n\ntiếng việt: https://institute.vinbigdata.org/events/vinbigdata-chia-se-100-gio-du-lieu-tieng-noi-cho-cong-dong/\nin eglish: https://institute.vinbigdata.org/en/events/vinbigdata-shares-100-hour-data-for-the-community/\nVLSP 2020 workshop: https://vlsp.org.vn/vlsp2020\n\nofficial download: https://drive.google.com/file/d/1vUSxdORDxk-ePUt-bUVDahpoXiqKchMx/view?usp=sharing\ncontact: info@vinbigdata.org… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"vlsp2020_vinai_100h","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VLSP 2020 - VinAI - ASR challenge dataset\n\t\n\nofficial announcement:\n\ntiếng việt: https://institute.vinbigdata.org/events/vinbigdata-chia-se-100-gio-du-lieu-tieng-noi-cho-cong-dong/\nin eglish: https://institute.vinbigdata.org/en/events/vinbigdata-shares-100-hour-data-for-the-community/\nVLSP 2020 workshop: https://vlsp.org.vn/vlsp2020\n\nofficial download: https://drive.google.com/file/d/1vUSxdORDxk-ePUt-bUVDahpoXiqKchMx/view?usp=sharing\ncontact: info@vinbigdata.org… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"fpt_fosd","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/fpt_fosd","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of FPT Open Speech Dataset (FOSD)\n\t\n\nreleased publicly in 2018 by FPT Corporation\n100h, 25.9k samples\nofficial link (dead): https://fpt.ai/fpt-open-speech-data/\nmirror: https://data.mendeley.com/datasets/k9sxg2twv4/4\nDOI: 10.17632/k9sxg2twv4.4\npre-process:\n\nremove non-sense strings: -N \\r\\n\nremove 4 files because missing transcription:\nSet001_V0.1_008210.mp3\nSet001_V0.1_010753.mp3\nSet001_V0.1_011477.mp3\nSet001_V0.1_011841.mp3\n\n\n\nneed to do: check misspelling\nusage… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/fpt_fosd.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"fpt_fosd","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/fpt_fosd","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of FPT Open Speech Dataset (FOSD)\n\t\n\nreleased publicly in 2018 by FPT Corporation\n100h, 25.9k samples\nofficial link (dead): https://fpt.ai/fpt-open-speech-data/\nmirror: https://data.mendeley.com/datasets/k9sxg2twv4/4\nDOI: 10.17632/k9sxg2twv4.4\npre-process:\n\nremove non-sense strings: -N \\r\\n\nremove 4 files because missing transcription:\nSet001_V0.1_008210.mp3\nSet001_V0.1_010753.mp3\nSet001_V0.1_011477.mp3\nSet001_V0.1_011841.mp3\n\n\n\nneed to do: check misspelling\nusage… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/fpt_fosd.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"infore1_25hours","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore1_25hours","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset №1\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n25h, 14.9k samples, InfoRe paid a contractor to read text\nofficial download: magnet:?xt=urn:btih:1cbe13fb14a390c852c016a924b4a5e879d85f41&dn=25hours.zip&tr=http%3A%2F%2Foffice.socials.vn%3A8725%2Fannounce\nmirror: https://files.huylenguyen.com/datasets/infore/25hours.zip\nunzip password: BroughtToYouByInfoRe\npre-process: see… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore1_25hours.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"infore1_25hours","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore1_25hours","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset №1\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n25h, 14.9k samples, InfoRe paid a contractor to read text\nofficial download: magnet:?xt=urn:btih:1cbe13fb14a390c852c016a924b4a5e879d85f41&dn=25hours.zip&tr=http%3A%2F%2Foffice.socials.vn%3A8725%2Fannounce\nmirror: https://files.huylenguyen.com/datasets/infore/25hours.zip\nunzip password: BroughtToYouByInfoRe\npre-process: see… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore1_25hours.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"infore2_audiobooks","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore2_audiobooks","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset №2\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n415h, 315k samples, vietnamese audiobooks of chinese wǔxiá 武俠 & xiānxiá 仙俠\nbộ dữ liệu bóc ra từ YouTube đọc truyện võ hiệp & tiên hiệp, áp dụng kĩ thuật đối chiếu văn bản để dán nhãn tự động\nofficial download:… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore2_audiobooks.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"infore2_audiobooks","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/infore2_audiobooks","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset №2\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n415h, 315k samples, vietnamese audiobooks of chinese wǔxiá 武俠 & xiānxiá 仙俠\nbộ dữ liệu bóc ra từ YouTube đọc truyện võ hiệp & tiên hiệp, áp dụng kĩ thuật đối chiếu văn bản để dán nhãn tự động\nofficial download:… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore2_audiobooks.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"elevenlabs_dataset","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skypro1111/elevenlabs_dataset","creator_name":"Serhii Kravchenko","creator_url":"https://huggingface.co/skypro1111","description":"\n\t\n\t\t\n\t\tSynthetic TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was created with the aim of exploring the concept of using synthetic datasets for training Text-to-Speech (TTS) models. It consists of 1,388 audio files with a total duration of 2 hours and 20 minutes and their corresponding textual transcripts. The dataset leverages the capabilities of advanced AI services, utilizing paid subscriptions to ChatGPT-4 for text generation and ElevenLabs.io for audio generation.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/skypro1111/elevenlabs_dataset.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"imasc_slr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/imasc_slr","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"Clone of : thennal/IMaSC\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Rhulk_pt-br","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/satierf/Rhulk_pt-br","creator_name":"thiago freitas pimenta","creator_url":"https://huggingface.co/satierf","description":"satierf/Rhulk_pt-br dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MSC","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smcproject/MSC","creator_name":"Swathanthra Malayalam Computing","creator_url":"https://huggingface.co/smcproject","description":"\n\t\n\t\t\n\t\tDataset Card for [msc]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n1541 speech samples\n75 speech contributors\n1:38:16 hours of speech\n482 unique sentences\n1400 unique words\n553 unique syllables\n48 unique phonemes\n\nFor more detailed analysis see the python notebook provided here\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nAutomatic Speech Recognition system development, gender and age identification of speakers\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nMalayalam\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\nfile_name… See the full description on the dataset page: https://huggingface.co/datasets/smcproject/MSC.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"librispeech-alignments","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gilkeyio/librispeech-alignments","creator_name":"Kim Gilkey","creator_url":"https://huggingface.co/gilkeyio","description":"\n\t\n\t\t\n\t\tDataset Card for Librispeech Alignments\n\t\n\nLibrispeech with alignments generated by the Montreal Forced Aligner. The original alignments in TextGrid format can be found here\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLibrispeech is a corpus of read English speech, designed for training and evaluating automatic speech recognition (ASR) systems. The dataset contains 1000 hours of 16kHz read English speech derived from audiobooks.\nThe Montreal Forced Aligner (MFA) was used… See the full description on the dataset page: https://huggingface.co/datasets/gilkeyio/librispeech-alignments.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for CML-TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish… See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"english_dialects","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/english_dialects","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for \"english_dialects\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 31 hours of transcribed high-quality audio of English sentences recorded by 120 volunteers speaking with different accents of the British Isles. The dataset is intended for linguistic analysis as well as use for speech technologies. The speakers self-identified as native speakers of Southern England, Midlands, Northern England, Welsh, Scottish and Irish varieties of English.\nThe recording scripts… See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/english_dialects.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"google-tamil","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-tamil","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for Tamil Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 7 hours of transcribed high-quality audio of Tamil sentences recorded by 50 volunteers. The dataset is intended for speech technologies. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).\nautomatic-speech-recognition… See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-tamil.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Tamil","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"google-chilean-spanish","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/google-chilean-spanish","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for Tamil Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 7 hours of transcribed high-quality audio of Chilean Spanish sentences recorded by 31 volunteers. The dataset is intended for speech technologies. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).\nautomatic-speech-recognition… See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-chilean-spanish.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Spanish","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"speechocean762","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mispeech/speechocean762","creator_name":"Xiaomi Dasheng Team","creator_url":"https://huggingface.co/mispeech","description":"\n\t\n\t\t\n\t\tspeechocean762: A non-native English corpus for pronunciation scoring task\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nPronunciation scoring is a crucial technology in computer-assisted language learning (CALL) systems. The pronunciation quality scores might be given at phoneme-level, word-level, and sentence-level for a typical pronunciation scoring task.\nThis corpus aims to provide a free public dataset for the pronunciation scoring task.\nKey features:\n\nIt is available for free download for both… See the full description on the dataset page: https://huggingface.co/datasets/mispeech/speechocean762.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"Éric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"Éric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"multilingual-tts","keyword":"text-to-speech","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\n\t\n\t\t\n\t\tBefore Anything and Everything ⚱\n\t\n\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) 🇵🇸\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.… See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"wikitoxic","keyword":"hate-speech-detection","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pietrolesci/wikitoxic","creator_name":"Pietro Lesci","creator_url":"https://huggingface.co/pietrolesci","description":"This dataset has been created as an artefact of the paper AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets (Lesci and Vlachos, 2024).\nMore info about this dataset in the appendix of the paper. \nThis is the same dataset as OxAISH-AL-LLM/wiki_toxic.\nThe only differences are:\n\nAddition of a unique identifier, uid.\n\nAddition of the indices, that is, 3 columns with the embeddings of 3 different sentence-transformers\n\nall-mpnet-base-v2\nmulti-qa-mpnet-base-dot-v1… See the full description on the dataset page: https://huggingface.co/datasets/pietrolesci/wikitoxic.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"AlbanianSpeech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Yakidev/AlbanianSpeech","creator_name":"Trust Oriakhi","creator_url":"https://huggingface.co/Yakidev","description":"Yakidev/AlbanianSpeech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Albanian","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"samromur_children_test","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ericwang/samromur_children_test","creator_name":"Zhiyong Wang","creator_url":"https://huggingface.co/Ericwang","description":"\n\t\n\t\t\n\t\tDataset Card for samromur_children\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Samrómur Children Corpus consists of audio recordings and metadata files containing prompts read by the participants. It contains more than 137000 validated speech-recordings uttered by Icelandic children.\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab (LVL) at the Reykjavik University, in cooperation with Almannarómur, Center for Language Technology. The recording process has… See the full description on the dataset page: https://huggingface.co/datasets/Ericwang/samromur_children_test.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ami-ihm-timestamped","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distil-whisper/ami-ihm-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"ami-sdm-timestamped","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distil-whisper/ami-sdm-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"common_voice_13_0_dv_preprocessed","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ferno22/common_voice_13_0_dv_preprocessed","creator_name":"Ant","creator_url":"https://huggingface.co/ferno22","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 13.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 27141 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 17689 validated hours in 108 languages, but more voices and languages are always added. \nTake a look at the Languages page to… See the full description on the dataset page: https://huggingface.co/datasets/ferno22/common_voice_13_0_dv_preprocessed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"hifi-tts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MikhailT/hifi-tts","creator_name":"Mikhail Tsimashkou","creator_url":"https://huggingface.co/MikhailT","description":"Hi-Fi Multi-Speaker English TTS Dataset (Hi-Fi TTS) is based on LibriVox's public domain audio books and Gutenberg Project texts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"common_voice_13_0_dv_preprocessed","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fmagot01/common_voice_13_0_dv_preprocessed","creator_name":"Francisco Magot","creator_url":"https://huggingface.co/fmagot01","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 13.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 27141 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 17689 validated hours in 108 languages, but more voices and languages are always added. \nTake a look at the Languages page to… See the full description on the dataset page: https://huggingface.co/datasets/fmagot01/common_voice_13_0_dv_preprocessed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"common_voice_13_0_dv_preprocessed","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ssahir/common_voice_13_0_dv_preprocessed","creator_name":"Saad Sahir","creator_url":"https://huggingface.co/ssahir","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 13.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 27141 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 17689 validated hours in 108 languages, but more voices and languages are always added. \nTake a look at the Languages page to… See the full description on the dataset page: https://huggingface.co/datasets/ssahir/common_voice_13_0_dv_preprocessed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"AISHELL-3","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISHELL/AISHELL-3","creator_name":"aishelltech","creator_url":"https://huggingface.co/AISHELL","description":"AISHELL-3 is a large-scale and high-fidelity multi-speaker Mandarin speech corpus published by Beijing Shell Shell Technology Co.,Ltd. It can be used to train multi-speaker Text-to-Speech (TTS) systems.The corpus contains roughly 85 hours of emotion-neutral recordings spoken by 218 native Chinese mandarin speakers and total 88035 utterances. Their auxiliary attributes such as gender, age group and native accents are explicitly marked and provided in the corpus. Accordingly, transcripts in… See the full description on the dataset page: https://huggingface.co/datasets/AISHELL/AISHELL-3.","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"work","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gustav114514/work","creator_name":"Ryohei Kasai","creator_url":"https://huggingface.co/Gustav114514","description":"\n\t\n\t\t\n\t\n\t\n\t\tFine-tuned XLSR-53 large model for speech recognition in Japanese\n\t\n\nFine-tuned facebook/wav2vec2-large-xlsr-53 on Japanese using the train and validation splits of Common Voice 6.1, CSS10 and JSUT.\nWhen using this model, make sure that your speech input is sampled at 16kHz.\nThis model has been fine-tuned thanks to the GPU credits generously given by the OVHcloud :)\nThe script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint\n\n\t\n\t\t\n\t\n\t\n\t\tUsage… See the full description on the dataset page: https://huggingface.co/datasets/Gustav114514/work.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","🇺🇸 Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"work","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gustav114514/work","creator_name":"Ryohei Kasai","creator_url":"https://huggingface.co/Gustav114514","description":"\n\t\n\t\t\n\t\n\t\n\t\tFine-tuned XLSR-53 large model for speech recognition in Japanese\n\t\n\nFine-tuned facebook/wav2vec2-large-xlsr-53 on Japanese using the train and validation splits of Common Voice 6.1, CSS10 and JSUT.\nWhen using this model, make sure that your speech input is sampled at 16kHz.\nThis model has been fine-tuned thanks to the GPU credits generously given by the OVHcloud :)\nThe script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint\n\n\t\n\t\t\n\t\n\t\n\t\tUsage… See the full description on the dataset page: https://huggingface.co/datasets/Gustav114514/work.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","🇺🇸 Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"shkolkovo-bobr.video-webinars-audio","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","description":"\n\t\n\t\t\n\t\tshkolkovo-bobr.video-webinars-audio\n\t\n\nDataset of audio of ≈2573 webinars from bobr.video with text transcription made with whisper and VAD. Webinars are parts of free online school exams training courses made by Shkolkovo.\nLanguage: Russian, includes some webinars on English\nDataset structure:\n\nmp3 files in format ID.mp3, where ID is webinar ID. You can check original webinar with url like bobr.video/watch/ID. Some webinars may contain multiple speakers and music.\ntxt file in format… See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Russian","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"shkolkovo-bobr.video-webinars-audio","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","description":"\n\t\n\t\t\n\t\tshkolkovo-bobr.video-webinars-audio\n\t\n\nDataset of audio of ≈2573 webinars from bobr.video with text transcription made with whisper and VAD. Webinars are parts of free online school exams training courses made by Shkolkovo.\nLanguage: Russian, includes some webinars on English\nDataset structure:\n\nmp3 files in format ID.mp3, where ID is webinar ID. You can check original webinar with url like bobr.video/watch/ID. Some webinars may contain multiple speakers and music.\ntxt file in format… See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Russian","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"ToneSpeak","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/ToneSpeak","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tToneSpeak\n\t\n\nToneSpeak — большой русскоязычный аудиодатасет с подробным описанием интонаций, тембра и эмоциональных характеристик голоса.\n\n\n\t\n\t\t\n\t\tОписание\n\t\n\nДля каждого фрагмента аудио собраны:\n\nТекстовая расшифровка (text)\nПодробное описание интонации и эмоций (text_description), разбитое по ключевым параметрам:\nAccent/Affect  \nVoice Affect  \nTone  \nPhrasing  \nPunctuation  \nEmotion  \nEmphasis  \nPronunciation  \nPauses  \nPersonality Affect— и другие релевантные характеристики (не… See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneSpeak.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ToneSpeak","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/ToneSpeak","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tToneSpeak\n\t\n\nToneSpeak — большой русскоязычный аудиодатасет с подробным описанием интонаций, тембра и эмоциональных характеристик голоса.\n\n\n\t\n\t\t\n\t\tОписание\n\t\n\nДля каждого фрагмента аудио собраны:\n\nТекстовая расшифровка (text)\nПодробное описание интонации и эмоций (text_description), разбитое по ключевым параметрам:\nAccent/Affect  \nVoice Affect  \nTone  \nPhrasing  \nPunctuation  \nEmotion  \nEmphasis  \nPronunciation  \nPauses  \nPersonality Affect— и другие релевантные характеристики (не… See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneSpeak.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ami","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edinburghcstr/ami","creator_name":"University of Edingburgh - Centre For Speech Technology Research","creator_url":"https://huggingface.co/edinburghcstr","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"cmu-arctic-xvectors","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors","creator_name":"Matthijs Hollemans","creator_url":"https://huggingface.co/Matthijs","description":"\n\t\n\t\t\n\t\tSpeaker embeddings extracted from CMU ARCTIC\n\t\n\nThere is one .npy file for each utterance in the dataset, 7931 files in total. The speaker embeddings are 512-element X-vectors.\nThe CMU ARCTIC dataset divides the utterances among the following speakers:\n\nbdl (US male)\nslt (US female)\njmk (Canadian male)\nawb (Scottish male)\nrms (US male)\nclb (US female)\nksp (Indian male)\n\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\nUsage:\nfrom… See the full description on the dataset page: https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors.","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","mit","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"粵語計算語言學基礎建設組 (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\n\t\n\t\t\n\t\t張悦楷講古語音數據集\n\t\n\nEnglish\n呢個係張悦楷講《三國演義》、《水滸傳》、《走進毛澤東的最後歲月》語音數據集。張悦楷係廣州最出名嘅講古佬 / 粵語説書藝人。佢從上世紀七十年代開始就喺廣東各個收音電台度講古，佢把聲係好多廣州人嘅共同回憶。本數據集收集嘅係佢最知名嘅三部作品。\n數據集用途：\n\nTTS（語音合成）訓練集\nASR（語音識別）訓練集或測試集\n各種語言學、文學研究\n直接聽嚟欣賞藝術！\n\nTTS 效果演示：https://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\t説明\n\t\n\n\n所有文本都根據 https://jyutping.org/blog/typo/ 同 https://jyutping.org/blog/particles/ 規範用字。\n所有文本都使用全角標點，冇半角標點。\n所有文本都用漢字轉寫，無阿拉伯數字無英文字母\n所有音頻源都存放喺/source，為方便直接用作訓練數據，切分後嘅音頻都放喺 opus/\n所有 opus 音頻皆為 48000 Hz 採樣率。… See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"粵語計算語言學基礎建設組 (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\n\t\n\t\t\n\t\t張悦楷講古語音數據集\n\t\n\nEnglish\n呢個係張悦楷講《三國演義》、《水滸傳》、《走進毛澤東的最後歲月》語音數據集。張悦楷係廣州最出名嘅講古佬 / 粵語説書藝人。佢從上世紀七十年代開始就喺廣東各個收音電台度講古，佢把聲係好多廣州人嘅共同回憶。本數據集收集嘅係佢最知名嘅三部作品。\n數據集用途：\n\nTTS（語音合成）訓練集\nASR（語音識別）訓練集或測試集\n各種語言學、文學研究\n直接聽嚟欣賞藝術！\n\nTTS 效果演示：https://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\t説明\n\t\n\n\n所有文本都根據 https://jyutping.org/blog/typo/ 同 https://jyutping.org/blog/particles/ 規範用字。\n所有文本都使用全角標點，冇半角標點。\n所有文本都用漢字轉寫，無阿拉伯數字無英文字母\n所有音頻源都存放喺/source，為方便直接用作訓練數據，切分後嘅音頻都放喺 opus/\n所有 opus 音頻皆為 48000 Hz 採樣率。… See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"Audio-FLAN-Dataset","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\n\t\n\t\t\n\t\tAudio-FLAN Dataset (Paper)\n\t\n\n(the FULL audio files and jsonl files are still updating)\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \n\n\t\n\t\t\n\t\t1. Dataset Structure\n\t\n\nThe Audio-FLAN-Dataset has the following directory structure:\nAudio-FLAN-Dataset/\n├── audio_files/\n│   ├── audio/\n│   │   └── 177_TAU_Urban_Acoustic_Scenes_2022/\n│   │   └── 179_Audioset_for_Audio_Inpainting/\n│   │   └── ...\n│   ├── music/\n│   │   └──… See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Audio-FLAN-Dataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\n\t\n\t\t\n\t\tAudio-FLAN Dataset (Paper)\n\t\n\n(the FULL audio files and jsonl files are still updating)\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \n\n\t\n\t\t\n\t\t1. Dataset Structure\n\t\n\nThe Audio-FLAN-Dataset has the following directory structure:\nAudio-FLAN-Dataset/\n├── audio_files/\n│   ├── audio/\n│   │   └── 177_TAU_Urban_Acoustic_Scenes_2022/\n│   │   └── 179_Audioset_for_Audio_Inpainting/\n│   │   └── ...\n│   ├── music/\n│   │   └──… See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Audio-FLAN-Dataset","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\n\t\n\t\t\n\t\tAudio-FLAN Dataset (Paper)\n\t\n\n(the FULL audio files and jsonl files are still updating)\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \n\n\t\n\t\t\n\t\t1. Dataset Structure\n\t\n\nThe Audio-FLAN-Dataset has the following directory structure:\nAudio-FLAN-Dataset/\n├── audio_files/\n│   ├── audio/\n│   │   └── 177_TAU_Urban_Acoustic_Scenes_2022/\n│   │   └── 179_Audioset_for_Audio_Inpainting/\n│   │   └── ...\n│   ├── music/\n│   │   └──… See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"MMMG","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UW-FMRL2/MMMG","creator_name":"Foundation Model and RL Research Lab @ UW","creator_url":"https://huggingface.co/UW-FMRL2","description":"\n\t\n\t\t\n\t\tDataset Card for MMMG\n\t\n\n\nWe present MMMG, a comprehensive and human-aligned benchmark for multimodal generation across 4 modality combinations (image, audio, interleaved text and image, interleaved text and audio), with a focus on tasks that present significant challenges for generation models, while still enabling reliable automatic evaluation. \nThis huggingface page only contains the raw dataset of MMMG, for full evaluation suite, please refer to our github page:… See the full description on the dataset page: https://huggingface.co/datasets/UW-FMRL2/MMMG.","first_N":5,"first_N_keywords":["text-to-audio","text-to-image","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"voxpopuli","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/voxpopuli","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"common_voice_11_0","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0","creator_name":"Mozilla Foundation","creator_url":"https://huggingface.co/mozilla-foundation","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 11.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 24210 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 16413 validated hours in 100 languages, but more voices and languages are always added. \nTake a look at the Languages page to… See the full description on the dataset page: https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"YueMotion","keyword":"speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/YueMotion","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"YueMotion is a Cantonese speech emotion dataset.","first_N":5,"first_N_keywords":["Yue Chinese","cc-by-sa-4.0","1K - 10K","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"nota","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nota","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\n\t\n\t\t\n\t\tDataset Card for Nota\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis data was created by the public institution Nota, which is part of the Danish Ministry of Culture. Nota has a library audiobooks and audiomagazines for people with reading or sight disabilities. Nota also produces a number of audiobooks and audiomagazines themselves.  \nThe dataset consists of audio and associated transcriptions from Nota's audiomagazines \"Inspiration\" and \"Radio/TV\". All files related to one reading of one edition… See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nota.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"nota","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/nota","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\n\t\n\t\t\n\t\tDataset Card for Nota\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis data was created by the public institution Nota, which is part of the Danish Ministry of Culture. Nota has a library audiobooks and audiomagazines for people with reading or sight disabilities. Nota also produces a number of audiobooks and audiomagazines themselves.  \nThe dataset consists of audio and associated transcriptions from Nota's audiomagazines \"Inspiration\" and \"Radio/TV\". All files related to one reading of one edition… See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nota.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"japanese-anime-speech","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joujiboi/japanese-anime-speech","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","description":"\n\t\n\t\t\n\t\tJapanese Anime Speech Dataset\n\t\n\n日本語はこちら\njapanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.\nThe goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre is… See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"japanese-anime-speech","keyword":"speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joujiboi/japanese-anime-speech","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","description":"\n\t\n\t\t\n\t\tJapanese Anime Speech Dataset\n\t\n\n日本語はこちら\njapanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.\nThe goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre is… See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"libritts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/libritts","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\n\t\n\t\t\n\t\tDataset Card for LibriTTS\n\t\n\n\n\nLibriTTS is a multi-speaker English corpus of approximately 585 hours of read English speech at 24kHz sampling rate, \nprepared by Heiga Zen with the assistance of Google Speech and Google Brain team members. The LibriTTS corpus is \ndesigned for TTS research. It is derived from the original materials (mp3 audio files from LibriVox and text files \nfrom Project Gutenberg) of the LibriSpeech corpus.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the LibriTTS dataset, adapted… See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/libritts.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"pony-speech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-speech","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"profanity-speech-suroboyoan","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jaal047/profanity-speech-suroboyoan","creator_name":"Rijal Akhdan Khirulah","creator_url":"https://huggingface.co/Jaal047","description":"\n\t\n\t\t\n\t\tDataset Audio Perkataan Vulgar Bahasa Jawa Dialek Surabaya\n\t\n\n\n\t\n\t\t\n\t\tDeskripsi\n\t\n\nDataset ini berisi audio rekaman percakapan dalam bahasa Jawa dialek Surabaya yang mengandung perkataan vulgar. Setiap rekaman dilengkapi dengan transkripsi teks yang sesuai.Dataset ini dibuat sebagai bagian dari penelitian skripsi saya dengan tujuan untuk mendukung analisis dan pengembangan dalam bidang deteksi perkataan vulgar dalam bahasa Jawa dialek Surabaya menggunakan teknologi speech-to-text… See the full description on the dataset page: https://huggingface.co/datasets/Jaal047/profanity-speech-suroboyoan.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Indonesian","Javanese","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"openai-voices","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leafspark/openai-voices","creator_name":"leafspark","creator_url":"https://huggingface.co/leafspark","description":"\n\t\n\t\t\n\t\tOpenAI Voices\n\t\n\nA collection of TTS samples collected from the OpenAI API and app.\nCurrently the following voices are available:\n\nSky\nJuniper\n\nThese are not labeled, however they are clean lossless audio files, and may contain noise from the model.\nPlease refer to sky/statement.wav for the highest quality voice sample!\n","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"mls-eng-speaker-descriptions","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of English MLS\n\t\n\nThis dataset consists in annotations of the English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.\nThis dataset… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-speaker-descriptions","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of English MLS\n\t\n\nThis dataset consists in annotations of the English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.\nThis dataset… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"libritts-r-filtered-speaker-descriptions","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/libritts-r-filtered-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated LibriTTS-R\n\t\n\nThis dataset is an annotated version of a filtered LibriTTS-R [1]. \nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately 960 hours of read English speech at 24kHz sampling rate, published in 2019. \nIn the text_description column, it provides natural language annotations on the characteristics of speakers and utterances, that have been generated using the Data-Speech… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts-r-filtered-speaker-descriptions.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiMed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leduckhai/MultiMed","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","description":"\n\t\n\t\t\n\t\tMultiMed: Multilingual Medical Speech Recognition via Attention Encoder Decoder\n\t\n\nACL 2025\nKhai Le-Duc, Phuc Phan, Tan-Hanh Pham, Bach Phan Tat,\n\nMinh-Huong Ngo, Chris Ngo, Thanh Nguyen-Tang, Truong-Son Hy\n\n\nPlease press ⭐ button and/or cite papers if you feel helpful.\n\n\n  \n\n\n\nAbstract:\nMultilingual automatic speech recognition (ASR) in the medical domain serves as a foundational task for various downstream applications such as speech translation, spoken language understanding, and… See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/MultiMed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","English","German","French"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_eu_v2.1","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/composite_corpus_eu_v2.1","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tComposite dataset for Basque made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/eu: \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\ngttsehu/basque_parliament_1/eu: \"train_clean\" split removing some of the… See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_eu_v2.1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Tamil","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tTamil Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Tamil monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Tamil\nTotal Duration: ~20.33 hours (Male: 10.3 hours, Female: 10.03 hours)\nAudio Format: WAV\nSampling Rate:… See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil.","first_N":5,"first_N_keywords":["text-to-speech","Tamil","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/MANGO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n255,150 human ratings of TTS-generated outputs and ground-truth human speech.\nCovers two major Indian languages: Hindi & Tamil, and English.\nBased on the MUSHRA (Multiple Stimuli with Hidden Reference… See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/MANGO.","first_N":5,"first_N_keywords":["text-to-speech","crowd-sourced","Hindi","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/MANGO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n255,150 human ratings of TTS-generated outputs and ground-truth human speech.\nCovers two major Indian languages: Hindi & Tamil, and English.\nBased on the MUSHRA (Multiple Stimuli with Hidden Reference… See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/MANGO.","first_N":5,"first_N_keywords":["text-to-speech","crowd-sourced","Hindi","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/MANGO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n255,150 human ratings of TTS-generated outputs and ground-truth human speech.\nCovers two major Indian languages: Hindi & Tamil, and English.\nBased on the MUSHRA (Multiple Stimuli with Hidden Reference… See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/MANGO.","first_N":5,"first_N_keywords":["text-to-speech","crowd-sourced","Hindi","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"tts-crh-abibullah","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/tts-crh-abibullah","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\nThis is subset of Abibullah voice with train/test splits.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nQuality: high\nDuration: 2h50m\nFrequency: 48 kHz\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { qirimtatar-tts (Revision c2ceec6)… See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-abibullah.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-crh-sevil","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/tts-crh-sevil","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\nThis is subset of Sevil voice with train/test splits.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nQuality: high\nDuration: 2h29m\nFrequency: 48 kHz\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { qirimtatar-tts (Revision c2ceec6) }… See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-sevil.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-crh-arslan","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/tts-crh-arslan","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\nThis is subset of Arslan voice with train/test splits.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nQuality: high\nDuration: 1h20m\nFrequency: 48 kHz\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { qirimtatar-tts (Revision c2ceec6) }… See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-arslan.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-tetiana","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-tetiana","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for 🇺🇦 Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }… See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-tetiana.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-lada","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-lada","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for 🇺🇦 Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }… See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-lada.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-oleksa","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-oleksa","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for 🇺🇦 Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }… See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-oleksa.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-mykyta","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/opentts-mykyta","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for 🇺🇦 Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }… See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-mykyta.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"voice-of-america","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/voice-of-america","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tVoice of America for  🇺🇦 Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\nDuration: 390.99 hours\n\nmean: 4.315471\nstd: 3.63682\nmin: 0.2995625\n25%: 1.82\n50%: 3.42\n75%: 5.628\nmax: 29.98\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year… See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/voice-of-america.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Ukrainian","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Audio-Children-Stories-Collection-Large","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Audio-Children-Stories-Collection-Large","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Audio Chidren Stories Collection Large\nThis dataset has 5600++ audio files in .mp3 format. This has been created using my existing dataset Children-Stories-Collection.\nI have used first 5600++ stories from Children-Stories-1-Final.json file for creating this audio dataset.\nYou can use this for training and research purpose.\nThank you for your love & support.\n","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to download… See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"text-to-speech-sentences","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/text-to-speech-sentences","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"\n\t\n\t\t\n\t\tTexts for Ukrainian Text to Speech dataset\n\t\n\nCode for this dataset is here: https://github.com/egorsmkv/uk-tts-dataset-text\n","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"text-to-speech-phonemized-sentences","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speech-uk/text-to-speech-phonemized-sentences","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","description":"Phonemized version of https://huggingface.co/datasets/speech-uk/text-to-speech-sentences with some additional fields.\n","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ArVoice","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ArVoice","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n  ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis\n\n\n\n    ArVoice is a multi-speaker Modern Standard Arabic (MSA) speech corpus with fully diacritized transcriptions, intended  for multi-speaker speech synthesis, and can be useful for other tasks such as speech-based diacritic restoration, voice conversion, and deepfake detection.  \n      ArVoice comprises: (1) professionally recorded audio by 2 male and 2 female voice artists from diacritized transcripts, (2) professionally… See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ArVoice.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ArVoice","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ArVoice","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n  ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis\n\n\n\n    ArVoice is a multi-speaker Modern Standard Arabic (MSA) speech corpus with fully diacritized transcriptions, intended  for multi-speaker speech synthesis, and can be useful for other tasks such as speech-based diacritic restoration, voice conversion, and deepfake detection.  \n      ArVoice comprises: (1) professionally recorded audio by 2 male and 2 female voice artists from diacritized transcripts, (2) professionally… See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ArVoice.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"listening_test","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ttsds/listening_test","creator_name":"TTS Distribution Score","creator_url":"https://huggingface.co/ttsds","description":"\n\t\n\t\t\n\t\tListening Test Results for TTSDS2\n\t\n\nThis dataset contains all 11,000+ ratings collected for 20 synthetic speech systems for the TTSDS2 study (link coming soon).\nThe scores are MOS (Mean Opinion Score), CMOS (Comparative Mean Opinion Score) and SMOS (Speaker Similarity Mean Opinion Score).\nAll annotators included passed three attention checks throughout the survey.\n","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"TTS-Multilingual-Test-Set","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MiniMaxAI/TTS-Multilingual-Test-Set","creator_name":"MiniMax","creator_url":"https://huggingface.co/MiniMaxAI","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nTo assess the multilingual zero-shot voice cloning capabilities of TTS models, we have constructed a test set encompassing 24 languages. This dataset provides both audio samples for voice cloning and corresponding test texts.\nSpecifically, the test set for each language includes:\n100 distinct test sentences.\nAudio samples from two speakers (one male and one female) carefully selected from the Mozilla Common Voice (MCV) dataset, intended for voice cloning.\nResearchers can… See the full description on the dataset page: https://huggingface.co/datasets/MiniMaxAI/TTS-Multilingual-Test-Set.","first_N":5,"first_N_keywords":["text-to-speech","cc-by-sa-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"tts-indo","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agufsamudra/tts-indo","creator_name":"Gufranaka Samudra","creator_url":"https://huggingface.co/agufsamudra","description":"\n\t\n\t\t\n\t\tagufsamudra/tts-indo\n\t\n\nagufsamudra/tts-indo is a preprocessed Indonesian speech dataset designed for training Text-to-Speech (TTS) models. This dataset is derived from the original Dataset TTS Indo available on Kaggle.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nNumber of Examples: 114,036\nDataset Size: ~4GB\nAudio Sampling Rate: 16,000 Hz\nFeatures:\naudio: WAV audio recordings\ntext: Transcription of the audio\n\n\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach sample in the dataset contains:\n\naudio: A dictionary… See the full description on the dataset page: https://huggingface.co/datasets/agufsamudra/tts-indo.","first_N":5,"first_N_keywords":["text-to-speech","Indonesian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ParaDeHate","keyword":"hate-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ScaDSAI/ParaDeHate","creator_name":"Center for Scalable Data Analytics and Artificial Intelligence","creator_url":"https://huggingface.co/ScaDSAI","description":"\n\t\n\t\t\n\t\tPARADEHATE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParaDeHate is a parallel dataset designed for hate speech detoxification, containing 8,276 pairs of toxic (hate speech) and detoxified (non-hateful) text samples. It was created using an LLM-in-the-loop pipeline with GPT-4o-mini, automating the process of rewriting hate speech into non-toxic, semantically equivalent text. The dataset is sourced from four existing hate speech datasets (CreHate, HateXplain, Davidson, and Founta) and focuses on… See the full description on the dataset page: https://huggingface.co/datasets/ScaDSAI/ParaDeHate.","first_N":5,"first_N_keywords":["text-classification","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"twi-words-speech-text-parallel-multispeaker","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 340908 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 340908 audio files >… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel-multispeaker.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"twi-words-speech-text-parallel-multispeaker","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 340908 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 340908 audio files >… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel-multispeaker.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"twi-words-speech-text-parallel-multispeaker","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 340908 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 340908 audio files >… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel-multispeaker.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"languages_dataset","keyword":"linguistics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ultimate-dictionary/languages_dataset","creator_name":"Ultimate Dictionary","creator_url":"https://huggingface.co/ultimate-dictionary","description":"This dataset contains a set of 8612 languages from across the world as well as data such as Glottocode, ISO-639-3 codes, names, language families etc.\nOriginal source: https://glottolog.org/glottolog/language\n","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"fleurs-farsi","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi","creator_name":"Mohammad Sadegh Gholizadeh","creator_url":"https://huggingface.co/MohammadGholizadeh","description":"\n\t\n\t\t\n\t\tFLEURS Farsi (fa_ir) - Processed Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the Farsi (Persian, fa_ir) portion of the FLEURS (Few-shot Learning Evaluation of Universal Representations of Speech) dataset, processed into a Hugging Face datasets compatible format. FLEURS is a many-language speech dataset created by Google, designed for evaluating speech recognition systems, particularly in low-resource scenarios.\nThis version includes audio recordings and their… See the full description on the dataset page: https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi.","first_N":5,"first_N_keywords":["Persian","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"fluke","keyword":"linguistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/joey234/fluke","creator_name":"Thinh Truong","creator_url":"https://huggingface.co/joey234","description":"\n\t\n\t\t\n\t\tFLUKE: A Task-Agnostic Framework for Linguistic Capability Testing\n\t\n\nPaper: FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness EvaluationDataset: huggingface.co/datasets/joey234/fluke\nAuthors: Yulia Otmakhova¹*, Hung Thinh Truong¹*, Rahmad Mahendra², Zenan Zhai³, Rongxin Zhu¹'³, Daniel Beck², Jey Han Lau¹\n¹The University of Melbourne, ²RMIT University, ³Oracle\n*Equal contribution\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nFLUKE (Framework for Linguistic Capability… See the full description on the dataset page: https://huggingface.co/datasets/joey234/fluke.","first_N":5,"first_N_keywords":["text-classification","token-classification","zero-shot-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"ar_sarcasm","keyword":"sarcasm-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iabufarha/ar_sarcasm","creator_name":"Ibrahim","creator_url":"https://huggingface.co/iabufarha","description":"\n\t\n\t\t\n\t\tDataset Card for ArSarcasm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArSarcasm is a new Arabic sarcasm detection dataset.\nThe dataset was created using previously available Arabic sentiment analysis\ndatasets (SemEval 2017\nand ASTD) and adds sarcasm and\ndialect labels to them.\nThe dataset contains 10,547 tweets, 1,682 (16%) of which are sarcastic.\nFor more details, please check the paper\nFrom Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and… See the full description on the dataset page: https://huggingface.co/datasets/iabufarha/ar_sarcasm.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"kor_sarcasm","keyword":"sarcasm-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SpellOnYou/kor_sarcasm","creator_name":"SpellOnYou","creator_url":"https://huggingface.co/SpellOnYou","description":"\n\t\n\t\t\n\t\tDataset Card for Korean Sarcasm Detection\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These tweets were gathered by querying for: 역설, 아무말, 운수좋은날, 笑, 뭐래 아닙니다, 그럴리없다, 어그로, irony sarcastic, and sarcasm. The dataset was pre-processed by removing the keyword hashtag, urls and mentions of the user… See the full description on the dataset page: https://huggingface.co/datasets/SpellOnYou/kor_sarcasm.","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ASCEND","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/ASCEND","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"\n\t\n\t\t\n\t\tDataset Card for ASCEND\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.… See the full description on the dataset page: https://huggingface.co/datasets/CAiRE/ASCEND.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ASCEND","keyword":"speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/ASCEND","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"\n\t\n\t\t\n\t\tDataset Card for ASCEND\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.… See the full description on the dataset page: https://huggingface.co/datasets/CAiRE/ASCEND.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"NPSC_test","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/NPSC_test","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\n\t\n\t\t\n\t\tDataset Card for NBAiLab/NPSC\n\t\n\nThe Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Språkbanken at the National Library in Norway. \nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokmål or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount… See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/NPSC_test.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHateCheck is a suite of functional test for hate speech detection models. \nThe dataset contains 3,728 validated test cases in 29 functional tests.\n19 functional tests correspond to distinct types of hate. The other 11 functional tests cover challenging types of non-hate.\nThis allows for targeted diagnostic insights into model performance.\nIn our ACL paper, we found critical weaknesses in all commercial and academic hate… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It… See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It… See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sharif_emotional_speech_dataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset","creator_name":"Paria Jamshid Lou","creator_url":"https://huggingface.co/pariajm","description":"\n\t\n\t\t\n\t\n\t\n\t\tSharif Emotional Speech Dataset (ShEMO)\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe dataset includes 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data extracted from online Persian radio plays. The ShEMO covers speech samples of 87 native-Persian speakers for five basic emotions including anger, fear, happiness, sadness and surprise, as well as neutral state. Twelve annotators label the underlying emotional state of utterances and majority voting is used… See the full description on the dataset page: https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","radio-plays"],"keywords_longer_than_N":true},
	{"name":"measuring-hate-speech","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech","creator_name":"D-Lab, UC Berkeley","creator_url":"https://huggingface.co/ucberkeley-dlab","description":"\n\t\n\t\t\n\t\tDataset card for Measuring Hate Speech\n\t\n\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022), consisting of 39,565 comments annotated by 7,912 annotators, for 135,556 combined rows. The primary outcome variable is the \"hate speech score\" but the 10 constituent ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech benchmark) can also be treated as… See the full description on the dataset page: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","sentiment-classification","multi-label-classification","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"measuring-hate-speech","keyword":"hate-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech","creator_name":"D-Lab, UC Berkeley","creator_url":"https://huggingface.co/ucberkeley-dlab","description":"\n\t\n\t\t\n\t\tDataset card for Measuring Hate Speech\n\t\n\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022), consisting of 39,565 comments annotated by 7,912 annotators, for 135,556 combined rows. The primary outcome variable is the \"hate speech score\" but the 10 constituent ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech benchmark) can also be treated as… See the full description on the dataset page: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","sentiment-classification","multi-label-classification","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ascend","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/filwsyl/ascend","creator_name":"jianyuan.zengjy","creator_url":"https://huggingface.co/filwsyl","description":"\n\t\n\t\t\n\t\tDataset Card for ASCEND\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.… See the full description on the dataset page: https://huggingface.co/datasets/filwsyl/ascend.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"honest","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MilaNLProc/honest","creator_name":"MilaNLP","creator_url":"https://huggingface.co/MilaNLProc","description":"HONEST dataset comprises a set of templates for measuring hurtful sentence completions in language models. The templates are provided in six languages (English, Italian, French, Portuguese, Romanian, and Spanish) for binary gender and in English for LGBTQAI+ individuals. WARNING: This dataset contains content that are offensive and/or hateful in nature.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","no-annotation","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Sinhala-English-Code-Mixed-Code-Switched-Dataset","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-English-Code-Mixed-Code-Switched-Dataset","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","description":"\n\t\n\t\t\n\t\n\t\n\t\tSinhala-English-Code-Mixed-Code-Switched-Dataset\n\t\n\nThis dataset contains 10,000 comments that have been annotated at the sentence level for sentiment analysis, humor detection, hate speech detection, aspect identification, and language identification.\nThe following is the tag scheme.\n\nSentiment -  Positive, Negative, Neutral,  Conflict\nHumor - Humorous, Non humorous\nHate Speech - Hate-Inducing, Abusive, Not offensive\nAspect - Network, Billing or Price, Package, Customer Service… See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-English-Code-Mixed-Code-Switched-Dataset.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","hate-speech-detection","language-identification","multilingual"],"keywords_longer_than_N":true},
	{"name":"amazon_polarity","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_polarity","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AmazonPolarityClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAmazon Polarity Classification Dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://huggingface.co/datasets/amazon_polarity\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AmazonPolarityClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_polarity.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"toxic_conversations_50k","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/toxic_conversations_50k","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ToxicConversationsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCollection of comments from the Civil Comments platform together with annotations if the comment is toxic or not.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/overview\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport… See the full description on the dataset page: https://huggingface.co/datasets/mteb/toxic_conversations_50k.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"hatecheck-spanish","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-spanish","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-spanish.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-portuguese","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-portuguese","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-portuguese.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-polish","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-polish","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-polish.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-mandarin","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-mandarin","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-mandarin.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-italian","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-italian","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-italian.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-hindi","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-hindi","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-hindi.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-german","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-german","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-german.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-french","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-french","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-french.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-dutch","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-dutch","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-dutch.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-arabic","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-arabic","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-arabic.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-fb-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn… See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-fb-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn… See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"openstt-uk","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/openstt-uk","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\n\t\n\t\t\n\t\tOpen Speech-to-Text corpus for 🇺🇦 Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset has transcriptions with other metadata for the VOA Ukrainian dataset (~398h).\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { openstt-uk (Revision 88d95da) },\n    year         = 2025… See the full description on the dataset page: https://huggingface.co/datasets/Yehor/openstt-uk.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Ukrainian","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"zeroth-korean","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/zeroth-korean","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\n\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\nZeroth project introduces free Korean speech corpus and aims to make Korean… See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/zeroth-korean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","monolingual","extended|kresnik/zeroth_korean","Korean"],"keywords_longer_than_N":true},
	{"name":"wiki_toxic","keyword":"hate-speech-detection","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OxAISH-AL-LLM/wiki_toxic","creator_name":"OxAI Safety Hub Active Learning with Large Language Models Labs Team","creator_url":"https://huggingface.co/OxAISH-AL-LLM","description":"Jigsaw Toxic Comment Challenge dataset. This dataset was the basis of a Kaggle competition run by Jigsaw","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"youtube-transcriptions","keyword":"speech","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jamescalam/youtube-transcriptions","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","description":"The YouTube transcriptions dataset contains technical tutorials (currently from James Briggs, Daniel Bourke, and AI Coffee Break) transcribed using OpenAI's Whisper (large). Each row represents roughly a sentence-length chunk of text alongside the video URL and timestamp.\nNote that each item in the dataset contains just a short chunk of text. For most use cases you will likely need to merge multiple rows to create more substantial chunks of text, if you need to do that, this code snippet will… See the full description on the dataset page: https://huggingface.co/datasets/jamescalam/youtube-transcriptions.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","visual-question-answering","open-domain-qa","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"sova_rudevices","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bond005/sova_rudevices","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","description":"\n\t\n\t\t\n\t\tDataset Card for sova_rudevices\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSOVA Dataset is free public STT/ASR dataset. It consists of several parts, one of them is SOVA RuDevices. This part is an acoustic corpus of approximately 100 hours of 16kHz Russian live speech with manual annotating, prepared by SOVA.ai team.\nAuthors do not divide the dataset into train, validation and test subsets. Therefore, I was compelled to prepare this splitting. The training subset includes more than 82 hours, the… See the full description on the dataset page: https://huggingface.co/datasets/bond005/sova_rudevices.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"IMaSC","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/IMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tIMaSC: ICFOSS Malayalam Speech Corpus\n\t\n\nIMaSC is a Malayalam text and speech corpus made available by ICFOSS for the purpose of developing speech technology for Malayalam, particularly text-to-speech. The corpus contains 34,473 text-audio pairs of Malayalam sentences spoken by 8 speakers, totalling in approximately 50 hours of audio.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 34,473 instances with fields text, speaker, and audio. The audio is mono, sampled at 16kH. The… See the full description on the dataset page: https://huggingface.co/datasets/thennal/IMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"IMaSC","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/IMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tIMaSC: ICFOSS Malayalam Speech Corpus\n\t\n\nIMaSC is a Malayalam text and speech corpus made available by ICFOSS for the purpose of developing speech technology for Malayalam, particularly text-to-speech. The corpus contains 34,473 text-audio pairs of Malayalam sentences spoken by 8 speakers, totalling in approximately 50 hours of audio.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 34,473 instances with fields text, speaker, and audio. The audio is mono, sampled at 16kH. The… See the full description on the dataset page: https://huggingface.co/datasets/thennal/IMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_dummy","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy","creator_name":"Sanchit Gandhi","creator_url":"https://huggingface.co/sanchit-gandhi","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr_dummy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a truncated version of the LibriSpeech dataset. It contains 20 samples from each of the splits. To view the full dataset, visit: https://huggingface.co/datasets/librispeech_asr\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been… See the full description on the dataset page: https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_es","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_es","creator_name":"Carlos Daniel Hernández Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_es","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_es","creator_name":"Carlos Daniel Hernández Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"nst","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jzju/nst","creator_name":"Johan Ju","creator_url":"https://huggingface.co/jzju","description":"Homepage: https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-56\nUsed lydfiler_16_1.tar.gz and metadata_se_csv.zip\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Swedish","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ravnursson_asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr","creator_name":"Carlos Daniel Hernández Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"\n\t\n\t\t\n\t\tDataset Card for ravnursson_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus \"RAVNURSSON FAROESE SPEECH AND TRANSCRIPTS\" (or RAVNURSSON Corpus for short) is a collection of speech recordings with transcriptions intended for Automatic Speech Recognition (ASR) applications in the language that is spoken at the Faroe Islands (Faroese). It was curated at the Reykjavík University (RU) in 2022.\nThe RAVNURSSON Corpus is an extract of the \"Basic Language Resource Kit 1.0\" (BLARK 1.0) [1] developed… See the full description on the dataset page: https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"kmhas_korean_hate_speech","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech","creator_name":"Jean Lee","creator_url":"https://huggingface.co/jeanlee","description":"The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\nThe fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","hate-speech-detection","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"ciempiess_test","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_test","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"The CIEMPIESS TEST Corpus is a gender balanced corpus destined to test acoustic models for the speech recognition task. The corpus was manually transcribed and it contains audio recordings from 10 male and 10 female speakers. The CIEMPIESS TEST is one of the three corpora included at the LDC's \\\"CIEMPIESS Experimentation\\\" (LDC2019S07).","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"samromur_children","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_children","creator_name":"Language and Voice Laboratory (Reykjavík University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"The Samrómur Children corpus contains more than 137000 validated speech-recordings uttered by Icelandic children.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"xbmu_amdo31","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/syzym/xbmu_amdo31","creator_name":"Senyan Li","creator_url":"https://huggingface.co/syzym","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for [XBMU-AMDO31]\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nXBMU-AMDO31 dataset is a speech recognition corpus of Amdo Tibetan dialect. The open source corpus contains 31 hours of speech data and resources related to build speech recognition systems, including transcribed texts and a Tibetan pronunciation dictionary.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nautomatic-speech-recognition: The dataset can be used to train a model for Amdo Tibetan Automatic Speech… See the full description on the dataset page: https://huggingface.co/datasets/syzym/xbmu_amdo31.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","monolingual","tib","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"raddromur_asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr","creator_name":"Language and Voice Laboratory (Reykjavík University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"\n\t\n\t\t\n\t\tDataset Card for raddromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Raddrómur Icelandic Speech 22.09\" (\"Raddrómur Corpus\" for short) is an Icelandic corpus created by the Language and Voice Laboratory (LVL) at Reykjavík University (RU) in 2022. It is made out of radio podcasts mostly taken from RÚV (ruv.is).\n\n\t\n\t\t\n\t\tExample Usage\n\t\n\nThe Raddrómur Corpus counts with the train split only. To load the training split pass its name as a config name:\nfrom datasets import load_dataset… See the full description on the dataset page: https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"quran-data","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ashraf-ali/quran-data","creator_name":"Ashraf Ali","creator_url":"https://huggingface.co/ashraf-ali","description":"\n\t\n\t\t\n\t\tDataset Card for Quran audio\n\t\n\nContent \n\n7 Imam Full Quran Recitation: 7*6236 wav file\ncsv contains the Text info for 11k subset short wav file\n\n\nTarteel.io user dataset ~25k wav\ncsv contains the Text info for 18k subset of the accepted user quality\n\n\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tarteel.io","cc0-1.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"bible_tts_hausa","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vpetukhov/bible_tts_hausa","creator_name":"Viktor Petukhov","creator_url":"https://huggingface.co/vpetukhov","description":"\n\t\n\t\t\n\t\tDataset Card for BibleTTS Hausa\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBibleTTS is a large high-quality open Text-to-Speech dataset with up to 80 hours of single speaker, studio quality 48kHz recordings.\nThis is a Hausa part of the dataset. Aligned hours: 86.6, aligned verses: 40,603.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nHausa\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: audio path\nsentence: transcription of the audio\nlocale: always set to ha\nbook: 3-char book encoding\nverse: verse id… See the full description on the dataset page: https://huggingface.co/datasets/vpetukhov/bible_tts_hausa.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"bible_tts_hausa","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vpetukhov/bible_tts_hausa","creator_name":"Viktor Petukhov","creator_url":"https://huggingface.co/vpetukhov","description":"\n\t\n\t\t\n\t\tDataset Card for BibleTTS Hausa\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBibleTTS is a large high-quality open Text-to-Speech dataset with up to 80 hours of single speaker, studio quality 48kHz recordings.\nThis is a Hausa part of the dataset. Aligned hours: 86.6, aligned verses: 40,603.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nHausa\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: audio path\nsentence: transcription of the audio\nlocale: always set to ha\nbook: 3-char book encoding\nverse: verse id… See the full description on the dataset page: https://huggingface.co/datasets/vpetukhov/bible_tts_hausa.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"libris_clean_100","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automatic… See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"everyayah","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tarteel-ai/everyayah","creator_name":"Tarteel AI","creator_url":"https://huggingface.co/tarteel-ai","description":"﷽\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Arabic.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA typical data point comprises the audio file audio, and its transcription called text.\nThe duration is in seconds, and the… See the full description on the dataset page: https://huggingface.co/datasets/tarteel-ai/everyayah.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"msc","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/msc","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tSMC Malayalam Speech Corpus\n\t\n\nMalayalam Speech Corpus (MSC) is a repository of curated speech samples collected using MSC web application, released by Swathanthra Malayalam Computing. \nThe official blog post and source data can be found at https://blog.smc.org.in/malayalam-speech-corpus/.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe first version of Malayalam Speech Corpus contains 1541 speech samples from 75 contributors amounting to 1:38:16 hours of speech. It has 482 unique sentences, 1400… See the full description on the dataset page: https://huggingface.co/datasets/thennal/msc.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"ulca_ml","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/ulca_ml","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tULCA ASR Dataset Malayalam Speech Corpus\n\t\n\nThe labelled Malayalam speech subcorpus from the larger ULCA ASR Corpus.\nThe speech is taken from news broadcasts, and is largely composed of short soundbites with some longer outliers.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","found","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"multilingual-gec","keyword":"grammar","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juancavallotti/multilingual-gec","creator_name":"Juan Alberto Lopez Cavallotti","creator_url":"https://huggingface.co/juancavallotti","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Grammar Error Correction\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset can be used to train a transformer model (we used T5) to correct grammar errors in simple sentences written in English, Spanish, French, or German. \nThis dataset was developed as a component for the Squidigies platform.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nGrammar Error Correction: By appending the prefix fix grammar: to the prrompt.\nLanguage Detection: By appending the prefix:… See the full description on the dataset page: https://huggingface.co/datasets/juancavallotti/multilingual-gec.","first_N":5,"first_N_keywords":["translation","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"Umamusume-voice-text-pairs","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Plachta/Umamusume-voice-text-pairs","creator_name":"ElderFrog","creator_url":"https://huggingface.co/Plachta","description":"Plachta/Umamusume-voice-text-pairs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"Umamusume-voice-text-pairs","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Plachta/Umamusume-voice-text-pairs","creator_name":"ElderFrog","creator_url":"https://huggingface.co/Plachta","description":"Plachta/Umamusume-voice-text-pairs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"hungarian-single-speaker-tts","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts","creator_name":"KTH","creator_url":"https://huggingface.co/KTH","description":"\n\t\n\t\t\n\t\tDataset Card for CSS10 Hungarian: Single Speaker Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus consists of a single speaker, with 4515 segments extracted\nfrom a single LibriVox audiobook.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Hungarian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Splits… See the full description on the dataset page: https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts.","first_N":5,"first_N_keywords":["text-to-speech","other","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"gos-demo","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bartelds/gos-demo","creator_name":"Martijn Bartelds","creator_url":"https://huggingface.co/bartelds","description":"\n\t\n\t\t\n\t\tGronings transcribed speech\n\t\n\nDemonstration dataset with Gronings transcribed speech based on the dataset released by San et al. (2021).\nFor more information see the corresponding ASRU 2021 paper.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Gronings","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"pile-detoxify","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tomekkorbak/pile-detoxify","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","description":"\n\t\n\t\t\n\t\tDataset Card for pile-pii-scrubadub\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text from The Pile, annotated based on the toxicity of each sentence.\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the toxicity predicted by the Detoxify.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is taken from The Pile, which is English text.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData… See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-detoxify.","first_N":5,"first_N_keywords":["text-classification","other","acceptability-classification","hate-speech-detection","text-scoring"],"keywords_longer_than_N":true},
	{"name":"MusicCaps","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/MusicCaps","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for MusicCaps\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MusicCaps dataset contains 5,521 music examples, each of which is labeled with an English aspect list and a free text caption written by musicians. An aspect list is for example \"pop, tinny wide hi hats, mellow piano melody, high pitched female vocal melody, sustained pulsating synth lead\", while the caption consists of multiple sentences about the music, e.g., \n\"A low sounding male voice is rapping over a fast paced drums… See the full description on the dataset page: https://huggingface.co/datasets/google/MusicCaps.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-sa-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"cm.trial","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/taqwa92/cm.trial","creator_name":"taqwa mohamed","creator_url":"https://huggingface.co/taqwa92","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 11.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 24210 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 16413 validated hours in 100 languages, but more voices and languages are always added. \nTake a look at the Languages page to… See the full description on the dataset page: https://huggingface.co/datasets/taqwa92/cm.trial.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"fstdt-quotes","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes","creator_name":"Celeste Ma","creator_url":"https://huggingface.co/MtCelesteMa","description":"\n\t\n\t\t\n\t\tDataset Card for FSTDT Quotes\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFSTDT Quotes is a snapshot of the Fundies Say the Darndest Things website taken on 2023/02/03 14:16. It is intended for hate and fringe speech detection and classification.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nFSTDT Quotes is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example instance looks like this:\n{\n  \"id\": \"G\",\n  \"submitter\": \"anonymous\"… See the full description on the dataset page: https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"atco2_only_augmented","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/luigisaetta/atco2_only_augmented","creator_name":"LuigiSaetta","creator_url":"https://huggingface.co/luigisaetta","description":"luigisaetta/atco2_only_augmented dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ScienceQA","keyword":"grammar","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/derek-thomas/ScienceQA","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","description":"\n\t\n\t\t\n\t\tDataset Card Creation Guide\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLearn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMulti-modal Multiple Choice\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nExplore more samples here.\n{'image': Image,\n 'question': 'Which of these states is farthest north?',\n 'choices': ['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma'],\n 'answer': 0… See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/ScienceQA.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","other","visual-question-answering","text-classification"],"keywords_longer_than_N":true},
	{"name":"news-ro-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5… See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"news-ro-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5… See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages… See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages… See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"common_voice_11_clean_tokenized","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anforsm/common_voice_11_clean_tokenized","creator_name":"Anton Forsman","creator_url":"https://huggingface.co/anforsm","description":"A cleaned and tokenized version of the English data from Mozilla Common Voice 11 dataset.\nCleaning steps:\n\nFiltered on samples with >2 upvotes and <1 downvotes]\nRemoved non voice audio at start and end through pytorch VAD\n\nTokenization:\n\nAudio tokenized through EnCodec by Meta\nUsing 24khz pre-trained model, and target bandwidth of 1.5\nRepresented in text as audio_token_0 - audio_token_1023\n\n\nPrompts constructed as \"text: <common voice transcript>\\naudio: <audio tokens>\"\nPrompts tokenized with… See the full description on the dataset page: https://huggingface.co/datasets/anforsm/common_voice_11_clean_tokenized.","first_N":5,"first_N_keywords":["text-to-speech","text-generation","English","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"latvian-text","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RaivisDejus/latvian-text","creator_name":"Raivis Dejus","creator_url":"https://huggingface.co/RaivisDejus","description":"\n\t\n\t\t\n\t\tLatvian text dataset\n\t\n\nData set of latvian language texts. Intended for use in AI tool development, like speech recognition or spellcheckers\n\n\t\n\t\t\n\t\tData sources used\n\t\n\n\nLatvian Wikisource articles - https://wikisource.org/wiki/Category:Latvian\nLiterary works of Rainis - https://repository.clarin.lv/repository/xmlui/handle/20.500.12574/41\nLatvian Wikipedia articles - https://huggingface.co/datasets/joelito/EU_Wikipedias\nEuropean Parliament Proceedings Parallel Corpus -… See the full description on the dataset page: https://huggingface.co/datasets/RaivisDejus/latvian-text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|tilde_model"],"keywords_longer_than_N":true},
	{"name":"banc-trawsgrifiadau-bangor","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prvInSpace/banc-trawsgrifiadau-bangor","creator_name":"Preben Vangberg","creator_url":"https://huggingface.co/prvInSpace","description":"Huggingface Dataset version of Banc Trawsgrifiadau Bangor","first_N":5,"first_N_keywords":["automatic-speech-recognition","Welsh","cc0-1.0","10K - 100K","Audio"],"keywords_longer_than_N":true},
	{"name":"or_in_dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ranjit/or_in_dataset","creator_name":"Ranjit Patro","creator_url":"https://huggingface.co/Ranjit","description":"Ranjit/or_in_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Oriya","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ami-ihm","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distil-whisper/ami-ihm","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"ami-sdm","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distil-whisper/ami-sdm","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"snips_slu_v1.0","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MWilinski/snips_slu_v1.0","creator_name":"Michał Wiliński","creator_url":"https://huggingface.co/MWilinski","description":"\n\t\n\t\t\n\t\tDataset Card for SNIPS SLU v1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains SNIPS SLU Speech Recognition Dataset, available here.\nIt contains recordings of commands for smart home appliances in English, with info about demographics of the speaker.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gogogogo-1/test","creator_name":"mhj","creator_url":"https://huggingface.co/gogogogo-1","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Common Voice Corpus 10.0\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 20817 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 15234 validated hours in 96 languages, but more voices and languages are always added. \nTake a look at the Languages page… See the full description on the dataset page: https://huggingface.co/datasets/gogogogo-1/test.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"quantized-librispeech-train-360","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theblackcat102/quantized-librispeech-train-360","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"theblackcat102/quantized-librispeech-train-360 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"quantized-common-voice-en","keyword":"automatic-speech-recognition","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theblackcat102/quantized-common-voice-en","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"theblackcat102/quantized-common-voice-en dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mpl-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"common-voice-en-revoice","keyword":"automatic-speech-recognition","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theblackcat102/common-voice-en-revoice","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"theblackcat102/common-voice-en-revoice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mpl-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"km-speech-corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seanghay/km-speech-corpus","creator_name":"seanghay","creator_url":"https://huggingface.co/seanghay","description":"\n\t\n\t\t\n\t\tDataset Card for \"km-speech-corpus\"\n\t\n\nsampling_rate: 16000\nmean_seconds: 2.5068187111021882\nmax_seconds: 19.392\nmin_seconds: 0.448\ntotal_seconds: 37459.392\ntotal_hrs: 10.405386666666667\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Khmer","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"km-speech-corpus","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seanghay/km-speech-corpus","creator_name":"seanghay","creator_url":"https://huggingface.co/seanghay","description":"\n\t\n\t\t\n\t\tDataset Card for \"km-speech-corpus\"\n\t\n\nsampling_rate: 16000\nmean_seconds: 2.5068187111021882\nmax_seconds: 19.392\nmin_seconds: 0.448\ntotal_seconds: 37459.392\ntotal_hrs: 10.405386666666667\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Khmer","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"GMaSC","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/GMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tGMaSC: GEC Barton Hill Malayalam Speech Corpus\n\t\n\nGMaSC is a Malayalam text and speech corpus created by the Government Engineering College Barton Hill with an emphasis on Malayalam-accented English. The corpus contains 2,000 text-audio pairs of Malayalam sentences spoken by 2 speakers, totalling in approximately 139 minutes of audio. Each sentences has at least one English word common in Malayalam speech.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 2,000 instances with fields… See the full description on the dataset page: https://huggingface.co/datasets/thennal/GMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"GMaSC","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/GMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tGMaSC: GEC Barton Hill Malayalam Speech Corpus\n\t\n\nGMaSC is a Malayalam text and speech corpus created by the Government Engineering College Barton Hill with an emphasis on Malayalam-accented English. The corpus contains 2,000 text-audio pairs of Malayalam sentences spoken by 2 speakers, totalling in approximately 139 minutes of audio. Each sentences has at least one English word common in Malayalam speech.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 2,000 instances with fields… See the full description on the dataset page: https://huggingface.co/datasets/thennal/GMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"audio_letters_eo","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xekri/audio_letters_eo","creator_name":"Xekri Dragon","creator_url":"https://huggingface.co/xekri","description":"Audio files sampled at 48000Hz of an American male pronouncing the names of the Esperanto letters in three ways. Retroflex-r and trilled-r are included.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Esperanto","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"genshin_ch_10npc","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmj2002/genshin_ch_10npc","creator_name":"xmj","creator_url":"https://huggingface.co/xmj2002","description":"\n\t\n\t\t\n\t\tDataset Card for \"genshin_ch_10npc\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ParsiGoo","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kamtera/ParsiGoo","creator_name":"Flincer","creator_url":"https://huggingface.co/Kamtera","description":"A Persian multispeaker dataset for text-to-speech purposes.","first_N":5,"first_N_keywords":["text-to-speech","other","monolingual","original","Persian"],"keywords_longer_than_N":true},
	{"name":"tarteel-ai-everyayah-Quran","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran","creator_name":"Mohamed Salama","creator_url":"https://huggingface.co/Salama1429","description":"﷽\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tHow to download\n\t\n\n!pip install -q datasets\n\nfrom datasets import load_dataset\ndataset =load_dataset(\"Salama1429/tarteel-ai-everyayah-Quran\", verification_mode=\"no_checks\")\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in… See the full description on the dataset page: https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"whisperspeech","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/collabora/whisperspeech","creator_name":"Collabora","creator_url":"https://huggingface.co/collabora","description":"\n\t\n\t\t\n\t\tThe WhisperSpeech Dataset\n\t\n\nThis dataset contains data to train SPEAR TTS-like text-to-speech models that utilized semantic tokens derived from the OpenAI Whisper\nspeech recognition model.\nWe currently provide semantic and acoustic tokens for the LibriLight and LibriTTS datasets (English only).\nAcoustic tokens:\n\n24kHz EnCodec 6kbps (8 quantizers)\n\nSemantic tokens:\n\nWhisper tiny VQ bottleneck trained on a subset of LibriLight\n\nAvailable LibriLight subsets:\n\nsmall/medium/large… See the full description on the dataset page: https://huggingface.co/datasets/collabora/whisperspeech.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messages… See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences.","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messages… See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences.","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_individual","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Splend1dchan/librispeech_asr_individual","creator_name":"許湛然","creator_url":"https://huggingface.co/Splend1dchan","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"MusicCaps-ru","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/MusicCaps-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tMusicCaps-ru\n\t\n\nTranslated version of google/MusicCaps into Russian.\n","first_N":5,"first_N_keywords":["text-to-speech","translated","Russian","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"audiocaps","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/audiocaps","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\taudiocaps\n\t\n\nHuggingFace mirror of official data repo.\n","first_N":5,"first_N_keywords":["text-to-speech","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"audiocaps-ru","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/audiocaps-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\taudiocaps-ru\n\t\n\nTranslated version of d0rj/audiocaps into Russian.\n","first_N":5,"first_N_keywords":["text-to-speech","translated","monolingual","d0rj/audiocaps","Russian"],"keywords_longer_than_N":true},
	{"name":"amis_voice","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caasih/amis_voice","creator_name":"Isaac Huang","creator_url":"https://huggingface.co/caasih","description":"\n\t\n\t\t\n\t\tamis_voice\n\t\n\n\n\t\n\t\t\n\t\ttest data\n\t\n\n\nDr. Safulo Kacaw Lalanges introduces himself in Amis (Pangcah) Language: YouTube, WAV\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Amis","cc-by-sa-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"the-mc-speech-dataset","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset","creator_name":"Mateusz Czyżnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This is public domain speech dataset consisting of 24018 short audio clips of a single speaker reading sentences in Polish. A transcription is provided for each clip. Clips have total length of more than 22 hours.\nTexts are in public domain. The audio was recorded in 2021-22 as a part of my master's thesis and is in public domain.\nIf you use this dataset, please cite:\n@masterthesis{mcspeech,\n  title={Analiza porównawcza korpusów nagrań mowy dla celów syntezy mowy w języku polskim}… See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Polish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"the-mc-speech-dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset","creator_name":"Mateusz Czyżnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This is public domain speech dataset consisting of 24018 short audio clips of a single speaker reading sentences in Polish. A transcription is provided for each clip. Clips have total length of more than 22 hours.\nTexts are in public domain. The audio was recorded in 2021-22 as a part of my master's thesis and is in public domain.\nIf you use this dataset, please cite:\n@masterthesis{mcspeech,\n  title={Analiza porównawcza korpusów nagrań mowy dla celów syntezy mowy w języku polskim}… See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Polish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"samromur_synthetic","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_synthetic","creator_name":"Language and Voice Laboratory (Reykjavík University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"Samrómur Synthetic consists of 72 hours of synthetized speech in Icelandic.","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"edited_common_voice","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lunarlist/edited_common_voice","creator_name":"taetiya taechamatavorn","creator_url":"https://huggingface.co/lunarlist","description":"\n\t\n\t\t\n\t\tDataset Card for \"edited_common_voice\"\n\t\n\nMore Information needed\nThis dataset is a Thai TTS dataset that use the voice from Common Voice dataset and modify the voice to not to sound like the original.\nMedium: Text-To-Speech ภาษาไทยด้วย Tacotron2\n","first_N":5,"first_N_keywords":["text-to-speech","Thai","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"cantone","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/cantone","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"\n\t\n\t\t\n\t\n\t\n\t\tCantone\n\t\n\nA dataset of 34,489 recordings of Cantonese syllables by 10 speakers.\nThose syllables are generated through the Cantonese speech synthesis engines of Amazon, Apple, Google, and Microsoft.\nAll recordings are stored as WAV files with the following format\n\nChannel: mono\nSample rate: 16 kHz\nBits per sample: 16\n\nHere's a breakdown of the number of recordings under each speaker:\n\n\t\n\t\t\nCompany\nSpeaker\n# Syllables\n\n\n\t\t\nAmazon\nHiujin\n3,885\n\n\nApple\nAasing\n2,977\n\n\nApple\nSinji\n2,977… See the full description on the dataset page: https://huggingface.co/datasets/AlienKevin/cantone.","first_N":5,"first_N_keywords":["audio-classification","Yue Chinese","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech-Synthesizer-TTS","keyword":"text-to-speech","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","Spanish Sign Language","unlicense","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech-Synthesizer-TTS","keyword":"speech","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","Spanish Sign Language","unlicense","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech-Synthesizer-TTS","keyword":"text-to-speech","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","Spanish Sign Language","unlicense","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"new_data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/new_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/new_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"EGY2K","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahafvii/EGY2K","creator_name":"xx","creator_url":"https://huggingface.co/rahafvii","description":"rahafvii/EGY2K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ami-disfluent","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/ami-disfluent","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/ami-disfluent dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Fenrir-Voice","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Fenrir-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Fenrir-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"audio-data","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinTelecmi/audio-data","creator_name":"Sachin Mohanty","creator_url":"https://huggingface.co/SachinTelecmi","description":"SachinTelecmi/audio-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Hindi","mit","1K<n<10K","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"tatar-speech-commands","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/tatar-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tAn Open-Source Tatar Speech Commands Dataset\n\t\n\nPaper: Paper\nAn Open-Source Tatar Speech Commands Dataset for IoT and Robotics Applications\nGitHub: https://github.com/IS2AI/TatarSCR\nDescription:\nThe dataset covers 35 commands used in robotics, IoT, and smart systems. In total, the dataset contains 3,547 one-second utterances from 153 people. The utterances were saved in the WAV format with a sampling rate of 16 kHz. \nCitation: The project was developed in academic collaboration between… See the full description on the dataset page: https://huggingface.co/datasets/issai/tatar-speech-commands.","first_N":5,"first_N_keywords":["audio-classification","Tatar","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Turkish_Speech_Corpus","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Turkish_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tTurkish Speech Corpus (TSC)\n\t\n\nThis repository presents an open-source Turkish Speech Corpus, introduced in \"Multilingual Speech Recognition for Turkic Languages\". The corpus contains 218.2 hours of transcribed speech with 186,171 utterances and is the largest publicly available Turkish dataset of its kind at that time. \nPaper: Multilingual Speech Recognition for Turkic Languages.  \nGitHub Repository: https://github.com/IS2AI/TurkicASR\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\n@Article{info14020074… See the full description on the dataset page: https://huggingface.co/datasets/issai/Turkish_Speech_Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","mit","Audio","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"Turkish_Speech_Corpus","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Turkish_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tTurkish Speech Corpus (TSC)\n\t\n\nThis repository presents an open-source Turkish Speech Corpus, introduced in \"Multilingual Speech Recognition for Turkic Languages\". The corpus contains 218.2 hours of transcribed speech with 186,171 utterances and is the largest publicly available Turkish dataset of its kind at that time. \nPaper: Multilingual Speech Recognition for Turkic Languages.  \nGitHub Repository: https://github.com/IS2AI/TurkicASR\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\n@Article{info14020074… See the full description on the dataset page: https://huggingface.co/datasets/issai/Turkish_Speech_Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","mit","Audio","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"kazakh-speech-commands","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/kazakh-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tKazakh Speech Commands Dataset\n\t\n\nPaper: Speech Command Recognition: Text-to-Speech and Speech Corpus Scraping Are All You Need\nRepository: https://github.com/IS2AI/Kazakh-Speech-Commands-Dataset\nDescription: The dataset contains 3,623 utterances for 35 commands. The utterances were saved in the WAV format with a sampling rate of 16 kHz. The dataset was collected from 119 participants (62 males, 57 females) from different regions of Kazakhstan.\n\n\t\n\t\t\nID\nCommand (en)\nCommand (kk)\n#… See the full description on the dataset page: https://huggingface.co/datasets/issai/kazakh-speech-commands.","first_N":5,"first_N_keywords":["audio-classification","Kazakh","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"zeroth-STT-Ko","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\n\t\n\t\t\n\t\tZeroth-STT-Ko Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset combines the following publicly available Korean language datasets:\nJunhoee/STT_Korean_Dataset_80000\nand\nZeroth-Korean Dataset (from Project: Zeroth, by GoodAtlas and Gridspace)\nThis provides over 102K rows of data (sentences) in total.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0… See the full description on the dataset page: https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"jacob-common-voice-19-zh-TW-curated","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jacob-common-voice-19-zh-TW-curated","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/jacob-common-voice-19-zh-TW-curated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chinese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jacob-common-voice-19-zh-TW-curated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jacob-common-voice-19-zh-TW-curated","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/jacob-common-voice-19-zh-TW-curated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chinese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset 🎤\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\t📊 Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset 🎤\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\t📊 Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset 🎤\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\t📊 Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset 🎤\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\t📊 Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"uzlib","keyword":"linguistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tahrirchi/uzlib","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","description":"\n\t\n\t\t\n\t\tUzbek Linguistic Benchmark (UzLiB)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nUzLiB (Uzbek Linguistic Benchmark) is the first comprehensive multiple-choice question benchmark designed to evaluate the linguistic understanding and capabilities of Large Language Models (LLMs) in the Uzbek language. It assesses how well models grasp correct Uzbek forms, usage, meanings, and contextual nuances.\nFor more detailed background on the motivation, creation process, and initial findings, please refer to… See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uzlib.","first_N":5,"first_N_keywords":["question-answering","Uzbek","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"rel_dataset","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m522t/rel_dataset","creator_name":"Mehrshad Taji","creator_url":"https://huggingface.co/m522t","description":"m522t/rel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mls-annotated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of non English MLS\n\t\n\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.… See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Portuguese"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large… See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large… See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large… See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"MRC-psycholinguistic-database","keyword":"linguistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StephanAkkerman/MRC-psycholinguistic-database","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\n\t\n\t\t\n\t\tMRC Psycholinguistic Database\n\t\n\nThis is the complete MRC psycholinguistic database as found on https://websites.psychology.uwa.edu.au/school/mrcdatabase/uwa_mrc.htm.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is ideal for training and evaluating machine learning models for English word concreteness.\n\n\t\n\t\t\n\t\tAcknowledgments\n\t\n\nWe extend our heartfelt gratitude to all the authors of the original dataset.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the MIT license.\n","first_N":5,"first_N_keywords":["text-classification","English","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered-annotated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and annotated CML TTS\n\t\n\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The… See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"synthetic_dem","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/synthetic_dem","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for synthetic_dem\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Synthetic DEM Corpus is the result of the first phase of a collaboration between El Colegio de México (COLMEX) and the Barcelona Supercomputing Center (BSC).\nIt all began when COLMEX was looking for a way to have its Diccionario del Español de México (DEM), which can be accessed online, include the option to play each of its words with a Mexican accent through synthetic speech files. On the other hand, BSC is always on… See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/synthetic_dem.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"synthetic_dem","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/synthetic_dem","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for synthetic_dem\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Synthetic DEM Corpus is the result of the first phase of a collaboration between El Colegio de México (COLMEX) and the Barcelona Supercomputing Center (BSC).\nIt all began when COLMEX was looking for a way to have its Diccionario del Español de México (DEM), which can be accessed online, include the option to play each of its words with a Mexican accent through synthetic speech files. On the other hand, BSC is always on… See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/synthetic_dem.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"JA_audio_JA_text_180k_samples","keyword":"automatic-speech-recognition","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":"","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Japanese"],"keywords_longer_than_N":true},
	{"name":"JA_audio_JA_text_180k_samples","keyword":"text-to-speech","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":"","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Japanese"],"keywords_longer_than_N":true},
	{"name":"TV-44kHz-Full","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full","creator_name":"Thorsten Müller","creator_url":"https://huggingface.co/Thorsten-Voice","description":"\n\t\n\t\t\n\t\tThe \"Thorsten-Voice\" dataset\n\t\n\nThis truly open source (CC0 license) german (🇩🇪) voice dataset contains about 40 hours of transcribed voice recordings by Thorsten Müller, \na single male, native speaker in over 38.000 wave files.\n\nMono\nSamplerate: 44.100Hz\nTrimmed silence at begin/end\nDenoised\nNormalized to -24dB\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\n\"Please keep in mind, I am not a professional speaker, just an open source speech technology enthusiast who donates his voice. I contribute my personal… See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","German","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"indicvoices_pa_tagged_transcripts","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_pa_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information… See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"indicvoices_mr_tagged_transcripts","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_mr_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information… See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"indicvoices_bn_tagged_transcripts","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_bn_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information… See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Theresa","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"linguistics","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from… See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"KikuyuASR_trainingdataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DigiGreen/KikuyuASR_trainingdataset","creator_name":"Digital Green","creator_url":"https://huggingface.co/DigiGreen","description":"This dataset is obtained as part of AIEP prject by Digital Green and Karya from the extension workers, lead farmers and farmers.\nProcess of collection of data:\nSelected users were given the option of doing a task and getting paid for it.\nThe users were supposed to record the sentence as it appeared on the screen.\nThe audio file thus obtained was validated matched with the sentences to fine tune the model.\nAlso available are the python script that helps in processing and splitting the data into… See the full description on the dataset page: https://huggingface.co/datasets/DigiGreen/KikuyuASR_trainingdataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kikuyu","apache-2.0","10K<n<100K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"Theresa-Recording","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa-Recording","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa-Recording dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Japanese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"anta_women_tts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galsenai/anta_women_tts","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","description":"\n\t\n\t\t\n\t\tAnta Women TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a cleaned version of the Wolof TTS dataset by GalsenAI. \nWe extracted the female voice, denoised it and enhanced it with the Resemble Enhance library. \nWe also cleaned up the annotations by removing special characters, emojis, Arabic and Russian characters. \nWe've corrected a few annotation errors, but there are potentially many more to come. \nSome lines and audios judged not qualitative enough have been removed from the dataset… See the full description on the dataset page: https://huggingface.co/datasets/galsenai/anta_women_tts.","first_N":5,"first_N_keywords":["text-to-speech","Wolof","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"wolof-audio-data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galsenai/wolof-audio-data","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","description":"\n\t\n\t\t\n\t\tWolof Audio Dataset\n\t\n\nThe Wolof Audio Dataset is a collection of audio recordings and their corresponding transcriptions in Wolof. This dataset is designed to support the development of Automatic Speech Recognition (ASR) models for the Wolof language. It was created by combining four existing datasets:\n\nALFFA: Available at serge-wilson/wolof_speech_transcription\nFLEURS: Available at vonewman/fleurs-wolof-dataset\nUrban Bus Wolof Speech Dataset: Available at vonewman/urban-bus-wolof… See the full description on the dataset page: https://huggingface.co/datasets/galsenai/wolof-audio-data.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Wolof","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"CanaryAura","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nkazi/CanaryAura","creator_name":"Nazmul Kazi","creator_url":"https://huggingface.co/nkazi","description":"\n\t\n\t\t\n\t\tDataset Card for \"Canary Aura\"\n\t\n\nThis is a dataset for...\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Bengali","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tBengali Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Bengali monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Bengali\nTotal Duration: ~15.06 hours (Male: 10.05 hours, Female: 5.01 hours)\nAudio Format: WAV\nSampling Rate:… See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali.","first_N":5,"first_N_keywords":["text-to-speech","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"KikuyuASR_trainingdataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CGIAR/KikuyuASR_trainingdataset","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","description":"This dataset is obtained as part of AIEP prject by Digital Green and Karya from the extension workers, lead farmers and farmers.\nProcess of collection of data:\nSelected users were given the option of doing a task and getting paid for it.\nThe users were supposed to record the sentence as it appeared on the screen.\nThe audio file thus obtained was validated matched with the sentences to fine tune the model.\nAlso available are the python script that helps in processing and splitting the data into… See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/KikuyuASR_trainingdataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kikuyu","apache-2.0","10K<n<100K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"emova-sft-4m","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-4m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-4M\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-4M is a comprehensive dataset curated for omni-modal instruction tuning, including textual, visual, and audio interactions. This dataset is created by gathering open-sourced multi-modal instruction datasets and synthesizing high-quality omni-modal conversation data to enhance user experience. This dataset is… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-4m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"emova-sft-4m","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-4m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-4M\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-4M is a comprehensive dataset curated for omni-modal instruction tuning, including textual, visual, and audio interactions. This dataset is created by gathering open-sourced multi-modal instruction datasets and synthesizing high-quality omni-modal conversation data to enhance user experience. This dataset is… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-4m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DrAliGomaa/arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech","creator_name":"arabic_speech","creator_url":"https://huggingface.co/DrAliGomaa","description":"\n\t\n\t\t\n\t\tDataset Card for quran and hadith dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nArabic specialized dataset to make sure that AI is not changing our sacred scriptures in speech recognition by training and evaluating upon quran and hadith.\n\nCombining quran + magma'a el zawa'ed book of sidi Nour eldin elhaithamy author including 14 book of hadith of approximately 10,000 hadith without repititions + other existing datasets like common voice, fleurs, media speech\n\nFirst dataset to have full… See the full description on the dataset page: https://huggingface.co/datasets/DrAliGomaa/arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Rosmontis","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Chinese","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"cretan-speech-corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ilsp/cretan-speech-corpus","creator_name":"Institute for Language and Speech Processing","creator_url":"https://huggingface.co/ilsp","description":"Cretan is a variety of Modern Greek predominantly used by\nspeakers who reside on the island of Crete or belong to the Cretan\ndiaspora. This includes communities of Cretan origin that were\nrelocated to the village of Hamidieh in Syria and to Western\nAsia Minor, following the population exchange between Greece\nand Turkey in 1923. The historical and geographical factors\nthat have shaped the development and preservation of the dialect\ninclude the long-term isolation of Crete from the mainland, and… See the full description on the dataset page: https://huggingface.co/datasets/ilsp/cretan-speech-corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"alphanumeric-audio-dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset","creator_name":"Sakshee Patil","creator_url":"https://huggingface.co/sakshee05","description":"\n\t\n\t\t\n\t\tSpeech Recognition Bias Reduction Project\n\t\n\n\n\t\n\t\t\n\t\tExecutive Summary\n\t\n\nWelcome to the Speech Recognition Bias Reduction Project. It aims to create a more inclusive and representative dataset for improving automated speech recognition systems. This project addresses the challenges faced by speakers with non-native English accents, particularly when interacting with automated voice systems that struggle to interpret alphanumeric information such as names, phone numbers, and addresses.… See the full description on the dataset page: https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"piper_italiano","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kirys79/piper_italiano","creator_name":"Federico Improta","creator_url":"https://huggingface.co/kirys79","description":"\n\t\n\t\t\n\t\tPiper Italiano\n\t\n\nSto cercando di creare un nuovo checkpoint per PiperTTS in italiano.\nLa fonte per il traine è il Multilingual LibriSpeech (MLS) rilasciato sotto licenza Creative Commons\nQui metterò i dataset estratti dal suddetto blocco dati\nIl dataset è nel formato che gradisce PiperTTS come indicato a questo link\n\nAurora è lo speaker 6807\nLeonardo è lo speaker 1595 - Probabile voce di Riccardo (modello originale di piper) ma ad una maggiore qualità\n\n","first_N":5,"first_N_keywords":["text-to-speech","Italian","cc-by-4.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"2M-Belebele","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"2M-Flores-ASL","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Flores-ASL","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Flores\n\t\n\nAs part of the 2M-Belebele project, we have produced video recodings of ASL signing for all the dev and devtest \nsentences in the original flores200 dataset.\nTo obtain ASL sign recordings, we provide translators of ASL and native signers with the English text version of the sentences to be recorded.\nThe interpreters are then asked to translate these sentences into ASL, create glosses for all sentences, and record their interpretations into ASL one sentence at a time. \nThe… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Flores-ASL.","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","American Sign Language","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-eval","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-Eval\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-Eval is an evaluation dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-Eval is part of EMOVA-Datasets collection, and the training… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-eval","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-Eval\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-Eval is an evaluation dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-Eval is part of EMOVA-Datasets collection, and the training… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikitongues-darija","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/wikitongues-darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"\n\t\n\t\t\n\t\tWikitongues-Darija\n\t\n\nThis is a small test dataset for Automatic Speech Recognition in Darija language, built from 2 captioned videos of the WikiTongues project:\n\nnawal\nanass\n\nProcess:\n\neach webm video has been converted to monochannel 16khz wav files with ffmpeg :\n\nffmpeg -i WIKITONGUES-_Nawal_speaking_Moroccan_Arabic.webm.1080p.vp9.webm -ar 16000 -ac 1 nawal.wav\n\n\neach audio has been cut in samples of less than 30 seconds audio according to the captions timestamps. The script may be… See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/wikitongues-darija.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc-by-sa-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Google_Myanmar_ASR","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/Google_Myanmar_ASR","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tGoogle Myanmar ASR Dataset\n\t\n\nThis dataset is a processed and organized version of the original OpenSLR-80 Burmese Speech Corpus. It has been carefully structured for ASR tasks with additional preprocessing steps to enhance usability and consistency.\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Google Myanmar ASR Dataset is based on the Burmese Speech Corpus, originally published by Google. It consists of audio files and their corresponding transcriptions. The dataset is primarily aimed at… See the full description on the dataset page: https://huggingface.co/datasets/freococo/Google_Myanmar_ASR.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-generation","Burmese","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Google_Myanmar_ASR","keyword":"speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/Google_Myanmar_ASR","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tGoogle Myanmar ASR Dataset\n\t\n\nThis dataset is a processed and organized version of the original OpenSLR-80 Burmese Speech Corpus. It has been carefully structured for ASR tasks with additional preprocessing steps to enhance usability and consistency.\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Google Myanmar ASR Dataset is based on the Burmese Speech Corpus, originally published by Google. It consists of audio files and their corresponding transcriptions. The dataset is primarily aimed at… See the full description on the dataset page: https://huggingface.co/datasets/freococo/Google_Myanmar_ASR.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-generation","Burmese","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"UrduRomanSentimentClassification","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  UrduRomanSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Roman Urdu dataset is a data corpus comprising of more than 20000 records tagged for sentiment (Positive, Negative, Neutral)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://archive.ics.uci.edu/dataset/458/roman+urdu+data+set\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"english-tts-eval","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ntt123/english-tts-eval","creator_name":"Thông Nguyễn","creator_url":"https://huggingface.co/ntt123","description":"\n\t\n\t\t\n\t\tEnglish Text-to-Speech Evaluation Dataset\n\t\n\nThe english-tts-eval dataset evaluates the performance of Text-to-Speech (TTS) systems. It includes a diverse collection of English text samples covering a wide range of use cases, such as news updates, navigation assistance, customer service, and storytelling.\nThere are 100 examples, each of which includes:\n\nText: The original text sample.\nNormalized Text: The spoken form of the text, with numbers and abbreviations expanded.\nCategory: The… See the full description on the dataset page: https://huggingface.co/datasets/ntt123/english-tts-eval.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"French_Grammar_Explanations","keyword":"grammar","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sufi2425/French_Grammar_Explanations","creator_name":"Sufian \"CreativeAlloy\"","creator_url":"https://huggingface.co/Sufi2425","description":"\nThis dataset contains 1500+ French grammar explanations. It's the one I used to train my finetuned LLM called FrenchLlama-3.2-1B-Instruct.\nYou can use this dataset for your own training purposes & find the aforementioned model on my HuggingFace profile.\n","first_N":5,"first_N_keywords":["question-answering","text-generation","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"semi-Voxpopuli","keyword":"speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli","creator_name":"Jagadeesh Rachapudi","creator_url":"https://huggingface.co/Jagadeesh9580","description":"\n\t\n\t\t\n\t\tVoxPopuli Multilingual Audio Dataset\n\t\n\nThis dataset contains audio recordings in English (EN), Polish (PL), and Swedish (SV) languages. It is derived from the VoxPopuli dataset and tailored for multilingual language processing tasks.\nThe dataset includes audio clips and corresponding metadata to support research and development in multilingual audio processing.\n\n\t\n\t\t\n\t\tDataset Files\n\t\n\nThe dataset includes the following files:\n\ndata.csv: Contains metadata about the audio files… See the full description on the dataset page: https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"STT_uz","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/STT_uz","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"The dataset is organized into the following directories and files:\naudio/\nother/: Contains .tar archives like uz_other_0.taruz_other_1.tar\ntrain/: Contains .tar archives like uz_train_0.tar.\nvalidated/: Contains .tar archives like uz_validated_0.tar, uz_validated_1.tar, and uz_validated_2.tar.\ntest/: Contains individual .wav files.\ntranscription/: Contains .tsv files including:\nother.tsv\ntrain.tsv\nvalidated.tsv\ntest.tsv\nThe .tsv files have two columns: file_name and transcription. Each entry… See the full description on the dataset page: https://huggingface.co/datasets/Beehzod/STT_uz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"uzbek_stt_data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uzbek_stt_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uzbek_stt_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"yogera_runyankore_ailab_4_0_1","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shawal777/yogera_runyankore_ailab_4_0_1","creator_name":"Shawal Mbalire","creator_url":"https://huggingface.co/Shawal777","description":"Shawal777/yogera_runyankore_ailab_4_0_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","image-to-text","Nyankole","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"wolof_tts","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galsenai/wolof_tts","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","description":"\n\t\n\t\t\n\t\tWolof TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a Wolof Text To Speech (TTS) dataset collected by Baamtu Datamation as part of the AI4D African language program. \nThe original dataset is hosted on Zenodo and it contains recordings from two (02) natif Wolof speakers (a male and female voice). Each speaker recored more than 20,000 sentences.\n\n\t\n\t\t\n\t\n\t\n\t\tSpeaking time:\n\t\n\n-- Male: 22h 28mn 41s\n-- Female: 18h 47mn 19s\n\nThe text dataset comes from news websites, Wikipedia and self… See the full description on the dataset page: https://huggingface.co/datasets/galsenai/wolof_tts.","first_N":5,"first_N_keywords":["text-to-speech","Wolof","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"vietnam-normalize-24k","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thanhkt/vietnam-normalize-24k","creator_name":"Tran Khanh Thanh","creator_url":"https://huggingface.co/thanhkt","description":"thanhkt/vietnam-normalize-24k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-to-speech","summarization","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"bot_stt","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/bot_stt","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/bot_stt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"kenyan_national_parks","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gikebe/kenyan_national_parks","creator_name":"Elizabeth Gikebe","creator_url":"https://huggingface.co/gikebe","description":"gikebe/kenyan_national_parks dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"GPTInformal-Persian","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MahtaFetrat/GPTInformal-Persian","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","description":"\n\t\n\t\t\n\t\tGPTInformal Persian\n\t\n\n\nGPTInformal Persian is a Persian dataset of 6+ hours of audio and text pairs designed for speech synthesis and other speech-related tasks. The dataset has been collected, processed, and annotated as a part of the Mana-TTS project. For details on data processing pipeline and statistics, please refer to the paper in the Citation secition.\n\n\t\n\t\t\n\t\n\t\n\t\tData Source\n\t\n\nThe text for this dataset was generated using GPT4o, with prompts covering a wide range of subjects… See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/GPTInformal-Persian.","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Obama-Sample-Dataset","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ModelsLab/Obama-Sample-Dataset","creator_name":"ModelsLab","creator_url":"https://huggingface.co/ModelsLab","description":"\n\n\t\n\t\t\n\t\tObama Voice Sample Dataset for RVC Training\n\t\n\nA curated dataset of Barack Obama's voice samples, specifically prepared for training Demo RVC (Retrieval-based Voice Conversion) model on ModelsLab.\n\n\t\n\t\t\n\t\tDataset Specifications\n\t\n\n\nTotal Duration: 25+ minutes\nAudio Format: WAV\nSampling Rate: 24 kHz\nContent Type: Clean speech samples from speeches and addresses\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is designed for training RVC (Retrieval-based Voice Conversion) models. The minimum recommended… See the full description on the dataset page: https://huggingface.co/datasets/ModelsLab/Obama-Sample-Dataset.","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"told-br","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/told-br","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BrazilianToxicTweetsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    ToLD-Br is the biggest dataset for toxic tweets in Brazilian Portuguese, crowdsourced by 42 annotators selected from\n    a pool of 129 volunteers. Annotators were selected aiming to create a plural group in terms of demographics (ethnicity,\n    sexual orientation, age, gender). Each tweet was labeled by three annotators in 6 possible categories: LGBTQ+phobia,\n    Xenophobia, Obscene, Insult… See the full description on the dataset page: https://huggingface.co/datasets/mteb/told-br.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"common_voice_19_0_zh-TW","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/common_voice_19_0_zh-TW","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\n\t\n\t\t\n\t\tCommon Voice Corpus 19.0 Chinese (Taiwan)\n\t\n\nThe test set is the same as the original test set, while validated_without_test includes all validated examples except those with sentence IDs that appear in the test set.\n\nvalidated_without_test has about 50,000 examples in total, equivalent to approximately 44 hours, and is intended for use as the training set.\ntest has about 5,000 examples, which is approximately 5 hours.\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and merges… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and merges… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"BERSt","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rosie-Lab/BERSt","creator_name":"SFU Robots with Social Intelligence and Empathy Lab","creator_url":"https://huggingface.co/Rosie-Lab","description":"\n\t\n\t\t\n\t\tBERSt Dataset\n\t\n\nWe release the BERSt Dataset for various speech recognition tasks including Automatic Speech Recognition (ASR) and Speech Emotion Recogniton (SER)\nRead the paper here\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n4526 single phrase recordings (~3.75h)\n98 professional actors\n19 phone positions\n7 emotion classes\n3 vocal intensity levels\nvaried regional and non-native English accents\nnonsense phrases covering all English Phonemes\n\n\n\t\n\t\t\n\t\tData collection\n\t\n\nThe BERSt dataset represents data… See the full description on the dataset page: https://huggingface.co/datasets/Rosie-Lab/BERSt.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jeli-asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"jeli-asr","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"ai-gospel-music-dictionaries","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries","creator_name":"Cruz Macias","creator_url":"https://huggingface.co/cmathhug","description":"\n\t\n\t\t\n\t\tAI Gospel Music Dictionaries\n\t\n\nA comprehensive collection of JSON dictionaries designed to support AI-powered gospel music and lyrics generation, with a focus on biblical and theological content.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a curated set of dictionaries that can be used for:\n\nMusic generation tasks\nLyrics generation with biblical themes\nInstrument and genre specifications\nBiblical reference materials\n\n\n\t\n\t\t\n\t\tDictionaries\n\t\n\n\n\t\n\t\t\n\t\tBiblical Content… See the full description on the dataset page: https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","cc0-1.0","n<1K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"SIWIS_French_Speech_Synthesis_Database","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database","creator_name":"Anthonny Olime","creator_url":"https://huggingface.co/Aviv-anthonnyolime","description":"\n\t\n\t\t\n\t\tSIWIS French Speech Synthesis Database\n\t\n\nThis README provides a concise description of the dataset, including its structure, file naming conventions, and known labeling issues. Additionally, suggestions for potential improvements are outlined in the TODO section.  \nThe dataset is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting its use for any purpose.  \nFor more details about the database design and recording process, please refer… See the full description on the dataset page: https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","French","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SIWIS_French_Speech_Synthesis_Database","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database","creator_name":"Anthonny Olime","creator_url":"https://huggingface.co/Aviv-anthonnyolime","description":"\n\t\n\t\t\n\t\tSIWIS French Speech Synthesis Database\n\t\n\nThis README provides a concise description of the dataset, including its structure, file naming conventions, and known labeling issues. Additionally, suggestions for potential improvements are outlined in the TODO section.  \nThe dataset is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting its use for any purpose.  \nFor more details about the database design and recording process, please refer… See the full description on the dataset page: https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","French","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Kore-Voice","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Kore-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Kore-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"dataset_for_STT_TTSmodels","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/dataset_for_STT_TTSmodels","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/dataset_for_STT_TTSmodels dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"soomali-asr-dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skydheere/soomali-asr-dataset","creator_name":"imran adam ","creator_url":"https://huggingface.co/skydheere","description":"\n\t\n\t\t\n\t\tSomali ASR Dataset\n\t\n\nThis dataset contains audio recordings and corresponding transcriptions in Somali, designed for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Somali (so)\nSize: 10K - 100K samples\nFormat: Parquet\nModalities: Audio + Text\nLicense: CC-BY 4.0\nTask: Automatic Speech Recognition\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used to train and evaluate ASR models for the Somali language. It is particularly helpful for developing speech… See the full description on the dataset page: https://huggingface.co/datasets/skydheere/soomali-asr-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Somali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"kokoro-82M-voices","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ecyht2/kokoro-82M-voices","creator_name":"ecyht2","creator_url":"https://huggingface.co/ecyht2","description":"\n\t\n\t\t\n\t\tKokoro-82M Voices\n\t\n\nThis dataset contains all the voices available in hexgrad/Kokoro-82M.\nThis dataset provides the voices in 3 different formats.\n\nIndividual voices embeddings in different JSON file\nSingle JSON which contains all the voices in a JSON object.\nParquet format for usage via datasets\nThe voices name is the same as the .pth file names shown below.\n\nvoices = [\n    \"af\",\n    \"af_bella\",\n    \"af_nicole\",\n    \"af_sarah\",\n    \"af_sky\",\n    \"am_adam\",\n    \"am_michael\"… See the full description on the dataset page: https://huggingface.co/datasets/ecyht2/kokoro-82M-voices.","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"gemini-flash-2.0-speech","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"\n\t\n\t\t\n\t\t🎙️ Gemini Flash 2.0 Speech Dataset\n\t\n\n\nThis is a high quality synthetic speech dataset generated by Gemini Flash 2.0 via the Multimodel Live API. It contains speech from 2 speakers - Puck (Male) and Kore (Female) in English.\n\n\t\n\t\t\n\t\n\t\n\t\t〽️ Stats\n\t\n\nTotal number of audio files: 47,256*2 = 94512Total duration: 1023527.20 seconds (284.31 hours)   \nAverage duration: 10.83 seconds   \nShortest file: 0.6 secondsLongest file: 92.12 seconds   \n\n\n\n\t\n\t\t\n\t\t🧩 Data Composition\n\t\n\nThe text in the… See the full description on the dataset page: https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"gemini-flash-2.0-speech","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"\n\t\n\t\t\n\t\t🎙️ Gemini Flash 2.0 Speech Dataset\n\t\n\n\nThis is a high quality synthetic speech dataset generated by Gemini Flash 2.0 via the Multimodel Live API. It contains speech from 2 speakers - Puck (Male) and Kore (Female) in English.\n\n\t\n\t\t\n\t\n\t\n\t\t〽️ Stats\n\t\n\nTotal number of audio files: 47,256*2 = 94512Total duration: 1023527.20 seconds (284.31 hours)   \nAverage duration: 10.83 seconds   \nShortest file: 0.6 secondsLongest file: 92.12 seconds   \n\n\n\n\t\n\t\t\n\t\t🧩 Data Composition\n\t\n\nThe text in the… See the full description on the dataset page: https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Uzbek_Speech_Corpus","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tUzbek Speech Corpus (USC)\n\t\n\nPaper: USC: An Open-Source Uzbek Speech Corpus and Initial Speech Recognition Experiments\nSummary: This repository contains dataset for reproducing the results presented in the paper \"USC: An Open-Source Uzbek Speech Corpus\". USC is a freely available, manually checked speech corpus comprising 958 speakers and 105 hours of transcribed audio recordings. \nDataset Summary:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nLanguage\nUzbek\n\n\nSize\n105 hours of audio\n\n\nNumber of… See the full description on the dataset page: https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","Audio","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"Uzbek_Speech_Corpus","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tUzbek Speech Corpus (USC)\n\t\n\nPaper: USC: An Open-Source Uzbek Speech Corpus and Initial Speech Recognition Experiments\nSummary: This repository contains dataset for reproducing the results presented in the paper \"USC: An Open-Source Uzbek Speech Corpus\". USC is a freely available, manually checked speech corpus comprising 958 speakers and 105 hours of transcribed audio recordings. \nDataset Summary:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nLanguage\nUzbek\n\n\nSize\n105 hours of audio\n\n\nNumber of… See the full description on the dataset page: https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","Audio","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"Multilingual_Speech_Dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tMultilingual Speech Dataset\n\t\n\nPaper: A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\nRepository: https://github.com/IS2AI/MultilingualASR\nDescription: This repository provides the dataset used in the paper \"A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\". The paper focuses on training a single end-to-end (E2E) ASR model for Kazakh, Russian, and English, comparing monolingual and multilingual approaches… See the full description on the dataset page: https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","Russian","English","mit"],"keywords_longer_than_N":true},
	{"name":"Multilingual_Speech_Dataset","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tMultilingual Speech Dataset\n\t\n\nPaper: A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\nRepository: https://github.com/IS2AI/MultilingualASR\nDescription: This repository provides the dataset used in the paper \"A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\". The paper focuses on training a single end-to-end (E2E) ASR model for Kazakh, Russian, and English, comparing monolingual and multilingual approaches… See the full description on the dataset page: https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","Russian","English","mit"],"keywords_longer_than_N":true},
	{"name":"Kazakh_Speech_Corpus_2","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tKazakh Speech Corpus 2 (KSC2)\n\t\n\nThis dataset card describes the KSC2, an industrial-scale, open-source speech corpus for the Kazakh language.\nPaper: KSC2: An Industrial-Scale Open-Source Kazakh Speech Corpus\nSummary: KSC2 corpus subsumes the previously introduced two corpora: Kazakh Speech Corpus and Kazakh Text-To-Speech 2, and supplements additional data from other sources like tv programs, radio, senate, and podcasts. In total, KSC2 contains around 1.2k hours of high-quality… See the full description on the dataset page: https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","mit","Audio","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"Kazakh_Speech_Corpus_2","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\n\t\n\t\t\n\t\tKazakh Speech Corpus 2 (KSC2)\n\t\n\nThis dataset card describes the KSC2, an industrial-scale, open-source speech corpus for the Kazakh language.\nPaper: KSC2: An Industrial-Scale Open-Source Kazakh Speech Corpus\nSummary: KSC2 corpus subsumes the previously introduced two corpora: Kazakh Speech Corpus and Kazakh Text-To-Speech 2, and supplements additional data from other sources like tv programs, radio, senate, and podcasts. In total, KSC2 contains around 1.2k hours of high-quality… See the full description on the dataset page: https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","mit","Audio","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"jl-speech","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jl-speech","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\n\t\n\t\t\n\t\tJL Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJL Speech is a male voice version of the LJ Speech dataset. It contains 13,100 short audio clips of a single speaker reading passages from books. The total audio duration is approximately 24 hours, with audio quality improved to 48 kHz sampling rate.\nThis dataset is licensed under the CC-BY-4.0 License.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tCreation\n\t\n\nThe JL Speech dataset was created by converting the original LJ Speech dataset to a male… See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/jl-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"jl-speech","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jl-speech","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\n\t\n\t\t\n\t\tJL Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJL Speech is a male voice version of the LJ Speech dataset. It contains 13,100 short audio clips of a single speaker reading passages from books. The total audio duration is approximately 24 hours, with audio quality improved to 48 kHz sampling rate.\nThis dataset is licensed under the CC-BY-4.0 License.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tCreation\n\t\n\nThe JL Speech dataset was created by converting the original LJ Speech dataset to a male… See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/jl-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Zeroth-STT-Korean","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/o0dimplz0o/Zeroth-STT-Korean","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\n\t\n\t\t\n\t\tZeroth-STT-Korean Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a shuffled version of the Zeroth-STT-Ko dataset.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0 license.\nJunhoee/STT_Korean_Dataset_80000 Dataset, created by [Junhoee], 2024.\nAvailable at https://huggingface.co/datasets/Junhoee/STT_Korean_Dataset_80000\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"virc","keyword":"hate-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/oeg/virc","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","description":"\n\t\n\t\t\n\t\tVulnerable Identities Recognition Corpus (VIRC) for Hate Speech Analysis\n\t\n\nWelcome to the Vulnerable Identities Recognition Corpus (VIRC), a dataset created to enhance hate speech analysis in Italian and Spanish news headlines. VIRC provides annotated headlines aimed at identifying vulnerable identities, dangerous discourse, derogatory mentions, and entities. This corpus contributes to developing more sophisticated hate speech detection tools and policies for creating a safer online… See the full description on the dataset page: https://huggingface.co/datasets/oeg/virc.","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","text-classification","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"uzbek-speech-corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murodbek/uzbek-speech-corpus","creator_name":"Abror Shopulatov","creator_url":"https://huggingface.co/murodbek","description":"\n\t\n\t\t\n\t\tUzbek Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Uzbek speech corpus (USC) has been developed in collaboration between ISSAI and the Image and Speech Processing Laboratory in the Department of Computer Systems of the Tashkent University of Information Technologies. The USC comprises 958 different speakers with a total of 105 hours of transcribed audio recordings. To ensure high quality, the USC has been manually checked by native speakers. The USC is primarily designed for… See the full description on the dataset page: https://huggingface.co/datasets/murodbek/uzbek-speech-corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-test2","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deniskaanalpay/tts-test2","creator_name":"denis kaan alpay","creator_url":"https://huggingface.co/deniskaanalpay","description":"deniskaanalpay/tts-test2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Turkish","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Telugu-NLP-AI-Dialect-Comedy-video-Dataset","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Automation-Tribe/Telugu-NLP-AI-Dialect-Comedy-video-Dataset","creator_name":"AUTTRIBE-AI-AUTOMATION","creator_url":"https://huggingface.co/Automation-Tribe","description":"Telugu is one of the sweetest and oldest languages of India. A deep Dive into Telugu its spoken in 2 states and majorly 16 regional dailects.\nThis Dataset help you perform operations in NLP and Speech Recognition Models towards telugu Dialects.\n","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Telugu","Kannada","English"],"keywords_longer_than_N":true},
	{"name":"PhonemeFakeV2","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phonemefake/PhonemeFakeV2","creator_name":"PhonemeFake Dataset","creator_url":"https://huggingface.co/phonemefake","description":"\n\t\n\t\t\n\t\tPhonemeFake -  A Phonetic Deepfake Dataset\n\t\n\n\n\nWe introduce PhonemeFake, a DF attack that manipulates critical speech segments using language reasoning, significantly reducing human perception and SoTA\nmodel accuracies.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nWe provide example spoof audio in the viewers tab along with the transcription of the bonafide sample, the manipulated transcription and the audio timings for a small set of the data.\nThe dataset is split into three subsets. The spoof samples… See the full description on the dataset page: https://huggingface.co/datasets/phonemefake/PhonemeFakeV2.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"kinh-phap-hoa-ke-trom-huong","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"Normalized using https://github.com/oysterlanguage/emiliapipex\n@article{emilia,\n      title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},\n      author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},\n      journal={arXiv},\n      volume={abs/2407.05361}… See the full description on the dataset page: https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"kinh-phap-hoa-ke-trom-huong","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","description":"Normalized using https://github.com/oysterlanguage/emiliapipex\n@article{emilia,\n      title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},\n      author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},\n      journal={arXiv},\n      volume={abs/2407.05361}… See the full description on the dataset page: https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong.","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"KoGEM","keyword":"grammar","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Poppo/KoGEM","creator_name":"SungHo Kim","creator_url":"https://huggingface.co/Poppo","description":"\n\t\n\t\t\n\t\tDataset Card for KoGEM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nKoGEM is a benchmark designed to assess Korean linguistic competence in both large language models (LLMs) and humans through 1.5k multiple-choice questions covering five main linguistic categories with 16 subcategories. Refer to the [not yet](not yet) for more details.\n\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\n# pip install -q datasets\nfrom datasets import load_dataset\ndataset = load_dataset(\"Poppo/KoGEM\")[\"test\"]\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example… See the full description on the dataset page: https://huggingface.co/datasets/Poppo/KoGEM.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","Korean","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MultiMed-ST","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leduckhai/MultiMed-ST","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","description":"\n\t\n\t\t\n\t\tMultiMed-ST: Large-scale Many-to-many Multilingual Medical Speech Translation\n\t\n\nPreprint\nKhai Le-Duc*, Tuyen Tran*,\nBach Phan Tat, Nguyen Kim Hai Bui, Quan Dang, Hung-Phong Tran, Thanh-Thuy Nguyen, Ly Nguyen, Tuan-Minh Phan, Thi Thu Phuong Tran, Chris Ngo,\nNguyen X. Khanh**, Thanh Nguyen-Tang**\n\n\n*Equal contribution\n**Equal supervision\n\n\nAbstract:\nMultilingual speech translation (ST) in the medical domain  enhances patient care by enabling efficient communication across language… See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/MultiMed-ST.","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","Vietnamese","English","German"],"keywords_longer_than_N":true},
	{"name":"opentts-uk-aesthetics","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\n\t\n\t\t\n\t\tAesthetics of Open Text-to-Speech for 🇺🇦 Ukrainian dataset\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis dataset contains metrics for https://huggingface.co/datasets/Yehor/opentts-uk dataset retrieved by https://github.com/facebookresearch/audiobox-aesthetics \n\n\t\n\t\t\n\t\tHow metrics calculated?\n\t\n\nYou can find a… See the full description on the dataset page: https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics.","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"myanmar-written-corpus","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/myanmar-written-corpus","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tMyanmar Written Corpus\n\t\n\nThe Myanmar Written Corpus is a comprehensive collection of high-quality, but not fully CLEAN, written Myanmar text, designed to address the lack of large-scale, openly accessible resources for Myanmar Natural Language Processing (NLP). It is tailored to support various tasks such as text-to-speech (TTS), automatic speech recognition (ASR), translation, text generation, and more.\nThis dataset serves as a critical resource for researchers and developers aiming… See the full description on the dataset page: https://huggingface.co/datasets/freococo/myanmar-written-corpus.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-speech","Burmese","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"gahd","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jagoldz/gahd","creator_name":"Janis Goldzycher","creator_url":"https://huggingface.co/jagoldz","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for GAHD\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nGAHD is a German Adversarial Hate speech Dataset containing 10,996 examples. We collected the dataset via four rounds of Dynamic Adversarial Data Collection and explored various methods of supporting annotators in finding adversarial examples.\n\nPaper: https://aclanthology.org/2024.naacl-long.248/\nRepository: https://github.com/jagol/gahd\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\ngahd.csv contains the following columns:\n\ngahd_id:… See the full description on the dataset page: https://huggingface.co/datasets/jagoldz/gahd.","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","10K<n<100K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"gahd","keyword":"hate-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jagoldz/gahd","creator_name":"Janis Goldzycher","creator_url":"https://huggingface.co/jagoldz","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for GAHD\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nGAHD is a German Adversarial Hate speech Dataset containing 10,996 examples. We collected the dataset via four rounds of Dynamic Adversarial Data Collection and explored various methods of supporting annotators in finding adversarial examples.\n\nPaper: https://aclanthology.org/2024.naacl-long.248/\nRepository: https://github.com/jagol/gahd\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\ngahd.csv contains the following columns:\n\ngahd_id:… See the full description on the dataset page: https://huggingface.co/datasets/jagoldz/gahd.","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","10K<n<100K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_eu_v2.1","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1","creator_name":"Asier Herranz","creator_url":"https://huggingface.co/asierhv","description":"\n\t\n\t\t\n\t\tComposite dataset for Basque made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/eu: \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\ngttsehu/basque_parliament_1/eu: \"train_clean\" split removing some of the… See the full description on the dataset page: https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"mother_tongue_dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MothersTongue/mother_tongue_dataset","creator_name":"Patronela  Tiwaringe ","creator_url":"https://huggingface.co/MothersTongue","description":"MothersTongue/mother_tongue_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Shona","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de Mécanique des Structures et des Systèmes Couplés","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speaker… See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de Mécanique des Structures et des Systèmes Couplés","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speaker… See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"dataset-mmb-v1","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gitgato/dataset-mmb-v1","creator_name":"Git Porter","creator_url":"https://huggingface.co/gitgato","description":"\n\t\n\t\t\n\t\tmabama-v6-audio Dataset\n\t\n\nEste dataset, mabama-v6-audio, está diseñado para tareas de text-to-speech (TTS) y contiene grabaciones de audio junto con sus correspondientes transcripciones en español. Está dividido en tres partes: entrenamiento, prueba y validación, permitiendo un desarrollo y evaluación efectivos de modelos TTS.\n\n\t\n\t\t\n\t\tEstructura del Dataset\n\t\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nfile_name: Nombre del archivo de audio.\ntext: Transcripción del audio.\nspeaker_id: Identificador del… See the full description on the dataset page: https://huggingface.co/datasets/gitgato/dataset-mmb-v1.","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ESLTTS","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/ESLTTS","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tESLTTS\n\t\n\nThe full paper can be accessed here: arXiv, IEEE Xplore.\n\n\t\n\t\t\n\t\tDataset Access\n\t\n\nYou can access this dataset through Huggingface or Google Driver or IEEE Dataport.\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nWith the progress made in speaker-adaptive TTS approaches, advanced approaches have shown a remarkable capacity to reproduce the speaker’s voice in the commonly used TTS datasets. However, mimicking voices characterized by substantial accents, such as non-native English speakers, is still… See the full description on the dataset page: https://huggingface.co/datasets/MushanW/ESLTTS.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","English"],"keywords_longer_than_N":true},
	{"name":"swerec_classification","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/swerec_classification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SweRecClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Swedish dataset for sentiment classification on review\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://aclanthology.org/2023.nodalida-1.20/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"SweRecClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)… See the full description on the dataset page: https://huggingface.co/datasets/mteb/swerec_classification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"FLEURS-GA-EN","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the Irish-to-English portion of the FLEURS dataset.\nFleurs is the speech version of the FLoRes machine translation benchmark.\nThe Irish portion consists of 3991 utterances, which correspond to approximately 16 hours and 45 minutes (16:45:17) of audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'audio', 'text_ga', 'text_en'],\n        num_rows: 3991\n    })\n})\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{fleurs2022arxiv… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"FLEURS-GA-EN","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the Irish-to-English portion of the FLEURS dataset.\nFleurs is the speech version of the FLoRes machine translation benchmark.\nThe Irish portion consists of 3991 utterances, which correspond to approximately 16 hours and 45 minutes (16:45:17) of audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'audio', 'text_ga', 'text_en'],\n        num_rows: 3991\n    })\n})\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{fleurs2022arxiv… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"mabama-v1-audio","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ovieyra21/mabama-v1-audio","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","description":"ovieyra21/mabama-v1-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","10M<n<100M","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"coral-tts","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CoRal-project/coral-tts","creator_name":"CoRal","creator_url":"https://huggingface.co/CoRal-project","description":"\n\t\n\t\t\n\t\tDataset Card for CoRal TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of two professional Danish speakers, female and male, recording roughly 17 hours of Danish speech each.\nThe dataset is part of the CoRal project which is funded by the Danish Innovation Fund.\nThe text data was selected by the Alexandra Institute (Github repo for the dataset creation) and consists of sentences from sundhed.dk, borger.dk, names of bus stops and stations, manually filtered Reddit comments, and… See the full description on the dataset page: https://huggingface.co/datasets/CoRal-project/coral-tts.","first_N":5,"first_N_keywords":["text-to-speech","Danish","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"mabama-v6-audio","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ovieyra21/mabama-v6-audio","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","description":"\n\t\n\t\t\n\t\tmabama-v6-audio Dataset\n\t\n\nEste dataset, mabama-v6-audio, está diseñado para tareas de text-to-speech (TTS) y contiene grabaciones de audio junto con sus correspondientes transcripciones en español. Está dividido en tres partes: entrenamiento, prueba y validación, permitiendo un desarrollo y evaluación efectivos de modelos TTS.\n\n\t\n\t\t\n\t\tEstructura del Dataset\n\t\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nfile_name: Nombre del archivo de audio.\ntext: Transcripción del audio.\nspeaker_id: Identificador del… See the full description on the dataset page: https://huggingface.co/datasets/ovieyra21/mabama-v6-audio.","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"parler-tts_mls_eng_10k_snac_token_old","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blanchon/parler-tts_mls_eng_10k_snac_token_old","creator_name":"Julien BLANCHON","creator_url":"https://huggingface.co/blanchon","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/blanchon/parler-tts_mls_eng_10k_snac_token_old.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"SpokenWords-GA-EN-MTed","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis is the Irish portion of the Spoken Words dataset (available at MLCommons/ml_spoken_words),\nwith merged splits “train”, “validation”, and “test”, augmented with machine translation.\nThe Irish sentences are automatically translated into English using Google Translation API.\nThe dataset includes approximately 3 hours and 2 minutes of audio (03:02:02), spoken by multiple narrators.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['keyword'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"SpokenWords-GA-EN-MTed","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis is the Irish portion of the Spoken Words dataset (available at MLCommons/ml_spoken_words),\nwith merged splits “train”, “validation”, and “test”, augmented with machine translation.\nThe Irish sentences are automatically translated into English using Google Translation API.\nThe dataset includes approximately 3 hours and 2 minutes of audio (03:02:02), spoken by multiple narrators.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['keyword'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"Living-Audio-Irish","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Living-Audio-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nLiving Audio Irish speech corpus. This version is based on the Irish dataset on Kaggle.\nThe original dataset with audio in more languages is available on GitHub as part of the Idlak project.\nThe details of the Irish portion of the Living Audio dataset are as follows:\n\n\t\n\t\t\nSpeaker\nLanguage\nAccent\nGender\nTotal duration(mm:ss)\nSample rate (Hz)\n\n\n\t\t\nCLL\nIrish (ga)\nNon-native (ie)\nMan\n61:56\n48,000\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['sentence'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Living-Audio-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Irish","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Living-Audio-Irish","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Living-Audio-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nLiving Audio Irish speech corpus. This version is based on the Irish dataset on Kaggle.\nThe original dataset with audio in more languages is available on GitHub as part of the Idlak project.\nThe details of the Irish portion of the Living Audio dataset are as follows:\n\n\t\n\t\t\nSpeaker\nLanguage\nAccent\nGender\nTotal duration(mm:ss)\nSample rate (Hz)\n\n\n\t\t\nCLL\nIrish (ga)\nNon-native (ie)\nMan\n61:56\n48,000\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['sentence'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Living-Audio-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Irish","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"tele_con_ciencia","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/tele_con_ciencia","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for tele_con_ciencia\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAccording to the Facebook page of Tele con Ciencia:\n\"Nuestra misión es la comunicación pública de la ciencia y la tecnología mexicana. El objetivo, \nla participación activa de todos los mexicanos en las áreas del descubrimiento científico y el \ndesarrollo tecnológico.\"\n\"Our mission is to spread the achievements of the Mexican Science and Technology. The main goal\nis to promote the active participation of mexican people in… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/tele_con_ciencia.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"librivox_spanish","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/librivox_spanish","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for librivox_spanish\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibrivox is a non-commercial, non-profit and ad-free project that is dedicated to make all books in the public domain available, for free, in audio format on the internet. According to this, we downloaded 300 titles in Spanish to create the LIBRIVOX SPANISH CORPUS.\nThe LIBRIVOX SPANISH CORPUS has a duration of 73 hours and it is constituted by audio files between 3 and 10 seconds long, manually segmented. Transcription are… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/librivox_spanish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"voxforge_spanish","keyword":"automatic-speech-recognition","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/voxforge_spanish","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\n\t\n\t\t\n\t\tDataset Card for voxforge_spanish\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVoxForge was set up to collect transcribed speech for use with Free and Open Source Speech Recognition Engines (on Linux, Windows and Mac). They promise they will make available all submitted audio files under the GPL license, and then 'compile' them into acoustic models for use with Open Source speech recognition engines such as CMU Sphinx, ISIP, Julius and HTK. According to this, we downloaded the Spanish recordings of… See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/voxforge_spanish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","gpl-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ikk_bible_JHNandMRK_chapter1_to_10","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ogbi/ikk_bible_JHNandMRK_chapter1_to_10","creator_name":"Daniel Ogbuigwe","creator_url":"https://huggingface.co/ogbi","description":"\n\t\n\t\t\n\t\tikk_bible_JHNandMRK_chapter1_to_10 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThis dataset is not fully setup, you will encounter errors while trying to load the data.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ikaaudio dataset comprises segments from the first 10 chapters of the Ika translation of the New Testament. It contains verse-level audio segments, manually verified to include only high-quality segments were the transcription sufficiently matches the audio. The MMS_FA MMS… See the full description on the dataset page: https://huggingface.co/datasets/ogbi/ikk_bible_JHNandMRK_chapter1_to_10.","first_N":5,"first_N_keywords":["Ika","apache-2.0","Audio","🇺🇸 Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"libritts_r","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/libritts_r","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\n\t\n\t\t\n\t\tDataset Card for LibriTTS-R\n\t\n\n\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus \n(http://www.openslr.org/60/) which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate, published in 2019.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the LibriTTS-R dataset, adapted for the datasets library.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThere are 7 splits (dots replace dashes from the original dataset, to comply with hf naming… See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/libritts_r.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours… See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours… See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"latam-xix","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"spanish-corpus-xix","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"glaswegian_audio","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/divakaivan/glaswegian_audio","creator_name":"Ivan Ivanov","creator_url":"https://huggingface.co/divakaivan","description":"\n\t\n\t\t\n\t\tWARNING! Some derogatory slang is included in the dataset\n\t\n\nLatest total length: 120 minutes\nSource:\nScottish phrases 1-10, privately recorded audio, Limmy, and 1 episode of Glasga Da\nMetadata:\n\n\t\n\t\t\nColumn Name\nData Type\nInformation\n\n\n\t\t\nindex\nint\nUnique identifier for each row\n\n\nfile_name\nstring\nPath to the audio file\n\n\ntranscription\nstring\nText transcription of the audio\n\n\nlength_seconds\nfloat\nLength of the audio file in seconds\n\n\nsampling_rate\nint\nSampling rate of the audio file… See the full description on the dataset page: https://huggingface.co/datasets/divakaivan/glaswegian_audio.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","n<1K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"gujarati-f-openslr","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/gujarati-f-openslr","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\n\t\n\t\t\n\t\tGujarati OpenSLR Female\n\t\n\nInterspeech data downloaded from https://www.openslr.org/resources/78/gu_in_female.zip\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nGujarati Data (Most of the entries are <30 seconds and hence Whisper Models can be used for accurate timestamp prediction)\nAlso, the audio seems to have been spoken by a single female.\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Gujarati","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mixed_shona_dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kittech/mixed_shona_dataset","creator_name":"Bright Chirindo","creator_url":"https://huggingface.co/Kittech","description":"Kittech/mixed_shona_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text-classification","automatic-speech-recognition","Shona","English"],"keywords_longer_than_N":true},
	{"name":"vais1000","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vais1000","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VAIS-1000\n\t\n\nofficial announcement: https://vais.vn/vi/tai-ve/hts_for_vietnamese (dead)\nmirror: https://github.com/undertheseanlp/text_to_speech/tree/run/data/vais1000/raw\nsmall only 1h40min audio - 1 speaker (female northern accent) - 1k samples\npre-process: none\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q \"datasets[audio]\"\nfrom datasets import load_dataset\nfrom torch.utils.data import… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vais1000.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vais1000","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/vais1000","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VAIS-1000\n\t\n\nofficial announcement: https://vais.vn/vi/tai-ve/hts_for_vietnamese (dead)\nmirror: https://github.com/undertheseanlp/text_to_speech/tree/run/data/vais1000/raw\nsmall only 1h40min audio - 1 speaker (female northern accent) - 1k samples\npre-process: none\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q \"datasets[audio]\"\nfrom datasets import load_dataset\nfrom torch.utils.data import… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vais1000.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"fake_voices","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Fake Voices\n\t\n\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of… See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Portuguese","mit","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"LSVSC","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/LSVSC","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of LSVSC dataset (novel large-scale Vietnamese speech corpus)\n\t\n\nofficial announcement: https://www.mdpi.com/2079-9292/13/5/977\nofficial download: https://drive.google.com/drive/folders/1tiPKaIOC7bt6isv5qFqf61O_2jFK8ZOI\n100h, 57k samples\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/clean-lsvsc.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/LSVSC.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"LSVSC","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/LSVSC","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of LSVSC dataset (novel large-scale Vietnamese speech corpus)\n\t\n\nofficial announcement: https://www.mdpi.com/2079-9292/13/5/977\nofficial download: https://drive.google.com/drive/folders/1tiPKaIOC7bt6isv5qFqf61O_2jFK8ZOI\n100h, 57k samples\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/clean-lsvsc.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/LSVSC.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Speech-Irish","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the Tatoeba dataset, consisting of 1,983 text segments.\nThe dataset consists of two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 2 hours and 39 minutes (02:39:31) spread across 3,966 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio', 'text_ga'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Speech-Irish","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the Tatoeba dataset, consisting of 1,983 text segments.\nThe dataset consists of two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 2 hours and 39 minutes (02:39:31) spread across 3,966 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio', 'text_ga'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"Wikimedia-Speech-Irish","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the Wikimedia dataset, consisting of 7,545 text segments.\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 34 hours and 23 minutes (34:23:12) spread across 15,090 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio', 'text_ga'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"Wikimedia-Speech-Irish","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the Wikimedia dataset, consisting of 7,545 text segments.\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 34 hours and 23 minutes (34:23:12) spread across 15,090 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio', 'text_ga'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Wikimedia-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ClArTTS","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe present a speech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated. The final ClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nA typical data point comprises the name of the audio file, called… See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ClArTTS.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-1.0-en-client_id-grouped","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-1.0-en-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 60 samples and a maximum of… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","English"],"keywords_longer_than_N":true},
	{"name":"pony-singing","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/synthbot/pony-singing","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","description":"synthbot/pony-singing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"limmits-2024","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","description":"\n\t\n\t\t\n\t\n\t\n\t\tIndic TTS dataset\n\t\n\n7 languages from IISC's LIMMITS Challenge 2024\n\n\t\n\t\t\n\t\n\t\n\t\tRoadmap\n\t\n\nTo use this for training VALLE-X & VoiceBox based TTS models\n\n\t\n\t\t\n\t\n\t\n\t\tFetch the tars directly\n\t\n\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\nwget -O… See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"limmits-2024","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","description":"\n\t\n\t\t\n\t\n\t\n\t\tIndic TTS dataset\n\t\n\n7 languages from IISC's LIMMITS Challenge 2024\n\n\t\n\t\t\n\t\n\t\n\t\tRoadmap\n\t\n\nTo use this for training VALLE-X & VoiceBox based TTS models\n\n\t\n\t\t\n\t\n\t\n\t\tFetch the tars directly\n\t\n\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\nwget -O… See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset… See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-CN-client_id-grouped","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-zh-CN-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-TW-client_id-grouped","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-zh-TW-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-ja-client_id-grouped","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-ja-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum of… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Japanese"],"keywords_longer_than_N":true},
	{"name":"ai_hub_summ_train","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jr-d-analyst24/ai_hub_summ_train","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/ai_hub_summ_train dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["summarization","Korean","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Saudilang-Code-Switch-Corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus","creator_name":"SDAIA NCAI","creator_url":"https://huggingface.co/SDAIANCAI","description":"\n\t\n\t\t\n\t\tSCC - Saudilang Code-Switch Corpus\n\t\n\nThe National Center for Artificial Intelligence at the Saudi Data and Artificial Intelligence Authority (SDAIA), published the \"SCC\" dataset, which stands for \"Saudilang Code-Switch Corpus”.\nThis dataset contains a transcription of general conversations taken from a YouTube podcast \"Thmanyah\" that has been transcribed by the National Center for Artificial Intelligence in SDAIA. The data features three episodes covering different domains: investment… See the full description on the dataset page: https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Saudilang-Code-Switch-Corpus","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus","creator_name":"SDAIA NCAI","creator_url":"https://huggingface.co/SDAIANCAI","description":"\n\t\n\t\t\n\t\tSCC - Saudilang Code-Switch Corpus\n\t\n\nThe National Center for Artificial Intelligence at the Saudi Data and Artificial Intelligence Authority (SDAIA), published the \"SCC\" dataset, which stands for \"Saudilang Code-Switch Corpus”.\nThis dataset contains a transcription of general conversations taken from a YouTube podcast \"Thmanyah\" that has been transcribed by the National Center for Artificial Intelligence in SDAIA. The data features three episodes covering different domains: investment… See the full description on the dataset page: https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-openslr-80","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (OpenSLR-80)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual OpenSLR dataset. \nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof OpenSLR HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nOpenSLR is a site devoted to hosting speech and language resources, such as training… See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-openslr-80","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (OpenSLR-80)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual OpenSLR dataset. \nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof OpenSLR HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nOpenSLR is a site devoted to hosting speech and language resources, such as training… See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-openslr-80.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Ar-En-Code-Switching-Textual-Dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDAIANCAI/Ar-En-Code-Switching-Textual-Dataset","creator_name":"SDAIA NCAI","creator_url":"https://huggingface.co/SDAIANCAI","description":"\n\t\n\t\t\n\t\tArE-CSTD: Arabic-English Code-Switching Textual Dataset\n\t\n\nThe National Center for Artificial Intelligence at the Saudi Data and Artificial Intelligence Authority (SDAIA), published the \"ArE-CSTD\" dataset, which stands for \"Arabic-English Code-Switching Textual Dataset”.\nThis dataset contains 330K dialectical Arabic-English code-swithing sentences generated by the large language model GPT-4.\n\n\t\n\t\t\n\t\tTXT Files\n\t\n\nThere are 6 txt files. 2 files for Modern Standard Arabic(MSA) train and… See the full description on the dataset page: https://huggingface.co/datasets/SDAIANCAI/Ar-En-Code-Switching-Textual-Dataset.","first_N":5,"first_N_keywords":["text-generation","automatic-speech-recognition","Arabic","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"parlament_parla_v3","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/parlament_parla_v3","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for ParlamentParla v3 - Speech Corpus of Catalan Parliamentary Sessions\n\t\n\nA speech corpus composed of Catalan Parliamentary Sessions.The v3 and last version of the corpus includes both clean and other quality segments, divided into short segments (less than 30 seconds) and long segments (more than 30 seconds). The total dataset encompasses 1059h 48m 04s of speech, including 945h 51m 06s for the short segments and 113h 56m 58s for the long segments, with a total of… See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/parlament_parla_v3.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Catalan","cc-by-4.0","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"Tuda-De","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/uhhlt/Tuda-De","creator_name":"LT Group at UHH","creator_url":"https://huggingface.co/uhhlt","description":"\n\t\n\t\t\n\t\tOpen speech data for German speech recognition\n\t\n\nLanguage Technology, Universität Hamburg, Germany\nhttps://www.inf.uni-hamburg.de/en/inst/ab/lt (formerly TU-Darmstadt)\nhttps://www.lt.tu-darmstadt.de\nTelecooperation labs, TU-Darmstadt, Germany\nhttps://www.tk.informatik.tu-darmstadt.de\n\n\t\n\t\t\n\t\n\t\n\t\tGeneral information\n\t\n\n\nThe speech data was collected in a controlled environment (same room, same microphone distances, etc. )\nDistance between speakers and the microphones is about 1 meter… See the full description on the dataset page: https://huggingface.co/datasets/uhhlt/Tuda-De.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"elevenlabs_multilingual_v2-technical-speech","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WpythonW/elevenlabs_multilingual_v2-technical-speech","creator_name":"Andrew","creator_url":"https://huggingface.co/WpythonW","description":"\n\t\n\t\t\n\t\tElevenLabs Multilingual V2 Technical Speech Dataset\n\t\n\nThis dataset contains automatically generated technical phrases in three domains, converted to speech using the ElevenLabs Multilingual V2 model with Adam voice.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes audio samples of technical phrases across three categories:\n\nMachine Learning (ML)\nScience\nTechnology\n\nEach entry contains:\n\nAudio file in MP3 format (22050Hz)\nSource text\nText length\nCategory label\n\n\n\t\n\t\t\n\t\tData… See the full description on the dataset page: https://huggingface.co/datasets/WpythonW/elevenlabs_multilingual_v2-technical-speech.","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"wiki-en-in-neerja-speech","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"This dataset contains 10K audio samples generated using Microsoft Edge Text-to-Speech via EdgeTTS. \n\nTotal samples: 10K\nAudio format: MP3\nSample rate: 24kHz\nTotal duration: 95735.86 seconds (26.59 hours)\nAverage duration: 9.57 seconds\nLanguages included: English\nVoices used: en-IN-NeerjaExpressiveNeural\n\nInput sentences were randomly sampled from Wikipedia, provided by the Wikimedia Foundation under the GNU Free Documentation License (GFDL) and the Creative Commons Attribution-Share-Alike 3.0… See the full description on the dataset page: https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SpeechBrown","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-lab/SpeechBrown","creator_name":"LLM-Lab-Org  @QCRI-ALT","creator_url":"https://huggingface.co/llm-lab","description":"  \nModels | Springer Link | arXiv Link | Proposed Dataset  | ACM Digital Library | Website\n\n\t\t\n\t\tDataset Summary\n\t\n\nSpeech Brown is a comprehensive, synthetic, and diverse paired speech-text dataset in 15 categories, covering a wide range of topics from fiction to religion. This dataset consists of over 55,000 sentence-level samples.  \nTo train the CLASP model, we created this dataset based on the Brown Corpus. The synthetic speech was generated using the NVIDIA Tacotron 2 text-to-speech… See the full description on the dataset page: https://huggingface.co/datasets/llm-lab/SpeechBrown.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"bam-asr-early","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/bam-asr-early","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Bambara-ASR-Early Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \nData sources include all publicly available collections of audio with Bambara transcriptions as of December 2024, organized for accessibility and usability.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"bam-asr-early","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/bam-asr-early","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Bambara-ASR-Early Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \nData sources include all publicly available collections of audio with Bambara transcriptions as of December 2024, organized for accessibility and usability.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"picovoice-wake-word-benchmark","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark","creator_name":"Adam Jones","creator_url":"https://huggingface.co/domdomegg","description":"\n\t\n\t\t\n\t\tPicovoice Wake Word Benchmark Dataset\n\t\n\nThis dataset contains a collection of wake word recordings used for benchmarking wake word detection systems. The dataset has been reformatted from the original Picovoice Wake Word Benchmark repository for easier use with Hugging Face's ecosystem.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains over 300 recordings of six different wake words from more than 50 distinct speakers. These recordings were originally used to benchmark different… See the full description on the dataset page: https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Puck-Voice","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Puck-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Puck-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Aoede-Voice","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Aoede-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","description":"fireblade2534/Gemini-2.0-Flash-Aoede-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"SUMM-RE","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/SUMM-RE","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"Note: if the data viewer is not working, use the \"example\" subset.\n\n\t\n\t\t\n\t\tSUMM-RE\n\t\n\nThe SUMM-RE dataset is a collection of transcripts of French conversations, aligned with the audio signal.\nIt is a corpus of meeting-style conversations in French created for the purpose of the SUMM-RE project (ANR-20-CE23-0017). \nThe full dataset is described in Hunter et al. (2024): \"SUMM-RE: A corpus of French meeting-style conversations\".\n\nCreated by: Recording and manual correction of the corpus was… See the full description on the dataset page: https://huggingface.co/datasets/linagora/SUMM-RE.","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","French","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ar-eg-dataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DrAliGomaa/ar-eg-dataset","creator_name":"arabic_speech","creator_url":"https://huggingface.co/DrAliGomaa","description":"An in-progress dataset for arabic-egyptian-dialect, specifically made from transcripton of DrAliGomaa videos on youtube.\nDr Ali Gomaa is a famous Egyptian Islamic Scholar and he was the mufti of Egypt from 2003-2013\n\nLink to his youtube channel: https://www.youtube.com/@DrAliGomaa\nLink to his page on facebook: https://www.facebook.com/DrAliGomaa\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ChFT","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tzyll/ChFT","creator_name":"Zhiyuan Tang","creator_url":"https://huggingface.co/tzyll","description":"\n\t\n\t\t\n\t\tDataset Card for ChFT\n\t\n\n\n\nThis dataset is published with the paper Full-text Error Correction for Chinese Speech Recognition with Large Language Model in ICASSP 2025.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/tzyll/ChFT.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","apache-2.0","arxiv:2409.07790","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"linto-dataset-audio-ar-tn","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\n(linagora/linto-asr-ar-tn).\n\nDataset Summary\nDataset composition\nSources\nData Table\nData sources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian is a diverse… See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\n(linagora/linto-asr-ar-tn).\n\nDataset Summary\nDataset composition\nSources\nData Table\nData sources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian is a diverse… See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\n\nDataset Summary\nDataset composition\nSources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on LinTO… See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\n\nDataset Summary\nDataset composition\nSources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on LinTO… See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"RapBank","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zqning/RapBank","creator_name":"ziqianning","creator_url":"https://huggingface.co/zqning","description":"\n\t\n\t\t\n\t\tDataset Card for RapBank\n\t\n\n\n\nRapBank is the first dataset for rap generation. The rap songs are collected from YouTube, and we provide a meticulously designed pipeline for data processing\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://github.com/NZqian/RapBank\nPaper: https://arxiv.org/abs/2408.15474\nDemo: https://nzqian.github.io/Freestyler/\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\nThe RapBank dataset comprises links to a total of 94, 164 songs.\nHowever, due to… See the full description on the dataset page: https://huggingface.co/datasets/zqning/RapBank.","first_N":5,"first_N_keywords":["text-to-speech","cc-by-sa-4.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"earnings21","keyword":"speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Revai/earnings21","creator_name":"Rev","creator_url":"https://huggingface.co/Revai","description":"\n\t\n\t\t\n\t\tEarnings 21\n\t\n\nThe Earnings 21 dataset ( also referred to as earnings21 ) is a 39-hour corpus of earnings calls containing entity dense speech from nine different financial sectors. This corpus is intended to benchmark automatic speech recognition (ASR) systems in the wild with special attention towards named entity recognition (NER).\nIn this repo, we provided the transcoded files to 16KHz with the formatted text. This limits the utility of the original dataset due to the restrictions… See the full description on the dataset page: https://huggingface.co/datasets/Revai/earnings21.","first_N":5,"first_N_keywords":["English","cc-by-sa-4.0","Audio","arxiv:2104.11348","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"speakeroverlap_multiseg","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zbrunner/speakeroverlap_multiseg","creator_name":"Zoe Brunner","creator_url":"https://huggingface.co/zbrunner","description":"\n\t\n\t\t\n\t\tMultiSeg Dataset for ASR Hallucinations\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nMultiSeg is a perturbed and altered version of the TEDLIUM3 dataset, specifically created for evaluating the robustness of Automatic Speech Recognition (ASR) systems. This dataset is derived from the 'speakeroverlap' subset, which consists of held-back training data from TEDLIUM3.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThe primary purpose of the MultiSeg dataset is to:\n\nElicit hallucinations from ASR systems\nEvaluate ASR performance under… See the full description on the dataset page: https://huggingface.co/datasets/zbrunner/speakeroverlap_multiseg.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and CML-TTS\n\t\n\nThis dataset is a filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in… See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Polish"],"keywords_longer_than_N":true},
	{"name":"uzbek_speech_data","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uzbek_speech_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uzbek_speech_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"uz-data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uz-data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uz-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"STT-v1","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FILM6912/STT-v1","creator_name":"FILM","creator_url":"https://huggingface.co/FILM6912","description":"FILM6912/STT-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Thai","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"LnNor","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiBridge/LnNor","creator_name":"MultiBridge","creator_url":"https://huggingface.co/MultiBridge","description":"\n\t\n\t\t\n\t\tDataset Card for the LnNor Corpus\n\t\n\n\nA multilingual dataset of high-quality speech recordings in Norwegian, English, and Polish, designed for research into cross-linguistic influence, multilingual language acquisition, and applications in NLP and speech processing such as ASR, TTS, and linguistic variability modeling. The dataset features structured experimental tasks such as reading, picture and video description, and spontaneous conversation to capture phonological, syntactic, and… See the full description on the dataset page: https://huggingface.co/datasets/MultiBridge/LnNor.","first_N":5,"first_N_keywords":["token-classification","text-classification","automatic-speech-recognition","audio-classification","Norwegian"],"keywords_longer_than_N":true},
	{"name":"speech-to-text","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LeVy4/speech-to-text","creator_name":"Le Thao Vy","creator_url":"https://huggingface.co/LeVy4","description":"LeVy4/speech-to-text dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"acl-paper","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/acl-paper","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"\n\t\n\t\t\n\t\tACL Entire\n\t\n\n\n  \n\n\nACL Entire is a comprehensive dataset containing all papers from both ACL and Non-ACL events listed on the ACL Anthology website. This dataset includes complete bibliographic information for all years.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nEvents Covered: Papers from ACL and Non-ACL events.\nBibliography: Includes complete bibliographic details for every paper.\nYears Covered: Comprehensive data spanning all available years.\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nAll data has been compiled from the ACL… See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/acl-paper.","first_N":5,"first_N_keywords":["text-classification","translation","summarization","text2text-generation","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"text_to_speech_dataset","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kishor798/text_to_speech_dataset","creator_name":"Kishor thagunna","creator_url":"https://huggingface.co/Kishor798","description":"Kishor798/text_to_speech_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"mabama-data","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aztro/mabama-data","creator_name":"Jose Omar Vieyra","creator_url":"https://huggingface.co/aztro","description":"aztro/mabama-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"TIE_shorts","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raianand/TIE_shorts","creator_name":"Anand Rai","creator_url":"https://huggingface.co/raianand","description":"\n\t\n\t\t\n\t\tDataset Card for TIE_Shorts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTIE_shorts is a derived version of the Technical Indian English (TIE) dataset, a large-scale speech dataset (~ 8K hours) originally consisting of approximately 750 GB of content \nsourced from the NPTEL platform. The original TIE dataset contains around 9.8K technical lectures in English delivered by instructors from various regions across India, \nwith each lecture averaging about 50 minutes. These lectures cover a wide range of… See the full description on the dataset page: https://huggingface.co/datasets/raianand/TIE_shorts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TIE_shorts","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raianand/TIE_shorts","creator_name":"Anand Rai","creator_url":"https://huggingface.co/raianand","description":"\n\t\n\t\t\n\t\tDataset Card for TIE_Shorts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTIE_shorts is a derived version of the Technical Indian English (TIE) dataset, a large-scale speech dataset (~ 8K hours) originally consisting of approximately 750 GB of content \nsourced from the NPTEL platform. The original TIE dataset contains around 9.8K technical lectures in English delivered by instructors from various regions across India, \nwith each lecture averaging about 50 minutes. These lectures cover a wide range of… See the full description on the dataset page: https://huggingface.co/datasets/raianand/TIE_shorts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"indicvoices_hi_tagged_transcripts","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_hi_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information… See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Vulpisfoglia","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Vulpisfoglia","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Vulpisfoglia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_ca","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_ca","creator_name":"Carlos Daniel Hernández Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Catalan","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_ca","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_ca","creator_name":"Carlos Daniel Hernández Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Catalan","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pavanyellow/librispeech_asr","creator_name":"Pavan Katta","creator_url":"https://huggingface.co/pavanyellow","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tLibriSpeech ASR 2s Splits Dataset\n\t\n\nVersion of LibriSpeech ASR corpus split into 2s clips.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset from the Hub\ndataset = load_dataset(\"pavanyellow/librispeech_asr\")\n\n# Or load a specific split\ndataset = load_dataset(\"pavanyellow/librispeech_asr\", split=\"train\")\n\n# Access the data\nfor example in dataset['train'][:5]:\n   audio = example['audio']\n   text = example['text']\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"emova-alignment-7m","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-Alignment-7M\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-Alignment-7M is a comprehensive dataset curated for omni-modal pre-training, including vision-language and speech-language alignment. \nThis dataset is created using open-sourced image-text pre-training datasets, OCR datasets, and 2,000 hours of ASR and TTS data. \nThis dataset is part of the EMOVA-Datasets… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"emova-alignment-7m","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-Alignment-7M\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-Alignment-7M is a comprehensive dataset curated for omni-modal pre-training, including vision-language and speech-language alignment. \nThis dataset is created using open-sourced image-text pre-training datasets, OCR datasets, and 2,000 hours of ASR and TTS data. \nThis dataset is part of the EMOVA-Datasets… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"bengali_regional_dataset_refine","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sha1779/bengali_regional_dataset_refine","creator_name":"Md sazzad hossain","creator_url":"https://huggingface.co/sha1779","description":"This is the dataset of  ভাষা-বিচিত্রা: ASR for Regional Dialects competition.\nhere i preprocessed and make train and eval split.\nthis dataset consist of 10 dialact named 'barishal', 'chittagong', 'habiganj', 'kishoreganj', 'narail',\n       'narsingdi', 'rangpur', 'sandwip', 'sylhet', 'tangail'.\nbarishal district has 796 samples\nchittagong district has 1406 samples\nhabiganj district has 940 samples\nkishoreganj district has 1638 samples\nnarail district has 1488 samples\nnarsingdi district has… See the full description on the dataset page: https://huggingface.co/datasets/sha1779/bengali_regional_dataset_refine.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"commonvoice-12.0-arabic-voice-converted","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted","creator_name":"Modar M. Alfadly","creator_url":"https://huggingface.co/xmodar","description":"\n\t\n\t\t\n\t\tDataset Card for Voice Converted Arabic Common Voice 12.0\n\t\n\nThis dataset is derived from the Common Voice Arabic Corpus 12.0 and includes automatically diacritized transcriptions and phoneme representations for the original augmented audio data. The recordings feature Arabic text read aloud by users, where the text was initially undiacritized, allowing for potential reading errors. The diacritization and phonemes were generated automatically, resulting in a dataset that is valuable… See the full description on the dataset page: https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"darija-speech-to-text","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/darija-speech-to-text","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"\n\t\n\t\t\n\t\tSpeech To Text Darija dataset\n\t\n\nReupload of adiren7/darija_speech_to_text\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","apache-2.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"google_wellformed_query-hf","keyword":"grammar","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BEE-spoke-data/google_wellformed_query-hf","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","description":"\n\t\n\t\t\n\t\tgoogle_wellformed_query-hf\n\t\n\nOriginal google_wellformed_query loaded/converted to parquet format so trust_remote_code is not needed.\n","first_N":5,"first_N_keywords":["text-classification","English","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"emova-asr-tts-eval","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-ASR-TTS-Eval\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-ASR-TTS-Eval is a dataset designed for evaluating the ASR and TTS performance of Omni-modal LLMs. It is derived from the test-clean set of the LibriSpeech dataset. This dataset is part of the EMOVA-Datasets collection. We extract the speech units using the EMOVA Speech Tokenizer.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThis… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"emova-asr-tts-eval","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-ASR-TTS-Eval\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-ASR-TTS-Eval is a dataset designed for evaluating the ASR and TTS performance of Omni-modal LLMs. It is derived from the test-clean set of the LibriSpeech dataset. This dataset is part of the EMOVA-Datasets collection. We extract the speech units using the EMOVA Speech Tokenizer.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThis… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"WisesightSentimentClassification","keyword":"hate-speech-detection","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/WisesightSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  WisesightSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, News, Written\nReference\nhttps://github.com/PyThaiNLP/wisesight-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/WisesightSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Lappland-the-Decadenza","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland-the-Decadenza","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland-the-Decadenza dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"luvila-kikongo-grammar","keyword":"grammar","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/luvila-kikongo-grammar","creator_name":"NIONGOLO Chrys Fé-Marty","creator_url":"https://huggingface.co/Svngoku","description":"Svngoku/luvila-kikongo-grammar dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Kongo","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"automatic-speech-recognition","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_SER_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","monolingual","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"speech","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_SER_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","monolingual","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V2","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V2","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V2 version and the version described in paper:\n\nThe V2 version provide audio in 44.1kHz sample rate. (Supersampling)\nThe V2 versionn removed some samples (~5%) due to the volumn and text aligment issues.\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to address the… See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V2.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"Lappland","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"wolof-audio-data","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vonewman/wolof-audio-data","creator_name":"Abdoulaye Diallo","creator_url":"https://huggingface.co/vonewman","description":"\n\t\n\t\t\n\t\tWolof Audio Dataset\n\t\n\nThe Wolof Audio Dataset is a collection of audio recordings and their corresponding transcriptions in Wolof. This dataset is designed to support the development of Automatic Speech Recognition (ASR) models for the Wolof language. It was created by combining three existing datasets:\n\nALFFA: Available at serge-wilson/wolof_speech_transcription\nFLEURS: Available at vonewman/fleurs-wolof-dataset\nUrban Bus Wolof Speech Dataset: Available at vonewman/urban-bus-wolof… See the full description on the dataset page: https://huggingface.co/datasets/vonewman/wolof-audio-data.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Wolof","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MCEval8K","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iszhaoxin/MCEval8K","creator_name":"XIN ZHAO","creator_url":"https://huggingface.co/iszhaoxin","description":"\n\t\n\t\t\n\t\tMCEval8K\n\t\n\nMCEval8K is a diverse multiple-choice evaluation benchmark for probing language models’ (LMs) understanding of a broad range of language skills using neuron-level analysis. \nIt was introduced in the ACL 2025 paper - \"Neuron Empirical Gradient: Discovering and Quantifying Neurons’ Global Linear Controllability\".\n\n\t\n\t\t\n\t\t🔍 Overview\n\t\n\nMCEval8K consists of 22 tasks grouped into six skill genres, covering linguistic analysis, content classification, reasoning, factuality… See the full description on the dataset page: https://huggingface.co/datasets/iszhaoxin/MCEval8K.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","natural-language-inference","acceptability-classification"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-231k","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-231K\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-231K is a comprehensive dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-231K is part of EMOVA-Datasets collection and is used in… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-231k","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-231K\n\t\n\n\n\n\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-231K is a comprehensive dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-231K is part of EMOVA-Datasets collection and is used in… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"2k_grammar_corrections","keyword":"grammar","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ambrosfitz/2k_grammar_corrections","creator_name":"Christopher Smith","creator_url":"https://huggingface.co/ambrosfitz","description":"ambrosfitz/2k_grammar_corrections dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","English","cc-by-sa-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"UZ_voice","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/UZ_voice","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/UZ_voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"raw-speech-whispervq-v1","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Menlo/raw-speech-whispervq-v1","creator_name":"Menlo Research","creator_url":"https://huggingface.co/Menlo","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains over 2,4M English ASR samples, using:\n\nThe a training set of parler-tts/mls_eng_10k\nTokenized using WhisperVQ.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset, Audio\n# Load Instruction Speech dataset\n\ndataset = load_dataset(\"homebrewltd/raw-speech-whispervq-v1\",split='train')\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\ntokens\nsequence\nTokenized using Encodec\n\n\ntext\nsequence\nConverted audio tokens\n\n\n\t\n\n\n\t\n\t\t\n\t\tBias, Risks… See the full description on the dataset page: https://huggingface.co/datasets/Menlo/raw-speech-whispervq-v1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"automatic-speech-recognition","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_ASR_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Japanese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"speech","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_ASR_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Japanese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_es_v1.0","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/composite_corpus_es_v1.0","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tComposite dataset for Spanish made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/es: \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\nopenslr: a train split made from the SLR(39,61,67,71,72,73,74,75,108) subsets… See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_es_v1.0.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"dry-replies","keyword":"linguistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ni5arga/dry-replies","creator_name":"Nisarga","creator_url":"https://huggingface.co/ni5arga","description":"\n\t\n\t\t\n\t\tDry Replies Dataset\n\t\n\nA collection of 200+ short, neutral, and minimalistic replies commonly used in casual conversations. Perfect for chatbots, sentiment analysis, or even linguistic studies. All responses are lowercase and simple, making them easy to integrate into various projects.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nChatbots: Add realistic and casual replies to conversational models.  \nSentiment Analysis: Test systems with neutral or dry responses.  \nText Generation: Incorporate concise replies… See the full description on the dataset page: https://huggingface.co/datasets/ni5arga/dry-replies.","first_N":5,"first_N_keywords":["English","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"znanio-audios","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/znanio-audios","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Znanio.ru Educational Audio\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 3,417 educational audio files from the znanio.ru platform, a resource for teachers, educators, students, and parents providing diverse educational content. Znanio.ru has been a pioneer in educational technologies and distance learning in the Russian-speaking internet since 2009.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, with potential multilingual content:\n\nRussian (ru): The… See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/znanio-audios.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"filatov_24000","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/patriotyk/filatov_24000","creator_name":"Serhiy Stetskovych ","creator_url":"https://huggingface.co/patriotyk","description":"patriotyk/filatov_24000 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SBCSAE","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dklement/SBCSAE","creator_name":"Dominik Klement","creator_url":"https://huggingface.co/dklement","description":"A detailed dataset description (including description, audio samples, and statistics) is provided here: https://domklement.github.io/sbcsae/\nIf you use the dataset, please, do not forget to cite our work:\n@inproceedings{maciejewski24_interspeech,\n  title     = {Evaluating the Santa Barbara Corpus: Challenges of the Breadth of Conversational Spoken Language},\n  author    = {Matthew Maciejewski and Dominik Klement and Ruizhe Huang and Matthew Wiesner and Sanjeev Khudanpur},\n  year      = {2024}… See the full description on the dataset page: https://huggingface.co/datasets/dklement/SBCSAE.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ksponspeech-eval","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yfyeung/ksponspeech-eval","creator_name":"Yifan Yang","creator_url":"https://huggingface.co/yfyeung","description":"paper link: https://www.mdpi.com/846876\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","cc-by-4.0","Audio","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"inbrowser-proctor-dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset","creator_name":"Aayush Man Shrestha","creator_url":"https://huggingface.co/lord-reso","description":"\n\t\n\t\t\n\t\tDataset Card for Inbrowser Proctor Dataset\n\t\n\n\n\t\n\t\t\n\t\tProject Description\n\t\n\nInbrowser Proctoring is an online browser proctoring application designed to supervise exams and prevent cheating in real-time. Utilizing a combination of video, audio, and screen recording technologies, along with advanced AI algorithms, the system closely monitors test-takers to identify suspicious behaviors and activities. By analyzing audio and visual data, it can detect anomalies that may indicate… See the full description on the dataset page: https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"inbrowser-proctor-dataset","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset","creator_name":"Aayush Man Shrestha","creator_url":"https://huggingface.co/lord-reso","description":"\n\t\n\t\t\n\t\tDataset Card for Inbrowser Proctor Dataset\n\t\n\n\n\t\n\t\t\n\t\tProject Description\n\t\n\nInbrowser Proctoring is an online browser proctoring application designed to supervise exams and prevent cheating in real-time. Utilizing a combination of video, audio, and screen recording technologies, along with advanced AI algorithms, the system closely monitors test-takers to identify suspicious behaviors and activities. By analyzing audio and visual data, it can detect anomalies that may indicate… See the full description on the dataset page: https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"DocMSU","keyword":"sarcasm-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/coderchen01/DocMSU","creator_name":"Junjie Chen","creator_url":"https://huggingface.co/coderchen01","description":"\n\t\n\t\t\n\t\tDocMSU: A Comprehensive Benchmark for Document-level Multimodal Sarcasm Understanding\n\t\n\nThis is a replication of the DocMSU dataset for easier access.\n\n\t\n\t\t\n\t\tReference\n\t\n\nDu, H., Nan, G., Zhang, S., Xie, B., Xu, J., Fan, H., Cui, Q., Tao, X. and Jiang, X., 2024, March. DocMSU: A Comprehensive Benchmark for Document-Level Multimodal Sarcasm Understanding. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 38, No. 16, pp. 17933-17941).\n","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"enwaucymraeg","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanasash/enwaucymraeg","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","description":"The training and development set sentences are taken from CoVoST and have been compared to all validated sentences in the Welsh Common Voice data to ensure none of the already recorded sentences will be used here. Then all sentences containing personal names have been extracted and replaced with a randomly generated name using the Faker library and a custom Welsh names list. The sentences were then recorded by 26 volunteers from North-West Wales, 15 women, 10 men and one non-binary person.… See the full description on the dataset page: https://huggingface.co/datasets/wanasash/enwaucymraeg.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Welsh","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Mana-TTS","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MahtaFetrat/Mana-TTS","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","description":"\n\t\n\t\t\n\t\tManaTTS Persian: a recipe for creating TTS datasets for lower resource languages\n\t\n\n\nMana-TTS is a comprehensive Persian Text-to-Speech (TTS) dataset, featuring 102 hours of high-quality single-speaker audio, specifically designed for speech synthesis and related tasks. The dataset has been carefully collected, processed, and annotated to ensure high-quality data for training TTS models. For details on data processing pipeline and statistics, please refer to the paper in the Citation… See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/Mana-TTS.","first_N":5,"first_N_keywords":["cc0-1.0","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"commonvoice_17_tr_fixed","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ysdede/commonvoice_17_tr_fixed","creator_name":"Yunus Dede","creator_url":"https://huggingface.co/ysdede","description":"\n\t\n\t\t\n\t\tImproving CommonVoice 17 Turkish Dataset\n\t\n\nI recently worked on enhancing the Mozilla CommonVoice 17 Turkish dataset to create a higher quality training set for speech recognition models.Here's an overview of my process and findings.\n\n\t\n\t\t\n\t\tInitial Analysis and Split Organization\n\t\n\nMy first step was analyzing the dataset organization to understand its structure.Through analysis of filename stems as unique keys, I revealed and documented an important aspect of CommonVoice's design… See the full description on the dataset page: https://huggingface.co/datasets/ysdede/commonvoice_17_tr_fixed.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"speech","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/peanut999/speech","creator_name":"butter","creator_url":"https://huggingface.co/peanut999","description":"peanut999/speech dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","English","Malay","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-for-asr","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-for-asr","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset for ASR\n\t\n\nThis dataset is a comprehensive collection of Myanmar language speech data specifically curated for Automatic Speech Recognition (ASR) task. It combines following datasets:\n\nMyanmar Speech Dataset (Google Fleurs)\nMyanmar Speech Dataset (OpenSLR-80)\n\nBy merging these complementary resources, this dataset provides a more robust foundation for training and evaluating ASR models for… See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-for-asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_zh","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minghanw/sdf_dataset_zh","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated… See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_zh.","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_zh","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minghanw/sdf_dataset_zh","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated… See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_zh.","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"LAION's Got Talent: Generated Voice Acting Dataset\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\"LAION's Got Talent\" is a synthetic voice acting dataset designed to offer a broad range of emotional expressions, vocal bursts, and multi-language utterances. This dataset is a component of the BUD-E project, led by LAION with support from Intel, and aims to drive forward research in context-aware and empathetic AI voice assistants.\n\n\n\t\n\t\t\n\t\tUpdated Composition\n\t\n\n\nVoices and Languages  \n\nEnglish: 11 OpenAI voices, each… See the full description on the dataset page: https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning.","first_N":5,"first_N_keywords":["English","French","German","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)… See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)… See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)… See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"swahili-tts-dataset","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jacksonwambali/swahili-tts-dataset","creator_name":"Jackson Wambali","creator_url":"https://huggingface.co/jacksonwambali","description":"\n\t\n\t\t\n\t\tSwahili TTS Dataset\n\t\n\nThis dataset contains 10 Swahili audio clips with corresponding transcripts, used to train a Text-to-Speech (TTS) model using Coqui TTS.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nwavs/: Contains WAV audio files (One.wav to Ten.wav).\nmetadata.csv: Contains the following columns:\nfile_name: Name of the audio file.\naudio_path: Path to the audio file.\ntranscript: Swahili transcript of the audio.\nduration: Duration of the audio in seconds.\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nThis dataset can… See the full description on the dataset page: https://huggingface.co/datasets/jacksonwambali/swahili-tts-dataset.","first_N":5,"first_N_keywords":["Swahili","cc-by-4.0","Audio","🇺🇸 Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"audio_recordings","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/da2ce7/audio_recordings","creator_name":"Cam","creator_url":"https://huggingface.co/da2ce7","description":"\n\t\n\t\t\n\t\tAudio Recordings\n\t\n\nThese are some personal and open source audio recordings. Feel free to use.\n","first_N":5,"first_N_keywords":["audio-to-audio","audio-text-to-text","any-to-any","text-to-speech","English"],"keywords_longer_than_N":true},
	{"name":"common_voice_20_armenian","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chillarmo/common_voice_20_armenian","creator_name":"Movses Movsesyan","creator_url":"https://huggingface.co/Chillarmo","description":"\n\t\n\t\t\n\t\tCommon Voice 20 - Armenian\n\t\n\nThis dataset is the Armenian portion of Mozilla's Common Voice 20.0 release, \na massively multilingual collection of transcribed speech intended for speech technology research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Armenian (hy)\nSource: Mozilla Common Voice\nVersion: 20.0\nLicense: CC0-1.0\n\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Armenian","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"causalgym","keyword":"linguistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aryaman/causalgym","creator_name":"Aryaman Arora","creator_url":"https://huggingface.co/aryaman","description":"CausalGym is a benchmark for comparing the performance of causal interpretability methods\non a variety of simple linguistic tasks taken from the SyntaxGym evaluation set\n(Gauthier et al., 2020, Hu et al., 2020)\nand converted into a format suitable for interventional interpretability.\nThe dataset includes train/dev/test splits (exactly as used in the experiments in the paper).\nThe base/src columns are the prompts on which intervention is done. Each of these is a list of strings,\nwith each… See the full description on the dataset page: https://huggingface.co/datasets/aryaman/causalgym.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Indic-subtitler-audio_evals","keyword":"automatic-speech-recognition","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals","creator_name":"Kurian Benoy","creator_url":"https://huggingface.co/kurianbenoy","description":"\n\t\n\t\t\n\t\tIndic_audio_evals\n\t\n\nAs part of this project. We are evaluating our performance of various ASR models as well\nin a benchmarking dataset, we have created in various languages. This benchmarking dataset\nis more alligned to real-world use-cases rather than having any academic datasets.\n\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\n\nDataset Link in HuggingFace: kurianbenoy/Indic-subtitler-audio_evals\n\nThis dataset contains audio file in .wav format and video file in .mp4. The respective groundtruth will be… See the full description on the dataset page: https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","Hindi","English","Bengali"],"keywords_longer_than_N":true},
	{"name":"arabic_xvector_embeddings","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings","creator_name":"Hawau Olamide Toyin","creator_url":"https://huggingface.co/herwoww","description":"\n\t\n\t\t\n\t\tArabic Speaker Embeddings extracted from ASC and ClArTTS\n\t\n\nThere is one speaker embedding for each utterance in the validation set of both datasets. The speaker embeddings are 512-element X-vectors.\nArabic Speech Corpus has 100 files for a single male speaker and ClArTTS has 205 files for a single male speaker.\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\nUsage:\nfrom datasets import load_dataset\n\nembeddings_dataset =… See the full description on the dataset page: https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings.","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RaviNaik/Fleurs-Kn","creator_name":"Ravi Naik","creator_url":"https://huggingface.co/RaviNaik","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.… See the full description on the dataset page: https://huggingface.co/datasets/RaviNaik/Fleurs-Kn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn","creator_name":"Kannada LLM Labs","creator_url":"https://huggingface.co/Kannada-LLM-Labs","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.… See the full description on the dataset page: https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn","creator_name":"Indic-LLM-Labs","creator_url":"https://huggingface.co/Indic-LLM-Labs","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.… See the full description on the dataset page: https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"movieAudio","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shaggysus/movieAudio","creator_name":"Sandun de silva","creator_url":"https://huggingface.co/shaggysus","description":"shaggysus/movieAudio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"assamese_speech_corpus","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/madhabpaul/assamese_speech_corpus","creator_name":"Madhab Paul","creator_url":"https://huggingface.co/madhabpaul","description":"madhabpaul/assamese_speech_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Assamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"assamese_speech_corpus","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/madhabpaul/assamese_speech_corpus","creator_name":"Madhab Paul","creator_url":"https://huggingface.co/madhabpaul","description":"madhabpaul/assamese_speech_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Assamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"twi_dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d3vnerd/twi_dataset","creator_name":"jeffery crentsil","creator_url":"https://huggingface.co/d3vnerd","description":"d3vnerd/twi_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"zh-taiwan","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ivanzhu109/zh-taiwan","creator_name":"IvanZhu","creator_url":"https://huggingface.co/ivanzhu109","description":"ivanzhu109/zh-taiwan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Preprocessed-MS-IL-POST-Data","keyword":"parts-of-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/musfiqdehan/Preprocessed-MS-IL-POST-Data","creator_name":"Md. Musfiqur Rahaman","creator_url":"https://huggingface.co/musfiqdehan","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\n\n\t\n\t\t\n\t\tData Collection… See the full description on the dataset page: https://huggingface.co/datasets/musfiqdehan/Preprocessed-MS-IL-POST-Data.","first_N":5,"first_N_keywords":["text-classification","token-classification","Bengali","English","mit"],"keywords_longer_than_N":true},
	{"name":"asr-farsi-youtube-chunked-30-seconds","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/asr-farsi-youtube-chunked-30-seconds","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\n\t\n\t\t\n\t\tHow To Use\n\t\n\nfrom datasets import load_dataset\ntrain = load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='train+val')\ntest =load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='test')\n\n+300 Hours ASR dataset generated from this kaggle dataset\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"omega-multimodal","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/omegalabsinc/omega-multimodal","creator_name":"OMEGA Labs, Inc.","creator_url":"https://huggingface.co/omegalabsinc","description":"\n\t\n\t\t\n\t\tOMEGA Labs Bittensor Subnet: Multimodal Dataset for AGI Research\n\t\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe OMEGA Labs Bittensor Subnet Dataset is a groundbreaking resource for accelerating Artificial General Intelligence (AGI) research and development. This dataset, powered by the Bittensor decentralized network, aims to be the world's largest multimodal dataset, capturing the vast landscape of human knowledge and creation.\nWith over 1 million hours of footage and 30 million+ 2-minute video… See the full description on the dataset page: https://huggingface.co/datasets/omegalabsinc/omega-multimodal.","first_N":5,"first_N_keywords":["video-text-to-text","video-classification","image-classification","image-to-text","image-to-video"],"keywords_longer_than_N":true},
	{"name":"escagleu-64k","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/escagleu-64k","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for escagleu-64K corpus\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nescagleu-64k is a parallel corpus comprising 64091 sentences translated among Spanish, Catalan, Valencian Catalan, Galician, and Basque.\nThe original sentences are in Spanish and come from the Spanish Common Voice Corpus.\nWe prepared this corpus with the aim of creating a parallel speech dataset among these languages using the Common Voice platform between the frame of the… See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/escagleu-64k.","first_N":5,"first_N_keywords":["translation","audio-to-audio","automatic-speech-recognition","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"mls_eng_10k","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng_10k","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls_eng_10k","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng_10k","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls_eng","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls_eng","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls_eng","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"kor-hate-sentence","keyword":"hate-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SJ-Donald/kor-hate-sentence","creator_name":"SJ.KIM","creator_url":"https://huggingface.co/SJ-Donald","description":"\n\t\n\t\t\n\t\tSJ-Donald/kor-hate-sentence\n\t\n\nSJ-Donald/kor-hate-sentence is merged dataset from fllow\n\n\t\n\t\t\n\t\tDatasets\n\t\n\n\nsmilegate-ai/kor_unsmile\nkorean-hate-speech\nCurse-detection-data\nkorean-malicious-comments-dataset\n\nMerge datasets from above and drop duplicates.\n\n\t\n\t\t\n\t\n\t\n\t\tHow to use\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"SJ-Donald/kor-hate-sentence\")\nprint(ds)\n\nDatasetDict({\n    train: Dataset({\n        features: ['문장', 'hate', 'clean', 'labels'],\n        num_rows: 29328… See the full description on the dataset page: https://huggingface.co/datasets/SJ-Donald/kor-hate-sentence.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"mabama-v","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aztro/mabama-v","creator_name":"Jose Omar Vieyra","creator_url":"https://huggingface.co/aztro","description":"aztro/mabama-v dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"vivechan-spritual-text-dataset-v2","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v2","creator_name":"Om Ashishkumar Soni","creator_url":"https://huggingface.co/om-ashish-soni","description":"\n\t\n\t\t\n\t\tVivechan - Spiritual Text Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Vivechan - Spiritual Text Dataset is an open and public collection of textual data extracted from significant spiritual texts, curated to support discussions, inquiries, doubts, and Q&A sessions within the realm of spirituality. This dataset provides valuable content from the following revered sources:\n\nShrimad Bhagwat Mahapurana\nShripad Shri Vallabha Charitramrutam\nShiv Mahapurana Sankshipt\nValmiki Ramayan… See the full description on the dataset page: https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v2.","first_N":5,"first_N_keywords":["text-retrieval","text2text-generation","text-to-speech","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Hokchia","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yjhuang01/Hokchia","creator_name":"Yijun Huang","creator_url":"https://huggingface.co/yjhuang01","description":"\n\t\n\t\t\n\t\tHokchia Audio Dataset\n\t\n\nHokchia, or the Fuqing dialect, is a branch of Eastern Min Chinese spoken mainly in the Fuqing City of Fujian province, China. Unlike Hokkien, which is more widely recognized and spoken in various parts of Southeast Asia, Hokchia maintains its unique linguistic characteristics and is primarily used within the Fuqing community and its diaspora. This dialect is known for its distinct pronunciation, vocabulary, and grammatical structures compared to other Min… See the full description on the dataset page: https://huggingface.co/datasets/yjhuang01/Hokchia.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","original","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"luna-speech-dataset","keyword":"automatic-speech-recognition","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/luna-speech-dataset","creator_name":"Mateusz Czyżnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This speech dataset consists of 10385 short audio clips of multiple speakers conversing in Polish. A transcription is provided for each clip, also gender of speaker is provided for part of the dataset. Clips have total length of almost 10 hours.\nThis dataset was created from LUNA dataset of human-human and human-computer dialogues on the topic of public transport. The postprocessing consisted of extracting segments with human speech together with their transcripts. If you are interested in the… See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/luna-speech-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Polish","bsd-2-clause","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MediaSpeech","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tMediaSpeech\n\t\n\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\nBaseline models and WAV version of the dataset can be… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"MediaSpeech","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tMediaSpeech\n\t\n\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\nBaseline models and WAV version of the dataset can be… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"MediaSpeech","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tMediaSpeech\n\t\n\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\nBaseline models and WAV version of the dataset can be… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"jalandhary_asr","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirfan899/jalandhary_asr","creator_name":"Muhammad Irfan","creator_url":"https://huggingface.co/mirfan899","description":"Jalandhary dataset is created using whisper model for STT and TTS. Some audios are ommited due to issues while trimming them. If there are some isues \nin the dataset or audio not matching the text you can start a discussion or ping me to correcting it. \n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Urdu","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jalandhary_asr","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirfan899/jalandhary_asr","creator_name":"Muhammad Irfan","creator_url":"https://huggingface.co/mirfan899","description":"Jalandhary dataset is created using whisper model for STT and TTS. Some audios are ommited due to issues while trimming them. If there are some isues \nin the dataset or audio not matching the text you can start a discussion or ping me to correcting it. \n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Urdu","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_test_clean_word_timestamp","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/olympusmons/librispeech_asr_test_clean_word_timestamp","creator_name":"ML","creator_url":"https://huggingface.co/olympusmons","description":"\n\t\n\t\t\n\t\tWord-level timestamp annotated Librispeech ASR test set\n\t\n\nThis dataset contains word-level timestamp information for the Librispeech ASR test (clean) dataset.\nIt contains 2620 short files that have been force-aligned with its text to get reasonably accurate word-level timestamp information.\nSuitable for use in timestamp benchmarking of ASR models or audio dataset preprocessing.\nTo request access to more datasets like this, please fill out this form:… See the full description on the dataset page: https://huggingface.co/datasets/olympusmons/librispeech_asr_test_clean_word_timestamp.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"libritts_r_tags_tagged_10k_generated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/libritts_r_tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated LibriTTS-R\n\t\n\nThis dataset is an annotated version of LibriTTS-R [1]. LibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately 960 hours of read English speech at 24kHz sampling rate, published in 2019. \nIn the text_description column, it provides natural language annotations on the characteristics of speakers and utterances, that have been generated using the Data-Speech repository.… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Ergonomics_Chiar_Customer_Viewdata_E-commerse","keyword":"text-to-speech","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liaHa/Ergonomics_Chiar_Customer_Viewdata_E-commerse","creator_name":"lia","creator_url":"https://huggingface.co/liaHa","description":"liaHa/Ergonomics_Chiar_Customer_Viewdata_E-commerse dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["feature-extraction","text-classification","zero-shot-classification","text-to-speech","English"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"pwr-azon-speech-dataset","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/czyzi0/pwr-azon-speech-dataset","creator_name":"Mateusz Czyżnikiewicz","creator_url":"https://huggingface.co/czyzi0","description":"This speech dataset consists of 15332 short audio clips of multiple speakers speaking in Polish. Transcription is provided for 14491 audio clips (train split), and it is missing for 841 audio clips (unsup split). Gender of speaker is provided for the whole dataset. Clips have total length of almost 31 hours.\nThis dataset was created from Korpus nagrań próbek mowy do celów budowy modeli akustycznych dla automatycznego rozpoznawania mowy w języku polskim. The dataset was repackaged into easier… See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/pwr-azon-speech-dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Polish","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"px-corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bastiendechamps/px-corpus","creator_name":"Bastien Dechamps","creator_url":"https://huggingface.co/bastiendechamps","description":"\n\t\n\t\t\n\t\tPxCorpus : A Spoken Drug Prescription Dataset in French\n\t\n\nPxCorpus is to the best of our knowledge, the first spoken medical drug prescriptions corpus to be distributed. \nIt contains 4 hours of transcribed and annotated dialogues of drug prescriptions in \nFrench acquired through an experiment with 55 participants experts and non-experts  in drug prescriptions.\nThe automatic transcriptions were verified by human effort and aligned with \nsemantic labels to allow training of NLP models.… See the full description on the dataset page: https://huggingface.co/datasets/bastiendechamps/px-corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","French","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MEDISCO","keyword":"automatic-speech-recognition","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrqorib/MEDISCO","creator_name":"Reza Qorib","creator_url":"https://huggingface.co/mrqorib","description":"\n\t\n\t\t\n\t\tBuilding MEDISCO: Indonesian Speech Corpus for Medical Domain\n\t\n\nThe dataset was published in the following paper:\n\nBuilding MEDISCO: Indonesian Speech Corpus for Medical Domain (PDF | IEEEXplore) \nMuhammad Reza Qorib and Mirna Adriani \n2018 International Conference on Asian Language Processing (IALP)\n\nPlease look for the raw files (inside the \"Files and versions\" tab) as the dataset viewer parsed by Huggingface does not show the text transcript.\nPlease direct any questions to… See the full description on the dataset page: https://huggingface.co/datasets/mrqorib/MEDISCO.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Indonesian","gpl-3.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"BanglaEnglishMixedAsrDataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akhikhan123/BanglaEnglishMixedAsrDataset","creator_name":"Fatema Tuz Zohra Akhi","creator_url":"https://huggingface.co/akhikhan123","description":"akhikhan123/BanglaEnglishMixedAsrDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","Bengali","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"chuvash_voice","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexantonov/chuvash_voice","creator_name":"Alexander Antonov","creator_url":"https://huggingface.co/alexantonov","description":"\n\t\n\t\t\n\t\tHow to use\n\t\n\nWe recommend using our dataset in conjunction with the Common Voice Corpus. We have attempted to maintain a consistent structure.\nfrom datasets import load_dataset, DatasetDict, concatenate_datasets, Audio\n\ncomm_voice = DatasetDict()\ncomm_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"train+validation\", use_auth_token=True)\ncomm_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"test\", use_auth_token=True)… See the full description on the dataset page: https://huggingface.co/datasets/alexantonov/chuvash_voice.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chuvash","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"chuvash_voice","keyword":"text-to-speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexantonov/chuvash_voice","creator_name":"Alexander Antonov","creator_url":"https://huggingface.co/alexantonov","description":"\n\t\n\t\t\n\t\tHow to use\n\t\n\nWe recommend using our dataset in conjunction with the Common Voice Corpus. We have attempted to maintain a consistent structure.\nfrom datasets import load_dataset, DatasetDict, concatenate_datasets, Audio\n\ncomm_voice = DatasetDict()\ncomm_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"train+validation\", use_auth_token=True)\ncomm_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"test\", use_auth_token=True)… See the full description on the dataset page: https://huggingface.co/datasets/alexantonov/chuvash_voice.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chuvash","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton. The corpus was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in… See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"IndicSentiment","keyword":"hate-speech-detection","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA new, multilingual, and n-way parallel dataset for sentiment analysis in 13 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicSentimentClassification\"])\nevaluator =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicSentiment.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"spelling-correction-french-news","keyword":"grammar","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fdemelo/spelling-correction-french-news","creator_name":"Flávio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","description":"\n\t\n\t\t\n\t\tSpelling correction dataset (French)\n\t\n\nThis dataset is generated by transforming/corrupting sentences of a French news corpus\nprovided by the University of Leipzig.\nThe following transformations are applied to words in the sentences:\n\nconcatenation of pairs of words\nswapping of neighboring letters in words\ninsertion\ndeletion\nreplacement (by neighboring characters in AZERTY keyboard)\n\n\n\t\n\t\t\n\t\n\t\n\t\tGeneration\n\t\n\npip install happytransformer \n./scripts/get_data.py -t news -y 2023 -s 10K… See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/spelling-correction-french-news.","first_N":5,"first_N_keywords":["French","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Clapping_Sound_Dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/Clapping_Sound_Dataset","creator_name":"ninjagamer","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/Clapping_Sound_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"sampleDental","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/srirama/sampleDental","creator_name":"srirama","creator_url":"https://huggingface.co/srirama","description":"srirama/sampleDental dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Speech-MASSIVE_vie","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/Speech-MASSIVE_vie","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tVietnamse subset of the Speech-MASSIVE dataset\n\t\n\nextracted from:\n\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE-test\n\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-speechmassive.py\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Speech-MASSIVE_vie","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/Speech-MASSIVE_vie","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tVietnamse subset of the Speech-MASSIVE dataset\n\t\n\nextracted from:\n\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE-test\n\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-speechmassive.py\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ASCEND-phoneme","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/katyayego/ASCEND-phoneme","creator_name":"Katya Yegorova","creator_url":"https://huggingface.co/katyayego","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a modified version of the ASCEND dataset which consists of spontaneous Mandarin-English code-switched speech. The ASCEND dataset was published by Lovenia et al. (2022) (Check here for the dataset and here for the paper). \nThis dataset adds a phonetic transcription column to the dataset using the eSpeak backend from the phonemizer library created by Bernard et al. (2021) (Check it out here).\n\n\t\n\t\n\t\n\t\tthe following documentation is a modified version of… See the full description on the dataset page: https://huggingface.co/datasets/katyayego/ASCEND-phoneme.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","Chinese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BibleMMS_vie","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/BibleMMS_vie","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tVietnamse subset of the BibleMMS dataset\n\t\n\nextracted from: https://huggingface.co/datasets/Flux9665/BibleMMS\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-biblemms.py\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"BibleMMS_vie","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/BibleMMS_vie","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tVietnamse subset of the BibleMMS dataset\n\t\n\nextracted from: https://huggingface.co/datasets/Flux9665/BibleMMS\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-biblemms.py\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"arabic_quranic_asr","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadique5/arabic_quranic_asr","creator_name":"Sadique Abdullah","creator_url":"https://huggingface.co/Sadique5","description":"\n\t\n\t\t\n\t\tDataset details\n\t\n\nThis dataset contains quran recitations of every ayats or verses. Also contains 10k unique words from quran.\n\n\t\n\t\t\n\t\tDataset Purpose\n\t\n\nThis dataset can be used to train ASR models that can be used for teaching beginners to recite quran. It can also be used for training TTS models that produces quran recitations in a way so that beginners can easily learn.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arabic_quranic_asr","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadique5/arabic_quranic_asr","creator_name":"Sadique Abdullah","creator_url":"https://huggingface.co/Sadique5","description":"\n\t\n\t\t\n\t\tDataset details\n\t\n\nThis dataset contains quran recitations of every ayats or verses. Also contains 10k unique words from quran.\n\n\t\n\t\t\n\t\tDataset Purpose\n\t\n\nThis dataset can be used to train ASR models that can be used for teaching beginners to recite quran. It can also be used for training TTS models that produces quran recitations in a way so that beginners can easily learn.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"yogera_runyankore_ailab","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shawal777/yogera_runyankore_ailab","creator_name":"Shawal Mbalire","creator_url":"https://huggingface.co/Shawal777","description":"Shawal777/yogera_runyankore_ailab dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","image-to-text","Nyankole","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"persian_tts_stt","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SmartGitiCorp/persian_tts_stt","creator_name":"Smart Giti Corporation","creator_url":"https://huggingface.co/SmartGitiCorp","description":"This dataset contains more than 10k records and 15 hours of clear vocal voice aligning with text in csv file.\n","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"VietMed_unlabeled","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) unlabeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the unlabeled set: 966h - 230k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-unlabeled.py\nneed to do: check misspelling, restore foreign words phonetised to… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"VietMed_unlabeled","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) unlabeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the unlabeled set: 966h - 230k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-unlabeled.py\nneed to do: check misspelling, restore foreign words phonetised to… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"VietMed_labeled","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_labeled","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) labeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the labeled set: 9.2k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-labeled.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_labeled.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"VietMed_labeled","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMed_labeled","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) labeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the labeled set: 9.2k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-labeled.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_labeled.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"stock_market_asx_audio","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sdeering/stock_market_asx_audio","creator_name":"Sam","creator_url":"https://huggingface.co/sdeering","description":"\n\t\n\t\t\n\t\tDataset Card for Stock Market ASX Audio\n\t\n\nContains audios for every listed company on the Australian Stock Exchange (ASX). The dataset contains 2329 audio files of people saying the name of the company.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nsentence_id (string): An id for the sentence used for the recording.\nvoice_id (string): An id for which client (voice) made the recording.\naudio (dict): A dictionary containing the path to the downloaded audio file.\nsentence (string): The sentence the user was… See the full description on the dataset page: https://huggingface.co/datasets/sdeering/stock_market_asx_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","sdeering","google translate","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"darija_speech_to_text","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adiren7/darija_speech_to_text","creator_name":"Adil Oubaibou","creator_url":"https://huggingface.co/adiren7","description":"adiren7/darija_speech_to_text dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Libriheavy-HQ","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\n\t\n\t\t\n\t\tDataset Card for Libriheavy-HQ\n\t\n\n\n\nLibriheavy: a 50,000 hours ASR corpus with punctuation casing \nand context. Libriheavy is a labeled version of Libri-Light.\nLibriheavy-HQ replaces the default Libri-Light audio files with the highest quality available versions from librivox \nwithout re-encoding them. \nIn most cases, this consists an upgrade of the source audio from a 64kbps .mp3 to a 128kbps .mp3.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis is the Libriheavy-HQ dataset, adapted for the datasets… See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Libriheavy-HQ","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","description":"\n\t\n\t\t\n\t\tDataset Card for Libriheavy-HQ\n\t\n\n\n\nLibriheavy: a 50,000 hours ASR corpus with punctuation casing \nand context. Libriheavy is a labeled version of Libri-Light.\nLibriheavy-HQ replaces the default Libri-Light audio files with the highest quality available versions from librivox \nwithout re-encoding them. \nIn most cases, this consists an upgrade of the source audio from a 64kbps .mp3 to a 128kbps .mp3.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis is the Libriheavy-HQ dataset, adapted for the datasets… See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"mabama-v6","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gitgato/mabama-v6","creator_name":"Git Porter","creator_url":"https://huggingface.co/gitgato","description":"\n\t\n\t\t\n\t\tDataset mabama-v6\n\t\n\nDataset de audio para entrenar modelos de síntesis de voz (TTS) en español.\n\n\t\n\t\t\n\t\tDescripción\n\t\n\n\nContenido: Audios en español con sus transcripciones textuales.\nHablante: mabama (voz única).\nDuración total: X horas (ajusta este valor).\nTasa de muestreo: 22.05 kHz (o la que uses).\n\n\n\t\n\t\t\n\t\tEstructura\n\t\n\n","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"elcc","keyword":"linguistics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bboldt/elcc","creator_name":"Brendon Boldt","creator_url":"https://huggingface.co/bboldt","description":"\n\t\n\t\t\n\t\n\t\n\t\tELCC\n\t\n\nThe Emergent Language Corpus Collection is collection of corpora and metadata\nfrom a variety of emergent communication simulations.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing ELCC\n\t\n\nYou can clone this repository with git LFS and use the data directly or load\nthe data via the mlcroissant library.  To install the mlcroissant library and\nnecessary dependencies, see the conda environment at util/environment.yml.\nBelow we show an example of loading ELCC's data via mlcroissant.\nimport mlcroissant as mlc… See the full description on the dataset page: https://huggingface.co/datasets/bboldt/elcc.","first_N":5,"first_N_keywords":["cc-by-4.0","10M<n<100M","arxiv:2407.04158","doi:10.57967/hf/2533","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"kikongo-bible-asr","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/kikongo-bible-asr","creator_name":"NIONGOLO Chrys Fé-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tKikongo Bible ASR\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]… See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/kikongo-bible-asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kongo","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"kikongo-bible-asr","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/kikongo-bible-asr","creator_name":"NIONGOLO Chrys Fé-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tKikongo Bible ASR\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]… See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/kikongo-bible-asr.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kongo","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"killkan","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ctaguchi/killkan","creator_name":"Chihiro Taguchi","creator_url":"https://huggingface.co/ctaguchi","description":"\n\t\n\t\t\n\t\tKillkan: Speech Recognition dataset for Kichwa\n\t\n\nKillkan (Kichwa uyachkata payllatak killkak anta) is the first automatic speech recognition (ASR) dataset for the Kichwa language.\nSee also our paper (https://arxiv.org/abs/2404.15501).\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Quechua","Imbabura Highland Quichua","Chimborazo Highland Quichua","Salasaca Highland Quichua"],"keywords_longer_than_N":true},
	{"name":"GLOBE","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tUpdated\n\t\n\n\n\t\n\t\t\n\t\tYou can use the V3 version, which includes more data, detailed speech quality annotations, and the original Common Voice IDs.\n\t\n\n\n\t\n\t\t\n\t\tAlternatively, you can use the V2 version to avoid the abnormal voice volume issue in this version.\n\t\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to… See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"BibleMMS","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flux9665/BibleMMS","creator_name":"Florian Lux","creator_url":"https://huggingface.co/Flux9665","description":"The Dataset associated with the Paper \"Meta Learning Text-to-Speech Synthesis in over 7000 Languages\" by Florian Lux, Sarina Meyer, Lyonel Behringer, Frank Zalkow, Phat Do, Matt Coler, Emanuël A. P. Habets and Ngoc Thang Vu (Interspeech 2024).\nWe generate 2000 spoken utterances per language using the subsets of the eBible dataset [1] that are under free licenses as the text input to the MMS TTS models [2]. \nThe languages associated with the following ISO-639-3 codes are represented in this… See the full description on the dataset page: https://huggingface.co/datasets/Flux9665/BibleMMS.","first_N":5,"first_N_keywords":["text-to-speech","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v1","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tEwe bible for Text-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Ewe","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v1","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tEwe bible for Text-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Ewe","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v1","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tTwi Text-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Twi"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v1","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tTwi Text-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Twi"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v2_tts","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tText-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","translation","Ewe"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v2_tts","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ewe_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tText-to-Speech\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","translation","Ewe"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v2_tts","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tText-to-Speech Dataset\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Twi","Akan"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v2_tts","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/twi_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tText-to-Speech Dataset\n\t\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Twi","Akan"],"keywords_longer_than_N":true},
	{"name":"EUbookshop-Speech-Irish","keyword":"automatic-speech-recognition","license":"European Union Public License 1.1","license_url":"https://choosealicense.com/licenses/eupl-1.1/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the EUbookshop dataset, consisting of 33,634 text segments.\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 159 hours and 45 minutes (159:45:05) spread across 67,268 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"EUbookshop-Speech-Irish","keyword":"text-to-speech","license":"European Union Public License 1.1","license_url":"https://choosealicense.com/licenses/eupl-1.1/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the EUbookshop dataset, consisting of 33,634 text segments.\nThe dataset includes two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 159 hours and 45 minutes (159:45:05) spread across 67,268 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio'… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/EUbookshop-Speech-Irish.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"libritts_r_filtered","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/libritts_r_filtered","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Filtered LibriTTS-R\n\t\n\nThis is a filtered version of LibriTTS-R. It has been filtered based on two sources:\n\nLibriTTS-R paper [1], which lists samples for which speech restoration have failed\nLibriTTS-P [2] list of excluded speakers for which multiple speakers have been detected.\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_filtered.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"libritts_r_filtered","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parler-tts/libritts_r_filtered","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","description":"\n\t\n\t\t\n\t\tDataset Card for Filtered LibriTTS-R\n\t\n\nThis is a filtered version of LibriTTS-R. It has been filtered based on two sources:\n\nLibriTTS-R paper [1], which lists samples for which speech restoration have failed\nLibriTTS-P [2] list of excluded speakers for which multiple speakers have been detected.\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate… See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_filtered.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ToneBooks","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/ToneBooks","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tToneBooks\n\t\n\nToneBooks — большой русскоязычный датасет фрагментов аудиокниг с разметкой интонаций, тембра и эмоциональных характеристик голоса.\n\n\n\t\n\t\t\n\t\tОписание\n\t\n\nДля каждого аудиофрагмента собраны:\n\nТекстовая расшифровка (text)\nПодробное описание интонации и эмоций (text_description), структурированное по ключевым параметрам:\nAccent/Affect  \nVoice Affect  \nTone  \nPhrasing  \nPunctuation  \nEmotion  \nEmphasis  \nPronunciation  \nPauses  \nPersonality Affect— а также другие релевантные… See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneBooks.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ToneBooks","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/ToneBooks","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\n\t\n\t\t\n\t\tToneBooks\n\t\n\nToneBooks — большой русскоязычный датасет фрагментов аудиокниг с разметкой интонаций, тембра и эмоциональных характеристик голоса.\n\n\n\t\n\t\t\n\t\tОписание\n\t\n\nДля каждого аудиофрагмента собраны:\n\nТекстовая расшифровка (text)\nПодробное описание интонации и эмоций (text_description), структурированное по ключевым параметрам:\nAccent/Affect  \nVoice Affect  \nTone  \nPhrasing  \nPunctuation  \nEmotion  \nEmphasis  \nPronunciation  \nPauses  \nPersonality Affect— а также другие релевантные… See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneBooks.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"0.1_augmented_hate_speech_dataset","keyword":"hate-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emradar/0.1_augmented_hate_speech_dataset","creator_name":"Emir Adar","creator_url":"https://huggingface.co/emradar","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022) and augmented by Adar and Wiberg (2025).\nThis dataset card is a work in progress and will be improved over time.\n\n\t\n\t\t\n\t\tContributions\n\t\n\nDataset curated by @ck37, @pssachdeva and augmented by @emradar and @Wiberacci.\n\n\t\n\t\t\n\t\tReferences\n\t\n\nKennedy, C. J., Bacon, G., Sahn, A., & von Vacano, C. (2020). Constructing interval variables via faceted Rasch measurement and… See the full description on the dataset page: https://huggingface.co/datasets/emradar/0.1_augmented_hate_speech_dataset.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","arxiv:2009.10277","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"0.1_augmented_implicit_hate_speech_dataset","keyword":"hate-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/emradar/0.1_augmented_implicit_hate_speech_dataset","creator_name":"Emir Adar","creator_url":"https://huggingface.co/emradar","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a public release of the dataset described in ElSherief et al. (2022) and augmented by Adar and Wiberg (2025).\nThis dataset card is a work in progress and will be improved over time.\n\n\t\n\t\t\n\t\tContributions\n\t\n\nDataset augmented by @emradar and @Wiberacci.\n\n\t\n\t\t\n\t\tReferences\n\t\n\nElSherief, M., Ziems, C., Muchlinski, D., Anupindi, V., Seybolt, J., De Choudhury, M., & Yang, D. (2021). Latent Hatred: A Benchmark for Understanding Implicit Hate Speech. In Proceedings of… See the full description on the dataset page: https://huggingface.co/datasets/emradar/0.1_augmented_implicit_hate_speech_dataset.","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","arrow"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-3lang-raw","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-3lang-raw","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (3 Languages, Raw)\n\t\n\nThis dataset is a curated subset of previously published speech command datasets in Kazakh, Tatar, and Russian. It is intended for use in multilingual speech command recognition and keyword spotting tasks. No data augmentation has been applied.\nAll files are included in their original form as released in the cited works below. This repository simply reorganizes them for convenience and accessibility.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages… See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-3lang-raw.","first_N":5,"first_N_keywords":["Kazakh","Tatar","Russian","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting… See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang.","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"vocalno","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/t0bi4s/vocalno","creator_name":"sujiuheng","creator_url":"https://huggingface.co/t0bi4s","description":"\n\t\n\t\t\n\t\tTobias Chinese TTS Dataset\n\t\n\n这是一个中文文本转语音(TTS)数据集，包含约997个高质量的中文音频-文本对。\n\n\t\n\t\t\n\t\t数据集信息\n\t\n\n\n语言: 中文 (Chinese)\n任务: 文本转语音 (Text-to-Speech)\n样本数量: ~997个音频-文本对\n音频格式: WAV, 16kHz采样率\n许可证: MIT\n发言人: 单一发言人\n\n\n\t\n\t\t\n\t\t数据集结构\n\t\n\nfrom datasets import load_dataset\n\n# 加载完整数据集\ndataset = load_dataset(\"your_username/tobias-tts-chinese\")\n\n# 只加载训练集\ntrain_dataset = load_dataset(\"your_username/tobias-tts-chinese\", split=\"train\")\n\n# 只加载验证集\nvalidation_dataset = load_dataset(\"your_username/tobias-tts-chinese\"… See the full description on the dataset page: https://huggingface.co/datasets/t0bi4s/vocalno.","first_N":5,"first_N_keywords":["text-to-speech","Chinese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang-zip","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting… See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip.","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"LLM_Dys","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tong0/LLM_Dys","creator_name":"huanpm","creator_url":"https://huggingface.co/tong0","description":"\n\t\n\t\t\n\t\t🔊 LLM-Dys Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLLM-Dys is an innovative dataset that leverages large language models to help realistic dysfluent speech synthesis. This comprehensive dataset supports multiple types of dysfluency at different linguistic levels, enabling advanced research in speech synthesis and dysfluency analysis.\n\n\t\n\t\t\n\t\t🔍 Dysfluency Types\n\t\n\nOur dataset supports multiple types of dysfluency at both word and phoneme levels:\n\n\t\n\t\t\n\t\t✨ Key Features\n\t\n\n\nNatural and authentic… See the full description on the dataset page: https://huggingface.co/datasets/tong0/LLM_Dys.","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","automatic-speech-recognition","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LLM_Dys","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tong0/LLM_Dys","creator_name":"huanpm","creator_url":"https://huggingface.co/tong0","description":"\n\t\n\t\t\n\t\t🔊 LLM-Dys Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLLM-Dys is an innovative dataset that leverages large language models to help realistic dysfluent speech synthesis. This comprehensive dataset supports multiple types of dysfluency at different linguistic levels, enabling advanced research in speech synthesis and dysfluency analysis.\n\n\t\n\t\t\n\t\t🔍 Dysfluency Types\n\t\n\nOur dataset supports multiple types of dysfluency at both word and phoneme levels:\n\n\t\n\t\t\n\t\t✨ Key Features\n\t\n\n\nNatural and authentic… See the full description on the dataset page: https://huggingface.co/datasets/tong0/LLM_Dys.","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","automatic-speech-recognition","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LLM_Dys","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tong0/LLM_Dys","creator_name":"huanpm","creator_url":"https://huggingface.co/tong0","description":"\n\t\n\t\t\n\t\t🔊 LLM-Dys Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLLM-Dys is an innovative dataset that leverages large language models to help realistic dysfluent speech synthesis. This comprehensive dataset supports multiple types of dysfluency at different linguistic levels, enabling advanced research in speech synthesis and dysfluency analysis.\n\n\t\n\t\t\n\t\t🔍 Dysfluency Types\n\t\n\nOur dataset supports multiple types of dysfluency at both word and phoneme levels:\n\n\t\n\t\t\n\t\t✨ Key Features\n\t\n\n\nNatural and authentic… See the full description on the dataset page: https://huggingface.co/datasets/tong0/LLM_Dys.","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","automatic-speech-recognition","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"LLM_Dys","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tong0/LLM_Dys","creator_name":"huanpm","creator_url":"https://huggingface.co/tong0","description":"\n\t\n\t\t\n\t\t🔊 LLM-Dys Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLLM-Dys is an innovative dataset that leverages large language models to help realistic dysfluent speech synthesis. This comprehensive dataset supports multiple types of dysfluency at different linguistic levels, enabling advanced research in speech synthesis and dysfluency analysis.\n\n\t\n\t\t\n\t\t🔍 Dysfluency Types\n\t\n\nOur dataset supports multiple types of dysfluency at both word and phoneme levels:\n\n\t\n\t\t\n\t\t✨ Key Features\n\t\n\n\nNatural and authentic… See the full description on the dataset page: https://huggingface.co/datasets/tong0/LLM_Dys.","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","automatic-speech-recognition","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise… See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise… See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-multispeaker","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 21138 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 21138 audio files > 1KB… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-multispeaker","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 21138 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 21138 audio files > 1KB… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-multispeaker","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 21138 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 21138 audio files > 1KB… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"russian_librispeech","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/istupakov/russian_librispeech","creator_name":"Ilya Stupakov","creator_url":"https://huggingface.co/istupakov","description":"\n\t\n\t\t\n\t\tRussian LibriSpeech (RuLS)\n\t\n\nIdentifier: SLR96 from openslr.org\nSummary: This dataset is based on LibriVox audiobooks\nCategory: Speech\nLicense: The dataset is Public Domain in the USA.\nAbout this resource:\nRussian LibriSpeech (RuLS) dataset is based on LibriVox's public domain audio books (see BOOKS.TXT for the list of included books) and contains about 98 hours of audio data.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"russian_librispeech","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/istupakov/russian_librispeech","creator_name":"Ilya Stupakov","creator_url":"https://huggingface.co/istupakov","description":"\n\t\n\t\t\n\t\tRussian LibriSpeech (RuLS)\n\t\n\nIdentifier: SLR96 from openslr.org\nSummary: This dataset is based on LibriVox audiobooks\nCategory: Speech\nLicense: The dataset is Public Domain in the USA.\nAbout this resource:\nRussian LibriSpeech (RuLS) dataset is based on LibriVox's public domain audio books (see BOOKS.TXT for the list of included books) and contains about 98 hours of audio data.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/audiobooks","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tCrimean Tatar Audiobooks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCrimean Tatar Audiobooks is a speech dataset sourced from different sources (public radio stations/youtube channels) containing audiobooks in Crimean Tatar. The dataset comprises recordings of different native fiction books, all read by a single female speaker (for now). The dataset is intended for text-to-speech (TTS) research and development in the Crimean Tatar language. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains… See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/audiobooks.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Crimean Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/audiobooks","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tCrimean Tatar Audiobooks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCrimean Tatar Audiobooks is a speech dataset sourced from different sources (public radio stations/youtube channels) containing audiobooks in Crimean Tatar. The dataset comprises recordings of different native fiction books, all read by a single female speaker (for now). The dataset is intended for text-to-speech (TTS) research and development in the Crimean Tatar language. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains… See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/audiobooks.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Crimean Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gaydmi/audiobooks","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","description":"\n\t\n\t\t\n\t\tCrimean Tatar Audiobooks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCrimean Tatar Audiobooks is a speech dataset sourced from different sources (public radio stations/youtube channels) containing audiobooks in Crimean Tatar. The dataset comprises recordings of different native fiction books, all read by a single female speaker (for now). The dataset is intended for text-to-speech (TTS) research and development in the Crimean Tatar language. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains… See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/audiobooks.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Crimean Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"voxceleb","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alphaqmoi/voxceleb","creator_name":"Victor Kwemoi","creator_url":"https://huggingface.co/alphaqmoi","description":"This dataset includes both VoxCeleb and VoxCeleb2\n\n\t\n\t\t\n\t\tMultipart Zips\n\t\n\nAlready joined zips for convenience but these specified files are NOT part of the original datasets\nvox2_mp4_1.zip - vox2_mp4_6.zip \nvox2_aac_1.zip - vox2_aac_2.zip \n\n\t\n\t\t\n\t\tJoining Zip\n\t\n\ncat vox1_dev* > vox1_dev_wav.zip\n\ncat vox2_dev_aac* > vox2_aac.zip\n\ncat vox2_dev_mp4* > vox2_mp4.zip\n\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@article{Nagrani19,\n    author = \"Arsha Nagrani and Joon~Son Chung and Weidi Xie and Andrew… See the full description on the dataset page: https://huggingface.co/datasets/alphaqmoi/voxceleb.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","image-classification","video-classification","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V3","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MushanW/GLOBE_V3","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V3 version and two previous versions (V1|V2):\n\nThis version is built base on Common Voice 21.0 English Subset.\n   This version only includes utterance that are an exact match with the transcription from Whisper V3 LARGE (CER == 0).\n   This version includes the original Common Voice metadata (age, gender, accent, and ID).\n   All audio files in this version are at 24kHz sampling rate.\n   All audio files in this version are unenhanced. (We’d greatly… See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V3.","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech_test_vad","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/guynich/multilingual_librispeech_test_vad","creator_name":"Guy Nicholson","creator_url":"https://huggingface.co/guynich","description":"Voice Activity Detection (VAD) Test Dataset\nThis dataset is based on the test splits found in\nmultilingual_librispeech\ndataset.  It includes two binary features:\n\nspeech: Indicates presence of speech ([0, 1]), computed using a dynamic threshold method with background noise estimation and smoothing.\n\nconfidence: A post-processing flag to optionally correct transient dropouts in speech. It is set to 1 by default, but switches to 0 for up to ~0.1 seconds (3 chunks of audio) following a transition… See the full description on the dataset page: https://huggingface.co/datasets/guynich/multilingual_librispeech_test_vad.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","keyword":"speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","creator_name":"MAdel","creator_url":"https://huggingface.co/MAdel121","description":"\n\t\n\t\t\n\t\tCurated Arabic Speech Dataset for Seasme (from MCV17)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a curated and preprocessed version of the Arabic (ar) subset from Mozilla Common Voice (MCV) 17.0. It has been specifically prepared for fine-tuning conversational speech models, with a primary focus on the Seasme-CSM model architecture. The dataset consists of audio clips in WAV format (24kHz, mono) and their corresponding transcripts, along with integer speaker IDs.\nThe original… See the full description on the dataset page: https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning.","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"mls-speechtokenizer","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anilkeshwani/mls-speechtokenizer","creator_name":"Anil Keshwani","creator_url":"https://huggingface.co/anilkeshwani","description":"anilkeshwani/mls-speechtokenizer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mls-speechtokenizer","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/anilkeshwani/mls-speechtokenizer","creator_name":"Anil Keshwani","creator_url":"https://huggingface.co/anilkeshwani","description":"anilkeshwani/mls-speechtokenizer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"my_dataset_2","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kashif314/my_dataset_2","creator_name":"kashif","creator_url":"https://huggingface.co/kashif314","description":"kashif314/my_dataset_2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Urdu","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Punjabi","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Punjabi","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tPunjabi Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Punjabi monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Punjabi\nTotal Duration: ~20 hours (Male: 10 hours, Female: 10 hours)\nAudio Format: WAV\nSampling Rate: 48000Hz… See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Punjabi.","first_N":5,"first_N_keywords":["text-to-speech","pb","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"sTinyStories","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/sTinyStories","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\n\t\n\t\t\n\t\tsTinyStories\n\t\n\nA spoken version of TinyStories Synthesized with LJ voice using FastSpeech2.\nThe dataset was synthesized to boost the training of Speech Language Models as detailed in the paper \"Slamming: Training a Speech Language Model on One GPU in a Day\".\nIt was first suggested by Cuervo et. al 2024.\nWe refer you to the SlamKit codebase to see how you can train a SpeechLM with this dataset.\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/slprl/sTinyStories.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"sTinyStories","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/slprl/sTinyStories","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","description":"\n\t\n\t\t\n\t\tsTinyStories\n\t\n\nA spoken version of TinyStories Synthesized with LJ voice using FastSpeech2.\nThe dataset was synthesized to boost the training of Speech Language Models as detailed in the paper \"Slamming: Training a Speech Language Model on One GPU in a Day\".\nIt was first suggested by Cuervo et. al 2024.\nWe refer you to the SlamKit codebase to see how you can train a SpeechLM with this dataset.\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/slprl/sTinyStories.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_parquet_10k","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (10k)\n\t\n\nThis dataset contains 20000 synthetic speech recordings in the Pashto language,\nwith 10000 male voice recordings and 10000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 10000 sentences\nTotal Recordings: 20000 audio files (10000 male + 10000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_parquet_10k","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (10k)\n\t\n\nThis dataset contains 20000 synthetic speech recordings in the Pashto language,\nwith 10000 male voice recordings and 10000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 10000 sentences\nTotal Recordings: 20000 audio files (10000 male + 10000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"qirimtatar-tts","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/qirimtatar-tts","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tVoices\n\t\n\n\n\t\n\t\t\n\t\tMale\n\t\n\n\n\t\n\t\t\n\t\tAbibullah\n\t\n\n\nQuality: high\nDuration: 2h + 50m\nAudio formats: OPUS\nFrequency: 48000 Hz\n\n\n\t\n\t\t\n\t\tArslan\n\t\n\n\nQuality: high\nDuration: 40m + 40m\nAudio formats: OPUS\nFrequency: 48000 Hz\n\n\n\t\n\t\t\n\t\tFemale\n\t\n\n\n\t\n\t\t\n\t\tSevil\n\t\n\n\nQuality:… See the full description on the dataset page: https://huggingface.co/datasets/Yehor/qirimtatar-tts.","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"rulibrispeech","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sh1man/rulibrispeech","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nwav 16kHz\n\n\t\n\t\t\n\t\t📊 Статистика датасета\n\t\n\n\n\t\n\t\t\n\t\tИнформация по сплитам\n\t\n\n\n\t\n\t\t\n\t\t🔹 Тренировочный набор (train)\n\t\n\n\n\t\n\t\t\nМетрика\nЗначение\n\n\n\t\t\nКоличество семплов\n54,472\n\n\nОбщая продолжительность\n92.79 часов (334028.33 секунд)\n\n\nСредняя продолжительность семпла\n6.13 секунд\n\n\n\t\n\n\n\t\n\t\t\n\t\t🔹 Валидационный набор (validate)\n\t\n\n\n\t\n\t\t\nМетрика\nЗначение\n\n\n\t\t\nКоличество семплов\n1,400\n\n\nОбщая продолжительность\n2.81 часов (10105.46 секунд)\n\n\nСредняя продолжительность семпла\n7.22… See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rulibrispeech.","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","10K - 100K","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"latam-spanish-speech-orpheus-tts-24khz","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz","creator_name":"Gian Diego Javes Lecca","creator_url":"https://huggingface.co/GianDiego","description":"\n\t\n\t\t\n\t\tLATAM Spanish High-Quality Speech Dataset (24kHz - Orpheus TTS Ready)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains approximately 24 hours of high-quality speech audio in Latin American Spanish, specifically prepared for Text-to-Speech (TTS) applications like OrpheusTTS, which require a 24kHz sampling rate.\nThe audio files are derived from the Crowdsourced high-quality speech datasets made by Google and were obtained via OpenSLR. The original recordings were high-quality… See the full description on the dataset page: https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","monolingual","original:openslr","Spanish"],"keywords_longer_than_N":true},
	{"name":"latam-spanish-speech-orpheus-tts-24khz","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz","creator_name":"Gian Diego Javes Lecca","creator_url":"https://huggingface.co/GianDiego","description":"\n\t\n\t\t\n\t\tLATAM Spanish High-Quality Speech Dataset (24kHz - Orpheus TTS Ready)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains approximately 24 hours of high-quality speech audio in Latin American Spanish, specifically prepared for Text-to-Speech (TTS) applications like OrpheusTTS, which require a 24kHz sampling rate.\nThe audio files are derived from the Crowdsourced high-quality speech datasets made by Google and were obtained via OpenSLR. The original recordings were high-quality… See the full description on the dataset page: https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","monolingual","original:openslr","Spanish"],"keywords_longer_than_N":true},
	{"name":"latam-spanish-speech-orpheus-tts-24khz","keyword":"speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz","creator_name":"Gian Diego Javes Lecca","creator_url":"https://huggingface.co/GianDiego","description":"\n\t\n\t\t\n\t\tLATAM Spanish High-Quality Speech Dataset (24kHz - Orpheus TTS Ready)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains approximately 24 hours of high-quality speech audio in Latin American Spanish, specifically prepared for Text-to-Speech (TTS) applications like OrpheusTTS, which require a 24kHz sampling rate.\nThe audio files are derived from the Crowdsourced high-quality speech datasets made by Google and were obtained via OpenSLR. The original recordings were high-quality… See the full description on the dataset page: https://huggingface.co/datasets/GianDiego/latam-spanish-speech-orpheus-tts-24khz.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","monolingual","original:openslr","Spanish"],"keywords_longer_than_N":true},
	{"name":"talromur3_without_emotions","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/atlithor/talromur3_without_emotions","creator_name":"Atli","creator_url":"https://huggingface.co/atlithor","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis corpus is an emotion-less version of Talromur3_with_prompts. talromur_3_without_emotions is a prompt-labelled corpus that can be used for fine-tuning models, such as ParlerTTS.The corpus consists of approximately 15,000 utterances, spoken by 7 named speakers in 6 different emotions (see more info here).\nThe dataset is an expanded version of Talromur-3: an Icelandic emotional speech corpus.We have added natural-language descriptions of utterance-level pitch, speech… See the full description on the dataset page: https://huggingface.co/datasets/atlithor/talromur3_without_emotions.","first_N":5,"first_N_keywords":["text-to-speech","Icelandic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"KSL-LEX","keyword":"linguistics","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AAILab/KSL-LEX","creator_name":"Assistive AI Lab @ KAIST","creator_url":"https://huggingface.co/AAILab","description":"\n\t\n\t\t\n\t\tDataset Card for KSL-LEX\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nKSL-LEX is a publicly available lexical database of Korean Sign Language (KSL), inspired by the ASL-LEX project (American Sign Language Lexical Database). It is based on the Korean Sign Language Dictionary's everyday signs collection, which contains 3,669 signs, but has been expanded to include more detailed linguistic information, resulting in 6,463 entries (6,289 unique headwords).\nThe primary… See the full description on the dataset page: https://huggingface.co/datasets/AAILab/KSL-LEX.","first_N":5,"first_N_keywords":["Korean","gpl-3.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential… See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential… See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential… See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"TOSD","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tamazight-NLP/TOSD","creator_name":"Tamazight NLP","creator_url":"https://huggingface.co/Tamazight-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Tamazight Open Speech Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/Tamazight-NLP/TOSD.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Standard Moroccan Tamazight","ber","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"TOSD","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tamazight-NLP/TOSD","creator_name":"Tamazight NLP","creator_url":"https://huggingface.co/Tamazight-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Tamazight Open Speech Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/Tamazight-NLP/TOSD.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Standard Moroccan Tamazight","ber","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"farsi-asr-dataset","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/farsi-asr/farsi-asr-dataset","creator_name":"Farsi ASR","creator_url":"https://huggingface.co/farsi-asr","description":"\n\n\t\n\t\t\n\t\tFarsi ASR Dataset\n\t\n\nThe largest open-source Persian Automatic Speech Recognition (ASR) dataset, collected from various sources. The codes associated with the collection of this dataset is also available in the Farsi ASR Dataset GitHub repository.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","mit","1M<n<10M","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"mlc-mlsw-melspects","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/einstein8612/mlc-mlsw-melspects","creator_name":"Joey Li","creator_url":"https://huggingface.co/einstein8612","description":"\n\t\n\t\t\n\t\tMLCommons Multilingual Spoken Words Mel-Spectograms\n\t\n\nThis dataset contains all English words from the dataset available at MLCommons (or also available on huggingface). These audio files have been processed into Mel spectrograms for downstream usage in DCNNs or similar processes.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset description\n\t\n\nThere's a total of 6624343 samples of Mel spectograms. There are a total of 38150 different words, the cls is the index of that word in alphabetical order. With every entry… See the full description on the dataset page: https://huggingface.co/datasets/einstein8612/mlc-mlsw-melspects.","first_N":5,"first_N_keywords":["zero-shot-classification","audio-classification","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"sinhala-bank-speech","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech","creator_name":"Ishan Sugathadasa","creator_url":"https://huggingface.co/IshanSuga","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThis dataset contains 100 audio files, one male voice in the format .wav. \nThe domain of this dataset is Banking.Only Language is Sinhalese(Sinhala,si)\nTotal Duration: 700.283 seconds.\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by… See the full description on the dataset page: https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Sinhala","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Lux-Japanese-Speech-Corpus","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus","creator_name":"KohnoseLami","creator_url":"https://huggingface.co/Lami","description":"\n\t\n\t\t\n\t\tLux Japanese Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\nLux Japanese Speech Corpus は、オリジナルキャラクター「Lux (ルクス)」による日本語のテキスト読み上げ音声を収録したデータセットです。このデータセットは、以下の2種類の音声ファイルで構成されています。\n\nraw: 加工前の 96kHz/16bit の WAV ファイル\ncleaned: ノイズ除去などの処理を施した 96kHz/16bit の WAV ファイル\n\n各音声ファイルに対応するトランスクリプション（読み上げた文章）は、metadata.csv に記録しています。データセット全体のメタ情報は dataset_infos.json で管理されています。\n\n\t\n\t\t\n\t\tディレクトリ構造\n\t\n\n以下は、このリポジトリの推奨ディレクトリ構造の例です。\nLux-Japanese-Speech-Corpus/\n├── .gitattributes           # Gitのカスタマイズファイル\n├── README.md… See the full description on the dataset page: https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-4.0","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"Lux-Japanese-Speech-Corpus","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus","creator_name":"KohnoseLami","creator_url":"https://huggingface.co/Lami","description":"\n\t\n\t\t\n\t\tLux Japanese Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\nLux Japanese Speech Corpus は、オリジナルキャラクター「Lux (ルクス)」による日本語のテキスト読み上げ音声を収録したデータセットです。このデータセットは、以下の2種類の音声ファイルで構成されています。\n\nraw: 加工前の 96kHz/16bit の WAV ファイル\ncleaned: ノイズ除去などの処理を施した 96kHz/16bit の WAV ファイル\n\n各音声ファイルに対応するトランスクリプション（読み上げた文章）は、metadata.csv に記録しています。データセット全体のメタ情報は dataset_infos.json で管理されています。\n\n\t\n\t\t\n\t\tディレクトリ構造\n\t\n\n以下は、このリポジトリの推奨ディレクトリ構造の例です。\nLux-Japanese-Speech-Corpus/\n├── .gitattributes           # Gitのカスタマイズファイル\n├── README.md… See the full description on the dataset page: https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-4.0","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"ScreenTalk-XS","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataLabX/ScreenTalk-XS","creator_name":"Itbanque","creator_url":"https://huggingface.co/DataLabX","description":"\n\t\n\t\t\n\t\t🎬 ScreenTalk-XS: Sample Speech Dataset from Screen Content 🖥️\n\t\n\n  \n\n\t\n\t\t\n\t\n\t\n\t\t📢 What is ScreenTalk-XS?\n\t\n\nScreenTalk-XS is a high-quality transcribed speech dataset containing 10k speech samples from diverse screen content.It is designed for automatic speech recognition (ASR), natural language processing (NLP), and conversational AI research.  \n✅ This dataset is freely available for research and educational use.🔹 If you need a larger dataset with more diverse speech samples… See the full description on the dataset page: https://huggingface.co/datasets/DataLabX/ScreenTalk-XS.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"nepali_speech_to_text","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text","creator_name":"Pujan Paudel","creator_url":"https://huggingface.co/pujanpaudel","description":"\n\t\n\t\t\n\t\tNepali Speech-to-Text Dataset\n\t\n\nThis repository contains a dataset for Automatic Speech Recognition (ASR) in the Nepali language. The dataset is designed for supervised learning tasks and includes audio files along with their corresponding transcriptions. The audio samples have been collected from various open-source platforms and other publicly available sources on the internet.  \nEach audio file has an average length of 15 seconds and has been converted into a consistent WAV format… See the full description on the dataset page: https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Nepali","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"havacilik-veriseti","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mehmedadymn/havacilik-veriseti","creator_name":"adıyaman","creator_url":"https://huggingface.co/mehmedadymn","description":"\n\t\n\t\t\n\t\tATC Veri Kümesi - Whisper Modeli ile İnce Ayar\n\t\n\nBu veri kümesi, OpenAI'nin Whisper modelini, Hava Trafik Kontrolü (ATC) iletişimlerinde transkripsiyon doğruluğunu artırmak amacıyla ince ayar yapmak için oluşturulmuştur. Veri kümesi, iki ana kaynaktan alınan transkripsiyonlar ve karşılık gelen ses dosyalarını içermektedir: ATCO2 ve UWB-ATCC korpusu, özellikle havacılıkla ilgili iletişimler için seçilmiştir. Veri kümesi, Otomatik Konuşma Tanıma (ASR) projelerinde kullanılmak üzere… See the full description on the dataset page: https://huggingface.co/datasets/mehmedadymn/havacilik-veriseti.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","Turkish","English","mit"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_2_7","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise… See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_2_7","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise… See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"raw_1hr_myanmar_asr_audio","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t🇲🇲 Raw 1-Hour Burmese ASR Audio Dataset\n\t\n\nA 1-hour dataset of Burmese (Myanmar language) spoken audio clips with transcripts, curated from official public-service media broadcasts by PVTV Myanmar — the media voice of Myanmar’s National Unity Government (NUG).\nThis dataset is intended for automatic speech recognition (ASR) and Burmese speech-processing research.\n➡️ Author: freococo➡️ License: MIT➡️ Language: Burmese (my)\n\n\n\t\n\t\t\n\t\n\t\n\t\t📦 Dataset Summary\n\t\n\n\nDuration: ~1 hour\nChunks:… See the full description on the dataset page: https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"raw_1hr_myanmar_asr_audio","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t🇲🇲 Raw 1-Hour Burmese ASR Audio Dataset\n\t\n\nA 1-hour dataset of Burmese (Myanmar language) spoken audio clips with transcripts, curated from official public-service media broadcasts by PVTV Myanmar — the media voice of Myanmar’s National Unity Government (NUG).\nThis dataset is intended for automatic speech recognition (ASR) and Burmese speech-processing research.\n➡️ Author: freococo➡️ License: MIT➡️ Language: Burmese (my)\n\n\n\t\n\t\t\n\t\n\t\n\t\t📦 Dataset Summary\n\t\n\n\nDuration: ~1 hour\nChunks:… See the full description on the dataset page: https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"kasem-words-speech-text-parallel","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/kasem-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tKasem Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 997676 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 997676 audio files > 1KB… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-words-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"kasem-words-speech-text-parallel","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/kasem-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tKasem Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 997676 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 997676 audio files > 1KB… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-words-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"kasem-words-speech-text-parallel","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/kasem-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tKasem Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 997676 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 997676 audio files > 1KB… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-words-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"kasem-speech-text-parallel","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tKasem Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 75990 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 75990 audio files > 1KB… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"kasem-speech-text-parallel","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tKasem Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 75990 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 75990 audio files > 1KB… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"kasem-speech-text-parallel","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tKasem Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 75990 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 75990 audio files > 1KB… See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"Balanced_hate_speech18","keyword":"hate-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/architrawat25/Balanced_hate_speech18","creator_name":"Archit Rawat","creator_url":"https://huggingface.co/architrawat25","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/architrawat25/Balanced_hate_speech18.","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"HumSpeechBlend","keyword":"speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend","creator_name":"Sourabh Saini","creator_url":"https://huggingface.co/CuriousMonkey7","description":"\n\t\n\t\t\n\t\tWORK IN PROGRESS\n\t\n\n\n\t\n\t\t\n\t\t[WIP]HumSpeechBlend Dataset: Humming vs Speech Detection\n\t\n\n\n\t\n\t\t\n\t\t📌 Overview\n\t\n\nHumSpeechBlend is a dataset designed to fine-tune Voice Activity Detection (VAD) models to distinguish between humming and actual speech. Current VAD models often misclassify humming as speech, leading to incorrect segmentation in speech processing tasks. This dataset provides a structured collection of humming audio interspersed with speech to help improve model accuracy.… See the full description on the dataset page: https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend.","first_N":5,"first_N_keywords":["voice-activity-detection","English","cc-by-sa-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"augmented_codealpaca-20k-using-together-ai-deepseek-v1","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eagle0504/augmented_codealpaca-20k-using-together-ai-deepseek-v1","creator_name":"Yiqiao Yin","creator_url":"https://huggingface.co/eagle0504","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset, named CodeAlpaca-20k, consists of examples that blend coding instructions with outputs and reasoning. Each entry includes structured fields like output, instruction, input, and cot (Chain of Thought). It is particularly designed to train and evaluate AI models that generate code and explanations based on simple programming tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tData Collection and Preparation\n\t\n\nData entries are augmented using the augment_answer function that makes API… See the full description on the dataset page: https://huggingface.co/datasets/eagle0504/augmented_codealpaca-20k-using-together-ai-deepseek-v1.","first_N":5,"first_N_keywords":["reinforcement-learning","text-generation","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset 🎤\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\t🎙️ Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"automatic-speech-recognition","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset 🎤\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\t🎙️ Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset 🎤\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\t🎙️ Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset 🎤\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\t🎙️ Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the… See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"real-world-noise-through-zoom","keyword":"automatic-speech-recognition","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KoelLabs/real-world-noise-through-zoom","creator_name":"Koel Labs","creator_url":"https://huggingface.co/KoelLabs","description":"\n\t\n\t\t\n\t\tReal-World Noise Through Zoom (RWNTZ)\n\t\n\n\n5 different real world noise settings (bedroom, crowded room, background music, rain, road with cars)\n2 different speakers\nvarious microphone distances (6 inches, 24 inches)\n32 total samples with different phrases\nrecorded through Zoom to simulate real-world linguistic fieldwork scenarios\nmanually verified word level transcriptions\ng2p phoneme trancriptions\naudio to phoneme trancriptions with a variety of Wav2Vec2 based models\n\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","agpl-3.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"whisper-internal-test","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulus/whisper-internal-test","creator_name":"Minseok Lee","creator_url":"https://huggingface.co/neulus","description":"Original datasets can be found in shb777/gemini-flash-2.0-speech.\nFor personal testing purposes.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"task2_advanced","keyword":"linguistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lamdary/task2_advanced","creator_name":"Daria Malysheva","creator_url":"https://huggingface.co/lamdary","description":"\n\t\n\t\t\n\t\tСтатистический анализ и визуализация\n\t\n\n\n\t\n\t\t\n\t\tОписание\n\t\n\nДанный датасет представляет результат статистического анализа текста книги \"Harry Potter and the Philosopher's Stone\", выполненного с использованием различных методов обработки естественного языка. В процессе анализа были проведены три ключевых типа анализа:\n\nАнализ уникальности данных: Оценка доли уникальных слов в корпусе текста и вычисление коэффициента лексического разнообразия.\nАнализ частоты POS-тегов: Изучение частоты… See the full description on the dataset page: https://huggingface.co/datasets/lamdary/task2_advanced.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"natasha_sova_ai","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/intexcp/natasha_sova_ai","creator_name":"Ivan","creator_url":"https://huggingface.co/intexcp","description":"This is a saved natasha dataset from SOVA AI\n","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","1B<n<10B","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"ruslan_sova_ai","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/intexcp/ruslan_sova_ai","creator_name":"Ivan","creator_url":"https://huggingface.co/intexcp","description":"This is a saved ruslan dataset from SOVA AI\n","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"cv10-uk-testset-clean","keyword":"automatic-speech-recognition","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yehor/cv10-uk-testset-clean","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","description":"\n\t\n\t\t\n\t\tThe cleaned Common Voice 10 (test set) that has been checked by a human for Ukrainian 🇺🇦\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains the archive of Common Voice 10 (test set) with checked Ukrainian transcriptions and audios.\nAll audios have been checked by a human to be sure that they are correct. \nThis archive is used to test all ASR models listed here: https://github.com/egorsmkv/speech-recognition-uk\n\n\t\n\t\t\n\t\n\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech… See the full description on the dataset page: https://huggingface.co/datasets/Yehor/cv10-uk-testset-clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Ukrainian","mpl-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"syntetic_necoarc_rus","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kostya165/syntetic_necoarc_rus","creator_name":"pleroma_cascade","creator_url":"https://huggingface.co/Kostya165","description":"\n\t\n\t\t\n\t\tОписание датасета\n\t\n\nЭтот датасет содержит синтетические аудиозаписи русской речи, обработанные с использованием технологии RVC (Retrieval-based Voice Conversion) NecoArc. Датасет предназначен для обучения и тестирования моделей синтеза и распознавания речи на русском языке.\nЯ не осилил файнтюн TTS модели легковесной , так что если сможете сделать это буду благодарен за обратную связь\n\nЯзык: Русский\nЛицензия: MIT\n\n\n\t\n\t\t\n\t\n\t\n\t\tСтруктура датасета\n\t\n\nДатасет содержит следующие поля:\n\ntext… See the full description on the dataset page: https://huggingface.co/datasets/Kostya165/syntetic_necoarc_rus.","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"YouTube_Video_Transkriptleri_TR","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anilosan15/YouTube_Video_Transkriptleri_TR","creator_name":"Hüseyin Anıl Çakmak","creator_url":"https://huggingface.co/Anilosan15","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of nearly 5 hours of video from over 40 Creative Commons-licensed videos on YouTube. The videos contain the voices of more than 100 different people. The audio files have been resampled to 16 kHz. The videos have been divided into chunks of up to 25 seconds. This dataset is intended for developing Turkish STT (Speech-to-Text) models.\n\n\t\n\t\t\n\t\tDatasets Preparetion\n\t\n\nThe audio files and transcript data were scraped from YouTube. The scraped… See the full description on the dataset page: https://huggingface.co/datasets/Anilosan15/YouTube_Video_Transkriptleri_TR.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"common-voice-20-mn-normalized","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized","creator_name":"Ankhbayasgalan Davaadorj","creator_url":"https://huggingface.co/warmestman","description":"\n\t\n\t\t\n\t\tCommon Voice 20.0 Mongolian Dataset\n\t\n\nThis dataset is a subset of Mozilla's Common Voice project, containing Mongolian speech data. It's part of Common Voice 20.0 release.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio clips in .mp3 format\nTranscriptions for each audio clip\nTrain/test/dev splits\nAdditional metadata including speaker demographics\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nSpeech Recognition\nVoice Analysis\nLinguistic Research\nSpeech Processing… See the full description on the dataset page: https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Mongolian","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"common-voice-20-mn-normalized","keyword":"speech","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized","creator_name":"Ankhbayasgalan Davaadorj","creator_url":"https://huggingface.co/warmestman","description":"\n\t\n\t\t\n\t\tCommon Voice 20.0 Mongolian Dataset\n\t\n\nThis dataset is a subset of Mozilla's Common Voice project, containing Mongolian speech data. It's part of Common Voice 20.0 release.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio clips in .mp3 format\nTranscriptions for each audio clip\nTrain/test/dev splits\nAdditional metadata including speaker demographics\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nSpeech Recognition\nVoice Analysis\nLinguistic Research\nSpeech Processing… See the full description on the dataset page: https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Mongolian","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AudioNormalizationDatasetRVC","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Illia56/AudioNormalizationDatasetRVC","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","description":"Illia56/AudioNormalizationDatasetRVC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","Russian","apache-2.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"Tamazight-ASR-Dataset-v2","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2","creator_name":"Soufiane Dahimi","creator_url":"https://huggingface.co/SoufianeDahimi","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains speech segments in Tamazight (specifically focusing on the Tachelhit dialect) paired with their corresponding Arabic transcriptions. It is designed to support the development of automatic speech recognition (ASR) systems for the Tamazight language, particularly for translation into Modern Standard Arabic.\nThis is an actively growing dataset, with regular updates and new data points being… See the full description on the dataset page: https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"libritts-r-mimi","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jkeisling/libritts-r-mimi","creator_name":"Jacob Keisling","creator_url":"https://huggingface.co/jkeisling","description":"\n\t\n\t\t\n\t\tLibriTTS-R Mimi encoding\n\t\n\nThis dataset converts all audio in the dev.clean, test.clean, train.100 and train.360 splits of the LibriTTS-R dataset from waveforms to tokens in Kyutai's Mimi neural codec.\nThese tokens are intended as targets for DualAR audio models, but also allow you to simply download all audio in ~50-100x less space, if you're comfortable decoding later on with rustymimi or Transformers.\nThis does NOT contain the original audio, please use the regular LibriTTS-R for… See the full description on the dataset page: https://huggingface.co/datasets/jkeisling/libritts-r-mimi.","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MiSide-Japanese","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AkitoP/MiSide-Japanese","creator_name":"L","creator_url":"https://huggingface.co/AkitoP","description":"AkitoP/MiSide-Japanese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Japanese","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"OpenSpeech-Dataset-by-Wang","keyword":"text-to-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VIZINTZOR/OpenSpeech-Dataset-by-Wang","creator_name":"VYNCX","creator_url":"https://huggingface.co/VIZINTZOR","description":"Dataset หลัก : https://www.wang.in.th/\nข้อมูล Dataset : \n\nไฟล์เสียงประมาณ 8,450 ไฟล์\n\nจำนวนเวลาทั้งหมดประมาณ 10 ชั่วโมง\n\nSampling Rate 48,000 hz(เพิ่มคุณภาพเสียงและลดเสียงรบกวนด้วย AI)\n\nประเภทไฟล์ Zip\n\nmetadata.csv\n\n\n00001.wav|ขอเปิดบัญชีธนาคารครับ\n00002.wav|ฉันว่าไปเชียงรายดีกว่า\n00003.wav|ใช้ใบรับรองเงินเดือนไหมค่ะ\n....\n\n","first_N":5,"first_N_keywords":["text-to-speech","Thai","cc-by-sa-4.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"nigerian_common_voice_dataset","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Common Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Common Voice Dataset is a comprehensive dataset consisting of 158 hours of audio recordings and corresponding transcription (sentence). \nThis dataset includes metadata like accent, locale that can help improve the accuracy of speech recognition engines. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for… See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"nigerian_common_voice_dataset","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Common Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Common Voice Dataset is a comprehensive dataset consisting of 158 hours of audio recordings and corresponding transcription (sentence). \nThis dataset includes metadata like accent, locale that can help improve the accuracy of speech recognition engines. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for… See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","description":"\n\n  \n\n\n\n  \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to use.For a detailed guide on how this dataset was created, follow the steps outlined in the GitHub repository: ParquetToHuggingFace.\n\n\t\n\t\t\n\t\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","description":"\n\n  \n\n\n\n  \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to use.For a detailed guide on how this dataset was created, follow the steps outlined in the GitHub repository: ParquetToHuggingFace.\n\n\t\n\t\t\n\t\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","description":"\n\n  \n\n\n\n  \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to use.For a detailed guide on how this dataset was created, follow the steps outlined in the GitHub repository: ParquetToHuggingFace.\n\n\t\n\t\t\n\t\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"thai-ser","keyword":"speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/airesearch/thai-ser","creator_name":"VISTEC-depa AI Research Institute of Thailand","creator_url":"https://huggingface.co/airesearch","description":"\n\t\n\t\t\n\t\t🇹🇭 THAI-SER Dataset 🎭\n\t\n\nPublished by: AI Research Institute of Thailand (AIResearch)\nIn collaboration with:  \n\nVidyasirimedhi Institute of Science and Technology (VISTEC)  \nDigital Economy Promotion Agency (depa)  \nDepartment of Computer Engineering, Faculty of Engineering, Chulalongkorn University  \nDepartment of Dramatic Arts, Faculty of Arts, Chulalongkorn University\n\nSponsored by: Advanced Info Services Public Company Limited (AIS), and Siam Commercial Bank (SCB)… See the full description on the dataset page: https://huggingface.co/datasets/airesearch/thai-ser.","first_N":5,"first_N_keywords":["audio-classification","Thai","cc-by-sa-4.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_eseu_v1.0","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/composite_corpus_eseu_v1.0","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\n\t\n\t\t\n\t\tComposite bilingual dataset for Spanish and Basque made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/es: a portion of the \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\nmozilla-foundation/common_voice_18_0/eu:… See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_eseu_v1.0.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","Spanish","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"VietMDD","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/doof-ferb/VietMDD","creator_name":"Phan Tuấn Anh","creator_url":"https://huggingface.co/doof-ferb","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMMD (Mispronunciation Detection and Diagnosis)\n\t\n\nofficial announcement: https://github.com/VietMDDDataset/VietMDD\nofficial download: https://drive.google.com/drive/folders/1TjTluTxEB99QhGFTYFWb-vEdWXM-lyKJ?usp=sharing\nDOI: 10.21437/Interspeech.2023-364\n5h, 4.2k samples\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/viet-mdd.py\n\ncustom split: orphan: speech without any transcription unlike in train/validation/test… See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMDD.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-google-fleurs","keyword":"text-to-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (Google Fleurs)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual Google Fleurs dataset.\nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof Google Fleurs HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark.… See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-google-fleurs","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (Google Fleurs)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual Google Fleurs dataset.\nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof Google Fleurs HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark.… See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-google-fleurs","keyword":"speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (Google Fleurs)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual Google Fleurs dataset.\nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof Google Fleurs HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark.… See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_en","keyword":"text-to-speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minghanw/sdf_dataset_en","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated… See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_en.","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_en","keyword":"speech","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minghanw/sdf_dataset_en","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated… See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_en.","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"no-filter-raw-NepaliParliamentDSv2","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kiranpantha/no-filter-raw-NepaliParliamentDSv2","creator_name":"Kiran Pantha","creator_url":"https://huggingface.co/kiranpantha","description":"kiranpantha/no-filter-raw-NepaliParliamentDSv2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"HATS-fr","keyword":"speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thibault-baneras-roux/HATS-fr","creator_name":"Thibault Bañeras-Roux","creator_url":"https://huggingface.co/thibault-baneras-roux","description":"\n\t\n\t\t\n\t\t🗃️ HATS Dataset\n\t\n\nHATS (Human Assessed Transcription Side-by-Side) is a data set for French 🇫🇷 which consists of 1,000 triplets (reference, hypothesis A, hypothesis B) and 7,150 human choice annotated by 143 subjects 🫂 Their objective was to select, given a textual reference, which of two erroneous hypotheses is the best.\n\n\n\n\n\nCurated by: Thibault Bañeras-Roux, Richard Dufour, Jane Wottawa, Mickael Rouvier, Teva Merlin\nFunded by: Agence Nationale de la Recherche - DIETS project… See the full description on the dataset page: https://huggingface.co/datasets/thibault-baneras-roux/HATS-fr.","first_N":5,"first_N_keywords":["French","mit","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"FeruzaSpeech_to_fine_tuning","keyword":"automatic-speech-recognition","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nickoo004/FeruzaSpeech_to_fine_tuning","creator_name":"Nicholas","creator_url":"https://huggingface.co/nickoo004","description":"\n\t\n\t\t\n\t\tFeruzaSpeech_to_fine_tuning\n\t\n\nA speech corpus of ⏱️ ~59.1 total hours of Uzbek audio paired with Latin‑script transcripts, intended for fine‑tuning ASR / speech‑to‑text models.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains recordings of native Uzbek speakers reading a mix of classical literature excerpts and school‑level writing prompts:\n\n001: Choliqushi (a novel by Rashod Nuri Guntekin, trans. by Mirzakalon Ismoiliy; first pub. Sept 1900).  \n002:… See the full description on the dataset page: https://huggingface.co/datasets/nickoo004/FeruzaSpeech_to_fine_tuning.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-audio","Uzbek","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"common_voice_21.0","keyword":"automatic-speech-recognition","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/common_voice_21.0","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nPartie en breton du jeu de données Common Voice 21.0.  \n\n\t\n\t\t\n\t\tChamps\n\t\n\n\naudio (dict) : Un dictionnaire contenant le chemin vers le fichier audio téléchargé, l'audio décodé et la fréquence d'échantillonnage.Notez que lors de l'accès à la colonne audio : dataset[0][\"audio\"], le fichier audio est automatiquement décodé et rééchantillonné à dataset.features[\"audio\"].sampling_rate. Le décodage et le rééchantillonnage d'un grand nombre de fichiers audio peuvent prendre… See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/common_voice_21.0.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Breton","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_test_vad","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/guynich/librispeech_asr_test_vad","creator_name":"Guy Nicholson","creator_url":"https://huggingface.co/guynich","description":"Voice Activity Detection (VAD) Test Dataset\nThis dataset is based on the test.clean and test.other splits from the\nlibrispeech_asr\ncorpus. It includes two binary features:\n\nspeech: Indicates presence of speech ([0, 1]), computed using a dynamic threshold method with background noise estimation and smoothing.\n\nconfidence: A post-processing flag to optionally correct transient dropouts in speech. It is set to 1 by default, but switches to 0 for up to ~0.1 seconds (3 chunks of audio) following a… See the full description on the dataset page: https://huggingface.co/datasets/guynich/librispeech_asr_test_vad.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"EmoVoice-DB","keyword":"text-to-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yhaha/EmoVoice-DB","creator_name":"yangguanrou","creator_url":"https://huggingface.co/yhaha","description":"\n\t\n\t\t\n\t\tDataset Card for EmoVoice-DB\n\t\n\n\n\t\n\t\t\n\t\tOverview of EmoVoice-DB\n\t\n\nEmoVoice-DB is an English emotional speech dataset featuring fine-grained emotion labels expressed through natural language descriptions. This dataset contains over 20,000 emotionally expressive speech samples, each annotated with detailed and precise emotional descriptions, totaling approximately 40 hours of audio. EmoVoice-DB is built using synthetic data generated by the powerful… See the full description on the dataset page: https://huggingface.co/datasets/yhaha/EmoVoice-DB.","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"grammar_sq_0.1","keyword":"grammar","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LTS-VVE/grammar_sq_0.1","creator_name":"LTS","creator_url":"https://huggingface.co/LTS-VVE","description":"\n\t\n\t\t\n\t\tPhysics and Math Problems Dataset\n\t\n\nThis repository contains a dataset of 5,623 enteries of different Albanian linguistics to improve Albanian queries further by introducing Albanian language rules and literature. The dataset is designed to support various NLP tasks and educational applications.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Rows: 5,623\nLanguage: Albanian\nTopics:\nemrat: gjinia (mashkullore, femërore, asnjanëse), numri (njëjës, shumës), format dialektore: 29\nemrat: format e… See the full description on the dataset page: https://huggingface.co/datasets/LTS-VVE/grammar_sq_0.1.","first_N":5,"first_N_keywords":["question-answering","Albanian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"transcription-scorer","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/transcription-scorer","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"\n\t\n\t\t\n\t\tTranscription Scorer Dataset\n\t\n\nThe Transcription Scorer dataset was created to support research in reference-free evaluation of Automatic Speech Recognition (ASR) systems using human feedback. Unlike traditional evaluation metrics such as WER and its derivatives, this dataset reflects subjective judgments of ASR outputs by human raters across multiple criteria, simulating the way a teacher grades students.\n\n\t\n\t\t\n\t\n\t\n\t\t⚙️ What’s Inside\n\t\n\nThis dataset contains 2153 audio samples (from… See the full description on the dataset page: https://huggingface.co/datasets/RobotsMali/transcription-scorer.","first_N":5,"first_N_keywords":["automatic-speech-recognition","reinforcement-learning","audio-classification","expert-annotated","found"],"keywords_longer_than_N":true},
	{"name":"transcription-scorer","keyword":"speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobotsMali/transcription-scorer","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"\n\t\n\t\t\n\t\tTranscription Scorer Dataset\n\t\n\nThe Transcription Scorer dataset was created to support research in reference-free evaluation of Automatic Speech Recognition (ASR) systems using human feedback. Unlike traditional evaluation metrics such as WER and its derivatives, this dataset reflects subjective judgments of ASR outputs by human raters across multiple criteria, simulating the way a teacher grades students.\n\n\t\n\t\t\n\t\n\t\n\t\t⚙️ What’s Inside\n\t\n\nThis dataset contains 2153 audio samples (from… See the full description on the dataset page: https://huggingface.co/datasets/RobotsMali/transcription-scorer.","first_N":5,"first_N_keywords":["automatic-speech-recognition","reinforcement-learning","audio-classification","expert-annotated","found"],"keywords_longer_than_N":true},
	{"name":"data-kit-sub-iwslt2025-if-long-constraint","keyword":"automatic-speech-recognition","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint","creator_name":"Maike Züfle","creator_url":"https://huggingface.co/maikezu","description":"\n\t\n\t\t\n\t\tData for KIT’s Instruction Following Submission for IWSLT 2025\n\t\n\nThis repo contains the data used to train our model for IWSLT 2025's Instruction-Following (IF) Speech Processing track.\nIWSLT 2025's Instruction-Following (IF) Speech Processing track in the scientific domain aims to benchmark foundation models that can follow natural \nlanguage instructions—an ability well-established in textbased LLMs but still emerging in speech-based counterparts. Our approach employs an end-to-end… See the full description on the dataset page: https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint.","first_N":5,"first_N_keywords":["automatic-speech-recognition","summarization","question-answering","translation","English"],"keywords_longer_than_N":true}
]
;
